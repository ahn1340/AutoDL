/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Using TensorFlow backend.
WARNING:tensorflow:From /home/ahnj/repo/autodl/AutoDL/model.py:27: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /home/ahnj/repo/autodl/AutoDL/model.py:31: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2020-03-09 18:39:34.519007: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-03-09 18:39:34.522949: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299960000 Hz
2020-03-09 18:39:34.523370: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5643dba3c530 executing computations on platform Host. Devices:
2020-03-09 18:39:34.523404: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-03-09 18:39:34.524315: I tensorflow/core/common_runtime/direct_session.cc:296] Device mapping:
/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device

18:39:34 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7fac6fa13668; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:36714>
18:39:34 WORKER: No dispatcher found. Waiting for one to initiate contact.
18:39:34 WORKER: start listening for jobs
18:39:34 wait_for_workers trying to get the condition
18:39:34 DISPATCHER: started the 'discover_worker' thread
18:39:34 DISPATCHER: started the 'job_runner' thread
18:39:34 DISPATCHER: Pyro daemon running on localhost:45767
18:39:34 DISPATCHER: Starting worker discovery
18:39:34 DISPATCHER: Found 1 potential workers, 0 currently in the pool.
18:39:34 DISPATCHER: discovered new worker, hpbandster.run_0.worker.metagpuj.30597140382006277952
18:39:34 HBMASTER: number of workers changed to 1
18:39:34 Enough workers to start this run!
18:39:34 adjust_queue_size: lock accquired
18:39:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:39:34 HBMASTER: starting run at 1583775574.6227458
18:39:34 HBMASTER: adjusted queue size to (0, 1)
18:39:34 DISPATCHER: Finished worker discovery
18:39:34 start sampling a new configuration.
18:39:34 DISPATCHER: Trying to submit another job.
18:39:34 done sampling a new configuration.
18:39:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:39:34 HBMASTER: schedule new run for iteration 0
18:39:34 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
18:39:34 HBMASTER: submitting job (0, 0, 0) to dispatcher
18:39:34 DISPATCHER: trying to submit job (0, 0, 0)
18:39:34 DISPATCHER: trying to notify the job_runner thread.
18:39:34 HBMASTER: job (0, 0, 0) submitted to dispatcher
18:39:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:39:34 DISPATCHER: Trying to submit another job.
18:39:34 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:39:34 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:39:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:39:34 WORKER: start processing job (0, 0, 0)
18:39:34 WORKER: args: ()
18:39:34 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 642, 'last_n_outputs': 18, 'leak_rate': 0.9800767858693685, 'lr': 0.0019990835235604433, 'optimizer': 'SGD', 'sparsity': 0.8193293006408634, 'steps_to_train': 93, 'weight_decay': 0.11009601256710216}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:40:34 DISPATCHER: Starting worker discovery
18:40:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:40:34 DISPATCHER: Finished worker discovery
18:41:34 DISPATCHER: Starting worker discovery
18:41:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:41:34 DISPATCHER: Finished worker discovery
18:41:38 WORKER: done with job (0, 0, 0), trying to register it.
18:41:38 WORKER: registered result for job (0, 0, 0) with dispatcher
18:41:38 DISPATCHER: job (0, 0, 0) finished
18:41:38 DISPATCHER: register_result: lock acquired
18:41:38 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
18:41:38 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 642, 'last_n_outputs': 18, 'leak_rate': 0.9800767858693685, 'lr': 0.0019990835235604433, 'optimizer': 'SGD', 'sparsity': 0.8193293006408634, 'steps_to_train': 93, 'weight_decay': 0.11009601256710216}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2847135865630731, 'info': {'music_genre': 0.2847135865630731, 'config': "{'batch_size': 16, 'hidden_dim': 642, 'last_n_outputs': 18, 'leak_rate': 0.9800767858693685, 'lr': 0.0019990835235604433, 'optimizer': 'SGD', 'sparsity': 0.8193293006408634, 'steps_to_train': 93, 'weight_decay': 0.11009601256710216}"}}
exception: None

18:41:38 job_callback for (0, 0, 0) started
18:41:38 DISPATCHER: Trying to submit another job.
18:41:38 job_callback for (0, 0, 0) got condition
18:41:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:41:38 Only 1 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
18:41:38 HBMASTER: Trying to run another job!
18:41:38 job_callback for (0, 0, 0) finished
18:41:38 start sampling a new configuration.
18:41:38 done sampling a new configuration.
18:41:38 HBMASTER: schedule new run for iteration 0
18:41:38 HBMASTER: trying submitting job (0, 0, 1) to dispatcher
18:41:38 HBMASTER: submitting job (0, 0, 1) to dispatcher
18:41:38 DISPATCHER: trying to submit job (0, 0, 1)
18:41:38 DISPATCHER: trying to notify the job_runner thread.
18:41:38 HBMASTER: job (0, 0, 1) submitted to dispatcher
18:41:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:41:38 DISPATCHER: Trying to submit another job.
18:41:38 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:41:38 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:41:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:41:38 WORKER: start processing job (0, 0, 1)
18:41:38 WORKER: args: ()
18:41:38 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 860, 'last_n_outputs': 37, 'leak_rate': 0.9332334335474193, 'lr': 0.0018048897299553276, 'optimizer': 'Adam', 'sparsity': 0.7526127280824344, 'steps_to_train': 64, 'weight_decay': 0.05932818562804613}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:42:34 DISPATCHER: Starting worker discovery
18:42:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:42:34 DISPATCHER: Finished worker discovery
18:43:33 WORKER: done with job (0, 0, 1), trying to register it.
18:43:33 WORKER: registered result for job (0, 0, 1) with dispatcher
18:43:33 DISPATCHER: job (0, 0, 1) finished
18:43:33 DISPATCHER: register_result: lock acquired
18:43:33 DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
18:43:33 job_id: (0, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 860, 'last_n_outputs': 37, 'leak_rate': 0.9332334335474193, 'lr': 0.0018048897299553276, 'optimizer': 'Adam', 'sparsity': 0.7526127280824344, 'steps_to_train': 64, 'weight_decay': 0.05932818562804613}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1807276147898562, 'info': {'music_genre': 0.1807276147898562, 'config': "{'batch_size': 16, 'hidden_dim': 860, 'last_n_outputs': 37, 'leak_rate': 0.9332334335474193, 'lr': 0.0018048897299553276, 'optimizer': 'Adam', 'sparsity': 0.7526127280824344, 'steps_to_train': 64, 'weight_decay': 0.05932818562804613}"}}
exception: None

18:43:33 job_callback for (0, 0, 1) started
18:43:33 job_callback for (0, 0, 1) got condition
18:43:33 DISPATCHER: Trying to submit another job.
18:43:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:43:33 Only 2 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
18:43:33 HBMASTER: Trying to run another job!
18:43:33 job_callback for (0, 0, 1) finished
18:43:33 start sampling a new configuration.
18:43:33 done sampling a new configuration.
18:43:33 HBMASTER: schedule new run for iteration 0
18:43:33 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
18:43:33 HBMASTER: submitting job (0, 0, 2) to dispatcher
18:43:33 DISPATCHER: trying to submit job (0, 0, 2)
18:43:33 DISPATCHER: trying to notify the job_runner thread.
18:43:33 HBMASTER: job (0, 0, 2) submitted to dispatcher
18:43:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:43:33 DISPATCHER: Trying to submit another job.
18:43:33 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:43:33 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:43:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:43:33 WORKER: start processing job (0, 0, 2)
18:43:33 WORKER: args: ()
18:43:33 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 221, 'last_n_outputs': 35, 'leak_rate': 0.974191059675765, 'lr': 0.04357793051288152, 'optimizer': 'SGD', 'sparsity': 0.9053486453564421, 'steps_to_train': 88, 'weight_decay': 0.019016856446360073}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:43:34 DISPATCHER: Starting worker discovery
18:43:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:43:34 DISPATCHER: Finished worker discovery
18:44:34 DISPATCHER: Starting worker discovery
18:44:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:44:34 DISPATCHER: Finished worker discovery
18:45:29 WORKER: done with job (0, 0, 2), trying to register it.
18:45:29 WORKER: registered result for job (0, 0, 2) with dispatcher
18:45:29 DISPATCHER: job (0, 0, 2) finished
18:45:29 DISPATCHER: register_result: lock acquired
18:45:29 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
18:45:29 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 221, 'last_n_outputs': 35, 'leak_rate': 0.974191059675765, 'lr': 0.04357793051288152, 'optimizer': 'SGD', 'sparsity': 0.9053486453564421, 'steps_to_train': 88, 'weight_decay': 0.019016856446360073}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.28249959559605053, 'info': {'music_genre': 0.28249959559605053, 'config': "{'batch_size': 32, 'hidden_dim': 221, 'last_n_outputs': 35, 'leak_rate': 0.974191059675765, 'lr': 0.04357793051288152, 'optimizer': 'SGD', 'sparsity': 0.9053486453564421, 'steps_to_train': 88, 'weight_decay': 0.019016856446360073}"}}
exception: None

18:45:29 job_callback for (0, 0, 2) started
18:45:29 job_callback for (0, 0, 2) got condition
18:45:29 DISPATCHER: Trying to submit another job.
18:45:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:45:29 Only 3 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
18:45:29 HBMASTER: Trying to run another job!
18:45:29 job_callback for (0, 0, 2) finished
18:45:29 start sampling a new configuration.
18:45:29 done sampling a new configuration.
18:45:29 HBMASTER: schedule new run for iteration 0
18:45:29 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
18:45:29 HBMASTER: submitting job (0, 0, 3) to dispatcher
18:45:29 DISPATCHER: trying to submit job (0, 0, 3)
18:45:29 DISPATCHER: trying to notify the job_runner thread.
18:45:29 HBMASTER: job (0, 0, 3) submitted to dispatcher
18:45:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:45:29 DISPATCHER: Trying to submit another job.
18:45:29 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:45:29 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:45:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:45:29 WORKER: start processing job (0, 0, 3)
18:45:29 WORKER: args: ()
18:45:29 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 336, 'last_n_outputs': 17, 'leak_rate': 0.8114219935540625, 'lr': 0.029473296876905558, 'optimizer': 'SGD', 'sparsity': 0.8969716241122381, 'steps_to_train': 95, 'weight_decay': 0.014325611558931153}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:45:34 DISPATCHER: Starting worker discovery
18:45:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:45:34 DISPATCHER: Finished worker discovery
18:46:34 DISPATCHER: Starting worker discovery
18:46:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:46:34 DISPATCHER: Finished worker discovery
18:47:10 WORKER: done with job (0, 0, 3), trying to register it.
18:47:10 WORKER: registered result for job (0, 0, 3) with dispatcher
18:47:10 DISPATCHER: job (0, 0, 3) finished
18:47:10 DISPATCHER: register_result: lock acquired
18:47:10 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
18:47:10 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 336, 'last_n_outputs': 17, 'leak_rate': 0.8114219935540625, 'lr': 0.029473296876905558, 'optimizer': 'SGD', 'sparsity': 0.8969716241122381, 'steps_to_train': 95, 'weight_decay': 0.014325611558931153}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.33742426875252884, 'info': {'music_genre': 0.33742426875252884, 'config': "{'batch_size': 64, 'hidden_dim': 336, 'last_n_outputs': 17, 'leak_rate': 0.8114219935540625, 'lr': 0.029473296876905558, 'optimizer': 'SGD', 'sparsity': 0.8969716241122381, 'steps_to_train': 95, 'weight_decay': 0.014325611558931153}"}}
exception: None

18:47:10 job_callback for (0, 0, 3) started
18:47:10 DISPATCHER: Trying to submit another job.
18:47:10 job_callback for (0, 0, 3) got condition
18:47:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:47:10 Only 4 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
18:47:10 HBMASTER: Trying to run another job!
18:47:10 job_callback for (0, 0, 3) finished
18:47:10 start sampling a new configuration.
18:47:10 done sampling a new configuration.
18:47:10 HBMASTER: schedule new run for iteration 0
18:47:10 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
18:47:10 HBMASTER: submitting job (0, 0, 4) to dispatcher
18:47:10 DISPATCHER: trying to submit job (0, 0, 4)
18:47:10 DISPATCHER: trying to notify the job_runner thread.
18:47:10 HBMASTER: job (0, 0, 4) submitted to dispatcher
18:47:10 DISPATCHER: Trying to submit another job.
18:47:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:47:10 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:47:10 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:47:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:47:10 WORKER: start processing job (0, 0, 4)
18:47:10 WORKER: args: ()
18:47:10 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 672, 'last_n_outputs': 25, 'leak_rate': 0.8615532224088688, 'lr': 0.04014773578203432, 'optimizer': 'SGD', 'sparsity': 0.8239901680578856, 'steps_to_train': 24, 'weight_decay': 0.02099052887802536}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:47:34 DISPATCHER: Starting worker discovery
18:47:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:47:34 DISPATCHER: Finished worker discovery
18:48:34 DISPATCHER: Starting worker discovery
18:48:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:48:34 DISPATCHER: Finished worker discovery
18:48:56 WORKER: done with job (0, 0, 4), trying to register it.
18:48:56 WORKER: registered result for job (0, 0, 4) with dispatcher
18:48:56 DISPATCHER: job (0, 0, 4) finished
18:48:56 DISPATCHER: register_result: lock acquired
18:48:56 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
18:48:56 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 672, 'last_n_outputs': 25, 'leak_rate': 0.8615532224088688, 'lr': 0.04014773578203432, 'optimizer': 'SGD', 'sparsity': 0.8239901680578856, 'steps_to_train': 24, 'weight_decay': 0.02099052887802536}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.271067231522379, 'info': {'music_genre': 0.271067231522379, 'config': "{'batch_size': 16, 'hidden_dim': 672, 'last_n_outputs': 25, 'leak_rate': 0.8615532224088688, 'lr': 0.04014773578203432, 'optimizer': 'SGD', 'sparsity': 0.8239901680578856, 'steps_to_train': 24, 'weight_decay': 0.02099052887802536}"}}
exception: None

18:48:56 job_callback for (0, 0, 4) started
18:48:56 job_callback for (0, 0, 4) got condition
18:48:56 DISPATCHER: Trying to submit another job.
18:48:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:48:56 Only 5 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
18:48:56 HBMASTER: Trying to run another job!
18:48:56 job_callback for (0, 0, 4) finished
18:48:56 start sampling a new configuration.
18:48:56 done sampling a new configuration.
18:48:56 HBMASTER: schedule new run for iteration 0
18:48:56 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
18:48:56 HBMASTER: submitting job (0, 0, 5) to dispatcher
18:48:56 DISPATCHER: trying to submit job (0, 0, 5)
18:48:56 DISPATCHER: trying to notify the job_runner thread.
18:48:56 HBMASTER: job (0, 0, 5) submitted to dispatcher
18:48:56 DISPATCHER: Trying to submit another job.
18:48:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:48:56 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:48:56 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:48:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:48:56 WORKER: start processing job (0, 0, 5)
18:48:56 WORKER: args: ()
18:48:56 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 610, 'last_n_outputs': 23, 'leak_rate': 0.9852129860039525, 'lr': 0.0018536160987891865, 'optimizer': 'SGD', 'sparsity': 0.9265468848113043, 'steps_to_train': 68, 'weight_decay': 0.03720912584797996}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:49:34 DISPATCHER: Starting worker discovery
18:49:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:49:34 DISPATCHER: Finished worker discovery
18:50:34 DISPATCHER: Starting worker discovery
18:50:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:50:34 DISPATCHER: Finished worker discovery
18:50:43 WORKER: done with job (0, 0, 5), trying to register it.
18:50:43 WORKER: registered result for job (0, 0, 5) with dispatcher
18:50:43 DISPATCHER: job (0, 0, 5) finished
18:50:43 DISPATCHER: register_result: lock acquired
18:50:43 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
18:50:43 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 610, 'last_n_outputs': 23, 'leak_rate': 0.9852129860039525, 'lr': 0.0018536160987891865, 'optimizer': 'SGD', 'sparsity': 0.9265468848113043, 'steps_to_train': 68, 'weight_decay': 0.03720912584797996}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.23564915820391685, 'info': {'music_genre': 0.23564915820391685, 'config': "{'batch_size': 16, 'hidden_dim': 610, 'last_n_outputs': 23, 'leak_rate': 0.9852129860039525, 'lr': 0.0018536160987891865, 'optimizer': 'SGD', 'sparsity': 0.9265468848113043, 'steps_to_train': 68, 'weight_decay': 0.03720912584797996}"}}
exception: None

18:50:43 job_callback for (0, 0, 5) started
18:50:43 DISPATCHER: Trying to submit another job.
18:50:43 job_callback for (0, 0, 5) got condition
18:50:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:50:43 Only 6 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
18:50:43 HBMASTER: Trying to run another job!
18:50:43 job_callback for (0, 0, 5) finished
18:50:43 start sampling a new configuration.
18:50:43 done sampling a new configuration.
18:50:43 HBMASTER: schedule new run for iteration 0
18:50:43 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
18:50:43 HBMASTER: submitting job (0, 0, 6) to dispatcher
18:50:43 DISPATCHER: trying to submit job (0, 0, 6)
18:50:43 DISPATCHER: trying to notify the job_runner thread.
18:50:43 HBMASTER: job (0, 0, 6) submitted to dispatcher
18:50:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:50:43 DISPATCHER: Trying to submit another job.
18:50:43 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:50:43 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:50:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:50:43 WORKER: start processing job (0, 0, 6)
18:50:43 WORKER: args: ()
18:50:43 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 758, 'last_n_outputs': 29, 'leak_rate': 0.888235519544332, 'lr': 0.010348469813695362, 'optimizer': 'SGD', 'sparsity': 0.8309097514731646, 'steps_to_train': 60, 'weight_decay': 0.03970961151284093}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:51:34 DISPATCHER: Starting worker discovery
18:51:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:51:34 DISPATCHER: Finished worker discovery
18:52:34 DISPATCHER: Starting worker discovery
18:52:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:52:34 DISPATCHER: Finished worker discovery
18:52:38 WORKER: done with job (0, 0, 6), trying to register it.
18:52:38 WORKER: registered result for job (0, 0, 6) with dispatcher
18:52:38 DISPATCHER: job (0, 0, 6) finished
18:52:38 DISPATCHER: register_result: lock acquired
18:52:38 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
18:52:38 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 758, 'last_n_outputs': 29, 'leak_rate': 0.888235519544332, 'lr': 0.010348469813695362, 'optimizer': 'SGD', 'sparsity': 0.8309097514731646, 'steps_to_train': 60, 'weight_decay': 0.03970961151284093}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2235426935185228, 'info': {'music_genre': 0.2235426935185228, 'config': "{'batch_size': 16, 'hidden_dim': 758, 'last_n_outputs': 29, 'leak_rate': 0.888235519544332, 'lr': 0.010348469813695362, 'optimizer': 'SGD', 'sparsity': 0.8309097514731646, 'steps_to_train': 60, 'weight_decay': 0.03970961151284093}"}}
exception: None

18:52:38 job_callback for (0, 0, 6) started
18:52:38 job_callback for (0, 0, 6) got condition
18:52:38 DISPATCHER: Trying to submit another job.
18:52:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:52:38 Only 7 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
18:52:38 HBMASTER: Trying to run another job!
18:52:38 job_callback for (0, 0, 6) finished
18:52:38 start sampling a new configuration.
18:52:38 done sampling a new configuration.
18:52:38 HBMASTER: schedule new run for iteration 0
18:52:38 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
18:52:38 HBMASTER: submitting job (0, 0, 7) to dispatcher
18:52:38 DISPATCHER: trying to submit job (0, 0, 7)
18:52:38 DISPATCHER: trying to notify the job_runner thread.
18:52:38 HBMASTER: job (0, 0, 7) submitted to dispatcher
18:52:38 DISPATCHER: Trying to submit another job.
18:52:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:52:38 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:52:38 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:52:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:52:38 WORKER: start processing job (0, 0, 7)
18:52:38 WORKER: args: ()
18:52:38 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 939, 'last_n_outputs': 10, 'leak_rate': 0.7638909754783694, 'lr': 0.020237506169901588, 'optimizer': 'SGD', 'sparsity': 0.8758984088090747, 'steps_to_train': 32, 'weight_decay': 0.16588223648289427}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:53:34 DISPATCHER: Starting worker discovery
18:53:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:53:34 DISPATCHER: Finished worker discovery
18:54:24 WORKER: done with job (0, 0, 7), trying to register it.
18:54:24 WORKER: registered result for job (0, 0, 7) with dispatcher
18:54:24 DISPATCHER: job (0, 0, 7) finished
18:54:24 DISPATCHER: register_result: lock acquired
18:54:24 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
18:54:24 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 939, 'last_n_outputs': 10, 'leak_rate': 0.7638909754783694, 'lr': 0.020237506169901588, 'optimizer': 'SGD', 'sparsity': 0.8758984088090747, 'steps_to_train': 32, 'weight_decay': 0.16588223648289427}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.25961579030026183, 'info': {'music_genre': 0.25961579030026183, 'config': "{'batch_size': 32, 'hidden_dim': 939, 'last_n_outputs': 10, 'leak_rate': 0.7638909754783694, 'lr': 0.020237506169901588, 'optimizer': 'SGD', 'sparsity': 0.8758984088090747, 'steps_to_train': 32, 'weight_decay': 0.16588223648289427}"}}
exception: None

18:54:24 job_callback for (0, 0, 7) started
18:54:24 DISPATCHER: Trying to submit another job.
18:54:24 job_callback for (0, 0, 7) got condition
18:54:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:54:24 Only 8 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
18:54:24 HBMASTER: Trying to run another job!
18:54:24 job_callback for (0, 0, 7) finished
18:54:24 start sampling a new configuration.
18:54:24 done sampling a new configuration.
18:54:24 HBMASTER: schedule new run for iteration 0
18:54:24 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
18:54:24 HBMASTER: submitting job (0, 0, 8) to dispatcher
18:54:24 DISPATCHER: trying to submit job (0, 0, 8)
18:54:24 DISPATCHER: trying to notify the job_runner thread.
18:54:24 HBMASTER: job (0, 0, 8) submitted to dispatcher
18:54:24 DISPATCHER: Trying to submit another job.
18:54:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:54:24 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:54:24 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:54:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:54:24 WORKER: start processing job (0, 0, 8)
18:54:24 WORKER: args: ()
18:54:24 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 496, 'last_n_outputs': 24, 'leak_rate': 0.8549932296178118, 'lr': 0.09649192190246667, 'optimizer': 'Adam', 'sparsity': 0.8110762038371955, 'steps_to_train': 64, 'weight_decay': 0.09454847583230133}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:54:34 DISPATCHER: Starting worker discovery
18:54:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:54:34 DISPATCHER: Finished worker discovery
18:55:34 DISPATCHER: Starting worker discovery
18:55:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:55:34 DISPATCHER: Finished worker discovery
18:56:07 WORKER: done with job (0, 0, 8), trying to register it.
18:56:07 WORKER: registered result for job (0, 0, 8) with dispatcher
18:56:07 DISPATCHER: job (0, 0, 8) finished
18:56:07 DISPATCHER: register_result: lock acquired
18:56:07 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
18:56:07 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 496, 'last_n_outputs': 24, 'leak_rate': 0.8549932296178118, 'lr': 0.09649192190246667, 'optimizer': 'Adam', 'sparsity': 0.8110762038371955, 'steps_to_train': 64, 'weight_decay': 0.09454847583230133}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0102765193182317, 'info': {'music_genre': 0.0102765193182317, 'config': "{'batch_size': 16, 'hidden_dim': 496, 'last_n_outputs': 24, 'leak_rate': 0.8549932296178118, 'lr': 0.09649192190246667, 'optimizer': 'Adam', 'sparsity': 0.8110762038371955, 'steps_to_train': 64, 'weight_decay': 0.09454847583230133}"}}
exception: None

18:56:07 DISPATCHER: Trying to submit another job.
18:56:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:56:07 job_callback for (0, 0, 8) started
18:56:07 job_callback for (0, 0, 8) got condition
18:56:07 Only 9 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
18:56:07 HBMASTER: Trying to run another job!
18:56:07 job_callback for (0, 0, 8) finished
18:56:07 start sampling a new configuration.
18:56:07 done sampling a new configuration.
18:56:07 HBMASTER: schedule new run for iteration 0
18:56:07 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
18:56:07 HBMASTER: submitting job (0, 0, 9) to dispatcher
18:56:07 DISPATCHER: trying to submit job (0, 0, 9)
18:56:07 DISPATCHER: trying to notify the job_runner thread.
18:56:07 HBMASTER: job (0, 0, 9) submitted to dispatcher
18:56:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:56:07 DISPATCHER: Trying to submit another job.
18:56:07 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:56:07 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:56:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:56:07 WORKER: start processing job (0, 0, 9)
18:56:07 WORKER: args: ()
18:56:07 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 420, 'last_n_outputs': 49, 'leak_rate': 0.9662824033714353, 'lr': 0.002403527057358322, 'optimizer': 'SGD', 'sparsity': 0.9170724317801324, 'steps_to_train': 50, 'weight_decay': 0.021860696132922096}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:56:34 DISPATCHER: Starting worker discovery
18:56:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:56:34 DISPATCHER: Finished worker discovery
18:57:34 DISPATCHER: Starting worker discovery
18:57:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:57:34 DISPATCHER: Finished worker discovery
18:57:53 WORKER: done with job (0, 0, 9), trying to register it.
18:57:53 WORKER: registered result for job (0, 0, 9) with dispatcher
18:57:53 DISPATCHER: job (0, 0, 9) finished
18:57:53 DISPATCHER: register_result: lock acquired
18:57:53 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
18:57:53 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 420, 'last_n_outputs': 49, 'leak_rate': 0.9662824033714353, 'lr': 0.002403527057358322, 'optimizer': 'SGD', 'sparsity': 0.9170724317801324, 'steps_to_train': 50, 'weight_decay': 0.021860696132922096}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.32055068593247543, 'info': {'music_genre': 0.32055068593247543, 'config': "{'batch_size': 32, 'hidden_dim': 420, 'last_n_outputs': 49, 'leak_rate': 0.9662824033714353, 'lr': 0.002403527057358322, 'optimizer': 'SGD', 'sparsity': 0.9170724317801324, 'steps_to_train': 50, 'weight_decay': 0.021860696132922096}"}}
exception: None

18:57:53 job_callback for (0, 0, 9) started
18:57:53 DISPATCHER: Trying to submit another job.
18:57:53 job_callback for (0, 0, 9) got condition
18:57:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:57:53 HBMASTER: Trying to run another job!
18:57:53 job_callback for (0, 0, 9) finished
18:57:53 start sampling a new configuration.
18:57:53 done sampling a new configuration.
18:57:53 HBMASTER: schedule new run for iteration 0
18:57:53 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
18:57:53 HBMASTER: submitting job (0, 0, 10) to dispatcher
18:57:53 DISPATCHER: trying to submit job (0, 0, 10)
18:57:53 DISPATCHER: trying to notify the job_runner thread.
18:57:53 HBMASTER: job (0, 0, 10) submitted to dispatcher
18:57:53 DISPATCHER: Trying to submit another job.
18:57:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:57:53 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:57:53 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:57:53 WORKER: start processing job (0, 0, 10)
18:57:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:57:53 WORKER: args: ()
18:57:53 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 568, 'last_n_outputs': 32, 'leak_rate': 0.8976127654399041, 'lr': 0.004644574282543848, 'optimizer': 'Adam', 'sparsity': 0.8344941598007602, 'steps_to_train': 33, 'weight_decay': 0.04782886245525173}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:58:34 DISPATCHER: Starting worker discovery
18:58:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:58:34 DISPATCHER: Finished worker discovery
18:59:34 DISPATCHER: Starting worker discovery
18:59:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:59:34 DISPATCHER: Finished worker discovery
18:59:43 WORKER: done with job (0, 0, 10), trying to register it.
18:59:43 WORKER: registered result for job (0, 0, 10) with dispatcher
18:59:43 DISPATCHER: job (0, 0, 10) finished
18:59:43 DISPATCHER: register_result: lock acquired
18:59:43 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
18:59:43 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 568, 'last_n_outputs': 32, 'leak_rate': 0.8976127654399041, 'lr': 0.004644574282543848, 'optimizer': 'Adam', 'sparsity': 0.8344941598007602, 'steps_to_train': 33, 'weight_decay': 0.04782886245525173}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2608101644213147, 'info': {'music_genre': 0.2608101644213147, 'config': "{'batch_size': 64, 'hidden_dim': 568, 'last_n_outputs': 32, 'leak_rate': 0.8976127654399041, 'lr': 0.004644574282543848, 'optimizer': 'Adam', 'sparsity': 0.8344941598007602, 'steps_to_train': 33, 'weight_decay': 0.04782886245525173}"}}
exception: None

18:59:43 job_callback for (0, 0, 10) started
18:59:43 job_callback for (0, 0, 10) got condition
18:59:43 DISPATCHER: Trying to submit another job.
18:59:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:59:43 HBMASTER: Trying to run another job!
18:59:43 job_callback for (0, 0, 10) finished
18:59:43 start sampling a new configuration.
18:59:43 done sampling a new configuration.
18:59:43 HBMASTER: schedule new run for iteration 0
18:59:43 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
18:59:43 HBMASTER: submitting job (0, 0, 11) to dispatcher
18:59:43 DISPATCHER: trying to submit job (0, 0, 11)
18:59:43 DISPATCHER: trying to notify the job_runner thread.
18:59:43 HBMASTER: job (0, 0, 11) submitted to dispatcher
18:59:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:59:43 DISPATCHER: Trying to submit another job.
18:59:43 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:59:43 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:59:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:59:43 WORKER: start processing job (0, 0, 11)
18:59:43 WORKER: args: ()
18:59:43 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 683, 'last_n_outputs': 39, 'leak_rate': 0.9969486860402164, 'lr': 0.022397172108553434, 'optimizer': 'SGD', 'sparsity': 0.751989653380844, 'steps_to_train': 62, 'weight_decay': 0.1311168468867145}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:00:34 DISPATCHER: Starting worker discovery
19:00:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:00:34 DISPATCHER: Finished worker discovery
19:01:34 DISPATCHER: Starting worker discovery
19:01:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:01:34 DISPATCHER: Finished worker discovery
19:01:38 WORKER: done with job (0, 0, 11), trying to register it.
19:01:38 WORKER: registered result for job (0, 0, 11) with dispatcher
19:01:38 DISPATCHER: job (0, 0, 11) finished
19:01:38 DISPATCHER: register_result: lock acquired
19:01:38 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
19:01:38 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 683, 'last_n_outputs': 39, 'leak_rate': 0.9969486860402164, 'lr': 0.022397172108553434, 'optimizer': 'SGD', 'sparsity': 0.751989653380844, 'steps_to_train': 62, 'weight_decay': 0.1311168468867145}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2780278093770697, 'info': {'music_genre': 0.2780278093770697, 'config': "{'batch_size': 64, 'hidden_dim': 683, 'last_n_outputs': 39, 'leak_rate': 0.9969486860402164, 'lr': 0.022397172108553434, 'optimizer': 'SGD', 'sparsity': 0.751989653380844, 'steps_to_train': 62, 'weight_decay': 0.1311168468867145}"}}
exception: None

19:01:38 job_callback for (0, 0, 11) started
19:01:38 DISPATCHER: Trying to submit another job.
19:01:38 job_callback for (0, 0, 11) got condition
19:01:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:01:38 HBMASTER: Trying to run another job!
19:01:38 job_callback for (0, 0, 11) finished
19:01:38 start sampling a new configuration.
19:01:38 done sampling a new configuration.
19:01:38 HBMASTER: schedule new run for iteration 0
19:01:38 HBMASTER: trying submitting job (0, 0, 12) to dispatcher
19:01:38 HBMASTER: submitting job (0, 0, 12) to dispatcher
19:01:38 DISPATCHER: trying to submit job (0, 0, 12)
19:01:38 DISPATCHER: trying to notify the job_runner thread.
19:01:38 HBMASTER: job (0, 0, 12) submitted to dispatcher
19:01:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:01:38 DISPATCHER: Trying to submit another job.
19:01:38 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:01:38 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:01:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:01:38 WORKER: start processing job (0, 0, 12)
19:01:38 WORKER: args: ()
19:01:38 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 508, 'last_n_outputs': 27, 'leak_rate': 0.9209632945808268, 'lr': 0.016675522943362695, 'optimizer': 'SGD', 'sparsity': 0.8694187324371924, 'steps_to_train': 43, 'weight_decay': 0.1021856681932437}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:02:34 DISPATCHER: Starting worker discovery
19:02:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:02:34 DISPATCHER: Finished worker discovery
19:03:23 WORKER: done with job (0, 0, 12), trying to register it.
19:03:23 WORKER: registered result for job (0, 0, 12) with dispatcher
19:03:23 DISPATCHER: job (0, 0, 12) finished
19:03:23 DISPATCHER: register_result: lock acquired
19:03:23 DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
19:03:23 job_id: (0, 0, 12)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 508, 'last_n_outputs': 27, 'leak_rate': 0.9209632945808268, 'lr': 0.016675522943362695, 'optimizer': 'SGD', 'sparsity': 0.8694187324371924, 'steps_to_train': 43, 'weight_decay': 0.1021856681932437}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.25598192986408463, 'info': {'music_genre': 0.25598192986408463, 'config': "{'batch_size': 32, 'hidden_dim': 508, 'last_n_outputs': 27, 'leak_rate': 0.9209632945808268, 'lr': 0.016675522943362695, 'optimizer': 'SGD', 'sparsity': 0.8694187324371924, 'steps_to_train': 43, 'weight_decay': 0.1021856681932437}"}}
exception: None

19:03:23 job_callback for (0, 0, 12) started
19:03:23 DISPATCHER: Trying to submit another job.
19:03:23 job_callback for (0, 0, 12) got condition
19:03:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:03:23 HBMASTER: Trying to run another job!
19:03:23 job_callback for (0, 0, 12) finished
19:03:23 start sampling a new configuration.
19:03:23 done sampling a new configuration.
19:03:23 HBMASTER: schedule new run for iteration 0
19:03:23 HBMASTER: trying submitting job (0, 0, 13) to dispatcher
19:03:23 HBMASTER: submitting job (0, 0, 13) to dispatcher
19:03:23 DISPATCHER: trying to submit job (0, 0, 13)
19:03:23 DISPATCHER: trying to notify the job_runner thread.
19:03:23 HBMASTER: job (0, 0, 13) submitted to dispatcher
19:03:23 DISPATCHER: Trying to submit another job.
19:03:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:03:23 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:03:23 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:03:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:03:23 WORKER: start processing job (0, 0, 13)
19:03:23 WORKER: args: ()
19:03:23 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 228, 'last_n_outputs': 44, 'leak_rate': 0.9803551700961937, 'lr': 0.03150058983451405, 'optimizer': 'Adam', 'sparsity': 0.8312515408292716, 'steps_to_train': 71, 'weight_decay': 0.044822654208139065}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:03:34 DISPATCHER: Starting worker discovery
19:03:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:03:34 DISPATCHER: Finished worker discovery
19:04:34 DISPATCHER: Starting worker discovery
19:04:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:04:34 DISPATCHER: Finished worker discovery
19:05:08 WORKER: done with job (0, 0, 13), trying to register it.
19:05:08 WORKER: registered result for job (0, 0, 13) with dispatcher
19:05:08 DISPATCHER: job (0, 0, 13) finished
19:05:08 DISPATCHER: register_result: lock acquired
19:05:08 DISPATCHER: job (0, 0, 13) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
19:05:08 job_id: (0, 0, 13)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 228, 'last_n_outputs': 44, 'leak_rate': 0.9803551700961937, 'lr': 0.03150058983451405, 'optimizer': 'Adam', 'sparsity': 0.8312515408292716, 'steps_to_train': 71, 'weight_decay': 0.044822654208139065}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.17422652528271768, 'info': {'music_genre': 0.17422652528271768, 'config': "{'batch_size': 32, 'hidden_dim': 228, 'last_n_outputs': 44, 'leak_rate': 0.9803551700961937, 'lr': 0.03150058983451405, 'optimizer': 'Adam', 'sparsity': 0.8312515408292716, 'steps_to_train': 71, 'weight_decay': 0.044822654208139065}"}}
exception: None

19:05:08 job_callback for (0, 0, 13) started
19:05:08 DISPATCHER: Trying to submit another job.
19:05:08 job_callback for (0, 0, 13) got condition
19:05:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:05:08 HBMASTER: Trying to run another job!
19:05:08 job_callback for (0, 0, 13) finished
19:05:08 start sampling a new configuration.
19:05:08 done sampling a new configuration.
19:05:08 HBMASTER: schedule new run for iteration 0
19:05:08 HBMASTER: trying submitting job (0, 0, 14) to dispatcher
19:05:08 HBMASTER: submitting job (0, 0, 14) to dispatcher
19:05:08 DISPATCHER: trying to submit job (0, 0, 14)
19:05:08 DISPATCHER: trying to notify the job_runner thread.
19:05:08 HBMASTER: job (0, 0, 14) submitted to dispatcher
19:05:08 DISPATCHER: Trying to submit another job.
19:05:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:05:08 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:05:08 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:05:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:05:08 WORKER: start processing job (0, 0, 14)
19:05:08 WORKER: args: ()
19:05:08 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 734, 'last_n_outputs': 13, 'leak_rate': 0.8203179175542041, 'lr': 0.010932053486805964, 'optimizer': 'SGD', 'sparsity': 0.9469909882823765, 'steps_to_train': 83, 'weight_decay': 0.027939474852217816}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:05:34 DISPATCHER: Starting worker discovery
19:05:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:05:34 DISPATCHER: Finished worker discovery
19:06:34 DISPATCHER: Starting worker discovery
19:06:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:06:34 DISPATCHER: Finished worker discovery
19:07:06 WORKER: done with job (0, 0, 14), trying to register it.
19:07:06 WORKER: registered result for job (0, 0, 14) with dispatcher
19:07:06 DISPATCHER: job (0, 0, 14) finished
19:07:06 DISPATCHER: register_result: lock acquired
19:07:06 DISPATCHER: job (0, 0, 14) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
19:07:06 job_id: (0, 0, 14)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 734, 'last_n_outputs': 13, 'leak_rate': 0.8203179175542041, 'lr': 0.010932053486805964, 'optimizer': 'SGD', 'sparsity': 0.9469909882823765, 'steps_to_train': 83, 'weight_decay': 0.027939474852217816}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.29043209254415636, 'info': {'music_genre': 0.29043209254415636, 'config': "{'batch_size': 128, 'hidden_dim': 734, 'last_n_outputs': 13, 'leak_rate': 0.8203179175542041, 'lr': 0.010932053486805964, 'optimizer': 'SGD', 'sparsity': 0.9469909882823765, 'steps_to_train': 83, 'weight_decay': 0.027939474852217816}"}}
exception: None

19:07:06 job_callback for (0, 0, 14) started
19:07:06 DISPATCHER: Trying to submit another job.
19:07:06 job_callback for (0, 0, 14) got condition
19:07:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:07:06 HBMASTER: Trying to run another job!
19:07:06 job_callback for (0, 0, 14) finished
19:07:06 start sampling a new configuration.
19:07:06 done sampling a new configuration.
19:07:06 HBMASTER: schedule new run for iteration 0
19:07:06 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
19:07:06 HBMASTER: submitting job (0, 0, 15) to dispatcher
19:07:06 DISPATCHER: trying to submit job (0, 0, 15)
19:07:06 DISPATCHER: trying to notify the job_runner thread.
19:07:06 HBMASTER: job (0, 0, 15) submitted to dispatcher
19:07:06 DISPATCHER: Trying to submit another job.
19:07:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:07:06 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:07:06 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:07:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:07:06 WORKER: start processing job (0, 0, 15)
19:07:06 WORKER: args: ()
19:07:06 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 447, 'last_n_outputs': 45, 'leak_rate': 0.8071276327265037, 'lr': 0.0016752517079885473, 'optimizer': 'Adam', 'sparsity': 0.9276162095204692, 'steps_to_train': 84, 'weight_decay': 0.010168087392014009}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:07:34 DISPATCHER: Starting worker discovery
19:07:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:07:34 DISPATCHER: Finished worker discovery
19:08:34 DISPATCHER: Starting worker discovery
19:08:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:08:34 DISPATCHER: Finished worker discovery
19:08:53 WORKER: done with job (0, 0, 15), trying to register it.
19:08:53 WORKER: registered result for job (0, 0, 15) with dispatcher
19:08:53 DISPATCHER: job (0, 0, 15) finished
19:08:53 DISPATCHER: register_result: lock acquired
19:08:53 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
19:08:53 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 447, 'last_n_outputs': 45, 'leak_rate': 0.8071276327265037, 'lr': 0.0016752517079885473, 'optimizer': 'Adam', 'sparsity': 0.9276162095204692, 'steps_to_train': 84, 'weight_decay': 0.010168087392014009}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.30175056946466317, 'info': {'music_genre': 0.30175056946466317, 'config': "{'batch_size': 64, 'hidden_dim': 447, 'last_n_outputs': 45, 'leak_rate': 0.8071276327265037, 'lr': 0.0016752517079885473, 'optimizer': 'Adam', 'sparsity': 0.9276162095204692, 'steps_to_train': 84, 'weight_decay': 0.010168087392014009}"}}
exception: None

19:08:53 job_callback for (0, 0, 15) started
19:08:53 DISPATCHER: Trying to submit another job.
19:08:53 job_callback for (0, 0, 15) got condition
19:08:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:08:53 HBMASTER: Trying to run another job!
19:08:53 job_callback for (0, 0, 15) finished
19:08:53 start sampling a new configuration.
19:08:53 done sampling a new configuration.
19:08:53 HBMASTER: schedule new run for iteration 0
19:08:53 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
19:08:53 HBMASTER: submitting job (0, 0, 16) to dispatcher
19:08:53 DISPATCHER: trying to submit job (0, 0, 16)
19:08:53 DISPATCHER: trying to notify the job_runner thread.
19:08:53 HBMASTER: job (0, 0, 16) submitted to dispatcher
19:08:53 DISPATCHER: Trying to submit another job.
19:08:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:08:53 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:08:53 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:08:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:08:53 WORKER: start processing job (0, 0, 16)
19:08:53 WORKER: args: ()
19:08:53 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 928, 'last_n_outputs': 39, 'leak_rate': 0.7712291552224392, 'lr': 0.011325469385035156, 'optimizer': 'SGD', 'sparsity': 0.8986935090231876, 'steps_to_train': 30, 'weight_decay': 0.01429806520025576}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:09:34 DISPATCHER: Starting worker discovery
19:09:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:09:34 DISPATCHER: Finished worker discovery
19:10:34 DISPATCHER: Starting worker discovery
19:10:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:10:34 DISPATCHER: Finished worker discovery
19:10:44 WORKER: done with job (0, 0, 16), trying to register it.
19:10:44 WORKER: registered result for job (0, 0, 16) with dispatcher
19:10:44 DISPATCHER: job (0, 0, 16) finished
19:10:44 DISPATCHER: register_result: lock acquired
19:10:44 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
19:10:44 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 928, 'last_n_outputs': 39, 'leak_rate': 0.7712291552224392, 'lr': 0.011325469385035156, 'optimizer': 'SGD', 'sparsity': 0.8986935090231876, 'steps_to_train': 30, 'weight_decay': 0.01429806520025576}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.35136095546266505, 'info': {'music_genre': 0.35136095546266505, 'config': "{'batch_size': 128, 'hidden_dim': 928, 'last_n_outputs': 39, 'leak_rate': 0.7712291552224392, 'lr': 0.011325469385035156, 'optimizer': 'SGD', 'sparsity': 0.8986935090231876, 'steps_to_train': 30, 'weight_decay': 0.01429806520025576}"}}
exception: None

19:10:44 job_callback for (0, 0, 16) started
19:10:44 DISPATCHER: Trying to submit another job.
19:10:44 job_callback for (0, 0, 16) got condition
19:10:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:10:44 HBMASTER: Trying to run another job!
19:10:44 job_callback for (0, 0, 16) finished
19:10:44 start sampling a new configuration.
19:10:44 done sampling a new configuration.
19:10:44 HBMASTER: schedule new run for iteration 0
19:10:44 HBMASTER: trying submitting job (0, 0, 17) to dispatcher
19:10:44 HBMASTER: submitting job (0, 0, 17) to dispatcher
19:10:44 DISPATCHER: trying to submit job (0, 0, 17)
19:10:44 DISPATCHER: trying to notify the job_runner thread.
19:10:44 HBMASTER: job (0, 0, 17) submitted to dispatcher
19:10:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:10:44 DISPATCHER: Trying to submit another job.
19:10:44 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:10:44 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:10:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:10:44 WORKER: start processing job (0, 0, 17)
19:10:44 WORKER: args: ()
19:10:44 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 204, 'last_n_outputs': 38, 'leak_rate': 0.8344815074988841, 'lr': 0.021386605141619993, 'optimizer': 'SGD', 'sparsity': 0.7640636728193183, 'steps_to_train': 91, 'weight_decay': 0.15964675179055765}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:11:34 DISPATCHER: Starting worker discovery
19:11:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:11:34 DISPATCHER: Finished worker discovery
19:12:34 WORKER: done with job (0, 0, 17), trying to register it.
19:12:34 WORKER: registered result for job (0, 0, 17) with dispatcher
19:12:34 DISPATCHER: job (0, 0, 17) finished
19:12:34 DISPATCHER: register_result: lock acquired
19:12:34 DISPATCHER: job (0, 0, 17) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
19:12:34 job_id: (0, 0, 17)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 204, 'last_n_outputs': 38, 'leak_rate': 0.8344815074988841, 'lr': 0.021386605141619993, 'optimizer': 'SGD', 'sparsity': 0.7640636728193183, 'steps_to_train': 91, 'weight_decay': 0.15964675179055765}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.22699161140407534, 'info': {'music_genre': 0.22699161140407534, 'config': "{'batch_size': 64, 'hidden_dim': 204, 'last_n_outputs': 38, 'leak_rate': 0.8344815074988841, 'lr': 0.021386605141619993, 'optimizer': 'SGD', 'sparsity': 0.7640636728193183, 'steps_to_train': 91, 'weight_decay': 0.15964675179055765}"}}
exception: None

19:12:34 job_callback for (0, 0, 17) started
19:12:34 DISPATCHER: Starting worker discovery
19:12:34 job_callback for (0, 0, 17) got condition
19:12:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:12:34 HBMASTER: Trying to run another job!
19:12:34 job_callback for (0, 0, 17) finished
19:12:34 start sampling a new configuration.
19:12:34 done sampling a new configuration.
19:12:34 DISPATCHER: Finished worker discovery
19:12:34 HBMASTER: schedule new run for iteration 0
19:12:34 DISPATCHER: Trying to submit another job.
19:12:34 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
19:12:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:12:34 HBMASTER: submitting job (0, 0, 18) to dispatcher
19:12:34 DISPATCHER: trying to submit job (0, 0, 18)
19:12:34 DISPATCHER: trying to notify the job_runner thread.
19:12:34 HBMASTER: job (0, 0, 18) submitted to dispatcher
19:12:34 DISPATCHER: Trying to submit another job.
19:12:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:12:34 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:12:34 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:12:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:12:34 WORKER: start processing job (0, 0, 18)
19:12:34 WORKER: args: ()
19:12:34 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 480, 'last_n_outputs': 47, 'leak_rate': 0.7969888259509879, 'lr': 0.0014004832876668735, 'optimizer': 'SGD', 'sparsity': 0.940045164225189, 'steps_to_train': 18, 'weight_decay': 0.019606760261550688}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:13:34 DISPATCHER: Starting worker discovery
19:13:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:13:34 DISPATCHER: Finished worker discovery
19:14:20 WORKER: done with job (0, 0, 18), trying to register it.
19:14:20 WORKER: registered result for job (0, 0, 18) with dispatcher
19:14:20 DISPATCHER: job (0, 0, 18) finished
19:14:20 DISPATCHER: register_result: lock acquired
19:14:20 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
19:14:20 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 480, 'last_n_outputs': 47, 'leak_rate': 0.7969888259509879, 'lr': 0.0014004832876668735, 'optimizer': 'SGD', 'sparsity': 0.940045164225189, 'steps_to_train': 18, 'weight_decay': 0.019606760261550688}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.29564539514944393, 'info': {'music_genre': 0.29564539514944393, 'config': "{'batch_size': 64, 'hidden_dim': 480, 'last_n_outputs': 47, 'leak_rate': 0.7969888259509879, 'lr': 0.0014004832876668735, 'optimizer': 'SGD', 'sparsity': 0.940045164225189, 'steps_to_train': 18, 'weight_decay': 0.019606760261550688}"}}
exception: None

19:14:20 job_callback for (0, 0, 18) started
19:14:20 DISPATCHER: Trying to submit another job.
19:14:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:14:20 job_callback for (0, 0, 18) got condition
19:14:20 HBMASTER: Trying to run another job!
19:14:20 job_callback for (0, 0, 18) finished
19:14:20 start sampling a new configuration.
19:14:20 done sampling a new configuration.
19:14:20 HBMASTER: schedule new run for iteration 0
19:14:20 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
19:14:20 HBMASTER: submitting job (0, 0, 19) to dispatcher
19:14:20 DISPATCHER: trying to submit job (0, 0, 19)
19:14:20 DISPATCHER: trying to notify the job_runner thread.
19:14:20 HBMASTER: job (0, 0, 19) submitted to dispatcher
19:14:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:14:20 DISPATCHER: Trying to submit another job.
19:14:20 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:14:20 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:14:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:14:20 WORKER: start processing job (0, 0, 19)
19:14:20 WORKER: args: ()
19:14:20 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 334, 'last_n_outputs': 50, 'leak_rate': 0.8295115346665963, 'lr': 0.032385178583977714, 'optimizer': 'Adam', 'sparsity': 0.9324654298947873, 'steps_to_train': 70, 'weight_decay': 0.03705378481346988}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:14:34 DISPATCHER: Starting worker discovery
19:14:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:14:34 DISPATCHER: Finished worker discovery
19:15:34 DISPATCHER: Starting worker discovery
19:15:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:15:34 DISPATCHER: Finished worker discovery
19:16:18 WORKER: done with job (0, 0, 19), trying to register it.
19:16:18 WORKER: registered result for job (0, 0, 19) with dispatcher
19:16:18 DISPATCHER: job (0, 0, 19) finished
19:16:18 DISPATCHER: register_result: lock acquired
19:16:18 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
19:16:18 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 334, 'last_n_outputs': 50, 'leak_rate': 0.8295115346665963, 'lr': 0.032385178583977714, 'optimizer': 'Adam', 'sparsity': 0.9324654298947873, 'steps_to_train': 70, 'weight_decay': 0.03705378481346988}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.14411374412590572, 'info': {'music_genre': 0.14411374412590572, 'config': "{'batch_size': 64, 'hidden_dim': 334, 'last_n_outputs': 50, 'leak_rate': 0.8295115346665963, 'lr': 0.032385178583977714, 'optimizer': 'Adam', 'sparsity': 0.9324654298947873, 'steps_to_train': 70, 'weight_decay': 0.03705378481346988}"}}
exception: None

19:16:18 job_callback for (0, 0, 19) started
19:16:18 job_callback for (0, 0, 19) got condition
19:16:18 DISPATCHER: Trying to submit another job.
19:16:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:16:18 done building a new model for budget 44.444444 based on 10/17 split
Best loss for this budget:-0.351361





19:16:18 HBMASTER: Trying to run another job!
19:16:18 job_callback for (0, 0, 19) finished
19:16:18 start sampling a new configuration.
19:16:18 best_vector: [1, 0.24305514329405917, 0.017386834405268115, 0.6176454188246554, 0.8703184074855491, 0, 0.5203117385154904, 0.9071800187483557, 0.0024798647157559975], 0.0006615414073473454, 0.050275719005798816, 3.325946990649583e-05
19:16:18 done sampling a new configuration.
19:16:18 HBMASTER: schedule new run for iteration 0
19:16:18 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
19:16:18 HBMASTER: submitting job (0, 0, 20) to dispatcher
19:16:18 DISPATCHER: trying to submit job (0, 0, 20)
19:16:18 DISPATCHER: trying to notify the job_runner thread.
19:16:18 HBMASTER: job (0, 0, 20) submitted to dispatcher
19:16:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:16:18 DISPATCHER: Trying to submit another job.
19:16:18 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:16:18 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:16:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:16:18 WORKER: start processing job (0, 0, 20)
19:16:18 WORKER: args: ()
19:16:18 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 394, 'last_n_outputs': 10, 'leak_rate': 0.9044113547061639, 'lr': 0.05503472680659306, 'optimizer': 'Adam', 'sparsity': 0.8748748172437177, 'steps_to_train': 92, 'weight_decay': 0.010074566743253667}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:16:34 DISPATCHER: Starting worker discovery
19:16:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:16:34 DISPATCHER: Finished worker discovery
19:17:34 DISPATCHER: Starting worker discovery
19:17:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:17:34 DISPATCHER: Finished worker discovery
19:18:07 WORKER: done with job (0, 0, 20), trying to register it.
19:18:07 WORKER: registered result for job (0, 0, 20) with dispatcher
19:18:07 DISPATCHER: job (0, 0, 20) finished
19:18:07 DISPATCHER: register_result: lock acquired
19:18:07 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
19:18:07 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 394, 'last_n_outputs': 10, 'leak_rate': 0.9044113547061639, 'lr': 0.05503472680659306, 'optimizer': 'Adam', 'sparsity': 0.8748748172437177, 'steps_to_train': 92, 'weight_decay': 0.010074566743253667}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3044443785193702, 'info': {'music_genre': 0.3044443785193702, 'config': "{'batch_size': 32, 'hidden_dim': 394, 'last_n_outputs': 10, 'leak_rate': 0.9044113547061639, 'lr': 0.05503472680659306, 'optimizer': 'Adam', 'sparsity': 0.8748748172437177, 'steps_to_train': 92, 'weight_decay': 0.010074566743253667}"}}
exception: None

19:18:07 job_callback for (0, 0, 20) started
19:18:07 DISPATCHER: Trying to submit another job.
19:18:07 job_callback for (0, 0, 20) got condition
19:18:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:18:07 done building a new model for budget 44.444444 based on 10/17 split
Best loss for this budget:-0.351361





19:18:07 HBMASTER: Trying to run another job!
19:18:07 job_callback for (0, 0, 20) finished
19:18:07 start sampling a new configuration.
19:18:07 done sampling a new configuration.
19:18:07 HBMASTER: schedule new run for iteration 0
19:18:07 HBMASTER: trying submitting job (0, 0, 21) to dispatcher
19:18:07 HBMASTER: submitting job (0, 0, 21) to dispatcher
19:18:07 DISPATCHER: trying to submit job (0, 0, 21)
19:18:07 DISPATCHER: trying to notify the job_runner thread.
19:18:07 HBMASTER: job (0, 0, 21) submitted to dispatcher
19:18:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:18:07 DISPATCHER: Trying to submit another job.
19:18:07 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:18:07 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:18:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:18:07 WORKER: start processing job (0, 0, 21)
19:18:07 WORKER: args: ()
19:18:07 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 891, 'last_n_outputs': 10, 'leak_rate': 0.7774330603097501, 'lr': 0.044398639328903755, 'optimizer': 'SGD', 'sparsity': 0.78134027846212, 'steps_to_train': 27, 'weight_decay': 0.058721091398200614}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:18:34 DISPATCHER: Starting worker discovery
19:18:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:18:34 DISPATCHER: Finished worker discovery
19:19:34 DISPATCHER: Starting worker discovery
19:19:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:19:34 DISPATCHER: Finished worker discovery
19:19:59 WORKER: done with job (0, 0, 21), trying to register it.
19:19:59 WORKER: registered result for job (0, 0, 21) with dispatcher
19:19:59 DISPATCHER: job (0, 0, 21) finished
19:19:59 DISPATCHER: register_result: lock acquired
19:19:59 DISPATCHER: job (0, 0, 21) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
19:19:59 job_id: (0, 0, 21)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 891, 'last_n_outputs': 10, 'leak_rate': 0.7774330603097501, 'lr': 0.044398639328903755, 'optimizer': 'SGD', 'sparsity': 0.78134027846212, 'steps_to_train': 27, 'weight_decay': 0.058721091398200614}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.18429335359572657, 'info': {'music_genre': 0.18429335359572657, 'config': "{'batch_size': 16, 'hidden_dim': 891, 'last_n_outputs': 10, 'leak_rate': 0.7774330603097501, 'lr': 0.044398639328903755, 'optimizer': 'SGD', 'sparsity': 0.78134027846212, 'steps_to_train': 27, 'weight_decay': 0.058721091398200614}"}}
exception: None

19:19:59 job_callback for (0, 0, 21) started
19:19:59 DISPATCHER: Trying to submit another job.
19:19:59 job_callback for (0, 0, 21) got condition
19:19:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:19:59 done building a new model for budget 44.444444 based on 10/18 split
Best loss for this budget:-0.351361





19:19:59 HBMASTER: Trying to run another job!
19:19:59 job_callback for (0, 0, 21) finished
19:19:59 start sampling a new configuration.
19:19:59 best_vector: [3, 0.3462820360873162, 0.832901890128982, 0.279373631144641, 0.02038240964726276, 1, 0.9603372914566709, 0.5830727348945967, 0.32681592350003924], 0.02983926911574753, 0.08385166003405534, 0.002502072249558349
19:19:59 done sampling a new configuration.
19:19:59 HBMASTER: schedule new run for iteration 0
19:19:59 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
19:19:59 HBMASTER: submitting job (0, 0, 22) to dispatcher
19:19:59 DISPATCHER: trying to submit job (0, 0, 22)
19:19:59 DISPATCHER: trying to notify the job_runner thread.
19:19:59 HBMASTER: job (0, 0, 22) submitted to dispatcher
19:19:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:19:59 DISPATCHER: Trying to submit another job.
19:19:59 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:19:59 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:19:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:19:59 WORKER: start processing job (0, 0, 22)
19:19:59 WORKER: args: ()
19:19:59 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 477, 'last_n_outputs': 44, 'leak_rate': 0.8198434077861603, 'lr': 0.0010984108629601098, 'optimizer': 'SGD', 'sparsity': 0.980480949949601, 'steps_to_train': 63, 'weight_decay': 0.026619342216413943}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:20:34 DISPATCHER: Starting worker discovery
19:20:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:20:34 DISPATCHER: Finished worker discovery
19:21:34 DISPATCHER: Starting worker discovery
19:21:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:21:34 DISPATCHER: Finished worker discovery
19:21:47 WORKER: done with job (0, 0, 22), trying to register it.
19:21:47 WORKER: registered result for job (0, 0, 22) with dispatcher
19:21:47 DISPATCHER: job (0, 0, 22) finished
19:21:47 DISPATCHER: register_result: lock acquired
19:21:47 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
19:21:47 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 477, 'last_n_outputs': 44, 'leak_rate': 0.8198434077861603, 'lr': 0.0010984108629601098, 'optimizer': 'SGD', 'sparsity': 0.980480949949601, 'steps_to_train': 63, 'weight_decay': 0.026619342216413943}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2718337074465076, 'info': {'music_genre': 0.2718337074465076, 'config': "{'batch_size': 128, 'hidden_dim': 477, 'last_n_outputs': 44, 'leak_rate': 0.8198434077861603, 'lr': 0.0010984108629601098, 'optimizer': 'SGD', 'sparsity': 0.980480949949601, 'steps_to_train': 63, 'weight_decay': 0.026619342216413943}"}}
exception: None

19:21:47 job_callback for (0, 0, 22) started
19:21:47 job_callback for (0, 0, 22) got condition
19:21:47 DISPATCHER: Trying to submit another job.
19:21:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:21:47 done building a new model for budget 44.444444 based on 10/19 split
Best loss for this budget:-0.351361





19:21:47 HBMASTER: Trying to run another job!
19:21:47 job_callback for (0, 0, 22) finished
19:21:47 start sampling a new configuration.
19:21:47 best_vector: [1, 0.296048624042252, 0.4818509252370287, 0.09933997083239332, 0.7617796327040712, 1, 0.4467436625519109, 0.9768865786196845, 0.19761726986411593], 0.016990914702436362, 0.13165478600199457, 0.0022369352391274026
19:21:47 done sampling a new configuration.
19:21:47 HBMASTER: schedule new run for iteration 0
19:21:47 HBMASTER: trying submitting job (0, 0, 23) to dispatcher
19:21:47 HBMASTER: submitting job (0, 0, 23) to dispatcher
19:21:47 DISPATCHER: trying to submit job (0, 0, 23)
19:21:47 DISPATCHER: trying to notify the job_runner thread.
19:21:47 HBMASTER: job (0, 0, 23) submitted to dispatcher
19:21:47 DISPATCHER: Trying to submit another job.
19:21:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:21:47 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:21:47 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:21:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:21:47 WORKER: start processing job (0, 0, 23)
19:21:47 WORKER: args: ()
19:21:47 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 437, 'last_n_outputs': 29, 'leak_rate': 0.7748349927080983, 'lr': 0.03338560612726758, 'optimizer': 'SGD', 'sparsity': 0.8572184790124586, 'steps_to_train': 98, 'weight_decay': 0.018076152464266044}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:22:34 DISPATCHER: Starting worker discovery
19:22:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:22:34 DISPATCHER: Finished worker discovery
19:23:32 WORKER: done with job (0, 0, 23), trying to register it.
19:23:32 WORKER: registered result for job (0, 0, 23) with dispatcher
19:23:32 DISPATCHER: job (0, 0, 23) finished
19:23:32 DISPATCHER: register_result: lock acquired
19:23:32 DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
19:23:32 job_id: (0, 0, 23)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 437, 'last_n_outputs': 29, 'leak_rate': 0.7748349927080983, 'lr': 0.03338560612726758, 'optimizer': 'SGD', 'sparsity': 0.8572184790124586, 'steps_to_train': 98, 'weight_decay': 0.018076152464266044}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2212074498648978, 'info': {'music_genre': 0.2212074498648978, 'config': "{'batch_size': 32, 'hidden_dim': 437, 'last_n_outputs': 29, 'leak_rate': 0.7748349927080983, 'lr': 0.03338560612726758, 'optimizer': 'SGD', 'sparsity': 0.8572184790124586, 'steps_to_train': 98, 'weight_decay': 0.018076152464266044}"}}
exception: None

19:23:32 job_callback for (0, 0, 23) started
19:23:32 DISPATCHER: Trying to submit another job.
19:23:32 job_callback for (0, 0, 23) got condition
19:23:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:23:32 done building a new model for budget 44.444444 based on 10/20 split
Best loss for this budget:-0.351361





19:23:32 HBMASTER: Trying to run another job!
19:23:32 job_callback for (0, 0, 23) finished
19:23:32 start sampling a new configuration.
19:23:32 best_vector: [1, 0.954609503185199, 0.14220148203364796, 0.06843083405366246, 0.648782913944723, 1, 0.9699853777765146, 0.4946811163501342, 0.22819981433056463], 0.007342984722400891, 0.04419735301609799, 0.0003245404879677665
19:23:32 done sampling a new configuration.
19:23:32 HBMASTER: schedule new run for iteration 0
19:23:32 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
19:23:32 HBMASTER: submitting job (0, 0, 24) to dispatcher
19:23:32 DISPATCHER: trying to submit job (0, 0, 24)
19:23:32 DISPATCHER: trying to notify the job_runner thread.
19:23:32 HBMASTER: job (0, 0, 24) submitted to dispatcher
19:23:32 DISPATCHER: Trying to submit another job.
19:23:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:23:32 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:23:32 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:23:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:23:32 WORKER: start processing job (0, 0, 24)
19:23:32 WORKER: args: ()
19:23:32 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 964, 'last_n_outputs': 15, 'leak_rate': 0.7671077085134156, 'lr': 0.01984110374220124, 'optimizer': 'SGD', 'sparsity': 0.9827964906663635, 'steps_to_train': 55, 'weight_decay': 0.019810471105085766}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:23:34 DISPATCHER: Starting worker discovery
19:23:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:23:34 DISPATCHER: Finished worker discovery
19:24:34 DISPATCHER: Starting worker discovery
19:24:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:24:34 DISPATCHER: Finished worker discovery
19:25:27 WORKER: done with job (0, 0, 24), trying to register it.
19:25:27 WORKER: registered result for job (0, 0, 24) with dispatcher
19:25:27 DISPATCHER: job (0, 0, 24) finished
19:25:27 DISPATCHER: register_result: lock acquired
19:25:27 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
19:25:27 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 964, 'last_n_outputs': 15, 'leak_rate': 0.7671077085134156, 'lr': 0.01984110374220124, 'optimizer': 'SGD', 'sparsity': 0.9827964906663635, 'steps_to_train': 55, 'weight_decay': 0.019810471105085766}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2982478966730592, 'info': {'music_genre': 0.2982478966730592, 'config': "{'batch_size': 32, 'hidden_dim': 964, 'last_n_outputs': 15, 'leak_rate': 0.7671077085134156, 'lr': 0.01984110374220124, 'optimizer': 'SGD', 'sparsity': 0.9827964906663635, 'steps_to_train': 55, 'weight_decay': 0.019810471105085766}"}}
exception: None

19:25:27 job_callback for (0, 0, 24) started
19:25:27 job_callback for (0, 0, 24) got condition
19:25:27 DISPATCHER: Trying to submit another job.
19:25:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:25:27 done building a new model for budget 44.444444 based on 10/21 split
Best loss for this budget:-0.351361





19:25:27 HBMASTER: Trying to run another job!
19:25:27 job_callback for (0, 0, 24) finished
19:25:27 start sampling a new configuration.
19:25:27 best_vector: [0, 0.5272137744772244, 0.06085904575144485, 0.6072210217719342, 0.7491590086210773, 0, 0.8125128344402802, 0.8461880106621187, 0.2303450855397476], 0.023154863479669212, 0.1292713624475384, 0.002993260749303589
19:25:27 done sampling a new configuration.
19:25:27 HBMASTER: schedule new run for iteration 0
19:25:27 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
19:25:27 HBMASTER: submitting job (0, 0, 25) to dispatcher
19:25:27 DISPATCHER: trying to submit job (0, 0, 25)
19:25:27 DISPATCHER: trying to notify the job_runner thread.
19:25:27 HBMASTER: job (0, 0, 25) submitted to dispatcher
19:25:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:25:27 DISPATCHER: Trying to submit another job.
19:25:27 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:25:27 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:25:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:25:27 WORKER: start processing job (0, 0, 25)
19:25:27 WORKER: args: ()
19:25:27 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 622, 'last_n_outputs': 12, 'leak_rate': 0.9018052554429835, 'lr': 0.03150054133954122, 'optimizer': 'Adam', 'sparsity': 0.9450030802656673, 'steps_to_train': 87, 'weight_decay': 0.01993819621480133}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:25:34 DISPATCHER: Starting worker discovery
19:25:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:25:34 DISPATCHER: Finished worker discovery
19:26:34 DISPATCHER: Starting worker discovery
19:26:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:26:34 DISPATCHER: Finished worker discovery
19:27:33 WORKER: done with job (0, 0, 25), trying to register it.
19:27:33 WORKER: registered result for job (0, 0, 25) with dispatcher
19:27:33 DISPATCHER: job (0, 0, 25) finished
19:27:33 DISPATCHER: register_result: lock acquired
19:27:33 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
19:27:33 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 622, 'last_n_outputs': 12, 'leak_rate': 0.9018052554429835, 'lr': 0.03150054133954122, 'optimizer': 'Adam', 'sparsity': 0.9450030802656673, 'steps_to_train': 87, 'weight_decay': 0.01993819621480133}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.09025440320709983, 'info': {'music_genre': 0.09025440320709983, 'config': "{'batch_size': 16, 'hidden_dim': 622, 'last_n_outputs': 12, 'leak_rate': 0.9018052554429835, 'lr': 0.03150054133954122, 'optimizer': 'Adam', 'sparsity': 0.9450030802656673, 'steps_to_train': 87, 'weight_decay': 0.01993819621480133}"}}
exception: None

19:27:33 job_callback for (0, 0, 25) started
19:27:33 DISPATCHER: Trying to submit another job.
19:27:33 job_callback for (0, 0, 25) got condition
19:27:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:27:33 done building a new model for budget 44.444444 based on 10/22 split
Best loss for this budget:-0.351361





19:27:33 HBMASTER: Trying to run another job!
19:27:33 job_callback for (0, 0, 25) finished
19:27:33 start sampling a new configuration.
19:27:33 best_vector: [1, 0.7794399343020567, 0.6638892209712662, 0.012226872346459326, 0.493717865299542, 1, 0.6937346820789096, 0.08474931025582405, 0.21756255764208138], 0.01572523072994504, 0.34260893732758885, 0.005387604589617615
19:27:33 done sampling a new configuration.
19:27:33 HBMASTER: schedule new run for iteration 0
19:27:33 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
19:27:33 HBMASTER: submitting job (0, 0, 26) to dispatcher
19:27:33 DISPATCHER: trying to submit job (0, 0, 26)
19:27:33 DISPATCHER: trying to notify the job_runner thread.
19:27:33 HBMASTER: job (0, 0, 26) submitted to dispatcher
19:27:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:27:33 DISPATCHER: Trying to submit another job.
19:27:33 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:27:33 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:27:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:27:33 WORKER: start processing job (0, 0, 26)
19:27:33 WORKER: args: ()
19:27:33 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 824, 'last_n_outputs': 37, 'leak_rate': 0.7530567180866148, 'lr': 0.009714841751105948, 'optimizer': 'SGD', 'sparsity': 0.9164963236989383, 'steps_to_train': 17, 'weight_decay': 0.019189135671540916}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:27:34 DISPATCHER: Starting worker discovery
19:27:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:27:34 DISPATCHER: Finished worker discovery
19:28:34 DISPATCHER: Starting worker discovery
19:28:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:28:34 DISPATCHER: Finished worker discovery
19:29:19 WORKER: done with job (0, 0, 26), trying to register it.
19:29:19 WORKER: registered result for job (0, 0, 26) with dispatcher
19:29:19 DISPATCHER: job (0, 0, 26) finished
19:29:19 DISPATCHER: register_result: lock acquired
19:29:19 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
19:29:19 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 824, 'last_n_outputs': 37, 'leak_rate': 0.7530567180866148, 'lr': 0.009714841751105948, 'optimizer': 'SGD', 'sparsity': 0.9164963236989383, 'steps_to_train': 17, 'weight_decay': 0.019189135671540916}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.37854936753906004, 'info': {'music_genre': 0.37854936753906004, 'config': "{'batch_size': 32, 'hidden_dim': 824, 'last_n_outputs': 37, 'leak_rate': 0.7530567180866148, 'lr': 0.009714841751105948, 'optimizer': 'SGD', 'sparsity': 0.9164963236989383, 'steps_to_train': 17, 'weight_decay': 0.019189135671540916}"}}
exception: None

19:29:19 job_callback for (0, 0, 26) started
19:29:19 DISPATCHER: Trying to submit another job.
19:29:19 job_callback for (0, 0, 26) got condition
19:29:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:29:19 done building a new model for budget 44.444444 based on 10/22 split
Best loss for this budget:-0.378549





19:29:19 HBMASTER: Trying to run another job!
19:29:19 job_callback for (0, 0, 26) finished
19:29:19 ITERATION: Advancing config (0, 0, 3) to next budget 133.333333
19:29:19 ITERATION: Advancing config (0, 0, 9) to next budget 133.333333
19:29:19 ITERATION: Advancing config (0, 0, 14) to next budget 133.333333
19:29:19 ITERATION: Advancing config (0, 0, 15) to next budget 133.333333
19:29:19 ITERATION: Advancing config (0, 0, 16) to next budget 133.333333
19:29:19 ITERATION: Advancing config (0, 0, 18) to next budget 133.333333
19:29:19 ITERATION: Advancing config (0, 0, 20) to next budget 133.333333
19:29:19 ITERATION: Advancing config (0, 0, 24) to next budget 133.333333
19:29:19 ITERATION: Advancing config (0, 0, 26) to next budget 133.333333
19:29:19 HBMASTER: schedule new run for iteration 0
19:29:19 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
19:29:19 HBMASTER: submitting job (0, 0, 3) to dispatcher
19:29:19 DISPATCHER: trying to submit job (0, 0, 3)
19:29:19 DISPATCHER: trying to notify the job_runner thread.
19:29:19 HBMASTER: job (0, 0, 3) submitted to dispatcher
19:29:19 DISPATCHER: Trying to submit another job.
19:29:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:29:19 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:29:19 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:29:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:29:19 WORKER: start processing job (0, 0, 3)
19:29:19 WORKER: args: ()
19:29:19 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 336, 'last_n_outputs': 17, 'leak_rate': 0.8114219935540625, 'lr': 0.029473296876905558, 'optimizer': 'SGD', 'sparsity': 0.8969716241122381, 'steps_to_train': 95, 'weight_decay': 0.014325611558931153}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:29:34 DISPATCHER: Starting worker discovery
19:29:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:29:34 DISPATCHER: Finished worker discovery
19:30:34 DISPATCHER: Starting worker discovery
19:30:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:30:34 DISPATCHER: Finished worker discovery
19:31:34 DISPATCHER: Starting worker discovery
19:31:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:31:34 DISPATCHER: Finished worker discovery
19:32:34 DISPATCHER: Starting worker discovery
19:32:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:32:34 DISPATCHER: Finished worker discovery
19:32:49 WORKER: done with job (0, 0, 3), trying to register it.
19:32:49 WORKER: registered result for job (0, 0, 3) with dispatcher
19:32:49 DISPATCHER: job (0, 0, 3) finished
19:32:49 DISPATCHER: register_result: lock acquired
19:32:49 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
19:32:49 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 336, 'last_n_outputs': 17, 'leak_rate': 0.8114219935540625, 'lr': 0.029473296876905558, 'optimizer': 'SGD', 'sparsity': 0.8969716241122381, 'steps_to_train': 95, 'weight_decay': 0.014325611558931153}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3190248567632944, 'info': {'music_genre': 0.3190248567632944, 'config': "{'batch_size': 64, 'hidden_dim': 336, 'last_n_outputs': 17, 'leak_rate': 0.8114219935540625, 'lr': 0.029473296876905558, 'optimizer': 'SGD', 'sparsity': 0.8969716241122381, 'steps_to_train': 95, 'weight_decay': 0.014325611558931153}"}}
exception: None

19:32:49 job_callback for (0, 0, 3) started
19:32:49 job_callback for (0, 0, 3) got condition
19:32:49 DISPATCHER: Trying to submit another job.
19:32:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:32:49 Only 1 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
19:32:49 HBMASTER: Trying to run another job!
19:32:49 job_callback for (0, 0, 3) finished
19:32:49 HBMASTER: schedule new run for iteration 0
19:32:49 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
19:32:49 HBMASTER: submitting job (0, 0, 9) to dispatcher
19:32:49 DISPATCHER: trying to submit job (0, 0, 9)
19:32:49 DISPATCHER: trying to notify the job_runner thread.
19:32:49 HBMASTER: job (0, 0, 9) submitted to dispatcher
19:32:49 DISPATCHER: Trying to submit another job.
19:32:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:32:49 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:32:49 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:32:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:32:49 WORKER: start processing job (0, 0, 9)
19:32:49 WORKER: args: ()
19:32:49 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 420, 'last_n_outputs': 49, 'leak_rate': 0.9662824033714353, 'lr': 0.002403527057358322, 'optimizer': 'SGD', 'sparsity': 0.9170724317801324, 'steps_to_train': 50, 'weight_decay': 0.021860696132922096}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:33:34 DISPATCHER: Starting worker discovery
19:33:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:33:34 DISPATCHER: Finished worker discovery
19:34:34 DISPATCHER: Starting worker discovery
19:34:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:34:35 DISPATCHER: Finished worker discovery
19:35:35 DISPATCHER: Starting worker discovery
19:35:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:35:35 DISPATCHER: Finished worker discovery
19:36:18 WORKER: done with job (0, 0, 9), trying to register it.
19:36:18 WORKER: registered result for job (0, 0, 9) with dispatcher
19:36:18 DISPATCHER: job (0, 0, 9) finished
19:36:18 DISPATCHER: register_result: lock acquired
19:36:18 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
19:36:18 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 420, 'last_n_outputs': 49, 'leak_rate': 0.9662824033714353, 'lr': 0.002403527057358322, 'optimizer': 'SGD', 'sparsity': 0.9170724317801324, 'steps_to_train': 50, 'weight_decay': 0.021860696132922096}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.36149858146085084, 'info': {'music_genre': 0.36149858146085084, 'config': "{'batch_size': 32, 'hidden_dim': 420, 'last_n_outputs': 49, 'leak_rate': 0.9662824033714353, 'lr': 0.002403527057358322, 'optimizer': 'SGD', 'sparsity': 0.9170724317801324, 'steps_to_train': 50, 'weight_decay': 0.021860696132922096}"}}
exception: None

19:36:18 job_callback for (0, 0, 9) started
19:36:18 DISPATCHER: Trying to submit another job.
19:36:18 job_callback for (0, 0, 9) got condition
19:36:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:36:18 Only 2 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
19:36:18 HBMASTER: Trying to run another job!
19:36:18 job_callback for (0, 0, 9) finished
19:36:18 HBMASTER: schedule new run for iteration 0
19:36:18 HBMASTER: trying submitting job (0, 0, 14) to dispatcher
19:36:18 HBMASTER: submitting job (0, 0, 14) to dispatcher
19:36:18 DISPATCHER: trying to submit job (0, 0, 14)
19:36:18 DISPATCHER: trying to notify the job_runner thread.
19:36:18 HBMASTER: job (0, 0, 14) submitted to dispatcher
19:36:18 DISPATCHER: Trying to submit another job.
19:36:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:36:18 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:36:18 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:36:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:36:18 WORKER: start processing job (0, 0, 14)
19:36:18 WORKER: args: ()
19:36:18 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 734, 'last_n_outputs': 13, 'leak_rate': 0.8203179175542041, 'lr': 0.010932053486805964, 'optimizer': 'SGD', 'sparsity': 0.9469909882823765, 'steps_to_train': 83, 'weight_decay': 0.027939474852217816}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:36:35 DISPATCHER: Starting worker discovery
19:36:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:36:35 DISPATCHER: Finished worker discovery
19:37:35 DISPATCHER: Starting worker discovery
19:37:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:37:35 DISPATCHER: Finished worker discovery
19:38:35 DISPATCHER: Starting worker discovery
19:38:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:38:35 DISPATCHER: Finished worker discovery
19:39:35 DISPATCHER: Starting worker discovery
19:39:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:39:35 DISPATCHER: Finished worker discovery
19:39:56 WORKER: done with job (0, 0, 14), trying to register it.
19:39:56 WORKER: registered result for job (0, 0, 14) with dispatcher
19:39:56 DISPATCHER: job (0, 0, 14) finished
19:39:56 DISPATCHER: register_result: lock acquired
19:39:56 DISPATCHER: job (0, 0, 14) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
19:39:56 job_id: (0, 0, 14)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 734, 'last_n_outputs': 13, 'leak_rate': 0.8203179175542041, 'lr': 0.010932053486805964, 'optimizer': 'SGD', 'sparsity': 0.9469909882823765, 'steps_to_train': 83, 'weight_decay': 0.027939474852217816}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.31310851197450684, 'info': {'music_genre': 0.31310851197450684, 'config': "{'batch_size': 128, 'hidden_dim': 734, 'last_n_outputs': 13, 'leak_rate': 0.8203179175542041, 'lr': 0.010932053486805964, 'optimizer': 'SGD', 'sparsity': 0.9469909882823765, 'steps_to_train': 83, 'weight_decay': 0.027939474852217816}"}}
exception: None

19:39:56 job_callback for (0, 0, 14) started
19:39:56 job_callback for (0, 0, 14) got condition
19:39:56 DISPATCHER: Trying to submit another job.
19:39:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:39:56 Only 3 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
19:39:56 HBMASTER: Trying to run another job!
19:39:56 job_callback for (0, 0, 14) finished
19:39:56 HBMASTER: schedule new run for iteration 0
19:39:56 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
19:39:56 HBMASTER: submitting job (0, 0, 15) to dispatcher
19:39:56 DISPATCHER: trying to submit job (0, 0, 15)
19:39:56 DISPATCHER: trying to notify the job_runner thread.
19:39:56 HBMASTER: job (0, 0, 15) submitted to dispatcher
19:39:56 DISPATCHER: Trying to submit another job.
19:39:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:39:56 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:39:56 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:39:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:39:56 WORKER: start processing job (0, 0, 15)
19:39:56 WORKER: args: ()
19:39:56 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 447, 'last_n_outputs': 45, 'leak_rate': 0.8071276327265037, 'lr': 0.0016752517079885473, 'optimizer': 'Adam', 'sparsity': 0.9276162095204692, 'steps_to_train': 84, 'weight_decay': 0.010168087392014009}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:40:35 DISPATCHER: Starting worker discovery
19:40:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:40:35 DISPATCHER: Finished worker discovery
19:41:35 DISPATCHER: Starting worker discovery
19:41:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:41:35 DISPATCHER: Finished worker discovery
19:42:35 DISPATCHER: Starting worker discovery
19:42:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:42:35 DISPATCHER: Finished worker discovery
19:43:14 WORKER: done with job (0, 0, 15), trying to register it.
19:43:14 WORKER: registered result for job (0, 0, 15) with dispatcher
19:43:14 DISPATCHER: job (0, 0, 15) finished
19:43:14 DISPATCHER: register_result: lock acquired
19:43:14 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
19:43:14 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 447, 'last_n_outputs': 45, 'leak_rate': 0.8071276327265037, 'lr': 0.0016752517079885473, 'optimizer': 'Adam', 'sparsity': 0.9276162095204692, 'steps_to_train': 84, 'weight_decay': 0.010168087392014009}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.37136225345645385, 'info': {'music_genre': 0.37136225345645385, 'config': "{'batch_size': 64, 'hidden_dim': 447, 'last_n_outputs': 45, 'leak_rate': 0.8071276327265037, 'lr': 0.0016752517079885473, 'optimizer': 'Adam', 'sparsity': 0.9276162095204692, 'steps_to_train': 84, 'weight_decay': 0.010168087392014009}"}}
exception: None

19:43:14 job_callback for (0, 0, 15) started
19:43:14 job_callback for (0, 0, 15) got condition
19:43:14 DISPATCHER: Trying to submit another job.
19:43:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:43:14 Only 4 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
19:43:14 HBMASTER: Trying to run another job!
19:43:14 job_callback for (0, 0, 15) finished
19:43:14 HBMASTER: schedule new run for iteration 0
19:43:14 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
19:43:14 HBMASTER: submitting job (0, 0, 16) to dispatcher
19:43:14 DISPATCHER: trying to submit job (0, 0, 16)
19:43:14 DISPATCHER: trying to notify the job_runner thread.
19:43:14 HBMASTER: job (0, 0, 16) submitted to dispatcher
19:43:14 DISPATCHER: Trying to submit another job.
19:43:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:43:14 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:43:14 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:43:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:43:14 WORKER: start processing job (0, 0, 16)
19:43:14 WORKER: args: ()
19:43:14 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 928, 'last_n_outputs': 39, 'leak_rate': 0.7712291552224392, 'lr': 0.011325469385035156, 'optimizer': 'SGD', 'sparsity': 0.8986935090231876, 'steps_to_train': 30, 'weight_decay': 0.01429806520025576}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:43:35 DISPATCHER: Starting worker discovery
19:43:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:43:35 DISPATCHER: Finished worker discovery
19:44:35 DISPATCHER: Starting worker discovery
19:44:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:44:35 DISPATCHER: Finished worker discovery
19:45:35 DISPATCHER: Starting worker discovery
19:45:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:45:35 DISPATCHER: Finished worker discovery
19:46:32 WORKER: done with job (0, 0, 16), trying to register it.
19:46:32 WORKER: registered result for job (0, 0, 16) with dispatcher
19:46:32 DISPATCHER: job (0, 0, 16) finished
19:46:32 DISPATCHER: register_result: lock acquired
19:46:32 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
19:46:32 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 928, 'last_n_outputs': 39, 'leak_rate': 0.7712291552224392, 'lr': 0.011325469385035156, 'optimizer': 'SGD', 'sparsity': 0.8986935090231876, 'steps_to_train': 30, 'weight_decay': 0.01429806520025576}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.36117890863103697, 'info': {'music_genre': 0.36117890863103697, 'config': "{'batch_size': 128, 'hidden_dim': 928, 'last_n_outputs': 39, 'leak_rate': 0.7712291552224392, 'lr': 0.011325469385035156, 'optimizer': 'SGD', 'sparsity': 0.8986935090231876, 'steps_to_train': 30, 'weight_decay': 0.01429806520025576}"}}
exception: None

19:46:32 job_callback for (0, 0, 16) started
19:46:32 DISPATCHER: Trying to submit another job.
19:46:32 job_callback for (0, 0, 16) got condition
19:46:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:46:32 Only 5 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
19:46:32 HBMASTER: Trying to run another job!
19:46:32 job_callback for (0, 0, 16) finished
19:46:32 HBMASTER: schedule new run for iteration 0
19:46:32 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
19:46:32 HBMASTER: submitting job (0, 0, 18) to dispatcher
19:46:32 DISPATCHER: trying to submit job (0, 0, 18)
19:46:32 DISPATCHER: trying to notify the job_runner thread.
19:46:32 HBMASTER: job (0, 0, 18) submitted to dispatcher
19:46:32 DISPATCHER: Trying to submit another job.
19:46:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:46:32 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:46:32 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:46:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:46:32 WORKER: start processing job (0, 0, 18)
19:46:32 WORKER: args: ()
19:46:32 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 480, 'last_n_outputs': 47, 'leak_rate': 0.7969888259509879, 'lr': 0.0014004832876668735, 'optimizer': 'SGD', 'sparsity': 0.940045164225189, 'steps_to_train': 18, 'weight_decay': 0.019606760261550688}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:46:35 DISPATCHER: Starting worker discovery
19:46:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:46:35 DISPATCHER: Finished worker discovery
19:47:35 DISPATCHER: Starting worker discovery
19:47:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:47:35 DISPATCHER: Finished worker discovery
19:48:35 DISPATCHER: Starting worker discovery
19:48:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:48:35 DISPATCHER: Finished worker discovery
19:49:35 DISPATCHER: Starting worker discovery
19:49:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:49:35 DISPATCHER: Finished worker discovery
19:49:51 WORKER: done with job (0, 0, 18), trying to register it.
19:49:51 WORKER: registered result for job (0, 0, 18) with dispatcher
19:49:51 DISPATCHER: job (0, 0, 18) finished
19:49:51 DISPATCHER: register_result: lock acquired
19:49:51 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
19:49:51 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 480, 'last_n_outputs': 47, 'leak_rate': 0.7969888259509879, 'lr': 0.0014004832876668735, 'optimizer': 'SGD', 'sparsity': 0.940045164225189, 'steps_to_train': 18, 'weight_decay': 0.019606760261550688}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3503176919321515, 'info': {'music_genre': 0.3503176919321515, 'config': "{'batch_size': 64, 'hidden_dim': 480, 'last_n_outputs': 47, 'leak_rate': 0.7969888259509879, 'lr': 0.0014004832876668735, 'optimizer': 'SGD', 'sparsity': 0.940045164225189, 'steps_to_train': 18, 'weight_decay': 0.019606760261550688}"}}
exception: None

19:49:51 job_callback for (0, 0, 18) started
19:49:51 DISPATCHER: Trying to submit another job.
19:49:51 job_callback for (0, 0, 18) got condition
19:49:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:49:51 Only 6 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
19:49:51 HBMASTER: Trying to run another job!
19:49:51 job_callback for (0, 0, 18) finished
19:49:51 HBMASTER: schedule new run for iteration 0
19:49:51 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
19:49:51 HBMASTER: submitting job (0, 0, 20) to dispatcher
19:49:51 DISPATCHER: trying to submit job (0, 0, 20)
19:49:51 DISPATCHER: trying to notify the job_runner thread.
19:49:51 HBMASTER: job (0, 0, 20) submitted to dispatcher
19:49:51 DISPATCHER: Trying to submit another job.
19:49:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:49:51 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:49:51 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:49:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:49:51 WORKER: start processing job (0, 0, 20)
19:49:51 WORKER: args: ()
19:49:51 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 394, 'last_n_outputs': 10, 'leak_rate': 0.9044113547061639, 'lr': 0.05503472680659306, 'optimizer': 'Adam', 'sparsity': 0.8748748172437177, 'steps_to_train': 92, 'weight_decay': 0.010074566743253667}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:50:35 DISPATCHER: Starting worker discovery
19:50:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:50:35 DISPATCHER: Finished worker discovery
19:51:35 DISPATCHER: Starting worker discovery
19:51:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:51:35 DISPATCHER: Finished worker discovery
19:52:35 DISPATCHER: Starting worker discovery
19:52:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:52:35 DISPATCHER: Finished worker discovery
19:53:15 WORKER: done with job (0, 0, 20), trying to register it.
19:53:15 WORKER: registered result for job (0, 0, 20) with dispatcher
19:53:15 DISPATCHER: job (0, 0, 20) finished
19:53:15 DISPATCHER: register_result: lock acquired
19:53:15 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
19:53:15 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 394, 'last_n_outputs': 10, 'leak_rate': 0.9044113547061639, 'lr': 0.05503472680659306, 'optimizer': 'Adam', 'sparsity': 0.8748748172437177, 'steps_to_train': 92, 'weight_decay': 0.010074566743253667}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1950922618272686, 'info': {'music_genre': 0.1950922618272686, 'config': "{'batch_size': 32, 'hidden_dim': 394, 'last_n_outputs': 10, 'leak_rate': 0.9044113547061639, 'lr': 0.05503472680659306, 'optimizer': 'Adam', 'sparsity': 0.8748748172437177, 'steps_to_train': 92, 'weight_decay': 0.010074566743253667}"}}
exception: None

19:53:15 job_callback for (0, 0, 20) started
19:53:15 job_callback for (0, 0, 20) got condition
19:53:15 DISPATCHER: Trying to submit another job.
19:53:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:53:15 Only 7 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
19:53:15 HBMASTER: Trying to run another job!
19:53:15 job_callback for (0, 0, 20) finished
19:53:15 HBMASTER: schedule new run for iteration 0
19:53:15 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
19:53:15 HBMASTER: submitting job (0, 0, 24) to dispatcher
19:53:15 DISPATCHER: trying to submit job (0, 0, 24)
19:53:15 DISPATCHER: trying to notify the job_runner thread.
19:53:15 HBMASTER: job (0, 0, 24) submitted to dispatcher
19:53:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:53:15 DISPATCHER: Trying to submit another job.
19:53:15 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:53:15 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:53:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:53:15 WORKER: start processing job (0, 0, 24)
19:53:15 WORKER: args: ()
19:53:15 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 964, 'last_n_outputs': 15, 'leak_rate': 0.7671077085134156, 'lr': 0.01984110374220124, 'optimizer': 'SGD', 'sparsity': 0.9827964906663635, 'steps_to_train': 55, 'weight_decay': 0.019810471105085766}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:53:35 DISPATCHER: Starting worker discovery
19:53:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:53:35 DISPATCHER: Finished worker discovery
19:54:35 DISPATCHER: Starting worker discovery
19:54:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:54:35 DISPATCHER: Finished worker discovery
19:55:35 DISPATCHER: Starting worker discovery
19:55:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:55:35 DISPATCHER: Finished worker discovery
19:56:31 WORKER: done with job (0, 0, 24), trying to register it.
19:56:31 WORKER: registered result for job (0, 0, 24) with dispatcher
19:56:31 DISPATCHER: job (0, 0, 24) finished
19:56:31 DISPATCHER: register_result: lock acquired
19:56:31 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
19:56:31 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 964, 'last_n_outputs': 15, 'leak_rate': 0.7671077085134156, 'lr': 0.01984110374220124, 'optimizer': 'SGD', 'sparsity': 0.9827964906663635, 'steps_to_train': 55, 'weight_decay': 0.019810471105085766}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.30101717763858016, 'info': {'music_genre': 0.30101717763858016, 'config': "{'batch_size': 32, 'hidden_dim': 964, 'last_n_outputs': 15, 'leak_rate': 0.7671077085134156, 'lr': 0.01984110374220124, 'optimizer': 'SGD', 'sparsity': 0.9827964906663635, 'steps_to_train': 55, 'weight_decay': 0.019810471105085766}"}}
exception: None

19:56:31 job_callback for (0, 0, 24) started
19:56:31 DISPATCHER: Trying to submit another job.
19:56:31 job_callback for (0, 0, 24) got condition
19:56:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:56:31 Only 8 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
19:56:31 HBMASTER: Trying to run another job!
19:56:31 job_callback for (0, 0, 24) finished
19:56:31 HBMASTER: schedule new run for iteration 0
19:56:31 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
19:56:31 HBMASTER: submitting job (0, 0, 26) to dispatcher
19:56:31 DISPATCHER: trying to submit job (0, 0, 26)
19:56:31 DISPATCHER: trying to notify the job_runner thread.
19:56:31 HBMASTER: job (0, 0, 26) submitted to dispatcher
19:56:31 DISPATCHER: Trying to submit another job.
19:56:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:56:31 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:56:31 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:56:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:56:31 WORKER: start processing job (0, 0, 26)
19:56:31 WORKER: args: ()
19:56:31 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 824, 'last_n_outputs': 37, 'leak_rate': 0.7530567180866148, 'lr': 0.009714841751105948, 'optimizer': 'SGD', 'sparsity': 0.9164963236989383, 'steps_to_train': 17, 'weight_decay': 0.019189135671540916}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:56:35 DISPATCHER: Starting worker discovery
19:56:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:56:35 DISPATCHER: Finished worker discovery
19:57:35 DISPATCHER: Starting worker discovery
19:57:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:57:35 DISPATCHER: Finished worker discovery
19:58:35 DISPATCHER: Starting worker discovery
19:58:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:58:35 DISPATCHER: Finished worker discovery
19:59:35 DISPATCHER: Starting worker discovery
19:59:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:59:35 DISPATCHER: Finished worker discovery
19:59:47 WORKER: done with job (0, 0, 26), trying to register it.
19:59:47 WORKER: registered result for job (0, 0, 26) with dispatcher
19:59:47 DISPATCHER: job (0, 0, 26) finished
19:59:47 DISPATCHER: register_result: lock acquired
19:59:47 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
19:59:47 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 824, 'last_n_outputs': 37, 'leak_rate': 0.7530567180866148, 'lr': 0.009714841751105948, 'optimizer': 'SGD', 'sparsity': 0.9164963236989383, 'steps_to_train': 17, 'weight_decay': 0.019189135671540916}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3833262930653618, 'info': {'music_genre': 0.3833262930653618, 'config': "{'batch_size': 32, 'hidden_dim': 824, 'last_n_outputs': 37, 'leak_rate': 0.7530567180866148, 'lr': 0.009714841751105948, 'optimizer': 'SGD', 'sparsity': 0.9164963236989383, 'steps_to_train': 17, 'weight_decay': 0.019189135671540916}"}}
exception: None

19:59:47 job_callback for (0, 0, 26) started
19:59:47 DISPATCHER: Trying to submit another job.
19:59:47 job_callback for (0, 0, 26) got condition
19:59:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:59:47 Only 9 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
19:59:47 HBMASTER: Trying to run another job!
19:59:47 job_callback for (0, 0, 26) finished
19:59:47 ITERATION: Advancing config (0, 0, 9) to next budget 400.000000
19:59:47 ITERATION: Advancing config (0, 0, 15) to next budget 400.000000
19:59:47 ITERATION: Advancing config (0, 0, 26) to next budget 400.000000
19:59:47 HBMASTER: schedule new run for iteration 0
19:59:47 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
19:59:47 HBMASTER: submitting job (0, 0, 9) to dispatcher
19:59:47 DISPATCHER: trying to submit job (0, 0, 9)
19:59:47 DISPATCHER: trying to notify the job_runner thread.
19:59:47 HBMASTER: job (0, 0, 9) submitted to dispatcher
19:59:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:59:47 DISPATCHER: Trying to submit another job.
19:59:47 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:59:47 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:59:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:59:47 WORKER: start processing job (0, 0, 9)
19:59:47 WORKER: args: ()
19:59:47 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 420, 'last_n_outputs': 49, 'leak_rate': 0.9662824033714353, 'lr': 0.002403527057358322, 'optimizer': 'SGD', 'sparsity': 0.9170724317801324, 'steps_to_train': 50, 'weight_decay': 0.021860696132922096}, 'budget': 400.0, 'working_directory': '.'}
20:00:35 DISPATCHER: Starting worker discovery
20:00:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:00:35 DISPATCHER: Finished worker discovery
20:01:35 DISPATCHER: Starting worker discovery
20:01:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:01:35 DISPATCHER: Finished worker discovery
20:02:35 DISPATCHER: Starting worker discovery
20:02:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:02:35 DISPATCHER: Finished worker discovery
20:03:35 DISPATCHER: Starting worker discovery
20:03:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:03:35 DISPATCHER: Finished worker discovery
20:04:35 DISPATCHER: Starting worker discovery
20:04:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:04:35 DISPATCHER: Finished worker discovery
20:05:35 DISPATCHER: Starting worker discovery
20:05:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:05:35 DISPATCHER: Finished worker discovery
20:06:35 DISPATCHER: Starting worker discovery
20:06:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:06:35 DISPATCHER: Finished worker discovery
20:07:35 WORKER: done with job (0, 0, 9), trying to register it.
20:07:35 WORKER: registered result for job (0, 0, 9) with dispatcher
20:07:35 DISPATCHER: job (0, 0, 9) finished
20:07:35 DISPATCHER: register_result: lock acquired
20:07:35 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
20:07:35 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 420, 'last_n_outputs': 49, 'leak_rate': 0.9662824033714353, 'lr': 0.002403527057358322, 'optimizer': 'SGD', 'sparsity': 0.9170724317801324, 'steps_to_train': 50, 'weight_decay': 0.021860696132922096}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.37592779482558025, 'info': {'music_genre': 0.37592779482558025, 'config': "{'batch_size': 32, 'hidden_dim': 420, 'last_n_outputs': 49, 'leak_rate': 0.9662824033714353, 'lr': 0.002403527057358322, 'optimizer': 'SGD', 'sparsity': 0.9170724317801324, 'steps_to_train': 50, 'weight_decay': 0.021860696132922096}"}}
exception: None

20:07:35 job_callback for (0, 0, 9) started
20:07:35 job_callback for (0, 0, 9) got condition
20:07:35 DISPATCHER: Trying to submit another job.
20:07:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:07:35 Only 1 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
20:07:35 HBMASTER: Trying to run another job!
20:07:35 job_callback for (0, 0, 9) finished
20:07:35 HBMASTER: schedule new run for iteration 0
20:07:35 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
20:07:35 HBMASTER: submitting job (0, 0, 15) to dispatcher
20:07:35 DISPATCHER: trying to submit job (0, 0, 15)
20:07:35 DISPATCHER: trying to notify the job_runner thread.
20:07:35 HBMASTER: job (0, 0, 15) submitted to dispatcher
20:07:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:07:35 DISPATCHER: Trying to submit another job.
20:07:35 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.30597140382006277952
20:07:35 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
20:07:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:07:35 WORKER: start processing job (0, 0, 15)
20:07:35 WORKER: args: ()
20:07:35 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 447, 'last_n_outputs': 45, 'leak_rate': 0.8071276327265037, 'lr': 0.0016752517079885473, 'optimizer': 'Adam', 'sparsity': 0.9276162095204692, 'steps_to_train': 84, 'weight_decay': 0.010168087392014009}, 'budget': 400.0, 'working_directory': '.'}
20:07:35 DISPATCHER: Starting worker discovery
20:07:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:07:35 DISPATCHER: Finished worker discovery
20:08:35 DISPATCHER: Starting worker discovery
20:08:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:08:35 DISPATCHER: Finished worker discovery
20:09:35 DISPATCHER: Starting worker discovery
20:09:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:09:35 DISPATCHER: Finished worker discovery
20:10:35 DISPATCHER: Starting worker discovery
20:10:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:10:35 DISPATCHER: Finished worker discovery
20:11:35 DISPATCHER: Starting worker discovery
20:11:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:11:35 DISPATCHER: Finished worker discovery
20:12:35 DISPATCHER: Starting worker discovery
20:12:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:12:35 DISPATCHER: Finished worker discovery
20:13:35 DISPATCHER: Starting worker discovery
20:13:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:13:35 DISPATCHER: Finished worker discovery
20:14:35 DISPATCHER: Starting worker discovery
20:14:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:14:35 DISPATCHER: Finished worker discovery
20:15:30 WORKER: done with job (0, 0, 15), trying to register it.
20:15:30 WORKER: registered result for job (0, 0, 15) with dispatcher
20:15:30 DISPATCHER: job (0, 0, 15) finished
20:15:30 DISPATCHER: register_result: lock acquired
20:15:30 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
20:15:30 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 447, 'last_n_outputs': 45, 'leak_rate': 0.8071276327265037, 'lr': 0.0016752517079885473, 'optimizer': 'Adam', 'sparsity': 0.9276162095204692, 'steps_to_train': 84, 'weight_decay': 0.010168087392014009}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3794582955822288, 'info': {'music_genre': 0.3794582955822288, 'config': "{'batch_size': 64, 'hidden_dim': 447, 'last_n_outputs': 45, 'leak_rate': 0.8071276327265037, 'lr': 0.0016752517079885473, 'optimizer': 'Adam', 'sparsity': 0.9276162095204692, 'steps_to_train': 84, 'weight_decay': 0.010168087392014009}"}}
exception: None

20:15:30 job_callback for (0, 0, 15) started
20:15:30 job_callback for (0, 0, 15) got condition
20:15:30 DISPATCHER: Trying to submit another job.
20:15:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:15:30 Only 2 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
20:15:30 HBMASTER: Trying to run another job!
20:15:30 job_callback for (0, 0, 15) finished
20:15:30 HBMASTER: schedule new run for iteration 0
20:15:30 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
20:15:30 HBMASTER: submitting job (0, 0, 26) to dispatcher
20:15:30 DISPATCHER: trying to submit job (0, 0, 26)
20:15:30 DISPATCHER: trying to notify the job_runner thread.
20:15:30 HBMASTER: job (0, 0, 26) submitted to dispatcher
20:15:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:15:30 DISPATCHER: Trying to submit another job.
20:15:30 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.30597140382006277952
20:15:30 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
20:15:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:15:30 WORKER: start processing job (0, 0, 26)
20:15:30 WORKER: args: ()
20:15:30 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 824, 'last_n_outputs': 37, 'leak_rate': 0.7530567180866148, 'lr': 0.009714841751105948, 'optimizer': 'SGD', 'sparsity': 0.9164963236989383, 'steps_to_train': 17, 'weight_decay': 0.019189135671540916}, 'budget': 400.0, 'working_directory': '.'}
20:15:35 DISPATCHER: Starting worker discovery
20:15:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:15:35 DISPATCHER: Finished worker discovery
20:16:35 DISPATCHER: Starting worker discovery
20:16:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:16:35 DISPATCHER: Finished worker discovery
20:17:35 DISPATCHER: Starting worker discovery
20:17:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:17:35 DISPATCHER: Finished worker discovery
20:18:35 DISPATCHER: Starting worker discovery
20:18:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:18:35 DISPATCHER: Finished worker discovery
20:19:35 DISPATCHER: Starting worker discovery
20:19:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:19:35 DISPATCHER: Finished worker discovery
20:20:35 DISPATCHER: Starting worker discovery
20:20:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:20:35 DISPATCHER: Finished worker discovery
20:21:35 DISPATCHER: Starting worker discovery
20:21:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:21:35 DISPATCHER: Finished worker discovery
20:22:35 DISPATCHER: Starting worker discovery
20:22:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:22:35 DISPATCHER: Finished worker discovery
20:23:11 WORKER: done with job (0, 0, 26), trying to register it.
20:23:11 WORKER: registered result for job (0, 0, 26) with dispatcher
20:23:11 DISPATCHER: job (0, 0, 26) finished
20:23:11 DISPATCHER: register_result: lock acquired
20:23:11 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
20:23:11 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 824, 'last_n_outputs': 37, 'leak_rate': 0.7530567180866148, 'lr': 0.009714841751105948, 'optimizer': 'SGD', 'sparsity': 0.9164963236989383, 'steps_to_train': 17, 'weight_decay': 0.019189135671540916}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.4000604017531285, 'info': {'music_genre': 0.4000604017531285, 'config': "{'batch_size': 32, 'hidden_dim': 824, 'last_n_outputs': 37, 'leak_rate': 0.7530567180866148, 'lr': 0.009714841751105948, 'optimizer': 'SGD', 'sparsity': 0.9164963236989383, 'steps_to_train': 17, 'weight_decay': 0.019189135671540916}"}}
exception: None

20:23:11 job_callback for (0, 0, 26) started
20:23:11 DISPATCHER: Trying to submit another job.
20:23:11 job_callback for (0, 0, 26) got condition
20:23:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:23:11 Only 3 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
20:23:11 HBMASTER: Trying to run another job!
20:23:11 job_callback for (0, 0, 26) finished
20:23:11 ITERATION: Advancing config (0, 0, 26) to next budget 1200.000000
20:23:11 HBMASTER: schedule new run for iteration 0
20:23:11 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
20:23:11 HBMASTER: submitting job (0, 0, 26) to dispatcher
20:23:11 DISPATCHER: trying to submit job (0, 0, 26)
20:23:11 DISPATCHER: trying to notify the job_runner thread.
20:23:11 HBMASTER: job (0, 0, 26) submitted to dispatcher
20:23:11 DISPATCHER: Trying to submit another job.
20:23:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:23:11 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.30597140382006277952
20:23:11 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
20:23:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:23:11 WORKER: start processing job (0, 0, 26)
20:23:11 WORKER: args: ()
20:23:11 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 824, 'last_n_outputs': 37, 'leak_rate': 0.7530567180866148, 'lr': 0.009714841751105948, 'optimizer': 'SGD', 'sparsity': 0.9164963236989383, 'steps_to_train': 17, 'weight_decay': 0.019189135671540916}, 'budget': 1200.0, 'working_directory': '.'}
20:23:35 DISPATCHER: Starting worker discovery
20:23:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:23:35 DISPATCHER: Finished worker discovery
20:24:35 DISPATCHER: Starting worker discovery
20:24:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:24:35 DISPATCHER: Finished worker discovery
20:25:35 DISPATCHER: Starting worker discovery
20:25:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:25:35 DISPATCHER: Finished worker discovery
20:26:35 DISPATCHER: Starting worker discovery
20:26:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:26:35 DISPATCHER: Finished worker discovery
20:27:35 DISPATCHER: Starting worker discovery
20:27:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:27:35 DISPATCHER: Finished worker discovery
20:28:35 DISPATCHER: Starting worker discovery
20:28:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:28:35 DISPATCHER: Finished worker discovery
20:29:35 DISPATCHER: Starting worker discovery
20:29:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:29:35 DISPATCHER: Finished worker discovery
20:30:35 DISPATCHER: Starting worker discovery
20:30:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:30:35 DISPATCHER: Finished worker discovery
20:31:35 DISPATCHER: Starting worker discovery
20:31:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:31:35 DISPATCHER: Finished worker discovery
20:32:35 DISPATCHER: Starting worker discovery
20:32:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:32:35 DISPATCHER: Finished worker discovery
20:33:35 DISPATCHER: Starting worker discovery
20:33:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:33:35 DISPATCHER: Finished worker discovery
20:34:35 DISPATCHER: Starting worker discovery
20:34:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:34:35 DISPATCHER: Finished worker discovery
20:35:35 DISPATCHER: Starting worker discovery
20:35:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:35:35 DISPATCHER: Finished worker discovery
20:36:35 DISPATCHER: Starting worker discovery
20:36:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:36:35 DISPATCHER: Finished worker discovery
20:37:35 DISPATCHER: Starting worker discovery
20:37:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:37:35 DISPATCHER: Finished worker discovery
20:38:35 DISPATCHER: Starting worker discovery
20:38:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:38:35 DISPATCHER: Finished worker discovery
20:39:35 DISPATCHER: Starting worker discovery
20:39:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:39:35 DISPATCHER: Finished worker discovery
20:40:35 DISPATCHER: Starting worker discovery
20:40:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:40:35 DISPATCHER: Finished worker discovery
20:41:35 DISPATCHER: Starting worker discovery
20:41:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:41:35 DISPATCHER: Finished worker discovery
20:42:35 DISPATCHER: Starting worker discovery
20:42:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:42:35 DISPATCHER: Finished worker discovery
20:43:35 DISPATCHER: Starting worker discovery
20:43:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:43:35 DISPATCHER: Finished worker discovery
20:44:16 WORKER: done with job (0, 0, 26), trying to register it.
20:44:16 WORKER: registered result for job (0, 0, 26) with dispatcher
20:44:16 DISPATCHER: job (0, 0, 26) finished
20:44:16 DISPATCHER: register_result: lock acquired
20:44:16 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
20:44:16 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 824, 'last_n_outputs': 37, 'leak_rate': 0.7530567180866148, 'lr': 0.009714841751105948, 'optimizer': 'SGD', 'sparsity': 0.9164963236989383, 'steps_to_train': 17, 'weight_decay': 0.019189135671540916}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.3664365107602376, 'info': {'music_genre': 0.3664365107602376, 'config': "{'batch_size': 32, 'hidden_dim': 824, 'last_n_outputs': 37, 'leak_rate': 0.7530567180866148, 'lr': 0.009714841751105948, 'optimizer': 'SGD', 'sparsity': 0.9164963236989383, 'steps_to_train': 17, 'weight_decay': 0.019189135671540916}"}}
exception: None

20:44:16 job_callback for (0, 0, 26) started
20:44:16 DISPATCHER: Trying to submit another job.
20:44:16 job_callback for (0, 0, 26) got condition
20:44:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:44:16 Only 1 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
20:44:16 HBMASTER: Trying to run another job!
20:44:16 job_callback for (0, 0, 26) finished
20:44:16 start sampling a new configuration.
20:44:16 best_vector: [0, 0.9458793705358111, 0.30673009188155154, 0.004585294017369909, 0.12981471107739034, 1, 0.6523015501421534, 0.018191551328611152, 0.22585458555888585], 0.002088056644669032, 0.12210920014282285, 0.000254970926733442
20:44:16 done sampling a new configuration.
20:44:16 HBMASTER: schedule new run for iteration 1
20:44:16 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
20:44:16 HBMASTER: submitting job (1, 0, 0) to dispatcher
20:44:16 DISPATCHER: trying to submit job (1, 0, 0)
20:44:16 DISPATCHER: trying to notify the job_runner thread.
20:44:16 HBMASTER: job (1, 0, 0) submitted to dispatcher
20:44:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:44:16 DISPATCHER: Trying to submit another job.
20:44:16 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
20:44:16 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
20:44:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:44:16 WORKER: start processing job (1, 0, 0)
20:44:16 WORKER: args: ()
20:44:16 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 957, 'last_n_outputs': 22, 'leak_rate': 0.7511463235043425, 'lr': 0.0018181487937556228, 'optimizer': 'SGD', 'sparsity': 0.9065523720341169, 'steps_to_train': 11, 'weight_decay': 0.01967177690443899}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:44:35 DISPATCHER: Starting worker discovery
20:44:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:44:35 DISPATCHER: Finished worker discovery
20:45:35 DISPATCHER: Starting worker discovery
20:45:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:45:35 DISPATCHER: Finished worker discovery
20:46:35 DISPATCHER: Starting worker discovery
20:46:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:46:35 DISPATCHER: Finished worker discovery
20:47:29 WORKER: done with job (1, 0, 0), trying to register it.
20:47:29 WORKER: registered result for job (1, 0, 0) with dispatcher
20:47:29 DISPATCHER: job (1, 0, 0) finished
20:47:29 DISPATCHER: register_result: lock acquired
20:47:29 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
20:47:29 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 957, 'last_n_outputs': 22, 'leak_rate': 0.7511463235043425, 'lr': 0.0018181487937556228, 'optimizer': 'SGD', 'sparsity': 0.9065523720341169, 'steps_to_train': 11, 'weight_decay': 0.01967177690443899}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.30382393967807686, 'info': {'music_genre': 0.30382393967807686, 'config': "{'batch_size': 16, 'hidden_dim': 957, 'last_n_outputs': 22, 'leak_rate': 0.7511463235043425, 'lr': 0.0018181487937556228, 'optimizer': 'SGD', 'sparsity': 0.9065523720341169, 'steps_to_train': 11, 'weight_decay': 0.01967177690443899}"}}
exception: None

20:47:29 job_callback for (1, 0, 0) started
20:47:29 job_callback for (1, 0, 0) got condition
20:47:29 DISPATCHER: Trying to submit another job.
20:47:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:47:29 HBMASTER: Trying to run another job!
20:47:29 job_callback for (1, 0, 0) finished
20:47:29 start sampling a new configuration.
20:47:29 best_vector: [3, 0.8347065279256857, 0.7346698638794305, 0.190211564814119, 0.47302807771658734, 1, 0.8546807260035401, 0.2734078555623888, 0.20869363144228512], 0.011489111440828675, 0.38609609623702884, 0.004435901076536138
20:47:29 done sampling a new configuration.
20:47:29 HBMASTER: schedule new run for iteration 1
20:47:29 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
20:47:29 HBMASTER: submitting job (1, 0, 1) to dispatcher
20:47:29 DISPATCHER: trying to submit job (1, 0, 1)
20:47:29 DISPATCHER: trying to notify the job_runner thread.
20:47:29 HBMASTER: job (1, 0, 1) submitted to dispatcher
20:47:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:47:29 DISPATCHER: Trying to submit another job.
20:47:29 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
20:47:29 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
20:47:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:47:29 WORKER: start processing job (1, 0, 1)
20:47:29 WORKER: args: ()
20:47:29 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 868, 'last_n_outputs': 40, 'leak_rate': 0.7975528912035298, 'lr': 0.008831940923841135, 'optimizer': 'SGD', 'sparsity': 0.9551233742408496, 'steps_to_train': 34, 'weight_decay': 0.01868601419426691}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:47:35 DISPATCHER: Starting worker discovery
20:47:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:47:35 DISPATCHER: Finished worker discovery
20:48:35 DISPATCHER: Starting worker discovery
20:48:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:48:35 DISPATCHER: Finished worker discovery
20:49:35 DISPATCHER: Starting worker discovery
20:49:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:49:35 DISPATCHER: Finished worker discovery
20:50:35 DISPATCHER: Starting worker discovery
20:50:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:50:35 DISPATCHER: Finished worker discovery
20:50:46 WORKER: done with job (1, 0, 1), trying to register it.
20:50:46 WORKER: registered result for job (1, 0, 1) with dispatcher
20:50:46 DISPATCHER: job (1, 0, 1) finished
20:50:46 DISPATCHER: register_result: lock acquired
20:50:46 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
20:50:46 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 868, 'last_n_outputs': 40, 'leak_rate': 0.7975528912035298, 'lr': 0.008831940923841135, 'optimizer': 'SGD', 'sparsity': 0.9551233742408496, 'steps_to_train': 34, 'weight_decay': 0.01868601419426691}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.37121088261689084, 'info': {'music_genre': 0.37121088261689084, 'config': "{'batch_size': 128, 'hidden_dim': 868, 'last_n_outputs': 40, 'leak_rate': 0.7975528912035298, 'lr': 0.008831940923841135, 'optimizer': 'SGD', 'sparsity': 0.9551233742408496, 'steps_to_train': 34, 'weight_decay': 0.01868601419426691}"}}
exception: None

20:50:46 job_callback for (1, 0, 1) started
20:50:46 DISPATCHER: Trying to submit another job.
20:50:46 job_callback for (1, 0, 1) got condition
20:50:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:50:46 HBMASTER: Trying to run another job!
20:50:46 job_callback for (1, 0, 1) finished
20:50:46 start sampling a new configuration.
20:50:46 best_vector: [2, 0.5075422949801875, 0.9500764125875528, 0.42360367358747036, 0.46707470787704447, 1, 0.874461551944796, 0.17057939201495528, 0.030183063454942594], 0.033666253710995395, 0.07878376703403413, 0.0026523542892757483
20:50:46 done sampling a new configuration.
20:50:46 HBMASTER: schedule new run for iteration 1
20:50:46 HBMASTER: trying submitting job (1, 0, 2) to dispatcher
20:50:46 HBMASTER: submitting job (1, 0, 2) to dispatcher
20:50:46 DISPATCHER: trying to submit job (1, 0, 2)
20:50:46 DISPATCHER: trying to notify the job_runner thread.
20:50:46 HBMASTER: job (1, 0, 2) submitted to dispatcher
20:50:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:50:46 DISPATCHER: Trying to submit another job.
20:50:46 DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
20:50:46 DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
20:50:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:50:46 WORKER: start processing job (1, 0, 2)
20:50:46 WORKER: args: ()
20:50:46 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 606, 'last_n_outputs': 48, 'leak_rate': 0.8559009183968675, 'lr': 0.008593091094990797, 'optimizer': 'SGD', 'sparsity': 0.959870772466751, 'steps_to_train': 25, 'weight_decay': 0.010946343464368458}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:51:35 DISPATCHER: Starting worker discovery
20:51:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:51:35 DISPATCHER: Finished worker discovery
20:52:35 DISPATCHER: Starting worker discovery
20:52:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:52:35 DISPATCHER: Finished worker discovery
20:53:35 DISPATCHER: Starting worker discovery
20:53:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:53:35 DISPATCHER: Finished worker discovery
20:53:59 WORKER: done with job (1, 0, 2), trying to register it.
20:53:59 WORKER: registered result for job (1, 0, 2) with dispatcher
20:53:59 DISPATCHER: job (1, 0, 2) finished
20:53:59 DISPATCHER: register_result: lock acquired
20:53:59 DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
20:53:59 job_id: (1, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 606, 'last_n_outputs': 48, 'leak_rate': 0.8559009183968675, 'lr': 0.008593091094990797, 'optimizer': 'SGD', 'sparsity': 0.959870772466751, 'steps_to_train': 25, 'weight_decay': 0.010946343464368458}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3898764565890672, 'info': {'music_genre': 0.3898764565890672, 'config': "{'batch_size': 64, 'hidden_dim': 606, 'last_n_outputs': 48, 'leak_rate': 0.8559009183968675, 'lr': 0.008593091094990797, 'optimizer': 'SGD', 'sparsity': 0.959870772466751, 'steps_to_train': 25, 'weight_decay': 0.010946343464368458}"}}
exception: None

20:53:59 job_callback for (1, 0, 2) started
20:53:59 DISPATCHER: Trying to submit another job.
20:53:59 job_callback for (1, 0, 2) got condition
20:53:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:53:59 HBMASTER: Trying to run another job!
20:53:59 job_callback for (1, 0, 2) finished
20:53:59 start sampling a new configuration.
20:53:59 best_vector: [2, 0.9135692287238449, 0.7140037226744524, 0.7035297585857189, 0.4310620516327077, 0, 0.8372702063372681, 0.05159945340003369, 0.051665744786134386], 0.04368564521574679, 0.015213620764451078, 0.0006646168391627283
20:53:59 done sampling a new configuration.
20:53:59 HBMASTER: schedule new run for iteration 1
20:53:59 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
20:53:59 HBMASTER: submitting job (1, 0, 3) to dispatcher
20:53:59 DISPATCHER: trying to submit job (1, 0, 3)
20:53:59 DISPATCHER: trying to notify the job_runner thread.
20:53:59 HBMASTER: job (1, 0, 3) submitted to dispatcher
20:53:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:53:59 DISPATCHER: Trying to submit another job.
20:53:59 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
20:53:59 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
20:53:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:53:59 WORKER: start processing job (1, 0, 3)
20:53:59 WORKER: args: ()
20:53:59 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 931, 'last_n_outputs': 39, 'leak_rate': 0.9258824396464297, 'lr': 0.007279878033948909, 'optimizer': 'Adam', 'sparsity': 0.9509448495209444, 'steps_to_train': 14, 'weight_decay': 0.011673972978287372}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:54:35 DISPATCHER: Starting worker discovery
20:54:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:54:35 DISPATCHER: Finished worker discovery
20:55:35 DISPATCHER: Starting worker discovery
20:55:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:55:35 DISPATCHER: Finished worker discovery
20:56:35 DISPATCHER: Starting worker discovery
20:56:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:56:35 DISPATCHER: Finished worker discovery
20:57:12 WORKER: done with job (1, 0, 3), trying to register it.
20:57:12 WORKER: registered result for job (1, 0, 3) with dispatcher
20:57:12 DISPATCHER: job (1, 0, 3) finished
20:57:12 DISPATCHER: register_result: lock acquired
20:57:12 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
20:57:12 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 931, 'last_n_outputs': 39, 'leak_rate': 0.9258824396464297, 'lr': 0.007279878033948909, 'optimizer': 'Adam', 'sparsity': 0.9509448495209444, 'steps_to_train': 14, 'weight_decay': 0.011673972978287372}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2576789841456002, 'info': {'music_genre': 0.2576789841456002, 'config': "{'batch_size': 64, 'hidden_dim': 931, 'last_n_outputs': 39, 'leak_rate': 0.9258824396464297, 'lr': 0.007279878033948909, 'optimizer': 'Adam', 'sparsity': 0.9509448495209444, 'steps_to_train': 14, 'weight_decay': 0.011673972978287372}"}}
exception: None

20:57:12 job_callback for (1, 0, 3) started
20:57:12 job_callback for (1, 0, 3) got condition
20:57:12 DISPATCHER: Trying to submit another job.
20:57:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:57:12 HBMASTER: Trying to run another job!
20:57:12 job_callback for (1, 0, 3) finished
20:57:12 start sampling a new configuration.
20:57:12 done sampling a new configuration.
20:57:12 HBMASTER: schedule new run for iteration 1
20:57:12 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
20:57:12 HBMASTER: submitting job (1, 0, 4) to dispatcher
20:57:12 DISPATCHER: trying to submit job (1, 0, 4)
20:57:12 DISPATCHER: trying to notify the job_runner thread.
20:57:12 HBMASTER: job (1, 0, 4) submitted to dispatcher
20:57:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:57:12 DISPATCHER: Trying to submit another job.
20:57:12 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
20:57:12 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
20:57:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:57:12 WORKER: start processing job (1, 0, 4)
20:57:12 WORKER: args: ()
20:57:12 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 493, 'last_n_outputs': 43, 'leak_rate': 0.9773070459786387, 'lr': 0.001571730089000634, 'optimizer': 'Adam', 'sparsity': 0.9764479302407728, 'steps_to_train': 23, 'weight_decay': 0.05487976459995245}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:57:35 DISPATCHER: Starting worker discovery
20:57:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:57:35 DISPATCHER: Finished worker discovery
20:58:35 DISPATCHER: Starting worker discovery
20:58:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:58:35 DISPATCHER: Finished worker discovery
20:59:35 DISPATCHER: Starting worker discovery
20:59:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:59:35 DISPATCHER: Finished worker discovery
21:00:22 WORKER: done with job (1, 0, 4), trying to register it.
21:00:22 WORKER: registered result for job (1, 0, 4) with dispatcher
21:00:22 DISPATCHER: job (1, 0, 4) finished
21:00:22 DISPATCHER: register_result: lock acquired
21:00:22 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
21:00:22 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 493, 'last_n_outputs': 43, 'leak_rate': 0.9773070459786387, 'lr': 0.001571730089000634, 'optimizer': 'Adam', 'sparsity': 0.9764479302407728, 'steps_to_train': 23, 'weight_decay': 0.05487976459995245}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2464316014256007, 'info': {'music_genre': 0.2464316014256007, 'config': "{'batch_size': 32, 'hidden_dim': 493, 'last_n_outputs': 43, 'leak_rate': 0.9773070459786387, 'lr': 0.001571730089000634, 'optimizer': 'Adam', 'sparsity': 0.9764479302407728, 'steps_to_train': 23, 'weight_decay': 0.05487976459995245}"}}
exception: None

21:00:22 job_callback for (1, 0, 4) started
21:00:22 job_callback for (1, 0, 4) got condition
21:00:22 DISPATCHER: Trying to submit another job.
21:00:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:00:22 HBMASTER: Trying to run another job!
21:00:22 job_callback for (1, 0, 4) finished
21:00:22 start sampling a new configuration.
21:00:23 best_vector: [3, 0.9117865751113263, 0.9270367025809363, 0.1613777478877858, 0.39914346336387346, 1, 0.4143209412662198, 0.04901531006979586, 0.005770340515375366], 0.006205085173016234, 0.11738583791038515, 0.0007283891223398178
21:00:23 done sampling a new configuration.
21:00:23 HBMASTER: schedule new run for iteration 1
21:00:23 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
21:00:23 HBMASTER: submitting job (1, 0, 5) to dispatcher
21:00:23 DISPATCHER: trying to submit job (1, 0, 5)
21:00:23 DISPATCHER: trying to notify the job_runner thread.
21:00:23 HBMASTER: job (1, 0, 5) submitted to dispatcher
21:00:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:00:23 DISPATCHER: Trying to submit another job.
21:00:23 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952
21:00:23 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
21:00:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:00:23 WORKER: start processing job (1, 0, 5)
21:00:23 WORKER: args: ()
21:00:23 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 930, 'last_n_outputs': 48, 'leak_rate': 0.7903444369719465, 'lr': 0.006284734372433483, 'optimizer': 'SGD', 'sparsity': 0.8494370259038928, 'steps_to_train': 14, 'weight_decay': 0.010174366696947407}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:00:35 DISPATCHER: Starting worker discovery
21:00:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:00:35 DISPATCHER: Finished worker discovery
21:01:35 DISPATCHER: Starting worker discovery
21:01:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:01:35 DISPATCHER: Finished worker discovery
21:02:35 DISPATCHER: Starting worker discovery
21:02:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:02:35 DISPATCHER: Finished worker discovery
21:03:35 DISPATCHER: Starting worker discovery
21:03:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:03:35 DISPATCHER: Finished worker discovery
21:03:37 WORKER: done with job (1, 0, 5), trying to register it.
21:03:37 WORKER: registered result for job (1, 0, 5) with dispatcher
21:03:37 DISPATCHER: job (1, 0, 5) finished
21:03:37 DISPATCHER: register_result: lock acquired
21:03:37 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
21:03:37 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 930, 'last_n_outputs': 48, 'leak_rate': 0.7903444369719465, 'lr': 0.006284734372433483, 'optimizer': 'SGD', 'sparsity': 0.8494370259038928, 'steps_to_train': 14, 'weight_decay': 0.010174366696947407}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.330612075152359, 'info': {'music_genre': 0.330612075152359, 'config': "{'batch_size': 128, 'hidden_dim': 930, 'last_n_outputs': 48, 'leak_rate': 0.7903444369719465, 'lr': 0.006284734372433483, 'optimizer': 'SGD', 'sparsity': 0.8494370259038928, 'steps_to_train': 14, 'weight_decay': 0.010174366696947407}"}}
exception: None

21:03:37 job_callback for (1, 0, 5) started
21:03:37 DISPATCHER: Trying to submit another job.
21:03:37 job_callback for (1, 0, 5) got condition
21:03:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:03:37 HBMASTER: Trying to run another job!
21:03:37 job_callback for (1, 0, 5) finished
21:03:37 start sampling a new configuration.
21:03:38 best_vector: [0, 0.5850128164106675, 0.5877307293487947, 0.01930864634598048, 0.13383484114435162, 1, 0.5510248335997461, 0.6204312219992365, 0.004226008211370549], 0.09197301166942064, 0.07047163408731164, 0.006481488424275454
21:03:38 done sampling a new configuration.
21:03:38 HBMASTER: schedule new run for iteration 1
21:03:38 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
21:03:38 HBMASTER: submitting job (1, 0, 6) to dispatcher
21:03:38 DISPATCHER: trying to submit job (1, 0, 6)
21:03:38 DISPATCHER: trying to notify the job_runner thread.
21:03:38 HBMASTER: job (1, 0, 6) submitted to dispatcher
21:03:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:03:38 DISPATCHER: Trying to submit another job.
21:03:38 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952
21:03:38 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
21:03:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:03:38 WORKER: start processing job (1, 0, 6)
21:03:38 WORKER: args: ()
21:03:38 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 668, 'last_n_outputs': 34, 'leak_rate': 0.7548271615864951, 'lr': 0.0018521223917239492, 'optimizer': 'SGD', 'sparsity': 0.8822459600639391, 'steps_to_train': 66, 'weight_decay': 0.010127404661039221}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:04:35 DISPATCHER: Starting worker discovery
21:04:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:04:35 DISPATCHER: Finished worker discovery
21:05:35 DISPATCHER: Starting worker discovery
21:05:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:05:35 DISPATCHER: Finished worker discovery
21:06:35 DISPATCHER: Starting worker discovery
21:06:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:06:35 DISPATCHER: Finished worker discovery
21:06:55 WORKER: done with job (1, 0, 6), trying to register it.
21:06:55 WORKER: registered result for job (1, 0, 6) with dispatcher
21:06:55 DISPATCHER: job (1, 0, 6) finished
21:06:55 DISPATCHER: register_result: lock acquired
21:06:55 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
21:06:55 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 668, 'last_n_outputs': 34, 'leak_rate': 0.7548271615864951, 'lr': 0.0018521223917239492, 'optimizer': 'SGD', 'sparsity': 0.8822459600639391, 'steps_to_train': 66, 'weight_decay': 0.010127404661039221}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.34926877202335493, 'info': {'music_genre': 0.34926877202335493, 'config': "{'batch_size': 16, 'hidden_dim': 668, 'last_n_outputs': 34, 'leak_rate': 0.7548271615864951, 'lr': 0.0018521223917239492, 'optimizer': 'SGD', 'sparsity': 0.8822459600639391, 'steps_to_train': 66, 'weight_decay': 0.010127404661039221}"}}
exception: None

21:06:55 job_callback for (1, 0, 6) started
21:06:55 job_callback for (1, 0, 6) got condition
21:06:55 DISPATCHER: Trying to submit another job.
21:06:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:06:55 HBMASTER: Trying to run another job!
21:06:55 job_callback for (1, 0, 6) finished
21:06:55 start sampling a new configuration.
21:06:55 done sampling a new configuration.
21:06:55 HBMASTER: schedule new run for iteration 1
21:06:55 HBMASTER: trying submitting job (1, 0, 7) to dispatcher
21:06:55 HBMASTER: submitting job (1, 0, 7) to dispatcher
21:06:55 DISPATCHER: trying to submit job (1, 0, 7)
21:06:55 DISPATCHER: trying to notify the job_runner thread.
21:06:55 HBMASTER: job (1, 0, 7) submitted to dispatcher
21:06:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:06:55 DISPATCHER: Trying to submit another job.
21:06:55 DISPATCHER: starting job (1, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952
21:06:55 DISPATCHER: job (1, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
21:06:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:06:55 WORKER: start processing job (1, 0, 7)
21:06:55 WORKER: args: ()
21:06:55 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 531, 'last_n_outputs': 22, 'leak_rate': 0.9551238928362106, 'lr': 0.04109206623353178, 'optimizer': 'SGD', 'sparsity': 0.8018639309363168, 'steps_to_train': 12, 'weight_decay': 0.01424093655688567}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:07:35 DISPATCHER: Starting worker discovery
21:07:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:07:35 DISPATCHER: Finished worker discovery
21:08:35 DISPATCHER: Starting worker discovery
21:08:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:08:35 DISPATCHER: Finished worker discovery
21:09:35 DISPATCHER: Starting worker discovery
21:09:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:09:35 DISPATCHER: Finished worker discovery
21:10:07 WORKER: done with job (1, 0, 7), trying to register it.
21:10:07 WORKER: registered result for job (1, 0, 7) with dispatcher
21:10:07 DISPATCHER: job (1, 0, 7) finished
21:10:07 DISPATCHER: register_result: lock acquired
21:10:07 DISPATCHER: job (1, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
21:10:07 job_id: (1, 0, 7)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 531, 'last_n_outputs': 22, 'leak_rate': 0.9551238928362106, 'lr': 0.04109206623353178, 'optimizer': 'SGD', 'sparsity': 0.8018639309363168, 'steps_to_train': 12, 'weight_decay': 0.01424093655688567}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.31097205436029557, 'info': {'music_genre': 0.31097205436029557, 'config': "{'batch_size': 32, 'hidden_dim': 531, 'last_n_outputs': 22, 'leak_rate': 0.9551238928362106, 'lr': 0.04109206623353178, 'optimizer': 'SGD', 'sparsity': 0.8018639309363168, 'steps_to_train': 12, 'weight_decay': 0.01424093655688567}"}}
exception: None

21:10:07 job_callback for (1, 0, 7) started
21:10:07 DISPATCHER: Trying to submit another job.
21:10:07 job_callback for (1, 0, 7) got condition
21:10:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:10:07 HBMASTER: Trying to run another job!
21:10:07 job_callback for (1, 0, 7) finished
21:10:07 start sampling a new configuration.
21:10:07 best_vector: [3, 0.3100842165920006, 0.955881555950768, 0.16226603233603734, 0.4459616678028038, 1, 0.5971267806968211, 0.1226798024677761, 0.3846842072457765], 0.09487313029339366, 0.09887248734090011, 0.00938034237392513
21:10:07 done sampling a new configuration.
21:10:07 HBMASTER: schedule new run for iteration 1
21:10:07 HBMASTER: trying submitting job (1, 0, 8) to dispatcher
21:10:07 HBMASTER: submitting job (1, 0, 8) to dispatcher
21:10:07 DISPATCHER: trying to submit job (1, 0, 8)
21:10:07 DISPATCHER: trying to notify the job_runner thread.
21:10:07 HBMASTER: job (1, 0, 8) submitted to dispatcher
21:10:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:10:07 DISPATCHER: Trying to submit another job.
21:10:07 DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952
21:10:07 DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
21:10:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:10:07 WORKER: start processing job (1, 0, 8)
21:10:07 WORKER: args: ()
21:10:07 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 448, 'last_n_outputs': 49, 'leak_rate': 0.7905665080840093, 'lr': 0.007796924621553348, 'optimizer': 'SGD', 'sparsity': 0.8933104273672371, 'steps_to_train': 21, 'weight_decay': 0.0316581616620912}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:10:35 DISPATCHER: Starting worker discovery
21:10:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:10:35 DISPATCHER: Finished worker discovery
21:11:35 DISPATCHER: Starting worker discovery
21:11:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:11:35 DISPATCHER: Finished worker discovery
21:12:35 DISPATCHER: Starting worker discovery
21:12:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:12:35 DISPATCHER: Finished worker discovery
21:13:21 WORKER: done with job (1, 0, 8), trying to register it.
21:13:21 WORKER: registered result for job (1, 0, 8) with dispatcher
21:13:21 DISPATCHER: job (1, 0, 8) finished
21:13:21 DISPATCHER: register_result: lock acquired
21:13:21 DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
21:13:21 job_id: (1, 0, 8)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 448, 'last_n_outputs': 49, 'leak_rate': 0.7905665080840093, 'lr': 0.007796924621553348, 'optimizer': 'SGD', 'sparsity': 0.8933104273672371, 'steps_to_train': 21, 'weight_decay': 0.0316581616620912}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.392204672961438, 'info': {'music_genre': 0.392204672961438, 'config': "{'batch_size': 128, 'hidden_dim': 448, 'last_n_outputs': 49, 'leak_rate': 0.7905665080840093, 'lr': 0.007796924621553348, 'optimizer': 'SGD', 'sparsity': 0.8933104273672371, 'steps_to_train': 21, 'weight_decay': 0.0316581616620912}"}}
exception: None

21:13:21 job_callback for (1, 0, 8) started
21:13:21 job_callback for (1, 0, 8) got condition
21:13:21 DISPATCHER: Trying to submit another job.
21:13:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:13:21 HBMASTER: Trying to run another job!
21:13:21 job_callback for (1, 0, 8) finished
21:13:21 ITERATION: Advancing config (1, 0, 1) to next budget 400.000000
21:13:21 ITERATION: Advancing config (1, 0, 2) to next budget 400.000000
21:13:21 ITERATION: Advancing config (1, 0, 8) to next budget 400.000000
21:13:21 HBMASTER: schedule new run for iteration 1
21:13:21 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
21:13:21 HBMASTER: submitting job (1, 0, 1) to dispatcher
21:13:21 DISPATCHER: trying to submit job (1, 0, 1)
21:13:21 DISPATCHER: trying to notify the job_runner thread.
21:13:21 HBMASTER: job (1, 0, 1) submitted to dispatcher
21:13:21 DISPATCHER: Trying to submit another job.
21:13:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:13:21 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
21:13:21 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
21:13:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:13:21 WORKER: start processing job (1, 0, 1)
21:13:21 WORKER: args: ()
21:13:21 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 868, 'last_n_outputs': 40, 'leak_rate': 0.7975528912035298, 'lr': 0.008831940923841135, 'optimizer': 'SGD', 'sparsity': 0.9551233742408496, 'steps_to_train': 34, 'weight_decay': 0.01868601419426691}, 'budget': 400.0, 'working_directory': '.'}
21:13:35 DISPATCHER: Starting worker discovery
21:13:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:13:35 DISPATCHER: Finished worker discovery
21:14:35 DISPATCHER: Starting worker discovery
21:14:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:14:35 DISPATCHER: Finished worker discovery
21:15:35 DISPATCHER: Starting worker discovery
21:15:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:15:35 DISPATCHER: Finished worker discovery
21:16:35 DISPATCHER: Starting worker discovery
21:16:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:16:35 DISPATCHER: Finished worker discovery
21:17:35 DISPATCHER: Starting worker discovery
21:17:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:17:35 DISPATCHER: Finished worker discovery
21:18:35 DISPATCHER: Starting worker discovery
21:18:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:18:35 DISPATCHER: Finished worker discovery
21:19:35 DISPATCHER: Starting worker discovery
21:19:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:19:35 DISPATCHER: Finished worker discovery
21:20:35 DISPATCHER: Starting worker discovery
21:20:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:20:35 DISPATCHER: Finished worker discovery
21:21:03 WORKER: done with job (1, 0, 1), trying to register it.
21:21:03 WORKER: registered result for job (1, 0, 1) with dispatcher
21:21:03 DISPATCHER: job (1, 0, 1) finished
21:21:03 DISPATCHER: register_result: lock acquired
21:21:03 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
21:21:03 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 868, 'last_n_outputs': 40, 'leak_rate': 0.7975528912035298, 'lr': 0.008831940923841135, 'optimizer': 'SGD', 'sparsity': 0.9551233742408496, 'steps_to_train': 34, 'weight_decay': 0.01868601419426691}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.37667185296208544, 'info': {'music_genre': 0.37667185296208544, 'config': "{'batch_size': 128, 'hidden_dim': 868, 'last_n_outputs': 40, 'leak_rate': 0.7975528912035298, 'lr': 0.008831940923841135, 'optimizer': 'SGD', 'sparsity': 0.9551233742408496, 'steps_to_train': 34, 'weight_decay': 0.01868601419426691}"}}
exception: None

21:21:03 job_callback for (1, 0, 1) started
21:21:03 DISPATCHER: Trying to submit another job.
21:21:03 job_callback for (1, 0, 1) got condition
21:21:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:21:03 Only 4 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
21:21:03 HBMASTER: Trying to run another job!
21:21:03 job_callback for (1, 0, 1) finished
21:21:03 HBMASTER: schedule new run for iteration 1
21:21:03 HBMASTER: trying submitting job (1, 0, 2) to dispatcher
21:21:03 HBMASTER: submitting job (1, 0, 2) to dispatcher
21:21:03 DISPATCHER: trying to submit job (1, 0, 2)
21:21:03 DISPATCHER: trying to notify the job_runner thread.
21:21:03 HBMASTER: job (1, 0, 2) submitted to dispatcher
21:21:03 DISPATCHER: Trying to submit another job.
21:21:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:21:03 DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
21:21:03 DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
21:21:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:21:03 WORKER: start processing job (1, 0, 2)
21:21:03 WORKER: args: ()
21:21:03 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 606, 'last_n_outputs': 48, 'leak_rate': 0.8559009183968675, 'lr': 0.008593091094990797, 'optimizer': 'SGD', 'sparsity': 0.959870772466751, 'steps_to_train': 25, 'weight_decay': 0.010946343464368458}, 'budget': 400.0, 'working_directory': '.'}
21:21:35 DISPATCHER: Starting worker discovery
21:21:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:21:35 DISPATCHER: Finished worker discovery
21:22:35 DISPATCHER: Starting worker discovery
21:22:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:22:35 DISPATCHER: Finished worker discovery
21:23:35 DISPATCHER: Starting worker discovery
21:23:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:23:35 DISPATCHER: Finished worker discovery
21:24:35 DISPATCHER: Starting worker discovery
21:24:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:24:35 DISPATCHER: Finished worker discovery
21:25:35 DISPATCHER: Starting worker discovery
21:25:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:25:35 DISPATCHER: Finished worker discovery
21:26:35 DISPATCHER: Starting worker discovery
21:26:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:26:35 DISPATCHER: Finished worker discovery
21:27:35 DISPATCHER: Starting worker discovery
21:27:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:27:35 DISPATCHER: Finished worker discovery
21:28:35 DISPATCHER: Starting worker discovery
21:28:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:28:35 DISPATCHER: Finished worker discovery
21:28:48 WORKER: done with job (1, 0, 2), trying to register it.
21:28:48 WORKER: registered result for job (1, 0, 2) with dispatcher
21:28:48 DISPATCHER: job (1, 0, 2) finished
21:28:48 DISPATCHER: register_result: lock acquired
21:28:48 DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
21:28:48 job_id: (1, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 606, 'last_n_outputs': 48, 'leak_rate': 0.8559009183968675, 'lr': 0.008593091094990797, 'optimizer': 'SGD', 'sparsity': 0.959870772466751, 'steps_to_train': 25, 'weight_decay': 0.010946343464368458}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3768903593344146, 'info': {'music_genre': 0.3768903593344146, 'config': "{'batch_size': 64, 'hidden_dim': 606, 'last_n_outputs': 48, 'leak_rate': 0.8559009183968675, 'lr': 0.008593091094990797, 'optimizer': 'SGD', 'sparsity': 0.959870772466751, 'steps_to_train': 25, 'weight_decay': 0.010946343464368458}"}}
exception: None

21:28:48 job_callback for (1, 0, 2) started
21:28:48 job_callback for (1, 0, 2) got condition
21:28:48 DISPATCHER: Trying to submit another job.
21:28:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:28:48 Only 5 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
21:28:48 HBMASTER: Trying to run another job!
21:28:48 job_callback for (1, 0, 2) finished
21:28:48 HBMASTER: schedule new run for iteration 1
21:28:48 HBMASTER: trying submitting job (1, 0, 8) to dispatcher
21:28:48 HBMASTER: submitting job (1, 0, 8) to dispatcher
21:28:48 DISPATCHER: trying to submit job (1, 0, 8)
21:28:48 DISPATCHER: trying to notify the job_runner thread.
21:28:48 HBMASTER: job (1, 0, 8) submitted to dispatcher
21:28:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:28:48 DISPATCHER: Trying to submit another job.
21:28:48 DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952
21:28:48 DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
21:28:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:28:48 WORKER: start processing job (1, 0, 8)
21:28:48 WORKER: args: ()
21:28:48 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 448, 'last_n_outputs': 49, 'leak_rate': 0.7905665080840093, 'lr': 0.007796924621553348, 'optimizer': 'SGD', 'sparsity': 0.8933104273672371, 'steps_to_train': 21, 'weight_decay': 0.0316581616620912}, 'budget': 400.0, 'working_directory': '.'}
21:29:35 DISPATCHER: Starting worker discovery
21:29:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:29:35 DISPATCHER: Finished worker discovery
21:30:35 DISPATCHER: Starting worker discovery
21:30:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:30:35 DISPATCHER: Finished worker discovery
21:31:35 DISPATCHER: Starting worker discovery
21:31:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:31:35 DISPATCHER: Finished worker discovery
21:32:35 DISPATCHER: Starting worker discovery
21:32:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:32:35 DISPATCHER: Finished worker discovery
21:33:35 DISPATCHER: Starting worker discovery
21:33:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:33:35 DISPATCHER: Finished worker discovery
21:34:35 DISPATCHER: Starting worker discovery
21:34:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:34:35 DISPATCHER: Finished worker discovery
21:35:35 DISPATCHER: Starting worker discovery
21:35:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:35:35 DISPATCHER: Finished worker discovery
21:36:33 WORKER: done with job (1, 0, 8), trying to register it.
21:36:33 WORKER: registered result for job (1, 0, 8) with dispatcher
21:36:33 DISPATCHER: job (1, 0, 8) finished
21:36:33 DISPATCHER: register_result: lock acquired
21:36:33 DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
21:36:33 job_id: (1, 0, 8)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 448, 'last_n_outputs': 49, 'leak_rate': 0.7905665080840093, 'lr': 0.007796924621553348, 'optimizer': 'SGD', 'sparsity': 0.8933104273672371, 'steps_to_train': 21, 'weight_decay': 0.0316581616620912}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.365097841757535, 'info': {'music_genre': 0.365097841757535, 'config': "{'batch_size': 128, 'hidden_dim': 448, 'last_n_outputs': 49, 'leak_rate': 0.7905665080840093, 'lr': 0.007796924621553348, 'optimizer': 'SGD', 'sparsity': 0.8933104273672371, 'steps_to_train': 21, 'weight_decay': 0.0316581616620912}"}}
exception: None

21:36:33 job_callback for (1, 0, 8) started
21:36:33 job_callback for (1, 0, 8) got condition
21:36:33 DISPATCHER: Trying to submit another job.
21:36:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:36:33 Only 6 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
21:36:33 HBMASTER: Trying to run another job!
21:36:33 job_callback for (1, 0, 8) finished
21:36:33 ITERATION: Advancing config (1, 0, 2) to next budget 1200.000000
21:36:33 HBMASTER: schedule new run for iteration 1
21:36:33 HBMASTER: trying submitting job (1, 0, 2) to dispatcher
21:36:33 HBMASTER: submitting job (1, 0, 2) to dispatcher
21:36:33 DISPATCHER: trying to submit job (1, 0, 2)
21:36:33 DISPATCHER: trying to notify the job_runner thread.
21:36:33 HBMASTER: job (1, 0, 2) submitted to dispatcher
21:36:33 DISPATCHER: Trying to submit another job.
21:36:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:36:33 DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
21:36:33 DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
21:36:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:36:33 WORKER: start processing job (1, 0, 2)
21:36:33 WORKER: args: ()
21:36:33 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 606, 'last_n_outputs': 48, 'leak_rate': 0.8559009183968675, 'lr': 0.008593091094990797, 'optimizer': 'SGD', 'sparsity': 0.959870772466751, 'steps_to_train': 25, 'weight_decay': 0.010946343464368458}, 'budget': 1200.0, 'working_directory': '.'}
21:36:35 DISPATCHER: Starting worker discovery
21:36:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:36:35 DISPATCHER: Finished worker discovery
21:37:35 DISPATCHER: Starting worker discovery
21:37:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:37:35 DISPATCHER: Finished worker discovery
21:38:35 DISPATCHER: Starting worker discovery
21:38:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:38:35 DISPATCHER: Finished worker discovery
21:39:35 DISPATCHER: Starting worker discovery
21:39:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:39:35 DISPATCHER: Finished worker discovery
21:40:35 DISPATCHER: Starting worker discovery
21:40:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:40:35 DISPATCHER: Finished worker discovery
21:41:35 DISPATCHER: Starting worker discovery
21:41:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:41:35 DISPATCHER: Finished worker discovery
21:42:35 DISPATCHER: Starting worker discovery
21:42:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:42:35 DISPATCHER: Finished worker discovery
21:43:35 DISPATCHER: Starting worker discovery
21:43:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:43:35 DISPATCHER: Finished worker discovery
21:44:35 DISPATCHER: Starting worker discovery
21:44:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:44:35 DISPATCHER: Finished worker discovery
21:45:35 DISPATCHER: Starting worker discovery
21:45:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:45:36 DISPATCHER: Finished worker discovery
21:46:36 DISPATCHER: Starting worker discovery
21:46:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:46:36 DISPATCHER: Finished worker discovery
21:47:36 DISPATCHER: Starting worker discovery
21:47:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:47:36 DISPATCHER: Finished worker discovery
21:48:36 DISPATCHER: Starting worker discovery
21:48:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:48:36 DISPATCHER: Finished worker discovery
21:49:36 DISPATCHER: Starting worker discovery
21:49:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:49:36 DISPATCHER: Finished worker discovery
21:50:36 DISPATCHER: Starting worker discovery
21:50:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:50:36 DISPATCHER: Finished worker discovery
21:51:36 DISPATCHER: Starting worker discovery
21:51:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:51:36 DISPATCHER: Finished worker discovery
21:52:36 DISPATCHER: Starting worker discovery
21:52:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:52:36 DISPATCHER: Finished worker discovery
21:53:36 DISPATCHER: Starting worker discovery
21:53:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:53:36 DISPATCHER: Finished worker discovery
21:54:36 DISPATCHER: Starting worker discovery
21:54:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:54:36 DISPATCHER: Finished worker discovery
21:55:36 DISPATCHER: Starting worker discovery
21:55:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:55:36 DISPATCHER: Finished worker discovery
21:56:36 DISPATCHER: Starting worker discovery
21:56:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:56:36 DISPATCHER: Finished worker discovery
21:57:36 DISPATCHER: Starting worker discovery
21:57:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:57:36 DISPATCHER: Finished worker discovery
21:57:36 WORKER: done with job (1, 0, 2), trying to register it.
21:57:36 WORKER: registered result for job (1, 0, 2) with dispatcher
21:57:36 DISPATCHER: job (1, 0, 2) finished
21:57:36 DISPATCHER: register_result: lock acquired
21:57:36 DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
21:57:36 job_id: (1, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 606, 'last_n_outputs': 48, 'leak_rate': 0.8559009183968675, 'lr': 0.008593091094990797, 'optimizer': 'SGD', 'sparsity': 0.959870772466751, 'steps_to_train': 25, 'weight_decay': 0.010946343464368458}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.37780567534534276, 'info': {'music_genre': 0.37780567534534276, 'config': "{'batch_size': 64, 'hidden_dim': 606, 'last_n_outputs': 48, 'leak_rate': 0.8559009183968675, 'lr': 0.008593091094990797, 'optimizer': 'SGD', 'sparsity': 0.959870772466751, 'steps_to_train': 25, 'weight_decay': 0.010946343464368458}"}}
exception: None

21:57:36 job_callback for (1, 0, 2) started
21:57:36 job_callback for (1, 0, 2) got condition
21:57:36 DISPATCHER: Trying to submit another job.
21:57:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:57:36 Only 2 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
21:57:36 HBMASTER: Trying to run another job!
21:57:36 job_callback for (1, 0, 2) finished
21:57:36 start sampling a new configuration.
21:57:36 best_vector: [0, 0.7368081717190599, 0.05453597569338015, 0.08638761768192538, 0.624468870253613, 1, 0.8003761454761656, 0.3154580578726216, 0.007669175547524609], 0.011387389695364073, 0.16358676768344166, 0.00186282627261634
21:57:36 done sampling a new configuration.
21:57:36 HBMASTER: schedule new run for iteration 2
21:57:36 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
21:57:36 HBMASTER: submitting job (2, 0, 0) to dispatcher
21:57:36 DISPATCHER: trying to submit job (2, 0, 0)
21:57:36 DISPATCHER: trying to notify the job_runner thread.
21:57:36 HBMASTER: job (2, 0, 0) submitted to dispatcher
21:57:36 DISPATCHER: Trying to submit another job.
21:57:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:57:36 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
21:57:36 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
21:57:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:57:36 WORKER: start processing job (2, 0, 0)
21:57:36 WORKER: args: ()
21:57:36 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 790, 'last_n_outputs': 12, 'leak_rate': 0.7715969044204813, 'lr': 0.01773935155255175, 'optimizer': 'SGD', 'sparsity': 0.9420902749142798, 'steps_to_train': 38, 'weight_decay': 0.010232407501778853}, 'budget': 400.0, 'working_directory': '.'}
21:58:36 DISPATCHER: Starting worker discovery
21:58:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:58:36 DISPATCHER: Finished worker discovery
21:59:36 DISPATCHER: Starting worker discovery
21:59:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:59:36 DISPATCHER: Finished worker discovery
22:00:36 DISPATCHER: Starting worker discovery
22:00:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:00:36 DISPATCHER: Finished worker discovery
22:01:36 DISPATCHER: Starting worker discovery
22:01:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:01:36 DISPATCHER: Finished worker discovery
22:02:36 DISPATCHER: Starting worker discovery
22:02:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:02:36 DISPATCHER: Finished worker discovery
22:03:36 DISPATCHER: Starting worker discovery
22:03:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:03:36 DISPATCHER: Finished worker discovery
22:04:36 DISPATCHER: Starting worker discovery
22:04:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:04:36 DISPATCHER: Finished worker discovery
22:05:19 WORKER: done with job (2, 0, 0), trying to register it.
22:05:19 WORKER: registered result for job (2, 0, 0) with dispatcher
22:05:19 DISPATCHER: job (2, 0, 0) finished
22:05:19 DISPATCHER: register_result: lock acquired
22:05:19 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
22:05:19 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 790, 'last_n_outputs': 12, 'leak_rate': 0.7715969044204813, 'lr': 0.01773935155255175, 'optimizer': 'SGD', 'sparsity': 0.9420902749142798, 'steps_to_train': 38, 'weight_decay': 0.010232407501778853}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3040322010304698, 'info': {'music_genre': 0.3040322010304698, 'config': "{'batch_size': 16, 'hidden_dim': 790, 'last_n_outputs': 12, 'leak_rate': 0.7715969044204813, 'lr': 0.01773935155255175, 'optimizer': 'SGD', 'sparsity': 0.9420902749142798, 'steps_to_train': 38, 'weight_decay': 0.010232407501778853}"}}
exception: None

22:05:19 job_callback for (2, 0, 0) started
22:05:19 DISPATCHER: Trying to submit another job.
22:05:19 job_callback for (2, 0, 0) got condition
22:05:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:05:19 Only 7 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
22:05:19 HBMASTER: Trying to run another job!
22:05:19 job_callback for (2, 0, 0) finished
22:05:19 start sampling a new configuration.
22:05:19 best_vector: [1, 0.7654478970315046, 0.44193501600451746, 0.3747478045632026, 0.3933757221607417, 1, 0.9055867905953573, 0.10238061542750093, 0.023160915727377357], 0.026328344921457057, 0.07980729528397042, 0.002101193997484946
22:05:19 done sampling a new configuration.
22:05:19 HBMASTER: schedule new run for iteration 2
22:05:19 HBMASTER: trying submitting job (2, 0, 1) to dispatcher
22:05:19 HBMASTER: submitting job (2, 0, 1) to dispatcher
22:05:19 DISPATCHER: trying to submit job (2, 0, 1)
22:05:19 DISPATCHER: trying to notify the job_runner thread.
22:05:19 HBMASTER: job (2, 0, 1) submitted to dispatcher
22:05:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:05:19 DISPATCHER: Trying to submit another job.
22:05:19 DISPATCHER: starting job (2, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:05:19 DISPATCHER: job (2, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:05:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:05:19 WORKER: start processing job (2, 0, 1)
22:05:19 WORKER: args: ()
22:05:19 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 813, 'last_n_outputs': 28, 'leak_rate': 0.8436869511408006, 'lr': 0.006120000312499131, 'optimizer': 'SGD', 'sparsity': 0.9673408297428857, 'steps_to_train': 19, 'weight_decay': 0.010718476153985359}, 'budget': 400.0, 'working_directory': '.'}
22:05:36 DISPATCHER: Starting worker discovery
22:05:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:05:36 DISPATCHER: Finished worker discovery
22:06:36 DISPATCHER: Starting worker discovery
22:06:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:06:36 DISPATCHER: Finished worker discovery
22:07:36 DISPATCHER: Starting worker discovery
22:07:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:07:36 DISPATCHER: Finished worker discovery
22:08:36 DISPATCHER: Starting worker discovery
22:08:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:08:36 DISPATCHER: Finished worker discovery
22:09:36 DISPATCHER: Starting worker discovery
22:09:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:09:36 DISPATCHER: Finished worker discovery
22:10:36 DISPATCHER: Starting worker discovery
22:10:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:10:36 DISPATCHER: Finished worker discovery
22:11:36 DISPATCHER: Starting worker discovery
22:11:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:11:36 DISPATCHER: Finished worker discovery
22:12:36 DISPATCHER: Starting worker discovery
22:12:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:12:36 DISPATCHER: Finished worker discovery
22:13:01 WORKER: done with job (2, 0, 1), trying to register it.
22:13:01 WORKER: registered result for job (2, 0, 1) with dispatcher
22:13:01 DISPATCHER: job (2, 0, 1) finished
22:13:01 DISPATCHER: register_result: lock acquired
22:13:01 DISPATCHER: job (2, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
22:13:01 job_id: (2, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 813, 'last_n_outputs': 28, 'leak_rate': 0.8436869511408006, 'lr': 0.006120000312499131, 'optimizer': 'SGD', 'sparsity': 0.9673408297428857, 'steps_to_train': 19, 'weight_decay': 0.010718476153985359}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3513893099091978, 'info': {'music_genre': 0.3513893099091978, 'config': "{'batch_size': 32, 'hidden_dim': 813, 'last_n_outputs': 28, 'leak_rate': 0.8436869511408006, 'lr': 0.006120000312499131, 'optimizer': 'SGD', 'sparsity': 0.9673408297428857, 'steps_to_train': 19, 'weight_decay': 0.010718476153985359}"}}
exception: None

22:13:01 job_callback for (2, 0, 1) started
22:13:01 job_callback for (2, 0, 1) got condition
22:13:01 DISPATCHER: Trying to submit another job.
22:13:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:13:01 Only 8 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
22:13:01 HBMASTER: Trying to run another job!
22:13:01 job_callback for (2, 0, 1) finished
22:13:01 start sampling a new configuration.
22:13:01 done sampling a new configuration.
22:13:01 HBMASTER: schedule new run for iteration 2
22:13:01 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
22:13:01 HBMASTER: submitting job (2, 0, 2) to dispatcher
22:13:01 DISPATCHER: trying to submit job (2, 0, 2)
22:13:01 DISPATCHER: trying to notify the job_runner thread.
22:13:01 HBMASTER: job (2, 0, 2) submitted to dispatcher
22:13:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:13:01 DISPATCHER: Trying to submit another job.
22:13:01 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:13:01 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:13:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:13:01 WORKER: start processing job (2, 0, 2)
22:13:01 WORKER: args: ()
22:13:01 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 216, 'last_n_outputs': 47, 'leak_rate': 0.8315415903852081, 'lr': 0.006367735437464132, 'optimizer': 'SGD', 'sparsity': 0.9264097530252333, 'steps_to_train': 25, 'weight_decay': 0.07796178321887419}, 'budget': 400.0, 'working_directory': '.'}
22:13:36 DISPATCHER: Starting worker discovery
22:13:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:13:36 DISPATCHER: Finished worker discovery
22:14:36 DISPATCHER: Starting worker discovery
22:14:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:14:36 DISPATCHER: Finished worker discovery
22:15:36 DISPATCHER: Starting worker discovery
22:15:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:15:36 DISPATCHER: Finished worker discovery
22:16:36 DISPATCHER: Starting worker discovery
22:16:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:16:36 DISPATCHER: Finished worker discovery
22:17:36 DISPATCHER: Starting worker discovery
22:17:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:17:36 DISPATCHER: Finished worker discovery
22:18:36 DISPATCHER: Starting worker discovery
22:18:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:18:36 DISPATCHER: Finished worker discovery
22:19:36 DISPATCHER: Starting worker discovery
22:19:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:19:36 DISPATCHER: Finished worker discovery
22:20:36 DISPATCHER: Starting worker discovery
22:20:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:20:36 DISPATCHER: Finished worker discovery
22:20:43 WORKER: done with job (2, 0, 2), trying to register it.
22:20:43 WORKER: registered result for job (2, 0, 2) with dispatcher
22:20:43 DISPATCHER: job (2, 0, 2) finished
22:20:43 DISPATCHER: register_result: lock acquired
22:20:43 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
22:20:43 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 216, 'last_n_outputs': 47, 'leak_rate': 0.8315415903852081, 'lr': 0.006367735437464132, 'optimizer': 'SGD', 'sparsity': 0.9264097530252333, 'steps_to_train': 25, 'weight_decay': 0.07796178321887419}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.35798500203756145, 'info': {'music_genre': 0.35798500203756145, 'config': "{'batch_size': 16, 'hidden_dim': 216, 'last_n_outputs': 47, 'leak_rate': 0.8315415903852081, 'lr': 0.006367735437464132, 'optimizer': 'SGD', 'sparsity': 0.9264097530252333, 'steps_to_train': 25, 'weight_decay': 0.07796178321887419}"}}
exception: None

22:20:43 job_callback for (2, 0, 2) started
22:20:43 DISPATCHER: Trying to submit another job.
22:20:43 job_callback for (2, 0, 2) got condition
22:20:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:20:43 Only 9 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
22:20:43 HBMASTER: Trying to run another job!
22:20:43 job_callback for (2, 0, 2) finished
22:20:43 start sampling a new configuration.
22:20:43 done sampling a new configuration.
22:20:43 HBMASTER: schedule new run for iteration 2
22:20:43 HBMASTER: trying submitting job (2, 0, 3) to dispatcher
22:20:43 HBMASTER: submitting job (2, 0, 3) to dispatcher
22:20:43 DISPATCHER: trying to submit job (2, 0, 3)
22:20:43 DISPATCHER: trying to notify the job_runner thread.
22:20:43 HBMASTER: job (2, 0, 3) submitted to dispatcher
22:20:43 DISPATCHER: Trying to submit another job.
22:20:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:20:43 DISPATCHER: starting job (2, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:20:43 DISPATCHER: job (2, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:20:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:20:43 WORKER: start processing job (2, 0, 3)
22:20:43 WORKER: args: ()
22:20:43 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 412, 'last_n_outputs': 15, 'leak_rate': 0.8865377320288609, 'lr': 0.009291128634823823, 'optimizer': 'Adam', 'sparsity': 0.9618720493085553, 'steps_to_train': 97, 'weight_decay': 0.06982256361368669}, 'budget': 400.0, 'working_directory': '.'}
22:21:36 DISPATCHER: Starting worker discovery
22:21:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:21:36 DISPATCHER: Finished worker discovery
22:22:36 DISPATCHER: Starting worker discovery
22:22:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:22:36 DISPATCHER: Finished worker discovery
22:23:36 DISPATCHER: Starting worker discovery
22:23:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:23:36 DISPATCHER: Finished worker discovery
22:24:36 DISPATCHER: Starting worker discovery
22:24:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:24:36 DISPATCHER: Finished worker discovery
22:25:36 DISPATCHER: Starting worker discovery
22:25:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:25:36 DISPATCHER: Finished worker discovery
22:26:36 DISPATCHER: Starting worker discovery
22:26:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:26:36 DISPATCHER: Finished worker discovery
22:27:36 DISPATCHER: Starting worker discovery
22:27:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:27:36 DISPATCHER: Finished worker discovery
22:28:26 WORKER: done with job (2, 0, 3), trying to register it.
22:28:26 WORKER: registered result for job (2, 0, 3) with dispatcher
22:28:26 DISPATCHER: job (2, 0, 3) finished
22:28:26 DISPATCHER: register_result: lock acquired
22:28:26 DISPATCHER: job (2, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
22:28:26 job_id: (2, 0, 3)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 412, 'last_n_outputs': 15, 'leak_rate': 0.8865377320288609, 'lr': 0.009291128634823823, 'optimizer': 'Adam', 'sparsity': 0.9618720493085553, 'steps_to_train': 97, 'weight_decay': 0.06982256361368669}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.15481717293820332, 'info': {'music_genre': 0.15481717293820332, 'config': "{'batch_size': 32, 'hidden_dim': 412, 'last_n_outputs': 15, 'leak_rate': 0.8865377320288609, 'lr': 0.009291128634823823, 'optimizer': 'Adam', 'sparsity': 0.9618720493085553, 'steps_to_train': 97, 'weight_decay': 0.06982256361368669}"}}
exception: None

22:28:26 job_callback for (2, 0, 3) started
22:28:26 DISPATCHER: Trying to submit another job.
22:28:26 job_callback for (2, 0, 3) got condition
22:28:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:28:26 HBMASTER: Trying to run another job!
22:28:26 job_callback for (2, 0, 3) finished
22:28:26 start sampling a new configuration.
22:28:26 best_vector: [1, 0.9662571039709174, 0.7470317625919021, 0.4368193910204694, 0.5123205409127249, 1, 0.8469994309928112, 0.1487942707400951, 0.054270967452928726], 0.009814587589691379, 0.13182697044258196, 0.0012938273480923772
22:28:26 done sampling a new configuration.
22:28:26 HBMASTER: schedule new run for iteration 2
22:28:26 HBMASTER: trying submitting job (2, 0, 4) to dispatcher
22:28:26 HBMASTER: submitting job (2, 0, 4) to dispatcher
22:28:26 DISPATCHER: trying to submit job (2, 0, 4)
22:28:26 DISPATCHER: trying to notify the job_runner thread.
22:28:26 HBMASTER: job (2, 0, 4) submitted to dispatcher
22:28:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:28:26 DISPATCHER: Trying to submit another job.
22:28:26 DISPATCHER: starting job (2, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:28:26 DISPATCHER: job (2, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:28:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:28:26 WORKER: start processing job (2, 0, 4)
22:28:26 WORKER: args: ()
22:28:26 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 973, 'last_n_outputs': 40, 'leak_rate': 0.8592048477551173, 'lr': 0.01058378677548589, 'optimizer': 'SGD', 'sparsity': 0.9532798634382746, 'steps_to_train': 23, 'weight_decay': 0.01176543954308634}, 'budget': 400.0, 'working_directory': '.'}
22:28:36 DISPATCHER: Starting worker discovery
22:28:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:28:36 DISPATCHER: Finished worker discovery
22:29:36 DISPATCHER: Starting worker discovery
22:29:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:29:36 DISPATCHER: Finished worker discovery
22:30:36 DISPATCHER: Starting worker discovery
22:30:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:30:36 DISPATCHER: Finished worker discovery
22:31:36 DISPATCHER: Starting worker discovery
22:31:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:31:36 DISPATCHER: Finished worker discovery
22:32:36 DISPATCHER: Starting worker discovery
22:32:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:32:36 DISPATCHER: Finished worker discovery
22:33:36 DISPATCHER: Starting worker discovery
22:33:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:33:36 DISPATCHER: Finished worker discovery
22:34:36 DISPATCHER: Starting worker discovery
22:34:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:34:36 DISPATCHER: Finished worker discovery
22:35:36 DISPATCHER: Starting worker discovery
22:35:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:35:36 DISPATCHER: Finished worker discovery
22:36:11 WORKER: done with job (2, 0, 4), trying to register it.
22:36:11 WORKER: registered result for job (2, 0, 4) with dispatcher
22:36:11 DISPATCHER: job (2, 0, 4) finished
22:36:11 DISPATCHER: register_result: lock acquired
22:36:11 DISPATCHER: job (2, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
22:36:11 job_id: (2, 0, 4)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 973, 'last_n_outputs': 40, 'leak_rate': 0.8592048477551173, 'lr': 0.01058378677548589, 'optimizer': 'SGD', 'sparsity': 0.9532798634382746, 'steps_to_train': 23, 'weight_decay': 0.01176543954308634}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.37139087935809717, 'info': {'music_genre': 0.37139087935809717, 'config': "{'batch_size': 32, 'hidden_dim': 973, 'last_n_outputs': 40, 'leak_rate': 0.8592048477551173, 'lr': 0.01058378677548589, 'optimizer': 'SGD', 'sparsity': 0.9532798634382746, 'steps_to_train': 23, 'weight_decay': 0.01176543954308634}"}}
exception: None

22:36:11 job_callback for (2, 0, 4) started
22:36:11 job_callback for (2, 0, 4) got condition
22:36:11 DISPATCHER: Trying to submit another job.
22:36:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:36:11 HBMASTER: Trying to run another job!
22:36:11 job_callback for (2, 0, 4) finished
22:36:11 start sampling a new configuration.
22:36:11 done sampling a new configuration.
22:36:11 HBMASTER: schedule new run for iteration 2
22:36:11 HBMASTER: trying submitting job (2, 0, 5) to dispatcher
22:36:11 HBMASTER: submitting job (2, 0, 5) to dispatcher
22:36:11 DISPATCHER: trying to submit job (2, 0, 5)
22:36:11 DISPATCHER: trying to notify the job_runner thread.
22:36:11 HBMASTER: job (2, 0, 5) submitted to dispatcher
22:36:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:36:11 DISPATCHER: Trying to submit another job.
22:36:11 DISPATCHER: starting job (2, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:36:11 DISPATCHER: job (2, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:36:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:36:11 WORKER: start processing job (2, 0, 5)
22:36:11 WORKER: args: ()
22:36:11 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 991, 'last_n_outputs': 41, 'leak_rate': 0.9404243503814831, 'lr': 0.01593417302027931, 'optimizer': 'SGD', 'sparsity': 0.7791880714997468, 'steps_to_train': 37, 'weight_decay': 0.14288856804412792}, 'budget': 400.0, 'working_directory': '.'}
22:36:36 DISPATCHER: Starting worker discovery
22:36:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:36:36 DISPATCHER: Finished worker discovery
22:37:36 DISPATCHER: Starting worker discovery
22:37:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:37:36 DISPATCHER: Finished worker discovery
22:38:36 DISPATCHER: Starting worker discovery
22:38:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:38:36 DISPATCHER: Finished worker discovery
22:39:36 DISPATCHER: Starting worker discovery
22:39:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:39:36 DISPATCHER: Finished worker discovery
22:40:36 DISPATCHER: Starting worker discovery
22:40:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:40:36 DISPATCHER: Finished worker discovery
22:41:36 DISPATCHER: Starting worker discovery
22:41:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:41:36 DISPATCHER: Finished worker discovery
22:42:36 DISPATCHER: Starting worker discovery
22:42:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:42:36 DISPATCHER: Finished worker discovery
22:43:36 DISPATCHER: Starting worker discovery
22:43:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:43:36 DISPATCHER: Finished worker discovery
22:43:53 WORKER: done with job (2, 0, 5), trying to register it.
22:43:53 WORKER: registered result for job (2, 0, 5) with dispatcher
22:43:53 DISPATCHER: job (2, 0, 5) finished
22:43:53 DISPATCHER: register_result: lock acquired
22:43:53 DISPATCHER: job (2, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
22:43:53 job_id: (2, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 991, 'last_n_outputs': 41, 'leak_rate': 0.9404243503814831, 'lr': 0.01593417302027931, 'optimizer': 'SGD', 'sparsity': 0.7791880714997468, 'steps_to_train': 37, 'weight_decay': 0.14288856804412792}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.31118568729115015, 'info': {'music_genre': 0.31118568729115015, 'config': "{'batch_size': 64, 'hidden_dim': 991, 'last_n_outputs': 41, 'leak_rate': 0.9404243503814831, 'lr': 0.01593417302027931, 'optimizer': 'SGD', 'sparsity': 0.7791880714997468, 'steps_to_train': 37, 'weight_decay': 0.14288856804412792}"}}
exception: None

22:43:53 job_callback for (2, 0, 5) started
22:43:53 DISPATCHER: Trying to submit another job.
22:43:53 job_callback for (2, 0, 5) got condition
22:43:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:43:53 HBMASTER: Trying to run another job!
22:43:53 job_callback for (2, 0, 5) finished
22:43:53 ITERATION: Advancing config (2, 0, 2) to next budget 1200.000000
22:43:53 ITERATION: Advancing config (2, 0, 4) to next budget 1200.000000
22:43:53 HBMASTER: schedule new run for iteration 2
22:43:53 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
22:43:53 HBMASTER: submitting job (2, 0, 2) to dispatcher
22:43:53 DISPATCHER: trying to submit job (2, 0, 2)
22:43:53 DISPATCHER: trying to notify the job_runner thread.
22:43:53 HBMASTER: job (2, 0, 2) submitted to dispatcher
22:43:53 DISPATCHER: Trying to submit another job.
22:43:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:43:53 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:43:53 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:43:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:43:53 WORKER: start processing job (2, 0, 2)
22:43:53 WORKER: args: ()
22:43:53 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 216, 'last_n_outputs': 47, 'leak_rate': 0.8315415903852081, 'lr': 0.006367735437464132, 'optimizer': 'SGD', 'sparsity': 0.9264097530252333, 'steps_to_train': 25, 'weight_decay': 0.07796178321887419}, 'budget': 1200.0, 'working_directory': '.'}
22:44:36 DISPATCHER: Starting worker discovery
22:44:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:44:36 DISPATCHER: Finished worker discovery
22:45:36 DISPATCHER: Starting worker discovery
22:45:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:45:36 DISPATCHER: Finished worker discovery
22:46:36 DISPATCHER: Starting worker discovery
22:46:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:46:36 DISPATCHER: Finished worker discovery
22:47:36 DISPATCHER: Starting worker discovery
22:47:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:47:36 DISPATCHER: Finished worker discovery
22:48:36 DISPATCHER: Starting worker discovery
22:48:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:48:36 DISPATCHER: Finished worker discovery
22:49:36 DISPATCHER: Starting worker discovery
22:49:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:49:36 DISPATCHER: Finished worker discovery
22:50:36 DISPATCHER: Starting worker discovery
22:50:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:50:36 DISPATCHER: Finished worker discovery
22:51:36 DISPATCHER: Starting worker discovery
22:51:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:51:36 DISPATCHER: Finished worker discovery
22:52:36 DISPATCHER: Starting worker discovery
22:52:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:52:36 DISPATCHER: Finished worker discovery
22:53:36 DISPATCHER: Starting worker discovery
22:53:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:53:36 DISPATCHER: Finished worker discovery
22:54:36 DISPATCHER: Starting worker discovery
22:54:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:54:36 DISPATCHER: Finished worker discovery
22:55:36 DISPATCHER: Starting worker discovery
22:55:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:55:36 DISPATCHER: Finished worker discovery
22:56:36 DISPATCHER: Starting worker discovery
22:56:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:56:36 DISPATCHER: Finished worker discovery
22:57:36 DISPATCHER: Starting worker discovery
22:57:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:57:36 DISPATCHER: Finished worker discovery
22:58:36 DISPATCHER: Starting worker discovery
22:58:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:58:36 DISPATCHER: Finished worker discovery
22:59:36 DISPATCHER: Starting worker discovery
22:59:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:59:36 DISPATCHER: Finished worker discovery
23:00:36 DISPATCHER: Starting worker discovery
23:00:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:00:36 DISPATCHER: Finished worker discovery
23:01:36 DISPATCHER: Starting worker discovery
23:01:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:01:36 DISPATCHER: Finished worker discovery
23:02:36 DISPATCHER: Starting worker discovery
23:02:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:02:36 DISPATCHER: Finished worker discovery
23:03:36 DISPATCHER: Starting worker discovery
23:03:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:03:36 DISPATCHER: Finished worker discovery
23:04:36 DISPATCHER: Starting worker discovery
23:04:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:04:36 DISPATCHER: Finished worker discovery
23:04:55 WORKER: done with job (2, 0, 2), trying to register it.
23:04:55 WORKER: registered result for job (2, 0, 2) with dispatcher
23:04:55 DISPATCHER: job (2, 0, 2) finished
23:04:55 DISPATCHER: register_result: lock acquired
23:04:55 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:04:55 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 216, 'last_n_outputs': 47, 'leak_rate': 0.8315415903852081, 'lr': 0.006367735437464132, 'optimizer': 'SGD', 'sparsity': 0.9264097530252333, 'steps_to_train': 25, 'weight_decay': 0.07796178321887419}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.3267675890572107, 'info': {'music_genre': 0.3267675890572107, 'config': "{'batch_size': 16, 'hidden_dim': 216, 'last_n_outputs': 47, 'leak_rate': 0.8315415903852081, 'lr': 0.006367735437464132, 'optimizer': 'SGD', 'sparsity': 0.9264097530252333, 'steps_to_train': 25, 'weight_decay': 0.07796178321887419}"}}
exception: None

23:04:55 job_callback for (2, 0, 2) started
23:04:55 job_callback for (2, 0, 2) got condition
23:04:55 DISPATCHER: Trying to submit another job.
23:04:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:04:55 Only 3 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
23:04:55 HBMASTER: Trying to run another job!
23:04:55 job_callback for (2, 0, 2) finished
23:04:55 HBMASTER: schedule new run for iteration 2
23:04:55 HBMASTER: trying submitting job (2, 0, 4) to dispatcher
23:04:55 HBMASTER: submitting job (2, 0, 4) to dispatcher
23:04:55 DISPATCHER: trying to submit job (2, 0, 4)
23:04:55 DISPATCHER: trying to notify the job_runner thread.
23:04:55 HBMASTER: job (2, 0, 4) submitted to dispatcher
23:04:55 DISPATCHER: Trying to submit another job.
23:04:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:04:55 DISPATCHER: starting job (2, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:04:55 DISPATCHER: job (2, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:04:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:04:55 WORKER: start processing job (2, 0, 4)
23:04:55 WORKER: args: ()
23:04:55 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 973, 'last_n_outputs': 40, 'leak_rate': 0.8592048477551173, 'lr': 0.01058378677548589, 'optimizer': 'SGD', 'sparsity': 0.9532798634382746, 'steps_to_train': 23, 'weight_decay': 0.01176543954308634}, 'budget': 1200.0, 'working_directory': '.'}
23:05:36 DISPATCHER: Starting worker discovery
23:05:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:05:36 DISPATCHER: Finished worker discovery
23:06:36 DISPATCHER: Starting worker discovery
23:06:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:06:36 DISPATCHER: Finished worker discovery
23:07:36 DISPATCHER: Starting worker discovery
23:07:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:07:36 DISPATCHER: Finished worker discovery
23:08:36 DISPATCHER: Starting worker discovery
23:08:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:08:36 DISPATCHER: Finished worker discovery
23:09:36 DISPATCHER: Starting worker discovery
23:09:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:09:36 DISPATCHER: Finished worker discovery
23:10:36 DISPATCHER: Starting worker discovery
23:10:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:10:36 DISPATCHER: Finished worker discovery
23:11:36 DISPATCHER: Starting worker discovery
23:11:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:11:36 DISPATCHER: Finished worker discovery
23:12:36 DISPATCHER: Starting worker discovery
23:12:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:12:36 DISPATCHER: Finished worker discovery
23:13:36 DISPATCHER: Starting worker discovery
23:13:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:13:36 DISPATCHER: Finished worker discovery
23:14:36 DISPATCHER: Starting worker discovery
23:14:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:14:36 DISPATCHER: Finished worker discovery
23:15:36 DISPATCHER: Starting worker discovery
23:15:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:15:36 DISPATCHER: Finished worker discovery
23:16:36 DISPATCHER: Starting worker discovery
23:16:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:16:36 DISPATCHER: Finished worker discovery
23:17:36 DISPATCHER: Starting worker discovery
23:17:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:17:36 DISPATCHER: Finished worker discovery
23:18:36 DISPATCHER: Starting worker discovery
23:18:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:18:36 DISPATCHER: Finished worker discovery
23:19:36 DISPATCHER: Starting worker discovery
23:19:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:19:36 DISPATCHER: Finished worker discovery
23:20:36 DISPATCHER: Starting worker discovery
23:20:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:20:36 DISPATCHER: Finished worker discovery
23:21:36 DISPATCHER: Starting worker discovery
23:21:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:21:36 DISPATCHER: Finished worker discovery
23:22:36 DISPATCHER: Starting worker discovery
23:22:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:22:36 DISPATCHER: Finished worker discovery
23:23:36 DISPATCHER: Starting worker discovery
23:23:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:23:36 DISPATCHER: Finished worker discovery
23:24:36 DISPATCHER: Starting worker discovery
23:24:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:24:36 DISPATCHER: Finished worker discovery
23:25:36 DISPATCHER: Starting worker discovery
23:25:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:25:36 DISPATCHER: Finished worker discovery
23:25:57 WORKER: done with job (2, 0, 4), trying to register it.
23:25:57 WORKER: registered result for job (2, 0, 4) with dispatcher
23:25:57 DISPATCHER: job (2, 0, 4) finished
23:25:57 DISPATCHER: register_result: lock acquired
23:25:57 DISPATCHER: job (2, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:25:57 job_id: (2, 0, 4)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 973, 'last_n_outputs': 40, 'leak_rate': 0.8592048477551173, 'lr': 0.01058378677548589, 'optimizer': 'SGD', 'sparsity': 0.9532798634382746, 'steps_to_train': 23, 'weight_decay': 0.01176543954308634}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.36122621484410244, 'info': {'music_genre': 0.36122621484410244, 'config': "{'batch_size': 32, 'hidden_dim': 973, 'last_n_outputs': 40, 'leak_rate': 0.8592048477551173, 'lr': 0.01058378677548589, 'optimizer': 'SGD', 'sparsity': 0.9532798634382746, 'steps_to_train': 23, 'weight_decay': 0.01176543954308634}"}}
exception: None

23:25:57 job_callback for (2, 0, 4) started
23:25:57 job_callback for (2, 0, 4) got condition
23:25:57 DISPATCHER: Trying to submit another job.
23:25:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:25:57 Only 4 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
23:25:57 HBMASTER: Trying to run another job!
23:25:57 job_callback for (2, 0, 4) finished
23:25:57 start sampling a new configuration.
23:25:57 done sampling a new configuration.
23:25:57 HBMASTER: schedule new run for iteration 3
23:25:57 HBMASTER: trying submitting job (3, 0, 0) to dispatcher
23:25:57 HBMASTER: submitting job (3, 0, 0) to dispatcher
23:25:57 DISPATCHER: trying to submit job (3, 0, 0)
23:25:57 DISPATCHER: trying to notify the job_runner thread.
23:25:57 HBMASTER: job (3, 0, 0) submitted to dispatcher
23:25:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:25:57 DISPATCHER: Trying to submit another job.
23:25:57 DISPATCHER: starting job (3, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:25:57 DISPATCHER: job (3, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:25:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:25:57 WORKER: start processing job (3, 0, 0)
23:25:57 WORKER: args: ()
23:25:57 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 209, 'last_n_outputs': 39, 'leak_rate': 0.7763907625178652, 'lr': 0.006953990184757231, 'optimizer': 'SGD', 'sparsity': 0.8315292780676407, 'steps_to_train': 56, 'weight_decay': 0.013228726425115772}, 'budget': 1200.0, 'working_directory': '.'}
23:26:36 DISPATCHER: Starting worker discovery
23:26:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:26:36 DISPATCHER: Finished worker discovery
23:27:36 DISPATCHER: Starting worker discovery
23:27:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:27:36 DISPATCHER: Finished worker discovery
23:28:36 DISPATCHER: Starting worker discovery
23:28:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:28:36 DISPATCHER: Finished worker discovery
23:29:36 DISPATCHER: Starting worker discovery
23:29:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:29:36 DISPATCHER: Finished worker discovery
23:30:36 DISPATCHER: Starting worker discovery
23:30:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:30:36 DISPATCHER: Finished worker discovery
23:31:36 DISPATCHER: Starting worker discovery
23:31:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:31:36 DISPATCHER: Finished worker discovery
23:32:36 DISPATCHER: Starting worker discovery
23:32:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:32:36 DISPATCHER: Finished worker discovery
23:33:36 DISPATCHER: Starting worker discovery
23:33:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:33:36 DISPATCHER: Finished worker discovery
23:34:36 DISPATCHER: Starting worker discovery
23:34:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:34:36 DISPATCHER: Finished worker discovery
23:35:36 DISPATCHER: Starting worker discovery
23:35:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:35:36 DISPATCHER: Finished worker discovery
23:36:36 DISPATCHER: Starting worker discovery
23:36:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:36:36 DISPATCHER: Finished worker discovery
23:37:36 DISPATCHER: Starting worker discovery
23:37:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:37:37 DISPATCHER: Finished worker discovery
23:38:37 DISPATCHER: Starting worker discovery
23:38:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:38:37 DISPATCHER: Finished worker discovery
23:39:37 DISPATCHER: Starting worker discovery
23:39:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:39:37 DISPATCHER: Finished worker discovery
23:40:37 DISPATCHER: Starting worker discovery
23:40:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:40:37 DISPATCHER: Finished worker discovery
23:41:37 DISPATCHER: Starting worker discovery
23:41:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:41:37 DISPATCHER: Finished worker discovery
23:42:37 DISPATCHER: Starting worker discovery
23:42:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:42:37 DISPATCHER: Finished worker discovery
23:43:37 DISPATCHER: Starting worker discovery
23:43:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:43:37 DISPATCHER: Finished worker discovery
23:44:37 DISPATCHER: Starting worker discovery
23:44:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:44:37 DISPATCHER: Finished worker discovery
23:45:37 DISPATCHER: Starting worker discovery
23:45:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:45:37 DISPATCHER: Finished worker discovery
23:46:37 DISPATCHER: Starting worker discovery
23:46:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:46:37 DISPATCHER: Finished worker discovery
23:46:57 WORKER: done with job (3, 0, 0), trying to register it.
23:46:57 WORKER: registered result for job (3, 0, 0) with dispatcher
23:46:57 DISPATCHER: job (3, 0, 0) finished
23:46:57 DISPATCHER: register_result: lock acquired
23:46:57 DISPATCHER: job (3, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:46:57 job_id: (3, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 209, 'last_n_outputs': 39, 'leak_rate': 0.7763907625178652, 'lr': 0.006953990184757231, 'optimizer': 'SGD', 'sparsity': 0.8315292780676407, 'steps_to_train': 56, 'weight_decay': 0.013228726425115772}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.30759353970777, 'info': {'music_genre': 0.30759353970777, 'config': "{'batch_size': 16, 'hidden_dim': 209, 'last_n_outputs': 39, 'leak_rate': 0.7763907625178652, 'lr': 0.006953990184757231, 'optimizer': 'SGD', 'sparsity': 0.8315292780676407, 'steps_to_train': 56, 'weight_decay': 0.013228726425115772}"}}
exception: None

23:46:57 job_callback for (3, 0, 0) started
23:46:57 job_callback for (3, 0, 0) got condition
23:46:57 DISPATCHER: Trying to submit another job.
23:46:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:46:57 Only 5 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
23:46:57 HBMASTER: Trying to run another job!
23:46:57 job_callback for (3, 0, 0) finished
23:46:57 start sampling a new configuration.
23:46:57 best_vector: [0, 0.2455151639126048, 0.5101222225612494, 0.0918448218777177, 0.0025088739246273833, 1, 0.6044450840506153, 0.06667897488163957, 0.1239234276757687], 0.015685773584404396, 0.1058423554187731, 0.0016602192227389324
23:46:57 done sampling a new configuration.
23:46:57 HBMASTER: schedule new run for iteration 3
23:46:57 HBMASTER: trying submitting job (3, 0, 1) to dispatcher
23:46:57 HBMASTER: submitting job (3, 0, 1) to dispatcher
23:46:57 DISPATCHER: trying to submit job (3, 0, 1)
23:46:57 DISPATCHER: trying to notify the job_runner thread.
23:46:57 HBMASTER: job (3, 0, 1) submitted to dispatcher
23:46:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:46:57 DISPATCHER: Trying to submit another job.
23:46:57 DISPATCHER: starting job (3, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:46:57 DISPATCHER: job (3, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:46:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:46:57 WORKER: start processing job (3, 0, 1)
23:46:57 WORKER: args: ()
23:46:57 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 396, 'last_n_outputs': 30, 'leak_rate': 0.7729612054694295, 'lr': 0.0010116207942429212, 'optimizer': 'SGD', 'sparsity': 0.8950668201721477, 'steps_to_train': 16, 'weight_decay': 0.014495329654230091}, 'budget': 1200.0, 'working_directory': '.'}
23:47:37 DISPATCHER: Starting worker discovery
23:47:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:47:37 DISPATCHER: Finished worker discovery
23:48:37 DISPATCHER: Starting worker discovery
23:48:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:48:37 DISPATCHER: Finished worker discovery
23:49:37 DISPATCHER: Starting worker discovery
23:49:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:49:37 DISPATCHER: Finished worker discovery
23:50:37 DISPATCHER: Starting worker discovery
23:50:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:50:37 DISPATCHER: Finished worker discovery
23:51:37 DISPATCHER: Starting worker discovery
23:51:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:51:37 DISPATCHER: Finished worker discovery
23:52:37 DISPATCHER: Starting worker discovery
23:52:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:52:37 DISPATCHER: Finished worker discovery
23:53:37 DISPATCHER: Starting worker discovery
23:53:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:53:37 DISPATCHER: Finished worker discovery
23:54:37 DISPATCHER: Starting worker discovery
23:54:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:54:37 DISPATCHER: Finished worker discovery
23:55:37 DISPATCHER: Starting worker discovery
23:55:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:55:37 DISPATCHER: Finished worker discovery
23:56:37 DISPATCHER: Starting worker discovery
23:56:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:56:37 DISPATCHER: Finished worker discovery
23:57:37 DISPATCHER: Starting worker discovery
23:57:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:57:37 DISPATCHER: Finished worker discovery
23:58:37 DISPATCHER: Starting worker discovery
23:58:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:58:37 DISPATCHER: Finished worker discovery
23:59:37 DISPATCHER: Starting worker discovery
23:59:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:59:37 DISPATCHER: Finished worker discovery
00:00:37 DISPATCHER: Starting worker discovery
00:00:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:00:37 DISPATCHER: Finished worker discovery
00:01:37 DISPATCHER: Starting worker discovery
00:01:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:01:37 DISPATCHER: Finished worker discovery
00:02:37 DISPATCHER: Starting worker discovery
00:02:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:02:37 DISPATCHER: Finished worker discovery
00:03:37 DISPATCHER: Starting worker discovery
00:03:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:03:37 DISPATCHER: Finished worker discovery
00:04:37 DISPATCHER: Starting worker discovery
00:04:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:04:37 DISPATCHER: Finished worker discovery
00:05:37 DISPATCHER: Starting worker discovery
00:05:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:05:37 DISPATCHER: Finished worker discovery
00:06:37 DISPATCHER: Starting worker discovery
00:06:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:06:37 DISPATCHER: Finished worker discovery
00:07:37 DISPATCHER: Starting worker discovery
00:07:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:07:37 DISPATCHER: Finished worker discovery
00:07:58 WORKER: done with job (3, 0, 1), trying to register it.
00:07:58 WORKER: registered result for job (3, 0, 1) with dispatcher
00:07:58 DISPATCHER: job (3, 0, 1) finished
00:07:58 DISPATCHER: register_result: lock acquired
00:07:58 DISPATCHER: job (3, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
00:07:58 job_id: (3, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 396, 'last_n_outputs': 30, 'leak_rate': 0.7729612054694295, 'lr': 0.0010116207942429212, 'optimizer': 'SGD', 'sparsity': 0.8950668201721477, 'steps_to_train': 16, 'weight_decay': 0.014495329654230091}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.3337839625203952, 'info': {'music_genre': 0.3337839625203952, 'config': "{'batch_size': 16, 'hidden_dim': 396, 'last_n_outputs': 30, 'leak_rate': 0.7729612054694295, 'lr': 0.0010116207942429212, 'optimizer': 'SGD', 'sparsity': 0.8950668201721477, 'steps_to_train': 16, 'weight_decay': 0.014495329654230091}"}}
exception: None

00:07:58 job_callback for (3, 0, 1) started
00:07:58 job_callback for (3, 0, 1) got condition
00:07:58 DISPATCHER: Trying to submit another job.
00:07:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:07:58 Only 6 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
00:07:58 HBMASTER: Trying to run another job!
00:07:58 job_callback for (3, 0, 1) finished
00:07:58 start sampling a new configuration.
00:07:58 done sampling a new configuration.
00:07:58 HBMASTER: schedule new run for iteration 3
00:07:58 HBMASTER: trying submitting job (3, 0, 2) to dispatcher
00:07:58 HBMASTER: submitting job (3, 0, 2) to dispatcher
00:07:58 DISPATCHER: trying to submit job (3, 0, 2)
00:07:58 DISPATCHER: trying to notify the job_runner thread.
00:07:58 HBMASTER: job (3, 0, 2) submitted to dispatcher
00:07:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:07:58 DISPATCHER: Trying to submit another job.
00:07:58 DISPATCHER: starting job (3, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:07:58 DISPATCHER: job (3, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:07:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:07:58 WORKER: start processing job (3, 0, 2)
00:07:58 WORKER: args: ()
00:07:58 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 574, 'last_n_outputs': 47, 'leak_rate': 0.9855799179603675, 'lr': 0.009497868457128064, 'optimizer': 'SGD', 'sparsity': 0.7931167076859452, 'steps_to_train': 98, 'weight_decay': 0.1797317617771726}, 'budget': 1200.0, 'working_directory': '.'}
00:08:37 DISPATCHER: Starting worker discovery
00:08:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:08:37 DISPATCHER: Finished worker discovery
00:09:37 DISPATCHER: Starting worker discovery
00:09:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:09:37 DISPATCHER: Finished worker discovery
00:10:37 DISPATCHER: Starting worker discovery
00:10:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:10:37 DISPATCHER: Finished worker discovery
00:11:37 DISPATCHER: Starting worker discovery
00:11:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:11:37 DISPATCHER: Finished worker discovery
00:12:37 DISPATCHER: Starting worker discovery
00:12:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:12:37 DISPATCHER: Finished worker discovery
00:13:37 DISPATCHER: Starting worker discovery
00:13:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:13:37 DISPATCHER: Finished worker discovery
00:14:37 DISPATCHER: Starting worker discovery
00:14:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:14:37 DISPATCHER: Finished worker discovery
00:15:37 DISPATCHER: Starting worker discovery
00:15:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:15:37 DISPATCHER: Finished worker discovery
00:16:37 DISPATCHER: Starting worker discovery
00:16:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:16:37 DISPATCHER: Finished worker discovery
00:17:37 DISPATCHER: Starting worker discovery
00:17:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:17:37 DISPATCHER: Finished worker discovery
00:18:37 DISPATCHER: Starting worker discovery
00:18:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:18:37 DISPATCHER: Finished worker discovery
00:19:37 DISPATCHER: Starting worker discovery
00:19:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:19:37 DISPATCHER: Finished worker discovery
00:20:37 DISPATCHER: Starting worker discovery
00:20:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:20:37 DISPATCHER: Finished worker discovery
00:21:37 DISPATCHER: Starting worker discovery
00:21:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:21:37 DISPATCHER: Finished worker discovery
00:22:37 DISPATCHER: Starting worker discovery
00:22:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:22:37 DISPATCHER: Finished worker discovery
00:23:37 DISPATCHER: Starting worker discovery
00:23:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:23:37 DISPATCHER: Finished worker discovery
00:24:37 DISPATCHER: Starting worker discovery
00:24:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:24:37 DISPATCHER: Finished worker discovery
00:25:37 DISPATCHER: Starting worker discovery
00:25:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:25:37 DISPATCHER: Finished worker discovery
00:26:37 DISPATCHER: Starting worker discovery
00:26:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:26:37 DISPATCHER: Finished worker discovery
00:27:37 DISPATCHER: Starting worker discovery
00:27:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:27:37 DISPATCHER: Finished worker discovery
00:28:37 DISPATCHER: Starting worker discovery
00:28:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:28:37 DISPATCHER: Finished worker discovery
00:29:16 WORKER: done with job (3, 0, 2), trying to register it.
00:29:16 WORKER: registered result for job (3, 0, 2) with dispatcher
00:29:16 DISPATCHER: job (3, 0, 2) finished
00:29:16 DISPATCHER: register_result: lock acquired
00:29:16 DISPATCHER: job (3, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
00:29:16 job_id: (3, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 574, 'last_n_outputs': 47, 'leak_rate': 0.9855799179603675, 'lr': 0.009497868457128064, 'optimizer': 'SGD', 'sparsity': 0.7931167076859452, 'steps_to_train': 98, 'weight_decay': 0.1797317617771726}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.3435994962254544, 'info': {'music_genre': 0.3435994962254544, 'config': "{'batch_size': 128, 'hidden_dim': 574, 'last_n_outputs': 47, 'leak_rate': 0.9855799179603675, 'lr': 0.009497868457128064, 'optimizer': 'SGD', 'sparsity': 0.7931167076859452, 'steps_to_train': 98, 'weight_decay': 0.1797317617771726}"}}
exception: None

00:29:16 job_callback for (3, 0, 2) started
00:29:16 job_callback for (3, 0, 2) got condition
00:29:16 DISPATCHER: Trying to submit another job.
00:29:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:29:16 Only 7 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
00:29:16 HBMASTER: Trying to run another job!
00:29:16 job_callback for (3, 0, 2) finished
00:29:16 start sampling a new configuration.
00:29:16 best_vector: [1, 0.7502976520013633, 0.2504984654475505, 0.490515889820173, 0.6655889916047163, 1, 0.9936039715842607, 0.30517025638150064, 0.2375374206683135], 0.07531235757813973, 0.1098187935034239, 0.00827071224512975
00:29:16 done sampling a new configuration.
00:29:16 HBMASTER: schedule new run for iteration 3
00:29:16 HBMASTER: trying submitting job (3, 0, 3) to dispatcher
00:29:16 HBMASTER: submitting job (3, 0, 3) to dispatcher
00:29:16 DISPATCHER: trying to submit job (3, 0, 3)
00:29:16 DISPATCHER: trying to notify the job_runner thread.
00:29:16 HBMASTER: job (3, 0, 3) submitted to dispatcher
00:29:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:29:16 DISPATCHER: Trying to submit another job.
00:29:16 DISPATCHER: starting job (3, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:29:16 DISPATCHER: job (3, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:29:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:29:16 WORKER: start processing job (3, 0, 3)
00:29:16 WORKER: args: ()
00:29:16 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 800, 'last_n_outputs': 20, 'leak_rate': 0.8726289724550432, 'lr': 0.021437689837058002, 'optimizer': 'SGD', 'sparsity': 0.9884649531802225, 'steps_to_train': 37, 'weight_decay': 0.02037245228877414}, 'budget': 1200.0, 'working_directory': '.'}
00:29:37 DISPATCHER: Starting worker discovery
00:29:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:29:37 DISPATCHER: Finished worker discovery
00:30:37 DISPATCHER: Starting worker discovery
00:30:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:30:37 DISPATCHER: Finished worker discovery
00:31:37 DISPATCHER: Starting worker discovery
00:31:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:31:37 DISPATCHER: Finished worker discovery
00:32:37 DISPATCHER: Starting worker discovery
00:32:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:32:37 DISPATCHER: Finished worker discovery
00:33:37 DISPATCHER: Starting worker discovery
00:33:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:33:37 DISPATCHER: Finished worker discovery
00:34:37 DISPATCHER: Starting worker discovery
00:34:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:34:37 DISPATCHER: Finished worker discovery
00:35:37 DISPATCHER: Starting worker discovery
00:35:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:35:37 DISPATCHER: Finished worker discovery
00:36:37 DISPATCHER: Starting worker discovery
00:36:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:36:37 DISPATCHER: Finished worker discovery
00:37:37 DISPATCHER: Starting worker discovery
00:37:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:37:37 DISPATCHER: Finished worker discovery
00:38:37 DISPATCHER: Starting worker discovery
00:38:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:38:37 DISPATCHER: Finished worker discovery
00:39:37 DISPATCHER: Starting worker discovery
00:39:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:39:37 DISPATCHER: Finished worker discovery
00:40:37 DISPATCHER: Starting worker discovery
00:40:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:40:37 DISPATCHER: Finished worker discovery
00:41:37 DISPATCHER: Starting worker discovery
00:41:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:41:37 DISPATCHER: Finished worker discovery
00:42:37 DISPATCHER: Starting worker discovery
00:42:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:42:37 DISPATCHER: Finished worker discovery
00:43:37 DISPATCHER: Starting worker discovery
00:43:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:43:37 DISPATCHER: Finished worker discovery
00:44:37 DISPATCHER: Starting worker discovery
00:44:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:44:37 DISPATCHER: Finished worker discovery
00:45:37 DISPATCHER: Starting worker discovery
00:45:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:45:37 DISPATCHER: Finished worker discovery
00:46:37 DISPATCHER: Starting worker discovery
00:46:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:46:37 DISPATCHER: Finished worker discovery
00:47:37 DISPATCHER: Starting worker discovery
00:47:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:47:37 DISPATCHER: Finished worker discovery
00:48:37 DISPATCHER: Starting worker discovery
00:48:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:48:37 DISPATCHER: Finished worker discovery
00:49:37 DISPATCHER: Starting worker discovery
00:49:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:49:37 DISPATCHER: Finished worker discovery
00:50:21 WORKER: done with job (3, 0, 3), trying to register it.
00:50:21 WORKER: registered result for job (3, 0, 3) with dispatcher
00:50:21 DISPATCHER: job (3, 0, 3) finished
00:50:21 DISPATCHER: register_result: lock acquired
00:50:21 DISPATCHER: job (3, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
00:50:21 job_id: (3, 0, 3)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 800, 'last_n_outputs': 20, 'leak_rate': 0.8726289724550432, 'lr': 0.021437689837058002, 'optimizer': 'SGD', 'sparsity': 0.9884649531802225, 'steps_to_train': 37, 'weight_decay': 0.02037245228877414}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.33479226907858095, 'info': {'music_genre': 0.33479226907858095, 'config': "{'batch_size': 32, 'hidden_dim': 800, 'last_n_outputs': 20, 'leak_rate': 0.8726289724550432, 'lr': 0.021437689837058002, 'optimizer': 'SGD', 'sparsity': 0.9884649531802225, 'steps_to_train': 37, 'weight_decay': 0.02037245228877414}"}}
exception: None

00:50:21 job_callback for (3, 0, 3) started
00:50:21 DISPATCHER: Trying to submit another job.
00:50:21 job_callback for (3, 0, 3) got condition
00:50:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:50:21 Only 8 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
00:50:21 HBMASTER: Trying to run another job!
00:50:21 job_callback for (3, 0, 3) finished
00:50:21 start sampling a new configuration.
00:50:21 best_vector: [3, 0.5977237034910211, 0.780682415324293, 0.11992968532373434, 0.8904576422044701, 1, 0.8932935385079527, 0.10074252693485519, 0.14508931988499776], 0.0354418949642648, 0.058939875290117974, 0.0020889408692392275
00:50:21 done sampling a new configuration.
00:50:21 HBMASTER: schedule new run for iteration 4
00:50:21 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
00:50:21 HBMASTER: submitting job (4, 0, 0) to dispatcher
00:50:21 DISPATCHER: trying to submit job (4, 0, 0)
00:50:21 DISPATCHER: trying to notify the job_runner thread.
00:50:21 HBMASTER: job (4, 0, 0) submitted to dispatcher
00:50:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:50:21 DISPATCHER: Trying to submit another job.
00:50:21 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:50:21 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:50:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:50:21 WORKER: start processing job (4, 0, 0)
00:50:21 WORKER: args: ()
00:50:21 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 678, 'last_n_outputs': 42, 'leak_rate': 0.7799824213309335, 'lr': 0.060383083171274984, 'optimizer': 'SGD', 'sparsity': 0.9643904492419086, 'steps_to_train': 19, 'weight_decay': 0.015444204985240967}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:50:37 DISPATCHER: Starting worker discovery
00:50:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:50:37 DISPATCHER: Finished worker discovery
00:51:37 DISPATCHER: Starting worker discovery
00:51:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:51:37 DISPATCHER: Finished worker discovery
00:52:03 WORKER: done with job (4, 0, 0), trying to register it.
00:52:03 WORKER: registered result for job (4, 0, 0) with dispatcher
00:52:03 DISPATCHER: job (4, 0, 0) finished
00:52:03 DISPATCHER: register_result: lock acquired
00:52:03 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
00:52:03 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 678, 'last_n_outputs': 42, 'leak_rate': 0.7799824213309335, 'lr': 0.060383083171274984, 'optimizer': 'SGD', 'sparsity': 0.9643904492419086, 'steps_to_train': 19, 'weight_decay': 0.015444204985240967}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2733243954453595, 'info': {'music_genre': 0.2733243954453595, 'config': "{'batch_size': 128, 'hidden_dim': 678, 'last_n_outputs': 42, 'leak_rate': 0.7799824213309335, 'lr': 0.060383083171274984, 'optimizer': 'SGD', 'sparsity': 0.9643904492419086, 'steps_to_train': 19, 'weight_decay': 0.015444204985240967}"}}
exception: None

00:52:03 job_callback for (4, 0, 0) started
00:52:03 job_callback for (4, 0, 0) got condition
00:52:03 DISPATCHER: Trying to submit another job.
00:52:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:52:03 done building a new model for budget 44.444444 based on 10/23 split
Best loss for this budget:-0.378549





00:52:03 HBMASTER: Trying to run another job!
00:52:03 job_callback for (4, 0, 0) finished
00:52:03 start sampling a new configuration.
00:52:03 best_vector: [0, 0.5163275790654697, 0.03730414202658553, 0.14709146321176414, 0.02906873637325108, 1, 0.9515408128650182, 0.8820909669294748, 0.0018428705561457925], 0.022690823301811918, 0.011696518857565463, 0.0002654036426433289
00:52:03 done sampling a new configuration.
00:52:03 HBMASTER: schedule new run for iteration 4
00:52:03 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
00:52:03 HBMASTER: submitting job (4, 0, 1) to dispatcher
00:52:03 DISPATCHER: trying to submit job (4, 0, 1)
00:52:03 DISPATCHER: trying to notify the job_runner thread.
00:52:03 HBMASTER: job (4, 0, 1) submitted to dispatcher
00:52:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:52:03 DISPATCHER: Trying to submit another job.
00:52:03 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:52:03 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:52:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:52:03 WORKER: start processing job (4, 0, 1)
00:52:03 WORKER: args: ()
00:52:03 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 613, 'last_n_outputs': 11, 'leak_rate': 0.786772865802941, 'lr': 0.0011432401618438018, 'optimizer': 'SGD', 'sparsity': 0.9783697950876044, 'steps_to_train': 90, 'weight_decay': 0.01005536014206546}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:52:37 DISPATCHER: Starting worker discovery
00:52:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:52:37 DISPATCHER: Finished worker discovery
00:53:37 DISPATCHER: Starting worker discovery
00:53:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:53:37 DISPATCHER: Finished worker discovery
00:54:00 WORKER: done with job (4, 0, 1), trying to register it.
00:54:00 WORKER: registered result for job (4, 0, 1) with dispatcher
00:54:00 DISPATCHER: job (4, 0, 1) finished
00:54:00 DISPATCHER: register_result: lock acquired
00:54:00 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
00:54:00 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 613, 'last_n_outputs': 11, 'leak_rate': 0.786772865802941, 'lr': 0.0011432401618438018, 'optimizer': 'SGD', 'sparsity': 0.9783697950876044, 'steps_to_train': 90, 'weight_decay': 0.01005536014206546}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.22499097402112253, 'info': {'music_genre': 0.22499097402112253, 'config': "{'batch_size': 16, 'hidden_dim': 613, 'last_n_outputs': 11, 'leak_rate': 0.786772865802941, 'lr': 0.0011432401618438018, 'optimizer': 'SGD', 'sparsity': 0.9783697950876044, 'steps_to_train': 90, 'weight_decay': 0.01005536014206546}"}}
exception: None

00:54:00 job_callback for (4, 0, 1) started
00:54:00 DISPATCHER: Trying to submit another job.
00:54:00 job_callback for (4, 0, 1) got condition
00:54:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:54:00 done building a new model for budget 44.444444 based on 10/24 split
Best loss for this budget:-0.378549





00:54:00 HBMASTER: Trying to run another job!
00:54:00 job_callback for (4, 0, 1) finished
00:54:00 start sampling a new configuration.
00:54:00 done sampling a new configuration.
00:54:00 HBMASTER: schedule new run for iteration 4
00:54:00 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
00:54:00 HBMASTER: submitting job (4, 0, 2) to dispatcher
00:54:00 DISPATCHER: trying to submit job (4, 0, 2)
00:54:00 DISPATCHER: trying to notify the job_runner thread.
00:54:00 HBMASTER: job (4, 0, 2) submitted to dispatcher
00:54:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:54:00 DISPATCHER: Trying to submit another job.
00:54:00 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:54:00 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:54:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:54:00 WORKER: start processing job (4, 0, 2)
00:54:00 WORKER: args: ()
00:54:00 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 605, 'last_n_outputs': 10, 'leak_rate': 0.969511327236503, 'lr': 0.004431458373822611, 'optimizer': 'SGD', 'sparsity': 0.9349520179501145, 'steps_to_train': 63, 'weight_decay': 0.032596743584364346}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:54:37 DISPATCHER: Starting worker discovery
00:54:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:54:37 DISPATCHER: Finished worker discovery
00:55:37 DISPATCHER: Starting worker discovery
00:55:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:55:37 DISPATCHER: Finished worker discovery
00:55:40 WORKER: done with job (4, 0, 2), trying to register it.
00:55:40 WORKER: registered result for job (4, 0, 2) with dispatcher
00:55:40 DISPATCHER: job (4, 0, 2) finished
00:55:40 DISPATCHER: register_result: lock acquired
00:55:40 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
00:55:40 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 605, 'last_n_outputs': 10, 'leak_rate': 0.969511327236503, 'lr': 0.004431458373822611, 'optimizer': 'SGD', 'sparsity': 0.9349520179501145, 'steps_to_train': 63, 'weight_decay': 0.032596743584364346}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.27786306290331364, 'info': {'music_genre': 0.27786306290331364, 'config': "{'batch_size': 128, 'hidden_dim': 605, 'last_n_outputs': 10, 'leak_rate': 0.969511327236503, 'lr': 0.004431458373822611, 'optimizer': 'SGD', 'sparsity': 0.9349520179501145, 'steps_to_train': 63, 'weight_decay': 0.032596743584364346}"}}
exception: None

00:55:40 job_callback for (4, 0, 2) started
00:55:40 job_callback for (4, 0, 2) got condition
00:55:40 DISPATCHER: Trying to submit another job.
00:55:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:55:40 done building a new model for budget 44.444444 based on 10/25 split
Best loss for this budget:-0.378549





00:55:40 HBMASTER: Trying to run another job!
00:55:40 job_callback for (4, 0, 2) finished
00:55:40 start sampling a new configuration.
00:55:40 best_vector: [2, 0.8191006642126899, 0.0704774352693151, 0.4019037808154913, 0.33364820614049545, 1, 0.9326975685251437, 0.01663044539238706, 0.2949674422331573], 0.04125856307167607, 0.04281479401073925, 0.0017664768790929045
00:55:40 done sampling a new configuration.
00:55:40 HBMASTER: schedule new run for iteration 4
00:55:40 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
00:55:40 HBMASTER: submitting job (4, 0, 3) to dispatcher
00:55:40 DISPATCHER: trying to submit job (4, 0, 3)
00:55:40 DISPATCHER: trying to notify the job_runner thread.
00:55:40 HBMASTER: job (4, 0, 3) submitted to dispatcher
00:55:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:55:40 DISPATCHER: Trying to submit another job.
00:55:40 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:55:40 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:55:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:55:40 WORKER: start processing job (4, 0, 3)
00:55:40 WORKER: args: ()
00:55:40 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 856, 'last_n_outputs': 12, 'leak_rate': 0.8504759452038728, 'lr': 0.004648324218496446, 'optimizer': 'SGD', 'sparsity': 0.9738474164460345, 'steps_to_train': 11, 'weight_decay': 0.02419699808368557}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:56:37 DISPATCHER: Starting worker discovery
00:56:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:56:37 DISPATCHER: Finished worker discovery
00:57:23 WORKER: done with job (4, 0, 3), trying to register it.
00:57:23 WORKER: registered result for job (4, 0, 3) with dispatcher
00:57:23 DISPATCHER: job (4, 0, 3) finished
00:57:23 DISPATCHER: register_result: lock acquired
00:57:23 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
00:57:23 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 856, 'last_n_outputs': 12, 'leak_rate': 0.8504759452038728, 'lr': 0.004648324218496446, 'optimizer': 'SGD', 'sparsity': 0.9738474164460345, 'steps_to_train': 11, 'weight_decay': 0.02419699808368557}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3264109265450217, 'info': {'music_genre': 0.3264109265450217, 'config': "{'batch_size': 64, 'hidden_dim': 856, 'last_n_outputs': 12, 'leak_rate': 0.8504759452038728, 'lr': 0.004648324218496446, 'optimizer': 'SGD', 'sparsity': 0.9738474164460345, 'steps_to_train': 11, 'weight_decay': 0.02419699808368557}"}}
exception: None

00:57:23 job_callback for (4, 0, 3) started
00:57:23 job_callback for (4, 0, 3) got condition
00:57:23 DISPATCHER: Trying to submit another job.
00:57:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:57:23 done building a new model for budget 44.444444 based on 10/26 split
Best loss for this budget:-0.378549





00:57:23 HBMASTER: Trying to run another job!
00:57:23 job_callback for (4, 0, 3) finished
00:57:23 start sampling a new configuration.
00:57:23 done sampling a new configuration.
00:57:23 HBMASTER: schedule new run for iteration 4
00:57:23 HBMASTER: trying submitting job (4, 0, 4) to dispatcher
00:57:23 HBMASTER: submitting job (4, 0, 4) to dispatcher
00:57:23 DISPATCHER: trying to submit job (4, 0, 4)
00:57:23 DISPATCHER: trying to notify the job_runner thread.
00:57:23 HBMASTER: job (4, 0, 4) submitted to dispatcher
00:57:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:57:23 DISPATCHER: Trying to submit another job.
00:57:23 DISPATCHER: starting job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:57:23 DISPATCHER: job (4, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:57:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:57:23 WORKER: start processing job (4, 0, 4)
00:57:23 WORKER: args: ()
00:57:23 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 263, 'last_n_outputs': 30, 'leak_rate': 0.9507925851082605, 'lr': 0.015066505730024304, 'optimizer': 'Adam', 'sparsity': 0.90258644928106, 'steps_to_train': 14, 'weight_decay': 0.0530995079046707}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:57:37 DISPATCHER: Starting worker discovery
00:57:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:57:37 DISPATCHER: Finished worker discovery
00:58:37 DISPATCHER: Starting worker discovery
00:58:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:58:37 DISPATCHER: Finished worker discovery
00:59:05 WORKER: done with job (4, 0, 4), trying to register it.
00:59:05 WORKER: registered result for job (4, 0, 4) with dispatcher
00:59:05 DISPATCHER: job (4, 0, 4) finished
00:59:05 DISPATCHER: register_result: lock acquired
00:59:05 DISPATCHER: job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
00:59:05 job_id: (4, 0, 4)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 263, 'last_n_outputs': 30, 'leak_rate': 0.9507925851082605, 'lr': 0.015066505730024304, 'optimizer': 'Adam', 'sparsity': 0.90258644928106, 'steps_to_train': 14, 'weight_decay': 0.0530995079046707}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.11852365435841422, 'info': {'music_genre': 0.11852365435841422, 'config': "{'batch_size': 64, 'hidden_dim': 263, 'last_n_outputs': 30, 'leak_rate': 0.9507925851082605, 'lr': 0.015066505730024304, 'optimizer': 'Adam', 'sparsity': 0.90258644928106, 'steps_to_train': 14, 'weight_decay': 0.0530995079046707}"}}
exception: None

00:59:05 job_callback for (4, 0, 4) started
00:59:05 job_callback for (4, 0, 4) got condition
00:59:05 DISPATCHER: Trying to submit another job.
00:59:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:59:05 done building a new model for budget 44.444444 based on 10/27 split
Best loss for this budget:-0.378549





00:59:05 HBMASTER: Trying to run another job!
00:59:05 job_callback for (4, 0, 4) finished
00:59:05 start sampling a new configuration.
00:59:05 done sampling a new configuration.
00:59:05 HBMASTER: schedule new run for iteration 4
00:59:05 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
00:59:05 HBMASTER: submitting job (4, 0, 5) to dispatcher
00:59:05 DISPATCHER: trying to submit job (4, 0, 5)
00:59:05 DISPATCHER: trying to notify the job_runner thread.
00:59:05 HBMASTER: job (4, 0, 5) submitted to dispatcher
00:59:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:59:05 DISPATCHER: Trying to submit another job.
00:59:05 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:59:05 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:59:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:59:05 WORKER: start processing job (4, 0, 5)
00:59:05 WORKER: args: ()
00:59:05 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 806, 'last_n_outputs': 18, 'leak_rate': 0.8727119340498555, 'lr': 0.008175217164008345, 'optimizer': 'Adam', 'sparsity': 0.8635413489497767, 'steps_to_train': 94, 'weight_decay': 0.1409200082325993}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:59:37 DISPATCHER: Starting worker discovery
00:59:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:59:37 DISPATCHER: Finished worker discovery
01:00:37 DISPATCHER: Starting worker discovery
01:00:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:00:37 DISPATCHER: Finished worker discovery
01:00:49 WORKER: done with job (4, 0, 5), trying to register it.
01:00:49 WORKER: registered result for job (4, 0, 5) with dispatcher
01:00:49 DISPATCHER: job (4, 0, 5) finished
01:00:49 DISPATCHER: register_result: lock acquired
01:00:49 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:00:49 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 806, 'last_n_outputs': 18, 'leak_rate': 0.8727119340498555, 'lr': 0.008175217164008345, 'optimizer': 'Adam', 'sparsity': 0.8635413489497767, 'steps_to_train': 94, 'weight_decay': 0.1409200082325993}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.11825005707231102, 'info': {'music_genre': 0.11825005707231102, 'config': "{'batch_size': 16, 'hidden_dim': 806, 'last_n_outputs': 18, 'leak_rate': 0.8727119340498555, 'lr': 0.008175217164008345, 'optimizer': 'Adam', 'sparsity': 0.8635413489497767, 'steps_to_train': 94, 'weight_decay': 0.1409200082325993}"}}
exception: None

01:00:49 job_callback for (4, 0, 5) started
01:00:49 job_callback for (4, 0, 5) got condition
01:00:49 DISPATCHER: Trying to submit another job.
01:00:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:00:49 done building a new model for budget 44.444444 based on 10/28 split
Best loss for this budget:-0.378549





01:00:49 HBMASTER: Trying to run another job!
01:00:49 job_callback for (4, 0, 5) finished
01:00:49 start sampling a new configuration.
01:00:49 best_vector: [3, 0.1947728735403015, 0.8588291176334938, 0.39776975874615106, 0.0993520413309684, 0, 0.8033052376821364, 0.11162864882254964, 0.10375247643819492], 0.011131753294247, 0.362725797169487, 0.004037774087549806
01:00:49 done sampling a new configuration.
01:00:49 HBMASTER: schedule new run for iteration 4
01:00:49 HBMASTER: trying submitting job (4, 0, 6) to dispatcher
01:00:49 HBMASTER: submitting job (4, 0, 6) to dispatcher
01:00:49 DISPATCHER: trying to submit job (4, 0, 6)
01:00:49 DISPATCHER: trying to notify the job_runner thread.
01:00:49 HBMASTER: job (4, 0, 6) submitted to dispatcher
01:00:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:00:49 DISPATCHER: Trying to submit another job.
01:00:49 DISPATCHER: starting job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:00:49 DISPATCHER: job (4, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:00:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:00:49 WORKER: start processing job (4, 0, 6)
01:00:49 WORKER: args: ()
01:00:49 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 356, 'last_n_outputs': 45, 'leak_rate': 0.8494424396865378, 'lr': 0.0015801709836036192, 'optimizer': 'Adam', 'sparsity': 0.9427932570437128, 'steps_to_train': 20, 'weight_decay': 0.013645362702030513}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:01:37 DISPATCHER: Starting worker discovery
01:01:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:01:37 DISPATCHER: Finished worker discovery
01:02:32 WORKER: done with job (4, 0, 6), trying to register it.
01:02:32 WORKER: registered result for job (4, 0, 6) with dispatcher
01:02:32 DISPATCHER: job (4, 0, 6) finished
01:02:32 DISPATCHER: register_result: lock acquired
01:02:32 DISPATCHER: job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:02:32 job_id: (4, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 356, 'last_n_outputs': 45, 'leak_rate': 0.8494424396865378, 'lr': 0.0015801709836036192, 'optimizer': 'Adam', 'sparsity': 0.9427932570437128, 'steps_to_train': 20, 'weight_decay': 0.013645362702030513}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3158947972219609, 'info': {'music_genre': 0.3158947972219609, 'config': "{'batch_size': 128, 'hidden_dim': 356, 'last_n_outputs': 45, 'leak_rate': 0.8494424396865378, 'lr': 0.0015801709836036192, 'optimizer': 'Adam', 'sparsity': 0.9427932570437128, 'steps_to_train': 20, 'weight_decay': 0.013645362702030513}"}}
exception: None

01:02:32 job_callback for (4, 0, 6) started
01:02:32 DISPATCHER: Trying to submit another job.
01:02:32 job_callback for (4, 0, 6) got condition
01:02:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:02:32 done building a new model for budget 44.444444 based on 10/28 split
Best loss for this budget:-0.378549





01:02:32 HBMASTER: Trying to run another job!
01:02:32 job_callback for (4, 0, 6) finished
01:02:32 start sampling a new configuration.
01:02:32 best_vector: [0, 0.20734052872938702, 0.4336529986425045, 0.022335506401521342, 0.27966177094609024, 0, 0.7262319301162634, 0.007769405157728004, 0.07909727551373874], 0.004310831469765347, 0.20486625125586508, 0.0008831438830066377
01:02:32 done sampling a new configuration.
01:02:32 HBMASTER: schedule new run for iteration 4
01:02:32 HBMASTER: trying submitting job (4, 0, 7) to dispatcher
01:02:32 HBMASTER: submitting job (4, 0, 7) to dispatcher
01:02:32 DISPATCHER: trying to submit job (4, 0, 7)
01:02:32 DISPATCHER: trying to notify the job_runner thread.
01:02:32 HBMASTER: job (4, 0, 7) submitted to dispatcher
01:02:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:02:32 DISPATCHER: Trying to submit another job.
01:02:32 DISPATCHER: starting job (4, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:02:32 DISPATCHER: job (4, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:02:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:02:32 WORKER: start processing job (4, 0, 7)
01:02:32 WORKER: args: ()
01:02:32 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 366, 'last_n_outputs': 27, 'leak_rate': 0.7555838766003803, 'lr': 0.003625129637447108, 'optimizer': 'Adam', 'sparsity': 0.9242956632279032, 'steps_to_train': 10, 'weight_decay': 0.01267383147620247}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:02:37 DISPATCHER: Starting worker discovery
01:02:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:02:37 DISPATCHER: Finished worker discovery
01:03:37 DISPATCHER: Starting worker discovery
01:03:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:03:37 DISPATCHER: Finished worker discovery
01:04:15 WORKER: done with job (4, 0, 7), trying to register it.
01:04:15 WORKER: registered result for job (4, 0, 7) with dispatcher
01:04:15 DISPATCHER: job (4, 0, 7) finished
01:04:15 DISPATCHER: register_result: lock acquired
01:04:15 DISPATCHER: job (4, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:04:15 job_id: (4, 0, 7)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 366, 'last_n_outputs': 27, 'leak_rate': 0.7555838766003803, 'lr': 0.003625129637447108, 'optimizer': 'Adam', 'sparsity': 0.9242956632279032, 'steps_to_train': 10, 'weight_decay': 0.01267383147620247}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1731866824835858, 'info': {'music_genre': 0.1731866824835858, 'config': "{'batch_size': 16, 'hidden_dim': 366, 'last_n_outputs': 27, 'leak_rate': 0.7555838766003803, 'lr': 0.003625129637447108, 'optimizer': 'Adam', 'sparsity': 0.9242956632279032, 'steps_to_train': 10, 'weight_decay': 0.01267383147620247}"}}
exception: None

01:04:15 job_callback for (4, 0, 7) started
01:04:15 job_callback for (4, 0, 7) got condition
01:04:15 DISPATCHER: Trying to submit another job.
01:04:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:04:15 done building a new model for budget 44.444444 based on 10/29 split
Best loss for this budget:-0.378549





01:04:15 HBMASTER: Trying to run another job!
01:04:15 job_callback for (4, 0, 7) finished
01:04:15 start sampling a new configuration.
01:04:15 best_vector: [2, 0.4889097975035982, 0.9944215975560674, 0.7843913324863082, 0.1341931865933682, 0, 0.714057445332671, 0.021613106450544133, 0.07117380076393828], 0.003503655327786745, 0.2011138601083588, 0.0007046336474604094
01:04:15 done sampling a new configuration.
01:04:15 HBMASTER: schedule new run for iteration 4
01:04:15 HBMASTER: trying submitting job (4, 0, 8) to dispatcher
01:04:15 HBMASTER: submitting job (4, 0, 8) to dispatcher
01:04:15 DISPATCHER: trying to submit job (4, 0, 8)
01:04:15 DISPATCHER: trying to notify the job_runner thread.
01:04:15 HBMASTER: job (4, 0, 8) submitted to dispatcher
01:04:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:04:15 DISPATCHER: Trying to submit another job.
01:04:15 DISPATCHER: starting job (4, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:04:15 DISPATCHER: job (4, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:04:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:04:15 WORKER: start processing job (4, 0, 8)
01:04:15 WORKER: args: ()
01:04:15 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 591, 'last_n_outputs': 50, 'leak_rate': 0.946097833121577, 'lr': 0.0018551813648012947, 'optimizer': 'Adam', 'sparsity': 0.9213737868798411, 'steps_to_train': 11, 'weight_decay': 0.012376539997740629}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:04:37 DISPATCHER: Starting worker discovery
01:04:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:04:37 DISPATCHER: Finished worker discovery
01:05:37 DISPATCHER: Starting worker discovery
01:05:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:05:37 DISPATCHER: Finished worker discovery
01:05:59 WORKER: done with job (4, 0, 8), trying to register it.
01:05:59 WORKER: registered result for job (4, 0, 8) with dispatcher
01:05:59 DISPATCHER: job (4, 0, 8) finished
01:05:59 DISPATCHER: register_result: lock acquired
01:05:59 DISPATCHER: job (4, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:05:59 job_id: (4, 0, 8)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 591, 'last_n_outputs': 50, 'leak_rate': 0.946097833121577, 'lr': 0.0018551813648012947, 'optimizer': 'Adam', 'sparsity': 0.9213737868798411, 'steps_to_train': 11, 'weight_decay': 0.012376539997740629}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2352522165854247, 'info': {'music_genre': 0.2352522165854247, 'config': "{'batch_size': 64, 'hidden_dim': 591, 'last_n_outputs': 50, 'leak_rate': 0.946097833121577, 'lr': 0.0018551813648012947, 'optimizer': 'Adam', 'sparsity': 0.9213737868798411, 'steps_to_train': 11, 'weight_decay': 0.012376539997740629}"}}
exception: None

01:05:59 job_callback for (4, 0, 8) started
01:05:59 DISPATCHER: Trying to submit another job.
01:05:59 job_callback for (4, 0, 8) got condition
01:05:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:05:59 done building a new model for budget 44.444444 based on 10/30 split
Best loss for this budget:-0.378549





01:05:59 HBMASTER: Trying to run another job!
01:05:59 job_callback for (4, 0, 8) finished
01:05:59 start sampling a new configuration.
01:05:59 best_vector: [3, 0.638778314955551, 0.979798890086737, 0.042128506206345284, 0.5172297348532622, 1, 0.7061925988069171, 0.31274729925902556, 0.06970960833332157], 0.01049749890266359, 0.8214730065593076, 0.008623411984924091
01:05:59 done sampling a new configuration.
01:05:59 HBMASTER: schedule new run for iteration 4
01:05:59 HBMASTER: trying submitting job (4, 0, 9) to dispatcher
01:05:59 HBMASTER: submitting job (4, 0, 9) to dispatcher
01:05:59 DISPATCHER: trying to submit job (4, 0, 9)
01:05:59 DISPATCHER: trying to notify the job_runner thread.
01:05:59 HBMASTER: job (4, 0, 9) submitted to dispatcher
01:05:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:05:59 DISPATCHER: Trying to submit another job.
01:05:59 DISPATCHER: starting job (4, 0, 9) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:05:59 DISPATCHER: job (4, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:05:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:05:59 WORKER: start processing job (4, 0, 9)
01:05:59 WORKER: args: ()
01:05:59 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 711, 'last_n_outputs': 50, 'leak_rate': 0.7605321265515863, 'lr': 0.010825786793534508, 'optimizer': 'SGD', 'sparsity': 0.9194862237136601, 'steps_to_train': 38, 'weight_decay': 0.012322371315049593}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:06:37 DISPATCHER: Starting worker discovery
01:06:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:06:37 DISPATCHER: Finished worker discovery
01:07:37 DISPATCHER: Starting worker discovery
01:07:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:07:37 DISPATCHER: Finished worker discovery
01:07:45 WORKER: done with job (4, 0, 9), trying to register it.
01:07:45 WORKER: registered result for job (4, 0, 9) with dispatcher
01:07:45 DISPATCHER: job (4, 0, 9) finished
01:07:45 DISPATCHER: register_result: lock acquired
01:07:45 DISPATCHER: job (4, 0, 9) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:07:45 job_id: (4, 0, 9)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 711, 'last_n_outputs': 50, 'leak_rate': 0.7605321265515863, 'lr': 0.010825786793534508, 'optimizer': 'SGD', 'sparsity': 0.9194862237136601, 'steps_to_train': 38, 'weight_decay': 0.012322371315049593}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3295062892084539, 'info': {'music_genre': 0.3295062892084539, 'config': "{'batch_size': 128, 'hidden_dim': 711, 'last_n_outputs': 50, 'leak_rate': 0.7605321265515863, 'lr': 0.010825786793534508, 'optimizer': 'SGD', 'sparsity': 0.9194862237136601, 'steps_to_train': 38, 'weight_decay': 0.012322371315049593}"}}
exception: None

01:07:45 job_callback for (4, 0, 9) started
01:07:45 DISPATCHER: Trying to submit another job.
01:07:45 job_callback for (4, 0, 9) got condition
01:07:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:07:45 done building a new model for budget 44.444444 based on 10/31 split
Best loss for this budget:-0.378549





01:07:45 HBMASTER: Trying to run another job!
01:07:45 job_callback for (4, 0, 9) finished
01:07:45 start sampling a new configuration.
01:07:45 best_vector: [1, 0.5767995732924718, 0.014545440163095988, 0.40218945105133685, 0.2979255222263342, 1, 0.8482849096388793, 0.054629737739015694, 0.26845778999757347], 0.008457294104410845, 1.2021329444930902, 0.010166791864179462
01:07:45 done sampling a new configuration.
01:07:45 HBMASTER: schedule new run for iteration 4
01:07:45 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
01:07:45 HBMASTER: submitting job (4, 0, 10) to dispatcher
01:07:45 DISPATCHER: trying to submit job (4, 0, 10)
01:07:45 DISPATCHER: trying to notify the job_runner thread.
01:07:45 HBMASTER: job (4, 0, 10) submitted to dispatcher
01:07:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:07:45 DISPATCHER: Trying to submit another job.
01:07:45 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:07:45 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:07:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:07:45 WORKER: start processing job (4, 0, 10)
01:07:45 WORKER: args: ()
01:07:45 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 662, 'last_n_outputs': 10, 'leak_rate': 0.8505473627628342, 'lr': 0.0039432203319511435, 'optimizer': 'SGD', 'sparsity': 0.953588378313331, 'steps_to_train': 14, 'weight_decay': 0.02234969688056448}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:08:37 DISPATCHER: Starting worker discovery
01:08:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:08:37 DISPATCHER: Finished worker discovery
01:09:30 WORKER: done with job (4, 0, 10), trying to register it.
01:09:30 WORKER: registered result for job (4, 0, 10) with dispatcher
01:09:30 DISPATCHER: job (4, 0, 10) finished
01:09:30 DISPATCHER: register_result: lock acquired
01:09:30 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:09:30 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 662, 'last_n_outputs': 10, 'leak_rate': 0.8505473627628342, 'lr': 0.0039432203319511435, 'optimizer': 'SGD', 'sparsity': 0.953588378313331, 'steps_to_train': 14, 'weight_decay': 0.02234969688056448}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.256572847098854, 'info': {'music_genre': 0.256572847098854, 'config': "{'batch_size': 32, 'hidden_dim': 662, 'last_n_outputs': 10, 'leak_rate': 0.8505473627628342, 'lr': 0.0039432203319511435, 'optimizer': 'SGD', 'sparsity': 0.953588378313331, 'steps_to_train': 14, 'weight_decay': 0.02234969688056448}"}}
exception: None

01:09:30 job_callback for (4, 0, 10) started
01:09:30 job_callback for (4, 0, 10) got condition
01:09:30 DISPATCHER: Trying to submit another job.
01:09:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:09:30 done building a new model for budget 44.444444 based on 10/32 split
Best loss for this budget:-0.378549





01:09:30 HBMASTER: Trying to run another job!
01:09:30 job_callback for (4, 0, 10) finished
01:09:30 start sampling a new configuration.
01:09:30 best_vector: [0, 0.944752506232678, 0.8761949297660065, 0.12425452229336359, 0.08283431960371673, 1, 0.4790105600784705, 0.4814932026194652, 0.09121427455687334], 0.006283754014194168, 0.12609965788865932, 0.0007923792314463743
01:09:30 done sampling a new configuration.
01:09:30 HBMASTER: schedule new run for iteration 4
01:09:30 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
01:09:30 HBMASTER: submitting job (4, 0, 11) to dispatcher
01:09:30 DISPATCHER: trying to submit job (4, 0, 11)
01:09:30 DISPATCHER: trying to notify the job_runner thread.
01:09:30 HBMASTER: job (4, 0, 11) submitted to dispatcher
01:09:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:09:30 DISPATCHER: Trying to submit another job.
01:09:30 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:09:30 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:09:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:09:30 WORKER: start processing job (4, 0, 11)
01:09:30 WORKER: args: ()
01:09:30 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 956, 'last_n_outputs': 45, 'leak_rate': 0.7810636305733409, 'lr': 0.0014644300743280043, 'optimizer': 'SGD', 'sparsity': 0.864962534418833, 'steps_to_train': 53, 'weight_decay': 0.013142334213420988}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:09:37 DISPATCHER: Starting worker discovery
01:09:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:09:37 DISPATCHER: Finished worker discovery
01:10:37 DISPATCHER: Starting worker discovery
01:10:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:10:37 DISPATCHER: Finished worker discovery
01:11:17 WORKER: done with job (4, 0, 11), trying to register it.
01:11:17 WORKER: registered result for job (4, 0, 11) with dispatcher
01:11:17 DISPATCHER: job (4, 0, 11) finished
01:11:17 DISPATCHER: register_result: lock acquired
01:11:17 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:11:17 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 956, 'last_n_outputs': 45, 'leak_rate': 0.7810636305733409, 'lr': 0.0014644300743280043, 'optimizer': 'SGD', 'sparsity': 0.864962534418833, 'steps_to_train': 53, 'weight_decay': 0.013142334213420988}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.29879200581471876, 'info': {'music_genre': 0.29879200581471876, 'config': "{'batch_size': 16, 'hidden_dim': 956, 'last_n_outputs': 45, 'leak_rate': 0.7810636305733409, 'lr': 0.0014644300743280043, 'optimizer': 'SGD', 'sparsity': 0.864962534418833, 'steps_to_train': 53, 'weight_decay': 0.013142334213420988}"}}
exception: None

01:11:17 job_callback for (4, 0, 11) started
01:11:17 job_callback for (4, 0, 11) got condition
01:11:17 DISPATCHER: Trying to submit another job.
01:11:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:11:17 done building a new model for budget 44.444444 based on 10/33 split
Best loss for this budget:-0.378549





01:11:17 HBMASTER: Trying to run another job!
01:11:17 job_callback for (4, 0, 11) finished
01:11:17 start sampling a new configuration.
01:11:18 best_vector: [2, 0.16129149666720147, 0.04763823606391332, 0.6326155910206448, 0.7269381066988788, 1, 0.3607385237956403, 0.851118081255774, 0.023706187477741177], 0.025187237469405786, 0.40600954190624117, 0.010226258746837157
01:11:18 done sampling a new configuration.
01:11:18 HBMASTER: schedule new run for iteration 4
01:11:18 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
01:11:18 HBMASTER: submitting job (4, 0, 12) to dispatcher
01:11:18 DISPATCHER: trying to submit job (4, 0, 12)
01:11:18 DISPATCHER: trying to notify the job_runner thread.
01:11:18 HBMASTER: job (4, 0, 12) submitted to dispatcher
01:11:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:11:18 DISPATCHER: Trying to submit another job.
01:11:18 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:11:18 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:11:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:11:18 WORKER: start processing job (4, 0, 12)
01:11:18 WORKER: args: ()
01:11:18 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 329, 'last_n_outputs': 11, 'leak_rate': 0.9081538977551612, 'lr': 0.028436504685499554, 'optimizer': 'SGD', 'sparsity': 0.8365772457109537, 'steps_to_train': 87, 'weight_decay': 0.010735998965851748}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:11:37 DISPATCHER: Starting worker discovery
01:11:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:11:37 DISPATCHER: Finished worker discovery
01:12:37 DISPATCHER: Starting worker discovery
01:12:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:12:37 DISPATCHER: Finished worker discovery
01:13:20 WORKER: done with job (4, 0, 12), trying to register it.
01:13:20 WORKER: registered result for job (4, 0, 12) with dispatcher
01:13:20 DISPATCHER: job (4, 0, 12) finished
01:13:20 DISPATCHER: register_result: lock acquired
01:13:20 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:13:20 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 329, 'last_n_outputs': 11, 'leak_rate': 0.9081538977551612, 'lr': 0.028436504685499554, 'optimizer': 'SGD', 'sparsity': 0.8365772457109537, 'steps_to_train': 87, 'weight_decay': 0.010735998965851748}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2873371867058259, 'info': {'music_genre': 0.2873371867058259, 'config': "{'batch_size': 64, 'hidden_dim': 329, 'last_n_outputs': 11, 'leak_rate': 0.9081538977551612, 'lr': 0.028436504685499554, 'optimizer': 'SGD', 'sparsity': 0.8365772457109537, 'steps_to_train': 87, 'weight_decay': 0.010735998965851748}"}}
exception: None

01:13:20 job_callback for (4, 0, 12) started
01:13:20 job_callback for (4, 0, 12) got condition
01:13:20 DISPATCHER: Trying to submit another job.
01:13:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:13:20 done building a new model for budget 44.444444 based on 10/34 split
Best loss for this budget:-0.378549





01:13:20 HBMASTER: Trying to run another job!
01:13:20 job_callback for (4, 0, 12) finished
01:13:20 start sampling a new configuration.
01:13:20 done sampling a new configuration.
01:13:20 HBMASTER: schedule new run for iteration 4
01:13:20 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
01:13:20 HBMASTER: submitting job (4, 0, 13) to dispatcher
01:13:20 DISPATCHER: trying to submit job (4, 0, 13)
01:13:20 DISPATCHER: trying to notify the job_runner thread.
01:13:20 HBMASTER: job (4, 0, 13) submitted to dispatcher
01:13:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:13:20 DISPATCHER: Trying to submit another job.
01:13:20 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:13:20 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:13:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:13:20 WORKER: start processing job (4, 0, 13)
01:13:20 WORKER: args: ()
01:13:20 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 974, 'last_n_outputs': 11, 'leak_rate': 0.8848190507523888, 'lr': 0.005220714185690286, 'optimizer': 'Adam', 'sparsity': 0.7977400811976646, 'steps_to_train': 55, 'weight_decay': 0.010591155301926048}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:13:37 DISPATCHER: Starting worker discovery
01:13:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:13:37 DISPATCHER: Finished worker discovery
01:14:37 DISPATCHER: Starting worker discovery
01:14:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:14:37 DISPATCHER: Finished worker discovery
01:15:14 WORKER: done with job (4, 0, 13), trying to register it.
01:15:14 WORKER: registered result for job (4, 0, 13) with dispatcher
01:15:14 DISPATCHER: job (4, 0, 13) finished
01:15:14 DISPATCHER: register_result: lock acquired
01:15:14 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:15:14 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 974, 'last_n_outputs': 11, 'leak_rate': 0.8848190507523888, 'lr': 0.005220714185690286, 'optimizer': 'Adam', 'sparsity': 0.7977400811976646, 'steps_to_train': 55, 'weight_decay': 0.010591155301926048}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.28504942954748197, 'info': {'music_genre': 0.28504942954748197, 'config': "{'batch_size': 128, 'hidden_dim': 974, 'last_n_outputs': 11, 'leak_rate': 0.8848190507523888, 'lr': 0.005220714185690286, 'optimizer': 'Adam', 'sparsity': 0.7977400811976646, 'steps_to_train': 55, 'weight_decay': 0.010591155301926048}"}}
exception: None

01:15:14 job_callback for (4, 0, 13) started
01:15:14 DISPATCHER: Trying to submit another job.
01:15:14 job_callback for (4, 0, 13) got condition
01:15:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:15:14 done building a new model for budget 44.444444 based on 10/34 split
Best loss for this budget:-0.378549





01:15:14 HBMASTER: Trying to run another job!
01:15:14 job_callback for (4, 0, 13) finished
01:15:14 start sampling a new configuration.
01:15:14 best_vector: [3, 0.772060369822674, 0.8255676078475331, 0.3556843565183593, 0.41996451653620026, 0, 0.5430670730530784, 0.960751605986722, 0.07121797337224281], 0.03291831179388185, 0.09611906617844565, 0.0031640773897988373
01:15:14 done sampling a new configuration.
01:15:14 HBMASTER: schedule new run for iteration 4
01:15:14 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
01:15:14 HBMASTER: submitting job (4, 0, 14) to dispatcher
01:15:14 DISPATCHER: trying to submit job (4, 0, 14)
01:15:14 DISPATCHER: trying to notify the job_runner thread.
01:15:14 HBMASTER: job (4, 0, 14) submitted to dispatcher
01:15:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:15:14 DISPATCHER: Trying to submit another job.
01:15:14 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:15:14 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:15:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:15:14 WORKER: start processing job (4, 0, 14)
01:15:14 WORKER: args: ()
01:15:14 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 818, 'last_n_outputs': 43, 'leak_rate': 0.8389210891295898, 'lr': 0.0069171792986206775, 'optimizer': 'Adam', 'sparsity': 0.8803360975327388, 'steps_to_train': 97, 'weight_decay': 0.012378177885085596}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:15:37 DISPATCHER: Starting worker discovery
01:15:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:15:37 DISPATCHER: Finished worker discovery
01:16:37 DISPATCHER: Starting worker discovery
01:16:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:16:37 DISPATCHER: Finished worker discovery
01:17:07 WORKER: done with job (4, 0, 14), trying to register it.
01:17:07 WORKER: registered result for job (4, 0, 14) with dispatcher
01:17:07 DISPATCHER: job (4, 0, 14) finished
01:17:07 DISPATCHER: register_result: lock acquired
01:17:07 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:17:07 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 818, 'last_n_outputs': 43, 'leak_rate': 0.8389210891295898, 'lr': 0.0069171792986206775, 'optimizer': 'Adam', 'sparsity': 0.8803360975327388, 'steps_to_train': 97, 'weight_decay': 0.012378177885085596}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.28323598091494784, 'info': {'music_genre': 0.28323598091494784, 'config': "{'batch_size': 128, 'hidden_dim': 818, 'last_n_outputs': 43, 'leak_rate': 0.8389210891295898, 'lr': 0.0069171792986206775, 'optimizer': 'Adam', 'sparsity': 0.8803360975327388, 'steps_to_train': 97, 'weight_decay': 0.012378177885085596}"}}
exception: None

01:17:07 job_callback for (4, 0, 14) started
01:17:07 DISPATCHER: Trying to submit another job.
01:17:07 job_callback for (4, 0, 14) got condition
01:17:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:17:07 done building a new model for budget 44.444444 based on 10/35 split
Best loss for this budget:-0.378549





01:17:07 HBMASTER: Trying to run another job!
01:17:07 job_callback for (4, 0, 14) finished
01:17:07 start sampling a new configuration.
01:17:07 best_vector: [3, 0.31037188645344393, 0.872493564661691, 0.44517009320140616, 0.12132548584224767, 1, 0.7037485410076886, 0.758103825810453, 0.04554354856378234], 0.01753571950019871, 0.8372621930058282, 0.014681994964671439
01:17:07 done sampling a new configuration.
01:17:07 HBMASTER: schedule new run for iteration 4
01:17:07 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
01:17:07 HBMASTER: submitting job (4, 0, 15) to dispatcher
01:17:07 DISPATCHER: trying to submit job (4, 0, 15)
01:17:07 DISPATCHER: trying to notify the job_runner thread.
01:17:07 HBMASTER: job (4, 0, 15) submitted to dispatcher
01:17:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:17:07 DISPATCHER: Trying to submit another job.
01:17:07 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:17:07 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:17:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:17:07 WORKER: start processing job (4, 0, 15)
01:17:07 WORKER: args: ()
01:17:07 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 448, 'last_n_outputs': 45, 'leak_rate': 0.8612925233003516, 'lr': 0.001748440958837722, 'optimizer': 'SGD', 'sparsity': 0.9188996498418452, 'steps_to_train': 78, 'weight_decay': 0.011461818387758907}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:17:37 DISPATCHER: Starting worker discovery
01:17:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:17:37 DISPATCHER: Finished worker discovery
01:18:37 DISPATCHER: Starting worker discovery
01:18:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:18:37 DISPATCHER: Finished worker discovery
01:19:02 WORKER: done with job (4, 0, 15), trying to register it.
01:19:02 WORKER: registered result for job (4, 0, 15) with dispatcher
01:19:02 DISPATCHER: job (4, 0, 15) finished
01:19:02 DISPATCHER: register_result: lock acquired
01:19:02 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:19:02 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 448, 'last_n_outputs': 45, 'leak_rate': 0.8612925233003516, 'lr': 0.001748440958837722, 'optimizer': 'SGD', 'sparsity': 0.9188996498418452, 'steps_to_train': 78, 'weight_decay': 0.011461818387758907}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.325463123713976, 'info': {'music_genre': 0.325463123713976, 'config': "{'batch_size': 128, 'hidden_dim': 448, 'last_n_outputs': 45, 'leak_rate': 0.8612925233003516, 'lr': 0.001748440958837722, 'optimizer': 'SGD', 'sparsity': 0.9188996498418452, 'steps_to_train': 78, 'weight_decay': 0.011461818387758907}"}}
exception: None

01:19:02 job_callback for (4, 0, 15) started
01:19:02 job_callback for (4, 0, 15) got condition
01:19:02 DISPATCHER: Trying to submit another job.
01:19:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:19:02 done building a new model for budget 44.444444 based on 10/36 split
Best loss for this budget:-0.378549





01:19:02 HBMASTER: Trying to run another job!
01:19:02 job_callback for (4, 0, 15) finished
01:19:02 start sampling a new configuration.
01:19:02 best_vector: [3, 0.786093187604699, 0.5749892420183657, 0.18837253018135577, 0.720779651972146, 1, 0.6690466434536058, 0.3661833312107855, 0.18469838679396175], 0.02226784007448594, 1.8009521903512113, 0.04010331535653593
01:19:02 done sampling a new configuration.
01:19:02 HBMASTER: schedule new run for iteration 4
01:19:02 HBMASTER: trying submitting job (4, 0, 16) to dispatcher
01:19:02 HBMASTER: submitting job (4, 0, 16) to dispatcher
01:19:02 DISPATCHER: trying to submit job (4, 0, 16)
01:19:02 DISPATCHER: trying to notify the job_runner thread.
01:19:02 HBMASTER: job (4, 0, 16) submitted to dispatcher
01:19:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:19:02 DISPATCHER: Trying to submit another job.
01:19:02 DISPATCHER: starting job (4, 0, 16) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:19:02 DISPATCHER: job (4, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:19:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:19:02 WORKER: start processing job (4, 0, 16)
01:19:02 WORKER: args: ()
01:19:02 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 829, 'last_n_outputs': 33, 'leak_rate': 0.797093132545339, 'lr': 0.02764135342655125, 'optimizer': 'SGD', 'sparsity': 0.9105711944288654, 'steps_to_train': 43, 'weight_decay': 0.017389942314333454}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:19:37 DISPATCHER: Starting worker discovery
01:19:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:19:37 DISPATCHER: Finished worker discovery
01:20:37 DISPATCHER: Starting worker discovery
01:20:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:20:37 DISPATCHER: Finished worker discovery
01:20:54 WORKER: done with job (4, 0, 16), trying to register it.
01:20:54 WORKER: registered result for job (4, 0, 16) with dispatcher
01:20:54 DISPATCHER: job (4, 0, 16) finished
01:20:54 DISPATCHER: register_result: lock acquired
01:20:54 DISPATCHER: job (4, 0, 16) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:20:54 job_id: (4, 0, 16)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 829, 'last_n_outputs': 33, 'leak_rate': 0.797093132545339, 'lr': 0.02764135342655125, 'optimizer': 'SGD', 'sparsity': 0.9105711944288654, 'steps_to_train': 43, 'weight_decay': 0.017389942314333454}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.31846292981917407, 'info': {'music_genre': 0.31846292981917407, 'config': "{'batch_size': 128, 'hidden_dim': 829, 'last_n_outputs': 33, 'leak_rate': 0.797093132545339, 'lr': 0.02764135342655125, 'optimizer': 'SGD', 'sparsity': 0.9105711944288654, 'steps_to_train': 43, 'weight_decay': 0.017389942314333454}"}}
exception: None

01:20:54 job_callback for (4, 0, 16) started
01:20:54 DISPATCHER: Trying to submit another job.
01:20:54 job_callback for (4, 0, 16) got condition
01:20:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:20:54 done building a new model for budget 44.444444 based on 10/37 split
Best loss for this budget:-0.378549





01:20:54 HBMASTER: Trying to run another job!
01:20:54 job_callback for (4, 0, 16) finished
01:20:54 start sampling a new configuration.
01:20:54 done sampling a new configuration.
01:20:54 HBMASTER: schedule new run for iteration 4
01:20:54 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
01:20:54 HBMASTER: submitting job (4, 0, 17) to dispatcher
01:20:54 DISPATCHER: trying to submit job (4, 0, 17)
01:20:54 DISPATCHER: trying to notify the job_runner thread.
01:20:54 HBMASTER: job (4, 0, 17) submitted to dispatcher
01:20:54 DISPATCHER: Trying to submit another job.
01:20:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:20:54 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:20:54 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:20:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:20:54 WORKER: start processing job (4, 0, 17)
01:20:54 WORKER: args: ()
01:20:54 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 433, 'last_n_outputs': 41, 'leak_rate': 0.8460679205439984, 'lr': 0.007208677035872156, 'optimizer': 'SGD', 'sparsity': 0.8919392898777779, 'steps_to_train': 52, 'weight_decay': 0.023122919853463292}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:21:37 DISPATCHER: Starting worker discovery
01:21:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:21:37 DISPATCHER: Finished worker discovery
01:22:37 DISPATCHER: Starting worker discovery
01:22:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:22:37 DISPATCHER: Finished worker discovery
01:22:44 WORKER: done with job (4, 0, 17), trying to register it.
01:22:44 WORKER: registered result for job (4, 0, 17) with dispatcher
01:22:44 DISPATCHER: job (4, 0, 17) finished
01:22:44 DISPATCHER: register_result: lock acquired
01:22:44 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:22:44 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 433, 'last_n_outputs': 41, 'leak_rate': 0.8460679205439984, 'lr': 0.007208677035872156, 'optimizer': 'SGD', 'sparsity': 0.8919392898777779, 'steps_to_train': 52, 'weight_decay': 0.023122919853463292}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.29987976355638235, 'info': {'music_genre': 0.29987976355638235, 'config': "{'batch_size': 64, 'hidden_dim': 433, 'last_n_outputs': 41, 'leak_rate': 0.8460679205439984, 'lr': 0.007208677035872156, 'optimizer': 'SGD', 'sparsity': 0.8919392898777779, 'steps_to_train': 52, 'weight_decay': 0.023122919853463292}"}}
exception: None

01:22:44 job_callback for (4, 0, 17) started
01:22:44 DISPATCHER: Trying to submit another job.
01:22:44 job_callback for (4, 0, 17) got condition
01:22:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:22:44 done building a new model for budget 44.444444 based on 10/38 split
Best loss for this budget:-0.378549





01:22:44 HBMASTER: Trying to run another job!
01:22:44 job_callback for (4, 0, 17) finished
01:22:44 start sampling a new configuration.
01:22:44 best_vector: [3, 0.872128242374191, 0.9297435144014271, 0.4718741503397941, 0.7598811165288698, 1, 0.6706067030423634, 0.1102191778959869, 0.22736910534191318], 0.01464378291787539, 0.6527241606427288, 0.009558350913704543
01:22:44 done sampling a new configuration.
01:22:44 HBMASTER: schedule new run for iteration 4
01:22:44 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
01:22:44 HBMASTER: submitting job (4, 0, 18) to dispatcher
01:22:44 DISPATCHER: trying to submit job (4, 0, 18)
01:22:44 DISPATCHER: trying to notify the job_runner thread.
01:22:44 HBMASTER: job (4, 0, 18) submitted to dispatcher
01:22:44 DISPATCHER: Trying to submit another job.
01:22:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:22:44 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:22:44 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:22:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:22:44 WORKER: start processing job (4, 0, 18)
01:22:44 WORKER: args: ()
01:22:44 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 898, 'last_n_outputs': 48, 'leak_rate': 0.8679685375849485, 'lr': 0.03309498838905841, 'optimizer': 'SGD', 'sparsity': 0.9109456087301672, 'steps_to_train': 20, 'weight_decay': 0.019761232421341486}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:23:37 DISPATCHER: Starting worker discovery
01:23:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:23:37 DISPATCHER: Finished worker discovery
01:24:29 WORKER: done with job (4, 0, 18), trying to register it.
01:24:29 WORKER: registered result for job (4, 0, 18) with dispatcher
01:24:29 DISPATCHER: job (4, 0, 18) finished
01:24:29 DISPATCHER: register_result: lock acquired
01:24:29 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:24:29 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 898, 'last_n_outputs': 48, 'leak_rate': 0.8679685375849485, 'lr': 0.03309498838905841, 'optimizer': 'SGD', 'sparsity': 0.9109456087301672, 'steps_to_train': 20, 'weight_decay': 0.019761232421341486}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2907916631175884, 'info': {'music_genre': 0.2907916631175884, 'config': "{'batch_size': 128, 'hidden_dim': 898, 'last_n_outputs': 48, 'leak_rate': 0.8679685375849485, 'lr': 0.03309498838905841, 'optimizer': 'SGD', 'sparsity': 0.9109456087301672, 'steps_to_train': 20, 'weight_decay': 0.019761232421341486}"}}
exception: None

01:24:29 job_callback for (4, 0, 18) started
01:24:29 DISPATCHER: Trying to submit another job.
01:24:29 job_callback for (4, 0, 18) got condition
01:24:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:24:29 done building a new model for budget 44.444444 based on 10/39 split
Best loss for this budget:-0.378549





01:24:29 HBMASTER: Trying to run another job!
01:24:29 job_callback for (4, 0, 18) finished
01:24:29 start sampling a new configuration.
01:24:29 done sampling a new configuration.
01:24:29 HBMASTER: schedule new run for iteration 4
01:24:29 HBMASTER: trying submitting job (4, 0, 19) to dispatcher
01:24:29 HBMASTER: submitting job (4, 0, 19) to dispatcher
01:24:29 DISPATCHER: trying to submit job (4, 0, 19)
01:24:29 DISPATCHER: trying to notify the job_runner thread.
01:24:29 HBMASTER: job (4, 0, 19) submitted to dispatcher
01:24:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:24:29 DISPATCHER: Trying to submit another job.
01:24:29 DISPATCHER: starting job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:24:29 DISPATCHER: job (4, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:24:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:24:29 WORKER: start processing job (4, 0, 19)
01:24:29 WORKER: args: ()
01:24:29 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 837, 'last_n_outputs': 40, 'leak_rate': 0.8509830334914813, 'lr': 0.0012934955680248335, 'optimizer': 'SGD', 'sparsity': 0.8328358416994902, 'steps_to_train': 61, 'weight_decay': 0.12688766714993988}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:24:37 DISPATCHER: Starting worker discovery
01:24:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:24:37 DISPATCHER: Finished worker discovery
01:25:37 DISPATCHER: Starting worker discovery
01:25:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:25:37 DISPATCHER: Finished worker discovery
01:26:12 WORKER: done with job (4, 0, 19), trying to register it.
01:26:12 WORKER: registered result for job (4, 0, 19) with dispatcher
01:26:12 DISPATCHER: job (4, 0, 19) finished
01:26:12 DISPATCHER: register_result: lock acquired
01:26:12 DISPATCHER: job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:26:12 job_id: (4, 0, 19)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 837, 'last_n_outputs': 40, 'leak_rate': 0.8509830334914813, 'lr': 0.0012934955680248335, 'optimizer': 'SGD', 'sparsity': 0.8328358416994902, 'steps_to_train': 61, 'weight_decay': 0.12688766714993988}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.28981586295866985, 'info': {'music_genre': 0.28981586295866985, 'config': "{'batch_size': 32, 'hidden_dim': 837, 'last_n_outputs': 40, 'leak_rate': 0.8509830334914813, 'lr': 0.0012934955680248335, 'optimizer': 'SGD', 'sparsity': 0.8328358416994902, 'steps_to_train': 61, 'weight_decay': 0.12688766714993988}"}}
exception: None

01:26:12 job_callback for (4, 0, 19) started
01:26:12 DISPATCHER: Trying to submit another job.
01:26:12 job_callback for (4, 0, 19) got condition
01:26:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:26:12 done building a new model for budget 44.444444 based on 10/39 split
Best loss for this budget:-0.378549





01:26:12 HBMASTER: Trying to run another job!
01:26:12 job_callback for (4, 0, 19) finished
01:26:12 start sampling a new configuration.
01:26:12 best_vector: [0, 0.13445021787279124, 0.6106314119164237, 0.36619346020796417, 0.5642320245568644, 1, 0.6328906549478528, 0.9883846149977953, 0.13528710747647246], 0.05067872870217538, 1.2285728345574596, 0.06226250937340009
01:26:12 done sampling a new configuration.
01:26:12 HBMASTER: schedule new run for iteration 4
01:26:12 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
01:26:12 HBMASTER: submitting job (4, 0, 20) to dispatcher
01:26:12 DISPATCHER: trying to submit job (4, 0, 20)
01:26:12 DISPATCHER: trying to notify the job_runner thread.
01:26:12 HBMASTER: job (4, 0, 20) submitted to dispatcher
01:26:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:26:12 DISPATCHER: Trying to submit another job.
01:26:12 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:26:12 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:26:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:26:12 WORKER: start processing job (4, 0, 20)
01:26:12 WORKER: args: ()
01:26:12 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 307, 'last_n_outputs': 35, 'leak_rate': 0.841548365051991, 'lr': 0.013442004891829647, 'optimizer': 'SGD', 'sparsity': 0.9018937571874847, 'steps_to_train': 99, 'weight_decay': 0.014997282935434123}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:26:37 DISPATCHER: Starting worker discovery
01:26:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:26:37 DISPATCHER: Finished worker discovery
01:27:37 DISPATCHER: Starting worker discovery
01:27:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:27:37 DISPATCHER: Finished worker discovery
01:27:58 WORKER: done with job (4, 0, 20), trying to register it.
01:27:58 WORKER: registered result for job (4, 0, 20) with dispatcher
01:27:58 DISPATCHER: job (4, 0, 20) finished
01:27:58 DISPATCHER: register_result: lock acquired
01:27:58 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:27:58 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 307, 'last_n_outputs': 35, 'leak_rate': 0.841548365051991, 'lr': 0.013442004891829647, 'optimizer': 'SGD', 'sparsity': 0.9018937571874847, 'steps_to_train': 99, 'weight_decay': 0.014997282935434123}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.28160664904982813, 'info': {'music_genre': 0.28160664904982813, 'config': "{'batch_size': 16, 'hidden_dim': 307, 'last_n_outputs': 35, 'leak_rate': 0.841548365051991, 'lr': 0.013442004891829647, 'optimizer': 'SGD', 'sparsity': 0.9018937571874847, 'steps_to_train': 99, 'weight_decay': 0.014997282935434123}"}}
exception: None

01:27:58 job_callback for (4, 0, 20) started
01:27:58 job_callback for (4, 0, 20) got condition
01:27:58 DISPATCHER: Trying to submit another job.
01:27:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:27:58 done building a new model for budget 44.444444 based on 10/40 split
Best loss for this budget:-0.378549





01:27:58 HBMASTER: Trying to run another job!
01:27:58 job_callback for (4, 0, 20) finished
01:27:58 start sampling a new configuration.
01:27:58 best_vector: [1, 0.09024605813371614, 0.4630803218240845, 0.6212411830820905, 0.00846815055925762, 1, 0.7730274397052479, 0.2544733501880025, 0.15333805287984542], 0.028052052800864286, 0.5170938517181141, 0.014505544031398823
01:27:58 done sampling a new configuration.
01:27:58 HBMASTER: schedule new run for iteration 4
01:27:58 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
01:27:58 HBMASTER: submitting job (4, 0, 21) to dispatcher
01:27:58 DISPATCHER: trying to submit job (4, 0, 21)
01:27:58 DISPATCHER: trying to notify the job_runner thread.
01:27:58 HBMASTER: job (4, 0, 21) submitted to dispatcher
01:27:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:27:58 DISPATCHER: Trying to submit another job.
01:27:58 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:27:58 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:27:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:27:58 WORKER: start processing job (4, 0, 21)
01:27:58 WORKER: args: ()
01:27:58 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 272, 'last_n_outputs': 28, 'leak_rate': 0.9053102957705226, 'lr': 0.0010397676497449595, 'optimizer': 'SGD', 'sparsity': 0.9355265855292595, 'steps_to_train': 33, 'weight_decay': 0.015830601122059283}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:28:37 DISPATCHER: Starting worker discovery
01:28:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:28:37 DISPATCHER: Finished worker discovery
01:29:37 DISPATCHER: Starting worker discovery
01:29:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:29:37 DISPATCHER: Finished worker discovery
01:29:43 WORKER: done with job (4, 0, 21), trying to register it.
01:29:43 WORKER: registered result for job (4, 0, 21) with dispatcher
01:29:43 DISPATCHER: job (4, 0, 21) finished
01:29:43 DISPATCHER: register_result: lock acquired
01:29:43 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:29:43 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 272, 'last_n_outputs': 28, 'leak_rate': 0.9053102957705226, 'lr': 0.0010397676497449595, 'optimizer': 'SGD', 'sparsity': 0.9355265855292595, 'steps_to_train': 33, 'weight_decay': 0.015830601122059283}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2427597189512651, 'info': {'music_genre': 0.2427597189512651, 'config': "{'batch_size': 32, 'hidden_dim': 272, 'last_n_outputs': 28, 'leak_rate': 0.9053102957705226, 'lr': 0.0010397676497449595, 'optimizer': 'SGD', 'sparsity': 0.9355265855292595, 'steps_to_train': 33, 'weight_decay': 0.015830601122059283}"}}
exception: None

01:29:43 job_callback for (4, 0, 21) started
01:29:43 DISPATCHER: Trying to submit another job.
01:29:43 job_callback for (4, 0, 21) got condition
01:29:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:29:43 done building a new model for budget 44.444444 based on 10/41 split
Best loss for this budget:-0.378549





01:29:43 HBMASTER: Trying to run another job!
01:29:43 job_callback for (4, 0, 21) finished
01:29:43 start sampling a new configuration.
01:29:43 best_vector: [3, 0.9636722573238434, 0.27406976165205, 0.2496028839162092, 0.046095794977009, 1, 0.8979721995410423, 0.08886461840943716, 0.3580148225460743], 0.017649026285306797, 0.7321305964168149, 0.012921392140437709
01:29:43 done sampling a new configuration.
01:29:43 HBMASTER: schedule new run for iteration 4
01:29:43 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
01:29:43 HBMASTER: submitting job (4, 0, 22) to dispatcher
01:29:43 DISPATCHER: trying to submit job (4, 0, 22)
01:29:43 DISPATCHER: trying to notify the job_runner thread.
01:29:43 HBMASTER: job (4, 0, 22) submitted to dispatcher
01:29:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:29:43 DISPATCHER: Trying to submit another job.
01:29:43 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:29:43 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:29:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:29:43 WORKER: start processing job (4, 0, 22)
01:29:43 WORKER: args: ()
01:29:43 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 971, 'last_n_outputs': 21, 'leak_rate': 0.8124007209790522, 'lr': 0.0012364927946241528, 'optimizer': 'SGD', 'sparsity': 0.9655133278898501, 'steps_to_train': 18, 'weight_decay': 0.02922725461884117}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:30:37 DISPATCHER: Starting worker discovery
01:30:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:30:37 DISPATCHER: Finished worker discovery
01:31:29 WORKER: done with job (4, 0, 22), trying to register it.
01:31:29 WORKER: registered result for job (4, 0, 22) with dispatcher
01:31:29 DISPATCHER: job (4, 0, 22) finished
01:31:29 DISPATCHER: register_result: lock acquired
01:31:29 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:31:29 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 971, 'last_n_outputs': 21, 'leak_rate': 0.8124007209790522, 'lr': 0.0012364927946241528, 'optimizer': 'SGD', 'sparsity': 0.9655133278898501, 'steps_to_train': 18, 'weight_decay': 0.02922725461884117}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.24695548319576593, 'info': {'music_genre': 0.24695548319576593, 'config': "{'batch_size': 128, 'hidden_dim': 971, 'last_n_outputs': 21, 'leak_rate': 0.8124007209790522, 'lr': 0.0012364927946241528, 'optimizer': 'SGD', 'sparsity': 0.9655133278898501, 'steps_to_train': 18, 'weight_decay': 0.02922725461884117}"}}
exception: None

01:31:29 job_callback for (4, 0, 22) started
01:31:29 DISPATCHER: Trying to submit another job.
01:31:29 job_callback for (4, 0, 22) got condition
01:31:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:31:29 done building a new model for budget 44.444444 based on 10/42 split
Best loss for this budget:-0.378549





01:31:29 HBMASTER: Trying to run another job!
01:31:29 job_callback for (4, 0, 22) finished
01:31:29 start sampling a new configuration.
01:31:29 done sampling a new configuration.
01:31:29 HBMASTER: schedule new run for iteration 4
01:31:29 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
01:31:29 HBMASTER: submitting job (4, 0, 23) to dispatcher
01:31:29 DISPATCHER: trying to submit job (4, 0, 23)
01:31:29 DISPATCHER: trying to notify the job_runner thread.
01:31:29 HBMASTER: job (4, 0, 23) submitted to dispatcher
01:31:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:31:29 DISPATCHER: Trying to submit another job.
01:31:29 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:31:29 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:31:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:31:29 WORKER: start processing job (4, 0, 23)
01:31:29 WORKER: args: ()
01:31:29 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 711, 'last_n_outputs': 13, 'leak_rate': 0.9562355657631911, 'lr': 0.04535419689325987, 'optimizer': 'SGD', 'sparsity': 0.8181918836487843, 'steps_to_train': 88, 'weight_decay': 0.10483686219504298}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:31:37 DISPATCHER: Starting worker discovery
01:31:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:31:37 DISPATCHER: Finished worker discovery
01:32:37 DISPATCHER: Starting worker discovery
01:32:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:32:37 DISPATCHER: Finished worker discovery
01:33:27 WORKER: done with job (4, 0, 23), trying to register it.
01:33:27 WORKER: registered result for job (4, 0, 23) with dispatcher
01:33:27 DISPATCHER: job (4, 0, 23) finished
01:33:27 DISPATCHER: register_result: lock acquired
01:33:27 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:33:27 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 711, 'last_n_outputs': 13, 'leak_rate': 0.9562355657631911, 'lr': 0.04535419689325987, 'optimizer': 'SGD', 'sparsity': 0.8181918836487843, 'steps_to_train': 88, 'weight_decay': 0.10483686219504298}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.19954132622227239, 'info': {'music_genre': 0.19954132622227239, 'config': "{'batch_size': 32, 'hidden_dim': 711, 'last_n_outputs': 13, 'leak_rate': 0.9562355657631911, 'lr': 0.04535419689325987, 'optimizer': 'SGD', 'sparsity': 0.8181918836487843, 'steps_to_train': 88, 'weight_decay': 0.10483686219504298}"}}
exception: None

01:33:27 job_callback for (4, 0, 23) started
01:33:27 DISPATCHER: Trying to submit another job.
01:33:27 job_callback for (4, 0, 23) got condition
01:33:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:33:27 done building a new model for budget 44.444444 based on 10/43 split
Best loss for this budget:-0.378549





01:33:27 HBMASTER: Trying to run another job!
01:33:27 job_callback for (4, 0, 23) finished
01:33:27 start sampling a new configuration.
01:33:27 best_vector: [3, 0.23852572546624545, 0.8841283286202732, 0.8509699368042625, 0.010389407363795927, 1, 0.6883193863685079, 0.6116202208328916, 0.0864029673841929], 0.02757691306341234, 0.625405426519589, 0.01724675107651702
01:33:27 done sampling a new configuration.
01:33:27 HBMASTER: schedule new run for iteration 4
01:33:27 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
01:33:27 HBMASTER: submitting job (4, 0, 24) to dispatcher
01:33:27 DISPATCHER: trying to submit job (4, 0, 24)
01:33:27 DISPATCHER: trying to notify the job_runner thread.
01:33:27 HBMASTER: job (4, 0, 24) submitted to dispatcher
01:33:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:33:27 DISPATCHER: Trying to submit another job.
01:33:27 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:33:27 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:33:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:33:27 WORKER: start processing job (4, 0, 24)
01:33:27 WORKER: args: ()
01:33:27 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 391, 'last_n_outputs': 46, 'leak_rate': 0.9627424842010657, 'lr': 0.001049008034980207, 'optimizer': 'SGD', 'sparsity': 0.9151966527284419, 'steps_to_train': 65, 'weight_decay': 0.012954267245810171}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:33:37 DISPATCHER: Starting worker discovery
01:33:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:33:37 DISPATCHER: Finished worker discovery
01:34:37 DISPATCHER: Starting worker discovery
01:34:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:34:37 DISPATCHER: Finished worker discovery
01:35:11 WORKER: done with job (4, 0, 24), trying to register it.
01:35:11 WORKER: registered result for job (4, 0, 24) with dispatcher
01:35:11 DISPATCHER: job (4, 0, 24) finished
01:35:11 DISPATCHER: register_result: lock acquired
01:35:11 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:35:11 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 391, 'last_n_outputs': 46, 'leak_rate': 0.9627424842010657, 'lr': 0.001049008034980207, 'optimizer': 'SGD', 'sparsity': 0.9151966527284419, 'steps_to_train': 65, 'weight_decay': 0.012954267245810171}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.23911396172855742, 'info': {'music_genre': 0.23911396172855742, 'config': "{'batch_size': 128, 'hidden_dim': 391, 'last_n_outputs': 46, 'leak_rate': 0.9627424842010657, 'lr': 0.001049008034980207, 'optimizer': 'SGD', 'sparsity': 0.9151966527284419, 'steps_to_train': 65, 'weight_decay': 0.012954267245810171}"}}
exception: None

01:35:11 job_callback for (4, 0, 24) started
01:35:11 DISPATCHER: Trying to submit another job.
01:35:11 job_callback for (4, 0, 24) got condition
01:35:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:35:11 done building a new model for budget 44.444444 based on 10/44 split
Best loss for this budget:-0.378549





01:35:11 HBMASTER: Trying to run another job!
01:35:11 job_callback for (4, 0, 24) finished
01:35:11 start sampling a new configuration.
01:35:11 best_vector: [1, 0.8033535299910775, 0.7855131848843866, 0.3481682142552416, 0.9711597284114002, 1, 0.6888442894987717, 0.756719909552896, 0.1691832862497958], 0.01749975009779434, 0.6565539684543039, 0.011489530373665468
01:35:11 done sampling a new configuration.
01:35:11 HBMASTER: schedule new run for iteration 4
01:35:11 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
01:35:11 HBMASTER: submitting job (4, 0, 25) to dispatcher
01:35:11 DISPATCHER: trying to submit job (4, 0, 25)
01:35:11 DISPATCHER: trying to notify the job_runner thread.
01:35:11 HBMASTER: job (4, 0, 25) submitted to dispatcher
01:35:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:35:11 DISPATCHER: Trying to submit another job.
01:35:11 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:35:11 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:35:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:35:11 WORKER: start processing job (4, 0, 25)
01:35:11 WORKER: args: ()
01:35:11 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 843, 'last_n_outputs': 42, 'leak_rate': 0.8370420535638103, 'lr': 0.08756276295191735, 'optimizer': 'SGD', 'sparsity': 0.9153226294797052, 'steps_to_train': 78, 'weight_decay': 0.016600169792241697}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:35:37 DISPATCHER: Starting worker discovery
01:35:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:35:37 DISPATCHER: Finished worker discovery
01:36:37 DISPATCHER: Starting worker discovery
01:36:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:36:37 DISPATCHER: Finished worker discovery
01:37:03 WORKER: done with job (4, 0, 25), trying to register it.
01:37:03 WORKER: registered result for job (4, 0, 25) with dispatcher
01:37:03 DISPATCHER: job (4, 0, 25) finished
01:37:03 DISPATCHER: register_result: lock acquired
01:37:03 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:37:03 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 843, 'last_n_outputs': 42, 'leak_rate': 0.8370420535638103, 'lr': 0.08756276295191735, 'optimizer': 'SGD', 'sparsity': 0.9153226294797052, 'steps_to_train': 78, 'weight_decay': 0.016600169792241697}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.29254198735405873, 'info': {'music_genre': 0.29254198735405873, 'config': "{'batch_size': 32, 'hidden_dim': 843, 'last_n_outputs': 42, 'leak_rate': 0.8370420535638103, 'lr': 0.08756276295191735, 'optimizer': 'SGD', 'sparsity': 0.9153226294797052, 'steps_to_train': 78, 'weight_decay': 0.016600169792241697}"}}
exception: None

01:37:03 job_callback for (4, 0, 25) started
01:37:03 job_callback for (4, 0, 25) got condition
01:37:03 DISPATCHER: Trying to submit another job.
01:37:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:37:03 done building a new model for budget 44.444444 based on 10/45 split
Best loss for this budget:-0.378549





01:37:03 HBMASTER: Trying to run another job!
01:37:03 job_callback for (4, 0, 25) finished
01:37:03 start sampling a new configuration.
01:37:03 done sampling a new configuration.
01:37:03 HBMASTER: schedule new run for iteration 4
01:37:03 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
01:37:03 HBMASTER: submitting job (4, 0, 26) to dispatcher
01:37:03 DISPATCHER: trying to submit job (4, 0, 26)
01:37:03 DISPATCHER: trying to notify the job_runner thread.
01:37:03 HBMASTER: job (4, 0, 26) submitted to dispatcher
01:37:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:37:03 DISPATCHER: Trying to submit another job.
01:37:03 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:37:03 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:37:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:37:03 WORKER: start processing job (4, 0, 26)
01:37:03 WORKER: args: ()
01:37:03 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 564, 'last_n_outputs': 27, 'leak_rate': 0.7813055559333103, 'lr': 0.003692629080233394, 'optimizer': 'SGD', 'sparsity': 0.874547710476894, 'steps_to_train': 54, 'weight_decay': 0.040804041926228336}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:37:37 DISPATCHER: Starting worker discovery
01:37:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:37:37 DISPATCHER: Finished worker discovery
01:38:37 DISPATCHER: Starting worker discovery
01:38:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:38:37 DISPATCHER: Finished worker discovery
01:38:53 WORKER: done with job (4, 0, 26), trying to register it.
01:38:53 WORKER: registered result for job (4, 0, 26) with dispatcher
01:38:53 DISPATCHER: job (4, 0, 26) finished
01:38:53 DISPATCHER: register_result: lock acquired
01:38:53 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:38:53 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 564, 'last_n_outputs': 27, 'leak_rate': 0.7813055559333103, 'lr': 0.003692629080233394, 'optimizer': 'SGD', 'sparsity': 0.874547710476894, 'steps_to_train': 54, 'weight_decay': 0.040804041926228336}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2703301791863519, 'info': {'music_genre': 0.2703301791863519, 'config': "{'batch_size': 16, 'hidden_dim': 564, 'last_n_outputs': 27, 'leak_rate': 0.7813055559333103, 'lr': 0.003692629080233394, 'optimizer': 'SGD', 'sparsity': 0.874547710476894, 'steps_to_train': 54, 'weight_decay': 0.040804041926228336}"}}
exception: None

01:38:53 job_callback for (4, 0, 26) started
01:38:53 DISPATCHER: Trying to submit another job.
01:38:53 job_callback for (4, 0, 26) got condition
01:38:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:38:53 done building a new model for budget 44.444444 based on 10/45 split
Best loss for this budget:-0.378549





01:38:53 HBMASTER: Trying to run another job!
01:38:53 job_callback for (4, 0, 26) finished
01:38:53 ITERATION: Advancing config (4, 0, 3) to next budget 133.333333
01:38:53 ITERATION: Advancing config (4, 0, 6) to next budget 133.333333
01:38:53 ITERATION: Advancing config (4, 0, 9) to next budget 133.333333
01:38:53 ITERATION: Advancing config (4, 0, 11) to next budget 133.333333
01:38:53 ITERATION: Advancing config (4, 0, 15) to next budget 133.333333
01:38:53 ITERATION: Advancing config (4, 0, 16) to next budget 133.333333
01:38:53 ITERATION: Advancing config (4, 0, 17) to next budget 133.333333
01:38:53 ITERATION: Advancing config (4, 0, 18) to next budget 133.333333
01:38:53 ITERATION: Advancing config (4, 0, 25) to next budget 133.333333
01:38:53 HBMASTER: schedule new run for iteration 4
01:38:53 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
01:38:53 HBMASTER: submitting job (4, 0, 3) to dispatcher
01:38:53 DISPATCHER: trying to submit job (4, 0, 3)
01:38:53 DISPATCHER: trying to notify the job_runner thread.
01:38:53 HBMASTER: job (4, 0, 3) submitted to dispatcher
01:38:53 DISPATCHER: Trying to submit another job.
01:38:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:38:53 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:38:53 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:38:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:38:53 WORKER: start processing job (4, 0, 3)
01:38:53 WORKER: args: ()
01:38:53 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 856, 'last_n_outputs': 12, 'leak_rate': 0.8504759452038728, 'lr': 0.004648324218496446, 'optimizer': 'SGD', 'sparsity': 0.9738474164460345, 'steps_to_train': 11, 'weight_decay': 0.02419699808368557}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:39:37 DISPATCHER: Starting worker discovery
01:39:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:39:37 DISPATCHER: Finished worker discovery
01:40:37 DISPATCHER: Starting worker discovery
01:40:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:40:37 DISPATCHER: Finished worker discovery
01:41:37 DISPATCHER: Starting worker discovery
01:41:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:41:37 DISPATCHER: Finished worker discovery
01:42:08 WORKER: done with job (4, 0, 3), trying to register it.
01:42:08 WORKER: registered result for job (4, 0, 3) with dispatcher
01:42:08 DISPATCHER: job (4, 0, 3) finished
01:42:08 DISPATCHER: register_result: lock acquired
01:42:08 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:42:08 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 856, 'last_n_outputs': 12, 'leak_rate': 0.8504759452038728, 'lr': 0.004648324218496446, 'optimizer': 'SGD', 'sparsity': 0.9738474164460345, 'steps_to_train': 11, 'weight_decay': 0.02419699808368557}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3073593611686817, 'info': {'music_genre': 0.3073593611686817, 'config': "{'batch_size': 64, 'hidden_dim': 856, 'last_n_outputs': 12, 'leak_rate': 0.8504759452038728, 'lr': 0.004648324218496446, 'optimizer': 'SGD', 'sparsity': 0.9738474164460345, 'steps_to_train': 11, 'weight_decay': 0.02419699808368557}"}}
exception: None

01:42:08 job_callback for (4, 0, 3) started
01:42:08 DISPATCHER: Trying to submit another job.
01:42:08 job_callback for (4, 0, 3) got condition
01:42:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:42:08 HBMASTER: Trying to run another job!
01:42:08 job_callback for (4, 0, 3) finished
01:42:08 HBMASTER: schedule new run for iteration 4
01:42:08 HBMASTER: trying submitting job (4, 0, 6) to dispatcher
01:42:08 HBMASTER: submitting job (4, 0, 6) to dispatcher
01:42:08 DISPATCHER: trying to submit job (4, 0, 6)
01:42:08 DISPATCHER: trying to notify the job_runner thread.
01:42:08 HBMASTER: job (4, 0, 6) submitted to dispatcher
01:42:08 DISPATCHER: Trying to submit another job.
01:42:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:42:08 DISPATCHER: starting job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:42:08 DISPATCHER: job (4, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:42:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:42:08 WORKER: start processing job (4, 0, 6)
01:42:08 WORKER: args: ()
01:42:08 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 356, 'last_n_outputs': 45, 'leak_rate': 0.8494424396865378, 'lr': 0.0015801709836036192, 'optimizer': 'Adam', 'sparsity': 0.9427932570437128, 'steps_to_train': 20, 'weight_decay': 0.013645362702030513}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:42:37 DISPATCHER: Starting worker discovery
01:42:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:42:37 DISPATCHER: Finished worker discovery
01:43:37 DISPATCHER: Starting worker discovery
01:43:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:43:37 DISPATCHER: Finished worker discovery
01:44:37 DISPATCHER: Starting worker discovery
01:44:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:44:37 DISPATCHER: Finished worker discovery
01:45:20 WORKER: done with job (4, 0, 6), trying to register it.
01:45:20 WORKER: registered result for job (4, 0, 6) with dispatcher
01:45:20 DISPATCHER: job (4, 0, 6) finished
01:45:20 DISPATCHER: register_result: lock acquired
01:45:20 DISPATCHER: job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:45:20 job_id: (4, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 356, 'last_n_outputs': 45, 'leak_rate': 0.8494424396865378, 'lr': 0.0015801709836036192, 'optimizer': 'Adam', 'sparsity': 0.9427932570437128, 'steps_to_train': 20, 'weight_decay': 0.013645362702030513}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.32559883780343135, 'info': {'music_genre': 0.32559883780343135, 'config': "{'batch_size': 128, 'hidden_dim': 356, 'last_n_outputs': 45, 'leak_rate': 0.8494424396865378, 'lr': 0.0015801709836036192, 'optimizer': 'Adam', 'sparsity': 0.9427932570437128, 'steps_to_train': 20, 'weight_decay': 0.013645362702030513}"}}
exception: None

01:45:20 job_callback for (4, 0, 6) started
01:45:20 DISPATCHER: Trying to submit another job.
01:45:20 job_callback for (4, 0, 6) got condition
01:45:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:45:20 done building a new model for budget 133.333333 based on 10/17 split
Best loss for this budget:-0.392205





01:45:20 HBMASTER: Trying to run another job!
01:45:20 job_callback for (4, 0, 6) finished
01:45:20 HBMASTER: schedule new run for iteration 4
01:45:20 HBMASTER: trying submitting job (4, 0, 9) to dispatcher
01:45:20 HBMASTER: submitting job (4, 0, 9) to dispatcher
01:45:20 DISPATCHER: trying to submit job (4, 0, 9)
01:45:20 DISPATCHER: trying to notify the job_runner thread.
01:45:20 HBMASTER: job (4, 0, 9) submitted to dispatcher
01:45:20 DISPATCHER: Trying to submit another job.
01:45:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:45:20 DISPATCHER: starting job (4, 0, 9) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:45:20 DISPATCHER: job (4, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:45:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:45:20 WORKER: start processing job (4, 0, 9)
01:45:20 WORKER: args: ()
01:45:20 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 711, 'last_n_outputs': 50, 'leak_rate': 0.7605321265515863, 'lr': 0.010825786793534508, 'optimizer': 'SGD', 'sparsity': 0.9194862237136601, 'steps_to_train': 38, 'weight_decay': 0.012322371315049593}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:45:37 DISPATCHER: Starting worker discovery
01:45:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:45:37 DISPATCHER: Finished worker discovery
01:46:37 DISPATCHER: Starting worker discovery
01:46:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:46:37 DISPATCHER: Finished worker discovery
01:47:37 DISPATCHER: Starting worker discovery
01:47:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:47:37 DISPATCHER: Finished worker discovery
01:48:35 WORKER: done with job (4, 0, 9), trying to register it.
01:48:35 WORKER: registered result for job (4, 0, 9) with dispatcher
01:48:35 DISPATCHER: job (4, 0, 9) finished
01:48:35 DISPATCHER: register_result: lock acquired
01:48:35 DISPATCHER: job (4, 0, 9) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:48:35 job_id: (4, 0, 9)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 711, 'last_n_outputs': 50, 'leak_rate': 0.7605321265515863, 'lr': 0.010825786793534508, 'optimizer': 'SGD', 'sparsity': 0.9194862237136601, 'steps_to_train': 38, 'weight_decay': 0.012322371315049593}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.38705098174044156, 'info': {'music_genre': 0.38705098174044156, 'config': "{'batch_size': 128, 'hidden_dim': 711, 'last_n_outputs': 50, 'leak_rate': 0.7605321265515863, 'lr': 0.010825786793534508, 'optimizer': 'SGD', 'sparsity': 0.9194862237136601, 'steps_to_train': 38, 'weight_decay': 0.012322371315049593}"}}
exception: None

01:48:35 job_callback for (4, 0, 9) started
01:48:35 DISPATCHER: Trying to submit another job.
01:48:35 job_callback for (4, 0, 9) got condition
01:48:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:48:35 done building a new model for budget 133.333333 based on 10/17 split
Best loss for this budget:-0.392205





01:48:35 HBMASTER: Trying to run another job!
01:48:35 job_callback for (4, 0, 9) finished
01:48:35 HBMASTER: schedule new run for iteration 4
01:48:35 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
01:48:35 HBMASTER: submitting job (4, 0, 11) to dispatcher
01:48:35 DISPATCHER: trying to submit job (4, 0, 11)
01:48:35 DISPATCHER: trying to notify the job_runner thread.
01:48:35 HBMASTER: job (4, 0, 11) submitted to dispatcher
01:48:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:48:35 DISPATCHER: Trying to submit another job.
01:48:35 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:48:35 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:48:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:48:35 WORKER: start processing job (4, 0, 11)
01:48:35 WORKER: args: ()
01:48:35 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 956, 'last_n_outputs': 45, 'leak_rate': 0.7810636305733409, 'lr': 0.0014644300743280043, 'optimizer': 'SGD', 'sparsity': 0.864962534418833, 'steps_to_train': 53, 'weight_decay': 0.013142334213420988}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:48:37 DISPATCHER: Starting worker discovery
01:48:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:48:37 DISPATCHER: Finished worker discovery
01:49:37 DISPATCHER: Starting worker discovery
01:49:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:49:37 DISPATCHER: Finished worker discovery
01:50:37 DISPATCHER: Starting worker discovery
01:50:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:50:37 DISPATCHER: Finished worker discovery
01:51:37 DISPATCHER: Starting worker discovery
01:51:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:51:37 DISPATCHER: Finished worker discovery
01:51:52 WORKER: done with job (4, 0, 11), trying to register it.
01:51:52 WORKER: registered result for job (4, 0, 11) with dispatcher
01:51:52 DISPATCHER: job (4, 0, 11) finished
01:51:52 DISPATCHER: register_result: lock acquired
01:51:52 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:51:52 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 956, 'last_n_outputs': 45, 'leak_rate': 0.7810636305733409, 'lr': 0.0014644300743280043, 'optimizer': 'SGD', 'sparsity': 0.864962534418833, 'steps_to_train': 53, 'weight_decay': 0.013142334213420988}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3565113932735652, 'info': {'music_genre': 0.3565113932735652, 'config': "{'batch_size': 16, 'hidden_dim': 956, 'last_n_outputs': 45, 'leak_rate': 0.7810636305733409, 'lr': 0.0014644300743280043, 'optimizer': 'SGD', 'sparsity': 0.864962534418833, 'steps_to_train': 53, 'weight_decay': 0.013142334213420988}"}}
exception: None

01:51:52 job_callback for (4, 0, 11) started
01:51:52 DISPATCHER: Trying to submit another job.
01:51:52 job_callback for (4, 0, 11) got condition
01:51:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:51:52 done building a new model for budget 133.333333 based on 10/18 split
Best loss for this budget:-0.392205





01:51:52 HBMASTER: Trying to run another job!
01:51:52 job_callback for (4, 0, 11) finished
01:51:52 HBMASTER: schedule new run for iteration 4
01:51:52 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
01:51:52 HBMASTER: submitting job (4, 0, 15) to dispatcher
01:51:52 DISPATCHER: trying to submit job (4, 0, 15)
01:51:52 DISPATCHER: trying to notify the job_runner thread.
01:51:52 HBMASTER: job (4, 0, 15) submitted to dispatcher
01:51:52 DISPATCHER: Trying to submit another job.
01:51:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:51:52 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:51:52 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:51:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:51:52 WORKER: start processing job (4, 0, 15)
01:51:52 WORKER: args: ()
01:51:52 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 448, 'last_n_outputs': 45, 'leak_rate': 0.8612925233003516, 'lr': 0.001748440958837722, 'optimizer': 'SGD', 'sparsity': 0.9188996498418452, 'steps_to_train': 78, 'weight_decay': 0.011461818387758907}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:52:37 DISPATCHER: Starting worker discovery
01:52:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:52:37 DISPATCHER: Finished worker discovery
01:53:37 DISPATCHER: Starting worker discovery
01:53:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:53:37 DISPATCHER: Finished worker discovery
01:54:37 DISPATCHER: Starting worker discovery
01:54:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:54:37 DISPATCHER: Finished worker discovery
01:55:05 WORKER: done with job (4, 0, 15), trying to register it.
01:55:05 WORKER: registered result for job (4, 0, 15) with dispatcher
01:55:05 DISPATCHER: job (4, 0, 15) finished
01:55:05 DISPATCHER: register_result: lock acquired
01:55:05 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:55:05 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 448, 'last_n_outputs': 45, 'leak_rate': 0.8612925233003516, 'lr': 0.001748440958837722, 'optimizer': 'SGD', 'sparsity': 0.9188996498418452, 'steps_to_train': 78, 'weight_decay': 0.011461818387758907}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.37151773858569925, 'info': {'music_genre': 0.37151773858569925, 'config': "{'batch_size': 128, 'hidden_dim': 448, 'last_n_outputs': 45, 'leak_rate': 0.8612925233003516, 'lr': 0.001748440958837722, 'optimizer': 'SGD', 'sparsity': 0.9188996498418452, 'steps_to_train': 78, 'weight_decay': 0.011461818387758907}"}}
exception: None

01:55:05 job_callback for (4, 0, 15) started
01:55:05 DISPATCHER: Trying to submit another job.
01:55:05 job_callback for (4, 0, 15) got condition
01:55:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:55:05 done building a new model for budget 133.333333 based on 10/19 split
Best loss for this budget:-0.392205





01:55:05 HBMASTER: Trying to run another job!
01:55:05 job_callback for (4, 0, 15) finished
01:55:05 HBMASTER: schedule new run for iteration 4
01:55:05 HBMASTER: trying submitting job (4, 0, 16) to dispatcher
01:55:05 HBMASTER: submitting job (4, 0, 16) to dispatcher
01:55:05 DISPATCHER: trying to submit job (4, 0, 16)
01:55:05 DISPATCHER: trying to notify the job_runner thread.
01:55:05 HBMASTER: job (4, 0, 16) submitted to dispatcher
01:55:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:55:05 DISPATCHER: Trying to submit another job.
01:55:05 DISPATCHER: starting job (4, 0, 16) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:55:05 DISPATCHER: job (4, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:55:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:55:05 WORKER: start processing job (4, 0, 16)
01:55:05 WORKER: args: ()
01:55:05 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 829, 'last_n_outputs': 33, 'leak_rate': 0.797093132545339, 'lr': 0.02764135342655125, 'optimizer': 'SGD', 'sparsity': 0.9105711944288654, 'steps_to_train': 43, 'weight_decay': 0.017389942314333454}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:55:37 DISPATCHER: Starting worker discovery
01:55:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:55:37 DISPATCHER: Finished worker discovery
01:56:37 DISPATCHER: Starting worker discovery
01:56:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:56:37 DISPATCHER: Finished worker discovery
01:57:37 DISPATCHER: Starting worker discovery
01:57:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:57:37 DISPATCHER: Finished worker discovery
01:58:25 WORKER: done with job (4, 0, 16), trying to register it.
01:58:25 WORKER: registered result for job (4, 0, 16) with dispatcher
01:58:25 DISPATCHER: job (4, 0, 16) finished
01:58:25 DISPATCHER: register_result: lock acquired
01:58:25 DISPATCHER: job (4, 0, 16) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:58:25 job_id: (4, 0, 16)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 829, 'last_n_outputs': 33, 'leak_rate': 0.797093132545339, 'lr': 0.02764135342655125, 'optimizer': 'SGD', 'sparsity': 0.9105711944288654, 'steps_to_train': 43, 'weight_decay': 0.017389942314333454}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.339108714089164, 'info': {'music_genre': 0.339108714089164, 'config': "{'batch_size': 128, 'hidden_dim': 829, 'last_n_outputs': 33, 'leak_rate': 0.797093132545339, 'lr': 0.02764135342655125, 'optimizer': 'SGD', 'sparsity': 0.9105711944288654, 'steps_to_train': 43, 'weight_decay': 0.017389942314333454}"}}
exception: None

01:58:25 job_callback for (4, 0, 16) started
01:58:25 job_callback for (4, 0, 16) got condition
01:58:25 DISPATCHER: Trying to submit another job.
01:58:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:58:25 done building a new model for budget 133.333333 based on 10/20 split
Best loss for this budget:-0.392205





01:58:25 HBMASTER: Trying to run another job!
01:58:25 job_callback for (4, 0, 16) finished
01:58:25 HBMASTER: schedule new run for iteration 4
01:58:25 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
01:58:25 HBMASTER: submitting job (4, 0, 17) to dispatcher
01:58:25 DISPATCHER: trying to submit job (4, 0, 17)
01:58:25 DISPATCHER: trying to notify the job_runner thread.
01:58:25 HBMASTER: job (4, 0, 17) submitted to dispatcher
01:58:25 DISPATCHER: Trying to submit another job.
01:58:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:58:25 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:58:25 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:58:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:58:25 WORKER: start processing job (4, 0, 17)
01:58:25 WORKER: args: ()
01:58:25 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 433, 'last_n_outputs': 41, 'leak_rate': 0.8460679205439984, 'lr': 0.007208677035872156, 'optimizer': 'SGD', 'sparsity': 0.8919392898777779, 'steps_to_train': 52, 'weight_decay': 0.023122919853463292}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:58:37 DISPATCHER: Starting worker discovery
01:58:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:58:37 DISPATCHER: Finished worker discovery
01:59:37 DISPATCHER: Starting worker discovery
01:59:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:59:37 DISPATCHER: Finished worker discovery
02:00:37 DISPATCHER: Starting worker discovery
02:00:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:00:37 DISPATCHER: Finished worker discovery
02:01:37 DISPATCHER: Starting worker discovery
02:01:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:01:37 DISPATCHER: Finished worker discovery
02:01:44 WORKER: done with job (4, 0, 17), trying to register it.
02:01:44 WORKER: registered result for job (4, 0, 17) with dispatcher
02:01:45 DISPATCHER: job (4, 0, 17) finished
02:01:45 DISPATCHER: register_result: lock acquired
02:01:45 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
02:01:45 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 433, 'last_n_outputs': 41, 'leak_rate': 0.8460679205439984, 'lr': 0.007208677035872156, 'optimizer': 'SGD', 'sparsity': 0.8919392898777779, 'steps_to_train': 52, 'weight_decay': 0.023122919853463292}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.322685147875844, 'info': {'music_genre': 0.322685147875844, 'config': "{'batch_size': 64, 'hidden_dim': 433, 'last_n_outputs': 41, 'leak_rate': 0.8460679205439984, 'lr': 0.007208677035872156, 'optimizer': 'SGD', 'sparsity': 0.8919392898777779, 'steps_to_train': 52, 'weight_decay': 0.023122919853463292}"}}
exception: None

02:01:45 job_callback for (4, 0, 17) started
02:01:45 DISPATCHER: Trying to submit another job.
02:01:45 job_callback for (4, 0, 17) got condition
02:01:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:01:45 done building a new model for budget 133.333333 based on 10/21 split
Best loss for this budget:-0.392205





02:01:45 HBMASTER: Trying to run another job!
02:01:45 job_callback for (4, 0, 17) finished
02:01:45 HBMASTER: schedule new run for iteration 4
02:01:45 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
02:01:45 HBMASTER: submitting job (4, 0, 18) to dispatcher
02:01:45 DISPATCHER: trying to submit job (4, 0, 18)
02:01:45 DISPATCHER: trying to notify the job_runner thread.
02:01:45 HBMASTER: job (4, 0, 18) submitted to dispatcher
02:01:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:01:45 DISPATCHER: Trying to submit another job.
02:01:45 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:01:45 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:01:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:01:45 WORKER: start processing job (4, 0, 18)
02:01:45 WORKER: args: ()
02:01:45 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 898, 'last_n_outputs': 48, 'leak_rate': 0.8679685375849485, 'lr': 0.03309498838905841, 'optimizer': 'SGD', 'sparsity': 0.9109456087301672, 'steps_to_train': 20, 'weight_decay': 0.019761232421341486}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:02:37 DISPATCHER: Starting worker discovery
02:02:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:02:37 DISPATCHER: Finished worker discovery
02:03:37 DISPATCHER: Starting worker discovery
02:03:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:03:37 DISPATCHER: Finished worker discovery
02:04:37 DISPATCHER: Starting worker discovery
02:04:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:04:37 DISPATCHER: Finished worker discovery
02:04:58 WORKER: done with job (4, 0, 18), trying to register it.
02:04:58 WORKER: registered result for job (4, 0, 18) with dispatcher
02:04:58 DISPATCHER: job (4, 0, 18) finished
02:04:58 DISPATCHER: register_result: lock acquired
02:04:58 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
02:04:58 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 898, 'last_n_outputs': 48, 'leak_rate': 0.8679685375849485, 'lr': 0.03309498838905841, 'optimizer': 'SGD', 'sparsity': 0.9109456087301672, 'steps_to_train': 20, 'weight_decay': 0.019761232421341486}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3519032378460658, 'info': {'music_genre': 0.3519032378460658, 'config': "{'batch_size': 128, 'hidden_dim': 898, 'last_n_outputs': 48, 'leak_rate': 0.8679685375849485, 'lr': 0.03309498838905841, 'optimizer': 'SGD', 'sparsity': 0.9109456087301672, 'steps_to_train': 20, 'weight_decay': 0.019761232421341486}"}}
exception: None

02:04:58 job_callback for (4, 0, 18) started
02:04:58 DISPATCHER: Trying to submit another job.
02:04:58 job_callback for (4, 0, 18) got condition
02:04:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:04:58 done building a new model for budget 133.333333 based on 10/22 split
Best loss for this budget:-0.392205





02:04:58 HBMASTER: Trying to run another job!
02:04:58 job_callback for (4, 0, 18) finished
02:04:58 HBMASTER: schedule new run for iteration 4
02:04:58 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
02:04:58 HBMASTER: submitting job (4, 0, 25) to dispatcher
02:04:58 DISPATCHER: trying to submit job (4, 0, 25)
02:04:58 DISPATCHER: trying to notify the job_runner thread.
02:04:58 HBMASTER: job (4, 0, 25) submitted to dispatcher
02:04:58 DISPATCHER: Trying to submit another job.
02:04:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:04:58 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:04:58 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:04:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:04:58 WORKER: start processing job (4, 0, 25)
02:04:58 WORKER: args: ()
02:04:58 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 843, 'last_n_outputs': 42, 'leak_rate': 0.8370420535638103, 'lr': 0.08756276295191735, 'optimizer': 'SGD', 'sparsity': 0.9153226294797052, 'steps_to_train': 78, 'weight_decay': 0.016600169792241697}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:05:37 DISPATCHER: Starting worker discovery
02:05:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:05:38 DISPATCHER: Finished worker discovery
02:06:38 DISPATCHER: Starting worker discovery
02:06:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:06:38 DISPATCHER: Finished worker discovery
02:07:38 DISPATCHER: Starting worker discovery
02:07:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:07:38 DISPATCHER: Finished worker discovery
02:08:14 WORKER: done with job (4, 0, 25), trying to register it.
02:08:14 WORKER: registered result for job (4, 0, 25) with dispatcher
02:08:14 DISPATCHER: job (4, 0, 25) finished
02:08:14 DISPATCHER: register_result: lock acquired
02:08:14 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
02:08:14 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 843, 'last_n_outputs': 42, 'leak_rate': 0.8370420535638103, 'lr': 0.08756276295191735, 'optimizer': 'SGD', 'sparsity': 0.9153226294797052, 'steps_to_train': 78, 'weight_decay': 0.016600169792241697}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2960251598421735, 'info': {'music_genre': 0.2960251598421735, 'config': "{'batch_size': 32, 'hidden_dim': 843, 'last_n_outputs': 42, 'leak_rate': 0.8370420535638103, 'lr': 0.08756276295191735, 'optimizer': 'SGD', 'sparsity': 0.9153226294797052, 'steps_to_train': 78, 'weight_decay': 0.016600169792241697}"}}
exception: None

02:08:14 job_callback for (4, 0, 25) started
02:08:14 DISPATCHER: Trying to submit another job.
02:08:14 job_callback for (4, 0, 25) got condition
02:08:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:08:14 done building a new model for budget 133.333333 based on 10/22 split
Best loss for this budget:-0.392205





02:08:14 HBMASTER: Trying to run another job!
02:08:14 job_callback for (4, 0, 25) finished
02:08:14 ITERATION: Advancing config (4, 0, 9) to next budget 400.000000
02:08:14 ITERATION: Advancing config (4, 0, 11) to next budget 400.000000
02:08:14 ITERATION: Advancing config (4, 0, 15) to next budget 400.000000
02:08:14 HBMASTER: schedule new run for iteration 4
02:08:14 HBMASTER: trying submitting job (4, 0, 9) to dispatcher
02:08:14 HBMASTER: submitting job (4, 0, 9) to dispatcher
02:08:14 DISPATCHER: trying to submit job (4, 0, 9)
02:08:14 DISPATCHER: trying to notify the job_runner thread.
02:08:14 HBMASTER: job (4, 0, 9) submitted to dispatcher
02:08:14 DISPATCHER: Trying to submit another job.
02:08:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:08:14 DISPATCHER: starting job (4, 0, 9) on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:08:14 DISPATCHER: job (4, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:08:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:08:14 WORKER: start processing job (4, 0, 9)
02:08:14 WORKER: args: ()
02:08:14 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 711, 'last_n_outputs': 50, 'leak_rate': 0.7605321265515863, 'lr': 0.010825786793534508, 'optimizer': 'SGD', 'sparsity': 0.9194862237136601, 'steps_to_train': 38, 'weight_decay': 0.012322371315049593}, 'budget': 400.0, 'working_directory': '.'}
02:08:38 DISPATCHER: Starting worker discovery
02:08:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:08:38 DISPATCHER: Finished worker discovery
02:09:38 DISPATCHER: Starting worker discovery
02:09:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:09:38 DISPATCHER: Finished worker discovery
02:10:38 DISPATCHER: Starting worker discovery
02:10:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:10:38 DISPATCHER: Finished worker discovery
02:11:38 DISPATCHER: Starting worker discovery
02:11:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:11:38 DISPATCHER: Finished worker discovery
02:12:38 DISPATCHER: Starting worker discovery
02:12:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:12:38 DISPATCHER: Finished worker discovery
02:13:38 DISPATCHER: Starting worker discovery
02:13:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:13:38 DISPATCHER: Finished worker discovery
02:14:38 DISPATCHER: Starting worker discovery
02:14:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:14:38 DISPATCHER: Finished worker discovery
02:15:38 DISPATCHER: Starting worker discovery
02:15:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:15:38 DISPATCHER: Finished worker discovery
02:16:00 WORKER: done with job (4, 0, 9), trying to register it.
02:16:00 WORKER: registered result for job (4, 0, 9) with dispatcher
02:16:00 DISPATCHER: job (4, 0, 9) finished
02:16:00 DISPATCHER: register_result: lock acquired
02:16:00 DISPATCHER: job (4, 0, 9) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
02:16:00 job_id: (4, 0, 9)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 711, 'last_n_outputs': 50, 'leak_rate': 0.7605321265515863, 'lr': 0.010825786793534508, 'optimizer': 'SGD', 'sparsity': 0.9194862237136601, 'steps_to_train': 38, 'weight_decay': 0.012322371315049593}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3701091859848158, 'info': {'music_genre': 0.3701091859848158, 'config': "{'batch_size': 128, 'hidden_dim': 711, 'last_n_outputs': 50, 'leak_rate': 0.7605321265515863, 'lr': 0.010825786793534508, 'optimizer': 'SGD', 'sparsity': 0.9194862237136601, 'steps_to_train': 38, 'weight_decay': 0.012322371315049593}"}}
exception: None

02:16:00 job_callback for (4, 0, 9) started
02:16:00 job_callback for (4, 0, 9) got condition
02:16:00 DISPATCHER: Trying to submit another job.
02:16:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:16:00 HBMASTER: Trying to run another job!
02:16:00 job_callback for (4, 0, 9) finished
02:16:00 HBMASTER: schedule new run for iteration 4
02:16:00 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
02:16:00 HBMASTER: submitting job (4, 0, 11) to dispatcher
02:16:00 DISPATCHER: trying to submit job (4, 0, 11)
02:16:00 DISPATCHER: trying to notify the job_runner thread.
02:16:00 HBMASTER: job (4, 0, 11) submitted to dispatcher
02:16:00 DISPATCHER: Trying to submit another job.
02:16:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:16:00 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:16:00 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:16:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:16:00 WORKER: start processing job (4, 0, 11)
02:16:00 WORKER: args: ()
02:16:00 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 956, 'last_n_outputs': 45, 'leak_rate': 0.7810636305733409, 'lr': 0.0014644300743280043, 'optimizer': 'SGD', 'sparsity': 0.864962534418833, 'steps_to_train': 53, 'weight_decay': 0.013142334213420988}, 'budget': 400.0, 'working_directory': '.'}
02:16:38 DISPATCHER: Starting worker discovery
02:16:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:16:38 DISPATCHER: Finished worker discovery
02:17:38 DISPATCHER: Starting worker discovery
02:17:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:17:38 DISPATCHER: Finished worker discovery
02:18:38 DISPATCHER: Starting worker discovery
02:18:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:18:38 DISPATCHER: Finished worker discovery
02:19:38 DISPATCHER: Starting worker discovery
02:19:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:19:38 DISPATCHER: Finished worker discovery
02:20:38 DISPATCHER: Starting worker discovery
02:20:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:20:38 DISPATCHER: Finished worker discovery
02:21:38 DISPATCHER: Starting worker discovery
02:21:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:21:38 DISPATCHER: Finished worker discovery
02:22:38 DISPATCHER: Starting worker discovery
02:22:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:22:38 DISPATCHER: Finished worker discovery
02:23:38 DISPATCHER: Starting worker discovery
02:23:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:23:38 DISPATCHER: Finished worker discovery
02:23:46 WORKER: done with job (4, 0, 11), trying to register it.
02:23:46 WORKER: registered result for job (4, 0, 11) with dispatcher
02:23:46 DISPATCHER: job (4, 0, 11) finished
02:23:46 DISPATCHER: register_result: lock acquired
02:23:46 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
02:23:46 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 956, 'last_n_outputs': 45, 'leak_rate': 0.7810636305733409, 'lr': 0.0014644300743280043, 'optimizer': 'SGD', 'sparsity': 0.864962534418833, 'steps_to_train': 53, 'weight_decay': 0.013142334213420988}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3538882293010037, 'info': {'music_genre': 0.3538882293010037, 'config': "{'batch_size': 16, 'hidden_dim': 956, 'last_n_outputs': 45, 'leak_rate': 0.7810636305733409, 'lr': 0.0014644300743280043, 'optimizer': 'SGD', 'sparsity': 0.864962534418833, 'steps_to_train': 53, 'weight_decay': 0.013142334213420988}"}}
exception: None

02:23:46 job_callback for (4, 0, 11) started
02:23:46 DISPATCHER: Trying to submit another job.
02:23:46 job_callback for (4, 0, 11) got condition
02:23:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:23:46 HBMASTER: Trying to run another job!
02:23:46 job_callback for (4, 0, 11) finished
02:23:46 HBMASTER: schedule new run for iteration 4
02:23:46 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
02:23:46 HBMASTER: submitting job (4, 0, 15) to dispatcher
02:23:46 DISPATCHER: trying to submit job (4, 0, 15)
02:23:46 DISPATCHER: trying to notify the job_runner thread.
02:23:46 HBMASTER: job (4, 0, 15) submitted to dispatcher
02:23:46 DISPATCHER: Trying to submit another job.
02:23:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:23:46 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:23:46 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:23:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:23:46 WORKER: start processing job (4, 0, 15)
02:23:46 WORKER: args: ()
02:23:46 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 448, 'last_n_outputs': 45, 'leak_rate': 0.8612925233003516, 'lr': 0.001748440958837722, 'optimizer': 'SGD', 'sparsity': 0.9188996498418452, 'steps_to_train': 78, 'weight_decay': 0.011461818387758907}, 'budget': 400.0, 'working_directory': '.'}
02:24:38 DISPATCHER: Starting worker discovery
02:24:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:24:38 DISPATCHER: Finished worker discovery
02:25:38 DISPATCHER: Starting worker discovery
02:25:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:25:38 DISPATCHER: Finished worker discovery
02:26:38 DISPATCHER: Starting worker discovery
02:26:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:26:38 DISPATCHER: Finished worker discovery
02:27:38 DISPATCHER: Starting worker discovery
02:27:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:27:38 DISPATCHER: Finished worker discovery
02:28:38 DISPATCHER: Starting worker discovery
02:28:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:28:38 DISPATCHER: Finished worker discovery
02:29:38 DISPATCHER: Starting worker discovery
02:29:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:29:38 DISPATCHER: Finished worker discovery
02:30:38 DISPATCHER: Starting worker discovery
02:30:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:30:38 DISPATCHER: Finished worker discovery
02:31:24 WORKER: done with job (4, 0, 15), trying to register it.
02:31:24 WORKER: registered result for job (4, 0, 15) with dispatcher
02:31:24 DISPATCHER: job (4, 0, 15) finished
02:31:24 DISPATCHER: register_result: lock acquired
02:31:24 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
02:31:24 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 448, 'last_n_outputs': 45, 'leak_rate': 0.8612925233003516, 'lr': 0.001748440958837722, 'optimizer': 'SGD', 'sparsity': 0.9188996498418452, 'steps_to_train': 78, 'weight_decay': 0.011461818387758907}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.35841485636018144, 'info': {'music_genre': 0.35841485636018144, 'config': "{'batch_size': 128, 'hidden_dim': 448, 'last_n_outputs': 45, 'leak_rate': 0.8612925233003516, 'lr': 0.001748440958837722, 'optimizer': 'SGD', 'sparsity': 0.9188996498418452, 'steps_to_train': 78, 'weight_decay': 0.011461818387758907}"}}
exception: None

02:31:24 job_callback for (4, 0, 15) started
02:31:24 DISPATCHER: Trying to submit another job.
02:31:24 job_callback for (4, 0, 15) got condition
02:31:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:31:24 HBMASTER: Trying to run another job!
02:31:24 job_callback for (4, 0, 15) finished
02:31:24 ITERATION: Advancing config (4, 0, 9) to next budget 1200.000000
02:31:24 HBMASTER: schedule new run for iteration 4
02:31:24 HBMASTER: trying submitting job (4, 0, 9) to dispatcher
02:31:24 HBMASTER: submitting job (4, 0, 9) to dispatcher
02:31:24 DISPATCHER: trying to submit job (4, 0, 9)
02:31:24 DISPATCHER: trying to notify the job_runner thread.
02:31:24 HBMASTER: job (4, 0, 9) submitted to dispatcher
02:31:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:31:24 DISPATCHER: Trying to submit another job.
02:31:24 DISPATCHER: starting job (4, 0, 9) on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:31:24 DISPATCHER: job (4, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:31:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:31:24 WORKER: start processing job (4, 0, 9)
02:31:24 WORKER: args: ()
02:31:24 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 711, 'last_n_outputs': 50, 'leak_rate': 0.7605321265515863, 'lr': 0.010825786793534508, 'optimizer': 'SGD', 'sparsity': 0.9194862237136601, 'steps_to_train': 38, 'weight_decay': 0.012322371315049593}, 'budget': 1200.0, 'working_directory': '.'}
02:31:38 DISPATCHER: Starting worker discovery
02:31:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:31:38 DISPATCHER: Finished worker discovery
02:32:38 DISPATCHER: Starting worker discovery
02:32:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:32:38 DISPATCHER: Finished worker discovery
02:33:38 DISPATCHER: Starting worker discovery
02:33:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:33:38 DISPATCHER: Finished worker discovery
02:34:38 DISPATCHER: Starting worker discovery
02:34:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:34:38 DISPATCHER: Finished worker discovery
02:35:38 DISPATCHER: Starting worker discovery
02:35:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:35:38 DISPATCHER: Finished worker discovery
02:36:38 DISPATCHER: Starting worker discovery
02:36:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:36:38 DISPATCHER: Finished worker discovery
02:37:38 DISPATCHER: Starting worker discovery
02:37:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:37:38 DISPATCHER: Finished worker discovery
02:38:38 DISPATCHER: Starting worker discovery
02:38:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:38:38 DISPATCHER: Finished worker discovery
02:39:38 DISPATCHER: Starting worker discovery
02:39:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:39:38 DISPATCHER: Finished worker discovery
02:40:38 DISPATCHER: Starting worker discovery
02:40:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:40:38 DISPATCHER: Finished worker discovery
02:41:38 DISPATCHER: Starting worker discovery
02:41:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:41:38 DISPATCHER: Finished worker discovery
02:42:38 DISPATCHER: Starting worker discovery
02:42:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:42:38 DISPATCHER: Finished worker discovery
02:43:38 DISPATCHER: Starting worker discovery
02:43:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:43:38 DISPATCHER: Finished worker discovery
02:44:38 DISPATCHER: Starting worker discovery
02:44:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:44:38 DISPATCHER: Finished worker discovery
02:45:38 DISPATCHER: Starting worker discovery
02:45:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:45:38 DISPATCHER: Finished worker discovery
02:46:38 DISPATCHER: Starting worker discovery
02:46:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:46:38 DISPATCHER: Finished worker discovery
02:47:38 DISPATCHER: Starting worker discovery
02:47:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:47:38 DISPATCHER: Finished worker discovery
02:48:38 DISPATCHER: Starting worker discovery
02:48:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:48:38 DISPATCHER: Finished worker discovery
02:49:38 DISPATCHER: Starting worker discovery
02:49:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:49:38 DISPATCHER: Finished worker discovery
02:50:38 DISPATCHER: Starting worker discovery
02:50:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:50:38 DISPATCHER: Finished worker discovery
02:51:38 DISPATCHER: Starting worker discovery
02:51:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:51:38 DISPATCHER: Finished worker discovery
02:52:24 WORKER: done with job (4, 0, 9), trying to register it.
02:52:24 WORKER: registered result for job (4, 0, 9) with dispatcher
02:52:24 DISPATCHER: job (4, 0, 9) finished
02:52:24 DISPATCHER: register_result: lock acquired
02:52:24 DISPATCHER: job (4, 0, 9) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
02:52:24 job_id: (4, 0, 9)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 711, 'last_n_outputs': 50, 'leak_rate': 0.7605321265515863, 'lr': 0.010825786793534508, 'optimizer': 'SGD', 'sparsity': 0.9194862237136601, 'steps_to_train': 38, 'weight_decay': 0.012322371315049593}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.3916935848019093, 'info': {'music_genre': 0.3916935848019093, 'config': "{'batch_size': 128, 'hidden_dim': 711, 'last_n_outputs': 50, 'leak_rate': 0.7605321265515863, 'lr': 0.010825786793534508, 'optimizer': 'SGD', 'sparsity': 0.9194862237136601, 'steps_to_train': 38, 'weight_decay': 0.012322371315049593}"}}
exception: None

02:52:24 job_callback for (4, 0, 9) started
02:52:24 job_callback for (4, 0, 9) got condition
02:52:24 DISPATCHER: Trying to submit another job.
02:52:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:52:24 Only 9 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
02:52:24 HBMASTER: Trying to run another job!
02:52:24 job_callback for (4, 0, 9) finished
02:52:24 start sampling a new configuration.
02:52:24 best_vector: [1, 0.13183697153709506, 0.7471574634467147, 0.30145786836541816, 0.0748169647083834, 0, 0.8608644547050169, 0.9329184335273372, 0.12640537913257652], 0.009817559044556915, 1.7128844417504283, 0.01681634414338774
02:52:24 done sampling a new configuration.
02:52:24 HBMASTER: schedule new run for iteration 5
02:52:24 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
02:52:24 HBMASTER: submitting job (5, 0, 0) to dispatcher
02:52:24 DISPATCHER: trying to submit job (5, 0, 0)
02:52:24 DISPATCHER: trying to notify the job_runner thread.
02:52:24 HBMASTER: job (5, 0, 0) submitted to dispatcher
02:52:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:52:24 DISPATCHER: Trying to submit another job.
02:52:24 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:52:24 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:52:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:52:24 WORKER: start processing job (5, 0, 0)
02:52:24 WORKER: args: ()
02:52:24 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 305, 'last_n_outputs': 40, 'leak_rate': 0.8253644670913546, 'lr': 0.0014113474061420927, 'optimizer': 'Adam', 'sparsity': 0.956607469129204, 'steps_to_train': 94, 'weight_decay': 0.014603507897579882}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:52:38 DISPATCHER: Starting worker discovery
02:52:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:52:38 DISPATCHER: Finished worker discovery
02:53:38 DISPATCHER: Starting worker discovery
02:53:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:53:38 DISPATCHER: Finished worker discovery
02:54:38 DISPATCHER: Starting worker discovery
02:54:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:54:38 DISPATCHER: Finished worker discovery
02:55:34 WORKER: done with job (5, 0, 0), trying to register it.
02:55:34 WORKER: registered result for job (5, 0, 0) with dispatcher
02:55:34 DISPATCHER: job (5, 0, 0) finished
02:55:34 DISPATCHER: register_result: lock acquired
02:55:34 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
02:55:34 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 305, 'last_n_outputs': 40, 'leak_rate': 0.8253644670913546, 'lr': 0.0014113474061420927, 'optimizer': 'Adam', 'sparsity': 0.956607469129204, 'steps_to_train': 94, 'weight_decay': 0.014603507897579882}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3063945949706492, 'info': {'music_genre': 0.3063945949706492, 'config': "{'batch_size': 32, 'hidden_dim': 305, 'last_n_outputs': 40, 'leak_rate': 0.8253644670913546, 'lr': 0.0014113474061420927, 'optimizer': 'Adam', 'sparsity': 0.956607469129204, 'steps_to_train': 94, 'weight_decay': 0.014603507897579882}"}}
exception: None

02:55:34 job_callback for (5, 0, 0) started
02:55:34 job_callback for (5, 0, 0) got condition
02:55:34 DISPATCHER: Trying to submit another job.
02:55:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:55:34 done building a new model for budget 133.333333 based on 10/23 split
Best loss for this budget:-0.392205





02:55:34 HBMASTER: Trying to run another job!
02:55:34 job_callback for (5, 0, 0) finished
02:55:34 start sampling a new configuration.
02:55:34 best_vector: [3, 0.2298704831888086, 0.8833144177375138, 0.7942307225765927, 0.2792867023553525, 1, 0.6337758542443872, 0.5305259829332529, 0.40952869837931216], 0.016056927438641816, 3.2976023856820498, 0.052949362228388815
02:55:34 done sampling a new configuration.
02:55:34 HBMASTER: schedule new run for iteration 5
02:55:34 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
02:55:34 HBMASTER: submitting job (5, 0, 1) to dispatcher
02:55:34 DISPATCHER: trying to submit job (5, 0, 1)
02:55:34 DISPATCHER: trying to notify the job_runner thread.
02:55:34 HBMASTER: job (5, 0, 1) submitted to dispatcher
02:55:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:55:34 DISPATCHER: Trying to submit another job.
02:55:34 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:55:34 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:55:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:55:34 WORKER: start processing job (5, 0, 1)
02:55:34 WORKER: args: ()
02:55:34 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 384, 'last_n_outputs': 46, 'leak_rate': 0.9485576806441481, 'lr': 0.003618873519782241, 'optimizer': 'SGD', 'sparsity': 0.9021062050186529, 'steps_to_train': 58, 'weight_decay': 0.034104298486764724}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:55:38 DISPATCHER: Starting worker discovery
02:55:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:55:38 DISPATCHER: Finished worker discovery
02:56:38 DISPATCHER: Starting worker discovery
02:56:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:56:38 DISPATCHER: Finished worker discovery
02:57:38 DISPATCHER: Starting worker discovery
02:57:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:57:38 DISPATCHER: Finished worker discovery
02:58:38 DISPATCHER: Starting worker discovery
02:58:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:58:38 DISPATCHER: Finished worker discovery
02:58:49 WORKER: done with job (5, 0, 1), trying to register it.
02:58:49 WORKER: registered result for job (5, 0, 1) with dispatcher
02:58:49 DISPATCHER: job (5, 0, 1) finished
02:58:49 DISPATCHER: register_result: lock acquired
02:58:49 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
02:58:49 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 384, 'last_n_outputs': 46, 'leak_rate': 0.9485576806441481, 'lr': 0.003618873519782241, 'optimizer': 'SGD', 'sparsity': 0.9021062050186529, 'steps_to_train': 58, 'weight_decay': 0.034104298486764724}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3354395484269511, 'info': {'music_genre': 0.3354395484269511, 'config': "{'batch_size': 128, 'hidden_dim': 384, 'last_n_outputs': 46, 'leak_rate': 0.9485576806441481, 'lr': 0.003618873519782241, 'optimizer': 'SGD', 'sparsity': 0.9021062050186529, 'steps_to_train': 58, 'weight_decay': 0.034104298486764724}"}}
exception: None

02:58:49 job_callback for (5, 0, 1) started
02:58:49 job_callback for (5, 0, 1) got condition
02:58:49 DISPATCHER: Trying to submit another job.
02:58:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:58:49 done building a new model for budget 133.333333 based on 10/24 split
Best loss for this budget:-0.392205





02:58:49 HBMASTER: Trying to run another job!
02:58:49 job_callback for (5, 0, 1) finished
02:58:49 start sampling a new configuration.
02:58:49 best_vector: [1, 0.8464453662050676, 0.9329829681342698, 0.1985986122911862, 0.3502630536490019, 1, 0.5007395792003575, 0.2237987459304953, 0.6262852423605454], 0.01885034907277211, 0.03865855383140218, 0.0007287272343704829
02:58:49 done sampling a new configuration.
02:58:49 HBMASTER: schedule new run for iteration 5
02:58:49 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
02:58:49 HBMASTER: submitting job (5, 0, 2) to dispatcher
02:58:49 DISPATCHER: trying to submit job (5, 0, 2)
02:58:49 DISPATCHER: trying to notify the job_runner thread.
02:58:49 HBMASTER: job (5, 0, 2) submitted to dispatcher
02:58:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:58:49 DISPATCHER: Trying to submit another job.
02:58:49 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:58:49 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:58:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:58:49 WORKER: start processing job (5, 0, 2)
02:58:49 WORKER: args: ()
02:58:49 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 878, 'last_n_outputs': 48, 'leak_rate': 0.7996496530727966, 'lr': 0.005017947431573378, 'optimizer': 'SGD', 'sparsity': 0.8701774990080858, 'steps_to_train': 30, 'weight_decay': 0.06528537246009015}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:59:38 DISPATCHER: Starting worker discovery
02:59:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:59:38 DISPATCHER: Finished worker discovery
03:00:38 DISPATCHER: Starting worker discovery
03:00:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:00:38 DISPATCHER: Finished worker discovery
03:01:38 DISPATCHER: Starting worker discovery
03:01:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:01:38 DISPATCHER: Finished worker discovery
03:02:04 WORKER: done with job (5, 0, 2), trying to register it.
03:02:04 WORKER: registered result for job (5, 0, 2) with dispatcher
03:02:04 DISPATCHER: job (5, 0, 2) finished
03:02:04 DISPATCHER: register_result: lock acquired
03:02:04 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
03:02:04 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 878, 'last_n_outputs': 48, 'leak_rate': 0.7996496530727966, 'lr': 0.005017947431573378, 'optimizer': 'SGD', 'sparsity': 0.8701774990080858, 'steps_to_train': 30, 'weight_decay': 0.06528537246009015}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3529018212682329, 'info': {'music_genre': 0.3529018212682329, 'config': "{'batch_size': 32, 'hidden_dim': 878, 'last_n_outputs': 48, 'leak_rate': 0.7996496530727966, 'lr': 0.005017947431573378, 'optimizer': 'SGD', 'sparsity': 0.8701774990080858, 'steps_to_train': 30, 'weight_decay': 0.06528537246009015}"}}
exception: None

03:02:04 job_callback for (5, 0, 2) started
03:02:04 DISPATCHER: Trying to submit another job.
03:02:04 job_callback for (5, 0, 2) got condition
03:02:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:02:04 done building a new model for budget 133.333333 based on 10/25 split
Best loss for this budget:-0.392205





03:02:04 HBMASTER: Trying to run another job!
03:02:04 job_callback for (5, 0, 2) finished
03:02:04 start sampling a new configuration.
03:02:04 best_vector: [3, 0.29562853458791305, 0.9501900279822653, 0.02574980146309583, 0.07414784690273087, 0, 0.6987600460052625, 0.9508610277818442, 0.16937295041567277], 0.05618422051922563, 2.051813406697381, 0.11527953690618924
03:02:04 done sampling a new configuration.
03:02:04 HBMASTER: schedule new run for iteration 5
03:02:04 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
03:02:04 HBMASTER: submitting job (5, 0, 3) to dispatcher
03:02:04 DISPATCHER: trying to submit job (5, 0, 3)
03:02:04 DISPATCHER: trying to notify the job_runner thread.
03:02:04 HBMASTER: job (5, 0, 3) submitted to dispatcher
03:02:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:02:04 DISPATCHER: Trying to submit another job.
03:02:04 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:02:04 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:02:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:02:04 WORKER: start processing job (5, 0, 3)
03:02:04 WORKER: args: ()
03:02:04 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 436, 'last_n_outputs': 48, 'leak_rate': 0.7564374503657739, 'lr': 0.0014070051718311407, 'optimizer': 'Adam', 'sparsity': 0.917702411041263, 'steps_to_train': 96, 'weight_decay': 0.01660960440759866}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:02:38 DISPATCHER: Starting worker discovery
03:02:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:02:38 DISPATCHER: Finished worker discovery
03:03:38 DISPATCHER: Starting worker discovery
03:03:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:03:38 DISPATCHER: Finished worker discovery
03:04:38 DISPATCHER: Starting worker discovery
03:04:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:04:38 DISPATCHER: Finished worker discovery
03:05:35 WORKER: done with job (5, 0, 3), trying to register it.
03:05:35 WORKER: registered result for job (5, 0, 3) with dispatcher
03:05:35 DISPATCHER: job (5, 0, 3) finished
03:05:35 DISPATCHER: register_result: lock acquired
03:05:35 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
03:05:35 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 436, 'last_n_outputs': 48, 'leak_rate': 0.7564374503657739, 'lr': 0.0014070051718311407, 'optimizer': 'Adam', 'sparsity': 0.917702411041263, 'steps_to_train': 96, 'weight_decay': 0.01660960440759866}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.405779211141258, 'info': {'music_genre': 0.405779211141258, 'config': "{'batch_size': 128, 'hidden_dim': 436, 'last_n_outputs': 48, 'leak_rate': 0.7564374503657739, 'lr': 0.0014070051718311407, 'optimizer': 'Adam', 'sparsity': 0.917702411041263, 'steps_to_train': 96, 'weight_decay': 0.01660960440759866}"}}
exception: None

03:05:35 job_callback for (5, 0, 3) started
03:05:35 DISPATCHER: Trying to submit another job.
03:05:35 job_callback for (5, 0, 3) got condition
03:05:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:05:35 done building a new model for budget 133.333333 based on 10/26 split
Best loss for this budget:-0.405779





03:05:35 HBMASTER: Trying to run another job!
03:05:35 job_callback for (5, 0, 3) finished
03:05:35 start sampling a new configuration.
03:05:35 done sampling a new configuration.
03:05:35 HBMASTER: schedule new run for iteration 5
03:05:35 HBMASTER: trying submitting job (5, 0, 4) to dispatcher
03:05:35 HBMASTER: submitting job (5, 0, 4) to dispatcher
03:05:35 DISPATCHER: trying to submit job (5, 0, 4)
03:05:35 DISPATCHER: trying to notify the job_runner thread.
03:05:35 HBMASTER: job (5, 0, 4) submitted to dispatcher
03:05:35 DISPATCHER: Trying to submit another job.
03:05:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:05:35 DISPATCHER: starting job (5, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:05:36 DISPATCHER: job (5, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:05:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:05:36 WORKER: start processing job (5, 0, 4)
03:05:36 WORKER: args: ()
03:05:36 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 818, 'last_n_outputs': 27, 'leak_rate': 0.9827136149408422, 'lr': 0.010090385923830693, 'optimizer': 'SGD', 'sparsity': 0.8500385476118512, 'steps_to_train': 70, 'weight_decay': 0.03513347968295354}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:05:38 DISPATCHER: Starting worker discovery
03:05:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:05:38 DISPATCHER: Finished worker discovery
03:06:38 DISPATCHER: Starting worker discovery
03:06:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:06:38 DISPATCHER: Finished worker discovery
03:07:38 DISPATCHER: Starting worker discovery
03:07:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:07:38 DISPATCHER: Finished worker discovery
03:08:38 DISPATCHER: Starting worker discovery
03:08:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:08:38 DISPATCHER: Finished worker discovery
03:09:03 WORKER: done with job (5, 0, 4), trying to register it.
03:09:03 WORKER: registered result for job (5, 0, 4) with dispatcher
03:09:03 DISPATCHER: job (5, 0, 4) finished
03:09:03 DISPATCHER: register_result: lock acquired
03:09:03 DISPATCHER: job (5, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
03:09:03 job_id: (5, 0, 4)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 818, 'last_n_outputs': 27, 'leak_rate': 0.9827136149408422, 'lr': 0.010090385923830693, 'optimizer': 'SGD', 'sparsity': 0.8500385476118512, 'steps_to_train': 70, 'weight_decay': 0.03513347968295354}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3100148073907442, 'info': {'music_genre': 0.3100148073907442, 'config': "{'batch_size': 32, 'hidden_dim': 818, 'last_n_outputs': 27, 'leak_rate': 0.9827136149408422, 'lr': 0.010090385923830693, 'optimizer': 'SGD', 'sparsity': 0.8500385476118512, 'steps_to_train': 70, 'weight_decay': 0.03513347968295354}"}}
exception: None

03:09:03 job_callback for (5, 0, 4) started
03:09:03 job_callback for (5, 0, 4) got condition
03:09:03 DISPATCHER: Trying to submit another job.
03:09:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:09:03 done building a new model for budget 133.333333 based on 10/27 split
Best loss for this budget:-0.405779





03:09:03 HBMASTER: Trying to run another job!
03:09:03 job_callback for (5, 0, 4) finished
03:09:03 start sampling a new configuration.
03:09:03 best_vector: [3, 0.4916149004398612, 0.8515108639655897, 0.6653274670131515, 0.2055174349306646, 0, 0.7416919197778609, 0.8884756058296274, 0.1162076740859225], 0.012806186837638508, 3.9403318493616646, 0.050460625865223145
03:09:03 done sampling a new configuration.
03:09:03 HBMASTER: schedule new run for iteration 5
03:09:03 HBMASTER: trying submitting job (5, 0, 5) to dispatcher
03:09:03 HBMASTER: submitting job (5, 0, 5) to dispatcher
03:09:03 DISPATCHER: trying to submit job (5, 0, 5)
03:09:03 DISPATCHER: trying to notify the job_runner thread.
03:09:03 HBMASTER: job (5, 0, 5) submitted to dispatcher
03:09:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:09:03 DISPATCHER: Trying to submit another job.
03:09:03 DISPATCHER: starting job (5, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:09:03 DISPATCHER: job (5, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:09:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:09:03 WORKER: start processing job (5, 0, 5)
03:09:03 WORKER: args: ()
03:09:03 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 593, 'last_n_outputs': 44, 'leak_rate': 0.9163318667532878, 'lr': 0.002576528020252805, 'optimizer': 'Adam', 'sparsity': 0.9280060607466866, 'steps_to_train': 90, 'weight_decay': 0.014164122355367575}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:09:38 DISPATCHER: Starting worker discovery
03:09:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:09:38 DISPATCHER: Finished worker discovery
03:10:38 DISPATCHER: Starting worker discovery
03:10:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:10:38 DISPATCHER: Finished worker discovery
03:11:38 DISPATCHER: Starting worker discovery
03:11:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:11:38 DISPATCHER: Finished worker discovery
03:12:32 WORKER: done with job (5, 0, 5), trying to register it.
03:12:32 WORKER: registered result for job (5, 0, 5) with dispatcher
03:12:32 DISPATCHER: job (5, 0, 5) finished
03:12:32 DISPATCHER: register_result: lock acquired
03:12:32 DISPATCHER: job (5, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
03:12:32 job_id: (5, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 593, 'last_n_outputs': 44, 'leak_rate': 0.9163318667532878, 'lr': 0.002576528020252805, 'optimizer': 'Adam', 'sparsity': 0.9280060607466866, 'steps_to_train': 90, 'weight_decay': 0.014164122355367575}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.323107669868105, 'info': {'music_genre': 0.323107669868105, 'config': "{'batch_size': 128, 'hidden_dim': 593, 'last_n_outputs': 44, 'leak_rate': 0.9163318667532878, 'lr': 0.002576528020252805, 'optimizer': 'Adam', 'sparsity': 0.9280060607466866, 'steps_to_train': 90, 'weight_decay': 0.014164122355367575}"}}
exception: None

03:12:32 job_callback for (5, 0, 5) started
03:12:32 job_callback for (5, 0, 5) got condition
03:12:32 DISPATCHER: Trying to submit another job.
03:12:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:12:32 done building a new model for budget 133.333333 based on 10/28 split
Best loss for this budget:-0.405779





03:12:32 HBMASTER: Trying to run another job!
03:12:32 job_callback for (5, 0, 5) finished
03:12:32 start sampling a new configuration.
03:12:32 done sampling a new configuration.
03:12:32 HBMASTER: schedule new run for iteration 5
03:12:32 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
03:12:32 HBMASTER: submitting job (5, 0, 6) to dispatcher
03:12:32 DISPATCHER: trying to submit job (5, 0, 6)
03:12:32 DISPATCHER: trying to notify the job_runner thread.
03:12:32 HBMASTER: job (5, 0, 6) submitted to dispatcher
03:12:32 DISPATCHER: Trying to submit another job.
03:12:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:12:32 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:12:32 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:12:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:12:32 WORKER: start processing job (5, 0, 6)
03:12:32 WORKER: args: ()
03:12:32 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 445, 'last_n_outputs': 41, 'leak_rate': 0.7633500679347058, 'lr': 0.00610881853213008, 'optimizer': 'Adam', 'sparsity': 0.7674921299272249, 'steps_to_train': 78, 'weight_decay': 0.19699529365099017}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:12:38 DISPATCHER: Starting worker discovery
03:12:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:12:38 DISPATCHER: Finished worker discovery
03:13:38 DISPATCHER: Starting worker discovery
03:13:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:13:38 DISPATCHER: Finished worker discovery
03:14:38 DISPATCHER: Starting worker discovery
03:14:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:14:38 DISPATCHER: Finished worker discovery
03:15:38 DISPATCHER: Starting worker discovery
03:15:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:15:38 DISPATCHER: Finished worker discovery
03:15:58 WORKER: done with job (5, 0, 6), trying to register it.
03:15:58 WORKER: registered result for job (5, 0, 6) with dispatcher
03:15:58 DISPATCHER: job (5, 0, 6) finished
03:15:58 DISPATCHER: register_result: lock acquired
03:15:58 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
03:15:58 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 445, 'last_n_outputs': 41, 'leak_rate': 0.7633500679347058, 'lr': 0.00610881853213008, 'optimizer': 'Adam', 'sparsity': 0.7674921299272249, 'steps_to_train': 78, 'weight_decay': 0.19699529365099017}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.11428736555190785, 'info': {'music_genre': 0.11428736555190785, 'config': "{'batch_size': 32, 'hidden_dim': 445, 'last_n_outputs': 41, 'leak_rate': 0.7633500679347058, 'lr': 0.00610881853213008, 'optimizer': 'Adam', 'sparsity': 0.7674921299272249, 'steps_to_train': 78, 'weight_decay': 0.19699529365099017}"}}
exception: None

03:15:58 job_callback for (5, 0, 6) started
03:15:58 DISPATCHER: Trying to submit another job.
03:15:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:15:58 job_callback for (5, 0, 6) got condition
03:15:58 done building a new model for budget 133.333333 based on 10/28 split
Best loss for this budget:-0.405779





03:15:58 HBMASTER: Trying to run another job!
03:15:58 job_callback for (5, 0, 6) finished
03:15:58 start sampling a new configuration.
03:15:58 best_vector: [0, 0.6878226900837371, 0.7528334685281658, 0.5027075220810734, 0.46555038695457074, 1, 0.8951500981856603, 0.09869793311791805, 0.231245202634067], 0.02839136835917786, 5.4357794667331145, 0.15432921715927525
03:15:58 done sampling a new configuration.
03:15:58 HBMASTER: schedule new run for iteration 5
03:15:58 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
03:15:58 HBMASTER: submitting job (5, 0, 7) to dispatcher
03:15:58 DISPATCHER: trying to submit job (5, 0, 7)
03:15:58 DISPATCHER: trying to notify the job_runner thread.
03:15:58 HBMASTER: job (5, 0, 7) submitted to dispatcher
03:15:58 DISPATCHER: Trying to submit another job.
03:15:58 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:15:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:15:58 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:15:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:15:58 WORKER: start processing job (5, 0, 7)
03:15:58 WORKER: args: ()
03:15:58 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 750, 'last_n_outputs': 40, 'leak_rate': 0.8756768805202684, 'lr': 0.00853298090763832, 'optimizer': 'SGD', 'sparsity': 0.9648360235645584, 'steps_to_train': 18, 'weight_decay': 0.019992032309033368}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:16:38 DISPATCHER: Starting worker discovery
03:16:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:16:38 DISPATCHER: Finished worker discovery
03:17:38 DISPATCHER: Starting worker discovery
03:17:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:17:38 DISPATCHER: Finished worker discovery
03:18:38 DISPATCHER: Starting worker discovery
03:18:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:18:38 DISPATCHER: Finished worker discovery
03:19:13 WORKER: done with job (5, 0, 7), trying to register it.
03:19:13 WORKER: registered result for job (5, 0, 7) with dispatcher
03:19:13 DISPATCHER: job (5, 0, 7) finished
03:19:13 DISPATCHER: register_result: lock acquired
03:19:13 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
03:19:13 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 750, 'last_n_outputs': 40, 'leak_rate': 0.8756768805202684, 'lr': 0.00853298090763832, 'optimizer': 'SGD', 'sparsity': 0.9648360235645584, 'steps_to_train': 18, 'weight_decay': 0.019992032309033368}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3586475151034752, 'info': {'music_genre': 0.3586475151034752, 'config': "{'batch_size': 16, 'hidden_dim': 750, 'last_n_outputs': 40, 'leak_rate': 0.8756768805202684, 'lr': 0.00853298090763832, 'optimizer': 'SGD', 'sparsity': 0.9648360235645584, 'steps_to_train': 18, 'weight_decay': 0.019992032309033368}"}}
exception: None

03:19:13 job_callback for (5, 0, 7) started
03:19:13 job_callback for (5, 0, 7) got condition
03:19:13 DISPATCHER: Trying to submit another job.
03:19:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:19:13 done building a new model for budget 133.333333 based on 10/29 split
Best loss for this budget:-0.405779





03:19:13 HBMASTER: Trying to run another job!
03:19:13 job_callback for (5, 0, 7) finished
03:19:13 start sampling a new configuration.
03:19:13 best_vector: [2, 0.3149707855420326, 0.9215517116759029, 0.31021838311427724, 0.6024650846412145, 1, 0.9868586735414764, 0.4284838964982811, 0.06664245535826407], 0.02302082934820048, 1.5320380394641195, 0.035268786261455125
03:19:13 done sampling a new configuration.
03:19:13 HBMASTER: schedule new run for iteration 5
03:19:13 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
03:19:13 HBMASTER: submitting job (5, 0, 8) to dispatcher
03:19:13 DISPATCHER: trying to submit job (5, 0, 8)
03:19:13 DISPATCHER: trying to notify the job_runner thread.
03:19:13 HBMASTER: job (5, 0, 8) submitted to dispatcher
03:19:13 DISPATCHER: Trying to submit another job.
03:19:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:19:13 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:19:13 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:19:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:19:13 WORKER: start processing job (5, 0, 8)
03:19:13 WORKER: args: ()
03:19:13 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 452, 'last_n_outputs': 47, 'leak_rate': 0.8275545957785693, 'lr': 0.016029876237128617, 'optimizer': 'SGD', 'sparsity': 0.9868460816499544, 'steps_to_train': 48, 'weight_decay': 0.012209667394082219}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:19:38 DISPATCHER: Starting worker discovery
03:19:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:19:38 DISPATCHER: Finished worker discovery
03:20:38 DISPATCHER: Starting worker discovery
03:20:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:20:38 DISPATCHER: Finished worker discovery
03:21:38 DISPATCHER: Starting worker discovery
03:21:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:21:38 DISPATCHER: Finished worker discovery
03:22:31 WORKER: done with job (5, 0, 8), trying to register it.
03:22:31 WORKER: registered result for job (5, 0, 8) with dispatcher
03:22:31 DISPATCHER: job (5, 0, 8) finished
03:22:31 DISPATCHER: register_result: lock acquired
03:22:31 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
03:22:31 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 452, 'last_n_outputs': 47, 'leak_rate': 0.8275545957785693, 'lr': 0.016029876237128617, 'optimizer': 'SGD', 'sparsity': 0.9868460816499544, 'steps_to_train': 48, 'weight_decay': 0.012209667394082219}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.33784324453999487, 'info': {'music_genre': 0.33784324453999487, 'config': "{'batch_size': 64, 'hidden_dim': 452, 'last_n_outputs': 47, 'leak_rate': 0.8275545957785693, 'lr': 0.016029876237128617, 'optimizer': 'SGD', 'sparsity': 0.9868460816499544, 'steps_to_train': 48, 'weight_decay': 0.012209667394082219}"}}
exception: None

03:22:31 job_callback for (5, 0, 8) started
03:22:31 DISPATCHER: Trying to submit another job.
03:22:31 job_callback for (5, 0, 8) got condition
03:22:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:22:31 done building a new model for budget 133.333333 based on 10/30 split
Best loss for this budget:-0.405779





03:22:31 HBMASTER: Trying to run another job!
03:22:31 job_callback for (5, 0, 8) finished
03:22:31 ITERATION: Advancing config (5, 0, 2) to next budget 400.000000
03:22:31 ITERATION: Advancing config (5, 0, 3) to next budget 400.000000
03:22:31 ITERATION: Advancing config (5, 0, 7) to next budget 400.000000
03:22:31 HBMASTER: schedule new run for iteration 5
03:22:31 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
03:22:31 HBMASTER: submitting job (5, 0, 2) to dispatcher
03:22:31 DISPATCHER: trying to submit job (5, 0, 2)
03:22:31 DISPATCHER: trying to notify the job_runner thread.
03:22:31 HBMASTER: job (5, 0, 2) submitted to dispatcher
03:22:31 DISPATCHER: Trying to submit another job.
03:22:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:22:31 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:22:31 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:22:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:22:31 WORKER: start processing job (5, 0, 2)
03:22:31 WORKER: args: ()
03:22:31 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 878, 'last_n_outputs': 48, 'leak_rate': 0.7996496530727966, 'lr': 0.005017947431573378, 'optimizer': 'SGD', 'sparsity': 0.8701774990080858, 'steps_to_train': 30, 'weight_decay': 0.06528537246009015}, 'budget': 400.0, 'working_directory': '.'}
03:22:38 DISPATCHER: Starting worker discovery
03:22:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:22:38 DISPATCHER: Finished worker discovery
03:23:38 DISPATCHER: Starting worker discovery
03:23:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:23:38 DISPATCHER: Finished worker discovery
03:24:38 DISPATCHER: Starting worker discovery
03:24:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:24:38 DISPATCHER: Finished worker discovery
03:25:38 DISPATCHER: Starting worker discovery
03:25:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:25:38 DISPATCHER: Finished worker discovery
03:26:38 DISPATCHER: Starting worker discovery
03:26:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:26:38 DISPATCHER: Finished worker discovery
03:27:38 DISPATCHER: Starting worker discovery
03:27:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:27:38 DISPATCHER: Finished worker discovery
03:28:38 DISPATCHER: Starting worker discovery
03:28:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:28:38 DISPATCHER: Finished worker discovery
03:29:38 DISPATCHER: Starting worker discovery
03:29:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:29:38 DISPATCHER: Finished worker discovery
03:30:14 WORKER: done with job (5, 0, 2), trying to register it.
03:30:14 WORKER: registered result for job (5, 0, 2) with dispatcher
03:30:14 DISPATCHER: job (5, 0, 2) finished
03:30:14 DISPATCHER: register_result: lock acquired
03:30:14 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
03:30:14 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 878, 'last_n_outputs': 48, 'leak_rate': 0.7996496530727966, 'lr': 0.005017947431573378, 'optimizer': 'SGD', 'sparsity': 0.8701774990080858, 'steps_to_train': 30, 'weight_decay': 0.06528537246009015}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3661118429981064, 'info': {'music_genre': 0.3661118429981064, 'config': "{'batch_size': 32, 'hidden_dim': 878, 'last_n_outputs': 48, 'leak_rate': 0.7996496530727966, 'lr': 0.005017947431573378, 'optimizer': 'SGD', 'sparsity': 0.8701774990080858, 'steps_to_train': 30, 'weight_decay': 0.06528537246009015}"}}
exception: None

03:30:14 job_callback for (5, 0, 2) started
03:30:14 job_callback for (5, 0, 2) got condition
03:30:14 DISPATCHER: Trying to submit another job.
03:30:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:30:14 HBMASTER: Trying to run another job!
03:30:14 job_callback for (5, 0, 2) finished
03:30:14 HBMASTER: schedule new run for iteration 5
03:30:14 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
03:30:14 HBMASTER: submitting job (5, 0, 3) to dispatcher
03:30:14 DISPATCHER: trying to submit job (5, 0, 3)
03:30:14 DISPATCHER: trying to notify the job_runner thread.
03:30:14 HBMASTER: job (5, 0, 3) submitted to dispatcher
03:30:14 DISPATCHER: Trying to submit another job.
03:30:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:30:14 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:30:14 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:30:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:30:14 WORKER: start processing job (5, 0, 3)
03:30:14 WORKER: args: ()
03:30:14 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 436, 'last_n_outputs': 48, 'leak_rate': 0.7564374503657739, 'lr': 0.0014070051718311407, 'optimizer': 'Adam', 'sparsity': 0.917702411041263, 'steps_to_train': 96, 'weight_decay': 0.01660960440759866}, 'budget': 400.0, 'working_directory': '.'}
03:30:38 DISPATCHER: Starting worker discovery
03:30:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:30:38 DISPATCHER: Finished worker discovery
03:31:38 DISPATCHER: Starting worker discovery
03:31:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:31:38 DISPATCHER: Finished worker discovery
03:32:38 DISPATCHER: Starting worker discovery
03:32:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:32:38 DISPATCHER: Finished worker discovery
03:33:38 DISPATCHER: Starting worker discovery
03:33:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:33:38 DISPATCHER: Finished worker discovery
03:34:38 DISPATCHER: Starting worker discovery
03:34:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:34:38 DISPATCHER: Finished worker discovery
03:35:38 DISPATCHER: Starting worker discovery
03:35:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:35:38 DISPATCHER: Finished worker discovery
03:36:38 DISPATCHER: Starting worker discovery
03:36:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:36:38 DISPATCHER: Finished worker discovery
03:37:38 DISPATCHER: Starting worker discovery
03:37:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:37:38 DISPATCHER: Finished worker discovery
03:38:04 WORKER: done with job (5, 0, 3), trying to register it.
03:38:04 WORKER: registered result for job (5, 0, 3) with dispatcher
03:38:04 DISPATCHER: job (5, 0, 3) finished
03:38:04 DISPATCHER: register_result: lock acquired
03:38:04 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
03:38:04 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 436, 'last_n_outputs': 48, 'leak_rate': 0.7564374503657739, 'lr': 0.0014070051718311407, 'optimizer': 'Adam', 'sparsity': 0.917702411041263, 'steps_to_train': 96, 'weight_decay': 0.01660960440759866}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3270048736872054, 'info': {'music_genre': 0.3270048736872054, 'config': "{'batch_size': 128, 'hidden_dim': 436, 'last_n_outputs': 48, 'leak_rate': 0.7564374503657739, 'lr': 0.0014070051718311407, 'optimizer': 'Adam', 'sparsity': 0.917702411041263, 'steps_to_train': 96, 'weight_decay': 0.01660960440759866}"}}
exception: None

03:38:04 job_callback for (5, 0, 3) started
03:38:04 job_callback for (5, 0, 3) got condition
03:38:04 DISPATCHER: Trying to submit another job.
03:38:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:38:04 HBMASTER: Trying to run another job!
03:38:04 job_callback for (5, 0, 3) finished
03:38:04 HBMASTER: schedule new run for iteration 5
03:38:04 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
03:38:04 HBMASTER: submitting job (5, 0, 7) to dispatcher
03:38:04 DISPATCHER: trying to submit job (5, 0, 7)
03:38:04 DISPATCHER: trying to notify the job_runner thread.
03:38:04 HBMASTER: job (5, 0, 7) submitted to dispatcher
03:38:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:38:04 DISPATCHER: Trying to submit another job.
03:38:04 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:38:04 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:38:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:38:04 WORKER: start processing job (5, 0, 7)
03:38:04 WORKER: args: ()
03:38:04 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 750, 'last_n_outputs': 40, 'leak_rate': 0.8756768805202684, 'lr': 0.00853298090763832, 'optimizer': 'SGD', 'sparsity': 0.9648360235645584, 'steps_to_train': 18, 'weight_decay': 0.019992032309033368}, 'budget': 400.0, 'working_directory': '.'}
03:38:38 DISPATCHER: Starting worker discovery
03:38:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:38:38 DISPATCHER: Finished worker discovery
03:39:38 DISPATCHER: Starting worker discovery
03:39:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:39:38 DISPATCHER: Finished worker discovery
03:40:38 DISPATCHER: Starting worker discovery
03:40:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:40:38 DISPATCHER: Finished worker discovery
03:41:38 DISPATCHER: Starting worker discovery
03:41:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:41:38 DISPATCHER: Finished worker discovery
03:42:38 DISPATCHER: Starting worker discovery
03:42:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:42:38 DISPATCHER: Finished worker discovery
03:43:38 DISPATCHER: Starting worker discovery
03:43:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:43:38 DISPATCHER: Finished worker discovery
03:44:38 DISPATCHER: Starting worker discovery
03:44:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:44:38 DISPATCHER: Finished worker discovery
03:45:38 DISPATCHER: Starting worker discovery
03:45:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:45:38 DISPATCHER: Finished worker discovery
03:45:44 WORKER: done with job (5, 0, 7), trying to register it.
03:45:44 WORKER: registered result for job (5, 0, 7) with dispatcher
03:45:44 DISPATCHER: job (5, 0, 7) finished
03:45:44 DISPATCHER: register_result: lock acquired
03:45:44 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
03:45:44 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 750, 'last_n_outputs': 40, 'leak_rate': 0.8756768805202684, 'lr': 0.00853298090763832, 'optimizer': 'SGD', 'sparsity': 0.9648360235645584, 'steps_to_train': 18, 'weight_decay': 0.019992032309033368}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3661916387877926, 'info': {'music_genre': 0.3661916387877926, 'config': "{'batch_size': 16, 'hidden_dim': 750, 'last_n_outputs': 40, 'leak_rate': 0.8756768805202684, 'lr': 0.00853298090763832, 'optimizer': 'SGD', 'sparsity': 0.9648360235645584, 'steps_to_train': 18, 'weight_decay': 0.019992032309033368}"}}
exception: None

03:45:44 job_callback for (5, 0, 7) started
03:45:44 DISPATCHER: Trying to submit another job.
03:45:44 job_callback for (5, 0, 7) got condition
03:45:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:45:44 HBMASTER: Trying to run another job!
03:45:44 job_callback for (5, 0, 7) finished
03:45:44 ITERATION: Advancing config (5, 0, 7) to next budget 1200.000000
03:45:44 HBMASTER: schedule new run for iteration 5
03:45:44 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
03:45:44 HBMASTER: submitting job (5, 0, 7) to dispatcher
03:45:44 DISPATCHER: trying to submit job (5, 0, 7)
03:45:44 DISPATCHER: trying to notify the job_runner thread.
03:45:44 HBMASTER: job (5, 0, 7) submitted to dispatcher
03:45:44 DISPATCHER: Trying to submit another job.
03:45:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:45:44 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:45:44 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:45:44 WORKER: start processing job (5, 0, 7)
03:45:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:45:44 WORKER: args: ()
03:45:44 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 750, 'last_n_outputs': 40, 'leak_rate': 0.8756768805202684, 'lr': 0.00853298090763832, 'optimizer': 'SGD', 'sparsity': 0.9648360235645584, 'steps_to_train': 18, 'weight_decay': 0.019992032309033368}, 'budget': 1200.0, 'working_directory': '.'}
03:46:38 DISPATCHER: Starting worker discovery
03:46:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:46:38 DISPATCHER: Finished worker discovery
03:47:38 DISPATCHER: Starting worker discovery
03:47:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:47:38 DISPATCHER: Finished worker discovery
03:48:38 DISPATCHER: Starting worker discovery
03:48:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:48:38 DISPATCHER: Finished worker discovery
03:49:38 DISPATCHER: Starting worker discovery
03:49:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:49:38 DISPATCHER: Finished worker discovery
03:50:38 DISPATCHER: Starting worker discovery
03:50:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:50:38 DISPATCHER: Finished worker discovery
03:51:38 DISPATCHER: Starting worker discovery
03:51:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:51:38 DISPATCHER: Finished worker discovery
03:52:38 DISPATCHER: Starting worker discovery
03:52:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:52:38 DISPATCHER: Finished worker discovery
03:53:38 DISPATCHER: Starting worker discovery
03:53:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:53:38 DISPATCHER: Finished worker discovery
03:54:38 DISPATCHER: Starting worker discovery
03:54:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:54:38 DISPATCHER: Finished worker discovery
03:55:38 DISPATCHER: Starting worker discovery
03:55:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:55:38 DISPATCHER: Finished worker discovery
03:56:38 DISPATCHER: Starting worker discovery
03:56:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:56:38 DISPATCHER: Finished worker discovery
03:57:38 DISPATCHER: Starting worker discovery
03:57:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:57:38 DISPATCHER: Finished worker discovery
03:58:38 DISPATCHER: Starting worker discovery
03:58:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:58:38 DISPATCHER: Finished worker discovery
03:59:38 DISPATCHER: Starting worker discovery
03:59:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:59:38 DISPATCHER: Finished worker discovery
04:00:38 DISPATCHER: Starting worker discovery
04:00:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:00:38 DISPATCHER: Finished worker discovery
04:01:38 DISPATCHER: Starting worker discovery
04:01:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:01:38 DISPATCHER: Finished worker discovery
04:02:38 DISPATCHER: Starting worker discovery
04:02:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:02:38 DISPATCHER: Finished worker discovery
04:03:38 DISPATCHER: Starting worker discovery
04:03:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:03:38 DISPATCHER: Finished worker discovery
04:04:38 DISPATCHER: Starting worker discovery
04:04:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:04:38 DISPATCHER: Finished worker discovery
04:05:38 DISPATCHER: Starting worker discovery
04:05:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:05:38 DISPATCHER: Finished worker discovery
04:06:38 DISPATCHER: Starting worker discovery
04:06:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:06:38 DISPATCHER: Finished worker discovery
04:06:48 WORKER: done with job (5, 0, 7), trying to register it.
04:06:48 WORKER: registered result for job (5, 0, 7) with dispatcher
04:06:48 DISPATCHER: job (5, 0, 7) finished
04:06:48 DISPATCHER: register_result: lock acquired
04:06:48 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
04:06:48 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 750, 'last_n_outputs': 40, 'leak_rate': 0.8756768805202684, 'lr': 0.00853298090763832, 'optimizer': 'SGD', 'sparsity': 0.9648360235645584, 'steps_to_train': 18, 'weight_decay': 0.019992032309033368}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.36890734488006105, 'info': {'music_genre': 0.36890734488006105, 'config': "{'batch_size': 16, 'hidden_dim': 750, 'last_n_outputs': 40, 'leak_rate': 0.8756768805202684, 'lr': 0.00853298090763832, 'optimizer': 'SGD', 'sparsity': 0.9648360235645584, 'steps_to_train': 18, 'weight_decay': 0.019992032309033368}"}}
exception: None

04:06:48 job_callback for (5, 0, 7) started
04:06:48 job_callback for (5, 0, 7) got condition
04:06:48 DISPATCHER: Trying to submit another job.
04:06:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:06:48 HBMASTER: Trying to run another job!
04:06:48 job_callback for (5, 0, 7) finished
04:06:48 start sampling a new configuration.
04:06:48 best_vector: [3, 0.9283672025671617, 0.9554216676229536, 0.14054544879115222, 0.5131243394536861, 1, 0.6937315410698168, 0.6511914806401355, 0.03665534720925517], 0.02483918633589457, 3.028064517344805, 0.07521465878343826
04:06:48 done sampling a new configuration.
04:06:48 HBMASTER: schedule new run for iteration 6
04:06:48 HBMASTER: trying submitting job (6, 0, 0) to dispatcher
04:06:48 HBMASTER: submitting job (6, 0, 0) to dispatcher
04:06:48 DISPATCHER: trying to submit job (6, 0, 0)
04:06:48 DISPATCHER: trying to notify the job_runner thread.
04:06:48 HBMASTER: job (6, 0, 0) submitted to dispatcher
04:06:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:06:48 DISPATCHER: Trying to submit another job.
04:06:48 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:06:48 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:06:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:06:48 WORKER: start processing job (6, 0, 0)
04:06:48 WORKER: args: ()
04:06:48 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 943, 'last_n_outputs': 49, 'leak_rate': 0.785136362197788, 'lr': 0.010623036627732368, 'optimizer': 'SGD', 'sparsity': 0.9164955698567561, 'steps_to_train': 69, 'weight_decay': 0.01116065558749684}, 'budget': 400.0, 'working_directory': '.'}
04:07:38 DISPATCHER: Starting worker discovery
04:07:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:07:38 DISPATCHER: Finished worker discovery
04:08:38 DISPATCHER: Starting worker discovery
04:08:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:08:38 DISPATCHER: Finished worker discovery
04:09:38 DISPATCHER: Starting worker discovery
04:09:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:09:38 DISPATCHER: Finished worker discovery
04:10:38 DISPATCHER: Starting worker discovery
04:10:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:10:38 DISPATCHER: Finished worker discovery
04:11:38 DISPATCHER: Starting worker discovery
04:11:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:11:38 DISPATCHER: Finished worker discovery
04:12:38 DISPATCHER: Starting worker discovery
04:12:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:12:38 DISPATCHER: Finished worker discovery
04:13:38 DISPATCHER: Starting worker discovery
04:13:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:13:38 DISPATCHER: Finished worker discovery
04:14:38 DISPATCHER: Starting worker discovery
04:14:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:14:38 DISPATCHER: Finished worker discovery
04:14:39 WORKER: done with job (6, 0, 0), trying to register it.
04:14:39 WORKER: registered result for job (6, 0, 0) with dispatcher
04:14:39 DISPATCHER: job (6, 0, 0) finished
04:14:39 DISPATCHER: register_result: lock acquired
04:14:39 DISPATCHER: job (6, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
04:14:39 job_id: (6, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 943, 'last_n_outputs': 49, 'leak_rate': 0.785136362197788, 'lr': 0.010623036627732368, 'optimizer': 'SGD', 'sparsity': 0.9164955698567561, 'steps_to_train': 69, 'weight_decay': 0.01116065558749684}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3723869134816136, 'info': {'music_genre': 0.3723869134816136, 'config': "{'batch_size': 128, 'hidden_dim': 943, 'last_n_outputs': 49, 'leak_rate': 0.785136362197788, 'lr': 0.010623036627732368, 'optimizer': 'SGD', 'sparsity': 0.9164955698567561, 'steps_to_train': 69, 'weight_decay': 0.01116065558749684}"}}
exception: None

04:14:39 job_callback for (6, 0, 0) started
04:14:39 job_callback for (6, 0, 0) got condition
04:14:39 DISPATCHER: Trying to submit another job.
04:14:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:14:39 HBMASTER: Trying to run another job!
04:14:39 job_callback for (6, 0, 0) finished
04:14:39 start sampling a new configuration.
04:14:39 best_vector: [3, 0.9505114010181093, 0.5803882259721652, 0.037572942043081786, 0.5682436375888632, 1, 0.6891998520271768, 0.08414125945265236, 0.0474116440208404], 0.018682088738759026, 5.514503719829627, 0.10302244784407384
04:14:39 done sampling a new configuration.
04:14:39 HBMASTER: schedule new run for iteration 6
04:14:39 HBMASTER: trying submitting job (6, 0, 1) to dispatcher
04:14:39 HBMASTER: submitting job (6, 0, 1) to dispatcher
04:14:39 DISPATCHER: trying to submit job (6, 0, 1)
04:14:39 DISPATCHER: trying to notify the job_runner thread.
04:14:39 HBMASTER: job (6, 0, 1) submitted to dispatcher
04:14:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:14:39 DISPATCHER: Trying to submit another job.
04:14:39 DISPATCHER: starting job (6, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:14:39 DISPATCHER: job (6, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:14:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:14:39 WORKER: start processing job (6, 0, 1)
04:14:39 WORKER: args: ()
04:14:39 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 961, 'last_n_outputs': 33, 'leak_rate': 0.7593932355107704, 'lr': 0.01369264268379453, 'optimizer': 'SGD', 'sparsity': 0.9154079644865224, 'steps_to_train': 17, 'weight_decay': 0.011526142140834588}, 'budget': 400.0, 'working_directory': '.'}
04:15:38 DISPATCHER: Starting worker discovery
04:15:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:15:38 DISPATCHER: Finished worker discovery
04:16:38 DISPATCHER: Starting worker discovery
04:16:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:16:38 DISPATCHER: Finished worker discovery
04:17:38 DISPATCHER: Starting worker discovery
04:17:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:17:38 DISPATCHER: Finished worker discovery
04:18:38 DISPATCHER: Starting worker discovery
04:18:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:18:38 DISPATCHER: Finished worker discovery
04:19:38 DISPATCHER: Starting worker discovery
04:19:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:19:38 DISPATCHER: Finished worker discovery
04:20:38 DISPATCHER: Starting worker discovery
04:20:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:20:38 DISPATCHER: Finished worker discovery
04:21:38 DISPATCHER: Starting worker discovery
04:21:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:21:38 DISPATCHER: Finished worker discovery
04:22:19 WORKER: done with job (6, 0, 1), trying to register it.
04:22:19 WORKER: registered result for job (6, 0, 1) with dispatcher
04:22:19 DISPATCHER: job (6, 0, 1) finished
04:22:19 DISPATCHER: register_result: lock acquired
04:22:19 DISPATCHER: job (6, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
04:22:19 job_id: (6, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 961, 'last_n_outputs': 33, 'leak_rate': 0.7593932355107704, 'lr': 0.01369264268379453, 'optimizer': 'SGD', 'sparsity': 0.9154079644865224, 'steps_to_train': 17, 'weight_decay': 0.011526142140834588}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.38851328230478144, 'info': {'music_genre': 0.38851328230478144, 'config': "{'batch_size': 128, 'hidden_dim': 961, 'last_n_outputs': 33, 'leak_rate': 0.7593932355107704, 'lr': 0.01369264268379453, 'optimizer': 'SGD', 'sparsity': 0.9154079644865224, 'steps_to_train': 17, 'weight_decay': 0.011526142140834588}"}}
exception: None

04:22:19 job_callback for (6, 0, 1) started
04:22:19 DISPATCHER: Trying to submit another job.
04:22:19 job_callback for (6, 0, 1) got condition
04:22:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:22:19 done building a new model for budget 400.000000 based on 10/17 split
Best loss for this budget:-0.400060





04:22:19 HBMASTER: Trying to run another job!
04:22:19 job_callback for (6, 0, 1) finished
04:22:19 start sampling a new configuration.
04:22:19 best_vector: [1, 0.9816892074590126, 0.5795795061327822, 0.8743522887936936, 0.966297462013262, 1, 0.9006080312053372, 0.32335299670352224, 0.0014969478475108239], 2.1834951649309928e-29, 0.0004579813209852489, -6.407510668489234e-06
04:22:19 done sampling a new configuration.
04:22:19 HBMASTER: schedule new run for iteration 6
04:22:19 HBMASTER: trying submitting job (6, 0, 2) to dispatcher
04:22:19 HBMASTER: submitting job (6, 0, 2) to dispatcher
04:22:19 DISPATCHER: trying to submit job (6, 0, 2)
04:22:19 DISPATCHER: trying to notify the job_runner thread.
04:22:19 HBMASTER: job (6, 0, 2) submitted to dispatcher
04:22:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:22:19 DISPATCHER: Trying to submit another job.
04:22:19 DISPATCHER: starting job (6, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:22:19 DISPATCHER: job (6, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:22:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:22:19 WORKER: start processing job (6, 0, 2)
04:22:19 WORKER: args: ()
04:22:19 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 986, 'last_n_outputs': 33, 'leak_rate': 0.9685880721984235, 'lr': 0.08562388399474494, 'optimizer': 'SGD', 'sparsity': 0.966145927489281, 'steps_to_train': 39, 'weight_decay': 0.010044945251943594}, 'budget': 400.0, 'working_directory': '.'}
04:22:38 DISPATCHER: Starting worker discovery
04:22:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:22:38 DISPATCHER: Finished worker discovery
04:23:38 DISPATCHER: Starting worker discovery
04:23:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:23:38 DISPATCHER: Finished worker discovery
04:24:38 DISPATCHER: Starting worker discovery
04:24:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:24:38 DISPATCHER: Finished worker discovery
04:25:38 DISPATCHER: Starting worker discovery
04:25:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:25:38 DISPATCHER: Finished worker discovery
04:26:38 DISPATCHER: Starting worker discovery
04:26:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:26:38 DISPATCHER: Finished worker discovery
04:27:38 DISPATCHER: Starting worker discovery
04:27:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:27:38 DISPATCHER: Finished worker discovery
04:28:38 DISPATCHER: Starting worker discovery
04:28:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:28:38 DISPATCHER: Finished worker discovery
04:29:38 DISPATCHER: Starting worker discovery
04:29:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:29:39 DISPATCHER: Finished worker discovery
04:30:07 WORKER: done with job (6, 0, 2), trying to register it.
04:30:07 WORKER: registered result for job (6, 0, 2) with dispatcher
04:30:07 DISPATCHER: job (6, 0, 2) finished
04:30:07 DISPATCHER: register_result: lock acquired
04:30:07 DISPATCHER: job (6, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
04:30:07 job_id: (6, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 986, 'last_n_outputs': 33, 'leak_rate': 0.9685880721984235, 'lr': 0.08562388399474494, 'optimizer': 'SGD', 'sparsity': 0.966145927489281, 'steps_to_train': 39, 'weight_decay': 0.010044945251943594}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3269900426652677, 'info': {'music_genre': 0.3269900426652677, 'config': "{'batch_size': 32, 'hidden_dim': 986, 'last_n_outputs': 33, 'leak_rate': 0.9685880721984235, 'lr': 0.08562388399474494, 'optimizer': 'SGD', 'sparsity': 0.966145927489281, 'steps_to_train': 39, 'weight_decay': 0.010044945251943594}"}}
exception: None

04:30:07 job_callback for (6, 0, 2) started
04:30:07 DISPATCHER: Trying to submit another job.
04:30:07 job_callback for (6, 0, 2) got condition
04:30:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:30:07 done building a new model for budget 400.000000 based on 10/17 split
Best loss for this budget:-0.400060





04:30:07 HBMASTER: Trying to run another job!
04:30:07 job_callback for (6, 0, 2) finished
04:30:07 start sampling a new configuration.
04:30:07 best_vector: [3, 0.16855649518817142, 0.9601595086541798, 0.24930869626303395, 0.3138745434241068, 0, 0.789875825481517, 0.9464413163971179, 0.008297767798984088], 2.422307336877349e-33, 4.128295302482643, -0.007670429268588481
04:30:07 done sampling a new configuration.
04:30:07 HBMASTER: schedule new run for iteration 6
04:30:07 HBMASTER: trying submitting job (6, 0, 3) to dispatcher
04:30:07 HBMASTER: submitting job (6, 0, 3) to dispatcher
04:30:07 DISPATCHER: trying to submit job (6, 0, 3)
04:30:07 DISPATCHER: trying to notify the job_runner thread.
04:30:07 HBMASTER: job (6, 0, 3) submitted to dispatcher
04:30:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:30:07 DISPATCHER: Trying to submit another job.
04:30:07 DISPATCHER: starting job (6, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:30:07 DISPATCHER: job (6, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:30:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:30:07 WORKER: start processing job (6, 0, 3)
04:30:07 WORKER: args: ()
04:30:07 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 335, 'last_n_outputs': 49, 'leak_rate': 0.8123271740657585, 'lr': 0.004243743113216056, 'optimizer': 'Adam', 'sparsity': 0.9395701981155641, 'steps_to_train': 96, 'weight_decay': 0.010251694241592653}, 'budget': 400.0, 'working_directory': '.'}
04:30:39 DISPATCHER: Starting worker discovery
04:30:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:30:39 DISPATCHER: Finished worker discovery
04:31:39 DISPATCHER: Starting worker discovery
04:31:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:31:39 DISPATCHER: Finished worker discovery
04:32:39 DISPATCHER: Starting worker discovery
04:32:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:32:39 DISPATCHER: Finished worker discovery
04:33:39 DISPATCHER: Starting worker discovery
04:33:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:33:39 DISPATCHER: Finished worker discovery
04:34:39 DISPATCHER: Starting worker discovery
04:34:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:34:39 DISPATCHER: Finished worker discovery
04:35:39 DISPATCHER: Starting worker discovery
04:35:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:35:39 DISPATCHER: Finished worker discovery
04:36:39 DISPATCHER: Starting worker discovery
04:36:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:36:39 DISPATCHER: Finished worker discovery
04:37:39 DISPATCHER: Starting worker discovery
04:37:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:37:39 DISPATCHER: Finished worker discovery
04:37:57 WORKER: done with job (6, 0, 3), trying to register it.
04:37:57 WORKER: registered result for job (6, 0, 3) with dispatcher
04:37:57 DISPATCHER: job (6, 0, 3) finished
04:37:57 DISPATCHER: register_result: lock acquired
04:37:57 DISPATCHER: job (6, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
04:37:57 job_id: (6, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 335, 'last_n_outputs': 49, 'leak_rate': 0.8123271740657585, 'lr': 0.004243743113216056, 'optimizer': 'Adam', 'sparsity': 0.9395701981155641, 'steps_to_train': 96, 'weight_decay': 0.010251694241592653}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3510271924631816, 'info': {'music_genre': 0.3510271924631816, 'config': "{'batch_size': 128, 'hidden_dim': 335, 'last_n_outputs': 49, 'leak_rate': 0.8123271740657585, 'lr': 0.004243743113216056, 'optimizer': 'Adam', 'sparsity': 0.9395701981155641, 'steps_to_train': 96, 'weight_decay': 0.010251694241592653}"}}
exception: None

04:37:57 job_callback for (6, 0, 3) started
04:37:57 job_callback for (6, 0, 3) got condition
04:37:57 DISPATCHER: Trying to submit another job.
04:37:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:37:57 done building a new model for budget 400.000000 based on 10/18 split
Best loss for this budget:-0.400060





04:37:57 HBMASTER: Trying to run another job!
04:37:57 job_callback for (6, 0, 3) finished
04:37:57 start sampling a new configuration.
04:37:57 best_vector: [3, 0.45138438461324515, 0.9888182553516368, 0.7283200493271509, 0.24618309269706296, 1, 0.809442511590445, 0.9644424198857533, 0.08203599294127144], 6.913326840859695e-32, 0.14464815898616573, -0.013954480596202959
04:37:57 done sampling a new configuration.
04:37:57 HBMASTER: schedule new run for iteration 6
04:37:57 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
04:37:57 HBMASTER: submitting job (6, 0, 4) to dispatcher
04:37:57 DISPATCHER: trying to submit job (6, 0, 4)
04:37:57 DISPATCHER: trying to notify the job_runner thread.
04:37:57 HBMASTER: job (6, 0, 4) submitted to dispatcher
04:37:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:37:57 DISPATCHER: Trying to submit another job.
04:37:57 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:37:57 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:37:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:37:57 WORKER: start processing job (6, 0, 4)
04:37:57 WORKER: args: ()
04:37:57 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 561, 'last_n_outputs': 50, 'leak_rate': 0.9320800123317877, 'lr': 0.003107178372931638, 'optimizer': 'SGD', 'sparsity': 0.9442662027817068, 'steps_to_train': 97, 'weight_decay': 0.012785899531800654}, 'budget': 400.0, 'working_directory': '.'}
04:38:39 DISPATCHER: Starting worker discovery
04:38:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:38:39 DISPATCHER: Finished worker discovery
04:39:39 DISPATCHER: Starting worker discovery
04:39:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:39:39 DISPATCHER: Finished worker discovery
04:40:39 DISPATCHER: Starting worker discovery
04:40:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:40:39 DISPATCHER: Finished worker discovery
04:41:39 DISPATCHER: Starting worker discovery
04:41:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:41:39 DISPATCHER: Finished worker discovery
04:42:39 DISPATCHER: Starting worker discovery
04:42:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:42:39 DISPATCHER: Finished worker discovery
04:43:39 DISPATCHER: Starting worker discovery
04:43:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:43:39 DISPATCHER: Finished worker discovery
04:44:39 DISPATCHER: Starting worker discovery
04:44:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:44:39 DISPATCHER: Finished worker discovery
04:45:37 WORKER: done with job (6, 0, 4), trying to register it.
04:45:37 WORKER: registered result for job (6, 0, 4) with dispatcher
04:45:37 DISPATCHER: job (6, 0, 4) finished
04:45:37 DISPATCHER: register_result: lock acquired
04:45:37 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
04:45:37 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 561, 'last_n_outputs': 50, 'leak_rate': 0.9320800123317877, 'lr': 0.003107178372931638, 'optimizer': 'SGD', 'sparsity': 0.9442662027817068, 'steps_to_train': 97, 'weight_decay': 0.012785899531800654}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.36665096362343574, 'info': {'music_genre': 0.36665096362343574, 'config': "{'batch_size': 128, 'hidden_dim': 561, 'last_n_outputs': 50, 'leak_rate': 0.9320800123317877, 'lr': 0.003107178372931638, 'optimizer': 'SGD', 'sparsity': 0.9442662027817068, 'steps_to_train': 97, 'weight_decay': 0.012785899531800654}"}}
exception: None

04:45:37 job_callback for (6, 0, 4) started
04:45:37 DISPATCHER: Trying to submit another job.
04:45:37 job_callback for (6, 0, 4) got condition
04:45:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:45:37 done building a new model for budget 400.000000 based on 10/19 split
Best loss for this budget:-0.400060





04:45:37 HBMASTER: Trying to run another job!
04:45:37 job_callback for (6, 0, 4) finished
04:45:37 start sampling a new configuration.
04:45:37 best_vector: [3, 0.4526960994545902, 0.8519614877673499, 0.09431415116603506, 0.30642871135852795, 0, 0.9156179100926378, 0.7499424172988444, 0.24365131186340958], 1.4320357921726573e-31, 0.0698306568499115, -0.02789499274861164
04:45:37 done sampling a new configuration.
04:45:37 HBMASTER: schedule new run for iteration 6
04:45:37 HBMASTER: trying submitting job (6, 0, 5) to dispatcher
04:45:37 HBMASTER: submitting job (6, 0, 5) to dispatcher
04:45:37 DISPATCHER: trying to submit job (6, 0, 5)
04:45:37 DISPATCHER: trying to notify the job_runner thread.
04:45:37 HBMASTER: job (6, 0, 5) submitted to dispatcher
04:45:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:45:37 DISPATCHER: Trying to submit another job.
04:45:37 DISPATCHER: starting job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:45:37 DISPATCHER: job (6, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:45:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:45:37 WORKER: start processing job (6, 0, 5)
04:45:37 WORKER: args: ()
04:45:37 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 562, 'last_n_outputs': 44, 'leak_rate': 0.7735785377915088, 'lr': 0.004100694565897287, 'optimizer': 'Adam', 'sparsity': 0.9697482984222331, 'steps_to_train': 78, 'weight_decay': 0.020749023626748627}, 'budget': 400.0, 'working_directory': '.'}
04:45:39 DISPATCHER: Starting worker discovery
04:45:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:45:39 DISPATCHER: Finished worker discovery
04:46:39 DISPATCHER: Starting worker discovery
04:46:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:46:39 DISPATCHER: Finished worker discovery
04:47:39 DISPATCHER: Starting worker discovery
04:47:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:47:39 DISPATCHER: Finished worker discovery
04:48:39 DISPATCHER: Starting worker discovery
04:48:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:48:39 DISPATCHER: Finished worker discovery
04:49:39 DISPATCHER: Starting worker discovery
04:49:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:49:39 DISPATCHER: Finished worker discovery
04:50:39 DISPATCHER: Starting worker discovery
04:50:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:50:39 DISPATCHER: Finished worker discovery
04:51:39 DISPATCHER: Starting worker discovery
04:51:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:51:39 DISPATCHER: Finished worker discovery
04:52:39 DISPATCHER: Starting worker discovery
04:52:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:52:39 DISPATCHER: Finished worker discovery
04:53:30 WORKER: done with job (6, 0, 5), trying to register it.
04:53:30 WORKER: registered result for job (6, 0, 5) with dispatcher
04:53:30 DISPATCHER: job (6, 0, 5) finished
04:53:30 DISPATCHER: register_result: lock acquired
04:53:30 DISPATCHER: job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
04:53:30 job_id: (6, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 562, 'last_n_outputs': 44, 'leak_rate': 0.7735785377915088, 'lr': 0.004100694565897287, 'optimizer': 'Adam', 'sparsity': 0.9697482984222331, 'steps_to_train': 78, 'weight_decay': 0.020749023626748627}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3056521830041291, 'info': {'music_genre': 0.3056521830041291, 'config': "{'batch_size': 128, 'hidden_dim': 562, 'last_n_outputs': 44, 'leak_rate': 0.7735785377915088, 'lr': 0.004100694565897287, 'optimizer': 'Adam', 'sparsity': 0.9697482984222331, 'steps_to_train': 78, 'weight_decay': 0.020749023626748627}"}}
exception: None

04:53:30 job_callback for (6, 0, 5) started
04:53:30 DISPATCHER: Trying to submit another job.
04:53:30 job_callback for (6, 0, 5) got condition
04:53:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:53:30 done building a new model for budget 400.000000 based on 10/20 split
Best loss for this budget:-0.400060





04:53:30 HBMASTER: Trying to run another job!
04:53:30 job_callback for (6, 0, 5) finished
04:53:30 ITERATION: Advancing config (6, 0, 0) to next budget 1200.000000
04:53:30 ITERATION: Advancing config (6, 0, 1) to next budget 1200.000000
04:53:30 HBMASTER: schedule new run for iteration 6
04:53:30 HBMASTER: trying submitting job (6, 0, 0) to dispatcher
04:53:30 HBMASTER: submitting job (6, 0, 0) to dispatcher
04:53:30 DISPATCHER: trying to submit job (6, 0, 0)
04:53:30 DISPATCHER: trying to notify the job_runner thread.
04:53:30 HBMASTER: job (6, 0, 0) submitted to dispatcher
04:53:30 DISPATCHER: Trying to submit another job.
04:53:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:53:30 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:53:30 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:53:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:53:30 WORKER: start processing job (6, 0, 0)
04:53:30 WORKER: args: ()
04:53:30 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 943, 'last_n_outputs': 49, 'leak_rate': 0.785136362197788, 'lr': 0.010623036627732368, 'optimizer': 'SGD', 'sparsity': 0.9164955698567561, 'steps_to_train': 69, 'weight_decay': 0.01116065558749684}, 'budget': 1200.0, 'working_directory': '.'}
04:53:39 DISPATCHER: Starting worker discovery
04:53:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:53:39 DISPATCHER: Finished worker discovery
04:54:39 DISPATCHER: Starting worker discovery
04:54:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:54:39 DISPATCHER: Finished worker discovery
04:55:39 DISPATCHER: Starting worker discovery
04:55:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:55:39 DISPATCHER: Finished worker discovery
04:56:39 DISPATCHER: Starting worker discovery
04:56:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:56:39 DISPATCHER: Finished worker discovery
04:57:39 DISPATCHER: Starting worker discovery
04:57:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:57:39 DISPATCHER: Finished worker discovery
04:58:39 DISPATCHER: Starting worker discovery
04:58:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:58:39 DISPATCHER: Finished worker discovery
04:59:39 DISPATCHER: Starting worker discovery
04:59:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:59:39 DISPATCHER: Finished worker discovery
05:00:39 DISPATCHER: Starting worker discovery
05:00:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:00:39 DISPATCHER: Finished worker discovery
05:01:39 DISPATCHER: Starting worker discovery
05:01:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:01:39 DISPATCHER: Finished worker discovery
05:02:39 DISPATCHER: Starting worker discovery
05:02:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:02:39 DISPATCHER: Finished worker discovery
05:03:39 DISPATCHER: Starting worker discovery
05:03:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:03:39 DISPATCHER: Finished worker discovery
05:04:39 DISPATCHER: Starting worker discovery
05:04:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:04:39 DISPATCHER: Finished worker discovery
05:05:39 DISPATCHER: Starting worker discovery
05:05:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:05:39 DISPATCHER: Finished worker discovery
05:06:39 DISPATCHER: Starting worker discovery
05:06:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:06:39 DISPATCHER: Finished worker discovery
05:07:39 DISPATCHER: Starting worker discovery
05:07:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:07:39 DISPATCHER: Finished worker discovery
05:08:39 DISPATCHER: Starting worker discovery
05:08:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:08:39 DISPATCHER: Finished worker discovery
05:09:39 DISPATCHER: Starting worker discovery
05:09:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:09:39 DISPATCHER: Finished worker discovery
05:10:39 DISPATCHER: Starting worker discovery
05:10:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:10:39 DISPATCHER: Finished worker discovery
05:11:39 DISPATCHER: Starting worker discovery
05:11:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:11:39 DISPATCHER: Finished worker discovery
05:12:39 DISPATCHER: Starting worker discovery
05:12:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:12:39 DISPATCHER: Finished worker discovery
05:13:39 DISPATCHER: Starting worker discovery
05:13:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:13:39 DISPATCHER: Finished worker discovery
05:14:34 WORKER: done with job (6, 0, 0), trying to register it.
05:14:34 WORKER: registered result for job (6, 0, 0) with dispatcher
05:14:34 DISPATCHER: job (6, 0, 0) finished
05:14:34 DISPATCHER: register_result: lock acquired
05:14:34 DISPATCHER: job (6, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
05:14:34 job_id: (6, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 943, 'last_n_outputs': 49, 'leak_rate': 0.785136362197788, 'lr': 0.010623036627732368, 'optimizer': 'SGD', 'sparsity': 0.9164955698567561, 'steps_to_train': 69, 'weight_decay': 0.01116065558749684}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.3751725005812089, 'info': {'music_genre': 0.3751725005812089, 'config': "{'batch_size': 128, 'hidden_dim': 943, 'last_n_outputs': 49, 'leak_rate': 0.785136362197788, 'lr': 0.010623036627732368, 'optimizer': 'SGD', 'sparsity': 0.9164955698567561, 'steps_to_train': 69, 'weight_decay': 0.01116065558749684}"}}
exception: None

05:14:34 job_callback for (6, 0, 0) started
05:14:34 job_callback for (6, 0, 0) got condition
05:14:34 DISPATCHER: Trying to submit another job.
05:14:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:14:34 HBMASTER: Trying to run another job!
05:14:34 job_callback for (6, 0, 0) finished
05:14:34 HBMASTER: schedule new run for iteration 6
05:14:34 HBMASTER: trying submitting job (6, 0, 1) to dispatcher
05:14:34 HBMASTER: submitting job (6, 0, 1) to dispatcher
05:14:34 DISPATCHER: trying to submit job (6, 0, 1)
05:14:34 DISPATCHER: trying to notify the job_runner thread.
05:14:34 HBMASTER: job (6, 0, 1) submitted to dispatcher
05:14:34 DISPATCHER: Trying to submit another job.
05:14:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:14:34 DISPATCHER: starting job (6, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:14:34 DISPATCHER: job (6, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:14:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:14:34 WORKER: start processing job (6, 0, 1)
05:14:34 WORKER: args: ()
05:14:34 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 961, 'last_n_outputs': 33, 'leak_rate': 0.7593932355107704, 'lr': 0.01369264268379453, 'optimizer': 'SGD', 'sparsity': 0.9154079644865224, 'steps_to_train': 17, 'weight_decay': 0.011526142140834588}, 'budget': 1200.0, 'working_directory': '.'}
05:14:39 DISPATCHER: Starting worker discovery
05:14:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:14:39 DISPATCHER: Finished worker discovery
05:15:39 DISPATCHER: Starting worker discovery
05:15:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:15:39 DISPATCHER: Finished worker discovery
05:16:39 DISPATCHER: Starting worker discovery
05:16:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:16:39 DISPATCHER: Finished worker discovery
05:17:39 DISPATCHER: Starting worker discovery
05:17:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:17:39 DISPATCHER: Finished worker discovery
05:18:39 DISPATCHER: Starting worker discovery
05:18:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:18:39 DISPATCHER: Finished worker discovery
05:19:39 DISPATCHER: Starting worker discovery
05:19:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:19:39 DISPATCHER: Finished worker discovery
05:20:39 DISPATCHER: Starting worker discovery
05:20:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:20:39 DISPATCHER: Finished worker discovery
05:21:39 DISPATCHER: Starting worker discovery
05:21:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:21:39 DISPATCHER: Finished worker discovery
05:22:39 DISPATCHER: Starting worker discovery
05:22:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:22:39 DISPATCHER: Finished worker discovery
05:23:39 DISPATCHER: Starting worker discovery
05:23:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:23:39 DISPATCHER: Finished worker discovery
05:24:39 DISPATCHER: Starting worker discovery
05:24:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:24:39 DISPATCHER: Finished worker discovery
05:25:39 DISPATCHER: Starting worker discovery
05:25:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:25:39 DISPATCHER: Finished worker discovery
05:26:39 DISPATCHER: Starting worker discovery
05:26:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:26:39 DISPATCHER: Finished worker discovery
05:27:39 DISPATCHER: Starting worker discovery
05:27:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:27:39 DISPATCHER: Finished worker discovery
05:28:39 DISPATCHER: Starting worker discovery
05:28:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:28:39 DISPATCHER: Finished worker discovery
05:29:39 DISPATCHER: Starting worker discovery
05:29:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:29:39 DISPATCHER: Finished worker discovery
05:30:39 DISPATCHER: Starting worker discovery
05:30:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:30:39 DISPATCHER: Finished worker discovery
05:31:39 DISPATCHER: Starting worker discovery
05:31:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:31:39 DISPATCHER: Finished worker discovery
05:32:39 DISPATCHER: Starting worker discovery
05:32:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:32:39 DISPATCHER: Finished worker discovery
05:33:39 DISPATCHER: Starting worker discovery
05:33:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:33:39 DISPATCHER: Finished worker discovery
05:34:39 DISPATCHER: Starting worker discovery
05:34:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:34:39 DISPATCHER: Finished worker discovery
05:35:35 WORKER: done with job (6, 0, 1), trying to register it.
05:35:35 WORKER: registered result for job (6, 0, 1) with dispatcher
05:35:35 DISPATCHER: job (6, 0, 1) finished
05:35:35 DISPATCHER: register_result: lock acquired
05:35:35 DISPATCHER: job (6, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
05:35:35 job_id: (6, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 961, 'last_n_outputs': 33, 'leak_rate': 0.7593932355107704, 'lr': 0.01369264268379453, 'optimizer': 'SGD', 'sparsity': 0.9154079644865224, 'steps_to_train': 17, 'weight_decay': 0.011526142140834588}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.3485138317781451, 'info': {'music_genre': 0.3485138317781451, 'config': "{'batch_size': 128, 'hidden_dim': 961, 'last_n_outputs': 33, 'leak_rate': 0.7593932355107704, 'lr': 0.01369264268379453, 'optimizer': 'SGD', 'sparsity': 0.9154079644865224, 'steps_to_train': 17, 'weight_decay': 0.011526142140834588}"}}
exception: None

05:35:35 job_callback for (6, 0, 1) started
05:35:35 job_callback for (6, 0, 1) got condition
05:35:35 DISPATCHER: Trying to submit another job.
05:35:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:35:35 HBMASTER: Trying to run another job!
05:35:35 job_callback for (6, 0, 1) finished
05:35:35 start sampling a new configuration.
05:35:35 best_vector: [3, 0.217630815940198, 0.9200026077583697, 0.3446790692401772, 0.6952944420782513, 1, 0.6050897329088787, 0.5785504416944504, 0.2013680475605425], 3.254701986024373e-31, 0.030724779236132232, -0.0005903150354951279
05:35:35 done sampling a new configuration.
05:35:35 HBMASTER: schedule new run for iteration 7
05:35:35 HBMASTER: trying submitting job (7, 0, 0) to dispatcher
05:35:35 HBMASTER: submitting job (7, 0, 0) to dispatcher
05:35:35 DISPATCHER: trying to submit job (7, 0, 0)
05:35:35 DISPATCHER: trying to notify the job_runner thread.
05:35:35 HBMASTER: job (7, 0, 0) submitted to dispatcher
05:35:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:35:35 DISPATCHER: Trying to submit another job.
05:35:35 DISPATCHER: starting job (7, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:35:35 DISPATCHER: job (7, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:35:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:35:35 WORKER: start processing job (7, 0, 0)
05:35:35 WORKER: args: ()
05:35:35 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 374, 'last_n_outputs': 47, 'leak_rate': 0.8361697673100443, 'lr': 0.024580396503278732, 'optimizer': 'SGD', 'sparsity': 0.8952215358981309, 'steps_to_train': 62, 'weight_decay': 0.01828040739093254}, 'budget': 1200.0, 'working_directory': '.'}
05:35:39 DISPATCHER: Starting worker discovery
05:35:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:35:39 DISPATCHER: Finished worker discovery
05:36:39 DISPATCHER: Starting worker discovery
05:36:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:36:39 DISPATCHER: Finished worker discovery
05:37:39 DISPATCHER: Starting worker discovery
05:37:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:37:39 DISPATCHER: Finished worker discovery
05:38:39 DISPATCHER: Starting worker discovery
05:38:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:38:39 DISPATCHER: Finished worker discovery
05:39:39 DISPATCHER: Starting worker discovery
05:39:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:39:39 DISPATCHER: Finished worker discovery
05:40:39 DISPATCHER: Starting worker discovery
05:40:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:40:39 DISPATCHER: Finished worker discovery
05:41:39 DISPATCHER: Starting worker discovery
05:41:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:41:39 DISPATCHER: Finished worker discovery
05:42:39 DISPATCHER: Starting worker discovery
05:42:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:42:39 DISPATCHER: Finished worker discovery
05:43:39 DISPATCHER: Starting worker discovery
05:43:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:43:39 DISPATCHER: Finished worker discovery
05:44:39 DISPATCHER: Starting worker discovery
05:44:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:44:39 DISPATCHER: Finished worker discovery
05:45:39 DISPATCHER: Starting worker discovery
05:45:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:45:39 DISPATCHER: Finished worker discovery
05:46:39 DISPATCHER: Starting worker discovery
05:46:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:46:39 DISPATCHER: Finished worker discovery
05:47:39 DISPATCHER: Starting worker discovery
05:47:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:47:39 DISPATCHER: Finished worker discovery
05:48:39 DISPATCHER: Starting worker discovery
05:48:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:48:39 DISPATCHER: Finished worker discovery
05:49:39 DISPATCHER: Starting worker discovery
05:49:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:49:39 DISPATCHER: Finished worker discovery
05:50:39 DISPATCHER: Starting worker discovery
05:50:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:50:39 DISPATCHER: Finished worker discovery
05:51:39 DISPATCHER: Starting worker discovery
05:51:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:51:39 DISPATCHER: Finished worker discovery
05:52:39 DISPATCHER: Starting worker discovery
05:52:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:52:39 DISPATCHER: Finished worker discovery
05:53:39 DISPATCHER: Starting worker discovery
05:53:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:53:39 DISPATCHER: Finished worker discovery
05:54:39 DISPATCHER: Starting worker discovery
05:54:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:54:39 DISPATCHER: Finished worker discovery
05:55:39 DISPATCHER: Starting worker discovery
05:55:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:55:39 DISPATCHER: Finished worker discovery
05:56:35 WORKER: done with job (7, 0, 0), trying to register it.
05:56:35 WORKER: registered result for job (7, 0, 0) with dispatcher
05:56:35 DISPATCHER: job (7, 0, 0) finished
05:56:35 DISPATCHER: register_result: lock acquired
05:56:35 DISPATCHER: job (7, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
05:56:35 job_id: (7, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 374, 'last_n_outputs': 47, 'leak_rate': 0.8361697673100443, 'lr': 0.024580396503278732, 'optimizer': 'SGD', 'sparsity': 0.8952215358981309, 'steps_to_train': 62, 'weight_decay': 0.01828040739093254}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.36662383684254646, 'info': {'music_genre': 0.36662383684254646, 'config': "{'batch_size': 128, 'hidden_dim': 374, 'last_n_outputs': 47, 'leak_rate': 0.8361697673100443, 'lr': 0.024580396503278732, 'optimizer': 'SGD', 'sparsity': 0.8952215358981309, 'steps_to_train': 62, 'weight_decay': 0.01828040739093254}"}}
exception: None

05:56:35 job_callback for (7, 0, 0) started
05:56:35 DISPATCHER: Trying to submit another job.
05:56:35 job_callback for (7, 0, 0) got condition
05:56:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:56:35 HBMASTER: Trying to run another job!
05:56:35 job_callback for (7, 0, 0) finished
05:56:35 start sampling a new configuration.
05:56:35 done sampling a new configuration.
05:56:35 HBMASTER: schedule new run for iteration 7
05:56:35 HBMASTER: trying submitting job (7, 0, 1) to dispatcher
05:56:35 HBMASTER: submitting job (7, 0, 1) to dispatcher
05:56:35 DISPATCHER: trying to submit job (7, 0, 1)
05:56:35 DISPATCHER: trying to notify the job_runner thread.
05:56:35 HBMASTER: job (7, 0, 1) submitted to dispatcher
05:56:35 DISPATCHER: Trying to submit another job.
05:56:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:56:35 DISPATCHER: starting job (7, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:56:35 DISPATCHER: job (7, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:56:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:56:35 WORKER: start processing job (7, 0, 1)
05:56:35 WORKER: args: ()
05:56:35 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 890, 'last_n_outputs': 33, 'leak_rate': 0.9707040364967735, 'lr': 0.012599132657185914, 'optimizer': 'SGD', 'sparsity': 0.9818747303740013, 'steps_to_train': 20, 'weight_decay': 0.039316585043619144}, 'budget': 1200.0, 'working_directory': '.'}
05:56:39 DISPATCHER: Starting worker discovery
05:56:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:56:39 DISPATCHER: Finished worker discovery
05:57:39 DISPATCHER: Starting worker discovery
05:57:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:57:39 DISPATCHER: Finished worker discovery
05:58:39 DISPATCHER: Starting worker discovery
05:58:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:58:39 DISPATCHER: Finished worker discovery
05:59:39 DISPATCHER: Starting worker discovery
05:59:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:59:39 DISPATCHER: Finished worker discovery
06:00:39 DISPATCHER: Starting worker discovery
06:00:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:00:39 DISPATCHER: Finished worker discovery
06:01:39 DISPATCHER: Starting worker discovery
06:01:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:01:39 DISPATCHER: Finished worker discovery
06:02:39 DISPATCHER: Starting worker discovery
06:02:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:02:39 DISPATCHER: Finished worker discovery
06:03:39 DISPATCHER: Starting worker discovery
06:03:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:03:39 DISPATCHER: Finished worker discovery
06:04:39 DISPATCHER: Starting worker discovery
06:04:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:04:39 DISPATCHER: Finished worker discovery
06:05:39 DISPATCHER: Starting worker discovery
06:05:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:05:39 DISPATCHER: Finished worker discovery
06:06:39 DISPATCHER: Starting worker discovery
06:06:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:06:39 DISPATCHER: Finished worker discovery
06:07:39 DISPATCHER: Starting worker discovery
06:07:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:07:39 DISPATCHER: Finished worker discovery
06:08:39 DISPATCHER: Starting worker discovery
06:08:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:08:39 DISPATCHER: Finished worker discovery
06:09:39 DISPATCHER: Starting worker discovery
06:09:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:09:39 DISPATCHER: Finished worker discovery
06:10:39 DISPATCHER: Starting worker discovery
06:10:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:10:39 DISPATCHER: Finished worker discovery
06:11:39 DISPATCHER: Starting worker discovery
06:11:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:11:39 DISPATCHER: Finished worker discovery
06:12:39 DISPATCHER: Starting worker discovery
06:12:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:12:39 DISPATCHER: Finished worker discovery
06:13:39 DISPATCHER: Starting worker discovery
06:13:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:13:39 DISPATCHER: Finished worker discovery
06:14:39 DISPATCHER: Starting worker discovery
06:14:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:14:39 DISPATCHER: Finished worker discovery
06:15:39 DISPATCHER: Starting worker discovery
06:15:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:15:39 DISPATCHER: Finished worker discovery
06:16:39 DISPATCHER: Starting worker discovery
06:16:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:16:39 DISPATCHER: Finished worker discovery
06:17:38 WORKER: done with job (7, 0, 1), trying to register it.
06:17:38 WORKER: registered result for job (7, 0, 1) with dispatcher
06:17:38 DISPATCHER: job (7, 0, 1) finished
06:17:38 DISPATCHER: register_result: lock acquired
06:17:38 DISPATCHER: job (7, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
06:17:38 job_id: (7, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 890, 'last_n_outputs': 33, 'leak_rate': 0.9707040364967735, 'lr': 0.012599132657185914, 'optimizer': 'SGD', 'sparsity': 0.9818747303740013, 'steps_to_train': 20, 'weight_decay': 0.039316585043619144}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.3814049446101935, 'info': {'music_genre': 0.3814049446101935, 'config': "{'batch_size': 64, 'hidden_dim': 890, 'last_n_outputs': 33, 'leak_rate': 0.9707040364967735, 'lr': 0.012599132657185914, 'optimizer': 'SGD', 'sparsity': 0.9818747303740013, 'steps_to_train': 20, 'weight_decay': 0.039316585043619144}"}}
exception: None

06:17:38 job_callback for (7, 0, 1) started
06:17:38 DISPATCHER: Trying to submit another job.
06:17:38 job_callback for (7, 0, 1) got condition
06:17:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:17:38 HBMASTER: Trying to run another job!
06:17:38 job_callback for (7, 0, 1) finished
06:17:38 start sampling a new configuration.
06:17:38 best_vector: [3, 0.43796733507857116, 0.8988817782284799, 0.42818920828818774, 0.5423022948048697, 0, 0.9772821782913454, 0.9680712243555318, 0.03685848044851754], 2.4598521427716245e-31, 0.04065284992590065, -0.026943105806163055
06:17:38 done sampling a new configuration.
06:17:38 HBMASTER: schedule new run for iteration 7
06:17:38 HBMASTER: trying submitting job (7, 0, 2) to dispatcher
06:17:38 HBMASTER: submitting job (7, 0, 2) to dispatcher
06:17:38 DISPATCHER: trying to submit job (7, 0, 2)
06:17:38 DISPATCHER: trying to notify the job_runner thread.
06:17:38 HBMASTER: job (7, 0, 2) submitted to dispatcher
06:17:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:17:38 DISPATCHER: Trying to submit another job.
06:17:38 DISPATCHER: starting job (7, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
06:17:38 DISPATCHER: job (7, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
06:17:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:17:38 WORKER: start processing job (7, 0, 2)
06:17:38 WORKER: args: ()
06:17:38 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 550, 'last_n_outputs': 46, 'leak_rate': 0.8570473020720469, 'lr': 0.01215079208482505, 'optimizer': 'Adam', 'sparsity': 0.9845477227899229, 'steps_to_train': 98, 'weight_decay': 0.011167449279381566}, 'budget': 1200.0, 'working_directory': '.'}
06:17:39 DISPATCHER: Starting worker discovery
06:17:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:17:39 DISPATCHER: Finished worker discovery
06:18:39 DISPATCHER: Starting worker discovery
06:18:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:18:39 DISPATCHER: Finished worker discovery
06:19:39 DISPATCHER: Starting worker discovery
06:19:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:19:39 DISPATCHER: Finished worker discovery
06:20:39 DISPATCHER: Starting worker discovery
06:20:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:20:39 DISPATCHER: Finished worker discovery
06:21:39 DISPATCHER: Starting worker discovery
06:21:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:21:39 DISPATCHER: Finished worker discovery
06:22:39 DISPATCHER: Starting worker discovery
06:22:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:22:39 DISPATCHER: Finished worker discovery
06:23:39 DISPATCHER: Starting worker discovery
06:23:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:23:39 DISPATCHER: Finished worker discovery
06:24:39 DISPATCHER: Starting worker discovery
06:24:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:24:39 DISPATCHER: Finished worker discovery
06:25:39 DISPATCHER: Starting worker discovery
06:25:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:25:39 DISPATCHER: Finished worker discovery
06:26:39 DISPATCHER: Starting worker discovery
06:26:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:26:39 DISPATCHER: Finished worker discovery
06:27:39 DISPATCHER: Starting worker discovery
06:27:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:27:39 DISPATCHER: Finished worker discovery
06:28:39 DISPATCHER: Starting worker discovery
06:28:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:28:39 DISPATCHER: Finished worker discovery
06:29:39 DISPATCHER: Starting worker discovery
06:29:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:29:39 DISPATCHER: Finished worker discovery
06:30:39 DISPATCHER: Starting worker discovery
06:30:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:30:39 DISPATCHER: Finished worker discovery
06:31:39 DISPATCHER: Starting worker discovery
06:31:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:31:39 DISPATCHER: Finished worker discovery
06:32:39 DISPATCHER: Starting worker discovery
06:32:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:32:39 DISPATCHER: Finished worker discovery
06:33:39 DISPATCHER: Starting worker discovery
06:33:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:33:39 DISPATCHER: Finished worker discovery
06:34:39 DISPATCHER: Starting worker discovery
06:34:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:34:39 DISPATCHER: Finished worker discovery
06:35:39 DISPATCHER: Starting worker discovery
06:35:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:35:39 DISPATCHER: Finished worker discovery
06:36:39 DISPATCHER: Starting worker discovery
06:36:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:36:39 DISPATCHER: Finished worker discovery
06:37:39 DISPATCHER: Starting worker discovery
06:37:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:37:39 DISPATCHER: Finished worker discovery
06:38:39 DISPATCHER: Starting worker discovery
06:38:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:38:39 DISPATCHER: Finished worker discovery
06:38:54 WORKER: done with job (7, 0, 2), trying to register it.
06:38:54 WORKER: registered result for job (7, 0, 2) with dispatcher
06:38:54 DISPATCHER: job (7, 0, 2) finished
06:38:54 DISPATCHER: register_result: lock acquired
06:38:54 DISPATCHER: job (7, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
06:38:54 job_id: (7, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 550, 'last_n_outputs': 46, 'leak_rate': 0.8570473020720469, 'lr': 0.01215079208482505, 'optimizer': 'Adam', 'sparsity': 0.9845477227899229, 'steps_to_train': 98, 'weight_decay': 0.011167449279381566}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.2168997213500145, 'info': {'music_genre': 0.2168997213500145, 'config': "{'batch_size': 128, 'hidden_dim': 550, 'last_n_outputs': 46, 'leak_rate': 0.8570473020720469, 'lr': 0.01215079208482505, 'optimizer': 'Adam', 'sparsity': 0.9845477227899229, 'steps_to_train': 98, 'weight_decay': 0.011167449279381566}"}}
exception: None

06:38:54 job_callback for (7, 0, 2) started
06:38:54 job_callback for (7, 0, 2) got condition
06:38:54 DISPATCHER: Trying to submit another job.
06:38:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:38:54 HBMASTER: Trying to run another job!
06:38:54 job_callback for (7, 0, 2) finished
06:38:54 start sampling a new configuration.
06:38:54 done sampling a new configuration.
06:38:54 HBMASTER: schedule new run for iteration 7
06:38:54 HBMASTER: trying submitting job (7, 0, 3) to dispatcher
06:38:54 HBMASTER: submitting job (7, 0, 3) to dispatcher
06:38:54 DISPATCHER: trying to submit job (7, 0, 3)
06:38:54 DISPATCHER: trying to notify the job_runner thread.
06:38:54 HBMASTER: job (7, 0, 3) submitted to dispatcher
06:38:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:38:54 DISPATCHER: Trying to submit another job.
06:38:54 DISPATCHER: starting job (7, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
06:38:54 DISPATCHER: job (7, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
06:38:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:38:54 WORKER: start processing job (7, 0, 3)
06:38:54 WORKER: args: ()
06:38:54 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 216, 'last_n_outputs': 42, 'leak_rate': 0.9330393174846396, 'lr': 0.004062355968818843, 'optimizer': 'SGD', 'sparsity': 0.7806125918628958, 'steps_to_train': 36, 'weight_decay': 0.016090150034710062}, 'budget': 1200.0, 'working_directory': '.'}
06:39:39 DISPATCHER: Starting worker discovery
06:39:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:39:39 DISPATCHER: Finished worker discovery
06:40:39 DISPATCHER: Starting worker discovery
06:40:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:40:39 DISPATCHER: Finished worker discovery
06:41:39 DISPATCHER: Starting worker discovery
06:41:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:41:39 DISPATCHER: Finished worker discovery
06:42:39 DISPATCHER: Starting worker discovery
06:42:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:42:39 DISPATCHER: Finished worker discovery
06:43:39 DISPATCHER: Starting worker discovery
06:43:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:43:39 DISPATCHER: Finished worker discovery
06:44:39 DISPATCHER: Starting worker discovery
06:44:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:44:39 DISPATCHER: Finished worker discovery
06:45:39 DISPATCHER: Starting worker discovery
06:45:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:45:39 DISPATCHER: Finished worker discovery
06:46:39 DISPATCHER: Starting worker discovery
06:46:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:46:39 DISPATCHER: Finished worker discovery
06:47:39 DISPATCHER: Starting worker discovery
06:47:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:47:39 DISPATCHER: Finished worker discovery
06:48:39 DISPATCHER: Starting worker discovery
06:48:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:48:39 DISPATCHER: Finished worker discovery
06:49:39 DISPATCHER: Starting worker discovery
06:49:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:49:39 DISPATCHER: Finished worker discovery
06:50:39 DISPATCHER: Starting worker discovery
06:50:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:50:39 DISPATCHER: Finished worker discovery
06:51:39 DISPATCHER: Starting worker discovery
06:51:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:51:39 DISPATCHER: Finished worker discovery
06:52:39 DISPATCHER: Starting worker discovery
06:52:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:52:39 DISPATCHER: Finished worker discovery
06:53:39 DISPATCHER: Starting worker discovery
06:53:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:53:40 DISPATCHER: Finished worker discovery
06:54:40 DISPATCHER: Starting worker discovery
06:54:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:54:40 DISPATCHER: Finished worker discovery
06:55:40 DISPATCHER: Starting worker discovery
06:55:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:55:40 DISPATCHER: Finished worker discovery
06:56:40 DISPATCHER: Starting worker discovery
06:56:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:56:40 DISPATCHER: Finished worker discovery
06:57:40 DISPATCHER: Starting worker discovery
06:57:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:57:40 DISPATCHER: Finished worker discovery
06:58:40 DISPATCHER: Starting worker discovery
06:58:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:58:40 DISPATCHER: Finished worker discovery
06:59:40 DISPATCHER: Starting worker discovery
06:59:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:59:40 DISPATCHER: Finished worker discovery
06:59:59 WORKER: done with job (7, 0, 3), trying to register it.
06:59:59 WORKER: registered result for job (7, 0, 3) with dispatcher
06:59:59 DISPATCHER: job (7, 0, 3) finished
06:59:59 DISPATCHER: register_result: lock acquired
06:59:59 DISPATCHER: job (7, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
06:59:59 job_id: (7, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 216, 'last_n_outputs': 42, 'leak_rate': 0.9330393174846396, 'lr': 0.004062355968818843, 'optimizer': 'SGD', 'sparsity': 0.7806125918628958, 'steps_to_train': 36, 'weight_decay': 0.016090150034710062}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.33738214523629717, 'info': {'music_genre': 0.33738214523629717, 'config': "{'batch_size': 128, 'hidden_dim': 216, 'last_n_outputs': 42, 'leak_rate': 0.9330393174846396, 'lr': 0.004062355968818843, 'optimizer': 'SGD', 'sparsity': 0.7806125918628958, 'steps_to_train': 36, 'weight_decay': 0.016090150034710062}"}}
exception: None

06:59:59 job_callback for (7, 0, 3) started
06:59:59 job_callback for (7, 0, 3) got condition
06:59:59 DISPATCHER: Trying to submit another job.
06:59:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:59:59 HBMASTER: Trying to run another job!
06:59:59 job_callback for (7, 0, 3) finished
06:59:59 start sampling a new configuration.
06:59:59 best_vector: [3, 0.13773312906015234, 0.740373873056837, 0.6425712366507053, 0.15518919645138515, 0, 0.803016287168946, 0.8729026909290982, 0.026099423517061442], 3.923228357046653e-33, 2.548921217404701, -0.043418245885164464
06:59:59 done sampling a new configuration.
06:59:59 HBMASTER: schedule new run for iteration 8
06:59:59 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
06:59:59 HBMASTER: submitting job (8, 0, 0) to dispatcher
06:59:59 DISPATCHER: trying to submit job (8, 0, 0)
06:59:59 DISPATCHER: trying to notify the job_runner thread.
06:59:59 HBMASTER: job (8, 0, 0) submitted to dispatcher
06:59:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:59:59 DISPATCHER: Trying to submit another job.
06:59:59 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
06:59:59 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
06:59:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:59:59 WORKER: start processing job (8, 0, 0)
06:59:59 WORKER: args: ()
06:59:59 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 310, 'last_n_outputs': 40, 'leak_rate': 0.9106428091626764, 'lr': 0.002043517649097409, 'optimizer': 'Adam', 'sparsity': 0.942723908920547, 'steps_to_train': 89, 'weight_decay': 0.010813247235387496}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:00:40 DISPATCHER: Starting worker discovery
07:00:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:00:40 DISPATCHER: Finished worker discovery
07:01:40 DISPATCHER: Starting worker discovery
07:01:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:01:40 DISPATCHER: Finished worker discovery
07:02:00 WORKER: done with job (8, 0, 0), trying to register it.
07:02:00 WORKER: registered result for job (8, 0, 0) with dispatcher
07:02:00 DISPATCHER: job (8, 0, 0) finished
07:02:00 DISPATCHER: register_result: lock acquired
07:02:00 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:02:00 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 310, 'last_n_outputs': 40, 'leak_rate': 0.9106428091626764, 'lr': 0.002043517649097409, 'optimizer': 'Adam', 'sparsity': 0.942723908920547, 'steps_to_train': 89, 'weight_decay': 0.010813247235387496}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3390092633183554, 'info': {'music_genre': 0.3390092633183554, 'config': "{'batch_size': 128, 'hidden_dim': 310, 'last_n_outputs': 40, 'leak_rate': 0.9106428091626764, 'lr': 0.002043517649097409, 'optimizer': 'Adam', 'sparsity': 0.942723908920547, 'steps_to_train': 89, 'weight_decay': 0.010813247235387496}"}}
exception: None

07:02:00 job_callback for (8, 0, 0) started
07:02:00 DISPATCHER: Trying to submit another job.
07:02:00 job_callback for (8, 0, 0) got condition
07:02:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:02:00 HBMASTER: Trying to run another job!
07:02:00 job_callback for (8, 0, 0) finished
07:02:00 start sampling a new configuration.
07:02:00 best_vector: [3, 0.13803422692304457, 0.8010175385297129, 0.8613682581955586, 0.5111663497277281, 1, 0.8303735280681801, 0.9673380984517272, 0.0663186533982977], 3.0445338964092355e-32, 0.3284575025357456, -0.0016496749759846664
07:02:00 done sampling a new configuration.
07:02:00 HBMASTER: schedule new run for iteration 8
07:02:00 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
07:02:00 HBMASTER: submitting job (8, 0, 1) to dispatcher
07:02:00 DISPATCHER: trying to submit job (8, 0, 1)
07:02:00 DISPATCHER: trying to notify the job_runner thread.
07:02:00 HBMASTER: job (8, 0, 1) submitted to dispatcher
07:02:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:02:00 DISPATCHER: Trying to submit another job.
07:02:00 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:02:00 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:02:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:02:00 WORKER: start processing job (8, 0, 1)
07:02:00 WORKER: args: ()
07:02:00 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 310, 'last_n_outputs': 42, 'leak_rate': 0.9653420645488897, 'lr': 0.010527680577572272, 'optimizer': 'SGD', 'sparsity': 0.9492896467363632, 'steps_to_train': 98, 'weight_decay': 0.012197829466366366}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:02:40 DISPATCHER: Starting worker discovery
07:02:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:02:40 DISPATCHER: Finished worker discovery
07:03:40 DISPATCHER: Starting worker discovery
07:03:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:03:40 DISPATCHER: Finished worker discovery
07:03:43 WORKER: done with job (8, 0, 1), trying to register it.
07:03:43 WORKER: registered result for job (8, 0, 1) with dispatcher
07:03:43 DISPATCHER: job (8, 0, 1) finished
07:03:43 DISPATCHER: register_result: lock acquired
07:03:43 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:03:43 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 310, 'last_n_outputs': 42, 'leak_rate': 0.9653420645488897, 'lr': 0.010527680577572272, 'optimizer': 'SGD', 'sparsity': 0.9492896467363632, 'steps_to_train': 98, 'weight_decay': 0.012197829466366366}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3020327663456989, 'info': {'music_genre': 0.3020327663456989, 'config': "{'batch_size': 128, 'hidden_dim': 310, 'last_n_outputs': 42, 'leak_rate': 0.9653420645488897, 'lr': 0.010527680577572272, 'optimizer': 'SGD', 'sparsity': 0.9492896467363632, 'steps_to_train': 98, 'weight_decay': 0.012197829466366366}"}}
exception: None

07:03:43 job_callback for (8, 0, 1) started
07:03:43 DISPATCHER: Trying to submit another job.
07:03:43 job_callback for (8, 0, 1) got condition
07:03:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:03:43 HBMASTER: Trying to run another job!
07:03:43 job_callback for (8, 0, 1) finished
07:03:43 start sampling a new configuration.
07:03:43 done sampling a new configuration.
07:03:43 HBMASTER: schedule new run for iteration 8
07:03:43 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
07:03:43 HBMASTER: submitting job (8, 0, 2) to dispatcher
07:03:43 DISPATCHER: trying to submit job (8, 0, 2)
07:03:43 DISPATCHER: trying to notify the job_runner thread.
07:03:43 HBMASTER: job (8, 0, 2) submitted to dispatcher
07:03:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:03:43 DISPATCHER: Trying to submit another job.
07:03:43 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:03:43 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:03:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:03:43 WORKER: start processing job (8, 0, 2)
07:03:43 WORKER: args: ()
07:03:43 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 761, 'last_n_outputs': 46, 'leak_rate': 0.9526078051760473, 'lr': 0.08199175812130413, 'optimizer': 'Adam', 'sparsity': 0.8628425665265245, 'steps_to_train': 30, 'weight_decay': 0.03977768134411548}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:04:40 DISPATCHER: Starting worker discovery
07:04:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:04:40 DISPATCHER: Finished worker discovery
07:05:31 WORKER: done with job (8, 0, 2), trying to register it.
07:05:31 WORKER: registered result for job (8, 0, 2) with dispatcher
07:05:31 DISPATCHER: job (8, 0, 2) finished
07:05:31 DISPATCHER: register_result: lock acquired
07:05:31 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:05:31 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 761, 'last_n_outputs': 46, 'leak_rate': 0.9526078051760473, 'lr': 0.08199175812130413, 'optimizer': 'Adam', 'sparsity': 0.8628425665265245, 'steps_to_train': 30, 'weight_decay': 0.03977768134411548}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.05138371760184718, 'info': {'music_genre': 0.05138371760184718, 'config': "{'batch_size': 32, 'hidden_dim': 761, 'last_n_outputs': 46, 'leak_rate': 0.9526078051760473, 'lr': 0.08199175812130413, 'optimizer': 'Adam', 'sparsity': 0.8628425665265245, 'steps_to_train': 30, 'weight_decay': 0.03977768134411548}"}}
exception: None

07:05:31 job_callback for (8, 0, 2) started
07:05:31 job_callback for (8, 0, 2) got condition
07:05:31 DISPATCHER: Trying to submit another job.
07:05:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:05:31 HBMASTER: Trying to run another job!
07:05:31 job_callback for (8, 0, 2) finished
07:05:31 start sampling a new configuration.
07:05:31 done sampling a new configuration.
07:05:31 HBMASTER: schedule new run for iteration 8
07:05:31 HBMASTER: trying submitting job (8, 0, 3) to dispatcher
07:05:31 HBMASTER: submitting job (8, 0, 3) to dispatcher
07:05:31 DISPATCHER: trying to submit job (8, 0, 3)
07:05:31 DISPATCHER: trying to notify the job_runner thread.
07:05:31 HBMASTER: job (8, 0, 3) submitted to dispatcher
07:05:31 DISPATCHER: Trying to submit another job.
07:05:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:05:31 DISPATCHER: starting job (8, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:05:31 DISPATCHER: job (8, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:05:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:05:31 WORKER: start processing job (8, 0, 3)
07:05:31 WORKER: args: ()
07:05:31 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 694, 'last_n_outputs': 34, 'leak_rate': 0.8130744023630299, 'lr': 0.06701010969055275, 'optimizer': 'Adam', 'sparsity': 0.7793467836810778, 'steps_to_train': 28, 'weight_decay': 0.1322648146257524}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:05:40 DISPATCHER: Starting worker discovery
07:05:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:05:40 DISPATCHER: Finished worker discovery
07:06:40 DISPATCHER: Starting worker discovery
07:06:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:06:40 DISPATCHER: Finished worker discovery
07:07:16 WORKER: done with job (8, 0, 3), trying to register it.
07:07:16 WORKER: registered result for job (8, 0, 3) with dispatcher
07:07:16 DISPATCHER: job (8, 0, 3) finished
07:07:16 DISPATCHER: register_result: lock acquired
07:07:16 DISPATCHER: job (8, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:07:16 job_id: (8, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 694, 'last_n_outputs': 34, 'leak_rate': 0.8130744023630299, 'lr': 0.06701010969055275, 'optimizer': 'Adam', 'sparsity': 0.7793467836810778, 'steps_to_train': 28, 'weight_decay': 0.1322648146257524}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.15815572031207467, 'info': {'music_genre': 0.15815572031207467, 'config': "{'batch_size': 128, 'hidden_dim': 694, 'last_n_outputs': 34, 'leak_rate': 0.8130744023630299, 'lr': 0.06701010969055275, 'optimizer': 'Adam', 'sparsity': 0.7793467836810778, 'steps_to_train': 28, 'weight_decay': 0.1322648146257524}"}}
exception: None

07:07:16 job_callback for (8, 0, 3) started
07:07:16 DISPATCHER: Trying to submit another job.
07:07:16 job_callback for (8, 0, 3) got condition
07:07:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:07:16 HBMASTER: Trying to run another job!
07:07:16 job_callback for (8, 0, 3) finished
07:07:16 start sampling a new configuration.
07:07:16 best_vector: [3, 0.21224930893706812, 0.9833566871617132, 0.3050891202192414, 0.2190111206415657, 0, 0.767622818315918, 0.6134007341900375, 0.049025371051888256], 1.1182156580875702e-33, 8.942818791414988, -0.12562134877554407
07:07:16 done sampling a new configuration.
07:07:16 HBMASTER: schedule new run for iteration 8
07:07:16 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
07:07:16 HBMASTER: submitting job (8, 0, 4) to dispatcher
07:07:16 DISPATCHER: trying to submit job (8, 0, 4)
07:07:16 DISPATCHER: trying to notify the job_runner thread.
07:07:16 HBMASTER: job (8, 0, 4) submitted to dispatcher
07:07:16 DISPATCHER: Trying to submit another job.
07:07:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:07:16 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:07:16 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:07:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:07:16 WORKER: start processing job (8, 0, 4)
07:07:16 WORKER: args: ()
07:07:16 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 370, 'last_n_outputs': 50, 'leak_rate': 0.8262722800548103, 'lr': 0.002741714578245071, 'optimizer': 'Adam', 'sparsity': 0.9342294763958203, 'steps_to_train': 65, 'weight_decay': 0.011581997804904856}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:07:40 DISPATCHER: Starting worker discovery
07:07:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:07:40 DISPATCHER: Finished worker discovery
07:08:40 DISPATCHER: Starting worker discovery
07:08:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:08:40 DISPATCHER: Finished worker discovery
07:09:01 WORKER: done with job (8, 0, 4), trying to register it.
07:09:01 WORKER: registered result for job (8, 0, 4) with dispatcher
07:09:01 DISPATCHER: job (8, 0, 4) finished
07:09:01 DISPATCHER: register_result: lock acquired
07:09:01 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:09:01 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 370, 'last_n_outputs': 50, 'leak_rate': 0.8262722800548103, 'lr': 0.002741714578245071, 'optimizer': 'Adam', 'sparsity': 0.9342294763958203, 'steps_to_train': 65, 'weight_decay': 0.011581997804904856}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3179750282768824, 'info': {'music_genre': 0.3179750282768824, 'config': "{'batch_size': 128, 'hidden_dim': 370, 'last_n_outputs': 50, 'leak_rate': 0.8262722800548103, 'lr': 0.002741714578245071, 'optimizer': 'Adam', 'sparsity': 0.9342294763958203, 'steps_to_train': 65, 'weight_decay': 0.011581997804904856}"}}
exception: None

07:09:01 job_callback for (8, 0, 4) started
07:09:01 DISPATCHER: Trying to submit another job.
07:09:01 job_callback for (8, 0, 4) got condition
07:09:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:09:01 HBMASTER: Trying to run another job!
07:09:01 job_callback for (8, 0, 4) finished
07:09:01 start sampling a new configuration.
07:09:01 best_vector: [3, 0.06979069414333361, 0.8408447732291867, 0.8556832953155042, 0.3212487765080446, 1, 0.6495058107573689, 0.8104920508039223, 0.013698177129886732], 9.715402357522646e-32, 0.10292934488973574, -0.008765446658001243
07:09:01 done sampling a new configuration.
07:09:01 HBMASTER: schedule new run for iteration 8
07:09:01 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
07:09:01 HBMASTER: submitting job (8, 0, 5) to dispatcher
07:09:01 DISPATCHER: trying to submit job (8, 0, 5)
07:09:01 DISPATCHER: trying to notify the job_runner thread.
07:09:01 HBMASTER: job (8, 0, 5) submitted to dispatcher
07:09:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:09:01 DISPATCHER: Trying to submit another job.
07:09:01 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:09:01 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:09:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:09:01 WORKER: start processing job (8, 0, 5)
07:09:01 WORKER: args: ()
07:09:01 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 255, 'last_n_outputs': 44, 'leak_rate': 0.9639208238288761, 'lr': 0.004390333919492041, 'optimizer': 'SGD', 'sparsity': 0.9058813945817685, 'steps_to_train': 83, 'weight_decay': 0.010418896872007073}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:09:40 DISPATCHER: Starting worker discovery
07:09:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:09:40 DISPATCHER: Finished worker discovery
07:10:40 DISPATCHER: Starting worker discovery
07:10:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:10:40 DISPATCHER: Finished worker discovery
07:10:55 WORKER: done with job (8, 0, 5), trying to register it.
07:10:55 WORKER: registered result for job (8, 0, 5) with dispatcher
07:10:55 DISPATCHER: job (8, 0, 5) finished
07:10:55 DISPATCHER: register_result: lock acquired
07:10:55 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:10:55 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 255, 'last_n_outputs': 44, 'leak_rate': 0.9639208238288761, 'lr': 0.004390333919492041, 'optimizer': 'SGD', 'sparsity': 0.9058813945817685, 'steps_to_train': 83, 'weight_decay': 0.010418896872007073}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.28306663701649853, 'info': {'music_genre': 0.28306663701649853, 'config': "{'batch_size': 128, 'hidden_dim': 255, 'last_n_outputs': 44, 'leak_rate': 0.9639208238288761, 'lr': 0.004390333919492041, 'optimizer': 'SGD', 'sparsity': 0.9058813945817685, 'steps_to_train': 83, 'weight_decay': 0.010418896872007073}"}}
exception: None

07:10:55 job_callback for (8, 0, 5) started
07:10:55 DISPATCHER: Trying to submit another job.
07:10:55 job_callback for (8, 0, 5) got condition
07:10:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:10:55 HBMASTER: Trying to run another job!
07:10:55 job_callback for (8, 0, 5) finished
07:10:55 start sampling a new configuration.
07:10:55 best_vector: [3, 0.19960731784568803, 0.7088755736928309, 0.08503878442525645, 0.08906707728657537, 0, 0.8656513132569539, 0.6790789413048199, 0.09160528552156738], 1.1399281950252346e-32, 0.8772482375329466, -0.08676370933282883
07:10:55 done sampling a new configuration.
07:10:55 HBMASTER: schedule new run for iteration 8
07:10:55 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
07:10:55 HBMASTER: submitting job (8, 0, 6) to dispatcher
07:10:55 DISPATCHER: trying to submit job (8, 0, 6)
07:10:55 DISPATCHER: trying to notify the job_runner thread.
07:10:55 HBMASTER: job (8, 0, 6) submitted to dispatcher
07:10:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:10:55 DISPATCHER: Trying to submit another job.
07:10:55 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:10:55 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:10:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:10:55 WORKER: start processing job (8, 0, 6)
07:10:55 WORKER: args: ()
07:10:55 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 359, 'last_n_outputs': 39, 'leak_rate': 0.7712596961063141, 'lr': 0.0015070725324933686, 'optimizer': 'Adam', 'sparsity': 0.9577563151816689, 'steps_to_train': 71, 'weight_decay': 0.013157737692559925}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:11:40 DISPATCHER: Starting worker discovery
07:11:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:11:40 DISPATCHER: Finished worker discovery
07:12:40 DISPATCHER: Starting worker discovery
07:12:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:12:40 DISPATCHER: Finished worker discovery
07:12:43 WORKER: done with job (8, 0, 6), trying to register it.
07:12:43 WORKER: registered result for job (8, 0, 6) with dispatcher
07:12:43 DISPATCHER: job (8, 0, 6) finished
07:12:43 DISPATCHER: register_result: lock acquired
07:12:43 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:12:43 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 359, 'last_n_outputs': 39, 'leak_rate': 0.7712596961063141, 'lr': 0.0015070725324933686, 'optimizer': 'Adam', 'sparsity': 0.9577563151816689, 'steps_to_train': 71, 'weight_decay': 0.013157737692559925}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3532642644544899, 'info': {'music_genre': 0.3532642644544899, 'config': "{'batch_size': 128, 'hidden_dim': 359, 'last_n_outputs': 39, 'leak_rate': 0.7712596961063141, 'lr': 0.0015070725324933686, 'optimizer': 'Adam', 'sparsity': 0.9577563151816689, 'steps_to_train': 71, 'weight_decay': 0.013157737692559925}"}}
exception: None

07:12:43 job_callback for (8, 0, 6) started
07:12:43 DISPATCHER: Trying to submit another job.
07:12:43 job_callback for (8, 0, 6) got condition
07:12:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:12:43 HBMASTER: Trying to run another job!
07:12:43 job_callback for (8, 0, 6) finished
07:12:43 start sampling a new configuration.
07:12:43 best_vector: [3, 0.25969954907395587, 0.7537675225659645, 0.6623883989354412, 0.39833339426875797, 1, 0.6379382414072492, 0.8940771550121892, 0.07510885130013485], 1.008741105957659e-31, 0.09913346388820347, -0.02571549247472116
07:12:43 done sampling a new configuration.
07:12:43 HBMASTER: schedule new run for iteration 8
07:12:43 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
07:12:43 HBMASTER: submitting job (8, 0, 7) to dispatcher
07:12:43 DISPATCHER: trying to submit job (8, 0, 7)
07:12:43 DISPATCHER: trying to notify the job_runner thread.
07:12:43 HBMASTER: job (8, 0, 7) submitted to dispatcher
07:12:43 DISPATCHER: Trying to submit another job.
07:12:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:12:43 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:12:43 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:12:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:12:43 WORKER: start processing job (8, 0, 7)
07:12:43 WORKER: args: ()
07:12:43 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 408, 'last_n_outputs': 40, 'leak_rate': 0.9155970997338603, 'lr': 0.006261332809837975, 'optimizer': 'SGD', 'sparsity': 0.9031051779377398, 'steps_to_train': 91, 'weight_decay': 0.012523302425104285}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:13:40 DISPATCHER: Starting worker discovery
07:13:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:13:40 DISPATCHER: Finished worker discovery
07:14:40 DISPATCHER: Starting worker discovery
07:14:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:14:40 DISPATCHER: Finished worker discovery
07:14:45 WORKER: done with job (8, 0, 7), trying to register it.
07:14:45 WORKER: registered result for job (8, 0, 7) with dispatcher
07:14:45 DISPATCHER: job (8, 0, 7) finished
07:14:45 DISPATCHER: register_result: lock acquired
07:14:45 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:14:45 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 408, 'last_n_outputs': 40, 'leak_rate': 0.9155970997338603, 'lr': 0.006261332809837975, 'optimizer': 'SGD', 'sparsity': 0.9031051779377398, 'steps_to_train': 91, 'weight_decay': 0.012523302425104285}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3176166596640241, 'info': {'music_genre': 0.3176166596640241, 'config': "{'batch_size': 128, 'hidden_dim': 408, 'last_n_outputs': 40, 'leak_rate': 0.9155970997338603, 'lr': 0.006261332809837975, 'optimizer': 'SGD', 'sparsity': 0.9031051779377398, 'steps_to_train': 91, 'weight_decay': 0.012523302425104285}"}}
exception: None

07:14:45 job_callback for (8, 0, 7) started
07:14:45 job_callback for (8, 0, 7) got condition
07:14:45 DISPATCHER: Trying to submit another job.
07:14:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:14:45 HBMASTER: Trying to run another job!
07:14:45 job_callback for (8, 0, 7) finished
07:14:45 start sampling a new configuration.
07:14:45 best_vector: [3, 0.2950282266408415, 0.8614825603243645, 0.2895262206056511, 0.5421166357192613, 1, 0.7103539015729086, 0.8764623710958204, 0.010311254002556638], 2.1798424162518853e-32, 0.45874875749938065, -0.047142185906508934
07:14:45 done sampling a new configuration.
07:14:45 HBMASTER: schedule new run for iteration 8
07:14:45 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
07:14:45 HBMASTER: submitting job (8, 0, 8) to dispatcher
07:14:45 DISPATCHER: trying to submit job (8, 0, 8)
07:14:45 DISPATCHER: trying to notify the job_runner thread.
07:14:45 HBMASTER: job (8, 0, 8) submitted to dispatcher
07:14:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:14:45 DISPATCHER: Trying to submit another job.
07:14:45 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:14:45 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:14:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:14:45 WORKER: start processing job (8, 0, 8)
07:14:45 WORKER: args: ()
07:14:45 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 436, 'last_n_outputs': 45, 'leak_rate': 0.8223815551514128, 'lr': 0.012140407698531176, 'optimizer': 'SGD', 'sparsity': 0.9204849363774981, 'steps_to_train': 89, 'weight_decay': 0.010313717954753093}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:15:40 DISPATCHER: Starting worker discovery
07:15:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:15:40 DISPATCHER: Finished worker discovery
07:16:40 DISPATCHER: Starting worker discovery
07:16:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:16:40 DISPATCHER: Finished worker discovery
07:16:46 WORKER: done with job (8, 0, 8), trying to register it.
07:16:46 WORKER: registered result for job (8, 0, 8) with dispatcher
07:16:46 DISPATCHER: job (8, 0, 8) finished
07:16:46 DISPATCHER: register_result: lock acquired
07:16:46 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:16:46 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 436, 'last_n_outputs': 45, 'leak_rate': 0.8223815551514128, 'lr': 0.012140407698531176, 'optimizer': 'SGD', 'sparsity': 0.9204849363774981, 'steps_to_train': 89, 'weight_decay': 0.010313717954753093}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.36926543114517696, 'info': {'music_genre': 0.36926543114517696, 'config': "{'batch_size': 128, 'hidden_dim': 436, 'last_n_outputs': 45, 'leak_rate': 0.8223815551514128, 'lr': 0.012140407698531176, 'optimizer': 'SGD', 'sparsity': 0.9204849363774981, 'steps_to_train': 89, 'weight_decay': 0.010313717954753093}"}}
exception: None

07:16:46 job_callback for (8, 0, 8) started
07:16:46 DISPATCHER: Trying to submit another job.
07:16:46 job_callback for (8, 0, 8) got condition
07:16:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:16:46 HBMASTER: Trying to run another job!
07:16:46 job_callback for (8, 0, 8) finished
07:16:46 start sampling a new configuration.
07:16:46 done sampling a new configuration.
07:16:46 HBMASTER: schedule new run for iteration 8
07:16:46 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
07:16:46 HBMASTER: submitting job (8, 0, 9) to dispatcher
07:16:46 DISPATCHER: trying to submit job (8, 0, 9)
07:16:46 DISPATCHER: trying to notify the job_runner thread.
07:16:46 HBMASTER: job (8, 0, 9) submitted to dispatcher
07:16:46 DISPATCHER: Trying to submit another job.
07:16:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:16:46 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:16:47 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:16:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:16:47 WORKER: start processing job (8, 0, 9)
07:16:47 WORKER: args: ()
07:16:47 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 274, 'last_n_outputs': 41, 'leak_rate': 0.873810806419927, 'lr': 0.04450048936902609, 'optimizer': 'SGD', 'sparsity': 0.956701074330136, 'steps_to_train': 69, 'weight_decay': 0.015081103778993056}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:17:40 DISPATCHER: Starting worker discovery
07:17:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:17:40 DISPATCHER: Finished worker discovery
07:18:32 WORKER: done with job (8, 0, 9), trying to register it.
07:18:32 WORKER: registered result for job (8, 0, 9) with dispatcher
07:18:32 DISPATCHER: job (8, 0, 9) finished
07:18:32 DISPATCHER: register_result: lock acquired
07:18:32 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:18:32 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 274, 'last_n_outputs': 41, 'leak_rate': 0.873810806419927, 'lr': 0.04450048936902609, 'optimizer': 'SGD', 'sparsity': 0.956701074330136, 'steps_to_train': 69, 'weight_decay': 0.015081103778993056}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.25687580267202564, 'info': {'music_genre': 0.25687580267202564, 'config': "{'batch_size': 16, 'hidden_dim': 274, 'last_n_outputs': 41, 'leak_rate': 0.873810806419927, 'lr': 0.04450048936902609, 'optimizer': 'SGD', 'sparsity': 0.956701074330136, 'steps_to_train': 69, 'weight_decay': 0.015081103778993056}"}}
exception: None

07:18:32 job_callback for (8, 0, 9) started
07:18:32 DISPATCHER: Trying to submit another job.
07:18:32 job_callback for (8, 0, 9) got condition
07:18:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:18:32 HBMASTER: Trying to run another job!
07:18:32 job_callback for (8, 0, 9) finished
07:18:32 start sampling a new configuration.
07:18:32 best_vector: [3, 0.02864629263465268, 0.9758045808129604, 0.17999130533057944, 0.3834940912147466, 1, 0.7427712525748895, 0.466425989777155, 0.18692114269234728], 5.518964798929176e-32, 0.18119340065260542, -0.0029089238903114434
07:18:32 done sampling a new configuration.
07:18:32 HBMASTER: schedule new run for iteration 8
07:18:32 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
07:18:32 HBMASTER: submitting job (8, 0, 10) to dispatcher
07:18:32 DISPATCHER: trying to submit job (8, 0, 10)
07:18:32 DISPATCHER: trying to notify the job_runner thread.
07:18:32 HBMASTER: job (8, 0, 10) submitted to dispatcher
07:18:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:18:32 DISPATCHER: Trying to submit another job.
07:18:32 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:18:32 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:18:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:18:32 WORKER: start processing job (8, 0, 10)
07:18:32 WORKER: args: ()
07:18:32 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 222, 'last_n_outputs': 50, 'leak_rate': 0.7949978263326448, 'lr': 0.005847741716604057, 'optimizer': 'SGD', 'sparsity': 0.9282651006179735, 'steps_to_train': 52, 'weight_decay': 0.017506124528618626}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:18:40 DISPATCHER: Starting worker discovery
07:18:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:18:40 DISPATCHER: Finished worker discovery
07:19:40 DISPATCHER: Starting worker discovery
07:19:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:19:40 DISPATCHER: Finished worker discovery
07:20:17 WORKER: done with job (8, 0, 10), trying to register it.
07:20:17 WORKER: registered result for job (8, 0, 10) with dispatcher
07:20:17 DISPATCHER: job (8, 0, 10) finished
07:20:17 DISPATCHER: register_result: lock acquired
07:20:17 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:20:17 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 222, 'last_n_outputs': 50, 'leak_rate': 0.7949978263326448, 'lr': 0.005847741716604057, 'optimizer': 'SGD', 'sparsity': 0.9282651006179735, 'steps_to_train': 52, 'weight_decay': 0.017506124528618626}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3245752520657629, 'info': {'music_genre': 0.3245752520657629, 'config': "{'batch_size': 128, 'hidden_dim': 222, 'last_n_outputs': 50, 'leak_rate': 0.7949978263326448, 'lr': 0.005847741716604057, 'optimizer': 'SGD', 'sparsity': 0.9282651006179735, 'steps_to_train': 52, 'weight_decay': 0.017506124528618626}"}}
exception: None

07:20:17 job_callback for (8, 0, 10) started
07:20:17 DISPATCHER: Trying to submit another job.
07:20:17 job_callback for (8, 0, 10) got condition
07:20:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:20:17 HBMASTER: Trying to run another job!
07:20:17 job_callback for (8, 0, 10) finished
07:20:17 start sampling a new configuration.
07:20:17 done sampling a new configuration.
07:20:17 HBMASTER: schedule new run for iteration 8
07:20:17 HBMASTER: trying submitting job (8, 0, 11) to dispatcher
07:20:17 HBMASTER: submitting job (8, 0, 11) to dispatcher
07:20:17 DISPATCHER: trying to submit job (8, 0, 11)
07:20:17 DISPATCHER: trying to notify the job_runner thread.
07:20:17 HBMASTER: job (8, 0, 11) submitted to dispatcher
07:20:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:20:17 DISPATCHER: Trying to submit another job.
07:20:17 DISPATCHER: starting job (8, 0, 11) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:20:17 DISPATCHER: job (8, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:20:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:20:17 WORKER: start processing job (8, 0, 11)
07:20:17 WORKER: args: ()
07:20:17 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 702, 'last_n_outputs': 43, 'leak_rate': 0.7876793411857601, 'lr': 0.002189376235020317, 'optimizer': 'SGD', 'sparsity': 0.8904865301935538, 'steps_to_train': 19, 'weight_decay': 0.02033245976207648}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:20:40 DISPATCHER: Starting worker discovery
07:20:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:20:40 DISPATCHER: Finished worker discovery
07:21:40 DISPATCHER: Starting worker discovery
07:21:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:21:40 DISPATCHER: Finished worker discovery
07:22:00 WORKER: done with job (8, 0, 11), trying to register it.
07:22:00 WORKER: registered result for job (8, 0, 11) with dispatcher
07:22:00 DISPATCHER: job (8, 0, 11) finished
07:22:00 DISPATCHER: register_result: lock acquired
07:22:00 DISPATCHER: job (8, 0, 11) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:22:00 job_id: (8, 0, 11)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 702, 'last_n_outputs': 43, 'leak_rate': 0.7876793411857601, 'lr': 0.002189376235020317, 'optimizer': 'SGD', 'sparsity': 0.8904865301935538, 'steps_to_train': 19, 'weight_decay': 0.02033245976207648}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.31609421471378185, 'info': {'music_genre': 0.31609421471378185, 'config': "{'batch_size': 16, 'hidden_dim': 702, 'last_n_outputs': 43, 'leak_rate': 0.7876793411857601, 'lr': 0.002189376235020317, 'optimizer': 'SGD', 'sparsity': 0.8904865301935538, 'steps_to_train': 19, 'weight_decay': 0.02033245976207648}"}}
exception: None

07:22:00 job_callback for (8, 0, 11) started
07:22:00 job_callback for (8, 0, 11) got condition
07:22:00 DISPATCHER: Trying to submit another job.
07:22:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:22:00 HBMASTER: Trying to run another job!
07:22:00 job_callback for (8, 0, 11) finished
07:22:00 start sampling a new configuration.
07:22:00 best_vector: [3, 0.08360090524765307, 0.8546202318161223, 0.009639266832256271, 0.8028948390673702, 1, 0.7699751635163199, 0.6404479685143967, 0.1119898778966244], 5.706739001689525e-31, 0.017523142370869636, -0.0019016436325728172
07:22:00 done sampling a new configuration.
07:22:00 HBMASTER: schedule new run for iteration 8
07:22:00 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
07:22:00 HBMASTER: submitting job (8, 0, 12) to dispatcher
07:22:00 DISPATCHER: trying to submit job (8, 0, 12)
07:22:00 DISPATCHER: trying to notify the job_runner thread.
07:22:00 HBMASTER: job (8, 0, 12) submitted to dispatcher
07:22:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:22:00 DISPATCHER: Trying to submit another job.
07:22:00 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:22:00 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:22:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:22:00 WORKER: start processing job (8, 0, 12)
07:22:00 WORKER: args: ()
07:22:00 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 266, 'last_n_outputs': 45, 'leak_rate': 0.7524098167080641, 'lr': 0.04034499612915124, 'optimizer': 'SGD', 'sparsity': 0.9347940392439168, 'steps_to_train': 68, 'weight_decay': 0.013986279096752598}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:22:40 DISPATCHER: Starting worker discovery
07:22:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:22:40 DISPATCHER: Finished worker discovery
07:23:40 DISPATCHER: Starting worker discovery
07:23:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:23:40 DISPATCHER: Finished worker discovery
07:23:45 WORKER: done with job (8, 0, 12), trying to register it.
07:23:45 WORKER: registered result for job (8, 0, 12) with dispatcher
07:23:45 DISPATCHER: job (8, 0, 12) finished
07:23:45 DISPATCHER: register_result: lock acquired
07:23:45 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:23:45 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 266, 'last_n_outputs': 45, 'leak_rate': 0.7524098167080641, 'lr': 0.04034499612915124, 'optimizer': 'SGD', 'sparsity': 0.9347940392439168, 'steps_to_train': 68, 'weight_decay': 0.013986279096752598}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.32247718646270657, 'info': {'music_genre': 0.32247718646270657, 'config': "{'batch_size': 128, 'hidden_dim': 266, 'last_n_outputs': 45, 'leak_rate': 0.7524098167080641, 'lr': 0.04034499612915124, 'optimizer': 'SGD', 'sparsity': 0.9347940392439168, 'steps_to_train': 68, 'weight_decay': 0.013986279096752598}"}}
exception: None

07:23:45 job_callback for (8, 0, 12) started
07:23:45 job_callback for (8, 0, 12) got condition
07:23:45 DISPATCHER: Trying to submit another job.
07:23:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:23:45 HBMASTER: Trying to run another job!
07:23:45 job_callback for (8, 0, 12) finished
07:23:45 start sampling a new configuration.
07:23:45 done sampling a new configuration.
07:23:45 HBMASTER: schedule new run for iteration 8
07:23:45 HBMASTER: trying submitting job (8, 0, 13) to dispatcher
07:23:45 HBMASTER: submitting job (8, 0, 13) to dispatcher
07:23:45 DISPATCHER: trying to submit job (8, 0, 13)
07:23:45 DISPATCHER: trying to notify the job_runner thread.
07:23:45 HBMASTER: job (8, 0, 13) submitted to dispatcher
07:23:45 DISPATCHER: Trying to submit another job.
07:23:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:23:45 DISPATCHER: starting job (8, 0, 13) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:23:45 DISPATCHER: job (8, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:23:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:23:45 WORKER: start processing job (8, 0, 13)
07:23:45 WORKER: args: ()
07:23:45 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 504, 'last_n_outputs': 26, 'leak_rate': 0.8783236594823383, 'lr': 0.0038195105270394723, 'optimizer': 'SGD', 'sparsity': 0.9876552283248115, 'steps_to_train': 58, 'weight_decay': 0.13860593702611318}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:24:40 DISPATCHER: Starting worker discovery
07:24:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:24:40 DISPATCHER: Finished worker discovery
07:25:35 WORKER: done with job (8, 0, 13), trying to register it.
07:25:35 WORKER: registered result for job (8, 0, 13) with dispatcher
07:25:35 DISPATCHER: job (8, 0, 13) finished
07:25:35 DISPATCHER: register_result: lock acquired
07:25:35 DISPATCHER: job (8, 0, 13) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:25:35 job_id: (8, 0, 13)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 504, 'last_n_outputs': 26, 'leak_rate': 0.8783236594823383, 'lr': 0.0038195105270394723, 'optimizer': 'SGD', 'sparsity': 0.9876552283248115, 'steps_to_train': 58, 'weight_decay': 0.13860593702611318}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3049031941062895, 'info': {'music_genre': 0.3049031941062895, 'config': "{'batch_size': 16, 'hidden_dim': 504, 'last_n_outputs': 26, 'leak_rate': 0.8783236594823383, 'lr': 0.0038195105270394723, 'optimizer': 'SGD', 'sparsity': 0.9876552283248115, 'steps_to_train': 58, 'weight_decay': 0.13860593702611318}"}}
exception: None

07:25:35 job_callback for (8, 0, 13) started
07:25:35 job_callback for (8, 0, 13) got condition
07:25:35 DISPATCHER: Trying to submit another job.
07:25:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:25:35 HBMASTER: Trying to run another job!
07:25:35 job_callback for (8, 0, 13) finished
07:25:35 start sampling a new configuration.
07:25:35 best_vector: [3, 0.304087647105095, 0.7040147887356869, 0.24301844272433737, 0.4257390065973695, 1, 0.7561549532714908, 0.9729924249417329, 0.08619498725341841], 3.5354572173759374e-32, 0.28284884769224083, -0.06908337871807144
07:25:35 done sampling a new configuration.
07:25:35 HBMASTER: schedule new run for iteration 8
07:25:35 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
07:25:35 HBMASTER: submitting job (8, 0, 14) to dispatcher
07:25:35 DISPATCHER: trying to submit job (8, 0, 14)
07:25:35 DISPATCHER: trying to notify the job_runner thread.
07:25:35 HBMASTER: job (8, 0, 14) submitted to dispatcher
07:25:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:25:35 DISPATCHER: Trying to submit another job.
07:25:35 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:25:35 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:25:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:25:35 WORKER: start processing job (8, 0, 14)
07:25:35 WORKER: args: ()
07:25:35 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 443, 'last_n_outputs': 38, 'leak_rate': 0.8107546106810843, 'lr': 0.007103592060993305, 'optimizer': 'SGD', 'sparsity': 0.9314771887851578, 'steps_to_train': 98, 'weight_decay': 0.012946198567327361}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:25:40 DISPATCHER: Starting worker discovery
07:25:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:25:40 DISPATCHER: Finished worker discovery
07:26:40 DISPATCHER: Starting worker discovery
07:26:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:26:40 DISPATCHER: Finished worker discovery
07:27:18 WORKER: done with job (8, 0, 14), trying to register it.
07:27:18 WORKER: registered result for job (8, 0, 14) with dispatcher
07:27:18 DISPATCHER: job (8, 0, 14) finished
07:27:18 DISPATCHER: register_result: lock acquired
07:27:18 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:27:18 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 443, 'last_n_outputs': 38, 'leak_rate': 0.8107546106810843, 'lr': 0.007103592060993305, 'optimizer': 'SGD', 'sparsity': 0.9314771887851578, 'steps_to_train': 98, 'weight_decay': 0.012946198567327361}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3379767296747165, 'info': {'music_genre': 0.3379767296747165, 'config': "{'batch_size': 128, 'hidden_dim': 443, 'last_n_outputs': 38, 'leak_rate': 0.8107546106810843, 'lr': 0.007103592060993305, 'optimizer': 'SGD', 'sparsity': 0.9314771887851578, 'steps_to_train': 98, 'weight_decay': 0.012946198567327361}"}}
exception: None

07:27:18 job_callback for (8, 0, 14) started
07:27:18 job_callback for (8, 0, 14) got condition
07:27:18 DISPATCHER: Trying to submit another job.
07:27:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:27:18 HBMASTER: Trying to run another job!
07:27:18 job_callback for (8, 0, 14) finished
07:27:18 start sampling a new configuration.
07:27:18 best_vector: [3, 0.4386367947597555, 0.8303567174327422, 0.6668483311068816, 0.19854117308203895, 1, 0.6055532239010651, 0.4681893166747304, 0.15931879834409146], 5.50126567206287e-33, 1.817763510455984, -0.008406349478996414
07:27:18 done sampling a new configuration.
07:27:18 HBMASTER: schedule new run for iteration 8
07:27:18 HBMASTER: trying submitting job (8, 0, 15) to dispatcher
07:27:18 HBMASTER: submitting job (8, 0, 15) to dispatcher
07:27:18 DISPATCHER: trying to submit job (8, 0, 15)
07:27:18 DISPATCHER: trying to notify the job_runner thread.
07:27:18 HBMASTER: job (8, 0, 15) submitted to dispatcher
07:27:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:27:18 DISPATCHER: Trying to submit another job.
07:27:18 DISPATCHER: starting job (8, 0, 15) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:27:18 DISPATCHER: job (8, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:27:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:27:18 WORKER: start processing job (8, 0, 15)
07:27:18 WORKER: args: ()
07:27:18 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 551, 'last_n_outputs': 44, 'leak_rate': 0.9167120827767203, 'lr': 0.0024950677695241043, 'optimizer': 'SGD', 'sparsity': 0.8953327737362556, 'steps_to_train': 52, 'weight_decay': 0.016116789568743052}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:27:40 DISPATCHER: Starting worker discovery
07:27:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:27:40 DISPATCHER: Finished worker discovery
07:28:40 DISPATCHER: Starting worker discovery
07:28:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:28:40 DISPATCHER: Finished worker discovery
07:29:04 WORKER: done with job (8, 0, 15), trying to register it.
07:29:04 WORKER: registered result for job (8, 0, 15) with dispatcher
07:29:04 DISPATCHER: job (8, 0, 15) finished
07:29:04 DISPATCHER: register_result: lock acquired
07:29:04 DISPATCHER: job (8, 0, 15) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:29:04 job_id: (8, 0, 15)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 551, 'last_n_outputs': 44, 'leak_rate': 0.9167120827767203, 'lr': 0.0024950677695241043, 'optimizer': 'SGD', 'sparsity': 0.8953327737362556, 'steps_to_train': 52, 'weight_decay': 0.016116789568743052}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3411810787001514, 'info': {'music_genre': 0.3411810787001514, 'config': "{'batch_size': 128, 'hidden_dim': 551, 'last_n_outputs': 44, 'leak_rate': 0.9167120827767203, 'lr': 0.0024950677695241043, 'optimizer': 'SGD', 'sparsity': 0.8953327737362556, 'steps_to_train': 52, 'weight_decay': 0.016116789568743052}"}}
exception: None

07:29:04 job_callback for (8, 0, 15) started
07:29:04 DISPATCHER: Trying to submit another job.
07:29:04 job_callback for (8, 0, 15) got condition
07:29:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:29:04 HBMASTER: Trying to run another job!
07:29:04 job_callback for (8, 0, 15) finished
07:29:04 start sampling a new configuration.
07:29:04 done sampling a new configuration.
07:29:04 HBMASTER: schedule new run for iteration 8
07:29:04 HBMASTER: trying submitting job (8, 0, 16) to dispatcher
07:29:04 HBMASTER: submitting job (8, 0, 16) to dispatcher
07:29:04 DISPATCHER: trying to submit job (8, 0, 16)
07:29:04 DISPATCHER: trying to notify the job_runner thread.
07:29:04 HBMASTER: job (8, 0, 16) submitted to dispatcher
07:29:04 DISPATCHER: Trying to submit another job.
07:29:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:29:04 DISPATCHER: starting job (8, 0, 16) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:29:04 DISPATCHER: job (8, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:29:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:29:04 WORKER: start processing job (8, 0, 16)
07:29:04 WORKER: args: ()
07:29:04 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 248, 'last_n_outputs': 22, 'leak_rate': 0.8194662198003695, 'lr': 0.03915942006878909, 'optimizer': 'Adam', 'sparsity': 0.9596545889102865, 'steps_to_train': 29, 'weight_decay': 0.09534898055781622}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:29:40 DISPATCHER: Starting worker discovery
07:29:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:29:40 DISPATCHER: Finished worker discovery
07:30:40 DISPATCHER: Starting worker discovery
07:30:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:30:40 DISPATCHER: Finished worker discovery
07:30:48 WORKER: done with job (8, 0, 16), trying to register it.
07:30:48 WORKER: registered result for job (8, 0, 16) with dispatcher
07:30:48 DISPATCHER: job (8, 0, 16) finished
07:30:48 DISPATCHER: register_result: lock acquired
07:30:48 DISPATCHER: job (8, 0, 16) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:30:48 job_id: (8, 0, 16)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 248, 'last_n_outputs': 22, 'leak_rate': 0.8194662198003695, 'lr': 0.03915942006878909, 'optimizer': 'Adam', 'sparsity': 0.9596545889102865, 'steps_to_train': 29, 'weight_decay': 0.09534898055781622}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.09963872949956873, 'info': {'music_genre': 0.09963872949956873, 'config': "{'batch_size': 128, 'hidden_dim': 248, 'last_n_outputs': 22, 'leak_rate': 0.8194662198003695, 'lr': 0.03915942006878909, 'optimizer': 'Adam', 'sparsity': 0.9596545889102865, 'steps_to_train': 29, 'weight_decay': 0.09534898055781622}"}}
exception: None

07:30:48 job_callback for (8, 0, 16) started
07:30:48 job_callback for (8, 0, 16) got condition
07:30:48 DISPATCHER: Trying to submit another job.
07:30:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:30:48 HBMASTER: Trying to run another job!
07:30:48 job_callback for (8, 0, 16) finished
07:30:48 start sampling a new configuration.
07:30:48 done sampling a new configuration.
07:30:48 HBMASTER: schedule new run for iteration 8
07:30:48 HBMASTER: trying submitting job (8, 0, 17) to dispatcher
07:30:48 HBMASTER: submitting job (8, 0, 17) to dispatcher
07:30:48 DISPATCHER: trying to submit job (8, 0, 17)
07:30:48 DISPATCHER: trying to notify the job_runner thread.
07:30:48 HBMASTER: job (8, 0, 17) submitted to dispatcher
07:30:48 DISPATCHER: Trying to submit another job.
07:30:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:30:48 DISPATCHER: starting job (8, 0, 17) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:30:48 DISPATCHER: job (8, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:30:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:30:48 WORKER: start processing job (8, 0, 17)
07:30:48 WORKER: args: ()
07:30:48 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 363, 'last_n_outputs': 13, 'leak_rate': 0.8347655442709452, 'lr': 0.0021921666532164854, 'optimizer': 'SGD', 'sparsity': 0.7662798813217002, 'steps_to_train': 35, 'weight_decay': 0.015252301635998793}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:31:40 DISPATCHER: Starting worker discovery
07:31:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:31:40 DISPATCHER: Finished worker discovery
07:32:34 WORKER: done with job (8, 0, 17), trying to register it.
07:32:34 WORKER: registered result for job (8, 0, 17) with dispatcher
07:32:34 DISPATCHER: job (8, 0, 17) finished
07:32:34 DISPATCHER: register_result: lock acquired
07:32:34 DISPATCHER: job (8, 0, 17) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:32:34 job_id: (8, 0, 17)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 363, 'last_n_outputs': 13, 'leak_rate': 0.8347655442709452, 'lr': 0.0021921666532164854, 'optimizer': 'SGD', 'sparsity': 0.7662798813217002, 'steps_to_train': 35, 'weight_decay': 0.015252301635998793}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.23819494151344187, 'info': {'music_genre': 0.23819494151344187, 'config': "{'batch_size': 32, 'hidden_dim': 363, 'last_n_outputs': 13, 'leak_rate': 0.8347655442709452, 'lr': 0.0021921666532164854, 'optimizer': 'SGD', 'sparsity': 0.7662798813217002, 'steps_to_train': 35, 'weight_decay': 0.015252301635998793}"}}
exception: None

07:32:34 job_callback for (8, 0, 17) started
07:32:34 job_callback for (8, 0, 17) got condition
07:32:34 DISPATCHER: Trying to submit another job.
07:32:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:32:34 HBMASTER: Trying to run another job!
07:32:34 job_callback for (8, 0, 17) finished
07:32:34 start sampling a new configuration.
07:32:34 best_vector: [3, 0.18856280152068633, 0.8453118804294639, 0.5451187521391111, 0.09278466978258021, 0, 0.8081451387145678, 0.9050848147367945, 0.12963943234631448], 3.682977365621359e-33, 2.7151945307469707, -0.07533793832327047
07:32:34 done sampling a new configuration.
07:32:34 HBMASTER: schedule new run for iteration 8
07:32:34 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
07:32:34 HBMASTER: submitting job (8, 0, 18) to dispatcher
07:32:34 DISPATCHER: trying to submit job (8, 0, 18)
07:32:34 DISPATCHER: trying to notify the job_runner thread.
07:32:34 HBMASTER: job (8, 0, 18) submitted to dispatcher
07:32:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:32:34 DISPATCHER: Trying to submit another job.
07:32:34 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:32:34 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:32:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:32:34 WORKER: start processing job (8, 0, 18)
07:32:34 WORKER: args: ()
07:32:34 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 351, 'last_n_outputs': 44, 'leak_rate': 0.8862796880347777, 'lr': 0.0015330959613066644, 'optimizer': 'Adam', 'sparsity': 0.9439548332914962, 'steps_to_train': 92, 'weight_decay': 0.01474567949669078}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:32:40 DISPATCHER: Starting worker discovery
07:32:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:32:40 DISPATCHER: Finished worker discovery
07:33:40 DISPATCHER: Starting worker discovery
07:33:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:33:40 DISPATCHER: Finished worker discovery
07:34:34 WORKER: done with job (8, 0, 18), trying to register it.
07:34:34 WORKER: registered result for job (8, 0, 18) with dispatcher
07:34:34 DISPATCHER: job (8, 0, 18) finished
07:34:34 DISPATCHER: register_result: lock acquired
07:34:34 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:34:34 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 351, 'last_n_outputs': 44, 'leak_rate': 0.8862796880347777, 'lr': 0.0015330959613066644, 'optimizer': 'Adam', 'sparsity': 0.9439548332914962, 'steps_to_train': 92, 'weight_decay': 0.01474567949669078}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3155084784249979, 'info': {'music_genre': 0.3155084784249979, 'config': "{'batch_size': 128, 'hidden_dim': 351, 'last_n_outputs': 44, 'leak_rate': 0.8862796880347777, 'lr': 0.0015330959613066644, 'optimizer': 'Adam', 'sparsity': 0.9439548332914962, 'steps_to_train': 92, 'weight_decay': 0.01474567949669078}"}}
exception: None

07:34:34 job_callback for (8, 0, 18) started
07:34:34 job_callback for (8, 0, 18) got condition
07:34:34 DISPATCHER: Trying to submit another job.
07:34:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:34:34 HBMASTER: Trying to run another job!
07:34:34 job_callback for (8, 0, 18) finished
07:34:34 start sampling a new configuration.
07:34:34 best_vector: [3, 0.07976344440201996, 0.8990663689676288, 0.8600722712394322, 0.1305602251044741, 0, 0.6564521855014647, 0.7491454374556653, 0.12916695970600012], 1.1992194723922165e-32, 0.8338757191835693, -0.009063318618749918
07:34:34 done sampling a new configuration.
07:34:34 HBMASTER: schedule new run for iteration 8
07:34:34 HBMASTER: trying submitting job (8, 0, 19) to dispatcher
07:34:34 HBMASTER: submitting job (8, 0, 19) to dispatcher
07:34:34 DISPATCHER: trying to submit job (8, 0, 19)
07:34:34 DISPATCHER: trying to notify the job_runner thread.
07:34:34 HBMASTER: job (8, 0, 19) submitted to dispatcher
07:34:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:34:34 DISPATCHER: Trying to submit another job.
07:34:34 DISPATCHER: starting job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:34:34 DISPATCHER: job (8, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:34:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:34:34 WORKER: start processing job (8, 0, 19)
07:34:34 WORKER: args: ()
07:34:34 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 263, 'last_n_outputs': 46, 'leak_rate': 0.9650180678098581, 'lr': 0.0018244016242122485, 'optimizer': 'Adam', 'sparsity': 0.9075485245203515, 'steps_to_train': 78, 'weight_decay': 0.014724823202764763}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:34:40 DISPATCHER: Starting worker discovery
07:34:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:34:40 DISPATCHER: Finished worker discovery
07:35:40 DISPATCHER: Starting worker discovery
07:35:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:35:40 DISPATCHER: Finished worker discovery
07:36:25 WORKER: done with job (8, 0, 19), trying to register it.
07:36:25 WORKER: registered result for job (8, 0, 19) with dispatcher
07:36:25 DISPATCHER: job (8, 0, 19) finished
07:36:25 DISPATCHER: register_result: lock acquired
07:36:25 DISPATCHER: job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:36:25 job_id: (8, 0, 19)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 263, 'last_n_outputs': 46, 'leak_rate': 0.9650180678098581, 'lr': 0.0018244016242122485, 'optimizer': 'Adam', 'sparsity': 0.9075485245203515, 'steps_to_train': 78, 'weight_decay': 0.014724823202764763}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.34811996286897623, 'info': {'music_genre': 0.34811996286897623, 'config': "{'batch_size': 128, 'hidden_dim': 263, 'last_n_outputs': 46, 'leak_rate': 0.9650180678098581, 'lr': 0.0018244016242122485, 'optimizer': 'Adam', 'sparsity': 0.9075485245203515, 'steps_to_train': 78, 'weight_decay': 0.014724823202764763}"}}
exception: None

07:36:25 job_callback for (8, 0, 19) started
07:36:25 DISPATCHER: Trying to submit another job.
07:36:25 job_callback for (8, 0, 19) got condition
07:36:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:36:25 HBMASTER: Trying to run another job!
07:36:25 job_callback for (8, 0, 19) finished
07:36:25 start sampling a new configuration.
07:36:25 done sampling a new configuration.
07:36:25 HBMASTER: schedule new run for iteration 8
07:36:25 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
07:36:25 HBMASTER: submitting job (8, 0, 20) to dispatcher
07:36:25 DISPATCHER: trying to submit job (8, 0, 20)
07:36:25 DISPATCHER: trying to notify the job_runner thread.
07:36:25 HBMASTER: job (8, 0, 20) submitted to dispatcher
07:36:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:36:25 DISPATCHER: Trying to submit another job.
07:36:25 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:36:25 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:36:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:36:25 WORKER: start processing job (8, 0, 20)
07:36:25 WORKER: args: ()
07:36:25 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 316, 'last_n_outputs': 15, 'leak_rate': 0.8345729993106867, 'lr': 0.0019767583683552134, 'optimizer': 'SGD', 'sparsity': 0.8629454813913463, 'steps_to_train': 86, 'weight_decay': 0.012506735753803178}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:36:40 DISPATCHER: Starting worker discovery
07:36:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:36:40 DISPATCHER: Finished worker discovery
07:37:40 DISPATCHER: Starting worker discovery
07:37:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:37:40 DISPATCHER: Finished worker discovery
07:38:20 WORKER: done with job (8, 0, 20), trying to register it.
07:38:20 WORKER: registered result for job (8, 0, 20) with dispatcher
07:38:20 DISPATCHER: job (8, 0, 20) finished
07:38:20 DISPATCHER: register_result: lock acquired
07:38:20 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:38:20 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 316, 'last_n_outputs': 15, 'leak_rate': 0.8345729993106867, 'lr': 0.0019767583683552134, 'optimizer': 'SGD', 'sparsity': 0.8629454813913463, 'steps_to_train': 86, 'weight_decay': 0.012506735753803178}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.23025768514221406, 'info': {'music_genre': 0.23025768514221406, 'config': "{'batch_size': 128, 'hidden_dim': 316, 'last_n_outputs': 15, 'leak_rate': 0.8345729993106867, 'lr': 0.0019767583683552134, 'optimizer': 'SGD', 'sparsity': 0.8629454813913463, 'steps_to_train': 86, 'weight_decay': 0.012506735753803178}"}}
exception: None

07:38:20 job_callback for (8, 0, 20) started
07:38:20 DISPATCHER: Trying to submit another job.
07:38:20 job_callback for (8, 0, 20) got condition
07:38:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:38:20 HBMASTER: Trying to run another job!
07:38:20 job_callback for (8, 0, 20) finished
07:38:20 start sampling a new configuration.
07:38:20 best_vector: [3, 0.39533626625516755, 0.660898902249235, 0.5092626724792035, 0.34191711467448405, 1, 0.6742424315673616, 0.6207462236591511, 0.018180112453482916], 4.2633588949931833e-32, 0.23455684229971424, -0.01530804374508324
07:38:20 done sampling a new configuration.
07:38:20 HBMASTER: schedule new run for iteration 8
07:38:20 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
07:38:20 HBMASTER: submitting job (8, 0, 21) to dispatcher
07:38:20 DISPATCHER: trying to submit job (8, 0, 21)
07:38:20 DISPATCHER: trying to notify the job_runner thread.
07:38:20 HBMASTER: job (8, 0, 21) submitted to dispatcher
07:38:20 DISPATCHER: Trying to submit another job.
07:38:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:38:20 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:38:20 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:38:20 WORKER: start processing job (8, 0, 21)
07:38:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:38:20 WORKER: args: ()
07:38:20 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 516, 'last_n_outputs': 37, 'leak_rate': 0.8773156681198009, 'lr': 0.004828744531828341, 'optimizer': 'SGD', 'sparsity': 0.9118181835761667, 'steps_to_train': 66, 'weight_decay': 0.010559731402737313}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:38:40 DISPATCHER: Starting worker discovery
07:38:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:38:40 DISPATCHER: Finished worker discovery
07:39:40 DISPATCHER: Starting worker discovery
07:39:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:39:40 DISPATCHER: Finished worker discovery
07:40:03 WORKER: done with job (8, 0, 21), trying to register it.
07:40:03 WORKER: registered result for job (8, 0, 21) with dispatcher
07:40:03 DISPATCHER: job (8, 0, 21) finished
07:40:03 DISPATCHER: register_result: lock acquired
07:40:03 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:40:03 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 516, 'last_n_outputs': 37, 'leak_rate': 0.8773156681198009, 'lr': 0.004828744531828341, 'optimizer': 'SGD', 'sparsity': 0.9118181835761667, 'steps_to_train': 66, 'weight_decay': 0.010559731402737313}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.36427126778462615, 'info': {'music_genre': 0.36427126778462615, 'config': "{'batch_size': 128, 'hidden_dim': 516, 'last_n_outputs': 37, 'leak_rate': 0.8773156681198009, 'lr': 0.004828744531828341, 'optimizer': 'SGD', 'sparsity': 0.9118181835761667, 'steps_to_train': 66, 'weight_decay': 0.010559731402737313}"}}
exception: None

07:40:03 job_callback for (8, 0, 21) started
07:40:03 job_callback for (8, 0, 21) got condition
07:40:03 DISPATCHER: Trying to submit another job.
07:40:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:40:03 HBMASTER: Trying to run another job!
07:40:03 job_callback for (8, 0, 21) finished
07:40:03 start sampling a new configuration.
07:40:03 done sampling a new configuration.
07:40:03 HBMASTER: schedule new run for iteration 8
07:40:03 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
07:40:03 HBMASTER: submitting job (8, 0, 22) to dispatcher
07:40:03 DISPATCHER: trying to submit job (8, 0, 22)
07:40:03 DISPATCHER: trying to notify the job_runner thread.
07:40:03 HBMASTER: job (8, 0, 22) submitted to dispatcher
07:40:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:40:03 DISPATCHER: Trying to submit another job.
07:40:03 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:40:03 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:40:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:40:03 WORKER: start processing job (8, 0, 22)
07:40:03 WORKER: args: ()
07:40:03 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 719, 'last_n_outputs': 15, 'leak_rate': 0.9542533417512717, 'lr': 0.04366669832546011, 'optimizer': 'SGD', 'sparsity': 0.8646287612143735, 'steps_to_train': 56, 'weight_decay': 0.06079746305440903}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:40:40 DISPATCHER: Starting worker discovery
07:40:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:40:40 DISPATCHER: Finished worker discovery
07:41:40 DISPATCHER: Starting worker discovery
07:41:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:41:40 DISPATCHER: Finished worker discovery
07:41:53 WORKER: done with job (8, 0, 22), trying to register it.
07:41:53 WORKER: registered result for job (8, 0, 22) with dispatcher
07:41:53 DISPATCHER: job (8, 0, 22) finished
07:41:53 DISPATCHER: register_result: lock acquired
07:41:53 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:41:53 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 719, 'last_n_outputs': 15, 'leak_rate': 0.9542533417512717, 'lr': 0.04366669832546011, 'optimizer': 'SGD', 'sparsity': 0.8646287612143735, 'steps_to_train': 56, 'weight_decay': 0.06079746305440903}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.22365502663177453, 'info': {'music_genre': 0.22365502663177453, 'config': "{'batch_size': 64, 'hidden_dim': 719, 'last_n_outputs': 15, 'leak_rate': 0.9542533417512717, 'lr': 0.04366669832546011, 'optimizer': 'SGD', 'sparsity': 0.8646287612143735, 'steps_to_train': 56, 'weight_decay': 0.06079746305440903}"}}
exception: None

07:41:53 job_callback for (8, 0, 22) started
07:41:53 DISPATCHER: Trying to submit another job.
07:41:53 job_callback for (8, 0, 22) got condition
07:41:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:41:53 HBMASTER: Trying to run another job!
07:41:53 job_callback for (8, 0, 22) finished
07:41:53 start sampling a new configuration.
07:41:53 best_vector: [3, 0.39017096600530143, 0.6984398655398842, 0.8954411660628457, 0.05562124152080433, 0, 0.6961399493184078, 0.3737031044502261, 0.16864383575576816], 2.701965170495442e-32, 0.3701009957195845, -0.00034196179114398285
07:41:53 done sampling a new configuration.
07:41:53 HBMASTER: schedule new run for iteration 8
07:41:53 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
07:41:53 HBMASTER: submitting job (8, 0, 23) to dispatcher
07:41:53 DISPATCHER: trying to submit job (8, 0, 23)
07:41:53 DISPATCHER: trying to notify the job_runner thread.
07:41:53 HBMASTER: job (8, 0, 23) submitted to dispatcher
07:41:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:41:53 DISPATCHER: Trying to submit another job.
07:41:53 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:41:53 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:41:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:41:53 WORKER: start processing job (8, 0, 23)
07:41:53 WORKER: args: ()
07:41:53 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 512, 'last_n_outputs': 38, 'leak_rate': 0.9738602915157114, 'lr': 0.0012919404114902896, 'optimizer': 'Adam', 'sparsity': 0.9170735878364179, 'steps_to_train': 44, 'weight_decay': 0.016573364765172724}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:42:40 DISPATCHER: Starting worker discovery
07:42:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:42:40 DISPATCHER: Finished worker discovery
07:43:38 WORKER: done with job (8, 0, 23), trying to register it.
07:43:38 WORKER: registered result for job (8, 0, 23) with dispatcher
07:43:38 DISPATCHER: job (8, 0, 23) finished
07:43:38 DISPATCHER: register_result: lock acquired
07:43:38 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:43:38 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 512, 'last_n_outputs': 38, 'leak_rate': 0.9738602915157114, 'lr': 0.0012919404114902896, 'optimizer': 'Adam', 'sparsity': 0.9170735878364179, 'steps_to_train': 44, 'weight_decay': 0.016573364765172724}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.35054604390010535, 'info': {'music_genre': 0.35054604390010535, 'config': "{'batch_size': 128, 'hidden_dim': 512, 'last_n_outputs': 38, 'leak_rate': 0.9738602915157114, 'lr': 0.0012919404114902896, 'optimizer': 'Adam', 'sparsity': 0.9170735878364179, 'steps_to_train': 44, 'weight_decay': 0.016573364765172724}"}}
exception: None

07:43:38 job_callback for (8, 0, 23) started
07:43:38 job_callback for (8, 0, 23) got condition
07:43:38 DISPATCHER: Trying to submit another job.
07:43:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:43:38 HBMASTER: Trying to run another job!
07:43:38 job_callback for (8, 0, 23) finished
07:43:38 start sampling a new configuration.
07:43:38 best_vector: [1, 0.8574468387523105, 0.8977986183920683, 0.9729864933004101, 0.7598214474457843, 1, 0.9124856772013683, 0.5784156323250387, 0.11169032781037933], 2.7069672474002276e-31, 0.03694171035724206, -0.0131789394750412
07:43:38 done sampling a new configuration.
07:43:38 HBMASTER: schedule new run for iteration 8
07:43:38 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
07:43:38 HBMASTER: submitting job (8, 0, 24) to dispatcher
07:43:38 DISPATCHER: trying to submit job (8, 0, 24)
07:43:38 DISPATCHER: trying to notify the job_runner thread.
07:43:38 HBMASTER: job (8, 0, 24) submitted to dispatcher
07:43:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:43:38 DISPATCHER: Trying to submit another job.
07:43:38 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:43:38 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:43:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:43:38 WORKER: start processing job (8, 0, 24)
07:43:38 WORKER: args: ()
07:43:38 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 886, 'last_n_outputs': 46, 'leak_rate': 0.9932466233251025, 'lr': 0.03308589558957674, 'optimizer': 'SGD', 'sparsity': 0.9689965625283283, 'steps_to_train': 62, 'weight_decay': 0.013973733833177461}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:43:40 DISPATCHER: Starting worker discovery
07:43:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:43:40 DISPATCHER: Finished worker discovery
07:44:40 DISPATCHER: Starting worker discovery
07:44:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:44:40 DISPATCHER: Finished worker discovery
07:45:32 WORKER: done with job (8, 0, 24), trying to register it.
07:45:32 WORKER: registered result for job (8, 0, 24) with dispatcher
07:45:32 DISPATCHER: job (8, 0, 24) finished
07:45:32 DISPATCHER: register_result: lock acquired
07:45:32 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:45:32 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 886, 'last_n_outputs': 46, 'leak_rate': 0.9932466233251025, 'lr': 0.03308589558957674, 'optimizer': 'SGD', 'sparsity': 0.9689965625283283, 'steps_to_train': 62, 'weight_decay': 0.013973733833177461}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.22427402126115048, 'info': {'music_genre': 0.22427402126115048, 'config': "{'batch_size': 32, 'hidden_dim': 886, 'last_n_outputs': 46, 'leak_rate': 0.9932466233251025, 'lr': 0.03308589558957674, 'optimizer': 'SGD', 'sparsity': 0.9689965625283283, 'steps_to_train': 62, 'weight_decay': 0.013973733833177461}"}}
exception: None

07:45:32 job_callback for (8, 0, 24) started
07:45:32 DISPATCHER: Trying to submit another job.
07:45:32 job_callback for (8, 0, 24) got condition
07:45:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:45:32 HBMASTER: Trying to run another job!
07:45:32 job_callback for (8, 0, 24) finished
07:45:32 start sampling a new configuration.
07:45:32 best_vector: [3, 0.43492274336468373, 0.7926195287008948, 0.13746651899559764, 0.3247214420510818, 1, 0.8515421396445688, 0.6962558428895305, 0.30578646117180913], 3.623464408586761e-32, 0.2759789768129734, -0.08205062889273104
07:45:32 done sampling a new configuration.
07:45:32 HBMASTER: schedule new run for iteration 8
07:45:32 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
07:45:32 HBMASTER: submitting job (8, 0, 25) to dispatcher
07:45:32 DISPATCHER: trying to submit job (8, 0, 25)
07:45:32 DISPATCHER: trying to notify the job_runner thread.
07:45:32 HBMASTER: job (8, 0, 25) submitted to dispatcher
07:45:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:45:32 DISPATCHER: Trying to submit another job.
07:45:32 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:45:32 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:45:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:45:32 WORKER: start processing job (8, 0, 25)
07:45:32 WORKER: args: ()
07:45:32 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 548, 'last_n_outputs': 42, 'leak_rate': 0.7843666297488994, 'lr': 0.004461109507913648, 'optimizer': 'SGD', 'sparsity': 0.9543701135146965, 'steps_to_train': 73, 'weight_decay': 0.024994091665130894}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:45:40 DISPATCHER: Starting worker discovery
07:45:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:45:40 DISPATCHER: Finished worker discovery
07:46:40 DISPATCHER: Starting worker discovery
07:46:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:46:40 DISPATCHER: Finished worker discovery
07:47:22 WORKER: done with job (8, 0, 25), trying to register it.
07:47:22 WORKER: registered result for job (8, 0, 25) with dispatcher
07:47:22 DISPATCHER: job (8, 0, 25) finished
07:47:22 DISPATCHER: register_result: lock acquired
07:47:22 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:47:22 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 548, 'last_n_outputs': 42, 'leak_rate': 0.7843666297488994, 'lr': 0.004461109507913648, 'optimizer': 'SGD', 'sparsity': 0.9543701135146965, 'steps_to_train': 73, 'weight_decay': 0.024994091665130894}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.32695656435410725, 'info': {'music_genre': 0.32695656435410725, 'config': "{'batch_size': 128, 'hidden_dim': 548, 'last_n_outputs': 42, 'leak_rate': 0.7843666297488994, 'lr': 0.004461109507913648, 'optimizer': 'SGD', 'sparsity': 0.9543701135146965, 'steps_to_train': 73, 'weight_decay': 0.024994091665130894}"}}
exception: None

07:47:22 job_callback for (8, 0, 25) started
07:47:22 job_callback for (8, 0, 25) got condition
07:47:22 DISPATCHER: Trying to submit another job.
07:47:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:47:22 HBMASTER: Trying to run another job!
07:47:22 job_callback for (8, 0, 25) finished
07:47:22 start sampling a new configuration.
07:47:22 done sampling a new configuration.
07:47:22 HBMASTER: schedule new run for iteration 8
07:47:22 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
07:47:22 HBMASTER: submitting job (8, 0, 26) to dispatcher
07:47:22 DISPATCHER: trying to submit job (8, 0, 26)
07:47:22 DISPATCHER: trying to notify the job_runner thread.
07:47:22 HBMASTER: job (8, 0, 26) submitted to dispatcher
07:47:22 DISPATCHER: Trying to submit another job.
07:47:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:47:22 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:47:22 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:47:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:47:22 WORKER: start processing job (8, 0, 26)
07:47:22 WORKER: args: ()
07:47:22 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 502, 'last_n_outputs': 32, 'leak_rate': 0.9370460819408959, 'lr': 0.060897987800007096, 'optimizer': 'Adam', 'sparsity': 0.9825820385275201, 'steps_to_train': 60, 'weight_decay': 0.02333870372854442}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:47:40 DISPATCHER: Starting worker discovery
07:47:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:47:40 DISPATCHER: Finished worker discovery
07:48:40 DISPATCHER: Starting worker discovery
07:48:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:48:40 DISPATCHER: Finished worker discovery
07:49:15 WORKER: done with job (8, 0, 26), trying to register it.
07:49:15 WORKER: registered result for job (8, 0, 26) with dispatcher
07:49:15 DISPATCHER: job (8, 0, 26) finished
07:49:15 DISPATCHER: register_result: lock acquired
07:49:15 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:49:15 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 502, 'last_n_outputs': 32, 'leak_rate': 0.9370460819408959, 'lr': 0.060897987800007096, 'optimizer': 'Adam', 'sparsity': 0.9825820385275201, 'steps_to_train': 60, 'weight_decay': 0.02333870372854442}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.11409922664535006, 'info': {'music_genre': 0.11409922664535006, 'config': "{'batch_size': 16, 'hidden_dim': 502, 'last_n_outputs': 32, 'leak_rate': 0.9370460819408959, 'lr': 0.060897987800007096, 'optimizer': 'Adam', 'sparsity': 0.9825820385275201, 'steps_to_train': 60, 'weight_decay': 0.02333870372854442}"}}
exception: None

07:49:15 job_callback for (8, 0, 26) started
07:49:15 job_callback for (8, 0, 26) got condition
07:49:15 DISPATCHER: Trying to submit another job.
07:49:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:49:15 HBMASTER: Trying to run another job!
07:49:15 job_callback for (8, 0, 26) finished
07:49:15 ITERATION: Advancing config (8, 0, 0) to next budget 133.333333
07:49:15 ITERATION: Advancing config (8, 0, 6) to next budget 133.333333
07:49:15 ITERATION: Advancing config (8, 0, 8) to next budget 133.333333
07:49:15 ITERATION: Advancing config (8, 0, 14) to next budget 133.333333
07:49:15 ITERATION: Advancing config (8, 0, 15) to next budget 133.333333
07:49:15 ITERATION: Advancing config (8, 0, 19) to next budget 133.333333
07:49:15 ITERATION: Advancing config (8, 0, 21) to next budget 133.333333
07:49:15 ITERATION: Advancing config (8, 0, 23) to next budget 133.333333
07:49:15 ITERATION: Advancing config (8, 0, 25) to next budget 133.333333
07:49:15 HBMASTER: schedule new run for iteration 8
07:49:15 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
07:49:15 HBMASTER: submitting job (8, 0, 0) to dispatcher
07:49:15 DISPATCHER: trying to submit job (8, 0, 0)
07:49:15 DISPATCHER: trying to notify the job_runner thread.
07:49:15 HBMASTER: job (8, 0, 0) submitted to dispatcher
07:49:15 DISPATCHER: Trying to submit another job.
07:49:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:49:15 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:49:15 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:49:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:49:15 WORKER: start processing job (8, 0, 0)
07:49:15 WORKER: args: ()
07:49:15 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 310, 'last_n_outputs': 40, 'leak_rate': 0.9106428091626764, 'lr': 0.002043517649097409, 'optimizer': 'Adam', 'sparsity': 0.942723908920547, 'steps_to_train': 89, 'weight_decay': 0.010813247235387496}, 'budget': 133.33333333333331, 'working_directory': '.'}
07:49:40 DISPATCHER: Starting worker discovery
07:49:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:49:40 DISPATCHER: Finished worker discovery
07:50:40 DISPATCHER: Starting worker discovery
07:50:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:50:40 DISPATCHER: Finished worker discovery
07:51:40 DISPATCHER: Starting worker discovery
07:51:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:51:40 DISPATCHER: Finished worker discovery
07:52:40 DISPATCHER: Starting worker discovery
07:52:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:52:40 DISPATCHER: Finished worker discovery
07:52:43 WORKER: done with job (8, 0, 0), trying to register it.
07:52:43 WORKER: registered result for job (8, 0, 0) with dispatcher
07:52:43 DISPATCHER: job (8, 0, 0) finished
07:52:43 DISPATCHER: register_result: lock acquired
07:52:43 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:52:43 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 310, 'last_n_outputs': 40, 'leak_rate': 0.9106428091626764, 'lr': 0.002043517649097409, 'optimizer': 'Adam', 'sparsity': 0.942723908920547, 'steps_to_train': 89, 'weight_decay': 0.010813247235387496}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.34964828013207394, 'info': {'music_genre': 0.34964828013207394, 'config': "{'batch_size': 128, 'hidden_dim': 310, 'last_n_outputs': 40, 'leak_rate': 0.9106428091626764, 'lr': 0.002043517649097409, 'optimizer': 'Adam', 'sparsity': 0.942723908920547, 'steps_to_train': 89, 'weight_decay': 0.010813247235387496}"}}
exception: None

07:52:43 job_callback for (8, 0, 0) started
07:52:43 DISPATCHER: Trying to submit another job.
07:52:43 job_callback for (8, 0, 0) got condition
07:52:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:52:43 HBMASTER: Trying to run another job!
07:52:43 job_callback for (8, 0, 0) finished
07:52:43 HBMASTER: schedule new run for iteration 8
07:52:43 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
07:52:43 HBMASTER: submitting job (8, 0, 6) to dispatcher
07:52:43 DISPATCHER: trying to submit job (8, 0, 6)
07:52:43 DISPATCHER: trying to notify the job_runner thread.
07:52:43 HBMASTER: job (8, 0, 6) submitted to dispatcher
07:52:43 DISPATCHER: Trying to submit another job.
07:52:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:52:43 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:52:43 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:52:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:52:43 WORKER: start processing job (8, 0, 6)
07:52:43 WORKER: args: ()
07:52:43 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 359, 'last_n_outputs': 39, 'leak_rate': 0.7712596961063141, 'lr': 0.0015070725324933686, 'optimizer': 'Adam', 'sparsity': 0.9577563151816689, 'steps_to_train': 71, 'weight_decay': 0.013157737692559925}, 'budget': 133.33333333333331, 'working_directory': '.'}
07:53:40 DISPATCHER: Starting worker discovery
07:53:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:53:40 DISPATCHER: Finished worker discovery
07:54:40 DISPATCHER: Starting worker discovery
07:54:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:54:40 DISPATCHER: Finished worker discovery
07:55:40 DISPATCHER: Starting worker discovery
07:55:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:55:40 DISPATCHER: Finished worker discovery
07:55:54 WORKER: done with job (8, 0, 6), trying to register it.
07:55:54 WORKER: registered result for job (8, 0, 6) with dispatcher
07:55:54 DISPATCHER: job (8, 0, 6) finished
07:55:54 DISPATCHER: register_result: lock acquired
07:55:54 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:55:54 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 359, 'last_n_outputs': 39, 'leak_rate': 0.7712596961063141, 'lr': 0.0015070725324933686, 'optimizer': 'Adam', 'sparsity': 0.9577563151816689, 'steps_to_train': 71, 'weight_decay': 0.013157737692559925}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3346781456865952, 'info': {'music_genre': 0.3346781456865952, 'config': "{'batch_size': 128, 'hidden_dim': 359, 'last_n_outputs': 39, 'leak_rate': 0.7712596961063141, 'lr': 0.0015070725324933686, 'optimizer': 'Adam', 'sparsity': 0.9577563151816689, 'steps_to_train': 71, 'weight_decay': 0.013157737692559925}"}}
exception: None

07:55:54 job_callback for (8, 0, 6) started
07:55:54 DISPATCHER: Trying to submit another job.
07:55:54 job_callback for (8, 0, 6) got condition
07:55:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:55:54 HBMASTER: Trying to run another job!
07:55:54 job_callback for (8, 0, 6) finished
07:55:54 HBMASTER: schedule new run for iteration 8
07:55:54 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
07:55:54 HBMASTER: submitting job (8, 0, 8) to dispatcher
07:55:54 DISPATCHER: trying to submit job (8, 0, 8)
07:55:54 DISPATCHER: trying to notify the job_runner thread.
07:55:54 HBMASTER: job (8, 0, 8) submitted to dispatcher
07:55:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:55:54 DISPATCHER: Trying to submit another job.
07:55:54 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:55:54 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:55:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:55:54 WORKER: start processing job (8, 0, 8)
07:55:54 WORKER: args: ()
07:55:54 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 436, 'last_n_outputs': 45, 'leak_rate': 0.8223815551514128, 'lr': 0.012140407698531176, 'optimizer': 'SGD', 'sparsity': 0.9204849363774981, 'steps_to_train': 89, 'weight_decay': 0.010313717954753093}, 'budget': 133.33333333333331, 'working_directory': '.'}
07:56:40 DISPATCHER: Starting worker discovery
07:56:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:56:40 DISPATCHER: Finished worker discovery
07:57:40 DISPATCHER: Starting worker discovery
07:57:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:57:40 DISPATCHER: Finished worker discovery
07:58:40 DISPATCHER: Starting worker discovery
07:58:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:58:40 DISPATCHER: Finished worker discovery
07:59:22 WORKER: done with job (8, 0, 8), trying to register it.
07:59:22 WORKER: registered result for job (8, 0, 8) with dispatcher
07:59:22 DISPATCHER: job (8, 0, 8) finished
07:59:22 DISPATCHER: register_result: lock acquired
07:59:22 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:59:22 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 436, 'last_n_outputs': 45, 'leak_rate': 0.8223815551514128, 'lr': 0.012140407698531176, 'optimizer': 'SGD', 'sparsity': 0.9204849363774981, 'steps_to_train': 89, 'weight_decay': 0.010313717954753093}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3962356355912718, 'info': {'music_genre': 0.3962356355912718, 'config': "{'batch_size': 128, 'hidden_dim': 436, 'last_n_outputs': 45, 'leak_rate': 0.8223815551514128, 'lr': 0.012140407698531176, 'optimizer': 'SGD', 'sparsity': 0.9204849363774981, 'steps_to_train': 89, 'weight_decay': 0.010313717954753093}"}}
exception: None

07:59:22 job_callback for (8, 0, 8) started
07:59:22 job_callback for (8, 0, 8) got condition
07:59:22 DISPATCHER: Trying to submit another job.
07:59:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:59:22 HBMASTER: Trying to run another job!
07:59:22 job_callback for (8, 0, 8) finished
07:59:22 HBMASTER: schedule new run for iteration 8
07:59:22 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
07:59:22 HBMASTER: submitting job (8, 0, 14) to dispatcher
07:59:22 DISPATCHER: trying to submit job (8, 0, 14)
07:59:22 DISPATCHER: trying to notify the job_runner thread.
07:59:22 HBMASTER: job (8, 0, 14) submitted to dispatcher
07:59:22 DISPATCHER: Trying to submit another job.
07:59:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:59:22 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:59:22 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:59:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:59:22 WORKER: start processing job (8, 0, 14)
07:59:22 WORKER: args: ()
07:59:22 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 443, 'last_n_outputs': 38, 'leak_rate': 0.8107546106810843, 'lr': 0.007103592060993305, 'optimizer': 'SGD', 'sparsity': 0.9314771887851578, 'steps_to_train': 98, 'weight_decay': 0.012946198567327361}, 'budget': 133.33333333333331, 'working_directory': '.'}
07:59:40 DISPATCHER: Starting worker discovery
07:59:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:59:40 DISPATCHER: Finished worker discovery
08:00:40 DISPATCHER: Starting worker discovery
08:00:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:00:40 DISPATCHER: Finished worker discovery
08:01:40 DISPATCHER: Starting worker discovery
08:01:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:01:40 DISPATCHER: Finished worker discovery
08:02:40 DISPATCHER: Starting worker discovery
08:02:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:02:40 DISPATCHER: Finished worker discovery
08:02:40 WORKER: done with job (8, 0, 14), trying to register it.
08:02:40 WORKER: registered result for job (8, 0, 14) with dispatcher
08:02:40 DISPATCHER: job (8, 0, 14) finished
08:02:40 DISPATCHER: register_result: lock acquired
08:02:40 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
08:02:40 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 443, 'last_n_outputs': 38, 'leak_rate': 0.8107546106810843, 'lr': 0.007103592060993305, 'optimizer': 'SGD', 'sparsity': 0.9314771887851578, 'steps_to_train': 98, 'weight_decay': 0.012946198567327361}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.32306224648109255, 'info': {'music_genre': 0.32306224648109255, 'config': "{'batch_size': 128, 'hidden_dim': 443, 'last_n_outputs': 38, 'leak_rate': 0.8107546106810843, 'lr': 0.007103592060993305, 'optimizer': 'SGD', 'sparsity': 0.9314771887851578, 'steps_to_train': 98, 'weight_decay': 0.012946198567327361}"}}
exception: None

08:02:40 job_callback for (8, 0, 14) started
08:02:40 DISPATCHER: Trying to submit another job.
08:02:40 job_callback for (8, 0, 14) got condition
08:02:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:02:40 HBMASTER: Trying to run another job!
08:02:40 job_callback for (8, 0, 14) finished
08:02:40 HBMASTER: schedule new run for iteration 8
08:02:40 HBMASTER: trying submitting job (8, 0, 15) to dispatcher
08:02:40 HBMASTER: submitting job (8, 0, 15) to dispatcher
08:02:40 DISPATCHER: trying to submit job (8, 0, 15)
08:02:40 DISPATCHER: trying to notify the job_runner thread.
08:02:40 HBMASTER: job (8, 0, 15) submitted to dispatcher
08:02:40 DISPATCHER: Trying to submit another job.
08:02:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:02:40 DISPATCHER: starting job (8, 0, 15) on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:02:40 DISPATCHER: job (8, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:02:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:02:40 WORKER: start processing job (8, 0, 15)
08:02:40 WORKER: args: ()
08:02:40 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 551, 'last_n_outputs': 44, 'leak_rate': 0.9167120827767203, 'lr': 0.0024950677695241043, 'optimizer': 'SGD', 'sparsity': 0.8953327737362556, 'steps_to_train': 52, 'weight_decay': 0.016116789568743052}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:03:40 DISPATCHER: Starting worker discovery
08:03:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:03:40 DISPATCHER: Finished worker discovery
08:04:40 DISPATCHER: Starting worker discovery
08:04:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:04:40 DISPATCHER: Finished worker discovery
08:05:40 DISPATCHER: Starting worker discovery
08:05:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:05:40 DISPATCHER: Finished worker discovery
08:06:02 WORKER: done with job (8, 0, 15), trying to register it.
08:06:02 WORKER: registered result for job (8, 0, 15) with dispatcher
08:06:02 DISPATCHER: job (8, 0, 15) finished
08:06:02 DISPATCHER: register_result: lock acquired
08:06:02 DISPATCHER: job (8, 0, 15) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
08:06:02 job_id: (8, 0, 15)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 551, 'last_n_outputs': 44, 'leak_rate': 0.9167120827767203, 'lr': 0.0024950677695241043, 'optimizer': 'SGD', 'sparsity': 0.8953327737362556, 'steps_to_train': 52, 'weight_decay': 0.016116789568743052}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.34850366876325234, 'info': {'music_genre': 0.34850366876325234, 'config': "{'batch_size': 128, 'hidden_dim': 551, 'last_n_outputs': 44, 'leak_rate': 0.9167120827767203, 'lr': 0.0024950677695241043, 'optimizer': 'SGD', 'sparsity': 0.8953327737362556, 'steps_to_train': 52, 'weight_decay': 0.016116789568743052}"}}
exception: None

08:06:02 job_callback for (8, 0, 15) started
08:06:02 job_callback for (8, 0, 15) got condition
08:06:02 DISPATCHER: Trying to submit another job.
08:06:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:06:02 HBMASTER: Trying to run another job!
08:06:02 job_callback for (8, 0, 15) finished
08:06:02 HBMASTER: schedule new run for iteration 8
08:06:02 HBMASTER: trying submitting job (8, 0, 19) to dispatcher
08:06:02 HBMASTER: submitting job (8, 0, 19) to dispatcher
08:06:02 DISPATCHER: trying to submit job (8, 0, 19)
08:06:02 DISPATCHER: trying to notify the job_runner thread.
08:06:02 HBMASTER: job (8, 0, 19) submitted to dispatcher
08:06:02 DISPATCHER: Trying to submit another job.
08:06:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:06:02 DISPATCHER: starting job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:06:02 DISPATCHER: job (8, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:06:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:06:02 WORKER: start processing job (8, 0, 19)
08:06:02 WORKER: args: ()
08:06:02 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 263, 'last_n_outputs': 46, 'leak_rate': 0.9650180678098581, 'lr': 0.0018244016242122485, 'optimizer': 'Adam', 'sparsity': 0.9075485245203515, 'steps_to_train': 78, 'weight_decay': 0.014724823202764763}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:06:40 DISPATCHER: Starting worker discovery
08:06:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:06:40 DISPATCHER: Finished worker discovery
08:07:40 DISPATCHER: Starting worker discovery
08:07:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:07:40 DISPATCHER: Finished worker discovery
08:08:40 DISPATCHER: Starting worker discovery
08:08:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:08:40 DISPATCHER: Finished worker discovery
08:09:28 WORKER: done with job (8, 0, 19), trying to register it.
08:09:28 WORKER: registered result for job (8, 0, 19) with dispatcher
08:09:28 DISPATCHER: job (8, 0, 19) finished
08:09:28 DISPATCHER: register_result: lock acquired
08:09:28 DISPATCHER: job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
08:09:28 job_id: (8, 0, 19)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 263, 'last_n_outputs': 46, 'leak_rate': 0.9650180678098581, 'lr': 0.0018244016242122485, 'optimizer': 'Adam', 'sparsity': 0.9075485245203515, 'steps_to_train': 78, 'weight_decay': 0.014724823202764763}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3468456491211076, 'info': {'music_genre': 0.3468456491211076, 'config': "{'batch_size': 128, 'hidden_dim': 263, 'last_n_outputs': 46, 'leak_rate': 0.9650180678098581, 'lr': 0.0018244016242122485, 'optimizer': 'Adam', 'sparsity': 0.9075485245203515, 'steps_to_train': 78, 'weight_decay': 0.014724823202764763}"}}
exception: None

08:09:28 job_callback for (8, 0, 19) started
08:09:28 DISPATCHER: Trying to submit another job.
08:09:28 job_callback for (8, 0, 19) got condition
08:09:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:09:28 HBMASTER: Trying to run another job!
08:09:28 job_callback for (8, 0, 19) finished
08:09:28 HBMASTER: schedule new run for iteration 8
08:09:28 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
08:09:28 HBMASTER: submitting job (8, 0, 21) to dispatcher
08:09:28 DISPATCHER: trying to submit job (8, 0, 21)
08:09:28 DISPATCHER: trying to notify the job_runner thread.
08:09:28 HBMASTER: job (8, 0, 21) submitted to dispatcher
08:09:28 DISPATCHER: Trying to submit another job.
08:09:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:09:28 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:09:28 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:09:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:09:28 WORKER: start processing job (8, 0, 21)
08:09:28 WORKER: args: ()
08:09:28 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 516, 'last_n_outputs': 37, 'leak_rate': 0.8773156681198009, 'lr': 0.004828744531828341, 'optimizer': 'SGD', 'sparsity': 0.9118181835761667, 'steps_to_train': 66, 'weight_decay': 0.010559731402737313}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:09:40 DISPATCHER: Starting worker discovery
08:09:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:09:40 DISPATCHER: Finished worker discovery
08:10:40 DISPATCHER: Starting worker discovery
08:10:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:10:40 DISPATCHER: Finished worker discovery
08:11:40 DISPATCHER: Starting worker discovery
08:11:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:11:40 DISPATCHER: Finished worker discovery
08:12:40 DISPATCHER: Starting worker discovery
08:12:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:12:40 DISPATCHER: Finished worker discovery
08:12:46 WORKER: done with job (8, 0, 21), trying to register it.
08:12:46 WORKER: registered result for job (8, 0, 21) with dispatcher
08:12:46 DISPATCHER: job (8, 0, 21) finished
08:12:46 DISPATCHER: register_result: lock acquired
08:12:46 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
08:12:46 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 516, 'last_n_outputs': 37, 'leak_rate': 0.8773156681198009, 'lr': 0.004828744531828341, 'optimizer': 'SGD', 'sparsity': 0.9118181835761667, 'steps_to_train': 66, 'weight_decay': 0.010559731402737313}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.36619719752755886, 'info': {'music_genre': 0.36619719752755886, 'config': "{'batch_size': 128, 'hidden_dim': 516, 'last_n_outputs': 37, 'leak_rate': 0.8773156681198009, 'lr': 0.004828744531828341, 'optimizer': 'SGD', 'sparsity': 0.9118181835761667, 'steps_to_train': 66, 'weight_decay': 0.010559731402737313}"}}
exception: None

08:12:46 job_callback for (8, 0, 21) started
08:12:46 job_callback for (8, 0, 21) got condition
08:12:46 DISPATCHER: Trying to submit another job.
08:12:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:12:46 HBMASTER: Trying to run another job!
08:12:46 job_callback for (8, 0, 21) finished
08:12:46 HBMASTER: schedule new run for iteration 8
08:12:46 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
08:12:46 HBMASTER: submitting job (8, 0, 23) to dispatcher
08:12:46 DISPATCHER: trying to submit job (8, 0, 23)
08:12:46 DISPATCHER: trying to notify the job_runner thread.
08:12:46 HBMASTER: job (8, 0, 23) submitted to dispatcher
08:12:46 DISPATCHER: Trying to submit another job.
08:12:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:12:46 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:12:46 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:12:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:12:46 WORKER: start processing job (8, 0, 23)
08:12:46 WORKER: args: ()
08:12:46 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 512, 'last_n_outputs': 38, 'leak_rate': 0.9738602915157114, 'lr': 0.0012919404114902896, 'optimizer': 'Adam', 'sparsity': 0.9170735878364179, 'steps_to_train': 44, 'weight_decay': 0.016573364765172724}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:13:40 DISPATCHER: Starting worker discovery
08:13:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:13:40 DISPATCHER: Finished worker discovery
08:14:40 DISPATCHER: Starting worker discovery
08:14:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:14:40 DISPATCHER: Finished worker discovery
08:15:40 DISPATCHER: Starting worker discovery
08:15:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:15:40 DISPATCHER: Finished worker discovery
08:15:58 WORKER: done with job (8, 0, 23), trying to register it.
08:15:58 WORKER: registered result for job (8, 0, 23) with dispatcher
08:15:58 DISPATCHER: job (8, 0, 23) finished
08:15:58 DISPATCHER: register_result: lock acquired
08:15:58 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
08:15:58 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 512, 'last_n_outputs': 38, 'leak_rate': 0.9738602915157114, 'lr': 0.0012919404114902896, 'optimizer': 'Adam', 'sparsity': 0.9170735878364179, 'steps_to_train': 44, 'weight_decay': 0.016573364765172724}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.37142251924356295, 'info': {'music_genre': 0.37142251924356295, 'config': "{'batch_size': 128, 'hidden_dim': 512, 'last_n_outputs': 38, 'leak_rate': 0.9738602915157114, 'lr': 0.0012919404114902896, 'optimizer': 'Adam', 'sparsity': 0.9170735878364179, 'steps_to_train': 44, 'weight_decay': 0.016573364765172724}"}}
exception: None

08:15:58 job_callback for (8, 0, 23) started
08:15:58 job_callback for (8, 0, 23) got condition
08:15:58 DISPATCHER: Trying to submit another job.
08:15:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:15:58 HBMASTER: Trying to run another job!
08:15:58 job_callback for (8, 0, 23) finished
08:15:58 HBMASTER: schedule new run for iteration 8
08:15:58 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
08:15:58 HBMASTER: submitting job (8, 0, 25) to dispatcher
08:15:58 DISPATCHER: trying to submit job (8, 0, 25)
08:15:58 DISPATCHER: trying to notify the job_runner thread.
08:15:58 HBMASTER: job (8, 0, 25) submitted to dispatcher
08:15:58 DISPATCHER: Trying to submit another job.
08:15:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:15:58 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:15:58 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:15:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:15:58 WORKER: start processing job (8, 0, 25)
08:15:58 WORKER: args: ()
08:15:58 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 548, 'last_n_outputs': 42, 'leak_rate': 0.7843666297488994, 'lr': 0.004461109507913648, 'optimizer': 'SGD', 'sparsity': 0.9543701135146965, 'steps_to_train': 73, 'weight_decay': 0.024994091665130894}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:16:40 DISPATCHER: Starting worker discovery
08:16:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:16:40 DISPATCHER: Finished worker discovery
08:17:40 DISPATCHER: Starting worker discovery
08:17:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:17:40 DISPATCHER: Finished worker discovery
08:18:40 DISPATCHER: Starting worker discovery
08:18:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:18:40 DISPATCHER: Finished worker discovery
08:19:12 WORKER: done with job (8, 0, 25), trying to register it.
08:19:12 WORKER: registered result for job (8, 0, 25) with dispatcher
08:19:12 DISPATCHER: job (8, 0, 25) finished
08:19:12 DISPATCHER: register_result: lock acquired
08:19:12 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
08:19:12 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 548, 'last_n_outputs': 42, 'leak_rate': 0.7843666297488994, 'lr': 0.004461109507913648, 'optimizer': 'SGD', 'sparsity': 0.9543701135146965, 'steps_to_train': 73, 'weight_decay': 0.024994091665130894}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3594369240429836, 'info': {'music_genre': 0.3594369240429836, 'config': "{'batch_size': 128, 'hidden_dim': 548, 'last_n_outputs': 42, 'leak_rate': 0.7843666297488994, 'lr': 0.004461109507913648, 'optimizer': 'SGD', 'sparsity': 0.9543701135146965, 'steps_to_train': 73, 'weight_decay': 0.024994091665130894}"}}
exception: None

08:19:12 job_callback for (8, 0, 25) started
08:19:12 DISPATCHER: Trying to submit another job.
08:19:12 job_callback for (8, 0, 25) got condition
08:19:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:19:12 HBMASTER: Trying to run another job!
08:19:12 job_callback for (8, 0, 25) finished
08:19:12 ITERATION: Advancing config (8, 0, 8) to next budget 400.000000
08:19:12 ITERATION: Advancing config (8, 0, 21) to next budget 400.000000
08:19:12 ITERATION: Advancing config (8, 0, 23) to next budget 400.000000
08:19:12 HBMASTER: schedule new run for iteration 8
08:19:12 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
08:19:12 HBMASTER: submitting job (8, 0, 8) to dispatcher
08:19:12 DISPATCHER: trying to submit job (8, 0, 8)
08:19:12 DISPATCHER: trying to notify the job_runner thread.
08:19:12 HBMASTER: job (8, 0, 8) submitted to dispatcher
08:19:12 DISPATCHER: Trying to submit another job.
08:19:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:19:12 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:19:12 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:19:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:19:12 WORKER: start processing job (8, 0, 8)
08:19:12 WORKER: args: ()
08:19:12 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 436, 'last_n_outputs': 45, 'leak_rate': 0.8223815551514128, 'lr': 0.012140407698531176, 'optimizer': 'SGD', 'sparsity': 0.9204849363774981, 'steps_to_train': 89, 'weight_decay': 0.010313717954753093}, 'budget': 400.0, 'working_directory': '.'}
08:19:40 DISPATCHER: Starting worker discovery
08:19:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:19:40 DISPATCHER: Finished worker discovery
08:20:40 DISPATCHER: Starting worker discovery
08:20:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:20:40 DISPATCHER: Finished worker discovery
08:21:40 DISPATCHER: Starting worker discovery
08:21:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:21:40 DISPATCHER: Finished worker discovery
08:22:40 DISPATCHER: Starting worker discovery
08:22:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:22:40 DISPATCHER: Finished worker discovery
08:23:40 DISPATCHER: Starting worker discovery
08:23:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:23:40 DISPATCHER: Finished worker discovery
08:24:40 DISPATCHER: Starting worker discovery
08:24:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:24:40 DISPATCHER: Finished worker discovery
08:25:40 DISPATCHER: Starting worker discovery
08:25:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:25:40 DISPATCHER: Finished worker discovery
08:26:40 DISPATCHER: Starting worker discovery
08:26:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:26:40 DISPATCHER: Finished worker discovery
08:26:57 WORKER: done with job (8, 0, 8), trying to register it.
08:26:57 WORKER: registered result for job (8, 0, 8) with dispatcher
08:26:57 DISPATCHER: job (8, 0, 8) finished
08:26:57 DISPATCHER: register_result: lock acquired
08:26:57 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
08:26:57 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 436, 'last_n_outputs': 45, 'leak_rate': 0.8223815551514128, 'lr': 0.012140407698531176, 'optimizer': 'SGD', 'sparsity': 0.9204849363774981, 'steps_to_train': 89, 'weight_decay': 0.010313717954753093}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3708485303910961, 'info': {'music_genre': 0.3708485303910961, 'config': "{'batch_size': 128, 'hidden_dim': 436, 'last_n_outputs': 45, 'leak_rate': 0.8223815551514128, 'lr': 0.012140407698531176, 'optimizer': 'SGD', 'sparsity': 0.9204849363774981, 'steps_to_train': 89, 'weight_decay': 0.010313717954753093}"}}
exception: None

08:26:57 job_callback for (8, 0, 8) started
08:26:57 DISPATCHER: Trying to submit another job.
08:26:57 job_callback for (8, 0, 8) got condition
08:26:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:26:57 done building a new model for budget 400.000000 based on 10/21 split
Best loss for this budget:-0.400060





08:26:57 HBMASTER: Trying to run another job!
08:26:57 job_callback for (8, 0, 8) finished
08:26:57 HBMASTER: schedule new run for iteration 8
08:26:57 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
08:26:57 HBMASTER: submitting job (8, 0, 21) to dispatcher
08:26:57 DISPATCHER: trying to submit job (8, 0, 21)
08:26:57 DISPATCHER: trying to notify the job_runner thread.
08:26:57 HBMASTER: job (8, 0, 21) submitted to dispatcher
08:26:57 DISPATCHER: Trying to submit another job.
08:26:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:26:57 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:26:57 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:26:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:26:57 WORKER: start processing job (8, 0, 21)
08:26:57 WORKER: args: ()
08:26:57 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 516, 'last_n_outputs': 37, 'leak_rate': 0.8773156681198009, 'lr': 0.004828744531828341, 'optimizer': 'SGD', 'sparsity': 0.9118181835761667, 'steps_to_train': 66, 'weight_decay': 0.010559731402737313}, 'budget': 400.0, 'working_directory': '.'}
08:27:40 DISPATCHER: Starting worker discovery
08:27:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:27:40 DISPATCHER: Finished worker discovery
08:28:40 DISPATCHER: Starting worker discovery
08:28:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:28:40 DISPATCHER: Finished worker discovery
08:29:40 DISPATCHER: Starting worker discovery
08:29:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:29:40 DISPATCHER: Finished worker discovery
08:30:40 DISPATCHER: Starting worker discovery
08:30:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:30:40 DISPATCHER: Finished worker discovery
08:31:40 DISPATCHER: Starting worker discovery
08:31:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:31:40 DISPATCHER: Finished worker discovery
08:32:40 DISPATCHER: Starting worker discovery
08:32:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:32:40 DISPATCHER: Finished worker discovery
08:33:40 DISPATCHER: Starting worker discovery
08:33:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:33:40 DISPATCHER: Finished worker discovery
08:34:39 WORKER: done with job (8, 0, 21), trying to register it.
08:34:39 WORKER: registered result for job (8, 0, 21) with dispatcher
08:34:39 DISPATCHER: job (8, 0, 21) finished
08:34:39 DISPATCHER: register_result: lock acquired
08:34:39 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
08:34:39 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 516, 'last_n_outputs': 37, 'leak_rate': 0.8773156681198009, 'lr': 0.004828744531828341, 'optimizer': 'SGD', 'sparsity': 0.9118181835761667, 'steps_to_train': 66, 'weight_decay': 0.010559731402737313}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3397339073986602, 'info': {'music_genre': 0.3397339073986602, 'config': "{'batch_size': 128, 'hidden_dim': 516, 'last_n_outputs': 37, 'leak_rate': 0.8773156681198009, 'lr': 0.004828744531828341, 'optimizer': 'SGD', 'sparsity': 0.9118181835761667, 'steps_to_train': 66, 'weight_decay': 0.010559731402737313}"}}
exception: None

08:34:39 job_callback for (8, 0, 21) started
08:34:39 job_callback for (8, 0, 21) got condition
08:34:39 DISPATCHER: Trying to submit another job.
08:34:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:34:39 done building a new model for budget 400.000000 based on 10/22 split
Best loss for this budget:-0.400060





08:34:39 HBMASTER: Trying to run another job!
08:34:39 job_callback for (8, 0, 21) finished
08:34:39 HBMASTER: schedule new run for iteration 8
08:34:39 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
08:34:39 HBMASTER: submitting job (8, 0, 23) to dispatcher
08:34:39 DISPATCHER: trying to submit job (8, 0, 23)
08:34:39 DISPATCHER: trying to notify the job_runner thread.
08:34:39 HBMASTER: job (8, 0, 23) submitted to dispatcher
08:34:39 DISPATCHER: Trying to submit another job.
08:34:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:34:39 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:34:39 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:34:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:34:39 WORKER: start processing job (8, 0, 23)
08:34:39 WORKER: args: ()
08:34:39 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 512, 'last_n_outputs': 38, 'leak_rate': 0.9738602915157114, 'lr': 0.0012919404114902896, 'optimizer': 'Adam', 'sparsity': 0.9170735878364179, 'steps_to_train': 44, 'weight_decay': 0.016573364765172724}, 'budget': 400.0, 'working_directory': '.'}
08:34:40 DISPATCHER: Starting worker discovery
08:34:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:34:40 DISPATCHER: Finished worker discovery
08:35:40 DISPATCHER: Starting worker discovery
08:35:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:35:40 DISPATCHER: Finished worker discovery
08:36:40 DISPATCHER: Starting worker discovery
08:36:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:36:40 DISPATCHER: Finished worker discovery
08:37:40 DISPATCHER: Starting worker discovery
08:37:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:37:40 DISPATCHER: Finished worker discovery
08:38:40 DISPATCHER: Starting worker discovery
08:38:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:38:40 DISPATCHER: Finished worker discovery
08:39:40 DISPATCHER: Starting worker discovery
08:39:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:39:40 DISPATCHER: Finished worker discovery
08:40:40 DISPATCHER: Starting worker discovery
08:40:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:40:40 DISPATCHER: Finished worker discovery
08:41:40 DISPATCHER: Starting worker discovery
08:41:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:41:40 DISPATCHER: Finished worker discovery
08:42:23 WORKER: done with job (8, 0, 23), trying to register it.
08:42:23 WORKER: registered result for job (8, 0, 23) with dispatcher
08:42:23 DISPATCHER: job (8, 0, 23) finished
08:42:23 DISPATCHER: register_result: lock acquired
08:42:23 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
08:42:23 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 512, 'last_n_outputs': 38, 'leak_rate': 0.9738602915157114, 'lr': 0.0012919404114902896, 'optimizer': 'Adam', 'sparsity': 0.9170735878364179, 'steps_to_train': 44, 'weight_decay': 0.016573364765172724}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.35819160829463603, 'info': {'music_genre': 0.35819160829463603, 'config': "{'batch_size': 128, 'hidden_dim': 512, 'last_n_outputs': 38, 'leak_rate': 0.9738602915157114, 'lr': 0.0012919404114902896, 'optimizer': 'Adam', 'sparsity': 0.9170735878364179, 'steps_to_train': 44, 'weight_decay': 0.016573364765172724}"}}
exception: None

08:42:23 job_callback for (8, 0, 23) started
08:42:23 DISPATCHER: Trying to submit another job.
08:42:23 job_callback for (8, 0, 23) got condition
08:42:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:42:23 done building a new model for budget 400.000000 based on 10/22 split
Best loss for this budget:-0.400060





08:42:23 HBMASTER: Trying to run another job!
08:42:23 job_callback for (8, 0, 23) finished
08:42:23 ITERATION: Advancing config (8, 0, 8) to next budget 1200.000000
08:42:23 HBMASTER: schedule new run for iteration 8
08:42:23 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
08:42:23 HBMASTER: submitting job (8, 0, 8) to dispatcher
08:42:23 DISPATCHER: trying to submit job (8, 0, 8)
08:42:23 DISPATCHER: trying to notify the job_runner thread.
08:42:23 HBMASTER: job (8, 0, 8) submitted to dispatcher
08:42:23 DISPATCHER: Trying to submit another job.
08:42:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:42:23 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:42:23 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:42:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:42:23 WORKER: start processing job (8, 0, 8)
08:42:23 WORKER: args: ()
08:42:23 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 436, 'last_n_outputs': 45, 'leak_rate': 0.8223815551514128, 'lr': 0.012140407698531176, 'optimizer': 'SGD', 'sparsity': 0.9204849363774981, 'steps_to_train': 89, 'weight_decay': 0.010313717954753093}, 'budget': 1200.0, 'working_directory': '.'}
08:42:40 DISPATCHER: Starting worker discovery
08:42:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:42:40 DISPATCHER: Finished worker discovery
08:43:40 DISPATCHER: Starting worker discovery
08:43:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:43:40 DISPATCHER: Finished worker discovery
08:44:40 DISPATCHER: Starting worker discovery
08:44:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:44:40 DISPATCHER: Finished worker discovery
08:45:40 DISPATCHER: Starting worker discovery
08:45:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:45:40 DISPATCHER: Finished worker discovery
08:46:40 DISPATCHER: Starting worker discovery
08:46:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:46:40 DISPATCHER: Finished worker discovery
08:47:40 DISPATCHER: Starting worker discovery
08:47:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:47:40 DISPATCHER: Finished worker discovery
08:48:40 DISPATCHER: Starting worker discovery
08:48:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:48:40 DISPATCHER: Finished worker discovery
08:49:40 DISPATCHER: Starting worker discovery
08:49:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:49:40 DISPATCHER: Finished worker discovery
08:50:40 DISPATCHER: Starting worker discovery
08:50:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:50:40 DISPATCHER: Finished worker discovery
08:51:40 DISPATCHER: Starting worker discovery
08:51:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:51:40 DISPATCHER: Finished worker discovery
08:52:40 DISPATCHER: Starting worker discovery
08:52:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:52:40 DISPATCHER: Finished worker discovery
08:53:40 DISPATCHER: Starting worker discovery
08:53:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:53:40 DISPATCHER: Finished worker discovery
08:54:40 DISPATCHER: Starting worker discovery
08:54:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:54:40 DISPATCHER: Finished worker discovery
08:55:40 DISPATCHER: Starting worker discovery
08:55:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:55:40 DISPATCHER: Finished worker discovery
08:56:40 DISPATCHER: Starting worker discovery
08:56:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:56:40 DISPATCHER: Finished worker discovery
08:57:40 DISPATCHER: Starting worker discovery
08:57:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:57:40 DISPATCHER: Finished worker discovery
08:58:40 DISPATCHER: Starting worker discovery
08:58:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:58:40 DISPATCHER: Finished worker discovery
08:59:40 DISPATCHER: Starting worker discovery
08:59:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:59:40 DISPATCHER: Finished worker discovery
09:00:40 DISPATCHER: Starting worker discovery
09:00:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:00:40 DISPATCHER: Finished worker discovery
09:01:40 DISPATCHER: Starting worker discovery
09:01:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:01:40 DISPATCHER: Finished worker discovery
09:02:40 DISPATCHER: Starting worker discovery
09:02:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:02:40 DISPATCHER: Finished worker discovery
09:03:38 WORKER: done with job (8, 0, 8), trying to register it.
09:03:38 WORKER: registered result for job (8, 0, 8) with dispatcher
09:03:38 DISPATCHER: job (8, 0, 8) finished
09:03:38 DISPATCHER: register_result: lock acquired
09:03:38 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
09:03:38 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 436, 'last_n_outputs': 45, 'leak_rate': 0.8223815551514128, 'lr': 0.012140407698531176, 'optimizer': 'SGD', 'sparsity': 0.9204849363774981, 'steps_to_train': 89, 'weight_decay': 0.010313717954753093}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.38784293942697234, 'info': {'music_genre': 0.38784293942697234, 'config': "{'batch_size': 128, 'hidden_dim': 436, 'last_n_outputs': 45, 'leak_rate': 0.8223815551514128, 'lr': 0.012140407698531176, 'optimizer': 'SGD', 'sparsity': 0.9204849363774981, 'steps_to_train': 89, 'weight_decay': 0.010313717954753093}"}}
exception: None

09:03:38 job_callback for (8, 0, 8) started
09:03:38 DISPATCHER: Trying to submit another job.
09:03:38 job_callback for (8, 0, 8) got condition
09:03:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:03:38 HBMASTER: Trying to run another job!
09:03:38 job_callback for (8, 0, 8) finished
09:03:38 start sampling a new configuration.
09:03:38 done sampling a new configuration.
09:03:38 HBMASTER: schedule new run for iteration 9
09:03:38 HBMASTER: trying submitting job (9, 0, 0) to dispatcher
09:03:38 HBMASTER: submitting job (9, 0, 0) to dispatcher
09:03:38 DISPATCHER: trying to submit job (9, 0, 0)
09:03:38 DISPATCHER: trying to notify the job_runner thread.
09:03:38 HBMASTER: job (9, 0, 0) submitted to dispatcher
09:03:38 DISPATCHER: Trying to submit another job.
09:03:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:03:38 DISPATCHER: starting job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:03:38 DISPATCHER: job (9, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:03:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:03:38 WORKER: start processing job (9, 0, 0)
09:03:38 WORKER: args: ()
09:03:38 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 429, 'last_n_outputs': 12, 'leak_rate': 0.9480565099439203, 'lr': 0.037041576053511216, 'optimizer': 'SGD', 'sparsity': 0.7824627453585302, 'steps_to_train': 42, 'weight_decay': 0.041812765973959255}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:03:40 DISPATCHER: Starting worker discovery
09:03:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:03:40 DISPATCHER: Finished worker discovery
09:04:40 DISPATCHER: Starting worker discovery
09:04:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:04:40 DISPATCHER: Finished worker discovery
09:05:40 DISPATCHER: Starting worker discovery
09:05:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:05:40 DISPATCHER: Finished worker discovery
09:06:40 DISPATCHER: Starting worker discovery
09:06:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:06:40 DISPATCHER: Finished worker discovery
09:06:52 WORKER: done with job (9, 0, 0), trying to register it.
09:06:52 WORKER: registered result for job (9, 0, 0) with dispatcher
09:06:52 DISPATCHER: job (9, 0, 0) finished
09:06:52 DISPATCHER: register_result: lock acquired
09:06:52 DISPATCHER: job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
09:06:52 job_id: (9, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 429, 'last_n_outputs': 12, 'leak_rate': 0.9480565099439203, 'lr': 0.037041576053511216, 'optimizer': 'SGD', 'sparsity': 0.7824627453585302, 'steps_to_train': 42, 'weight_decay': 0.041812765973959255}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.280592827718431, 'info': {'music_genre': 0.280592827718431, 'config': "{'batch_size': 32, 'hidden_dim': 429, 'last_n_outputs': 12, 'leak_rate': 0.9480565099439203, 'lr': 0.037041576053511216, 'optimizer': 'SGD', 'sparsity': 0.7824627453585302, 'steps_to_train': 42, 'weight_decay': 0.041812765973959255}"}}
exception: None

09:06:52 job_callback for (9, 0, 0) started
09:06:52 DISPATCHER: Trying to submit another job.
09:06:52 job_callback for (9, 0, 0) got condition
09:06:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:06:52 HBMASTER: Trying to run another job!
09:06:52 job_callback for (9, 0, 0) finished
09:06:52 start sampling a new configuration.
09:06:52 best_vector: [3, 0.21942778141478292, 0.7800021342286214, 0.2787771308849597, 0.32080622962878047, 0, 0.8642117328959893, 0.876847723502932, 0.06613461651774546], 9.447095496231445e-33, 1.058526401473248, -0.19478481959703767
09:06:52 done sampling a new configuration.
09:06:52 HBMASTER: schedule new run for iteration 9
09:06:52 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
09:06:52 HBMASTER: submitting job (9, 0, 1) to dispatcher
09:06:52 DISPATCHER: trying to submit job (9, 0, 1)
09:06:52 DISPATCHER: trying to notify the job_runner thread.
09:06:52 HBMASTER: job (9, 0, 1) submitted to dispatcher
09:06:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:06:52 DISPATCHER: Trying to submit another job.
09:06:52 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:06:52 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:06:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:06:52 WORKER: start processing job (9, 0, 1)
09:06:52 WORKER: args: ()
09:06:52 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 375, 'last_n_outputs': 41, 'leak_rate': 0.8196942827212399, 'lr': 0.004381395514090343, 'optimizer': 'Adam', 'sparsity': 0.9574108158950374, 'steps_to_train': 89, 'weight_decay': 0.012191106348803094}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:07:40 DISPATCHER: Starting worker discovery
09:07:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:07:40 DISPATCHER: Finished worker discovery
09:08:40 DISPATCHER: Starting worker discovery
09:08:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:08:40 DISPATCHER: Finished worker discovery
09:09:40 DISPATCHER: Starting worker discovery
09:09:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:09:40 DISPATCHER: Finished worker discovery
09:10:13 WORKER: done with job (9, 0, 1), trying to register it.
09:10:13 WORKER: registered result for job (9, 0, 1) with dispatcher
09:10:13 DISPATCHER: job (9, 0, 1) finished
09:10:13 DISPATCHER: register_result: lock acquired
09:10:13 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
09:10:13 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 375, 'last_n_outputs': 41, 'leak_rate': 0.8196942827212399, 'lr': 0.004381395514090343, 'optimizer': 'Adam', 'sparsity': 0.9574108158950374, 'steps_to_train': 89, 'weight_decay': 0.012191106348803094}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3353062180518149, 'info': {'music_genre': 0.3353062180518149, 'config': "{'batch_size': 128, 'hidden_dim': 375, 'last_n_outputs': 41, 'leak_rate': 0.8196942827212399, 'lr': 0.004381395514090343, 'optimizer': 'Adam', 'sparsity': 0.9574108158950374, 'steps_to_train': 89, 'weight_decay': 0.012191106348803094}"}}
exception: None

09:10:13 job_callback for (9, 0, 1) started
09:10:13 DISPATCHER: Trying to submit another job.
09:10:13 job_callback for (9, 0, 1) got condition
09:10:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:10:13 HBMASTER: Trying to run another job!
09:10:13 job_callback for (9, 0, 1) finished
09:10:13 start sampling a new configuration.
09:10:13 best_vector: [3, 0.734446403192336, 0.894384805260746, 0.8016770441517385, 0.5375129534177566, 1, 0.623402169314293, 0.7955117220894234, 0.0005546450811030612], 5.765287806421669e-32, 0.1734518784797091, -0.016461191024231294
09:10:13 done sampling a new configuration.
09:10:13 HBMASTER: schedule new run for iteration 9
09:10:13 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
09:10:13 HBMASTER: submitting job (9, 0, 2) to dispatcher
09:10:13 DISPATCHER: trying to submit job (9, 0, 2)
09:10:13 DISPATCHER: trying to notify the job_runner thread.
09:10:13 HBMASTER: job (9, 0, 2) submitted to dispatcher
09:10:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:10:13 DISPATCHER: Trying to submit another job.
09:10:13 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:10:13 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:10:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:10:13 WORKER: start processing job (9, 0, 2)
09:10:13 WORKER: args: ()
09:10:13 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 788, 'last_n_outputs': 46, 'leak_rate': 0.9504192610379346, 'lr': 0.011885731269104822, 'optimizer': 'SGD', 'sparsity': 0.8996165206354303, 'steps_to_train': 82, 'weight_decay': 0.010016629493390829}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:10:40 DISPATCHER: Starting worker discovery
09:10:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:10:40 DISPATCHER: Finished worker discovery
09:11:40 DISPATCHER: Starting worker discovery
09:11:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:11:40 DISPATCHER: Finished worker discovery
09:12:40 DISPATCHER: Starting worker discovery
09:12:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:12:40 DISPATCHER: Finished worker discovery
09:13:23 WORKER: done with job (9, 0, 2), trying to register it.
09:13:23 WORKER: registered result for job (9, 0, 2) with dispatcher
09:13:23 DISPATCHER: job (9, 0, 2) finished
09:13:23 DISPATCHER: register_result: lock acquired
09:13:23 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
09:13:23 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 788, 'last_n_outputs': 46, 'leak_rate': 0.9504192610379346, 'lr': 0.011885731269104822, 'optimizer': 'SGD', 'sparsity': 0.8996165206354303, 'steps_to_train': 82, 'weight_decay': 0.010016629493390829}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.35782611356628136, 'info': {'music_genre': 0.35782611356628136, 'config': "{'batch_size': 128, 'hidden_dim': 788, 'last_n_outputs': 46, 'leak_rate': 0.9504192610379346, 'lr': 0.011885731269104822, 'optimizer': 'SGD', 'sparsity': 0.8996165206354303, 'steps_to_train': 82, 'weight_decay': 0.010016629493390829}"}}
exception: None

09:13:23 job_callback for (9, 0, 2) started
09:13:23 job_callback for (9, 0, 2) got condition
09:13:23 DISPATCHER: Trying to submit another job.
09:13:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:13:23 HBMASTER: Trying to run another job!
09:13:23 job_callback for (9, 0, 2) finished
09:13:23 start sampling a new configuration.
09:13:23 done sampling a new configuration.
09:13:23 HBMASTER: schedule new run for iteration 9
09:13:23 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
09:13:23 HBMASTER: submitting job (9, 0, 3) to dispatcher
09:13:23 DISPATCHER: trying to submit job (9, 0, 3)
09:13:23 DISPATCHER: trying to notify the job_runner thread.
09:13:23 HBMASTER: job (9, 0, 3) submitted to dispatcher
09:13:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:13:23 DISPATCHER: Trying to submit another job.
09:13:23 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:13:23 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:13:23 WORKER: start processing job (9, 0, 3)
09:13:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:13:23 WORKER: args: ()
09:13:23 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 878, 'last_n_outputs': 40, 'leak_rate': 0.8737158319488083, 'lr': 0.006790823031537631, 'optimizer': 'Adam', 'sparsity': 0.8952225472759894, 'steps_to_train': 35, 'weight_decay': 0.013823671011488474}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:13:40 DISPATCHER: Starting worker discovery
09:13:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:13:41 DISPATCHER: Finished worker discovery
09:14:41 DISPATCHER: Starting worker discovery
09:14:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:14:41 DISPATCHER: Finished worker discovery
09:15:41 DISPATCHER: Starting worker discovery
09:15:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:15:41 DISPATCHER: Finished worker discovery
09:16:34 WORKER: done with job (9, 0, 3), trying to register it.
09:16:34 WORKER: registered result for job (9, 0, 3) with dispatcher
09:16:34 DISPATCHER: job (9, 0, 3) finished
09:16:34 DISPATCHER: register_result: lock acquired
09:16:34 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
09:16:34 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 878, 'last_n_outputs': 40, 'leak_rate': 0.8737158319488083, 'lr': 0.006790823031537631, 'optimizer': 'Adam', 'sparsity': 0.8952225472759894, 'steps_to_train': 35, 'weight_decay': 0.013823671011488474}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2627388688001207, 'info': {'music_genre': 0.2627388688001207, 'config': "{'batch_size': 128, 'hidden_dim': 878, 'last_n_outputs': 40, 'leak_rate': 0.8737158319488083, 'lr': 0.006790823031537631, 'optimizer': 'Adam', 'sparsity': 0.8952225472759894, 'steps_to_train': 35, 'weight_decay': 0.013823671011488474}"}}
exception: None

09:16:34 job_callback for (9, 0, 3) started
09:16:34 DISPATCHER: Trying to submit another job.
09:16:34 job_callback for (9, 0, 3) got condition
09:16:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:16:34 HBMASTER: Trying to run another job!
09:16:34 job_callback for (9, 0, 3) finished
09:16:34 start sampling a new configuration.
09:16:34 done sampling a new configuration.
09:16:34 HBMASTER: schedule new run for iteration 9
09:16:34 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
09:16:34 HBMASTER: submitting job (9, 0, 4) to dispatcher
09:16:34 DISPATCHER: trying to submit job (9, 0, 4)
09:16:34 DISPATCHER: trying to notify the job_runner thread.
09:16:34 HBMASTER: job (9, 0, 4) submitted to dispatcher
09:16:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:16:34 DISPATCHER: Trying to submit another job.
09:16:34 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:16:34 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:16:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:16:34 WORKER: start processing job (9, 0, 4)
09:16:34 WORKER: args: ()
09:16:34 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 698, 'last_n_outputs': 37, 'leak_rate': 0.7703821026768634, 'lr': 0.01444181234595762, 'optimizer': 'SGD', 'sparsity': 0.8165088504669563, 'steps_to_train': 36, 'weight_decay': 0.018366041950493336}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:16:41 DISPATCHER: Starting worker discovery
09:16:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:16:41 DISPATCHER: Finished worker discovery
09:17:41 DISPATCHER: Starting worker discovery
09:17:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:17:41 DISPATCHER: Finished worker discovery
09:18:41 DISPATCHER: Starting worker discovery
09:18:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:18:41 DISPATCHER: Finished worker discovery
09:19:41 DISPATCHER: Starting worker discovery
09:19:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:19:41 DISPATCHER: Finished worker discovery
09:19:44 WORKER: done with job (9, 0, 4), trying to register it.
09:19:44 WORKER: registered result for job (9, 0, 4) with dispatcher
09:19:44 DISPATCHER: job (9, 0, 4) finished
09:19:44 DISPATCHER: register_result: lock acquired
09:19:44 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
09:19:44 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 698, 'last_n_outputs': 37, 'leak_rate': 0.7703821026768634, 'lr': 0.01444181234595762, 'optimizer': 'SGD', 'sparsity': 0.8165088504669563, 'steps_to_train': 36, 'weight_decay': 0.018366041950493336}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3688702796962322, 'info': {'music_genre': 0.3688702796962322, 'config': "{'batch_size': 128, 'hidden_dim': 698, 'last_n_outputs': 37, 'leak_rate': 0.7703821026768634, 'lr': 0.01444181234595762, 'optimizer': 'SGD', 'sparsity': 0.8165088504669563, 'steps_to_train': 36, 'weight_decay': 0.018366041950493336}"}}
exception: None

09:19:44 job_callback for (9, 0, 4) started
09:19:44 job_callback for (9, 0, 4) got condition
09:19:44 DISPATCHER: Trying to submit another job.
09:19:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:19:44 HBMASTER: Trying to run another job!
09:19:44 job_callback for (9, 0, 4) finished
09:19:44 start sampling a new configuration.
09:19:44 done sampling a new configuration.
09:19:44 HBMASTER: schedule new run for iteration 9
09:19:44 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
09:19:44 HBMASTER: submitting job (9, 0, 5) to dispatcher
09:19:44 DISPATCHER: trying to submit job (9, 0, 5)
09:19:44 DISPATCHER: trying to notify the job_runner thread.
09:19:44 HBMASTER: job (9, 0, 5) submitted to dispatcher
09:19:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:19:44 DISPATCHER: Trying to submit another job.
09:19:44 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:19:44 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:19:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:19:44 WORKER: start processing job (9, 0, 5)
09:19:44 WORKER: args: ()
09:19:44 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 904, 'last_n_outputs': 46, 'leak_rate': 0.782211831796584, 'lr': 0.009455612339696284, 'optimizer': 'Adam', 'sparsity': 0.9650205224676593, 'steps_to_train': 84, 'weight_decay': 0.030654186723622842}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:20:41 DISPATCHER: Starting worker discovery
09:20:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:20:41 DISPATCHER: Finished worker discovery
09:21:41 DISPATCHER: Starting worker discovery
09:21:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:21:41 DISPATCHER: Finished worker discovery
09:22:41 DISPATCHER: Starting worker discovery
09:22:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:22:41 DISPATCHER: Finished worker discovery
09:23:05 WORKER: done with job (9, 0, 5), trying to register it.
09:23:05 WORKER: registered result for job (9, 0, 5) with dispatcher
09:23:05 DISPATCHER: job (9, 0, 5) finished
09:23:05 DISPATCHER: register_result: lock acquired
09:23:05 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
09:23:05 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 904, 'last_n_outputs': 46, 'leak_rate': 0.782211831796584, 'lr': 0.009455612339696284, 'optimizer': 'Adam', 'sparsity': 0.9650205224676593, 'steps_to_train': 84, 'weight_decay': 0.030654186723622842}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1972809907485224, 'info': {'music_genre': 0.1972809907485224, 'config': "{'batch_size': 64, 'hidden_dim': 904, 'last_n_outputs': 46, 'leak_rate': 0.782211831796584, 'lr': 0.009455612339696284, 'optimizer': 'Adam', 'sparsity': 0.9650205224676593, 'steps_to_train': 84, 'weight_decay': 0.030654186723622842}"}}
exception: None

09:23:05 job_callback for (9, 0, 5) started
09:23:05 job_callback for (9, 0, 5) got condition
09:23:05 DISPATCHER: Trying to submit another job.
09:23:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:23:05 HBMASTER: Trying to run another job!
09:23:05 job_callback for (9, 0, 5) finished
09:23:05 start sampling a new configuration.
09:23:05 best_vector: [3, 0.3066610346212648, 0.922451039083865, 0.15343176080778625, 0.08224563871613383, 1, 0.767731685917144, 0.6010388172189034, 0.13684243063834617], 4.588521760707864e-33, 2.179351111643702, -0.12010045774184229
09:23:05 done sampling a new configuration.
09:23:05 HBMASTER: schedule new run for iteration 9
09:23:05 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
09:23:05 HBMASTER: submitting job (9, 0, 6) to dispatcher
09:23:05 DISPATCHER: trying to submit job (9, 0, 6)
09:23:05 DISPATCHER: trying to notify the job_runner thread.
09:23:05 HBMASTER: job (9, 0, 6) submitted to dispatcher
09:23:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:23:05 DISPATCHER: Trying to submit another job.
09:23:05 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:23:05 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:23:05 WORKER: start processing job (9, 0, 6)
09:23:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:23:05 WORKER: args: ()
09:23:05 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 445, 'last_n_outputs': 47, 'leak_rate': 0.7883579402019466, 'lr': 0.0014604654164959568, 'optimizer': 'SGD', 'sparsity': 0.9342556046201146, 'steps_to_train': 64, 'weight_decay': 0.0150673232965359}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:23:41 DISPATCHER: Starting worker discovery
09:23:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:23:41 DISPATCHER: Finished worker discovery
09:24:41 DISPATCHER: Starting worker discovery
09:24:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:24:41 DISPATCHER: Finished worker discovery
09:25:41 DISPATCHER: Starting worker discovery
09:25:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:25:41 DISPATCHER: Finished worker discovery
09:26:20 WORKER: done with job (9, 0, 6), trying to register it.
09:26:20 WORKER: registered result for job (9, 0, 6) with dispatcher
09:26:20 DISPATCHER: job (9, 0, 6) finished
09:26:20 DISPATCHER: register_result: lock acquired
09:26:20 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
09:26:20 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 445, 'last_n_outputs': 47, 'leak_rate': 0.7883579402019466, 'lr': 0.0014604654164959568, 'optimizer': 'SGD', 'sparsity': 0.9342556046201146, 'steps_to_train': 64, 'weight_decay': 0.0150673232965359}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.33162679627013847, 'info': {'music_genre': 0.33162679627013847, 'config': "{'batch_size': 128, 'hidden_dim': 445, 'last_n_outputs': 47, 'leak_rate': 0.7883579402019466, 'lr': 0.0014604654164959568, 'optimizer': 'SGD', 'sparsity': 0.9342556046201146, 'steps_to_train': 64, 'weight_decay': 0.0150673232965359}"}}
exception: None

09:26:20 job_callback for (9, 0, 6) started
09:26:20 job_callback for (9, 0, 6) got condition
09:26:20 DISPATCHER: Trying to submit another job.
09:26:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:26:20 HBMASTER: Trying to run another job!
09:26:20 job_callback for (9, 0, 6) finished
09:26:20 start sampling a new configuration.
09:26:20 done sampling a new configuration.
09:26:20 HBMASTER: schedule new run for iteration 9
09:26:20 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
09:26:20 HBMASTER: submitting job (9, 0, 7) to dispatcher
09:26:20 DISPATCHER: trying to submit job (9, 0, 7)
09:26:20 DISPATCHER: trying to notify the job_runner thread.
09:26:20 HBMASTER: job (9, 0, 7) submitted to dispatcher
09:26:20 DISPATCHER: Trying to submit another job.
09:26:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:26:20 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:26:20 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:26:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:26:20 WORKER: start processing job (9, 0, 7)
09:26:20 WORKER: args: ()
09:26:20 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 962, 'last_n_outputs': 45, 'leak_rate': 0.95989527413455, 'lr': 0.022114150144239585, 'optimizer': 'SGD', 'sparsity': 0.9748688345830764, 'steps_to_train': 63, 'weight_decay': 0.06988853694720566}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:26:41 DISPATCHER: Starting worker discovery
09:26:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:26:41 DISPATCHER: Finished worker discovery
09:27:41 DISPATCHER: Starting worker discovery
09:27:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:27:41 DISPATCHER: Finished worker discovery
09:28:41 DISPATCHER: Starting worker discovery
09:28:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:28:41 DISPATCHER: Finished worker discovery
09:29:41 DISPATCHER: Starting worker discovery
09:29:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:29:41 DISPATCHER: Finished worker discovery
09:29:45 WORKER: done with job (9, 0, 7), trying to register it.
09:29:45 WORKER: registered result for job (9, 0, 7) with dispatcher
09:29:45 DISPATCHER: job (9, 0, 7) finished
09:29:45 DISPATCHER: register_result: lock acquired
09:29:45 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
09:29:45 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 962, 'last_n_outputs': 45, 'leak_rate': 0.95989527413455, 'lr': 0.022114150144239585, 'optimizer': 'SGD', 'sparsity': 0.9748688345830764, 'steps_to_train': 63, 'weight_decay': 0.06988853694720566}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3129765881562977, 'info': {'music_genre': 0.3129765881562977, 'config': "{'batch_size': 32, 'hidden_dim': 962, 'last_n_outputs': 45, 'leak_rate': 0.95989527413455, 'lr': 0.022114150144239585, 'optimizer': 'SGD', 'sparsity': 0.9748688345830764, 'steps_to_train': 63, 'weight_decay': 0.06988853694720566}"}}
exception: None

09:29:45 job_callback for (9, 0, 7) started
09:29:45 job_callback for (9, 0, 7) got condition
09:29:45 DISPATCHER: Trying to submit another job.
09:29:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:29:45 HBMASTER: Trying to run another job!
09:29:45 job_callback for (9, 0, 7) finished
09:29:45 start sampling a new configuration.
09:29:45 best_vector: [0, 0.895204176554608, 0.4226414305113887, 0.050382975701032055, 0.6551128660091995, 1, 0.7016029909855704, 0.4379357578681872, 0.0959254836224806], 2.068579749041636e-33, 4.834234698774827, -0.0026759555449968253
09:29:45 done sampling a new configuration.
09:29:45 HBMASTER: schedule new run for iteration 9
09:29:45 HBMASTER: trying submitting job (9, 0, 8) to dispatcher
09:29:45 HBMASTER: submitting job (9, 0, 8) to dispatcher
09:29:45 DISPATCHER: trying to submit job (9, 0, 8)
09:29:45 DISPATCHER: trying to notify the job_runner thread.
09:29:45 HBMASTER: job (9, 0, 8) submitted to dispatcher
09:29:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:29:45 DISPATCHER: Trying to submit another job.
09:29:45 DISPATCHER: starting job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:29:45 DISPATCHER: job (9, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:29:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:29:45 WORKER: start processing job (9, 0, 8)
09:29:45 WORKER: args: ()
09:29:45 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 917, 'last_n_outputs': 27, 'leak_rate': 0.762595743925258, 'lr': 0.02042799448888138, 'optimizer': 'SGD', 'sparsity': 0.918384717836537, 'steps_to_train': 49, 'weight_decay': 0.013329133924017626}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:30:41 DISPATCHER: Starting worker discovery
09:30:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:30:41 DISPATCHER: Finished worker discovery
09:31:41 DISPATCHER: Starting worker discovery
09:31:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:31:41 DISPATCHER: Finished worker discovery
09:32:41 DISPATCHER: Starting worker discovery
09:32:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:32:41 DISPATCHER: Finished worker discovery
09:33:02 WORKER: done with job (9, 0, 8), trying to register it.
09:33:02 WORKER: registered result for job (9, 0, 8) with dispatcher
09:33:02 DISPATCHER: job (9, 0, 8) finished
09:33:02 DISPATCHER: register_result: lock acquired
09:33:02 DISPATCHER: job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
09:33:02 job_id: (9, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 917, 'last_n_outputs': 27, 'leak_rate': 0.762595743925258, 'lr': 0.02042799448888138, 'optimizer': 'SGD', 'sparsity': 0.918384717836537, 'steps_to_train': 49, 'weight_decay': 0.013329133924017626}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3314338863569778, 'info': {'music_genre': 0.3314338863569778, 'config': "{'batch_size': 16, 'hidden_dim': 917, 'last_n_outputs': 27, 'leak_rate': 0.762595743925258, 'lr': 0.02042799448888138, 'optimizer': 'SGD', 'sparsity': 0.918384717836537, 'steps_to_train': 49, 'weight_decay': 0.013329133924017626}"}}
exception: None

09:33:02 job_callback for (9, 0, 8) started
09:33:02 DISPATCHER: Trying to submit another job.
09:33:02 job_callback for (9, 0, 8) got condition
09:33:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:33:02 HBMASTER: Trying to run another job!
09:33:02 job_callback for (9, 0, 8) finished
09:33:02 ITERATION: Advancing config (9, 0, 1) to next budget 400.000000
09:33:02 ITERATION: Advancing config (9, 0, 2) to next budget 400.000000
09:33:02 ITERATION: Advancing config (9, 0, 4) to next budget 400.000000
09:33:02 HBMASTER: schedule new run for iteration 9
09:33:02 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
09:33:02 HBMASTER: submitting job (9, 0, 1) to dispatcher
09:33:02 DISPATCHER: trying to submit job (9, 0, 1)
09:33:02 DISPATCHER: trying to notify the job_runner thread.
09:33:02 HBMASTER: job (9, 0, 1) submitted to dispatcher
09:33:02 DISPATCHER: Trying to submit another job.
09:33:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:33:02 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:33:02 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:33:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:33:02 WORKER: start processing job (9, 0, 1)
09:33:02 WORKER: args: ()
09:33:02 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 375, 'last_n_outputs': 41, 'leak_rate': 0.8196942827212399, 'lr': 0.004381395514090343, 'optimizer': 'Adam', 'sparsity': 0.9574108158950374, 'steps_to_train': 89, 'weight_decay': 0.012191106348803094}, 'budget': 400.0, 'working_directory': '.'}
09:33:41 DISPATCHER: Starting worker discovery
09:33:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:33:41 DISPATCHER: Finished worker discovery
09:34:41 DISPATCHER: Starting worker discovery
09:34:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:34:41 DISPATCHER: Finished worker discovery
09:35:41 DISPATCHER: Starting worker discovery
09:35:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:35:41 DISPATCHER: Finished worker discovery
09:36:41 DISPATCHER: Starting worker discovery
09:36:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:36:41 DISPATCHER: Finished worker discovery
09:37:41 DISPATCHER: Starting worker discovery
09:37:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:37:41 DISPATCHER: Finished worker discovery
09:38:41 DISPATCHER: Starting worker discovery
09:38:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:38:41 DISPATCHER: Finished worker discovery
09:39:41 DISPATCHER: Starting worker discovery
09:39:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:39:41 DISPATCHER: Finished worker discovery
09:40:41 DISPATCHER: Starting worker discovery
09:40:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:40:41 DISPATCHER: Finished worker discovery
09:40:44 WORKER: done with job (9, 0, 1), trying to register it.
09:40:44 WORKER: registered result for job (9, 0, 1) with dispatcher
09:40:44 DISPATCHER: job (9, 0, 1) finished
09:40:44 DISPATCHER: register_result: lock acquired
09:40:44 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
09:40:44 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 375, 'last_n_outputs': 41, 'leak_rate': 0.8196942827212399, 'lr': 0.004381395514090343, 'optimizer': 'Adam', 'sparsity': 0.9574108158950374, 'steps_to_train': 89, 'weight_decay': 0.012191106348803094}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3250121558472512, 'info': {'music_genre': 0.3250121558472512, 'config': "{'batch_size': 128, 'hidden_dim': 375, 'last_n_outputs': 41, 'leak_rate': 0.8196942827212399, 'lr': 0.004381395514090343, 'optimizer': 'Adam', 'sparsity': 0.9574108158950374, 'steps_to_train': 89, 'weight_decay': 0.012191106348803094}"}}
exception: None

09:40:44 job_callback for (9, 0, 1) started
09:40:44 DISPATCHER: Trying to submit another job.
09:40:44 job_callback for (9, 0, 1) got condition
09:40:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:40:44 done building a new model for budget 400.000000 based on 10/23 split
Best loss for this budget:-0.400060





09:40:44 HBMASTER: Trying to run another job!
09:40:44 job_callback for (9, 0, 1) finished
09:40:44 HBMASTER: schedule new run for iteration 9
09:40:44 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
09:40:44 HBMASTER: submitting job (9, 0, 2) to dispatcher
09:40:44 DISPATCHER: trying to submit job (9, 0, 2)
09:40:44 DISPATCHER: trying to notify the job_runner thread.
09:40:44 HBMASTER: job (9, 0, 2) submitted to dispatcher
09:40:44 DISPATCHER: Trying to submit another job.
09:40:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:40:44 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:40:44 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:40:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:40:44 WORKER: start processing job (9, 0, 2)
09:40:44 WORKER: args: ()
09:40:44 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 788, 'last_n_outputs': 46, 'leak_rate': 0.9504192610379346, 'lr': 0.011885731269104822, 'optimizer': 'SGD', 'sparsity': 0.8996165206354303, 'steps_to_train': 82, 'weight_decay': 0.010016629493390829}, 'budget': 400.0, 'working_directory': '.'}
09:41:41 DISPATCHER: Starting worker discovery
09:41:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:41:41 DISPATCHER: Finished worker discovery
09:42:41 DISPATCHER: Starting worker discovery
09:42:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:42:41 DISPATCHER: Finished worker discovery
09:43:41 DISPATCHER: Starting worker discovery
09:43:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:43:41 DISPATCHER: Finished worker discovery
09:44:41 DISPATCHER: Starting worker discovery
09:44:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:44:41 DISPATCHER: Finished worker discovery
09:45:41 DISPATCHER: Starting worker discovery
09:45:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:45:41 DISPATCHER: Finished worker discovery
09:46:41 DISPATCHER: Starting worker discovery
09:46:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:46:41 DISPATCHER: Finished worker discovery
09:47:41 DISPATCHER: Starting worker discovery
09:47:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:47:41 DISPATCHER: Finished worker discovery
09:48:27 WORKER: done with job (9, 0, 2), trying to register it.
09:48:27 WORKER: registered result for job (9, 0, 2) with dispatcher
09:48:27 DISPATCHER: job (9, 0, 2) finished
09:48:27 DISPATCHER: register_result: lock acquired
09:48:27 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
09:48:27 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 788, 'last_n_outputs': 46, 'leak_rate': 0.9504192610379346, 'lr': 0.011885731269104822, 'optimizer': 'SGD', 'sparsity': 0.8996165206354303, 'steps_to_train': 82, 'weight_decay': 0.010016629493390829}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3712206687689448, 'info': {'music_genre': 0.3712206687689448, 'config': "{'batch_size': 128, 'hidden_dim': 788, 'last_n_outputs': 46, 'leak_rate': 0.9504192610379346, 'lr': 0.011885731269104822, 'optimizer': 'SGD', 'sparsity': 0.8996165206354303, 'steps_to_train': 82, 'weight_decay': 0.010016629493390829}"}}
exception: None

09:48:27 job_callback for (9, 0, 2) started
09:48:27 DISPATCHER: Trying to submit another job.
09:48:27 job_callback for (9, 0, 2) got condition
09:48:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:48:27 done building a new model for budget 400.000000 based on 10/24 split
Best loss for this budget:-0.400060





09:48:27 HBMASTER: Trying to run another job!
09:48:27 job_callback for (9, 0, 2) finished
09:48:27 HBMASTER: schedule new run for iteration 9
09:48:27 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
09:48:27 HBMASTER: submitting job (9, 0, 4) to dispatcher
09:48:27 DISPATCHER: trying to submit job (9, 0, 4)
09:48:27 DISPATCHER: trying to notify the job_runner thread.
09:48:27 HBMASTER: job (9, 0, 4) submitted to dispatcher
09:48:27 DISPATCHER: Trying to submit another job.
09:48:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:48:27 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:48:27 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:48:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:48:27 WORKER: start processing job (9, 0, 4)
09:48:27 WORKER: args: ()
09:48:27 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 698, 'last_n_outputs': 37, 'leak_rate': 0.7703821026768634, 'lr': 0.01444181234595762, 'optimizer': 'SGD', 'sparsity': 0.8165088504669563, 'steps_to_train': 36, 'weight_decay': 0.018366041950493336}, 'budget': 400.0, 'working_directory': '.'}
09:48:41 DISPATCHER: Starting worker discovery
09:48:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:48:41 DISPATCHER: Finished worker discovery
09:49:41 DISPATCHER: Starting worker discovery
09:49:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:49:41 DISPATCHER: Finished worker discovery
09:50:41 DISPATCHER: Starting worker discovery
09:50:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:50:41 DISPATCHER: Finished worker discovery
09:51:41 DISPATCHER: Starting worker discovery
09:51:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:51:41 DISPATCHER: Finished worker discovery
09:52:41 DISPATCHER: Starting worker discovery
09:52:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:52:41 DISPATCHER: Finished worker discovery
09:53:41 DISPATCHER: Starting worker discovery
09:53:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:53:41 DISPATCHER: Finished worker discovery
09:54:41 DISPATCHER: Starting worker discovery
09:54:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:54:41 DISPATCHER: Finished worker discovery
09:55:41 DISPATCHER: Starting worker discovery
09:55:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:55:41 DISPATCHER: Finished worker discovery
09:56:05 WORKER: done with job (9, 0, 4), trying to register it.
09:56:05 WORKER: registered result for job (9, 0, 4) with dispatcher
09:56:05 DISPATCHER: job (9, 0, 4) finished
09:56:05 DISPATCHER: register_result: lock acquired
09:56:05 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
09:56:05 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 698, 'last_n_outputs': 37, 'leak_rate': 0.7703821026768634, 'lr': 0.01444181234595762, 'optimizer': 'SGD', 'sparsity': 0.8165088504669563, 'steps_to_train': 36, 'weight_decay': 0.018366041950493336}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.36796347640693355, 'info': {'music_genre': 0.36796347640693355, 'config': "{'batch_size': 128, 'hidden_dim': 698, 'last_n_outputs': 37, 'leak_rate': 0.7703821026768634, 'lr': 0.01444181234595762, 'optimizer': 'SGD', 'sparsity': 0.8165088504669563, 'steps_to_train': 36, 'weight_decay': 0.018366041950493336}"}}
exception: None

09:56:05 job_callback for (9, 0, 4) started
09:56:05 job_callback for (9, 0, 4) got condition
09:56:05 DISPATCHER: Trying to submit another job.
09:56:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:56:05 done building a new model for budget 400.000000 based on 10/25 split
Best loss for this budget:-0.400060





09:56:05 HBMASTER: Trying to run another job!
09:56:05 job_callback for (9, 0, 4) finished
09:56:05 ITERATION: Advancing config (9, 0, 2) to next budget 1200.000000
09:56:05 HBMASTER: schedule new run for iteration 9
09:56:05 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
09:56:05 HBMASTER: submitting job (9, 0, 2) to dispatcher
09:56:05 DISPATCHER: trying to submit job (9, 0, 2)
09:56:05 DISPATCHER: trying to notify the job_runner thread.
09:56:05 HBMASTER: job (9, 0, 2) submitted to dispatcher
09:56:05 DISPATCHER: Trying to submit another job.
09:56:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:56:05 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:56:05 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:56:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:56:05 WORKER: start processing job (9, 0, 2)
09:56:05 WORKER: args: ()
09:56:05 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 788, 'last_n_outputs': 46, 'leak_rate': 0.9504192610379346, 'lr': 0.011885731269104822, 'optimizer': 'SGD', 'sparsity': 0.8996165206354303, 'steps_to_train': 82, 'weight_decay': 0.010016629493390829}, 'budget': 1200.0, 'working_directory': '.'}
09:56:41 DISPATCHER: Starting worker discovery
09:56:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:56:41 DISPATCHER: Finished worker discovery
09:57:41 DISPATCHER: Starting worker discovery
09:57:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:57:41 DISPATCHER: Finished worker discovery
09:58:41 DISPATCHER: Starting worker discovery
09:58:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:58:41 DISPATCHER: Finished worker discovery
09:59:41 DISPATCHER: Starting worker discovery
09:59:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:59:41 DISPATCHER: Finished worker discovery
10:00:41 DISPATCHER: Starting worker discovery
10:00:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:00:41 DISPATCHER: Finished worker discovery
10:01:41 DISPATCHER: Starting worker discovery
10:01:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:01:41 DISPATCHER: Finished worker discovery
10:02:41 DISPATCHER: Starting worker discovery
10:02:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:02:41 DISPATCHER: Finished worker discovery
10:03:41 DISPATCHER: Starting worker discovery
10:03:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:03:41 DISPATCHER: Finished worker discovery
10:04:41 DISPATCHER: Starting worker discovery
10:04:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:04:41 DISPATCHER: Finished worker discovery
10:05:41 DISPATCHER: Starting worker discovery
10:05:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:05:41 DISPATCHER: Finished worker discovery
10:06:41 DISPATCHER: Starting worker discovery
10:06:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:06:41 DISPATCHER: Finished worker discovery
10:07:41 DISPATCHER: Starting worker discovery
10:07:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:07:41 DISPATCHER: Finished worker discovery
10:08:41 DISPATCHER: Starting worker discovery
10:08:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:08:41 DISPATCHER: Finished worker discovery
10:09:41 DISPATCHER: Starting worker discovery
10:09:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:09:41 DISPATCHER: Finished worker discovery
10:10:41 DISPATCHER: Starting worker discovery
10:10:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:10:41 DISPATCHER: Finished worker discovery
10:11:41 DISPATCHER: Starting worker discovery
10:11:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:11:41 DISPATCHER: Finished worker discovery
10:12:41 DISPATCHER: Starting worker discovery
10:12:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:12:41 DISPATCHER: Finished worker discovery
10:13:41 DISPATCHER: Starting worker discovery
10:13:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:13:41 DISPATCHER: Finished worker discovery
10:14:41 DISPATCHER: Starting worker discovery
10:14:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:14:41 DISPATCHER: Finished worker discovery
10:15:41 DISPATCHER: Starting worker discovery
10:15:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:15:41 DISPATCHER: Finished worker discovery
10:16:41 DISPATCHER: Starting worker discovery
10:16:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:16:41 DISPATCHER: Finished worker discovery
10:17:14 WORKER: done with job (9, 0, 2), trying to register it.
10:17:14 WORKER: registered result for job (9, 0, 2) with dispatcher
10:17:14 DISPATCHER: job (9, 0, 2) finished
10:17:14 DISPATCHER: register_result: lock acquired
10:17:14 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
10:17:14 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 788, 'last_n_outputs': 46, 'leak_rate': 0.9504192610379346, 'lr': 0.011885731269104822, 'optimizer': 'SGD', 'sparsity': 0.8996165206354303, 'steps_to_train': 82, 'weight_decay': 0.010016629493390829}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.3893390683469642, 'info': {'music_genre': 0.3893390683469642, 'config': "{'batch_size': 128, 'hidden_dim': 788, 'last_n_outputs': 46, 'leak_rate': 0.9504192610379346, 'lr': 0.011885731269104822, 'optimizer': 'SGD', 'sparsity': 0.8996165206354303, 'steps_to_train': 82, 'weight_decay': 0.010016629493390829}"}}
exception: None

10:17:14 job_callback for (9, 0, 2) started
10:17:14 DISPATCHER: Trying to submit another job.
10:17:14 job_callback for (9, 0, 2) got condition
10:17:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:17:14 HBMASTER: Trying to run another job!
10:17:14 job_callback for (9, 0, 2) finished
10:17:14 HBMASTER: shutdown initiated, shutdown_workers = True
10:17:14 WORKER: shutting down now!
10:17:15 DISPATCHER: Dispatcher shutting down
10:17:15 DISPATCHER: Trying to submit another job.
10:17:15 DISPATCHER: job_runner shutting down
10:17:15 DISPATCHER: discover_workers shutting down
10:17:15 DISPATCHER: 'discover_worker' thread exited
10:17:15 DISPATCHER: 'job_runner' thread exited
10:17:15 DISPATCHER: shut down complete
10:17:15 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7fac6c057cf8; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:39783>
10:17:15 WORKER: No dispatcher found. Waiting for one to initiate contact.
10:17:15 WORKER: start listening for jobs
10:17:15 wait_for_workers trying to get the condition
10:17:15 DISPATCHER: started the 'discover_worker' thread
10:17:15 DISPATCHER: started the 'job_runner' thread
10:17:15 DISPATCHER: Pyro daemon running on localhost:38963
10:17:15 DISPATCHER: Starting worker discovery
10:17:15 DISPATCHER: Found 1 potential workers, 0 currently in the pool.
10:17:15 DISPATCHER: discovered new worker, hpbandster.run_0.worker.metagpuj.30597140382006277952
10:17:15 HBMASTER: number of workers changed to 1
10:17:15 Enough workers to start this run!
10:17:15 adjust_queue_size: lock accquired
10:17:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:17:15 HBMASTER: starting run at 1583831835.3400667
10:17:15 HBMASTER: adjusted queue size to (0, 1)
10:17:15 DISPATCHER: Finished worker discovery
10:17:15 start sampling a new configuration.
10:17:15 DISPATCHER: Trying to submit another job.
10:17:15 done sampling a new configuration.
10:17:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:17:15 HBMASTER: schedule new run for iteration 0
10:17:15 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
10:17:15 HBMASTER: submitting job (0, 0, 0) to dispatcher
10:17:15 DISPATCHER: trying to submit job (0, 0, 0)
10:17:15 DISPATCHER: trying to notify the job_runner thread.
10:17:15 HBMASTER: job (0, 0, 0) submitted to dispatcher
10:17:15 DISPATCHER: Trying to submit another job.
10:17:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:17:15 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:17:15 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:17:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:17:15 WORKER: start processing job (0, 0, 0)
10:17:15 WORKER: args: ()
10:17:15 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0036990212515202498, 'num_filters_1': 29, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.021744818966596073, 'kernel_size_2': 5, 'num_filters_2': 34}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:18:15 DISPATCHER: Starting worker discovery
10:18:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:18:15 DISPATCHER: Finished worker discovery
10:18:58 WORKER: done with job (0, 0, 0), trying to register it.
10:18:58 WORKER: registered result for job (0, 0, 0) with dispatcher
10:18:58 DISPATCHER: job (0, 0, 0) finished
10:18:58 DISPATCHER: register_result: lock acquired
10:18:58 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
10:18:58 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0036990212515202498, 'num_filters_1': 29, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.021744818966596073, 'kernel_size_2': 5, 'num_filters_2': 34}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.437776089981671, 'info': {'music_genre': 0.437776089981671, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0036990212515202498, 'num_filters_1': 29, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.021744818966596073, 'kernel_size_2': 5, 'num_filters_2': 34}"}}
exception: None

10:18:58 job_callback for (0, 0, 0) started
10:18:58 DISPATCHER: Trying to submit another job.
10:18:58 job_callback for (0, 0, 0) got condition
10:18:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:18:58 Only 1 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:18:58 HBMASTER: Trying to run another job!
10:18:58 job_callback for (0, 0, 0) finished
10:18:58 start sampling a new configuration.
10:18:58 done sampling a new configuration.
10:18:58 HBMASTER: schedule new run for iteration 0
10:18:58 HBMASTER: trying submitting job (0, 0, 1) to dispatcher
10:18:58 HBMASTER: submitting job (0, 0, 1) to dispatcher
10:18:58 DISPATCHER: trying to submit job (0, 0, 1)
10:18:58 DISPATCHER: trying to notify the job_runner thread.
10:18:58 HBMASTER: job (0, 0, 1) submitted to dispatcher
10:18:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:18:58 DISPATCHER: Trying to submit another job.
10:18:58 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:18:58 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:18:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:18:58 WORKER: start processing job (0, 0, 1)
10:18:58 WORKER: args: ()
10:18:58 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.020290078894847473, 'num_filters_1': 106, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.07606525795182603}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:19:15 DISPATCHER: Starting worker discovery
10:19:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:19:15 DISPATCHER: Finished worker discovery
10:20:15 DISPATCHER: Starting worker discovery
10:20:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:20:15 DISPATCHER: Finished worker discovery
10:20:41 WORKER: done with job (0, 0, 1), trying to register it.
10:20:41 WORKER: registered result for job (0, 0, 1) with dispatcher
10:20:41 DISPATCHER: job (0, 0, 1) finished
10:20:41 DISPATCHER: register_result: lock acquired
10:20:41 DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
10:20:41 job_id: (0, 0, 1)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.020290078894847473, 'num_filters_1': 106, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.07606525795182603}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.009779114574163729, 'info': {'music_genre': 0.009779114574163729, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.020290078894847473, 'num_filters_1': 106, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.07606525795182603}"}}
exception: None

10:20:41 job_callback for (0, 0, 1) started
10:20:41 DISPATCHER: Trying to submit another job.
10:20:41 job_callback for (0, 0, 1) got condition
10:20:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:20:41 Only 2 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:20:41 HBMASTER: Trying to run another job!
10:20:41 job_callback for (0, 0, 1) finished
10:20:41 start sampling a new configuration.
10:20:41 done sampling a new configuration.
10:20:41 HBMASTER: schedule new run for iteration 0
10:20:41 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
10:20:41 HBMASTER: submitting job (0, 0, 2) to dispatcher
10:20:41 DISPATCHER: trying to submit job (0, 0, 2)
10:20:41 DISPATCHER: trying to notify the job_runner thread.
10:20:41 HBMASTER: job (0, 0, 2) submitted to dispatcher
10:20:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:20:41 DISPATCHER: Trying to submit another job.
10:20:41 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:20:41 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:20:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:20:41 WORKER: start processing job (0, 0, 2)
10:20:41 WORKER: args: ()
10:20:41 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0657647939641454, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.07668859800723184, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 67, 'num_filters_3': 30, 'num_filters_4': 70, 'num_filters_5': 66}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:21:15 DISPATCHER: Starting worker discovery
10:21:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:21:15 DISPATCHER: Finished worker discovery
10:22:15 DISPATCHER: Starting worker discovery
10:22:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:22:15 DISPATCHER: Finished worker discovery
10:22:22 WORKER: done with job (0, 0, 2), trying to register it.
10:22:22 WORKER: registered result for job (0, 0, 2) with dispatcher
10:22:22 DISPATCHER: job (0, 0, 2) finished
10:22:22 DISPATCHER: register_result: lock acquired
10:22:22 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
10:22:22 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0657647939641454, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.07668859800723184, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 67, 'num_filters_3': 30, 'num_filters_4': 70, 'num_filters_5': 66}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.13153959206795235, 'info': {'music_genre': 0.13153959206795235, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0657647939641454, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.07668859800723184, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 67, 'num_filters_3': 30, 'num_filters_4': 70, 'num_filters_5': 66}"}}
exception: None

10:22:22 job_callback for (0, 0, 2) started
10:22:22 job_callback for (0, 0, 2) got condition
10:22:22 DISPATCHER: Trying to submit another job.
10:22:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:22:22 Only 3 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:22:22 HBMASTER: Trying to run another job!
10:22:22 job_callback for (0, 0, 2) finished
10:22:22 start sampling a new configuration.
10:22:22 done sampling a new configuration.
10:22:22 HBMASTER: schedule new run for iteration 0
10:22:22 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
10:22:22 HBMASTER: submitting job (0, 0, 3) to dispatcher
10:22:22 DISPATCHER: trying to submit job (0, 0, 3)
10:22:22 DISPATCHER: trying to notify the job_runner thread.
10:22:22 HBMASTER: job (0, 0, 3) submitted to dispatcher
10:22:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:22:22 DISPATCHER: Trying to submit another job.
10:22:22 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:22:22 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:22:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:22:22 WORKER: start processing job (0, 0, 3)
10:22:22 WORKER: args: ()
10:22:22 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.00878137373544829, 'num_filters_1': 109, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.025602840292473072, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 104, 'num_filters_3': 63}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:23:15 DISPATCHER: Starting worker discovery
10:23:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:23:15 DISPATCHER: Finished worker discovery
10:24:01 WORKER: done with job (0, 0, 3), trying to register it.
10:24:01 WORKER: registered result for job (0, 0, 3) with dispatcher
10:24:01 DISPATCHER: job (0, 0, 3) finished
10:24:01 DISPATCHER: register_result: lock acquired
10:24:01 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
10:24:01 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.00878137373544829, 'num_filters_1': 109, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.025602840292473072, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 104, 'num_filters_3': 63}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5499645315414474, 'info': {'music_genre': 0.5499645315414474, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.00878137373544829, 'num_filters_1': 109, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.025602840292473072, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 104, 'num_filters_3': 63}"}}
exception: None

10:24:01 job_callback for (0, 0, 3) started
10:24:01 DISPATCHER: Trying to submit another job.
10:24:01 job_callback for (0, 0, 3) got condition
10:24:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:24:01 Only 4 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:24:01 HBMASTER: Trying to run another job!
10:24:01 job_callback for (0, 0, 3) finished
10:24:01 start sampling a new configuration.
10:24:01 done sampling a new configuration.
10:24:01 HBMASTER: schedule new run for iteration 0
10:24:01 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
10:24:01 HBMASTER: submitting job (0, 0, 4) to dispatcher
10:24:01 DISPATCHER: trying to submit job (0, 0, 4)
10:24:01 DISPATCHER: trying to notify the job_runner thread.
10:24:01 HBMASTER: job (0, 0, 4) submitted to dispatcher
10:24:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:24:01 DISPATCHER: Trying to submit another job.
10:24:01 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:24:01 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:24:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:24:01 WORKER: start processing job (0, 0, 4)
10:24:01 WORKER: args: ()
10:24:01 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0011111387842547762, 'num_filters_1': 66, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.09211635963001724, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 23, 'num_filters_3': 20, 'num_filters_4': 61, 'num_filters_5': 115}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:24:15 DISPATCHER: Starting worker discovery
10:24:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:24:15 DISPATCHER: Finished worker discovery
10:25:15 DISPATCHER: Starting worker discovery
10:25:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:25:15 DISPATCHER: Finished worker discovery
10:25:41 WORKER: done with job (0, 0, 4), trying to register it.
10:25:41 WORKER: registered result for job (0, 0, 4) with dispatcher
10:25:41 DISPATCHER: job (0, 0, 4) finished
10:25:41 DISPATCHER: register_result: lock acquired
10:25:41 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
10:25:41 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0011111387842547762, 'num_filters_1': 66, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.09211635963001724, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 23, 'num_filters_3': 20, 'num_filters_4': 61, 'num_filters_5': 115}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.35717714283405094, 'info': {'music_genre': 0.35717714283405094, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0011111387842547762, 'num_filters_1': 66, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.09211635963001724, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 23, 'num_filters_3': 20, 'num_filters_4': 61, 'num_filters_5': 115}"}}
exception: None

10:25:41 job_callback for (0, 0, 4) started
10:25:41 DISPATCHER: Trying to submit another job.
10:25:41 job_callback for (0, 0, 4) got condition
10:25:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:25:41 Only 5 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:25:41 HBMASTER: Trying to run another job!
10:25:41 job_callback for (0, 0, 4) finished
10:25:41 start sampling a new configuration.
10:25:41 done sampling a new configuration.
10:25:41 HBMASTER: schedule new run for iteration 0
10:25:41 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
10:25:41 HBMASTER: submitting job (0, 0, 5) to dispatcher
10:25:41 DISPATCHER: trying to submit job (0, 0, 5)
10:25:41 DISPATCHER: trying to notify the job_runner thread.
10:25:41 HBMASTER: job (0, 0, 5) submitted to dispatcher
10:25:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:25:41 DISPATCHER: Trying to submit another job.
10:25:41 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:25:41 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:25:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:25:41 WORKER: start processing job (0, 0, 5)
10:25:41 WORKER: args: ()
10:25:41 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001602103823566725, 'num_filters_1': 94, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.019605365181046216, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 34, 'num_filters_3': 65, 'num_filters_4': 74}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:26:15 DISPATCHER: Starting worker discovery
10:26:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:26:15 DISPATCHER: Finished worker discovery
10:27:15 DISPATCHER: Starting worker discovery
10:27:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:27:15 DISPATCHER: Finished worker discovery
10:27:19 WORKER: done with job (0, 0, 5), trying to register it.
10:27:19 WORKER: registered result for job (0, 0, 5) with dispatcher
10:27:19 DISPATCHER: job (0, 0, 5) finished
10:27:19 DISPATCHER: register_result: lock acquired
10:27:19 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
10:27:19 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001602103823566725, 'num_filters_1': 94, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.019605365181046216, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 34, 'num_filters_3': 65, 'num_filters_4': 74}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4651691607886026, 'info': {'music_genre': 0.4651691607886026, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001602103823566725, 'num_filters_1': 94, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.019605365181046216, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 34, 'num_filters_3': 65, 'num_filters_4': 74}"}}
exception: None

10:27:19 job_callback for (0, 0, 5) started
10:27:19 DISPATCHER: Trying to submit another job.
10:27:19 job_callback for (0, 0, 5) got condition
10:27:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:27:19 Only 6 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:27:19 HBMASTER: Trying to run another job!
10:27:19 job_callback for (0, 0, 5) finished
10:27:19 start sampling a new configuration.
10:27:19 done sampling a new configuration.
10:27:19 HBMASTER: schedule new run for iteration 0
10:27:19 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
10:27:19 HBMASTER: submitting job (0, 0, 6) to dispatcher
10:27:19 DISPATCHER: trying to submit job (0, 0, 6)
10:27:19 DISPATCHER: trying to notify the job_runner thread.
10:27:19 HBMASTER: job (0, 0, 6) submitted to dispatcher
10:27:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:27:19 DISPATCHER: Trying to submit another job.
10:27:19 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:27:19 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:27:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:27:19 WORKER: start processing job (0, 0, 6)
10:27:19 WORKER: args: ()
10:27:19 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.007437759227072326, 'num_filters_1': 45, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.06666464514113461, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 53, 'num_filters_3': 65, 'num_filters_4': 29}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:28:15 DISPATCHER: Starting worker discovery
10:28:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:28:15 DISPATCHER: Finished worker discovery
10:29:00 WORKER: done with job (0, 0, 6), trying to register it.
10:29:00 WORKER: registered result for job (0, 0, 6) with dispatcher
10:29:00 DISPATCHER: job (0, 0, 6) finished
10:29:00 DISPATCHER: register_result: lock acquired
10:29:00 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
10:29:00 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.007437759227072326, 'num_filters_1': 45, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.06666464514113461, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 53, 'num_filters_3': 65, 'num_filters_4': 29}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 6.261581986131862e-08, 'info': {'music_genre': -6.261581986131862e-08, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.007437759227072326, 'num_filters_1': 45, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.06666464514113461, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 53, 'num_filters_3': 65, 'num_filters_4': 29}"}}
exception: None

10:29:00 job_callback for (0, 0, 6) started
10:29:00 DISPATCHER: Trying to submit another job.
10:29:00 job_callback for (0, 0, 6) got condition
10:29:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:29:00 Only 7 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:29:00 HBMASTER: Trying to run another job!
10:29:00 job_callback for (0, 0, 6) finished
10:29:00 start sampling a new configuration.
10:29:00 done sampling a new configuration.
10:29:00 HBMASTER: schedule new run for iteration 0
10:29:00 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
10:29:00 HBMASTER: submitting job (0, 0, 7) to dispatcher
10:29:00 DISPATCHER: trying to submit job (0, 0, 7)
10:29:00 DISPATCHER: trying to notify the job_runner thread.
10:29:00 HBMASTER: job (0, 0, 7) submitted to dispatcher
10:29:00 DISPATCHER: Trying to submit another job.
10:29:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:29:00 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:29:00 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:29:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:29:00 WORKER: start processing job (0, 0, 7)
10:29:00 WORKER: args: ()
10:29:00 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001477146718560773, 'num_filters_1': 108, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.08587742495735039, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 20, 'num_filters_3': 28, 'num_filters_4': 53}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:29:15 DISPATCHER: Starting worker discovery
10:29:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:29:15 DISPATCHER: Finished worker discovery
10:30:15 DISPATCHER: Starting worker discovery
10:30:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:30:15 DISPATCHER: Finished worker discovery
10:30:39 WORKER: done with job (0, 0, 7), trying to register it.
10:30:39 WORKER: registered result for job (0, 0, 7) with dispatcher
10:30:39 DISPATCHER: job (0, 0, 7) finished
10:30:39 DISPATCHER: register_result: lock acquired
10:30:39 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
10:30:39 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001477146718560773, 'num_filters_1': 108, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.08587742495735039, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 20, 'num_filters_3': 28, 'num_filters_4': 53}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.10209978570060102, 'info': {'music_genre': 0.10209978570060102, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001477146718560773, 'num_filters_1': 108, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.08587742495735039, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 20, 'num_filters_3': 28, 'num_filters_4': 53}"}}
exception: None

10:30:39 job_callback for (0, 0, 7) started
10:30:39 DISPATCHER: Trying to submit another job.
10:30:39 job_callback for (0, 0, 7) got condition
10:30:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:30:39 Only 8 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:30:39 HBMASTER: Trying to run another job!
10:30:39 job_callback for (0, 0, 7) finished
10:30:39 start sampling a new configuration.
10:30:39 done sampling a new configuration.
10:30:39 HBMASTER: schedule new run for iteration 0
10:30:39 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
10:30:39 HBMASTER: submitting job (0, 0, 8) to dispatcher
10:30:39 DISPATCHER: trying to submit job (0, 0, 8)
10:30:39 DISPATCHER: trying to notify the job_runner thread.
10:30:39 HBMASTER: job (0, 0, 8) submitted to dispatcher
10:30:39 DISPATCHER: Trying to submit another job.
10:30:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:30:39 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:30:39 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:30:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:30:39 WORKER: start processing job (0, 0, 8)
10:30:39 WORKER: args: ()
10:30:39 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.003280106792977438, 'num_filters_1': 24, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.028466173269302085, 'kernel_size_2': 5, 'num_filters_2': 22}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:31:15 DISPATCHER: Starting worker discovery
10:31:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:31:15 DISPATCHER: Finished worker discovery
10:32:15 DISPATCHER: Starting worker discovery
10:32:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:32:15 DISPATCHER: Finished worker discovery
10:32:18 WORKER: done with job (0, 0, 8), trying to register it.
10:32:18 WORKER: registered result for job (0, 0, 8) with dispatcher
10:32:18 DISPATCHER: job (0, 0, 8) finished
10:32:18 DISPATCHER: register_result: lock acquired
10:32:18 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
10:32:18 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.003280106792977438, 'num_filters_1': 24, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.028466173269302085, 'kernel_size_2': 5, 'num_filters_2': 22}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.44668235659998945, 'info': {'music_genre': 0.44668235659998945, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.003280106792977438, 'num_filters_1': 24, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.028466173269302085, 'kernel_size_2': 5, 'num_filters_2': 22}"}}
exception: None

10:32:18 DISPATCHER: Trying to submit another job.
10:32:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:32:18 job_callback for (0, 0, 8) started
10:32:18 job_callback for (0, 0, 8) got condition
10:32:18 Only 9 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:32:18 HBMASTER: Trying to run another job!
10:32:18 job_callback for (0, 0, 8) finished
10:32:18 start sampling a new configuration.
10:32:18 done sampling a new configuration.
10:32:18 HBMASTER: schedule new run for iteration 0
10:32:18 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
10:32:18 HBMASTER: submitting job (0, 0, 9) to dispatcher
10:32:18 DISPATCHER: trying to submit job (0, 0, 9)
10:32:18 DISPATCHER: trying to notify the job_runner thread.
10:32:18 HBMASTER: job (0, 0, 9) submitted to dispatcher
10:32:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:32:18 DISPATCHER: Trying to submit another job.
10:32:18 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:32:18 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:32:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:32:18 WORKER: start processing job (0, 0, 9)
10:32:18 WORKER: args: ()
10:32:18 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.009063100394266329, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.03090961250845323, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 127, 'num_filters_3': 78, 'num_filters_4': 35, 'num_filters_5': 58}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:33:15 DISPATCHER: Starting worker discovery
10:33:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:33:15 DISPATCHER: Finished worker discovery
10:33:58 WORKER: done with job (0, 0, 9), trying to register it.
10:33:58 WORKER: registered result for job (0, 0, 9) with dispatcher
10:33:58 DISPATCHER: job (0, 0, 9) finished
10:33:58 DISPATCHER: register_result: lock acquired
10:33:58 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
10:33:58 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.009063100394266329, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.03090961250845323, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 127, 'num_filters_3': 78, 'num_filters_4': 35, 'num_filters_5': 58}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.43122707286153256, 'info': {'music_genre': 0.43122707286153256, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.009063100394266329, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.03090961250845323, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 127, 'num_filters_3': 78, 'num_filters_4': 35, 'num_filters_5': 58}"}}
exception: None

10:33:58 job_callback for (0, 0, 9) started
10:33:58 DISPATCHER: Trying to submit another job.
10:33:58 job_callback for (0, 0, 9) got condition
10:33:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:33:58 Only 10 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:33:58 HBMASTER: Trying to run another job!
10:33:58 job_callback for (0, 0, 9) finished
10:33:58 start sampling a new configuration.
10:33:58 done sampling a new configuration.
10:33:58 HBMASTER: schedule new run for iteration 0
10:33:58 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
10:33:58 HBMASTER: submitting job (0, 0, 10) to dispatcher
10:33:58 DISPATCHER: trying to submit job (0, 0, 10)
10:33:58 DISPATCHER: trying to notify the job_runner thread.
10:33:58 HBMASTER: job (0, 0, 10) submitted to dispatcher
10:33:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:33:58 DISPATCHER: Trying to submit another job.
10:33:58 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:33:58 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:33:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:33:58 WORKER: start processing job (0, 0, 10)
10:33:58 WORKER: args: ()
10:33:58 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003695625323980962, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.01071228099643476, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 19, 'num_filters_3': 79, 'num_filters_4': 100}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:34:15 DISPATCHER: Starting worker discovery
10:34:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:34:15 DISPATCHER: Finished worker discovery
10:35:15 DISPATCHER: Starting worker discovery
10:35:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:35:15 DISPATCHER: Finished worker discovery
10:35:39 WORKER: done with job (0, 0, 10), trying to register it.
10:35:39 WORKER: registered result for job (0, 0, 10) with dispatcher
10:35:39 DISPATCHER: job (0, 0, 10) finished
10:35:39 DISPATCHER: register_result: lock acquired
10:35:39 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
10:35:39 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003695625323980962, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.01071228099643476, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 19, 'num_filters_3': 79, 'num_filters_4': 100}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.45435357601701376, 'info': {'music_genre': 0.45435357601701376, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003695625323980962, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.01071228099643476, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 19, 'num_filters_3': 79, 'num_filters_4': 100}"}}
exception: None

10:35:39 job_callback for (0, 0, 10) started
10:35:39 job_callback for (0, 0, 10) got condition
10:35:39 DISPATCHER: Trying to submit another job.
10:35:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:35:39 Only 11 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:35:39 HBMASTER: Trying to run another job!
10:35:39 job_callback for (0, 0, 10) finished
10:35:39 start sampling a new configuration.
10:35:39 done sampling a new configuration.
10:35:39 HBMASTER: schedule new run for iteration 0
10:35:39 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
10:35:39 HBMASTER: submitting job (0, 0, 11) to dispatcher
10:35:39 DISPATCHER: trying to submit job (0, 0, 11)
10:35:39 DISPATCHER: trying to notify the job_runner thread.
10:35:39 HBMASTER: job (0, 0, 11) submitted to dispatcher
10:35:39 DISPATCHER: Trying to submit another job.
10:35:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:35:39 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:35:39 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:35:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:35:39 WORKER: start processing job (0, 0, 11)
10:35:39 WORKER: args: ()
10:35:39 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.012988902692184901, 'num_filters_1': 35, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.05251538903318694, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 71, 'num_filters_3': 59}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:36:15 DISPATCHER: Starting worker discovery
10:36:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:36:15 DISPATCHER: Finished worker discovery
10:37:15 DISPATCHER: Starting worker discovery
10:37:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:37:15 DISPATCHER: Finished worker discovery
10:37:18 WORKER: done with job (0, 0, 11), trying to register it.
10:37:18 WORKER: registered result for job (0, 0, 11) with dispatcher
10:37:18 DISPATCHER: job (0, 0, 11) finished
10:37:18 DISPATCHER: register_result: lock acquired
10:37:18 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
10:37:18 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.012988902692184901, 'num_filters_1': 35, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.05251538903318694, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 71, 'num_filters_3': 59}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0002567013994028565, 'info': {'music_genre': 0.0002567013994028565, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.012988902692184901, 'num_filters_1': 35, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.05251538903318694, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 71, 'num_filters_3': 59}"}}
exception: None

10:37:18 job_callback for (0, 0, 11) started
10:37:18 DISPATCHER: Trying to submit another job.
10:37:18 job_callback for (0, 0, 11) got condition
10:37:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:37:18 Only 12 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:37:18 HBMASTER: Trying to run another job!
10:37:18 job_callback for (0, 0, 11) finished
10:37:18 start sampling a new configuration.
10:37:18 done sampling a new configuration.
10:37:18 HBMASTER: schedule new run for iteration 0
10:37:18 HBMASTER: trying submitting job (0, 0, 12) to dispatcher
10:37:18 HBMASTER: submitting job (0, 0, 12) to dispatcher
10:37:18 DISPATCHER: trying to submit job (0, 0, 12)
10:37:18 DISPATCHER: trying to notify the job_runner thread.
10:37:18 HBMASTER: job (0, 0, 12) submitted to dispatcher
10:37:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:37:18 DISPATCHER: Trying to submit another job.
10:37:18 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:37:18 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:37:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:37:18 WORKER: start processing job (0, 0, 12)
10:37:18 WORKER: args: ()
10:37:18 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002804747529868057, 'num_filters_1': 23, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.04873196898663878, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 31, 'num_filters_3': 57}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:38:15 DISPATCHER: Starting worker discovery
10:38:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:38:15 DISPATCHER: Finished worker discovery
10:38:58 WORKER: done with job (0, 0, 12), trying to register it.
10:38:58 WORKER: registered result for job (0, 0, 12) with dispatcher
10:38:58 DISPATCHER: job (0, 0, 12) finished
10:38:58 DISPATCHER: register_result: lock acquired
10:38:58 DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
10:38:58 job_id: (0, 0, 12)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002804747529868057, 'num_filters_1': 23, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.04873196898663878, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 31, 'num_filters_3': 57}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.13965606736582464, 'info': {'music_genre': 0.13965606736582464, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002804747529868057, 'num_filters_1': 23, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.04873196898663878, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 31, 'num_filters_3': 57}"}}
exception: None

10:38:58 job_callback for (0, 0, 12) started
10:38:58 DISPATCHER: Trying to submit another job.
10:38:58 job_callback for (0, 0, 12) got condition
10:38:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:38:58 Only 13 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:38:58 HBMASTER: Trying to run another job!
10:38:58 job_callback for (0, 0, 12) finished
10:38:58 start sampling a new configuration.
10:38:58 done sampling a new configuration.
10:38:58 HBMASTER: schedule new run for iteration 0
10:38:58 HBMASTER: trying submitting job (0, 0, 13) to dispatcher
10:38:58 HBMASTER: submitting job (0, 0, 13) to dispatcher
10:38:58 DISPATCHER: trying to submit job (0, 0, 13)
10:38:58 DISPATCHER: trying to notify the job_runner thread.
10:38:58 HBMASTER: job (0, 0, 13) submitted to dispatcher
10:38:58 DISPATCHER: Trying to submit another job.
10:38:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:38:58 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:38:58 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:38:58 WORKER: start processing job (0, 0, 13)
10:38:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:38:58 WORKER: args: ()
10:38:58 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0021276491086069187, 'num_filters_1': 54, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.010153332517086468}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:39:15 DISPATCHER: Starting worker discovery
10:39:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:39:15 DISPATCHER: Finished worker discovery
10:40:15 DISPATCHER: Starting worker discovery
10:40:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:40:15 DISPATCHER: Finished worker discovery
10:40:38 WORKER: done with job (0, 0, 13), trying to register it.
10:40:38 WORKER: registered result for job (0, 0, 13) with dispatcher
10:40:38 DISPATCHER: job (0, 0, 13) finished
10:40:38 DISPATCHER: register_result: lock acquired
10:40:38 DISPATCHER: job (0, 0, 13) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
10:40:38 job_id: (0, 0, 13)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0021276491086069187, 'num_filters_1': 54, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.010153332517086468}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2944195203494955, 'info': {'music_genre': 0.2944195203494955, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0021276491086069187, 'num_filters_1': 54, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.010153332517086468}"}}
exception: None

10:40:38 job_callback for (0, 0, 13) started
10:40:38 job_callback for (0, 0, 13) got condition
10:40:38 DISPATCHER: Trying to submit another job.
10:40:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:40:38 Only 14 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:40:38 HBMASTER: Trying to run another job!
10:40:38 job_callback for (0, 0, 13) finished
10:40:38 start sampling a new configuration.
10:40:38 done sampling a new configuration.
10:40:38 HBMASTER: schedule new run for iteration 0
10:40:38 HBMASTER: trying submitting job (0, 0, 14) to dispatcher
10:40:38 HBMASTER: submitting job (0, 0, 14) to dispatcher
10:40:38 DISPATCHER: trying to submit job (0, 0, 14)
10:40:38 DISPATCHER: trying to notify the job_runner thread.
10:40:38 HBMASTER: job (0, 0, 14) submitted to dispatcher
10:40:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:40:38 DISPATCHER: Trying to submit another job.
10:40:38 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:40:38 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:40:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:40:38 WORKER: start processing job (0, 0, 14)
10:40:38 WORKER: args: ()
10:40:38 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.045566545503866636, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.048148108162976704}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:41:15 DISPATCHER: Starting worker discovery
10:41:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:41:15 DISPATCHER: Finished worker discovery
10:42:15 DISPATCHER: Starting worker discovery
10:42:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:42:15 DISPATCHER: Finished worker discovery
10:42:17 WORKER: done with job (0, 0, 14), trying to register it.
10:42:17 WORKER: registered result for job (0, 0, 14) with dispatcher
10:42:18 DISPATCHER: job (0, 0, 14) finished
10:42:18 DISPATCHER: register_result: lock acquired
10:42:18 DISPATCHER: job (0, 0, 14) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
10:42:18 job_id: (0, 0, 14)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.045566545503866636, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.048148108162976704}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2674065205906296, 'info': {'music_genre': 0.2674065205906296, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.045566545503866636, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.048148108162976704}"}}
exception: None

10:42:18 job_callback for (0, 0, 14) started
10:42:18 job_callback for (0, 0, 14) got condition
10:42:18 DISPATCHER: Trying to submit another job.
10:42:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:42:18 Only 15 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:42:18 HBMASTER: Trying to run another job!
10:42:18 job_callback for (0, 0, 14) finished
10:42:18 start sampling a new configuration.
10:42:18 done sampling a new configuration.
10:42:18 HBMASTER: schedule new run for iteration 0
10:42:18 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
10:42:18 HBMASTER: submitting job (0, 0, 15) to dispatcher
10:42:18 DISPATCHER: trying to submit job (0, 0, 15)
10:42:18 DISPATCHER: trying to notify the job_runner thread.
10:42:18 HBMASTER: job (0, 0, 15) submitted to dispatcher
10:42:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:42:18 DISPATCHER: Trying to submit another job.
10:42:18 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:42:18 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:42:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:42:18 WORKER: start processing job (0, 0, 15)
10:42:18 WORKER: args: ()
10:42:18 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.02183920671512108, 'num_filters_1': 26, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.017192458767431678, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 99, 'num_filters_3': 76, 'num_filters_4': 35}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:43:15 DISPATCHER: Starting worker discovery
10:43:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:43:15 DISPATCHER: Finished worker discovery
10:43:56 WORKER: done with job (0, 0, 15), trying to register it.
10:43:56 WORKER: registered result for job (0, 0, 15) with dispatcher
10:43:56 DISPATCHER: job (0, 0, 15) finished
10:43:56 DISPATCHER: register_result: lock acquired
10:43:56 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
10:43:56 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.02183920671512108, 'num_filters_1': 26, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.017192458767431678, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 99, 'num_filters_3': 76, 'num_filters_4': 35}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.43384448074379134, 'info': {'music_genre': 0.43384448074379134, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.02183920671512108, 'num_filters_1': 26, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.017192458767431678, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 99, 'num_filters_3': 76, 'num_filters_4': 35}"}}
exception: None

10:43:56 job_callback for (0, 0, 15) started
10:43:56 DISPATCHER: Trying to submit another job.
10:43:56 job_callback for (0, 0, 15) got condition
10:43:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:43:56 Only 16 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:43:56 HBMASTER: Trying to run another job!
10:43:56 job_callback for (0, 0, 15) finished
10:43:56 start sampling a new configuration.
10:43:56 done sampling a new configuration.
10:43:56 HBMASTER: schedule new run for iteration 0
10:43:56 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
10:43:56 HBMASTER: submitting job (0, 0, 16) to dispatcher
10:43:56 DISPATCHER: trying to submit job (0, 0, 16)
10:43:56 DISPATCHER: trying to notify the job_runner thread.
10:43:56 HBMASTER: job (0, 0, 16) submitted to dispatcher
10:43:56 DISPATCHER: Trying to submit another job.
10:43:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:43:56 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:43:56 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:43:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:43:56 WORKER: start processing job (0, 0, 16)
10:43:56 WORKER: args: ()
10:43:56 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0017827214948644475, 'num_filters_1': 28, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.025579082540056593, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 35, 'num_filters_3': 40}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:44:15 DISPATCHER: Starting worker discovery
10:44:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:44:15 DISPATCHER: Finished worker discovery
10:45:15 DISPATCHER: Starting worker discovery
10:45:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:45:15 DISPATCHER: Finished worker discovery
10:45:36 WORKER: done with job (0, 0, 16), trying to register it.
10:45:36 WORKER: registered result for job (0, 0, 16) with dispatcher
10:45:36 DISPATCHER: job (0, 0, 16) finished
10:45:36 DISPATCHER: register_result: lock acquired
10:45:36 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
10:45:36 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0017827214948644475, 'num_filters_1': 28, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.025579082540056593, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 35, 'num_filters_3': 40}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4034151973157324, 'info': {'music_genre': 0.4034151973157324, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0017827214948644475, 'num_filters_1': 28, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.025579082540056593, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 35, 'num_filters_3': 40}"}}
exception: None

10:45:36 job_callback for (0, 0, 16) started
10:45:36 job_callback for (0, 0, 16) got condition
10:45:36 DISPATCHER: Trying to submit another job.
10:45:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:45:36 HBMASTER: Trying to run another job!
10:45:36 job_callback for (0, 0, 16) finished
10:45:36 start sampling a new configuration.
10:45:36 done sampling a new configuration.
10:45:36 HBMASTER: schedule new run for iteration 0
10:45:36 HBMASTER: trying submitting job (0, 0, 17) to dispatcher
10:45:36 HBMASTER: submitting job (0, 0, 17) to dispatcher
10:45:36 DISPATCHER: trying to submit job (0, 0, 17)
10:45:36 DISPATCHER: trying to notify the job_runner thread.
10:45:36 HBMASTER: job (0, 0, 17) submitted to dispatcher
10:45:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:45:36 DISPATCHER: Trying to submit another job.
10:45:36 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:45:36 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:45:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:45:36 WORKER: start processing job (0, 0, 17)
10:45:36 WORKER: args: ()
10:45:36 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.08858437092393703, 'num_filters_1': 94, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.06698927268067097, 'kernel_size_2': 3, 'num_filters_2': 109}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:46:15 DISPATCHER: Starting worker discovery
10:46:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:46:15 DISPATCHER: Finished worker discovery
10:47:15 DISPATCHER: Starting worker discovery
10:47:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:47:15 DISPATCHER: Finished worker discovery
10:47:16 WORKER: done with job (0, 0, 17), trying to register it.
10:47:16 WORKER: registered result for job (0, 0, 17) with dispatcher
10:47:16 DISPATCHER: job (0, 0, 17) finished
10:47:16 DISPATCHER: register_result: lock acquired
10:47:16 DISPATCHER: job (0, 0, 17) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
10:47:16 job_id: (0, 0, 17)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.08858437092393703, 'num_filters_1': 94, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.06698927268067097, 'kernel_size_2': 3, 'num_filters_2': 109}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.29028924430840813, 'info': {'music_genre': 0.29028924430840813, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.08858437092393703, 'num_filters_1': 94, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.06698927268067097, 'kernel_size_2': 3, 'num_filters_2': 109}"}}
exception: None

10:47:16 DISPATCHER: Trying to submit another job.
10:47:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:47:16 job_callback for (0, 0, 17) started
10:47:16 job_callback for (0, 0, 17) got condition
10:47:16 HBMASTER: Trying to run another job!
10:47:16 job_callback for (0, 0, 17) finished
10:47:16 start sampling a new configuration.
10:47:16 done sampling a new configuration.
10:47:16 HBMASTER: schedule new run for iteration 0
10:47:16 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
10:47:16 HBMASTER: submitting job (0, 0, 18) to dispatcher
10:47:16 DISPATCHER: trying to submit job (0, 0, 18)
10:47:16 DISPATCHER: trying to notify the job_runner thread.
10:47:16 HBMASTER: job (0, 0, 18) submitted to dispatcher
10:47:16 DISPATCHER: Trying to submit another job.
10:47:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:47:16 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:47:16 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:47:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:47:16 WORKER: start processing job (0, 0, 18)
10:47:16 WORKER: args: ()
10:47:16 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.03428404226995257, 'num_filters_1': 36, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.18682365226025038, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 76, 'num_filters_3': 29, 'num_filters_4': 60}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:48:15 DISPATCHER: Starting worker discovery
10:48:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:48:15 DISPATCHER: Finished worker discovery
10:48:56 WORKER: done with job (0, 0, 18), trying to register it.
10:48:56 WORKER: registered result for job (0, 0, 18) with dispatcher
10:48:56 DISPATCHER: job (0, 0, 18) finished
10:48:56 DISPATCHER: register_result: lock acquired
10:48:56 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
10:48:56 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.03428404226995257, 'num_filters_1': 36, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.18682365226025038, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 76, 'num_filters_3': 29, 'num_filters_4': 60}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0027180602444433965, 'info': {'music_genre': 0.0027180602444433965, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.03428404226995257, 'num_filters_1': 36, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.18682365226025038, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 76, 'num_filters_3': 29, 'num_filters_4': 60}"}}
exception: None

10:48:56 job_callback for (0, 0, 18) started
10:48:56 DISPATCHER: Trying to submit another job.
10:48:56 job_callback for (0, 0, 18) got condition
10:48:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:48:56 HBMASTER: Trying to run another job!
10:48:56 job_callback for (0, 0, 18) finished
10:48:56 start sampling a new configuration.
10:48:56 done sampling a new configuration.
10:48:56 HBMASTER: schedule new run for iteration 0
10:48:56 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
10:48:56 HBMASTER: submitting job (0, 0, 19) to dispatcher
10:48:56 DISPATCHER: trying to submit job (0, 0, 19)
10:48:56 DISPATCHER: trying to notify the job_runner thread.
10:48:56 HBMASTER: job (0, 0, 19) submitted to dispatcher
10:48:56 DISPATCHER: Trying to submit another job.
10:48:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:48:56 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:48:56 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:48:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:48:56 WORKER: start processing job (0, 0, 19)
10:48:56 WORKER: args: ()
10:48:56 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.01675491069901469, 'num_filters_1': 100, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.01314086632416141, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 86, 'num_filters_3': 110, 'num_filters_4': 125, 'num_filters_5': 71}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:49:15 DISPATCHER: Starting worker discovery
10:49:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:49:15 DISPATCHER: Finished worker discovery
10:50:15 DISPATCHER: Starting worker discovery
10:50:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:50:15 DISPATCHER: Finished worker discovery
10:50:36 WORKER: done with job (0, 0, 19), trying to register it.
10:50:36 WORKER: registered result for job (0, 0, 19) with dispatcher
10:50:36 DISPATCHER: job (0, 0, 19) finished
10:50:36 DISPATCHER: register_result: lock acquired
10:50:36 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
10:50:36 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.01675491069901469, 'num_filters_1': 100, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.01314086632416141, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 86, 'num_filters_3': 110, 'num_filters_4': 125, 'num_filters_5': 71}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.01675491069901469, 'num_filters_1': 100, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.01314086632416141, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 86, 'num_filters_3': 110, 'num_filters_4': 125, 'num_filters_5': 71}"}}
exception: None

10:50:36 job_callback for (0, 0, 19) started
10:50:36 DISPATCHER: Trying to submit another job.
10:50:36 job_callback for (0, 0, 19) got condition
10:50:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:50:36 HBMASTER: Trying to run another job!
10:50:36 job_callback for (0, 0, 19) finished
10:50:36 start sampling a new configuration.
10:50:36 done sampling a new configuration.
10:50:36 HBMASTER: schedule new run for iteration 0
10:50:36 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
10:50:36 HBMASTER: submitting job (0, 0, 20) to dispatcher
10:50:36 DISPATCHER: trying to submit job (0, 0, 20)
10:50:36 DISPATCHER: trying to notify the job_runner thread.
10:50:36 HBMASTER: job (0, 0, 20) submitted to dispatcher
10:50:36 DISPATCHER: Trying to submit another job.
10:50:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:50:36 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:50:36 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:50:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:50:36 WORKER: start processing job (0, 0, 20)
10:50:36 WORKER: args: ()
10:50:36 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.006371282480759643, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.014707708814784224, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 51, 'num_filters_3': 51, 'num_filters_4': 35, 'num_filters_5': 36}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:51:15 DISPATCHER: Starting worker discovery
10:51:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:51:15 DISPATCHER: Finished worker discovery
10:52:15 DISPATCHER: Starting worker discovery
10:52:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:52:15 DISPATCHER: Finished worker discovery
10:52:18 WORKER: done with job (0, 0, 20), trying to register it.
10:52:18 WORKER: registered result for job (0, 0, 20) with dispatcher
10:52:18 DISPATCHER: job (0, 0, 20) finished
10:52:18 DISPATCHER: register_result: lock acquired
10:52:18 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
10:52:18 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.006371282480759643, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.014707708814784224, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 51, 'num_filters_3': 51, 'num_filters_4': 35, 'num_filters_5': 36}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.546006894846691, 'info': {'music_genre': 0.546006894846691, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.006371282480759643, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.014707708814784224, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 51, 'num_filters_3': 51, 'num_filters_4': 35, 'num_filters_5': 36}"}}
exception: None

10:52:18 job_callback for (0, 0, 20) started
10:52:18 job_callback for (0, 0, 20) got condition
10:52:18 DISPATCHER: Trying to submit another job.
10:52:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:52:18 HBMASTER: Trying to run another job!
10:52:18 job_callback for (0, 0, 20) finished
10:52:18 start sampling a new configuration.
10:52:18 done sampling a new configuration.
10:52:18 HBMASTER: schedule new run for iteration 0
10:52:18 HBMASTER: trying submitting job (0, 0, 21) to dispatcher
10:52:18 HBMASTER: submitting job (0, 0, 21) to dispatcher
10:52:18 DISPATCHER: trying to submit job (0, 0, 21)
10:52:18 DISPATCHER: trying to notify the job_runner thread.
10:52:18 HBMASTER: job (0, 0, 21) submitted to dispatcher
10:52:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:52:18 DISPATCHER: Trying to submit another job.
10:52:18 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:52:18 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:52:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:52:18 WORKER: start processing job (0, 0, 21)
10:52:18 WORKER: args: ()
10:52:18 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.013133342601945604, 'num_filters_1': 70, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.0780787899940777, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 98, 'num_filters_3': 29}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:53:15 DISPATCHER: Starting worker discovery
10:53:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:53:15 DISPATCHER: Finished worker discovery
10:53:59 WORKER: done with job (0, 0, 21), trying to register it.
10:53:59 WORKER: registered result for job (0, 0, 21) with dispatcher
10:53:59 DISPATCHER: job (0, 0, 21) finished
10:53:59 DISPATCHER: register_result: lock acquired
10:53:59 DISPATCHER: job (0, 0, 21) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
10:53:59 job_id: (0, 0, 21)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.013133342601945604, 'num_filters_1': 70, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.0780787899940777, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 98, 'num_filters_3': 29}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.15497085982402423, 'info': {'music_genre': 0.15497085982402423, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.013133342601945604, 'num_filters_1': 70, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.0780787899940777, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 98, 'num_filters_3': 29}"}}
exception: None

10:53:59 job_callback for (0, 0, 21) started
10:53:59 job_callback for (0, 0, 21) got condition
10:53:59 DISPATCHER: Trying to submit another job.
10:53:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:53:59 HBMASTER: Trying to run another job!
10:53:59 job_callback for (0, 0, 21) finished
10:53:59 start sampling a new configuration.
10:53:59 done sampling a new configuration.
10:53:59 HBMASTER: schedule new run for iteration 0
10:53:59 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
10:53:59 HBMASTER: submitting job (0, 0, 22) to dispatcher
10:53:59 DISPATCHER: trying to submit job (0, 0, 22)
10:53:59 DISPATCHER: trying to notify the job_runner thread.
10:53:59 HBMASTER: job (0, 0, 22) submitted to dispatcher
10:53:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:53:59 DISPATCHER: Trying to submit another job.
10:53:59 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:53:59 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:53:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:53:59 WORKER: start processing job (0, 0, 22)
10:53:59 WORKER: args: ()
10:53:59 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.01406588632823341, 'num_filters_1': 104, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.025451687188817865, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 21, 'num_filters_3': 68, 'num_filters_4': 91}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:54:15 DISPATCHER: Starting worker discovery
10:54:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:54:15 DISPATCHER: Finished worker discovery
10:55:15 DISPATCHER: Starting worker discovery
10:55:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:55:15 DISPATCHER: Finished worker discovery
10:55:41 WORKER: done with job (0, 0, 22), trying to register it.
10:55:41 WORKER: registered result for job (0, 0, 22) with dispatcher
10:55:41 DISPATCHER: job (0, 0, 22) finished
10:55:41 DISPATCHER: register_result: lock acquired
10:55:41 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
10:55:41 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.01406588632823341, 'num_filters_1': 104, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.025451687188817865, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 21, 'num_filters_3': 68, 'num_filters_4': 91}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.01406588632823341, 'num_filters_1': 104, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.025451687188817865, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 21, 'num_filters_3': 68, 'num_filters_4': 91}"}}
exception: None

10:55:41 job_callback for (0, 0, 22) started
10:55:41 job_callback for (0, 0, 22) got condition
10:55:41 DISPATCHER: Trying to submit another job.
10:55:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:55:41 HBMASTER: Trying to run another job!
10:55:41 job_callback for (0, 0, 22) finished
10:55:41 start sampling a new configuration.
10:55:41 done sampling a new configuration.
10:55:41 HBMASTER: schedule new run for iteration 0
10:55:41 HBMASTER: trying submitting job (0, 0, 23) to dispatcher
10:55:41 HBMASTER: submitting job (0, 0, 23) to dispatcher
10:55:41 DISPATCHER: trying to submit job (0, 0, 23)
10:55:41 DISPATCHER: trying to notify the job_runner thread.
10:55:41 HBMASTER: job (0, 0, 23) submitted to dispatcher
10:55:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:55:41 DISPATCHER: Trying to submit another job.
10:55:41 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:55:41 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:55:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:55:41 WORKER: start processing job (0, 0, 23)
10:55:41 WORKER: args: ()
10:55:41 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.018450305269082146, 'num_filters_1': 41, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.012935121600007649, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 113, 'num_filters_3': 23, 'num_filters_4': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:56:15 DISPATCHER: Starting worker discovery
10:56:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:56:15 DISPATCHER: Finished worker discovery
10:57:15 DISPATCHER: Starting worker discovery
10:57:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:57:15 DISPATCHER: Finished worker discovery
10:57:23 WORKER: done with job (0, 0, 23), trying to register it.
10:57:23 WORKER: registered result for job (0, 0, 23) with dispatcher
10:57:23 DISPATCHER: job (0, 0, 23) finished
10:57:23 DISPATCHER: register_result: lock acquired
10:57:23 DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
10:57:23 job_id: (0, 0, 23)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.018450305269082146, 'num_filters_1': 41, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.012935121600007649, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 113, 'num_filters_3': 23, 'num_filters_4': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.018450305269082146, 'num_filters_1': 41, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.012935121600007649, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 113, 'num_filters_3': 23, 'num_filters_4': 19}"}}
exception: None

10:57:23 job_callback for (0, 0, 23) started
10:57:23 job_callback for (0, 0, 23) got condition
10:57:23 DISPATCHER: Trying to submit another job.
10:57:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:57:23 HBMASTER: Trying to run another job!
10:57:23 job_callback for (0, 0, 23) finished
10:57:23 start sampling a new configuration.
10:57:23 done sampling a new configuration.
10:57:23 HBMASTER: schedule new run for iteration 0
10:57:23 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
10:57:23 HBMASTER: submitting job (0, 0, 24) to dispatcher
10:57:23 DISPATCHER: trying to submit job (0, 0, 24)
10:57:23 DISPATCHER: trying to notify the job_runner thread.
10:57:23 HBMASTER: job (0, 0, 24) submitted to dispatcher
10:57:23 DISPATCHER: Trying to submit another job.
10:57:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:57:23 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:57:23 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:57:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:57:23 WORKER: start processing job (0, 0, 24)
10:57:23 WORKER: args: ()
10:57:23 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.017317233946704983, 'num_filters_1': 69, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.03525990997999193}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:58:15 DISPATCHER: Starting worker discovery
10:58:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:58:15 DISPATCHER: Finished worker discovery
10:59:05 WORKER: done with job (0, 0, 24), trying to register it.
10:59:05 WORKER: registered result for job (0, 0, 24) with dispatcher
10:59:05 DISPATCHER: job (0, 0, 24) finished
10:59:05 DISPATCHER: register_result: lock acquired
10:59:05 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
10:59:05 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.017317233946704983, 'num_filters_1': 69, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.03525990997999193}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.08847177327855334, 'info': {'music_genre': 0.08847177327855334, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.017317233946704983, 'num_filters_1': 69, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.03525990997999193}"}}
exception: None

10:59:05 job_callback for (0, 0, 24) started
10:59:05 job_callback for (0, 0, 24) got condition
10:59:05 DISPATCHER: Trying to submit another job.
10:59:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:59:05 HBMASTER: Trying to run another job!
10:59:05 job_callback for (0, 0, 24) finished
10:59:05 start sampling a new configuration.
10:59:05 done sampling a new configuration.
10:59:05 HBMASTER: schedule new run for iteration 0
10:59:05 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
10:59:05 HBMASTER: submitting job (0, 0, 25) to dispatcher
10:59:05 DISPATCHER: trying to submit job (0, 0, 25)
10:59:05 DISPATCHER: trying to notify the job_runner thread.
10:59:05 HBMASTER: job (0, 0, 25) submitted to dispatcher
10:59:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:59:05 DISPATCHER: Trying to submit another job.
10:59:05 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:59:05 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:59:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:59:05 WORKER: start processing job (0, 0, 25)
10:59:05 WORKER: args: ()
10:59:05 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.04605696534099541, 'num_filters_1': 74, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.02110352837555572}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:59:15 DISPATCHER: Starting worker discovery
10:59:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:59:15 DISPATCHER: Finished worker discovery
11:00:15 DISPATCHER: Starting worker discovery
11:00:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:00:15 DISPATCHER: Finished worker discovery
11:00:46 WORKER: done with job (0, 0, 25), trying to register it.
11:00:46 WORKER: registered result for job (0, 0, 25) with dispatcher
11:00:46 DISPATCHER: job (0, 0, 25) finished
11:00:46 DISPATCHER: register_result: lock acquired
11:00:46 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
11:00:46 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.04605696534099541, 'num_filters_1': 74, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.02110352837555572}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.11243885606561578, 'info': {'music_genre': 0.11243885606561578, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.04605696534099541, 'num_filters_1': 74, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.02110352837555572}"}}
exception: None

11:00:46 job_callback for (0, 0, 25) started
11:00:46 job_callback for (0, 0, 25) got condition
11:00:46 DISPATCHER: Trying to submit another job.
11:00:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:00:46 HBMASTER: Trying to run another job!
11:00:46 job_callback for (0, 0, 25) finished
11:00:46 start sampling a new configuration.
11:00:46 done sampling a new configuration.
11:00:46 HBMASTER: schedule new run for iteration 0
11:00:46 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
11:00:46 HBMASTER: submitting job (0, 0, 26) to dispatcher
11:00:46 DISPATCHER: trying to submit job (0, 0, 26)
11:00:46 DISPATCHER: trying to notify the job_runner thread.
11:00:46 HBMASTER: job (0, 0, 26) submitted to dispatcher
11:00:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:00:46 DISPATCHER: Trying to submit another job.
11:00:46 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.30597140382006277952
11:00:46 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
11:00:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:00:46 WORKER: start processing job (0, 0, 26)
11:00:46 WORKER: args: ()
11:00:46 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.04512555694260726, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.17762325002478874, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 41, 'num_filters_3': 121}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:01:15 DISPATCHER: Starting worker discovery
11:01:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:01:15 DISPATCHER: Finished worker discovery
11:02:15 DISPATCHER: Starting worker discovery
11:02:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:02:15 DISPATCHER: Finished worker discovery
11:02:26 WORKER: done with job (0, 0, 26), trying to register it.
11:02:26 WORKER: registered result for job (0, 0, 26) with dispatcher
11:02:26 DISPATCHER: job (0, 0, 26) finished
11:02:26 DISPATCHER: register_result: lock acquired
11:02:26 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
11:02:26 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.04512555694260726, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.17762325002478874, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 41, 'num_filters_3': 121}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.09448285634167096, 'info': {'music_genre': 0.09448285634167096, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.04512555694260726, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.17762325002478874, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 41, 'num_filters_3': 121}"}}
exception: None

11:02:26 job_callback for (0, 0, 26) started
11:02:26 DISPATCHER: Trying to submit another job.
11:02:26 job_callback for (0, 0, 26) got condition
11:02:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:02:26 HBMASTER: Trying to run another job!
11:02:26 job_callback for (0, 0, 26) finished
11:02:26 ITERATION: Advancing config (0, 0, 0) to next budget 133.333333
11:02:26 ITERATION: Advancing config (0, 0, 3) to next budget 133.333333
11:02:26 ITERATION: Advancing config (0, 0, 5) to next budget 133.333333
11:02:26 ITERATION: Advancing config (0, 0, 8) to next budget 133.333333
11:02:26 ITERATION: Advancing config (0, 0, 9) to next budget 133.333333
11:02:26 ITERATION: Advancing config (0, 0, 10) to next budget 133.333333
11:02:26 ITERATION: Advancing config (0, 0, 15) to next budget 133.333333
11:02:26 ITERATION: Advancing config (0, 0, 16) to next budget 133.333333
11:02:26 ITERATION: Advancing config (0, 0, 20) to next budget 133.333333
11:02:26 HBMASTER: schedule new run for iteration 0
11:02:26 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
11:02:26 HBMASTER: submitting job (0, 0, 0) to dispatcher
11:02:26 DISPATCHER: trying to submit job (0, 0, 0)
11:02:26 DISPATCHER: trying to notify the job_runner thread.
11:02:26 HBMASTER: job (0, 0, 0) submitted to dispatcher
11:02:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:02:26 DISPATCHER: Trying to submit another job.
11:02:26 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
11:02:26 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
11:02:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:02:26 WORKER: start processing job (0, 0, 0)
11:02:26 WORKER: args: ()
11:02:26 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0036990212515202498, 'num_filters_1': 29, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.021744818966596073, 'kernel_size_2': 5, 'num_filters_2': 34}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:03:15 DISPATCHER: Starting worker discovery
11:03:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:03:15 DISPATCHER: Finished worker discovery
11:04:15 DISPATCHER: Starting worker discovery
11:04:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:04:15 DISPATCHER: Finished worker discovery
11:05:15 DISPATCHER: Starting worker discovery
11:05:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:05:15 DISPATCHER: Finished worker discovery
11:05:38 WORKER: done with job (0, 0, 0), trying to register it.
11:05:38 WORKER: registered result for job (0, 0, 0) with dispatcher
11:05:38 DISPATCHER: job (0, 0, 0) finished
11:05:38 DISPATCHER: register_result: lock acquired
11:05:38 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
11:05:38 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0036990212515202498, 'num_filters_1': 29, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.021744818966596073, 'kernel_size_2': 5, 'num_filters_2': 34}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3944427397149569, 'info': {'music_genre': 0.3944427397149569, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0036990212515202498, 'num_filters_1': 29, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.021744818966596073, 'kernel_size_2': 5, 'num_filters_2': 34}"}}
exception: None

11:05:38 job_callback for (0, 0, 0) started
11:05:38 job_callback for (0, 0, 0) got condition
11:05:38 DISPATCHER: Trying to submit another job.
11:05:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:05:38 Only 1 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
11:05:38 HBMASTER: Trying to run another job!
11:05:38 job_callback for (0, 0, 0) finished
11:05:38 HBMASTER: schedule new run for iteration 0
11:05:38 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
11:05:38 HBMASTER: submitting job (0, 0, 3) to dispatcher
11:05:38 DISPATCHER: trying to submit job (0, 0, 3)
11:05:38 DISPATCHER: trying to notify the job_runner thread.
11:05:38 HBMASTER: job (0, 0, 3) submitted to dispatcher
11:05:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:05:38 DISPATCHER: Trying to submit another job.
11:05:38 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
11:05:38 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
11:05:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:05:38 WORKER: start processing job (0, 0, 3)
11:05:38 WORKER: args: ()
11:05:38 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.00878137373544829, 'num_filters_1': 109, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.025602840292473072, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 104, 'num_filters_3': 63}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:06:15 DISPATCHER: Starting worker discovery
11:06:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:06:15 DISPATCHER: Finished worker discovery
11:07:15 DISPATCHER: Starting worker discovery
11:07:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:07:15 DISPATCHER: Finished worker discovery
11:08:15 DISPATCHER: Starting worker discovery
11:08:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:08:15 DISPATCHER: Finished worker discovery
11:08:48 WORKER: done with job (0, 0, 3), trying to register it.
11:08:48 WORKER: registered result for job (0, 0, 3) with dispatcher
11:08:48 DISPATCHER: job (0, 0, 3) finished
11:08:48 DISPATCHER: register_result: lock acquired
11:08:48 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
11:08:48 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.00878137373544829, 'num_filters_1': 109, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.025602840292473072, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 104, 'num_filters_3': 63}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4679630132637471, 'info': {'music_genre': 0.4679630132637471, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.00878137373544829, 'num_filters_1': 109, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.025602840292473072, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 104, 'num_filters_3': 63}"}}
exception: None

11:08:48 job_callback for (0, 0, 3) started
11:08:48 job_callback for (0, 0, 3) got condition
11:08:48 DISPATCHER: Trying to submit another job.
11:08:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:08:48 Only 2 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
11:08:48 HBMASTER: Trying to run another job!
11:08:48 job_callback for (0, 0, 3) finished
11:08:48 HBMASTER: schedule new run for iteration 0
11:08:48 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
11:08:48 HBMASTER: submitting job (0, 0, 5) to dispatcher
11:08:48 DISPATCHER: trying to submit job (0, 0, 5)
11:08:48 DISPATCHER: trying to notify the job_runner thread.
11:08:48 HBMASTER: job (0, 0, 5) submitted to dispatcher
11:08:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:08:48 DISPATCHER: Trying to submit another job.
11:08:48 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952
11:08:48 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
11:08:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:08:48 WORKER: start processing job (0, 0, 5)
11:08:48 WORKER: args: ()
11:08:48 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001602103823566725, 'num_filters_1': 94, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.019605365181046216, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 34, 'num_filters_3': 65, 'num_filters_4': 74}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:09:15 DISPATCHER: Starting worker discovery
11:09:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:09:15 DISPATCHER: Finished worker discovery
11:10:15 DISPATCHER: Starting worker discovery
11:10:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:10:15 DISPATCHER: Finished worker discovery
11:11:15 DISPATCHER: Starting worker discovery
11:11:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:11:15 DISPATCHER: Finished worker discovery
11:12:01 WORKER: done with job (0, 0, 5), trying to register it.
11:12:01 WORKER: registered result for job (0, 0, 5) with dispatcher
11:12:01 DISPATCHER: job (0, 0, 5) finished
11:12:01 DISPATCHER: register_result: lock acquired
11:12:01 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
11:12:01 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001602103823566725, 'num_filters_1': 94, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.019605365181046216, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 34, 'num_filters_3': 65, 'num_filters_4': 74}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3854077192133372, 'info': {'music_genre': 0.3854077192133372, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001602103823566725, 'num_filters_1': 94, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.019605365181046216, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 34, 'num_filters_3': 65, 'num_filters_4': 74}"}}
exception: None

11:12:01 job_callback for (0, 0, 5) started
11:12:01 job_callback for (0, 0, 5) got condition
11:12:01 DISPATCHER: Trying to submit another job.
11:12:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:12:01 Only 3 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
11:12:01 HBMASTER: Trying to run another job!
11:12:01 job_callback for (0, 0, 5) finished
11:12:01 HBMASTER: schedule new run for iteration 0
11:12:01 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
11:12:01 HBMASTER: submitting job (0, 0, 8) to dispatcher
11:12:01 DISPATCHER: trying to submit job (0, 0, 8)
11:12:01 DISPATCHER: trying to notify the job_runner thread.
11:12:01 HBMASTER: job (0, 0, 8) submitted to dispatcher
11:12:01 DISPATCHER: Trying to submit another job.
11:12:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:12:01 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952
11:12:01 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
11:12:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:12:01 WORKER: start processing job (0, 0, 8)
11:12:01 WORKER: args: ()
11:12:01 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.003280106792977438, 'num_filters_1': 24, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.028466173269302085, 'kernel_size_2': 5, 'num_filters_2': 22}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:12:15 DISPATCHER: Starting worker discovery
11:12:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:12:15 DISPATCHER: Finished worker discovery
11:13:15 DISPATCHER: Starting worker discovery
11:13:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:13:15 DISPATCHER: Finished worker discovery
11:14:15 DISPATCHER: Starting worker discovery
11:14:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:14:15 DISPATCHER: Finished worker discovery
11:15:12 WORKER: done with job (0, 0, 8), trying to register it.
11:15:12 WORKER: registered result for job (0, 0, 8) with dispatcher
11:15:12 DISPATCHER: job (0, 0, 8) finished
11:15:12 DISPATCHER: register_result: lock acquired
11:15:12 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
11:15:12 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.003280106792977438, 'num_filters_1': 24, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.028466173269302085, 'kernel_size_2': 5, 'num_filters_2': 22}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.36077989838770935, 'info': {'music_genre': 0.36077989838770935, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.003280106792977438, 'num_filters_1': 24, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.028466173269302085, 'kernel_size_2': 5, 'num_filters_2': 22}"}}
exception: None

11:15:12 job_callback for (0, 0, 8) started
11:15:12 job_callback for (0, 0, 8) got condition
11:15:12 DISPATCHER: Trying to submit another job.
11:15:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:15:12 Only 4 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
11:15:12 HBMASTER: Trying to run another job!
11:15:12 job_callback for (0, 0, 8) finished
11:15:12 HBMASTER: schedule new run for iteration 0
11:15:12 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
11:15:12 HBMASTER: submitting job (0, 0, 9) to dispatcher
11:15:12 DISPATCHER: trying to submit job (0, 0, 9)
11:15:12 DISPATCHER: trying to notify the job_runner thread.
11:15:12 HBMASTER: job (0, 0, 9) submitted to dispatcher
11:15:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:15:12 DISPATCHER: Trying to submit another job.
11:15:12 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.30597140382006277952
11:15:12 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
11:15:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:15:12 WORKER: start processing job (0, 0, 9)
11:15:12 WORKER: args: ()
11:15:12 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.009063100394266329, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.03090961250845323, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 127, 'num_filters_3': 78, 'num_filters_4': 35, 'num_filters_5': 58}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:15:15 DISPATCHER: Starting worker discovery
11:15:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:15:15 DISPATCHER: Finished worker discovery
11:16:15 DISPATCHER: Starting worker discovery
11:16:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:16:15 DISPATCHER: Finished worker discovery
11:17:15 DISPATCHER: Starting worker discovery
11:17:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:17:15 DISPATCHER: Finished worker discovery
11:18:15 DISPATCHER: Starting worker discovery
11:18:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:18:15 DISPATCHER: Finished worker discovery
11:18:24 WORKER: done with job (0, 0, 9), trying to register it.
11:18:24 WORKER: registered result for job (0, 0, 9) with dispatcher
11:18:24 DISPATCHER: job (0, 0, 9) finished
11:18:24 DISPATCHER: register_result: lock acquired
11:18:24 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
11:18:24 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.009063100394266329, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.03090961250845323, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 127, 'num_filters_3': 78, 'num_filters_4': 35, 'num_filters_5': 58}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.39204593024469925, 'info': {'music_genre': 0.39204593024469925, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.009063100394266329, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.03090961250845323, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 127, 'num_filters_3': 78, 'num_filters_4': 35, 'num_filters_5': 58}"}}
exception: None

11:18:24 job_callback for (0, 0, 9) started
11:18:24 DISPATCHER: Trying to submit another job.
11:18:24 job_callback for (0, 0, 9) got condition
11:18:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:18:24 Only 5 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
11:18:24 HBMASTER: Trying to run another job!
11:18:24 job_callback for (0, 0, 9) finished
11:18:24 HBMASTER: schedule new run for iteration 0
11:18:24 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
11:18:24 HBMASTER: submitting job (0, 0, 10) to dispatcher
11:18:24 DISPATCHER: trying to submit job (0, 0, 10)
11:18:24 DISPATCHER: trying to notify the job_runner thread.
11:18:24 HBMASTER: job (0, 0, 10) submitted to dispatcher
11:18:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:18:24 DISPATCHER: Trying to submit another job.
11:18:24 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.30597140382006277952
11:18:24 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
11:18:24 WORKER: start processing job (0, 0, 10)
11:18:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:18:24 WORKER: args: ()
11:18:24 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003695625323980962, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.01071228099643476, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 19, 'num_filters_3': 79, 'num_filters_4': 100}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:19:15 DISPATCHER: Starting worker discovery
11:19:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:19:15 DISPATCHER: Finished worker discovery
11:20:15 DISPATCHER: Starting worker discovery
11:20:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:20:15 DISPATCHER: Finished worker discovery
11:21:15 DISPATCHER: Starting worker discovery
11:21:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:21:15 DISPATCHER: Finished worker discovery
11:21:36 WORKER: done with job (0, 0, 10), trying to register it.
11:21:36 WORKER: registered result for job (0, 0, 10) with dispatcher
11:21:36 DISPATCHER: job (0, 0, 10) finished
11:21:36 DISPATCHER: register_result: lock acquired
11:21:36 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
11:21:36 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003695625323980962, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.01071228099643476, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 19, 'num_filters_3': 79, 'num_filters_4': 100}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5046170830349356, 'info': {'music_genre': 0.5046170830349356, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003695625323980962, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.01071228099643476, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 19, 'num_filters_3': 79, 'num_filters_4': 100}"}}
exception: None

11:21:36 job_callback for (0, 0, 10) started
11:21:36 DISPATCHER: Trying to submit another job.
11:21:36 job_callback for (0, 0, 10) got condition
11:21:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:21:36 Only 6 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
11:21:36 HBMASTER: Trying to run another job!
11:21:36 job_callback for (0, 0, 10) finished
11:21:36 HBMASTER: schedule new run for iteration 0
11:21:36 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
11:21:36 HBMASTER: submitting job (0, 0, 15) to dispatcher
11:21:36 DISPATCHER: trying to submit job (0, 0, 15)
11:21:36 DISPATCHER: trying to notify the job_runner thread.
11:21:36 HBMASTER: job (0, 0, 15) submitted to dispatcher
11:21:36 DISPATCHER: Trying to submit another job.
11:21:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:21:36 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.30597140382006277952
11:21:36 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
11:21:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:21:36 WORKER: start processing job (0, 0, 15)
11:21:36 WORKER: args: ()
11:21:36 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.02183920671512108, 'num_filters_1': 26, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.017192458767431678, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 99, 'num_filters_3': 76, 'num_filters_4': 35}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:22:15 DISPATCHER: Starting worker discovery
11:22:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:22:15 DISPATCHER: Finished worker discovery
11:23:15 DISPATCHER: Starting worker discovery
11:23:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:23:15 DISPATCHER: Finished worker discovery
11:24:15 DISPATCHER: Starting worker discovery
11:24:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:24:15 DISPATCHER: Finished worker discovery
11:24:48 WORKER: done with job (0, 0, 15), trying to register it.
11:24:48 WORKER: registered result for job (0, 0, 15) with dispatcher
11:24:48 DISPATCHER: job (0, 0, 15) finished
11:24:48 DISPATCHER: register_result: lock acquired
11:24:48 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
11:24:48 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.02183920671512108, 'num_filters_1': 26, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.017192458767431678, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 99, 'num_filters_3': 76, 'num_filters_4': 35}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2761044729212986, 'info': {'music_genre': 0.2761044729212986, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.02183920671512108, 'num_filters_1': 26, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.017192458767431678, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 99, 'num_filters_3': 76, 'num_filters_4': 35}"}}
exception: None

11:24:48 job_callback for (0, 0, 15) started
11:24:48 DISPATCHER: Trying to submit another job.
11:24:48 job_callback for (0, 0, 15) got condition
11:24:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:24:48 Only 7 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
11:24:48 HBMASTER: Trying to run another job!
11:24:48 job_callback for (0, 0, 15) finished
11:24:48 HBMASTER: schedule new run for iteration 0
11:24:48 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
11:24:48 HBMASTER: submitting job (0, 0, 16) to dispatcher
11:24:48 DISPATCHER: trying to submit job (0, 0, 16)
11:24:48 DISPATCHER: trying to notify the job_runner thread.
11:24:48 HBMASTER: job (0, 0, 16) submitted to dispatcher
11:24:48 DISPATCHER: Trying to submit another job.
11:24:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:24:48 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.30597140382006277952
11:24:48 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
11:24:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:24:48 WORKER: start processing job (0, 0, 16)
11:24:48 WORKER: args: ()
11:24:48 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0017827214948644475, 'num_filters_1': 28, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.025579082540056593, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 35, 'num_filters_3': 40}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:25:15 DISPATCHER: Starting worker discovery
11:25:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:25:15 DISPATCHER: Finished worker discovery
11:26:15 DISPATCHER: Starting worker discovery
11:26:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:26:15 DISPATCHER: Finished worker discovery
11:27:15 DISPATCHER: Starting worker discovery
11:27:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:27:15 DISPATCHER: Finished worker discovery
11:28:01 WORKER: done with job (0, 0, 16), trying to register it.
11:28:01 WORKER: registered result for job (0, 0, 16) with dispatcher
11:28:01 DISPATCHER: job (0, 0, 16) finished
11:28:01 DISPATCHER: register_result: lock acquired
11:28:01 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
11:28:01 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0017827214948644475, 'num_filters_1': 28, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.025579082540056593, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 35, 'num_filters_3': 40}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2599641368374157, 'info': {'music_genre': 0.2599641368374157, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0017827214948644475, 'num_filters_1': 28, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.025579082540056593, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 35, 'num_filters_3': 40}"}}
exception: None

11:28:01 job_callback for (0, 0, 16) started
11:28:01 job_callback for (0, 0, 16) got condition
11:28:01 DISPATCHER: Trying to submit another job.
11:28:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:28:01 Only 8 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
11:28:01 HBMASTER: Trying to run another job!
11:28:01 job_callback for (0, 0, 16) finished
11:28:01 HBMASTER: schedule new run for iteration 0
11:28:01 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
11:28:01 HBMASTER: submitting job (0, 0, 20) to dispatcher
11:28:01 DISPATCHER: trying to submit job (0, 0, 20)
11:28:01 DISPATCHER: trying to notify the job_runner thread.
11:28:01 HBMASTER: job (0, 0, 20) submitted to dispatcher
11:28:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:28:01 DISPATCHER: Trying to submit another job.
11:28:01 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.30597140382006277952
11:28:01 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
11:28:01 WORKER: start processing job (0, 0, 20)
11:28:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:28:01 WORKER: args: ()
11:28:01 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.006371282480759643, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.014707708814784224, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 51, 'num_filters_3': 51, 'num_filters_4': 35, 'num_filters_5': 36}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:28:15 DISPATCHER: Starting worker discovery
11:28:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:28:15 DISPATCHER: Finished worker discovery
11:29:15 DISPATCHER: Starting worker discovery
11:29:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:29:15 DISPATCHER: Finished worker discovery
11:30:15 DISPATCHER: Starting worker discovery
11:30:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:30:15 DISPATCHER: Finished worker discovery
11:31:13 WORKER: done with job (0, 0, 20), trying to register it.
11:31:13 WORKER: registered result for job (0, 0, 20) with dispatcher
11:31:13 DISPATCHER: job (0, 0, 20) finished
11:31:13 DISPATCHER: register_result: lock acquired
11:31:13 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
11:31:13 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.006371282480759643, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.014707708814784224, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 51, 'num_filters_3': 51, 'num_filters_4': 35, 'num_filters_5': 36}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4715946318524602, 'info': {'music_genre': 0.4715946318524602, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.006371282480759643, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.014707708814784224, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 51, 'num_filters_3': 51, 'num_filters_4': 35, 'num_filters_5': 36}"}}
exception: None

11:31:13 job_callback for (0, 0, 20) started
11:31:13 job_callback for (0, 0, 20) got condition
11:31:13 DISPATCHER: Trying to submit another job.
11:31:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:31:13 Only 9 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
11:31:13 HBMASTER: Trying to run another job!
11:31:13 job_callback for (0, 0, 20) finished
11:31:13 ITERATION: Advancing config (0, 0, 3) to next budget 400.000000
11:31:13 ITERATION: Advancing config (0, 0, 10) to next budget 400.000000
11:31:13 ITERATION: Advancing config (0, 0, 20) to next budget 400.000000
11:31:13 HBMASTER: schedule new run for iteration 0
11:31:13 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
11:31:13 HBMASTER: submitting job (0, 0, 3) to dispatcher
11:31:13 DISPATCHER: trying to submit job (0, 0, 3)
11:31:13 DISPATCHER: trying to notify the job_runner thread.
11:31:13 HBMASTER: job (0, 0, 3) submitted to dispatcher
11:31:13 DISPATCHER: Trying to submit another job.
11:31:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:31:13 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
11:31:13 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
11:31:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:31:13 WORKER: start processing job (0, 0, 3)
11:31:13 WORKER: args: ()
11:31:13 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.00878137373544829, 'num_filters_1': 109, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.025602840292473072, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 104, 'num_filters_3': 63}, 'budget': 400.0, 'working_directory': '.'}
11:31:15 DISPATCHER: Starting worker discovery
11:31:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:31:15 DISPATCHER: Finished worker discovery
11:32:15 DISPATCHER: Starting worker discovery
11:32:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:32:15 DISPATCHER: Finished worker discovery
11:33:15 DISPATCHER: Starting worker discovery
11:33:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:33:15 DISPATCHER: Finished worker discovery
11:34:15 DISPATCHER: Starting worker discovery
11:34:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:34:15 DISPATCHER: Finished worker discovery
11:35:15 DISPATCHER: Starting worker discovery
11:35:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:35:15 DISPATCHER: Finished worker discovery
11:36:15 DISPATCHER: Starting worker discovery
11:36:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:36:15 DISPATCHER: Finished worker discovery
11:37:15 DISPATCHER: Starting worker discovery
11:37:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:37:15 DISPATCHER: Finished worker discovery
11:38:15 DISPATCHER: Starting worker discovery
11:38:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:38:15 DISPATCHER: Finished worker discovery
11:38:53 WORKER: done with job (0, 0, 3), trying to register it.
11:38:53 WORKER: registered result for job (0, 0, 3) with dispatcher
11:38:53 DISPATCHER: job (0, 0, 3) finished
11:38:53 DISPATCHER: register_result: lock acquired
11:38:53 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
11:38:53 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.00878137373544829, 'num_filters_1': 109, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.025602840292473072, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 104, 'num_filters_3': 63}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.2411798783824624, 'info': {'music_genre': 0.2411798783824624, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.00878137373544829, 'num_filters_1': 109, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.025602840292473072, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 104, 'num_filters_3': 63}"}}
exception: None

11:38:53 job_callback for (0, 0, 3) started
11:38:53 DISPATCHER: Trying to submit another job.
11:38:53 job_callback for (0, 0, 3) got condition
11:38:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:38:53 Only 1 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
11:38:53 HBMASTER: Trying to run another job!
11:38:53 job_callback for (0, 0, 3) finished
11:38:53 HBMASTER: schedule new run for iteration 0
11:38:53 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
11:38:53 HBMASTER: submitting job (0, 0, 10) to dispatcher
11:38:53 DISPATCHER: trying to submit job (0, 0, 10)
11:38:53 DISPATCHER: trying to notify the job_runner thread.
11:38:53 HBMASTER: job (0, 0, 10) submitted to dispatcher
11:38:53 DISPATCHER: Trying to submit another job.
11:38:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:38:53 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.30597140382006277952
11:38:53 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
11:38:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:38:53 WORKER: start processing job (0, 0, 10)
11:38:53 WORKER: args: ()
11:38:53 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003695625323980962, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.01071228099643476, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 19, 'num_filters_3': 79, 'num_filters_4': 100}, 'budget': 400.0, 'working_directory': '.'}
11:39:15 DISPATCHER: Starting worker discovery
11:39:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:39:15 DISPATCHER: Finished worker discovery
11:40:15 DISPATCHER: Starting worker discovery
11:40:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:40:15 DISPATCHER: Finished worker discovery
11:41:15 DISPATCHER: Starting worker discovery
11:41:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:41:15 DISPATCHER: Finished worker discovery
11:42:15 DISPATCHER: Starting worker discovery
11:42:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:42:15 DISPATCHER: Finished worker discovery
11:43:15 DISPATCHER: Starting worker discovery
11:43:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:43:15 DISPATCHER: Finished worker discovery
11:44:15 DISPATCHER: Starting worker discovery
11:44:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:44:15 DISPATCHER: Finished worker discovery
11:45:15 DISPATCHER: Starting worker discovery
11:45:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:45:15 DISPATCHER: Finished worker discovery
11:46:15 DISPATCHER: Starting worker discovery
11:46:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:46:15 DISPATCHER: Finished worker discovery
11:46:34 WORKER: done with job (0, 0, 10), trying to register it.
11:46:34 WORKER: registered result for job (0, 0, 10) with dispatcher
11:46:34 DISPATCHER: job (0, 0, 10) finished
11:46:34 DISPATCHER: register_result: lock acquired
11:46:34 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
11:46:34 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003695625323980962, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.01071228099643476, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 19, 'num_filters_3': 79, 'num_filters_4': 100}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.45826922244173723, 'info': {'music_genre': 0.45826922244173723, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003695625323980962, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.01071228099643476, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 19, 'num_filters_3': 79, 'num_filters_4': 100}"}}
exception: None

11:46:34 job_callback for (0, 0, 10) started
11:46:34 job_callback for (0, 0, 10) got condition
11:46:34 DISPATCHER: Trying to submit another job.
11:46:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:46:34 Only 2 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
11:46:34 HBMASTER: Trying to run another job!
11:46:34 job_callback for (0, 0, 10) finished
11:46:34 HBMASTER: schedule new run for iteration 0
11:46:34 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
11:46:34 HBMASTER: submitting job (0, 0, 20) to dispatcher
11:46:34 DISPATCHER: trying to submit job (0, 0, 20)
11:46:34 DISPATCHER: trying to notify the job_runner thread.
11:46:34 HBMASTER: job (0, 0, 20) submitted to dispatcher
11:46:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:46:34 DISPATCHER: Trying to submit another job.
11:46:34 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.30597140382006277952
11:46:34 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
11:46:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:46:34 WORKER: start processing job (0, 0, 20)
11:46:34 WORKER: args: ()
11:46:34 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.006371282480759643, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.014707708814784224, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 51, 'num_filters_3': 51, 'num_filters_4': 35, 'num_filters_5': 36}, 'budget': 400.0, 'working_directory': '.'}
11:47:15 DISPATCHER: Starting worker discovery
11:47:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:47:15 DISPATCHER: Finished worker discovery
11:48:15 DISPATCHER: Starting worker discovery
11:48:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:48:15 DISPATCHER: Finished worker discovery
11:49:15 DISPATCHER: Starting worker discovery
11:49:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:49:15 DISPATCHER: Finished worker discovery
11:50:15 DISPATCHER: Starting worker discovery
11:50:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:50:16 DISPATCHER: Finished worker discovery
11:51:16 DISPATCHER: Starting worker discovery
11:51:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:51:16 DISPATCHER: Finished worker discovery
11:52:16 DISPATCHER: Starting worker discovery
11:52:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:52:16 DISPATCHER: Finished worker discovery
11:53:16 DISPATCHER: Starting worker discovery
11:53:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:53:16 DISPATCHER: Finished worker discovery
11:54:16 DISPATCHER: Starting worker discovery
11:54:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:54:16 DISPATCHER: Finished worker discovery
11:54:18 WORKER: done with job (0, 0, 20), trying to register it.
11:54:18 WORKER: registered result for job (0, 0, 20) with dispatcher
11:54:18 DISPATCHER: job (0, 0, 20) finished
11:54:18 DISPATCHER: register_result: lock acquired
11:54:18 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
11:54:18 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.006371282480759643, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.014707708814784224, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 51, 'num_filters_3': 51, 'num_filters_4': 35, 'num_filters_5': 36}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.49550389601293654, 'info': {'music_genre': 0.49550389601293654, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.006371282480759643, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.014707708814784224, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 51, 'num_filters_3': 51, 'num_filters_4': 35, 'num_filters_5': 36}"}}
exception: None

11:54:18 job_callback for (0, 0, 20) started
11:54:18 job_callback for (0, 0, 20) got condition
11:54:18 DISPATCHER: Trying to submit another job.
11:54:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:54:18 Only 3 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
11:54:18 HBMASTER: Trying to run another job!
11:54:18 job_callback for (0, 0, 20) finished
11:54:18 ITERATION: Advancing config (0, 0, 20) to next budget 1200.000000
11:54:18 HBMASTER: schedule new run for iteration 0
11:54:18 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
11:54:18 HBMASTER: submitting job (0, 0, 20) to dispatcher
11:54:18 DISPATCHER: trying to submit job (0, 0, 20)
11:54:18 DISPATCHER: trying to notify the job_runner thread.
11:54:18 HBMASTER: job (0, 0, 20) submitted to dispatcher
11:54:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:54:18 DISPATCHER: Trying to submit another job.
11:54:18 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.30597140382006277952
11:54:18 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
11:54:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:54:18 WORKER: start processing job (0, 0, 20)
11:54:18 WORKER: args: ()
11:54:18 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.006371282480759643, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.014707708814784224, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 51, 'num_filters_3': 51, 'num_filters_4': 35, 'num_filters_5': 36}, 'budget': 1200.0, 'working_directory': '.'}
11:55:16 DISPATCHER: Starting worker discovery
11:55:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:55:16 DISPATCHER: Finished worker discovery
11:56:16 DISPATCHER: Starting worker discovery
11:56:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:56:16 DISPATCHER: Finished worker discovery
11:57:16 DISPATCHER: Starting worker discovery
11:57:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:57:16 DISPATCHER: Finished worker discovery
11:58:16 DISPATCHER: Starting worker discovery
11:58:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:58:16 DISPATCHER: Finished worker discovery
11:59:16 DISPATCHER: Starting worker discovery
11:59:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:59:16 DISPATCHER: Finished worker discovery
12:00:16 DISPATCHER: Starting worker discovery
12:00:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:00:16 DISPATCHER: Finished worker discovery
12:01:16 DISPATCHER: Starting worker discovery
12:01:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:01:16 DISPATCHER: Finished worker discovery
12:02:16 DISPATCHER: Starting worker discovery
12:02:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:02:16 DISPATCHER: Finished worker discovery
12:03:16 DISPATCHER: Starting worker discovery
12:03:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:03:16 DISPATCHER: Finished worker discovery
12:04:16 DISPATCHER: Starting worker discovery
12:04:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:04:16 DISPATCHER: Finished worker discovery
12:05:16 DISPATCHER: Starting worker discovery
12:05:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:05:16 DISPATCHER: Finished worker discovery
12:06:16 DISPATCHER: Starting worker discovery
12:06:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:06:16 DISPATCHER: Finished worker discovery
12:07:16 DISPATCHER: Starting worker discovery
12:07:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:07:16 DISPATCHER: Finished worker discovery
12:08:16 DISPATCHER: Starting worker discovery
12:08:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:08:16 DISPATCHER: Finished worker discovery
12:09:16 DISPATCHER: Starting worker discovery
12:09:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:09:16 DISPATCHER: Finished worker discovery
12:10:16 DISPATCHER: Starting worker discovery
12:10:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:10:16 DISPATCHER: Finished worker discovery
12:11:16 DISPATCHER: Starting worker discovery
12:11:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:11:16 DISPATCHER: Finished worker discovery
12:12:16 DISPATCHER: Starting worker discovery
12:12:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:12:16 DISPATCHER: Finished worker discovery
12:13:16 DISPATCHER: Starting worker discovery
12:13:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:13:16 DISPATCHER: Finished worker discovery
12:14:16 DISPATCHER: Starting worker discovery
12:14:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:14:16 DISPATCHER: Finished worker discovery
12:15:16 DISPATCHER: Starting worker discovery
12:15:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:15:16 DISPATCHER: Finished worker discovery
12:15:35 WORKER: done with job (0, 0, 20), trying to register it.
12:15:35 WORKER: registered result for job (0, 0, 20) with dispatcher
12:15:35 DISPATCHER: job (0, 0, 20) finished
12:15:35 DISPATCHER: register_result: lock acquired
12:15:35 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
12:15:35 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.006371282480759643, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.014707708814784224, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 51, 'num_filters_3': 51, 'num_filters_4': 35, 'num_filters_5': 36}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.41000944980901616, 'info': {'music_genre': 0.41000944980901616, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.006371282480759643, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.014707708814784224, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 51, 'num_filters_3': 51, 'num_filters_4': 35, 'num_filters_5': 36}"}}
exception: None

12:15:35 job_callback for (0, 0, 20) started
12:15:35 job_callback for (0, 0, 20) got condition
12:15:35 DISPATCHER: Trying to submit another job.
12:15:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:15:35 Only 1 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
12:15:35 HBMASTER: Trying to run another job!
12:15:35 job_callback for (0, 0, 20) finished
12:15:35 start sampling a new configuration.
12:15:35 done sampling a new configuration.
12:15:35 HBMASTER: schedule new run for iteration 1
12:15:35 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
12:15:35 HBMASTER: submitting job (1, 0, 0) to dispatcher
12:15:35 DISPATCHER: trying to submit job (1, 0, 0)
12:15:35 DISPATCHER: trying to notify the job_runner thread.
12:15:35 HBMASTER: job (1, 0, 0) submitted to dispatcher
12:15:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:15:35 DISPATCHER: Trying to submit another job.
12:15:35 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
12:15:35 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
12:15:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:15:35 WORKER: start processing job (1, 0, 0)
12:15:35 WORKER: args: ()
12:15:35 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0010363950219962326, 'num_filters_1': 25, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.16977180727162064, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 100, 'num_filters_3': 20, 'num_filters_4': 39}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:16:16 DISPATCHER: Starting worker discovery
12:16:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:16:16 DISPATCHER: Finished worker discovery
12:17:16 DISPATCHER: Starting worker discovery
12:17:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:17:16 DISPATCHER: Finished worker discovery
12:18:16 DISPATCHER: Starting worker discovery
12:18:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:18:16 DISPATCHER: Finished worker discovery
12:18:48 WORKER: done with job (1, 0, 0), trying to register it.
12:18:48 WORKER: registered result for job (1, 0, 0) with dispatcher
12:18:48 DISPATCHER: job (1, 0, 0) finished
12:18:48 DISPATCHER: register_result: lock acquired
12:18:48 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
12:18:48 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0010363950219962326, 'num_filters_1': 25, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.16977180727162064, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 100, 'num_filters_3': 20, 'num_filters_4': 39}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.007935608817250518, 'info': {'music_genre': 0.007935608817250518, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0010363950219962326, 'num_filters_1': 25, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.16977180727162064, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 100, 'num_filters_3': 20, 'num_filters_4': 39}"}}
exception: None

12:18:48 job_callback for (1, 0, 0) started
12:18:48 DISPATCHER: Trying to submit another job.
12:18:48 job_callback for (1, 0, 0) got condition
12:18:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:18:48 Only 10 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:18:48 HBMASTER: Trying to run another job!
12:18:48 job_callback for (1, 0, 0) finished
12:18:48 start sampling a new configuration.
12:18:48 done sampling a new configuration.
12:18:48 HBMASTER: schedule new run for iteration 1
12:18:48 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
12:18:48 HBMASTER: submitting job (1, 0, 1) to dispatcher
12:18:48 DISPATCHER: trying to submit job (1, 0, 1)
12:18:48 DISPATCHER: trying to notify the job_runner thread.
12:18:48 HBMASTER: job (1, 0, 1) submitted to dispatcher
12:18:48 DISPATCHER: Trying to submit another job.
12:18:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:18:48 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
12:18:48 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
12:18:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:18:48 WORKER: start processing job (1, 0, 1)
12:18:48 WORKER: args: ()
12:18:48 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.002008081063629931, 'num_filters_1': 43, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.13690957320224234, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 73, 'num_filters_3': 21, 'num_filters_4': 53, 'num_filters_5': 60}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:19:16 DISPATCHER: Starting worker discovery
12:19:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:19:16 DISPATCHER: Finished worker discovery
12:20:16 DISPATCHER: Starting worker discovery
12:20:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:20:16 DISPATCHER: Finished worker discovery
12:21:16 DISPATCHER: Starting worker discovery
12:21:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:21:16 DISPATCHER: Finished worker discovery
12:22:01 WORKER: done with job (1, 0, 1), trying to register it.
12:22:01 WORKER: registered result for job (1, 0, 1) with dispatcher
12:22:01 DISPATCHER: job (1, 0, 1) finished
12:22:01 DISPATCHER: register_result: lock acquired
12:22:01 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
12:22:01 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.002008081063629931, 'num_filters_1': 43, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.13690957320224234, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 73, 'num_filters_3': 21, 'num_filters_4': 53, 'num_filters_5': 60}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.09446763216214775, 'info': {'music_genre': 0.09446763216214775, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.002008081063629931, 'num_filters_1': 43, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.13690957320224234, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 73, 'num_filters_3': 21, 'num_filters_4': 53, 'num_filters_5': 60}"}}
exception: None

12:22:01 job_callback for (1, 0, 1) started
12:22:01 DISPATCHER: Trying to submit another job.
12:22:01 job_callback for (1, 0, 1) got condition
12:22:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:22:01 Only 11 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:22:01 HBMASTER: Trying to run another job!
12:22:01 job_callback for (1, 0, 1) finished
12:22:01 start sampling a new configuration.
12:22:01 done sampling a new configuration.
12:22:01 HBMASTER: schedule new run for iteration 1
12:22:01 HBMASTER: trying submitting job (1, 0, 2) to dispatcher
12:22:01 HBMASTER: submitting job (1, 0, 2) to dispatcher
12:22:01 DISPATCHER: trying to submit job (1, 0, 2)
12:22:01 DISPATCHER: trying to notify the job_runner thread.
12:22:01 HBMASTER: job (1, 0, 2) submitted to dispatcher
12:22:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:22:01 DISPATCHER: Trying to submit another job.
12:22:01 DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
12:22:01 DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
12:22:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:22:01 WORKER: start processing job (1, 0, 2)
12:22:01 WORKER: args: ()
12:22:01 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.005800881826276337, 'num_filters_1': 84, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.01366050317754097, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 104, 'num_filters_3': 25}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:22:16 DISPATCHER: Starting worker discovery
12:22:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:22:16 DISPATCHER: Finished worker discovery
12:23:16 DISPATCHER: Starting worker discovery
12:23:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:23:16 DISPATCHER: Finished worker discovery
12:24:16 DISPATCHER: Starting worker discovery
12:24:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:24:16 DISPATCHER: Finished worker discovery
12:25:13 WORKER: done with job (1, 0, 2), trying to register it.
12:25:13 WORKER: registered result for job (1, 0, 2) with dispatcher
12:25:13 DISPATCHER: job (1, 0, 2) finished
12:25:13 DISPATCHER: register_result: lock acquired
12:25:13 DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
12:25:13 job_id: (1, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.005800881826276337, 'num_filters_1': 84, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.01366050317754097, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 104, 'num_filters_3': 25}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2781108211133424, 'info': {'music_genre': 0.2781108211133424, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.005800881826276337, 'num_filters_1': 84, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.01366050317754097, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 104, 'num_filters_3': 25}"}}
exception: None

12:25:13 job_callback for (1, 0, 2) started
12:25:13 DISPATCHER: Trying to submit another job.
12:25:13 job_callback for (1, 0, 2) got condition
12:25:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:25:13 Only 12 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:25:13 HBMASTER: Trying to run another job!
12:25:13 job_callback for (1, 0, 2) finished
12:25:13 start sampling a new configuration.
12:25:13 done sampling a new configuration.
12:25:13 HBMASTER: schedule new run for iteration 1
12:25:13 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
12:25:13 HBMASTER: submitting job (1, 0, 3) to dispatcher
12:25:13 DISPATCHER: trying to submit job (1, 0, 3)
12:25:13 DISPATCHER: trying to notify the job_runner thread.
12:25:13 HBMASTER: job (1, 0, 3) submitted to dispatcher
12:25:13 DISPATCHER: Trying to submit another job.
12:25:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:25:13 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
12:25:13 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
12:25:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:25:13 WORKER: start processing job (1, 0, 3)
12:25:13 WORKER: args: ()
12:25:13 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002883734141881324, 'num_filters_1': 94, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.07076236578632925, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 17, 'num_filters_3': 26}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:25:16 DISPATCHER: Starting worker discovery
12:25:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:25:16 DISPATCHER: Finished worker discovery
12:26:16 DISPATCHER: Starting worker discovery
12:26:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:26:16 DISPATCHER: Finished worker discovery
12:27:16 DISPATCHER: Starting worker discovery
12:27:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:27:16 DISPATCHER: Finished worker discovery
12:28:16 DISPATCHER: Starting worker discovery
12:28:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:28:16 DISPATCHER: Finished worker discovery
12:28:25 WORKER: done with job (1, 0, 3), trying to register it.
12:28:25 WORKER: registered result for job (1, 0, 3) with dispatcher
12:28:25 DISPATCHER: job (1, 0, 3) finished
12:28:25 DISPATCHER: register_result: lock acquired
12:28:25 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
12:28:25 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002883734141881324, 'num_filters_1': 94, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.07076236578632925, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 17, 'num_filters_3': 26}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.25474959938309244, 'info': {'music_genre': 0.25474959938309244, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002883734141881324, 'num_filters_1': 94, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.07076236578632925, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 17, 'num_filters_3': 26}"}}
exception: None

12:28:25 job_callback for (1, 0, 3) started
12:28:25 DISPATCHER: Trying to submit another job.
12:28:25 job_callback for (1, 0, 3) got condition
12:28:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:28:25 Only 13 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:28:25 HBMASTER: Trying to run another job!
12:28:25 job_callback for (1, 0, 3) finished
12:28:25 start sampling a new configuration.
12:28:25 done sampling a new configuration.
12:28:25 HBMASTER: schedule new run for iteration 1
12:28:25 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
12:28:25 HBMASTER: submitting job (1, 0, 4) to dispatcher
12:28:25 DISPATCHER: trying to submit job (1, 0, 4)
12:28:25 DISPATCHER: trying to notify the job_runner thread.
12:28:25 HBMASTER: job (1, 0, 4) submitted to dispatcher
12:28:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:28:25 DISPATCHER: Trying to submit another job.
12:28:25 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
12:28:25 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
12:28:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:28:25 WORKER: start processing job (1, 0, 4)
12:28:25 WORKER: args: ()
12:28:25 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0022185564900086135, 'num_filters_1': 93, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.12840101900643802}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:29:16 DISPATCHER: Starting worker discovery
12:29:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:29:16 DISPATCHER: Finished worker discovery
12:30:16 DISPATCHER: Starting worker discovery
12:30:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:30:16 DISPATCHER: Finished worker discovery
12:31:16 DISPATCHER: Starting worker discovery
12:31:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:31:16 DISPATCHER: Finished worker discovery
12:31:37 WORKER: done with job (1, 0, 4), trying to register it.
12:31:37 WORKER: registered result for job (1, 0, 4) with dispatcher
12:31:37 DISPATCHER: job (1, 0, 4) finished
12:31:37 DISPATCHER: register_result: lock acquired
12:31:37 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
12:31:37 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0022185564900086135, 'num_filters_1': 93, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.12840101900643802}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3769496388102964, 'info': {'music_genre': 0.3769496388102964, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0022185564900086135, 'num_filters_1': 93, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.12840101900643802}"}}
exception: None

12:31:37 job_callback for (1, 0, 4) started
12:31:37 DISPATCHER: Trying to submit another job.
12:31:37 job_callback for (1, 0, 4) got condition
12:31:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:31:37 Only 14 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:31:37 HBMASTER: Trying to run another job!
12:31:37 job_callback for (1, 0, 4) finished
12:31:37 start sampling a new configuration.
12:31:37 done sampling a new configuration.
12:31:37 HBMASTER: schedule new run for iteration 1
12:31:37 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
12:31:37 HBMASTER: submitting job (1, 0, 5) to dispatcher
12:31:37 DISPATCHER: trying to submit job (1, 0, 5)
12:31:37 DISPATCHER: trying to notify the job_runner thread.
12:31:37 HBMASTER: job (1, 0, 5) submitted to dispatcher
12:31:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:31:37 DISPATCHER: Trying to submit another job.
12:31:37 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952
12:31:37 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
12:31:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:31:37 WORKER: start processing job (1, 0, 5)
12:31:37 WORKER: args: ()
12:31:37 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.010552240008737168, 'num_filters_1': 54, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.04125119615375563, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 22, 'num_filters_3': 84, 'num_filters_4': 128}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:32:16 DISPATCHER: Starting worker discovery
12:32:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:32:16 DISPATCHER: Finished worker discovery
12:33:16 DISPATCHER: Starting worker discovery
12:33:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:33:16 DISPATCHER: Finished worker discovery
12:34:16 DISPATCHER: Starting worker discovery
12:34:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:34:16 DISPATCHER: Finished worker discovery
12:34:50 WORKER: done with job (1, 0, 5), trying to register it.
12:34:50 WORKER: registered result for job (1, 0, 5) with dispatcher
12:34:50 DISPATCHER: job (1, 0, 5) finished
12:34:50 DISPATCHER: register_result: lock acquired
12:34:50 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
12:34:50 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.010552240008737168, 'num_filters_1': 54, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.04125119615375563, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 22, 'num_filters_3': 84, 'num_filters_4': 128}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.010552240008737168, 'num_filters_1': 54, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.04125119615375563, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 22, 'num_filters_3': 84, 'num_filters_4': 128}"}}
exception: None

12:34:50 job_callback for (1, 0, 5) started
12:34:50 DISPATCHER: Trying to submit another job.
12:34:50 job_callback for (1, 0, 5) got condition
12:34:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:34:50 Only 15 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:34:50 HBMASTER: Trying to run another job!
12:34:50 job_callback for (1, 0, 5) finished
12:34:50 start sampling a new configuration.
12:34:50 done sampling a new configuration.
12:34:50 HBMASTER: schedule new run for iteration 1
12:34:50 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
12:34:50 HBMASTER: submitting job (1, 0, 6) to dispatcher
12:34:50 DISPATCHER: trying to submit job (1, 0, 6)
12:34:50 DISPATCHER: trying to notify the job_runner thread.
12:34:50 HBMASTER: job (1, 0, 6) submitted to dispatcher
12:34:50 DISPATCHER: Trying to submit another job.
12:34:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:34:50 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952
12:34:50 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
12:34:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:34:50 WORKER: start processing job (1, 0, 6)
12:34:50 WORKER: args: ()
12:34:50 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0013049726997249817, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.08311629900534563, 'kernel_size_2': 3, 'num_filters_2': 21}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:35:16 DISPATCHER: Starting worker discovery
12:35:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:35:16 DISPATCHER: Finished worker discovery
12:36:16 DISPATCHER: Starting worker discovery
12:36:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:36:16 DISPATCHER: Finished worker discovery
12:37:16 DISPATCHER: Starting worker discovery
12:37:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:37:16 DISPATCHER: Finished worker discovery
12:38:05 WORKER: done with job (1, 0, 6), trying to register it.
12:38:05 WORKER: registered result for job (1, 0, 6) with dispatcher
12:38:05 DISPATCHER: job (1, 0, 6) finished
12:38:05 DISPATCHER: register_result: lock acquired
12:38:05 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
12:38:05 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0013049726997249817, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.08311629900534563, 'kernel_size_2': 3, 'num_filters_2': 21}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.297019264300393, 'info': {'music_genre': 0.297019264300393, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0013049726997249817, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.08311629900534563, 'kernel_size_2': 3, 'num_filters_2': 21}"}}
exception: None

12:38:05 job_callback for (1, 0, 6) started
12:38:05 DISPATCHER: Trying to submit another job.
12:38:05 job_callback for (1, 0, 6) got condition
12:38:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:38:05 Only 16 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:38:05 HBMASTER: Trying to run another job!
12:38:05 job_callback for (1, 0, 6) finished
12:38:05 start sampling a new configuration.
12:38:05 done sampling a new configuration.
12:38:05 HBMASTER: schedule new run for iteration 1
12:38:05 HBMASTER: trying submitting job (1, 0, 7) to dispatcher
12:38:05 HBMASTER: submitting job (1, 0, 7) to dispatcher
12:38:05 DISPATCHER: trying to submit job (1, 0, 7)
12:38:05 DISPATCHER: trying to notify the job_runner thread.
12:38:05 HBMASTER: job (1, 0, 7) submitted to dispatcher
12:38:05 DISPATCHER: Trying to submit another job.
12:38:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:38:05 DISPATCHER: starting job (1, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952
12:38:05 DISPATCHER: job (1, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
12:38:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:38:05 WORKER: start processing job (1, 0, 7)
12:38:05 WORKER: args: ()
12:38:05 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.022262958377086056, 'num_filters_1': 47, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.044129274054851744, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 28, 'num_filters_3': 36, 'num_filters_4': 67}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:38:16 DISPATCHER: Starting worker discovery
12:38:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:38:16 DISPATCHER: Finished worker discovery
12:39:16 DISPATCHER: Starting worker discovery
12:39:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:39:16 DISPATCHER: Finished worker discovery
12:40:16 DISPATCHER: Starting worker discovery
12:40:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:40:16 DISPATCHER: Finished worker discovery
12:41:16 DISPATCHER: Starting worker discovery
12:41:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:41:16 DISPATCHER: Finished worker discovery
12:41:17 WORKER: done with job (1, 0, 7), trying to register it.
12:41:17 WORKER: registered result for job (1, 0, 7) with dispatcher
12:41:17 DISPATCHER: job (1, 0, 7) finished
12:41:17 DISPATCHER: register_result: lock acquired
12:41:17 DISPATCHER: job (1, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
12:41:17 job_id: (1, 0, 7)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.022262958377086056, 'num_filters_1': 47, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.044129274054851744, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 28, 'num_filters_3': 36, 'num_filters_4': 67}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.022262958377086056, 'num_filters_1': 47, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.044129274054851744, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 28, 'num_filters_3': 36, 'num_filters_4': 67}"}}
exception: None

12:41:17 job_callback for (1, 0, 7) started
12:41:17 DISPATCHER: Trying to submit another job.
12:41:17 job_callback for (1, 0, 7) got condition
12:41:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:41:17 HBMASTER: Trying to run another job!
12:41:17 job_callback for (1, 0, 7) finished
12:41:17 start sampling a new configuration.
12:41:17 done sampling a new configuration.
12:41:17 HBMASTER: schedule new run for iteration 1
12:41:17 HBMASTER: trying submitting job (1, 0, 8) to dispatcher
12:41:17 HBMASTER: submitting job (1, 0, 8) to dispatcher
12:41:17 DISPATCHER: trying to submit job (1, 0, 8)
12:41:17 DISPATCHER: trying to notify the job_runner thread.
12:41:17 HBMASTER: job (1, 0, 8) submitted to dispatcher
12:41:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:41:17 DISPATCHER: Trying to submit another job.
12:41:17 DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952
12:41:17 DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
12:41:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:41:17 WORKER: start processing job (1, 0, 8)
12:41:17 WORKER: args: ()
12:41:17 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0015735000735544703, 'num_filters_1': 108, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.10154150415119802, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 27, 'num_filters_3': 43, 'num_filters_4': 19, 'num_filters_5': 121}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:42:16 DISPATCHER: Starting worker discovery
12:42:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:42:16 DISPATCHER: Finished worker discovery
12:43:16 DISPATCHER: Starting worker discovery
12:43:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:43:16 DISPATCHER: Finished worker discovery
12:44:16 DISPATCHER: Starting worker discovery
12:44:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:44:16 DISPATCHER: Finished worker discovery
12:44:29 WORKER: done with job (1, 0, 8), trying to register it.
12:44:29 WORKER: registered result for job (1, 0, 8) with dispatcher
12:44:29 DISPATCHER: job (1, 0, 8) finished
12:44:29 DISPATCHER: register_result: lock acquired
12:44:29 DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
12:44:29 job_id: (1, 0, 8)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0015735000735544703, 'num_filters_1': 108, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.10154150415119802, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 27, 'num_filters_3': 43, 'num_filters_4': 19, 'num_filters_5': 121}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.13738542874878912, 'info': {'music_genre': 0.13738542874878912, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0015735000735544703, 'num_filters_1': 108, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.10154150415119802, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 27, 'num_filters_3': 43, 'num_filters_4': 19, 'num_filters_5': 121}"}}
exception: None

12:44:29 job_callback for (1, 0, 8) started
12:44:29 DISPATCHER: Trying to submit another job.
12:44:29 job_callback for (1, 0, 8) got condition
12:44:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:44:29 HBMASTER: Trying to run another job!
12:44:29 job_callback for (1, 0, 8) finished
12:44:29 ITERATION: Advancing config (1, 0, 2) to next budget 400.000000
12:44:29 ITERATION: Advancing config (1, 0, 4) to next budget 400.000000
12:44:29 ITERATION: Advancing config (1, 0, 6) to next budget 400.000000
12:44:29 HBMASTER: schedule new run for iteration 1
12:44:29 HBMASTER: trying submitting job (1, 0, 2) to dispatcher
12:44:29 HBMASTER: submitting job (1, 0, 2) to dispatcher
12:44:29 DISPATCHER: trying to submit job (1, 0, 2)
12:44:29 DISPATCHER: trying to notify the job_runner thread.
12:44:29 HBMASTER: job (1, 0, 2) submitted to dispatcher
12:44:29 DISPATCHER: Trying to submit another job.
12:44:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:44:29 DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
12:44:29 DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
12:44:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:44:29 WORKER: start processing job (1, 0, 2)
12:44:29 WORKER: args: ()
12:44:29 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.005800881826276337, 'num_filters_1': 84, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.01366050317754097, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 104, 'num_filters_3': 25}, 'budget': 400.0, 'working_directory': '.'}
12:45:16 DISPATCHER: Starting worker discovery
12:45:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:45:16 DISPATCHER: Finished worker discovery
12:46:16 DISPATCHER: Starting worker discovery
12:46:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:46:16 DISPATCHER: Finished worker discovery
12:47:16 DISPATCHER: Starting worker discovery
12:47:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:47:16 DISPATCHER: Finished worker discovery
12:48:16 DISPATCHER: Starting worker discovery
12:48:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:48:16 DISPATCHER: Finished worker discovery
12:49:16 DISPATCHER: Starting worker discovery
12:49:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:49:16 DISPATCHER: Finished worker discovery
12:50:16 DISPATCHER: Starting worker discovery
12:50:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:50:16 DISPATCHER: Finished worker discovery
12:51:16 DISPATCHER: Starting worker discovery
12:51:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:51:16 DISPATCHER: Finished worker discovery
12:52:10 WORKER: done with job (1, 0, 2), trying to register it.
12:52:10 WORKER: registered result for job (1, 0, 2) with dispatcher
12:52:10 DISPATCHER: job (1, 0, 2) finished
12:52:10 DISPATCHER: register_result: lock acquired
12:52:10 DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
12:52:10 job_id: (1, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.005800881826276337, 'num_filters_1': 84, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.01366050317754097, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 104, 'num_filters_3': 25}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3009810083569232, 'info': {'music_genre': 0.3009810083569232, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.005800881826276337, 'num_filters_1': 84, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.01366050317754097, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 104, 'num_filters_3': 25}"}}
exception: None

12:52:10 job_callback for (1, 0, 2) started
12:52:10 job_callback for (1, 0, 2) got condition
12:52:10 DISPATCHER: Trying to submit another job.
12:52:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:52:10 Only 4 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
12:52:10 HBMASTER: Trying to run another job!
12:52:10 job_callback for (1, 0, 2) finished
12:52:10 HBMASTER: schedule new run for iteration 1
12:52:10 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
12:52:10 HBMASTER: submitting job (1, 0, 4) to dispatcher
12:52:10 DISPATCHER: trying to submit job (1, 0, 4)
12:52:10 DISPATCHER: trying to notify the job_runner thread.
12:52:10 HBMASTER: job (1, 0, 4) submitted to dispatcher
12:52:10 DISPATCHER: Trying to submit another job.
12:52:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:52:10 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
12:52:10 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
12:52:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:52:10 WORKER: start processing job (1, 0, 4)
12:52:10 WORKER: args: ()
12:52:10 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0022185564900086135, 'num_filters_1': 93, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.12840101900643802}, 'budget': 400.0, 'working_directory': '.'}
12:52:16 DISPATCHER: Starting worker discovery
12:52:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:52:16 DISPATCHER: Finished worker discovery
12:53:16 DISPATCHER: Starting worker discovery
12:53:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:53:16 DISPATCHER: Finished worker discovery
12:54:16 DISPATCHER: Starting worker discovery
12:54:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:54:16 DISPATCHER: Finished worker discovery
12:55:16 DISPATCHER: Starting worker discovery
12:55:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:55:16 DISPATCHER: Finished worker discovery
12:56:16 DISPATCHER: Starting worker discovery
12:56:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:56:16 DISPATCHER: Finished worker discovery
12:57:16 DISPATCHER: Starting worker discovery
12:57:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:57:16 DISPATCHER: Finished worker discovery
12:58:16 DISPATCHER: Starting worker discovery
12:58:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:58:16 DISPATCHER: Finished worker discovery
12:59:16 DISPATCHER: Starting worker discovery
12:59:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:59:16 DISPATCHER: Finished worker discovery
12:59:51 WORKER: done with job (1, 0, 4), trying to register it.
12:59:51 WORKER: registered result for job (1, 0, 4) with dispatcher
12:59:51 DISPATCHER: job (1, 0, 4) finished
12:59:51 DISPATCHER: register_result: lock acquired
12:59:51 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
12:59:51 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0022185564900086135, 'num_filters_1': 93, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.12840101900643802}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.2899790669690803, 'info': {'music_genre': 0.2899790669690803, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0022185564900086135, 'num_filters_1': 93, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.12840101900643802}"}}
exception: None

12:59:51 job_callback for (1, 0, 4) started
12:59:51 job_callback for (1, 0, 4) got condition
12:59:51 DISPATCHER: Trying to submit another job.
12:59:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:59:51 Only 5 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
12:59:51 HBMASTER: Trying to run another job!
12:59:51 job_callback for (1, 0, 4) finished
12:59:51 HBMASTER: schedule new run for iteration 1
12:59:51 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
12:59:51 HBMASTER: submitting job (1, 0, 6) to dispatcher
12:59:51 DISPATCHER: trying to submit job (1, 0, 6)
12:59:51 DISPATCHER: trying to notify the job_runner thread.
12:59:51 HBMASTER: job (1, 0, 6) submitted to dispatcher
12:59:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:59:51 DISPATCHER: Trying to submit another job.
12:59:51 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952
12:59:51 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
12:59:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:59:51 WORKER: start processing job (1, 0, 6)
12:59:51 WORKER: args: ()
12:59:51 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0013049726997249817, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.08311629900534563, 'kernel_size_2': 3, 'num_filters_2': 21}, 'budget': 400.0, 'working_directory': '.'}
13:00:16 DISPATCHER: Starting worker discovery
13:00:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:00:16 DISPATCHER: Finished worker discovery
13:01:16 DISPATCHER: Starting worker discovery
13:01:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:01:16 DISPATCHER: Finished worker discovery
13:02:16 DISPATCHER: Starting worker discovery
13:02:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:02:16 DISPATCHER: Finished worker discovery
13:03:16 DISPATCHER: Starting worker discovery
13:03:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:03:16 DISPATCHER: Finished worker discovery
13:04:16 DISPATCHER: Starting worker discovery
13:04:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:04:16 DISPATCHER: Finished worker discovery
13:05:16 DISPATCHER: Starting worker discovery
13:05:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:05:16 DISPATCHER: Finished worker discovery
13:06:16 DISPATCHER: Starting worker discovery
13:06:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:06:16 DISPATCHER: Finished worker discovery
13:07:16 DISPATCHER: Starting worker discovery
13:07:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:07:16 DISPATCHER: Finished worker discovery
13:07:40 WORKER: done with job (1, 0, 6), trying to register it.
13:07:40 WORKER: registered result for job (1, 0, 6) with dispatcher
13:07:40 DISPATCHER: job (1, 0, 6) finished
13:07:40 DISPATCHER: register_result: lock acquired
13:07:40 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
13:07:40 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0013049726997249817, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.08311629900534563, 'kernel_size_2': 3, 'num_filters_2': 21}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.2757957313590771, 'info': {'music_genre': 0.2757957313590771, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0013049726997249817, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.08311629900534563, 'kernel_size_2': 3, 'num_filters_2': 21}"}}
exception: None

13:07:40 job_callback for (1, 0, 6) started
13:07:40 job_callback for (1, 0, 6) got condition
13:07:40 DISPATCHER: Trying to submit another job.
13:07:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:07:40 Only 6 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
13:07:40 HBMASTER: Trying to run another job!
13:07:40 job_callback for (1, 0, 6) finished
13:07:40 ITERATION: Advancing config (1, 0, 2) to next budget 1200.000000
13:07:40 HBMASTER: schedule new run for iteration 1
13:07:40 HBMASTER: trying submitting job (1, 0, 2) to dispatcher
13:07:40 HBMASTER: submitting job (1, 0, 2) to dispatcher
13:07:40 DISPATCHER: trying to submit job (1, 0, 2)
13:07:40 DISPATCHER: trying to notify the job_runner thread.
13:07:40 HBMASTER: job (1, 0, 2) submitted to dispatcher
13:07:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:07:40 DISPATCHER: Trying to submit another job.
13:07:40 DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:07:40 DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:07:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:07:40 WORKER: start processing job (1, 0, 2)
13:07:40 WORKER: args: ()
13:07:40 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.005800881826276337, 'num_filters_1': 84, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.01366050317754097, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 104, 'num_filters_3': 25}, 'budget': 1200.0, 'working_directory': '.'}
13:08:16 DISPATCHER: Starting worker discovery
13:08:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:08:16 DISPATCHER: Finished worker discovery
13:09:16 DISPATCHER: Starting worker discovery
13:09:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:09:16 DISPATCHER: Finished worker discovery
13:10:16 DISPATCHER: Starting worker discovery
13:10:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:10:16 DISPATCHER: Finished worker discovery
13:11:16 DISPATCHER: Starting worker discovery
13:11:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:11:16 DISPATCHER: Finished worker discovery
13:12:16 DISPATCHER: Starting worker discovery
13:12:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:12:16 DISPATCHER: Finished worker discovery
13:13:16 DISPATCHER: Starting worker discovery
13:13:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:13:16 DISPATCHER: Finished worker discovery
13:14:16 DISPATCHER: Starting worker discovery
13:14:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:14:16 DISPATCHER: Finished worker discovery
13:15:16 DISPATCHER: Starting worker discovery
13:15:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:15:16 DISPATCHER: Finished worker discovery
13:16:16 DISPATCHER: Starting worker discovery
13:16:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:16:16 DISPATCHER: Finished worker discovery
13:17:16 DISPATCHER: Starting worker discovery
13:17:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:17:16 DISPATCHER: Finished worker discovery
13:18:16 DISPATCHER: Starting worker discovery
13:18:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:18:16 DISPATCHER: Finished worker discovery
13:19:16 DISPATCHER: Starting worker discovery
13:19:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:19:16 DISPATCHER: Finished worker discovery
13:20:16 DISPATCHER: Starting worker discovery
13:20:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:20:16 DISPATCHER: Finished worker discovery
13:21:16 DISPATCHER: Starting worker discovery
13:21:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:21:16 DISPATCHER: Finished worker discovery
13:22:16 DISPATCHER: Starting worker discovery
13:22:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:22:16 DISPATCHER: Finished worker discovery
13:23:16 DISPATCHER: Starting worker discovery
13:23:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:23:16 DISPATCHER: Finished worker discovery
13:24:16 DISPATCHER: Starting worker discovery
13:24:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:24:16 DISPATCHER: Finished worker discovery
13:25:16 DISPATCHER: Starting worker discovery
13:25:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:25:16 DISPATCHER: Finished worker discovery
13:26:16 DISPATCHER: Starting worker discovery
13:26:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:26:16 DISPATCHER: Finished worker discovery
13:27:16 DISPATCHER: Starting worker discovery
13:27:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:27:16 DISPATCHER: Finished worker discovery
13:28:16 DISPATCHER: Starting worker discovery
13:28:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:28:17 DISPATCHER: Finished worker discovery
13:28:50 WORKER: done with job (1, 0, 2), trying to register it.
13:28:50 WORKER: registered result for job (1, 0, 2) with dispatcher
13:28:50 DISPATCHER: job (1, 0, 2) finished
13:28:50 DISPATCHER: register_result: lock acquired
13:28:50 DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
13:28:50 job_id: (1, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.005800881826276337, 'num_filters_1': 84, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.01366050317754097, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 104, 'num_filters_3': 25}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.31438562517042107, 'info': {'music_genre': 0.31438562517042107, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.005800881826276337, 'num_filters_1': 84, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.01366050317754097, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 104, 'num_filters_3': 25}"}}
exception: None

13:28:50 job_callback for (1, 0, 2) started
13:28:50 job_callback for (1, 0, 2) got condition
13:28:50 DISPATCHER: Trying to submit another job.
13:28:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:28:50 Only 2 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
13:28:50 HBMASTER: Trying to run another job!
13:28:50 job_callback for (1, 0, 2) finished
13:28:50 start sampling a new configuration.
13:28:50 done sampling a new configuration.
13:28:50 HBMASTER: schedule new run for iteration 2
13:28:50 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
13:28:50 HBMASTER: submitting job (2, 0, 0) to dispatcher
13:28:50 DISPATCHER: trying to submit job (2, 0, 0)
13:28:50 DISPATCHER: trying to notify the job_runner thread.
13:28:50 HBMASTER: job (2, 0, 0) submitted to dispatcher
13:28:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:28:50 DISPATCHER: Trying to submit another job.
13:28:50 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:28:50 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:28:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:28:50 WORKER: start processing job (2, 0, 0)
13:28:50 WORKER: args: ()
13:28:50 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.003611754932005246, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.08235276763666353, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 58, 'num_filters_3': 24, 'num_filters_4': 64, 'num_filters_5': 97}, 'budget': 400.0, 'working_directory': '.'}
13:29:17 DISPATCHER: Starting worker discovery
13:29:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:29:17 DISPATCHER: Finished worker discovery
13:30:17 DISPATCHER: Starting worker discovery
13:30:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:30:17 DISPATCHER: Finished worker discovery
13:31:17 DISPATCHER: Starting worker discovery
13:31:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:31:17 DISPATCHER: Finished worker discovery
13:32:17 DISPATCHER: Starting worker discovery
13:32:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:32:17 DISPATCHER: Finished worker discovery
13:33:17 DISPATCHER: Starting worker discovery
13:33:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:33:17 DISPATCHER: Finished worker discovery
13:34:17 DISPATCHER: Starting worker discovery
13:34:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:34:17 DISPATCHER: Finished worker discovery
13:35:17 DISPATCHER: Starting worker discovery
13:35:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:35:17 DISPATCHER: Finished worker discovery
13:36:17 DISPATCHER: Starting worker discovery
13:36:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:36:17 DISPATCHER: Finished worker discovery
13:36:37 WORKER: done with job (2, 0, 0), trying to register it.
13:36:37 WORKER: registered result for job (2, 0, 0) with dispatcher
13:36:37 DISPATCHER: job (2, 0, 0) finished
13:36:37 DISPATCHER: register_result: lock acquired
13:36:37 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
13:36:37 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.003611754932005246, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.08235276763666353, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 58, 'num_filters_3': 24, 'num_filters_4': 64, 'num_filters_5': 97}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.003611754932005246, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.08235276763666353, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 58, 'num_filters_3': 24, 'num_filters_4': 64, 'num_filters_5': 97}"}}
exception: None

13:36:37 job_callback for (2, 0, 0) started
13:36:37 DISPATCHER: Trying to submit another job.
13:36:37 job_callback for (2, 0, 0) got condition
13:36:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:36:37 Only 7 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
13:36:37 HBMASTER: Trying to run another job!
13:36:37 job_callback for (2, 0, 0) finished
13:36:37 start sampling a new configuration.
13:36:37 done sampling a new configuration.
13:36:37 HBMASTER: schedule new run for iteration 2
13:36:37 HBMASTER: trying submitting job (2, 0, 1) to dispatcher
13:36:37 HBMASTER: submitting job (2, 0, 1) to dispatcher
13:36:37 DISPATCHER: trying to submit job (2, 0, 1)
13:36:37 DISPATCHER: trying to notify the job_runner thread.
13:36:37 HBMASTER: job (2, 0, 1) submitted to dispatcher
13:36:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:36:37 DISPATCHER: Trying to submit another job.
13:36:37 DISPATCHER: starting job (2, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:36:37 DISPATCHER: job (2, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:36:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:36:37 WORKER: start processing job (2, 0, 1)
13:36:37 WORKER: args: ()
13:36:37 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.007776715310783336, 'num_filters_1': 87, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.017212219231083608, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 24, 'num_filters_3': 115, 'num_filters_4': 47, 'num_filters_5': 53}, 'budget': 400.0, 'working_directory': '.'}
13:37:17 DISPATCHER: Starting worker discovery
13:37:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:37:17 DISPATCHER: Finished worker discovery
13:38:17 DISPATCHER: Starting worker discovery
13:38:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:38:17 DISPATCHER: Finished worker discovery
13:39:17 DISPATCHER: Starting worker discovery
13:39:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:39:17 DISPATCHER: Finished worker discovery
13:40:17 DISPATCHER: Starting worker discovery
13:40:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:40:17 DISPATCHER: Finished worker discovery
13:41:17 DISPATCHER: Starting worker discovery
13:41:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:41:17 DISPATCHER: Finished worker discovery
13:42:17 DISPATCHER: Starting worker discovery
13:42:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:42:17 DISPATCHER: Finished worker discovery
13:43:17 DISPATCHER: Starting worker discovery
13:43:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:43:17 DISPATCHER: Finished worker discovery
13:44:17 WORKER: done with job (2, 0, 1), trying to register it.
13:44:17 WORKER: registered result for job (2, 0, 1) with dispatcher
13:44:17 DISPATCHER: job (2, 0, 1) finished
13:44:17 DISPATCHER: register_result: lock acquired
13:44:17 DISPATCHER: job (2, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
13:44:17 job_id: (2, 0, 1)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.007776715310783336, 'num_filters_1': 87, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.017212219231083608, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 24, 'num_filters_3': 115, 'num_filters_4': 47, 'num_filters_5': 53}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.007776715310783336, 'num_filters_1': 87, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.017212219231083608, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 24, 'num_filters_3': 115, 'num_filters_4': 47, 'num_filters_5': 53}"}}
exception: None

13:44:17 job_callback for (2, 0, 1) started
13:44:17 DISPATCHER: Trying to submit another job.
13:44:17 job_callback for (2, 0, 1) got condition
13:44:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:44:17 Only 8 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
13:44:17 HBMASTER: Trying to run another job!
13:44:17 job_callback for (2, 0, 1) finished
13:44:17 start sampling a new configuration.
13:44:17 done sampling a new configuration.
13:44:17 HBMASTER: schedule new run for iteration 2
13:44:17 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
13:44:17 HBMASTER: submitting job (2, 0, 2) to dispatcher
13:44:17 DISPATCHER: trying to submit job (2, 0, 2)
13:44:17 DISPATCHER: trying to notify the job_runner thread.
13:44:17 HBMASTER: job (2, 0, 2) submitted to dispatcher
13:44:17 DISPATCHER: Trying to submit another job.
13:44:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:44:17 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:44:17 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:44:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:44:17 WORKER: start processing job (2, 0, 2)
13:44:17 WORKER: args: ()
13:44:17 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.08777004252784679, 'num_filters_1': 79, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.1078691864194823}, 'budget': 400.0, 'working_directory': '.'}
13:44:17 DISPATCHER: Starting worker discovery
13:44:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:44:17 DISPATCHER: Finished worker discovery
13:45:17 DISPATCHER: Starting worker discovery
13:45:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:45:17 DISPATCHER: Finished worker discovery
13:46:17 DISPATCHER: Starting worker discovery
13:46:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:46:17 DISPATCHER: Finished worker discovery
13:47:17 DISPATCHER: Starting worker discovery
13:47:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:47:17 DISPATCHER: Finished worker discovery
13:48:17 DISPATCHER: Starting worker discovery
13:48:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:48:17 DISPATCHER: Finished worker discovery
13:49:17 DISPATCHER: Starting worker discovery
13:49:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:49:17 DISPATCHER: Finished worker discovery
13:50:17 DISPATCHER: Starting worker discovery
13:50:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:50:17 DISPATCHER: Finished worker discovery
13:51:17 DISPATCHER: Starting worker discovery
13:51:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:51:17 DISPATCHER: Finished worker discovery
13:51:55 WORKER: done with job (2, 0, 2), trying to register it.
13:51:55 WORKER: registered result for job (2, 0, 2) with dispatcher
13:51:55 DISPATCHER: job (2, 0, 2) finished
13:51:55 DISPATCHER: register_result: lock acquired
13:51:55 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
13:51:55 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.08777004252784679, 'num_filters_1': 79, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.1078691864194823}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.2494713025658145, 'info': {'music_genre': 0.2494713025658145, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.08777004252784679, 'num_filters_1': 79, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.1078691864194823}"}}
exception: None

13:51:55 job_callback for (2, 0, 2) started
13:51:55 DISPATCHER: Trying to submit another job.
13:51:55 job_callback for (2, 0, 2) got condition
13:51:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:51:55 Only 9 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
13:51:55 HBMASTER: Trying to run another job!
13:51:55 job_callback for (2, 0, 2) finished
13:51:55 start sampling a new configuration.
13:51:55 done sampling a new configuration.
13:51:55 HBMASTER: schedule new run for iteration 2
13:51:55 HBMASTER: trying submitting job (2, 0, 3) to dispatcher
13:51:55 HBMASTER: submitting job (2, 0, 3) to dispatcher
13:51:55 DISPATCHER: trying to submit job (2, 0, 3)
13:51:55 DISPATCHER: trying to notify the job_runner thread.
13:51:55 HBMASTER: job (2, 0, 3) submitted to dispatcher
13:51:55 DISPATCHER: Trying to submit another job.
13:51:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:51:55 DISPATCHER: starting job (2, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:51:55 DISPATCHER: job (2, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:51:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:51:55 WORKER: start processing job (2, 0, 3)
13:51:55 WORKER: args: ()
13:51:55 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.002273610285121588, 'num_filters_1': 65, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.02500776922258591, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 20, 'num_filters_3': 55}, 'budget': 400.0, 'working_directory': '.'}
13:52:17 DISPATCHER: Starting worker discovery
13:52:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:52:17 DISPATCHER: Finished worker discovery
13:53:17 DISPATCHER: Starting worker discovery
13:53:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:53:17 DISPATCHER: Finished worker discovery
13:54:17 DISPATCHER: Starting worker discovery
13:54:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:54:17 DISPATCHER: Finished worker discovery
13:55:17 DISPATCHER: Starting worker discovery
13:55:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:55:17 DISPATCHER: Finished worker discovery
13:56:17 DISPATCHER: Starting worker discovery
13:56:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:56:17 DISPATCHER: Finished worker discovery
13:57:17 DISPATCHER: Starting worker discovery
13:57:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:57:17 DISPATCHER: Finished worker discovery
13:58:17 DISPATCHER: Starting worker discovery
13:58:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:58:17 DISPATCHER: Finished worker discovery
13:59:17 DISPATCHER: Starting worker discovery
13:59:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:59:17 DISPATCHER: Finished worker discovery
13:59:35 WORKER: done with job (2, 0, 3), trying to register it.
13:59:35 WORKER: registered result for job (2, 0, 3) with dispatcher
13:59:35 DISPATCHER: job (2, 0, 3) finished
13:59:35 DISPATCHER: register_result: lock acquired
13:59:35 DISPATCHER: job (2, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
13:59:35 job_id: (2, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.002273610285121588, 'num_filters_1': 65, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.02500776922258591, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 20, 'num_filters_3': 55}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.37357036203653227, 'info': {'music_genre': 0.37357036203653227, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.002273610285121588, 'num_filters_1': 65, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.02500776922258591, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 20, 'num_filters_3': 55}"}}
exception: None

13:59:35 job_callback for (2, 0, 3) started
13:59:35 DISPATCHER: Trying to submit another job.
13:59:35 job_callback for (2, 0, 3) got condition
13:59:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:59:35 Only 10 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
13:59:35 HBMASTER: Trying to run another job!
13:59:35 job_callback for (2, 0, 3) finished
13:59:35 start sampling a new configuration.
13:59:35 done sampling a new configuration.
13:59:35 HBMASTER: schedule new run for iteration 2
13:59:35 HBMASTER: trying submitting job (2, 0, 4) to dispatcher
13:59:35 HBMASTER: submitting job (2, 0, 4) to dispatcher
13:59:35 DISPATCHER: trying to submit job (2, 0, 4)
13:59:35 DISPATCHER: trying to notify the job_runner thread.
13:59:35 HBMASTER: job (2, 0, 4) submitted to dispatcher
13:59:35 DISPATCHER: Trying to submit another job.
13:59:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:59:35 DISPATCHER: starting job (2, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:59:35 DISPATCHER: job (2, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:59:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:59:35 WORKER: start processing job (2, 0, 4)
13:59:35 WORKER: args: ()
13:59:35 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.05405562267058222, 'num_filters_1': 121, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.13517669465821708, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 19, 'num_filters_3': 20, 'num_filters_4': 43}, 'budget': 400.0, 'working_directory': '.'}
14:00:17 DISPATCHER: Starting worker discovery
14:00:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:00:17 DISPATCHER: Finished worker discovery
14:01:17 DISPATCHER: Starting worker discovery
14:01:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:01:17 DISPATCHER: Finished worker discovery
14:02:17 DISPATCHER: Starting worker discovery
14:02:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:02:17 DISPATCHER: Finished worker discovery
14:03:17 DISPATCHER: Starting worker discovery
14:03:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:03:17 DISPATCHER: Finished worker discovery
14:04:17 DISPATCHER: Starting worker discovery
14:04:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:04:17 DISPATCHER: Finished worker discovery
14:05:17 DISPATCHER: Starting worker discovery
14:05:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:05:17 DISPATCHER: Finished worker discovery
14:06:17 DISPATCHER: Starting worker discovery
14:06:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:06:17 DISPATCHER: Finished worker discovery
14:07:15 WORKER: done with job (2, 0, 4), trying to register it.
14:07:15 WORKER: registered result for job (2, 0, 4) with dispatcher
14:07:15 DISPATCHER: job (2, 0, 4) finished
14:07:15 DISPATCHER: register_result: lock acquired
14:07:15 DISPATCHER: job (2, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
14:07:15 job_id: (2, 0, 4)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.05405562267058222, 'num_filters_1': 121, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.13517669465821708, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 19, 'num_filters_3': 20, 'num_filters_4': 43}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.1371447124926539, 'info': {'music_genre': 0.1371447124926539, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.05405562267058222, 'num_filters_1': 121, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.13517669465821708, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 19, 'num_filters_3': 20, 'num_filters_4': 43}"}}
exception: None

14:07:15 job_callback for (2, 0, 4) started
14:07:15 job_callback for (2, 0, 4) got condition
14:07:15 DISPATCHER: Trying to submit another job.
14:07:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:07:15 Only 11 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
14:07:15 HBMASTER: Trying to run another job!
14:07:15 job_callback for (2, 0, 4) finished
14:07:15 start sampling a new configuration.
14:07:15 done sampling a new configuration.
14:07:15 HBMASTER: schedule new run for iteration 2
14:07:15 HBMASTER: trying submitting job (2, 0, 5) to dispatcher
14:07:15 HBMASTER: submitting job (2, 0, 5) to dispatcher
14:07:15 DISPATCHER: trying to submit job (2, 0, 5)
14:07:15 DISPATCHER: trying to notify the job_runner thread.
14:07:15 HBMASTER: job (2, 0, 5) submitted to dispatcher
14:07:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:07:15 DISPATCHER: Trying to submit another job.
14:07:15 DISPATCHER: starting job (2, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:07:15 DISPATCHER: job (2, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:07:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:07:15 WORKER: start processing job (2, 0, 5)
14:07:15 WORKER: args: ()
14:07:15 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.012655190644689167, 'num_filters_1': 44, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.013495443229008513, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 63, 'num_filters_3': 19, 'num_filters_4': 94, 'num_filters_5': 28}, 'budget': 400.0, 'working_directory': '.'}
14:07:17 DISPATCHER: Starting worker discovery
14:07:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:07:17 DISPATCHER: Finished worker discovery
14:08:17 DISPATCHER: Starting worker discovery
14:08:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:08:17 DISPATCHER: Finished worker discovery
14:09:17 DISPATCHER: Starting worker discovery
14:09:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:09:17 DISPATCHER: Finished worker discovery
14:10:17 DISPATCHER: Starting worker discovery
14:10:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:10:17 DISPATCHER: Finished worker discovery
14:11:17 DISPATCHER: Starting worker discovery
14:11:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:11:17 DISPATCHER: Finished worker discovery
14:12:17 DISPATCHER: Starting worker discovery
14:12:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:12:17 DISPATCHER: Finished worker discovery
14:13:17 DISPATCHER: Starting worker discovery
14:13:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:13:17 DISPATCHER: Finished worker discovery
14:14:17 DISPATCHER: Starting worker discovery
14:14:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:14:17 DISPATCHER: Finished worker discovery
14:14:59 WORKER: done with job (2, 0, 5), trying to register it.
14:14:59 WORKER: registered result for job (2, 0, 5) with dispatcher
14:14:59 DISPATCHER: job (2, 0, 5) finished
14:14:59 DISPATCHER: register_result: lock acquired
14:14:59 DISPATCHER: job (2, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
14:14:59 job_id: (2, 0, 5)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.012655190644689167, 'num_filters_1': 44, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.013495443229008513, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 63, 'num_filters_3': 19, 'num_filters_4': 94, 'num_filters_5': 28}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.012655190644689167, 'num_filters_1': 44, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.013495443229008513, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 63, 'num_filters_3': 19, 'num_filters_4': 94, 'num_filters_5': 28}"}}
exception: None

14:14:59 job_callback for (2, 0, 5) started
14:14:59 DISPATCHER: Trying to submit another job.
14:14:59 job_callback for (2, 0, 5) got condition
14:14:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:14:59 Only 12 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
14:14:59 HBMASTER: Trying to run another job!
14:14:59 job_callback for (2, 0, 5) finished
14:14:59 ITERATION: Advancing config (2, 0, 2) to next budget 1200.000000
14:14:59 ITERATION: Advancing config (2, 0, 3) to next budget 1200.000000
14:14:59 HBMASTER: schedule new run for iteration 2
14:14:59 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
14:14:59 HBMASTER: submitting job (2, 0, 2) to dispatcher
14:14:59 DISPATCHER: trying to submit job (2, 0, 2)
14:14:59 DISPATCHER: trying to notify the job_runner thread.
14:14:59 HBMASTER: job (2, 0, 2) submitted to dispatcher
14:14:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:14:59 DISPATCHER: Trying to submit another job.
14:14:59 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:14:59 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:14:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:14:59 WORKER: start processing job (2, 0, 2)
14:14:59 WORKER: args: ()
14:14:59 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.08777004252784679, 'num_filters_1': 79, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.1078691864194823}, 'budget': 1200.0, 'working_directory': '.'}
14:15:17 DISPATCHER: Starting worker discovery
14:15:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:15:17 DISPATCHER: Finished worker discovery
14:16:17 DISPATCHER: Starting worker discovery
14:16:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:16:17 DISPATCHER: Finished worker discovery
14:17:17 DISPATCHER: Starting worker discovery
14:17:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:17:17 DISPATCHER: Finished worker discovery
14:18:17 DISPATCHER: Starting worker discovery
14:18:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:18:17 DISPATCHER: Finished worker discovery
14:19:17 DISPATCHER: Starting worker discovery
14:19:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:19:17 DISPATCHER: Finished worker discovery
14:20:17 DISPATCHER: Starting worker discovery
14:20:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:20:17 DISPATCHER: Finished worker discovery
14:21:17 DISPATCHER: Starting worker discovery
14:21:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:21:17 DISPATCHER: Finished worker discovery
14:22:17 DISPATCHER: Starting worker discovery
14:22:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:22:17 DISPATCHER: Finished worker discovery
14:23:17 DISPATCHER: Starting worker discovery
14:23:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:23:17 DISPATCHER: Finished worker discovery
14:24:17 DISPATCHER: Starting worker discovery
14:24:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:24:17 DISPATCHER: Finished worker discovery
14:25:17 DISPATCHER: Starting worker discovery
14:25:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:25:17 DISPATCHER: Finished worker discovery
14:26:17 DISPATCHER: Starting worker discovery
14:26:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:26:17 DISPATCHER: Finished worker discovery
14:27:17 DISPATCHER: Starting worker discovery
14:27:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:27:17 DISPATCHER: Finished worker discovery
14:28:17 DISPATCHER: Starting worker discovery
14:28:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:28:17 DISPATCHER: Finished worker discovery
14:29:17 DISPATCHER: Starting worker discovery
14:29:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:29:17 DISPATCHER: Finished worker discovery
14:30:17 DISPATCHER: Starting worker discovery
14:30:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:30:17 DISPATCHER: Finished worker discovery
14:31:17 DISPATCHER: Starting worker discovery
14:31:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:31:17 DISPATCHER: Finished worker discovery
14:32:17 DISPATCHER: Starting worker discovery
14:32:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:32:17 DISPATCHER: Finished worker discovery
14:33:17 DISPATCHER: Starting worker discovery
14:33:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:33:17 DISPATCHER: Finished worker discovery
14:34:17 DISPATCHER: Starting worker discovery
14:34:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:34:17 DISPATCHER: Finished worker discovery
14:35:17 DISPATCHER: Starting worker discovery
14:35:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:35:17 DISPATCHER: Finished worker discovery
14:36:03 WORKER: done with job (2, 0, 2), trying to register it.
14:36:03 WORKER: registered result for job (2, 0, 2) with dispatcher
14:36:03 DISPATCHER: job (2, 0, 2) finished
14:36:03 DISPATCHER: register_result: lock acquired
14:36:03 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
14:36:03 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.08777004252784679, 'num_filters_1': 79, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.1078691864194823}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.28330648965053373, 'info': {'music_genre': 0.28330648965053373, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.08777004252784679, 'num_filters_1': 79, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.1078691864194823}"}}
exception: None

14:36:03 job_callback for (2, 0, 2) started
14:36:03 DISPATCHER: Trying to submit another job.
14:36:03 job_callback for (2, 0, 2) got condition
14:36:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:36:03 Only 3 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
14:36:03 HBMASTER: Trying to run another job!
14:36:03 job_callback for (2, 0, 2) finished
14:36:03 HBMASTER: schedule new run for iteration 2
14:36:03 HBMASTER: trying submitting job (2, 0, 3) to dispatcher
14:36:03 HBMASTER: submitting job (2, 0, 3) to dispatcher
14:36:03 DISPATCHER: trying to submit job (2, 0, 3)
14:36:03 DISPATCHER: trying to notify the job_runner thread.
14:36:03 HBMASTER: job (2, 0, 3) submitted to dispatcher
14:36:03 DISPATCHER: Trying to submit another job.
14:36:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:36:03 DISPATCHER: starting job (2, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:36:03 DISPATCHER: job (2, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:36:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:36:03 WORKER: start processing job (2, 0, 3)
14:36:03 WORKER: args: ()
14:36:03 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.002273610285121588, 'num_filters_1': 65, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.02500776922258591, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 20, 'num_filters_3': 55}, 'budget': 1200.0, 'working_directory': '.'}
14:36:17 DISPATCHER: Starting worker discovery
14:36:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:36:17 DISPATCHER: Finished worker discovery
14:37:17 DISPATCHER: Starting worker discovery
14:37:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:37:17 DISPATCHER: Finished worker discovery
14:38:17 DISPATCHER: Starting worker discovery
14:38:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:38:17 DISPATCHER: Finished worker discovery
14:39:17 DISPATCHER: Starting worker discovery
14:39:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:39:17 DISPATCHER: Finished worker discovery
14:40:17 DISPATCHER: Starting worker discovery
14:40:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:40:17 DISPATCHER: Finished worker discovery
14:41:17 DISPATCHER: Starting worker discovery
14:41:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:41:17 DISPATCHER: Finished worker discovery
14:42:17 DISPATCHER: Starting worker discovery
14:42:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:42:17 DISPATCHER: Finished worker discovery
14:43:17 DISPATCHER: Starting worker discovery
14:43:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:43:17 DISPATCHER: Finished worker discovery
14:44:17 DISPATCHER: Starting worker discovery
14:44:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:44:17 DISPATCHER: Finished worker discovery
14:45:17 DISPATCHER: Starting worker discovery
14:45:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:45:17 DISPATCHER: Finished worker discovery
14:46:17 DISPATCHER: Starting worker discovery
14:46:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:46:17 DISPATCHER: Finished worker discovery
14:47:17 DISPATCHER: Starting worker discovery
14:47:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:47:17 DISPATCHER: Finished worker discovery
14:48:17 DISPATCHER: Starting worker discovery
14:48:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:48:17 DISPATCHER: Finished worker discovery
14:49:17 DISPATCHER: Starting worker discovery
14:49:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:49:17 DISPATCHER: Finished worker discovery
14:50:17 DISPATCHER: Starting worker discovery
14:50:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:50:17 DISPATCHER: Finished worker discovery
14:51:17 DISPATCHER: Starting worker discovery
14:51:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:51:17 DISPATCHER: Finished worker discovery
14:52:17 DISPATCHER: Starting worker discovery
14:52:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:52:17 DISPATCHER: Finished worker discovery
14:53:17 DISPATCHER: Starting worker discovery
14:53:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:53:17 DISPATCHER: Finished worker discovery
14:54:17 DISPATCHER: Starting worker discovery
14:54:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:54:17 DISPATCHER: Finished worker discovery
14:55:17 DISPATCHER: Starting worker discovery
14:55:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:55:17 DISPATCHER: Finished worker discovery
14:56:17 DISPATCHER: Starting worker discovery
14:56:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:56:17 DISPATCHER: Finished worker discovery
14:57:09 WORKER: done with job (2, 0, 3), trying to register it.
14:57:09 WORKER: registered result for job (2, 0, 3) with dispatcher
14:57:09 DISPATCHER: job (2, 0, 3) finished
14:57:09 DISPATCHER: register_result: lock acquired
14:57:09 DISPATCHER: job (2, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
14:57:09 job_id: (2, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.002273610285121588, 'num_filters_1': 65, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.02500776922258591, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 20, 'num_filters_3': 55}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.31166915927158934, 'info': {'music_genre': 0.31166915927158934, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.002273610285121588, 'num_filters_1': 65, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.02500776922258591, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 20, 'num_filters_3': 55}"}}
exception: None

14:57:09 job_callback for (2, 0, 3) started
14:57:09 DISPATCHER: Trying to submit another job.
14:57:09 job_callback for (2, 0, 3) got condition
14:57:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:57:09 Only 4 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
14:57:09 HBMASTER: Trying to run another job!
14:57:09 job_callback for (2, 0, 3) finished
14:57:09 start sampling a new configuration.
14:57:09 done sampling a new configuration.
14:57:09 HBMASTER: schedule new run for iteration 3
14:57:09 HBMASTER: trying submitting job (3, 0, 0) to dispatcher
14:57:09 HBMASTER: submitting job (3, 0, 0) to dispatcher
14:57:09 DISPATCHER: trying to submit job (3, 0, 0)
14:57:09 DISPATCHER: trying to notify the job_runner thread.
14:57:09 HBMASTER: job (3, 0, 0) submitted to dispatcher
14:57:09 DISPATCHER: Trying to submit another job.
14:57:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:57:09 DISPATCHER: starting job (3, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:57:09 DISPATCHER: job (3, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:57:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:57:09 WORKER: start processing job (3, 0, 0)
14:57:09 WORKER: args: ()
14:57:09 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.061697030514628284, 'num_filters_1': 45, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.014523724793097785, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 44, 'num_filters_3': 20, 'num_filters_4': 31, 'num_filters_5': 20}, 'budget': 1200.0, 'working_directory': '.'}
14:57:17 DISPATCHER: Starting worker discovery
14:57:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:57:17 DISPATCHER: Finished worker discovery
14:58:17 DISPATCHER: Starting worker discovery
14:58:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:58:17 DISPATCHER: Finished worker discovery
14:59:17 DISPATCHER: Starting worker discovery
14:59:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:59:17 DISPATCHER: Finished worker discovery
15:00:17 DISPATCHER: Starting worker discovery
15:00:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:00:17 DISPATCHER: Finished worker discovery
15:01:17 DISPATCHER: Starting worker discovery
15:01:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:01:17 DISPATCHER: Finished worker discovery
15:02:17 DISPATCHER: Starting worker discovery
15:02:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:02:17 DISPATCHER: Finished worker discovery
15:03:17 DISPATCHER: Starting worker discovery
15:03:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:03:17 DISPATCHER: Finished worker discovery
15:04:17 DISPATCHER: Starting worker discovery
15:04:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:04:17 DISPATCHER: Finished worker discovery
15:05:17 DISPATCHER: Starting worker discovery
15:05:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:05:17 DISPATCHER: Finished worker discovery
15:06:17 DISPATCHER: Starting worker discovery
15:06:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:06:17 DISPATCHER: Finished worker discovery
15:07:17 DISPATCHER: Starting worker discovery
15:07:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:07:17 DISPATCHER: Finished worker discovery
15:08:17 DISPATCHER: Starting worker discovery
15:08:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:08:17 DISPATCHER: Finished worker discovery
15:09:17 DISPATCHER: Starting worker discovery
15:09:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:09:17 DISPATCHER: Finished worker discovery
15:10:17 DISPATCHER: Starting worker discovery
15:10:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:10:17 DISPATCHER: Finished worker discovery
15:11:17 DISPATCHER: Starting worker discovery
15:11:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:11:17 DISPATCHER: Finished worker discovery
15:12:17 DISPATCHER: Starting worker discovery
15:12:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:12:17 DISPATCHER: Finished worker discovery
15:13:17 DISPATCHER: Starting worker discovery
15:13:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:13:17 DISPATCHER: Finished worker discovery
15:14:17 DISPATCHER: Starting worker discovery
15:14:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:14:17 DISPATCHER: Finished worker discovery
15:15:17 DISPATCHER: Starting worker discovery
15:15:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:15:17 DISPATCHER: Finished worker discovery
15:16:17 DISPATCHER: Starting worker discovery
15:16:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:16:17 DISPATCHER: Finished worker discovery
15:17:17 DISPATCHER: Starting worker discovery
15:17:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:17:17 DISPATCHER: Finished worker discovery
15:18:17 DISPATCHER: Starting worker discovery
15:18:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:18:18 DISPATCHER: Finished worker discovery
15:18:26 WORKER: done with job (3, 0, 0), trying to register it.
15:18:26 WORKER: registered result for job (3, 0, 0) with dispatcher
15:18:26 DISPATCHER: job (3, 0, 0) finished
15:18:26 DISPATCHER: register_result: lock acquired
15:18:26 DISPATCHER: job (3, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
15:18:26 job_id: (3, 0, 0)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.061697030514628284, 'num_filters_1': 45, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.014523724793097785, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 44, 'num_filters_3': 20, 'num_filters_4': 31, 'num_filters_5': 20}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.061697030514628284, 'num_filters_1': 45, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.014523724793097785, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 44, 'num_filters_3': 20, 'num_filters_4': 31, 'num_filters_5': 20}"}}
exception: None

15:18:26 job_callback for (3, 0, 0) started
15:18:26 job_callback for (3, 0, 0) got condition
15:18:26 DISPATCHER: Trying to submit another job.
15:18:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:18:26 Only 5 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
15:18:26 HBMASTER: Trying to run another job!
15:18:26 job_callback for (3, 0, 0) finished
15:18:26 start sampling a new configuration.
15:18:26 done sampling a new configuration.
15:18:26 HBMASTER: schedule new run for iteration 3
15:18:26 HBMASTER: trying submitting job (3, 0, 1) to dispatcher
15:18:26 HBMASTER: submitting job (3, 0, 1) to dispatcher
15:18:26 DISPATCHER: trying to submit job (3, 0, 1)
15:18:26 DISPATCHER: trying to notify the job_runner thread.
15:18:26 HBMASTER: job (3, 0, 1) submitted to dispatcher
15:18:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:18:26 DISPATCHER: Trying to submit another job.
15:18:26 DISPATCHER: starting job (3, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
15:18:26 DISPATCHER: job (3, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
15:18:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:18:26 WORKER: start processing job (3, 0, 1)
15:18:26 WORKER: args: ()
15:18:26 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.017946750517925582, 'num_filters_1': 85, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.16966661990557533, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 38, 'num_filters_3': 56, 'num_filters_4': 51, 'num_filters_5': 24}, 'budget': 1200.0, 'working_directory': '.'}
15:19:18 DISPATCHER: Starting worker discovery
15:19:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:19:18 DISPATCHER: Finished worker discovery
15:20:18 DISPATCHER: Starting worker discovery
15:20:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:20:18 DISPATCHER: Finished worker discovery
15:21:18 DISPATCHER: Starting worker discovery
15:21:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:21:18 DISPATCHER: Finished worker discovery
15:22:18 DISPATCHER: Starting worker discovery
15:22:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:22:18 DISPATCHER: Finished worker discovery
15:23:18 DISPATCHER: Starting worker discovery
15:23:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:23:18 DISPATCHER: Finished worker discovery
15:24:18 DISPATCHER: Starting worker discovery
15:24:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:24:18 DISPATCHER: Finished worker discovery
15:25:18 DISPATCHER: Starting worker discovery
15:25:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:25:18 DISPATCHER: Finished worker discovery
15:26:18 DISPATCHER: Starting worker discovery
15:26:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:26:18 DISPATCHER: Finished worker discovery
15:27:18 DISPATCHER: Starting worker discovery
15:27:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:27:18 DISPATCHER: Finished worker discovery
15:28:18 DISPATCHER: Starting worker discovery
15:28:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:28:18 DISPATCHER: Finished worker discovery
15:29:18 DISPATCHER: Starting worker discovery
15:29:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:29:18 DISPATCHER: Finished worker discovery
15:30:18 DISPATCHER: Starting worker discovery
15:30:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:30:18 DISPATCHER: Finished worker discovery
15:31:18 DISPATCHER: Starting worker discovery
15:31:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:31:18 DISPATCHER: Finished worker discovery
15:32:18 DISPATCHER: Starting worker discovery
15:32:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:32:18 DISPATCHER: Finished worker discovery
15:33:18 DISPATCHER: Starting worker discovery
15:33:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:33:18 DISPATCHER: Finished worker discovery
15:34:18 DISPATCHER: Starting worker discovery
15:34:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:34:18 DISPATCHER: Finished worker discovery
15:35:18 DISPATCHER: Starting worker discovery
15:35:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:35:18 DISPATCHER: Finished worker discovery
15:36:18 DISPATCHER: Starting worker discovery
15:36:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:36:18 DISPATCHER: Finished worker discovery
15:37:18 DISPATCHER: Starting worker discovery
15:37:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:37:18 DISPATCHER: Finished worker discovery
15:38:18 DISPATCHER: Starting worker discovery
15:38:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:38:18 DISPATCHER: Finished worker discovery
15:39:18 DISPATCHER: Starting worker discovery
15:39:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:39:18 DISPATCHER: Finished worker discovery
15:39:30 WORKER: done with job (3, 0, 1), trying to register it.
15:39:30 WORKER: registered result for job (3, 0, 1) with dispatcher
15:39:30 DISPATCHER: job (3, 0, 1) finished
15:39:30 DISPATCHER: register_result: lock acquired
15:39:30 DISPATCHER: job (3, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
15:39:30 job_id: (3, 0, 1)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.017946750517925582, 'num_filters_1': 85, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.16966661990557533, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 38, 'num_filters_3': 56, 'num_filters_4': 51, 'num_filters_5': 24}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.017946750517925582, 'num_filters_1': 85, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.16966661990557533, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 38, 'num_filters_3': 56, 'num_filters_4': 51, 'num_filters_5': 24}"}}
exception: None

15:39:30 job_callback for (3, 0, 1) started
15:39:30 DISPATCHER: Trying to submit another job.
15:39:30 job_callback for (3, 0, 1) got condition
15:39:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:39:30 Only 6 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
15:39:30 HBMASTER: Trying to run another job!
15:39:30 job_callback for (3, 0, 1) finished
15:39:30 start sampling a new configuration.
15:39:30 done sampling a new configuration.
15:39:30 HBMASTER: schedule new run for iteration 3
15:39:30 HBMASTER: trying submitting job (3, 0, 2) to dispatcher
15:39:30 HBMASTER: submitting job (3, 0, 2) to dispatcher
15:39:30 DISPATCHER: trying to submit job (3, 0, 2)
15:39:30 DISPATCHER: trying to notify the job_runner thread.
15:39:30 HBMASTER: job (3, 0, 2) submitted to dispatcher
15:39:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:39:30 DISPATCHER: Trying to submit another job.
15:39:30 DISPATCHER: starting job (3, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
15:39:30 DISPATCHER: job (3, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
15:39:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:39:30 WORKER: start processing job (3, 0, 2)
15:39:30 WORKER: args: ()
15:39:30 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.01918646120683896, 'num_filters_1': 111, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.039586195933522556, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 128, 'num_filters_3': 16, 'num_filters_4': 45, 'num_filters_5': 54}, 'budget': 1200.0, 'working_directory': '.'}
15:40:18 DISPATCHER: Starting worker discovery
15:40:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:40:18 DISPATCHER: Finished worker discovery
15:41:18 DISPATCHER: Starting worker discovery
15:41:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:41:18 DISPATCHER: Finished worker discovery
15:42:18 DISPATCHER: Starting worker discovery
15:42:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:42:18 DISPATCHER: Finished worker discovery
15:43:18 DISPATCHER: Starting worker discovery
15:43:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:43:18 DISPATCHER: Finished worker discovery
15:44:18 DISPATCHER: Starting worker discovery
15:44:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:44:18 DISPATCHER: Finished worker discovery
15:45:18 DISPATCHER: Starting worker discovery
15:45:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:45:18 DISPATCHER: Finished worker discovery
15:46:18 DISPATCHER: Starting worker discovery
15:46:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:46:18 DISPATCHER: Finished worker discovery
15:47:18 DISPATCHER: Starting worker discovery
15:47:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:47:18 DISPATCHER: Finished worker discovery
15:48:18 DISPATCHER: Starting worker discovery
15:48:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:48:18 DISPATCHER: Finished worker discovery
15:49:18 DISPATCHER: Starting worker discovery
15:49:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:49:18 DISPATCHER: Finished worker discovery
15:50:18 DISPATCHER: Starting worker discovery
15:50:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:50:18 DISPATCHER: Finished worker discovery
15:51:18 DISPATCHER: Starting worker discovery
15:51:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:51:18 DISPATCHER: Finished worker discovery
15:52:18 DISPATCHER: Starting worker discovery
15:52:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:52:18 DISPATCHER: Finished worker discovery
15:53:18 DISPATCHER: Starting worker discovery
15:53:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:53:18 DISPATCHER: Finished worker discovery
15:54:18 DISPATCHER: Starting worker discovery
15:54:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:54:18 DISPATCHER: Finished worker discovery
15:55:18 DISPATCHER: Starting worker discovery
15:55:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:55:18 DISPATCHER: Finished worker discovery
15:56:18 DISPATCHER: Starting worker discovery
15:56:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:56:18 DISPATCHER: Finished worker discovery
15:57:18 DISPATCHER: Starting worker discovery
15:57:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:57:18 DISPATCHER: Finished worker discovery
15:58:18 DISPATCHER: Starting worker discovery
15:58:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:58:18 DISPATCHER: Finished worker discovery
15:59:18 DISPATCHER: Starting worker discovery
15:59:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:59:18 DISPATCHER: Finished worker discovery
16:00:18 DISPATCHER: Starting worker discovery
16:00:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:00:18 DISPATCHER: Finished worker discovery
16:00:36 WORKER: done with job (3, 0, 2), trying to register it.
16:00:36 WORKER: registered result for job (3, 0, 2) with dispatcher
16:00:36 DISPATCHER: job (3, 0, 2) finished
16:00:36 DISPATCHER: register_result: lock acquired
16:00:36 DISPATCHER: job (3, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
16:00:36 job_id: (3, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.01918646120683896, 'num_filters_1': 111, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.039586195933522556, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 128, 'num_filters_3': 16, 'num_filters_4': 45, 'num_filters_5': 54}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.2927050557204267, 'info': {'music_genre': 0.2927050557204267, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.01918646120683896, 'num_filters_1': 111, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.039586195933522556, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 128, 'num_filters_3': 16, 'num_filters_4': 45, 'num_filters_5': 54}"}}
exception: None

16:00:36 job_callback for (3, 0, 2) started
16:00:36 DISPATCHER: Trying to submit another job.
16:00:36 job_callback for (3, 0, 2) got condition
16:00:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:00:36 Only 7 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
16:00:36 HBMASTER: Trying to run another job!
16:00:36 job_callback for (3, 0, 2) finished
16:00:36 start sampling a new configuration.
16:00:36 done sampling a new configuration.
16:00:36 HBMASTER: schedule new run for iteration 3
16:00:36 HBMASTER: trying submitting job (3, 0, 3) to dispatcher
16:00:36 HBMASTER: submitting job (3, 0, 3) to dispatcher
16:00:36 DISPATCHER: trying to submit job (3, 0, 3)
16:00:36 DISPATCHER: trying to notify the job_runner thread.
16:00:36 HBMASTER: job (3, 0, 3) submitted to dispatcher
16:00:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:00:36 DISPATCHER: Trying to submit another job.
16:00:36 DISPATCHER: starting job (3, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:00:36 DISPATCHER: job (3, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:00:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:00:36 WORKER: start processing job (3, 0, 3)
16:00:36 WORKER: args: ()
16:00:36 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0787651000841171, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.012831744064881818, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 18, 'num_filters_3': 24, 'num_filters_4': 47}, 'budget': 1200.0, 'working_directory': '.'}
16:01:18 DISPATCHER: Starting worker discovery
16:01:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:01:18 DISPATCHER: Finished worker discovery
16:02:18 DISPATCHER: Starting worker discovery
16:02:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:02:18 DISPATCHER: Finished worker discovery
16:03:18 DISPATCHER: Starting worker discovery
16:03:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:03:18 DISPATCHER: Finished worker discovery
16:04:18 DISPATCHER: Starting worker discovery
16:04:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:04:18 DISPATCHER: Finished worker discovery
16:05:18 DISPATCHER: Starting worker discovery
16:05:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:05:18 DISPATCHER: Finished worker discovery
16:06:18 DISPATCHER: Starting worker discovery
16:06:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:06:18 DISPATCHER: Finished worker discovery
16:07:18 DISPATCHER: Starting worker discovery
16:07:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:07:18 DISPATCHER: Finished worker discovery
16:08:18 DISPATCHER: Starting worker discovery
16:08:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:08:18 DISPATCHER: Finished worker discovery
16:09:18 DISPATCHER: Starting worker discovery
16:09:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:09:18 DISPATCHER: Finished worker discovery
16:10:18 DISPATCHER: Starting worker discovery
16:10:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:10:18 DISPATCHER: Finished worker discovery
16:11:18 DISPATCHER: Starting worker discovery
16:11:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:11:18 DISPATCHER: Finished worker discovery
16:12:18 DISPATCHER: Starting worker discovery
16:12:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:12:18 DISPATCHER: Finished worker discovery
16:13:18 DISPATCHER: Starting worker discovery
16:13:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:13:18 DISPATCHER: Finished worker discovery
16:14:18 DISPATCHER: Starting worker discovery
16:14:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:14:18 DISPATCHER: Finished worker discovery
16:15:18 DISPATCHER: Starting worker discovery
16:15:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:15:18 DISPATCHER: Finished worker discovery
16:16:18 DISPATCHER: Starting worker discovery
16:16:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:16:18 DISPATCHER: Finished worker discovery
16:17:18 DISPATCHER: Starting worker discovery
16:17:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:17:18 DISPATCHER: Finished worker discovery
16:18:18 DISPATCHER: Starting worker discovery
16:18:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:18:18 DISPATCHER: Finished worker discovery
16:19:18 DISPATCHER: Starting worker discovery
16:19:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:19:18 DISPATCHER: Finished worker discovery
16:20:18 DISPATCHER: Starting worker discovery
16:20:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:20:18 DISPATCHER: Finished worker discovery
16:21:18 DISPATCHER: Starting worker discovery
16:21:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:21:18 DISPATCHER: Finished worker discovery
16:21:41 WORKER: done with job (3, 0, 3), trying to register it.
16:21:41 WORKER: registered result for job (3, 0, 3) with dispatcher
16:21:41 DISPATCHER: job (3, 0, 3) finished
16:21:41 DISPATCHER: register_result: lock acquired
16:21:41 DISPATCHER: job (3, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
16:21:41 job_id: (3, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0787651000841171, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.012831744064881818, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 18, 'num_filters_3': 24, 'num_filters_4': 47}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.002972328180163458, 'info': {'music_genre': 0.002972328180163458, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0787651000841171, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.012831744064881818, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 18, 'num_filters_3': 24, 'num_filters_4': 47}"}}
exception: None

16:21:41 job_callback for (3, 0, 3) started
16:21:41 DISPATCHER: Trying to submit another job.
16:21:41 job_callback for (3, 0, 3) got condition
16:21:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:21:41 Only 8 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
16:21:41 HBMASTER: Trying to run another job!
16:21:41 job_callback for (3, 0, 3) finished
16:21:41 start sampling a new configuration.
16:21:41 done sampling a new configuration.
16:21:41 HBMASTER: schedule new run for iteration 4
16:21:41 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
16:21:41 HBMASTER: submitting job (4, 0, 0) to dispatcher
16:21:41 DISPATCHER: trying to submit job (4, 0, 0)
16:21:41 DISPATCHER: trying to notify the job_runner thread.
16:21:41 HBMASTER: job (4, 0, 0) submitted to dispatcher
16:21:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:21:41 DISPATCHER: Trying to submit another job.
16:21:41 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:21:41 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:21:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:21:41 WORKER: start processing job (4, 0, 0)
16:21:41 WORKER: args: ()
16:21:41 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.010014263278886902, 'num_filters_1': 18, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.0408760116785914, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 23, 'num_filters_3': 36}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:22:18 DISPATCHER: Starting worker discovery
16:22:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:22:18 DISPATCHER: Finished worker discovery
16:23:18 DISPATCHER: Starting worker discovery
16:23:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:23:18 DISPATCHER: Finished worker discovery
16:23:24 WORKER: done with job (4, 0, 0), trying to register it.
16:23:24 WORKER: registered result for job (4, 0, 0) with dispatcher
16:23:24 DISPATCHER: job (4, 0, 0) finished
16:23:24 DISPATCHER: register_result: lock acquired
16:23:24 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
16:23:24 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.010014263278886902, 'num_filters_1': 18, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.0408760116785914, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 23, 'num_filters_3': 36}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -1.64357826152889e-05, 'info': {'music_genre': 1.64357826152889e-05, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.010014263278886902, 'num_filters_1': 18, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.0408760116785914, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 23, 'num_filters_3': 36}"}}
exception: None

16:23:24 job_callback for (4, 0, 0) started
16:23:24 job_callback for (4, 0, 0) got condition
16:23:24 DISPATCHER: Trying to submit another job.
16:23:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:23:24 HBMASTER: Trying to run another job!
16:23:24 job_callback for (4, 0, 0) finished
16:23:24 start sampling a new configuration.
16:23:24 done sampling a new configuration.
16:23:24 HBMASTER: schedule new run for iteration 4
16:23:24 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
16:23:24 HBMASTER: submitting job (4, 0, 1) to dispatcher
16:23:24 DISPATCHER: trying to submit job (4, 0, 1)
16:23:24 DISPATCHER: trying to notify the job_runner thread.
16:23:24 HBMASTER: job (4, 0, 1) submitted to dispatcher
16:23:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:23:24 DISPATCHER: Trying to submit another job.
16:23:24 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:23:24 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:23:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:23:24 WORKER: start processing job (4, 0, 1)
16:23:24 WORKER: args: ()
16:23:24 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.05083664109771327, 'num_filters_1': 57, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.04085002100158978, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 33, 'num_filters_3': 21}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:24:18 DISPATCHER: Starting worker discovery
16:24:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:24:18 DISPATCHER: Finished worker discovery
16:25:05 WORKER: done with job (4, 0, 1), trying to register it.
16:25:05 WORKER: registered result for job (4, 0, 1) with dispatcher
16:25:05 DISPATCHER: job (4, 0, 1) finished
16:25:05 DISPATCHER: register_result: lock acquired
16:25:05 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
16:25:05 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.05083664109771327, 'num_filters_1': 57, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.04085002100158978, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 33, 'num_filters_3': 21}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0005775879472076224, 'info': {'music_genre': 0.0005775879472076224, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.05083664109771327, 'num_filters_1': 57, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.04085002100158978, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 33, 'num_filters_3': 21}"}}
exception: None

16:25:05 job_callback for (4, 0, 1) started
16:25:05 DISPATCHER: Trying to submit another job.
16:25:05 job_callback for (4, 0, 1) got condition
16:25:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:25:05 HBMASTER: Trying to run another job!
16:25:05 job_callback for (4, 0, 1) finished
16:25:05 start sampling a new configuration.
16:25:05 done sampling a new configuration.
16:25:05 HBMASTER: schedule new run for iteration 4
16:25:05 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
16:25:05 HBMASTER: submitting job (4, 0, 2) to dispatcher
16:25:05 DISPATCHER: trying to submit job (4, 0, 2)
16:25:05 DISPATCHER: trying to notify the job_runner thread.
16:25:05 HBMASTER: job (4, 0, 2) submitted to dispatcher
16:25:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:25:05 DISPATCHER: Trying to submit another job.
16:25:05 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:25:05 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:25:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:25:05 WORKER: start processing job (4, 0, 2)
16:25:05 WORKER: args: ()
16:25:05 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0032801078944072392, 'num_filters_1': 25, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.13737845762720446, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 29, 'num_filters_3': 76}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:25:18 DISPATCHER: Starting worker discovery
16:25:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:25:18 DISPATCHER: Finished worker discovery
16:26:18 DISPATCHER: Starting worker discovery
16:26:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:26:18 DISPATCHER: Finished worker discovery
16:26:46 WORKER: done with job (4, 0, 2), trying to register it.
16:26:46 WORKER: registered result for job (4, 0, 2) with dispatcher
16:26:46 DISPATCHER: job (4, 0, 2) finished
16:26:46 DISPATCHER: register_result: lock acquired
16:26:46 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
16:26:46 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0032801078944072392, 'num_filters_1': 25, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.13737845762720446, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 29, 'num_filters_3': 76}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.13017112182252794, 'info': {'music_genre': 0.13017112182252794, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0032801078944072392, 'num_filters_1': 25, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.13737845762720446, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 29, 'num_filters_3': 76}"}}
exception: None

16:26:46 job_callback for (4, 0, 2) started
16:26:46 job_callback for (4, 0, 2) got condition
16:26:46 DISPATCHER: Trying to submit another job.
16:26:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:26:46 HBMASTER: Trying to run another job!
16:26:46 job_callback for (4, 0, 2) finished
16:26:46 start sampling a new configuration.
16:26:46 done sampling a new configuration.
16:26:46 HBMASTER: schedule new run for iteration 4
16:26:46 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
16:26:46 HBMASTER: submitting job (4, 0, 3) to dispatcher
16:26:46 DISPATCHER: trying to submit job (4, 0, 3)
16:26:46 DISPATCHER: trying to notify the job_runner thread.
16:26:46 HBMASTER: job (4, 0, 3) submitted to dispatcher
16:26:46 DISPATCHER: Trying to submit another job.
16:26:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:26:46 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:26:46 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:26:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:26:46 WORKER: start processing job (4, 0, 3)
16:26:46 WORKER: args: ()
16:26:46 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.02364468599449034, 'num_filters_1': 56, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.012810046768470884, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 33, 'num_filters_3': 53, 'num_filters_4': 54}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:27:18 DISPATCHER: Starting worker discovery
16:27:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:27:18 DISPATCHER: Finished worker discovery
16:28:18 DISPATCHER: Starting worker discovery
16:28:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:28:18 DISPATCHER: Finished worker discovery
16:28:28 WORKER: done with job (4, 0, 3), trying to register it.
16:28:28 WORKER: registered result for job (4, 0, 3) with dispatcher
16:28:28 DISPATCHER: job (4, 0, 3) finished
16:28:28 DISPATCHER: register_result: lock acquired
16:28:28 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
16:28:28 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.02364468599449034, 'num_filters_1': 56, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.012810046768470884, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 33, 'num_filters_3': 53, 'num_filters_4': 54}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.34722775928496225, 'info': {'music_genre': 0.34722775928496225, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.02364468599449034, 'num_filters_1': 56, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.012810046768470884, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 33, 'num_filters_3': 53, 'num_filters_4': 54}"}}
exception: None

16:28:28 job_callback for (4, 0, 3) started
16:28:28 DISPATCHER: Trying to submit another job.
16:28:28 job_callback for (4, 0, 3) got condition
16:28:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:28:28 HBMASTER: Trying to run another job!
16:28:28 job_callback for (4, 0, 3) finished
16:28:28 start sampling a new configuration.
16:28:28 done sampling a new configuration.
16:28:28 HBMASTER: schedule new run for iteration 4
16:28:28 HBMASTER: trying submitting job (4, 0, 4) to dispatcher
16:28:28 HBMASTER: submitting job (4, 0, 4) to dispatcher
16:28:28 DISPATCHER: trying to submit job (4, 0, 4)
16:28:28 DISPATCHER: trying to notify the job_runner thread.
16:28:28 HBMASTER: job (4, 0, 4) submitted to dispatcher
16:28:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:28:28 DISPATCHER: Trying to submit another job.
16:28:28 DISPATCHER: starting job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:28:28 DISPATCHER: job (4, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:28:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:28:28 WORKER: start processing job (4, 0, 4)
16:28:28 WORKER: args: ()
16:28:28 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0022115126271076363, 'num_filters_1': 28, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.022476636590969195}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:29:18 DISPATCHER: Starting worker discovery
16:29:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:29:18 DISPATCHER: Finished worker discovery
16:30:09 WORKER: done with job (4, 0, 4), trying to register it.
16:30:09 WORKER: registered result for job (4, 0, 4) with dispatcher
16:30:09 DISPATCHER: job (4, 0, 4) finished
16:30:09 DISPATCHER: register_result: lock acquired
16:30:09 DISPATCHER: job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
16:30:09 job_id: (4, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0022115126271076363, 'num_filters_1': 28, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.022476636590969195}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.42178000530383514, 'info': {'music_genre': 0.42178000530383514, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0022115126271076363, 'num_filters_1': 28, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.022476636590969195}"}}
exception: None

16:30:09 job_callback for (4, 0, 4) started
16:30:09 job_callback for (4, 0, 4) got condition
16:30:09 DISPATCHER: Trying to submit another job.
16:30:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:30:09 HBMASTER: Trying to run another job!
16:30:09 job_callback for (4, 0, 4) finished
16:30:09 start sampling a new configuration.
16:30:09 done sampling a new configuration.
16:30:09 HBMASTER: schedule new run for iteration 4
16:30:09 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
16:30:09 HBMASTER: submitting job (4, 0, 5) to dispatcher
16:30:09 DISPATCHER: trying to submit job (4, 0, 5)
16:30:09 DISPATCHER: trying to notify the job_runner thread.
16:30:09 HBMASTER: job (4, 0, 5) submitted to dispatcher
16:30:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:30:09 DISPATCHER: Trying to submit another job.
16:30:09 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:30:09 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:30:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:30:09 WORKER: start processing job (4, 0, 5)
16:30:09 WORKER: args: ()
16:30:09 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.017625553106771694, 'num_filters_1': 24, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.055787054690135014, 'kernel_size_2': 7, 'num_filters_2': 29}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:30:18 DISPATCHER: Starting worker discovery
16:30:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:30:18 DISPATCHER: Finished worker discovery
16:31:18 DISPATCHER: Starting worker discovery
16:31:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:31:18 DISPATCHER: Finished worker discovery
16:31:51 WORKER: done with job (4, 0, 5), trying to register it.
16:31:51 WORKER: registered result for job (4, 0, 5) with dispatcher
16:31:51 DISPATCHER: job (4, 0, 5) finished
16:31:51 DISPATCHER: register_result: lock acquired
16:31:51 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
16:31:51 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.017625553106771694, 'num_filters_1': 24, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.055787054690135014, 'kernel_size_2': 7, 'num_filters_2': 29}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.17925058630535923, 'info': {'music_genre': 0.17925058630535923, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.017625553106771694, 'num_filters_1': 24, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.055787054690135014, 'kernel_size_2': 7, 'num_filters_2': 29}"}}
exception: None

16:31:51 job_callback for (4, 0, 5) started
16:31:51 job_callback for (4, 0, 5) got condition
16:31:51 DISPATCHER: Trying to submit another job.
16:31:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:31:51 HBMASTER: Trying to run another job!
16:31:51 job_callback for (4, 0, 5) finished
16:31:51 start sampling a new configuration.
16:31:51 done sampling a new configuration.
16:31:51 HBMASTER: schedule new run for iteration 4
16:31:51 HBMASTER: trying submitting job (4, 0, 6) to dispatcher
16:31:51 HBMASTER: submitting job (4, 0, 6) to dispatcher
16:31:51 DISPATCHER: trying to submit job (4, 0, 6)
16:31:51 DISPATCHER: trying to notify the job_runner thread.
16:31:51 HBMASTER: job (4, 0, 6) submitted to dispatcher
16:31:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:31:51 DISPATCHER: Trying to submit another job.
16:31:51 DISPATCHER: starting job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:31:51 DISPATCHER: job (4, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:31:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:31:51 WORKER: start processing job (4, 0, 6)
16:31:51 WORKER: args: ()
16:31:51 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002607489482690399, 'num_filters_1': 66, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.0919653314163965, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 19, 'num_filters_3': 21}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:32:18 DISPATCHER: Starting worker discovery
16:32:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:32:18 DISPATCHER: Finished worker discovery
16:33:18 DISPATCHER: Starting worker discovery
16:33:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:33:18 DISPATCHER: Finished worker discovery
16:33:32 WORKER: done with job (4, 0, 6), trying to register it.
16:33:32 WORKER: registered result for job (4, 0, 6) with dispatcher
16:33:32 DISPATCHER: job (4, 0, 6) finished
16:33:32 DISPATCHER: register_result: lock acquired
16:33:32 DISPATCHER: job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
16:33:33 job_id: (4, 0, 6)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002607489482690399, 'num_filters_1': 66, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.0919653314163965, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 19, 'num_filters_3': 21}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.16225551550924505, 'info': {'music_genre': 0.16225551550924505, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002607489482690399, 'num_filters_1': 66, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.0919653314163965, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 19, 'num_filters_3': 21}"}}
exception: None

16:33:33 job_callback for (4, 0, 6) started
16:33:33 job_callback for (4, 0, 6) got condition
16:33:33 DISPATCHER: Trying to submit another job.
16:33:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:33:33 done building a new model for budget 44.444444 based on 17/28 split
Best loss for this budget:-0.549965





16:33:33 HBMASTER: Trying to run another job!
16:33:33 job_callback for (4, 0, 6) finished
16:33:33 start sampling a new configuration.
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/statsmodels/nonparametric/kernels.py:62: RuntimeWarning: divide by zero encountered in true_divide
  kernel_value = np.ones(Xi.size) * h / (num_levels - 1)
16:33:33 best_vector: [1, 0, 0.1080928938077205, 0.23499241887708083, 0.0767001024023764, 1, 0.8205741446523215, 0.16223803476667728, 0, 0, 0, 1, 0.3915518325390237, 0.8651833495817942, 0.5110157194686744, 0.40322200300124633], 3.762487337341958e-30, 0.002657816253825478, 1.913239880504258e-99
16:33:33 done sampling a new configuration.
16:33:33 HBMASTER: schedule new run for iteration 4
16:33:33 HBMASTER: trying submitting job (4, 0, 7) to dispatcher
16:33:33 HBMASTER: submitting job (4, 0, 7) to dispatcher
16:33:33 DISPATCHER: trying to submit job (4, 0, 7)
16:33:33 DISPATCHER: trying to notify the job_runner thread.
16:33:33 HBMASTER: job (4, 0, 7) submitted to dispatcher
16:33:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:33:33 DISPATCHER: Trying to submit another job.
16:33:33 DISPATCHER: starting job (4, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:33:33 DISPATCHER: job (4, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:33:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:33:33 WORKER: start processing job (4, 0, 7)
16:33:33 WORKER: args: ()
16:33:33 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0016450753224302986, 'num_filters_1': 25, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.01625835303684367}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:34:18 DISPATCHER: Starting worker discovery
16:34:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:34:18 DISPATCHER: Finished worker discovery
16:35:13 WORKER: done with job (4, 0, 7), trying to register it.
16:35:13 WORKER: registered result for job (4, 0, 7) with dispatcher
16:35:13 DISPATCHER: job (4, 0, 7) finished
16:35:13 DISPATCHER: register_result: lock acquired
16:35:13 DISPATCHER: job (4, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
16:35:13 job_id: (4, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0016450753224302986, 'num_filters_1': 25, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.01625835303684367}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4378244565374478, 'info': {'music_genre': 0.4378244565374478, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0016450753224302986, 'num_filters_1': 25, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.01625835303684367}"}}
exception: None

16:35:13 job_callback for (4, 0, 7) started
16:35:13 DISPATCHER: Trying to submit another job.
16:35:13 job_callback for (4, 0, 7) got condition
16:35:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:35:14 done building a new model for budget 44.444444 based on 17/29 split
Best loss for this budget:-0.549965





16:35:14 HBMASTER: Trying to run another job!
16:35:14 job_callback for (4, 0, 7) finished
16:35:14 start sampling a new configuration.
16:35:14 done sampling a new configuration.
16:35:14 HBMASTER: schedule new run for iteration 4
16:35:14 HBMASTER: trying submitting job (4, 0, 8) to dispatcher
16:35:14 HBMASTER: submitting job (4, 0, 8) to dispatcher
16:35:14 DISPATCHER: trying to submit job (4, 0, 8)
16:35:14 DISPATCHER: trying to notify the job_runner thread.
16:35:14 HBMASTER: job (4, 0, 8) submitted to dispatcher
16:35:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:35:14 DISPATCHER: Trying to submit another job.
16:35:14 DISPATCHER: starting job (4, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:35:14 DISPATCHER: job (4, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:35:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:35:14 WORKER: start processing job (4, 0, 8)
16:35:14 WORKER: args: ()
16:35:14 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0014542821437919294, 'num_filters_1': 52, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.05225325785800645, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 36, 'num_filters_3': 33, 'num_filters_4': 25}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:35:18 DISPATCHER: Starting worker discovery
16:35:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:35:18 DISPATCHER: Finished worker discovery
16:36:18 DISPATCHER: Starting worker discovery
16:36:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:36:18 DISPATCHER: Finished worker discovery
16:36:55 WORKER: done with job (4, 0, 8), trying to register it.
16:36:55 WORKER: registered result for job (4, 0, 8) with dispatcher
16:36:55 DISPATCHER: job (4, 0, 8) finished
16:36:55 DISPATCHER: register_result: lock acquired
16:36:55 DISPATCHER: job (4, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
16:36:55 job_id: (4, 0, 8)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0014542821437919294, 'num_filters_1': 52, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.05225325785800645, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 36, 'num_filters_3': 33, 'num_filters_4': 25}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.377222114905168, 'info': {'music_genre': 0.377222114905168, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0014542821437919294, 'num_filters_1': 52, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.05225325785800645, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 36, 'num_filters_3': 33, 'num_filters_4': 25}"}}
exception: None

16:36:55 job_callback for (4, 0, 8) started
16:36:55 DISPATCHER: Trying to submit another job.
16:36:55 job_callback for (4, 0, 8) got condition
16:36:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:36:55 done building a new model for budget 44.444444 based on 17/30 split
Best loss for this budget:-0.549965





16:36:55 HBMASTER: Trying to run another job!
16:36:55 job_callback for (4, 0, 8) finished
16:36:55 start sampling a new configuration.
16:36:55 best_vector: [0, 1, 0.26438287958504014, 0.15993325968276378, 0.738836073191979, 0, 0.48859266683404184, 0.11896678276191285, 2, 2, 0, 1, 0.18596658254339027, 0.37954472045089976, 0.7007938137120364, 0.9741513034051461], 2.4971885468221318e-30, 0.004004503389512091, 1.7900734233055642e-60
16:36:55 done sampling a new configuration.
16:36:55 HBMASTER: schedule new run for iteration 4
16:36:55 HBMASTER: trying submitting job (4, 0, 9) to dispatcher
16:36:55 HBMASTER: submitting job (4, 0, 9) to dispatcher
16:36:55 DISPATCHER: trying to submit job (4, 0, 9)
16:36:55 DISPATCHER: trying to notify the job_runner thread.
16:36:55 HBMASTER: job (4, 0, 9) submitted to dispatcher
16:36:55 DISPATCHER: Trying to submit another job.
16:36:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:36:55 DISPATCHER: starting job (4, 0, 9) on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:36:55 DISPATCHER: job (4, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:36:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:36:55 WORKER: start processing job (4, 0, 9)
16:36:55 WORKER: args: ()
16:36:55 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0033788254690832525, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.014281681807266824, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 23, 'num_filters_3': 35, 'num_filters_4': 68}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:37:18 DISPATCHER: Starting worker discovery
16:37:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:37:18 DISPATCHER: Finished worker discovery
16:38:18 DISPATCHER: Starting worker discovery
16:38:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:38:18 DISPATCHER: Finished worker discovery
16:38:37 WORKER: done with job (4, 0, 9), trying to register it.
16:38:37 WORKER: registered result for job (4, 0, 9) with dispatcher
16:38:37 DISPATCHER: job (4, 0, 9) finished
16:38:37 DISPATCHER: register_result: lock acquired
16:38:37 DISPATCHER: job (4, 0, 9) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
16:38:37 job_id: (4, 0, 9)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0033788254690832525, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.014281681807266824, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 23, 'num_filters_3': 35, 'num_filters_4': 68}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3082658062260173, 'info': {'music_genre': 0.3082658062260173, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0033788254690832525, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.014281681807266824, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 23, 'num_filters_3': 35, 'num_filters_4': 68}"}}
exception: None

16:38:37 job_callback for (4, 0, 9) started
16:38:37 DISPATCHER: Trying to submit another job.
16:38:37 job_callback for (4, 0, 9) got condition
16:38:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:38:37 done building a new model for budget 44.444444 based on 17/31 split
Best loss for this budget:-0.549965





16:38:37 HBMASTER: Trying to run another job!
16:38:37 job_callback for (4, 0, 9) finished
16:38:37 start sampling a new configuration.
16:38:37 best_vector: [3, 2, 0.3332119753409061, 0.3812035758994029, 0.48079952026305184, 1, 0.32953539332077564, 0.38960097327977294, 2, 1, 2, 1, 0.17059288419249127, 0.5093417992718898, 0.7791112176043076, 0.32928197471332915], 1.1125094439233766e-30, 0.008988687740693682, 5.538802586507636e-114
16:38:37 done sampling a new configuration.
16:38:37 HBMASTER: schedule new run for iteration 4
16:38:37 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
16:38:37 HBMASTER: submitting job (4, 0, 10) to dispatcher
16:38:37 DISPATCHER: trying to submit job (4, 0, 10)
16:38:37 DISPATCHER: trying to notify the job_runner thread.
16:38:37 HBMASTER: job (4, 0, 10) submitted to dispatcher
16:38:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:38:37 DISPATCHER: Trying to submit another job.
16:38:37 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:38:37 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:38:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:38:37 WORKER: start processing job (4, 0, 10)
16:38:37 WORKER: args: ()
16:38:37 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004638995494069737, 'num_filters_1': 35, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.032127915772929345, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 22, 'num_filters_3': 46}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:39:18 DISPATCHER: Starting worker discovery
16:39:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:39:18 DISPATCHER: Finished worker discovery
16:40:18 WORKER: done with job (4, 0, 10), trying to register it.
16:40:18 WORKER: registered result for job (4, 0, 10) with dispatcher
16:40:18 DISPATCHER: job (4, 0, 10) finished
16:40:18 DISPATCHER: register_result: lock acquired
16:40:18 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
16:40:18 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004638995494069737, 'num_filters_1': 35, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.032127915772929345, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 22, 'num_filters_3': 46}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4576717374811731, 'info': {'music_genre': 0.4576717374811731, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004638995494069737, 'num_filters_1': 35, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.032127915772929345, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 22, 'num_filters_3': 46}"}}
exception: None

16:40:18 job_callback for (4, 0, 10) started
16:40:18 job_callback for (4, 0, 10) got condition
16:40:18 DISPATCHER: Trying to submit another job.
16:40:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:40:18 done building a new model for budget 44.444444 based on 17/32 split
Best loss for this budget:-0.549965





16:40:18 HBMASTER: Trying to run another job!
16:40:18 job_callback for (4, 0, 10) finished
16:40:18 start sampling a new configuration.
16:40:18 DISPATCHER: Starting worker discovery
16:40:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:40:18 best_vector: [0, 2, 0.167146658486247, 0.275359871020762, 0.36449670019442776, 0, 0.1383228244145242, 0.45682047345404003, 2, 2, 2, 1, 0.493018290531237, 0.35065857151218555, 0.7802349958312815, 0.4521981067026248], 3.721028564161636e-31, 0.02687428980339753, 1.806188713847492e-51
16:40:18 done sampling a new configuration.
16:40:18 DISPATCHER: Finished worker discovery
16:40:18 HBMASTER: schedule new run for iteration 4
16:40:18 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
16:40:18 HBMASTER: submitting job (4, 0, 11) to dispatcher
16:40:18 DISPATCHER: trying to submit job (4, 0, 11)
16:40:18 DISPATCHER: trying to notify the job_runner thread.
16:40:18 HBMASTER: job (4, 0, 11) submitted to dispatcher
16:40:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:40:18 DISPATCHER: Trying to submit another job.
16:40:18 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:40:18 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:40:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:40:18 WORKER: start processing job (4, 0, 11)
16:40:18 WORKER: args: ()
16:40:18 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.002159202214534394, 'num_filters_1': 28, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.039294986019721284, 'kernel_size_2': 7, 'num_filters_2': 44}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:41:18 DISPATCHER: Starting worker discovery
16:41:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:41:18 DISPATCHER: Finished worker discovery
16:42:00 WORKER: done with job (4, 0, 11), trying to register it.
16:42:00 WORKER: registered result for job (4, 0, 11) with dispatcher
16:42:00 DISPATCHER: job (4, 0, 11) finished
16:42:00 DISPATCHER: register_result: lock acquired
16:42:00 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
16:42:00 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.002159202214534394, 'num_filters_1': 28, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.039294986019721284, 'kernel_size_2': 7, 'num_filters_2': 44}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2375533758880209, 'info': {'music_genre': 0.2375533758880209, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.002159202214534394, 'num_filters_1': 28, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.039294986019721284, 'kernel_size_2': 7, 'num_filters_2': 44}"}}
exception: None

16:42:00 job_callback for (4, 0, 11) started
16:42:00 job_callback for (4, 0, 11) got condition
16:42:00 DISPATCHER: Trying to submit another job.
16:42:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:42:00 done building a new model for budget 44.444444 based on 17/33 split
Best loss for this budget:-0.549965





16:42:00 HBMASTER: Trying to run another job!
16:42:00 job_callback for (4, 0, 11) finished
16:42:00 start sampling a new configuration.
16:42:01 best_vector: [2, 2, 0.4933615651546778, 0.09698012370753464, 0.8999412530073883, 1, 0.9169952769611522, 0.12543786708182225, 2, 1, 2, 1, 0.4565577661217523, 0.60306710858454, 0.18997837335779258, 0.45539337717480366], 5.009668068461245e-30, 0.0019961402359081988, 3.425335451092872e-53
16:42:01 done sampling a new configuration.
16:42:01 HBMASTER: schedule new run for iteration 4
16:42:01 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
16:42:01 HBMASTER: submitting job (4, 0, 12) to dispatcher
16:42:01 DISPATCHER: trying to submit job (4, 0, 12)
16:42:01 DISPATCHER: trying to notify the job_runner thread.
16:42:01 HBMASTER: job (4, 0, 12) submitted to dispatcher
16:42:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:42:01 DISPATCHER: Trying to submit another job.
16:42:01 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:42:01 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:42:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:42:01 WORKER: start processing job (4, 0, 12)
16:42:01 WORKER: args: ()
16:42:01 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.009698914487701592, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.014561242268050925, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 41, 'num_filters_3': 55, 'num_filters_4': 23, 'num_filters_5': 41}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:42:18 DISPATCHER: Starting worker discovery
16:42:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:42:18 DISPATCHER: Finished worker discovery
16:43:18 DISPATCHER: Starting worker discovery
16:43:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:43:18 DISPATCHER: Finished worker discovery
16:43:41 WORKER: done with job (4, 0, 12), trying to register it.
16:43:41 WORKER: registered result for job (4, 0, 12) with dispatcher
16:43:41 DISPATCHER: job (4, 0, 12) finished
16:43:41 DISPATCHER: register_result: lock acquired
16:43:41 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
16:43:41 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.009698914487701592, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.014561242268050925, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 41, 'num_filters_3': 55, 'num_filters_4': 23, 'num_filters_5': 41}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5178724177956644, 'info': {'music_genre': 0.5178724177956644, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.009698914487701592, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.014561242268050925, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 41, 'num_filters_3': 55, 'num_filters_4': 23, 'num_filters_5': 41}"}}
exception: None

16:43:41 job_callback for (4, 0, 12) started
16:43:41 job_callback for (4, 0, 12) got condition
16:43:41 DISPATCHER: Trying to submit another job.
16:43:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:43:41 done building a new model for budget 44.444444 based on 17/34 split
Best loss for this budget:-0.549965





16:43:41 HBMASTER: Trying to run another job!
16:43:41 job_callback for (4, 0, 12) finished
16:43:41 start sampling a new configuration.
16:43:41 done sampling a new configuration.
16:43:41 HBMASTER: schedule new run for iteration 4
16:43:41 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
16:43:41 HBMASTER: submitting job (4, 0, 13) to dispatcher
16:43:41 DISPATCHER: trying to submit job (4, 0, 13)
16:43:41 DISPATCHER: trying to notify the job_runner thread.
16:43:41 HBMASTER: job (4, 0, 13) submitted to dispatcher
16:43:41 DISPATCHER: Trying to submit another job.
16:43:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:43:41 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:43:41 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:43:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:43:41 WORKER: start processing job (4, 0, 13)
16:43:41 WORKER: args: ()
16:43:41 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.005050726385103805, 'num_filters_1': 63, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.15214345257352094, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 25, 'num_filters_3': 40, 'num_filters_4': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:44:18 DISPATCHER: Starting worker discovery
16:44:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:44:18 DISPATCHER: Finished worker discovery
16:45:18 DISPATCHER: Starting worker discovery
16:45:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:45:18 DISPATCHER: Finished worker discovery
16:45:22 WORKER: done with job (4, 0, 13), trying to register it.
16:45:22 WORKER: registered result for job (4, 0, 13) with dispatcher
16:45:22 DISPATCHER: job (4, 0, 13) finished
16:45:22 DISPATCHER: register_result: lock acquired
16:45:22 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
16:45:22 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.005050726385103805, 'num_filters_1': 63, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.15214345257352094, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 25, 'num_filters_3': 40, 'num_filters_4': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.07420449039154998, 'info': {'music_genre': 0.07420449039154998, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.005050726385103805, 'num_filters_1': 63, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.15214345257352094, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 25, 'num_filters_3': 40, 'num_filters_4': 18}"}}
exception: None

16:45:22 job_callback for (4, 0, 13) started
16:45:22 DISPATCHER: Trying to submit another job.
16:45:22 job_callback for (4, 0, 13) got condition
16:45:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:45:22 done building a new model for budget 44.444444 based on 17/34 split
Best loss for this budget:-0.549965





16:45:22 HBMASTER: Trying to run another job!
16:45:22 job_callback for (4, 0, 13) finished
16:45:22 start sampling a new configuration.
16:45:22 best_vector: [3, 1, 0.10181832201488909, 0.12409281463366639, 0.47341118572775903, 0, 0.7339040747156405, 0.07018461907685278, 1, 1, 2, 1, 0.5640008894304304, 0.6688246759168189, 0.3126153315673253, 0.9197901992467359], 1.5647426038949787e-30, 0.006390827459486221, 3.5357838170752627e-41
16:45:22 done sampling a new configuration.
16:45:22 HBMASTER: schedule new run for iteration 4
16:45:22 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
16:45:22 HBMASTER: submitting job (4, 0, 14) to dispatcher
16:45:22 DISPATCHER: trying to submit job (4, 0, 14)
16:45:22 DISPATCHER: trying to notify the job_runner thread.
16:45:22 HBMASTER: job (4, 0, 14) submitted to dispatcher
16:45:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:45:22 DISPATCHER: Trying to submit another job.
16:45:22 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:45:22 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:45:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:45:22 WORKER: start processing job (4, 0, 14)
16:45:22 WORKER: args: ()
16:45:22 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0015982203052153621, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.012339918593195049, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 51, 'num_filters_3': 64}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:46:18 DISPATCHER: Starting worker discovery
16:46:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:46:18 DISPATCHER: Finished worker discovery
16:47:04 WORKER: done with job (4, 0, 14), trying to register it.
16:47:04 WORKER: registered result for job (4, 0, 14) with dispatcher
16:47:04 DISPATCHER: job (4, 0, 14) finished
16:47:04 DISPATCHER: register_result: lock acquired
16:47:04 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
16:47:04 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0015982203052153621, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.012339918593195049, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 51, 'num_filters_3': 64}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3208760760843896, 'info': {'music_genre': 0.3208760760843896, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0015982203052153621, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.012339918593195049, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 51, 'num_filters_3': 64}"}}
exception: None

16:47:04 job_callback for (4, 0, 14) started
16:47:04 DISPATCHER: Trying to submit another job.
16:47:04 job_callback for (4, 0, 14) got condition
16:47:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:47:04 done building a new model for budget 44.444444 based on 17/35 split
Best loss for this budget:-0.549965





16:47:04 HBMASTER: Trying to run another job!
16:47:04 job_callback for (4, 0, 14) finished
16:47:04 start sampling a new configuration.
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/hpbandster/optimizers/config_generators/bohb.py:140: RuntimeWarning: invalid value encountered in true_divide
  minimize_me = lambda x: max(1e-32, g(x))/max(l(x),1e-32)
16:47:04 sampled vector: [3, 2, 0.060823348340162925, 0.624230136169968, 0.5878124701895227, 1, 0.2798249287775218, 0.7479738349302034, 0, 1, 2, 0, 0.527943152307361, 0.825665421406085, 0.49811301987784473, 0.20012884735304343] has EI value nan
16:47:04 data in the KDEs:
[[2.         2.         0.47178123 0.92218719 0.5        1.
  0.9065935  0.31381917 0.         1.         2.         1.
  0.89998624 0.66299556 0.38509383 0.62389945]
 [1.         0.         0.40211343 0.20671155 0.9000016  1.
  0.39010987 0.12877876 2.         2.         2.         1.
  0.56308999 0.56308999 0.38509383 0.39841284]
 [2.         2.         0.49336157 0.09625996 0.9000016  1.
  0.91758251 0.12543787 2.         1.         2.         1.
  0.45990111 0.59878947 0.18658964 0.45990111]
 [2.         1.         0.10234533 0.85218865 0.7000008  0.
  0.37912085 0.22472575 1.         1.         0.         1.
  0.37138871 0.67777156 0.7390824  0.94752148]
 [3.         2.         0.33321198 0.38509383 0.5        1.
  0.32417579 0.38960097 2.         1.         1.         1.
  0.16557314 0.51430515 0.88144294 0.62389945]
 [2.         2.         0.28384397 0.1205111  0.7000008  1.
  0.35714283 0.02296792 0.         1.         1.         1.
  0.09625996 0.76999494 0.88144294 0.94752148]
 [3.         0.         0.25794399 0.20671155 0.2999992  1.
  0.86263744 0.34920724 1.         0.         0.         1.
  0.16557314 0.1205111  0.64774283 0.94752148]
 [1.         0.         0.10809289 0.22601193 0.0999984  1.
  0.81868139 0.16223803 1.         1.         0.         1.
  0.56308999 0.67044128 0.64774283 0.94752148]
 [3.         0.         0.28404341 0.29618395 0.2999992  1.
  0.62087915 0.25929901 1.         1.         2.         1.
  0.37138871 0.67044128 0.18658964 0.45990111]
 [0.         2.         0.66961843 0.24455523 0.7000008  1.
  0.84065942 0.18088591 0.         2.         1.         1.
  0.8766912  0.75169097 0.38509383 0.45990111]
 [0.         2.         0.4786384  0.01501027 0.9000016  1.
  0.52197803 0.37669659 0.         0.         2.         1.
  0.99444858 0.76397201 0.38509383 0.62389945]
 [0.         2.         0.17234471 0.279593   0.0999984  1.
  0.60989013 0.27034836 2.         2.         2.         1.
  0.56308999 0.56308999 0.38509383 0.39841284]
 [2.         1.         0.12554175 0.279593   0.5        0.
  0.31318677 0.31350927 0.         1.         2.         1.
  0.38509383 0.44822661 0.38509383 0.62389945]
 [3.         2.         0.08132434 0.57227073 0.7000008  0.
  0.31318677 0.55195758 2.         2.         1.         1.
  0.39841284 0.35727442 0.22601193 0.62389945]
 [1.         2.         0.02288415 0.68498992 0.9000016  1.
  0.19230762 0.74121025 2.         0.         0.         1.
  0.18658964 0.1205111  0.64774283 0.94752148]
 [1.         0.         0.68686678 0.6073085  0.7000008  1.
  0.56593408 0.08266582 2.         2.         2.         1.
  0.35727442 0.5812766  0.59011412 0.39841284]
 [3.         1.         0.10181832 0.1205111  0.5        0.
  0.73076928 0.07018462 1.         1.         1.         1.
  0.56308999 0.67044128 0.38509383 0.94752148]]
[[0.         1.         0.26438288 0.16557314 0.7000008  0.
  0.48901099 0.11896678 2.         2.         0.         1.
  0.18658964 0.38509383 0.69910421 0.71951573]
 [0.         2.         0.16395    0.59011412 0.0999984  0.
  0.20329664 0.00507952 2.         2.         0.         1.
  0.18658964 0.38509383 0.69910421 0.71951573]
 [3.         2.         0.97367855 0.85218865 0.2999992  1.
  0.78571435 0.63488564 0.         1.         2.         1.
  0.92218719 0.67777156 0.29618395 0.71951573]
 [0.         1.         0.82932305 0.09625996 0.0999984  1.
  0.77472534 0.52464527 2.         1.         1.         1.
  0.29618395 0.31221238 0.71280933 0.68498992]
 [0.         2.         0.16714666 0.279593   0.2999992  0.
  0.13736256 0.45682047 2.         1.         1.         1.
  0.49328864 0.63198159 0.63992789 0.71951573]
 [2.         2.         0.62307138 0.20671155 0.2999992  1.
  0.71978027 0.57380186 2.         1.         2.         1.
  0.29618395 0.63198159 0.29618395 0.68498992]
 [0.         0.         0.20811128 0.68498992 0.5        0.
  0.64285717 0.74066251 2.         2.         1.         1.
  0.09625996 0.14357878 0.71280933 0.68498992]
 [0.         2.         0.55918764 0.71280933 0.5        1.
  0.60989013 0.68602037 0.         0.         2.         1.
  0.87189123 0.29618395 0.29618395 0.71951573]
 [0.         0.         0.22394689 0.18658964 0.5        0.
  0.35714283 0.52866879 1.         1.         0.         1.
  0.3277152  0.61567675 0.69910421 0.71951573]
 [1.         1.         0.90899673 0.01501027 0.9000016  1.
  0.71978027 0.68002337 0.         1.         1.         1.
  0.69209973 0.31221238 0.71280933 0.68498992]
 [1.         1.         0.25794406 0.22601193 0.5        1.
  0.42307691 0.87462906 0.         1.         1.         1.
  0.29618395 0.75169097 0.98694376 0.71951573]
 [0.         0.         0.83164766 0.7390824  0.0999984  0.
  0.39010987 0.24930638 0.         1.         0.         1.
  0.92218719 0.63198159 0.69910421 0.68498992]
 [0.         0.         0.08471182 0.91782962 0.7000008  0.
  0.5        0.71779976 0.         1.         1.         1.
  0.1205111  0.279593   0.5812766  0.68498992]
 [2.         2.         0.82721129 0.1205111  0.5        1.
  0.76373632 0.96039278 0.         2.         1.         1.
  0.45990111 0.97156701 0.71280933 0.68498992]
 [2.         2.         0.61923926 0.70600643 0.0999984  0.
  0.32417579 0.42065225 2.         2.         0.         1.
  0.18658964 0.38509383 0.69910421 0.71951573]
 [2.         2.         0.35167692 0.66299556 0.7000008  1.
  0.5        0.90870562 0.         2.         1.         1.
  0.22601193 0.44822661 0.07069733 0.68498992]
 [2.         1.         0.65364187 0.9089921  0.0999984  0.
  0.10439552 0.67729902 0.         0.         1.         1.
  0.87189123 0.29618395 0.71280933 0.68498992]
 [1.         1.         0.76754601 0.39841284 0.7000008  1.
  0.84065942 0.97725023 0.         2.         1.         1.
  0.75169097 0.29618395 0.63992789 0.71951573]
 [2.         2.         0.85308842 0.61567675 0.5        0.
  0.57692309 0.46977571 2.         0.         1.         1.
  0.35727442 0.14357878 0.98694376 0.71951573]
 [3.         2.         0.55678623 0.38509383 0.5        0.
  0.11538453 0.55362796 0.         1.         1.         1.
  0.71951573 0.63198159 0.63992789 0.68498992]
 [0.         2.         0.5003095  0.07069733 0.5        0.
  0.03846144 0.46998802 0.         2.         1.         1.
  0.18658964 0.39841284 0.71280933 0.68498992]
 [0.         0.         0.63300178 0.45990111 0.7000008  0.
  0.20329664 0.08590925 0.         2.         1.         1.
  0.93922664 0.18658964 0.09625996 0.68498992]
 [2.         2.         0.57408355 0.89998624 0.7000008  0.
  0.80769238 0.3118426  1.         0.         1.         1.
  0.14357878 0.69910421 0.83685346 0.68498992]
 [2.         1.         0.61207106 0.88144294 0.9000016  0.
  0.89560448 0.09117699 0.         0.         1.         1.
  0.81013485 0.92650497 0.98694376 0.71951573]
 [1.         2.         0.43572106 0.50391366 0.7000008  0.
  0.55494507 0.63326409 0.         1.         2.         1.
  0.5812766  0.67777156 0.29618395 0.68498992]]
16:47:04 bandwidth of the KDEs:
[0.98606045 0.8063266  0.1847257  0.24128407 0.23663565 0.39024394
 0.21590077 0.16333986 0.76533134 0.62175812 0.74201626 0.001
 0.23507581 0.17674708 0.19756956 0.20284421]
[0.93712776 0.70918985 0.23311272 0.26575611 0.22204764 0.43316175
 0.23016884 0.24245453 0.82786921 0.65969332 0.54024762 0.001
 0.26421777 0.20548924 0.2233817  0.01546583]
16:47:04 l(x) = inf
16:47:04 g(x) = inf
16:47:04 best_vector: [1, 1, 0.24392053593444837, 0.3073269752667208, 0.15918782805276227, 0, 0.8026637842026331, 0.27596994852304835, 0, 1, 1, 1, 0.36720409181272273, 0.12749733260849805, 0.6482328845327103, 0.9702124021136788], 3.9314110562164297e-31, 0.025436159834235066, 1.9875347949087641e-60
16:47:04 done sampling a new configuration.
16:47:04 HBMASTER: schedule new run for iteration 4
16:47:04 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
16:47:04 HBMASTER: submitting job (4, 0, 15) to dispatcher
16:47:04 DISPATCHER: trying to submit job (4, 0, 15)
16:47:04 DISPATCHER: trying to notify the job_runner thread.
16:47:04 HBMASTER: job (4, 0, 15) submitted to dispatcher
16:47:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:47:04 DISPATCHER: Trying to submit another job.
16:47:04 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:47:04 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:47:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:47:04 WORKER: start processing job (4, 0, 15)
16:47:04 WORKER: args: ()
16:47:04 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.003074971336758106, 'num_filters_1': 30, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.022858365932997664}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:47:18 DISPATCHER: Starting worker discovery
16:47:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:47:18 DISPATCHER: Finished worker discovery
16:48:18 DISPATCHER: Starting worker discovery
16:48:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:48:18 DISPATCHER: Finished worker discovery
16:48:44 WORKER: done with job (4, 0, 15), trying to register it.
16:48:44 WORKER: registered result for job (4, 0, 15) with dispatcher
16:48:44 DISPATCHER: job (4, 0, 15) finished
16:48:44 DISPATCHER: register_result: lock acquired
16:48:44 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
16:48:44 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.003074971336758106, 'num_filters_1': 30, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.022858365932997664}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.19456295468132784, 'info': {'music_genre': 0.19456295468132784, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.003074971336758106, 'num_filters_1': 30, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.022858365932997664}"}}
exception: None

16:48:44 job_callback for (4, 0, 15) started
16:48:44 job_callback for (4, 0, 15) got condition
16:48:44 DISPATCHER: Trying to submit another job.
16:48:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:48:44 done building a new model for budget 44.444444 based on 17/36 split
Best loss for this budget:-0.549965





16:48:44 HBMASTER: Trying to run another job!
16:48:44 job_callback for (4, 0, 15) finished
16:48:44 start sampling a new configuration.
16:48:44 done sampling a new configuration.
16:48:44 HBMASTER: schedule new run for iteration 4
16:48:44 HBMASTER: trying submitting job (4, 0, 16) to dispatcher
16:48:44 HBMASTER: submitting job (4, 0, 16) to dispatcher
16:48:44 DISPATCHER: trying to submit job (4, 0, 16)
16:48:44 DISPATCHER: trying to notify the job_runner thread.
16:48:44 HBMASTER: job (4, 0, 16) submitted to dispatcher
16:48:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:48:44 DISPATCHER: Trying to submit another job.
16:48:44 DISPATCHER: starting job (4, 0, 16) on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:48:44 DISPATCHER: job (4, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:48:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:48:44 WORKER: start processing job (4, 0, 16)
16:48:44 WORKER: args: ()
16:48:44 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.005747014572272674, 'num_filters_1': 24, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.010963990485669477, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 105, 'num_filters_3': 24, 'num_filters_4': 27}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:49:18 DISPATCHER: Starting worker discovery
16:49:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:49:18 DISPATCHER: Finished worker discovery
16:50:18 DISPATCHER: Starting worker discovery
16:50:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:50:18 DISPATCHER: Finished worker discovery
16:50:24 WORKER: done with job (4, 0, 16), trying to register it.
16:50:24 WORKER: registered result for job (4, 0, 16) with dispatcher
16:50:24 DISPATCHER: job (4, 0, 16) finished
16:50:24 DISPATCHER: register_result: lock acquired
16:50:24 DISPATCHER: job (4, 0, 16) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
16:50:24 job_id: (4, 0, 16)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.005747014572272674, 'num_filters_1': 24, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.010963990485669477, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 105, 'num_filters_3': 24, 'num_filters_4': 27}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.34744241155538885, 'info': {'music_genre': 0.34744241155538885, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.005747014572272674, 'num_filters_1': 24, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.010963990485669477, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 105, 'num_filters_3': 24, 'num_filters_4': 27}"}}
exception: None

16:50:24 job_callback for (4, 0, 16) started
16:50:24 job_callback for (4, 0, 16) got condition
16:50:24 DISPATCHER: Trying to submit another job.
16:50:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:50:24 done building a new model for budget 44.444444 based on 17/37 split
Best loss for this budget:-0.549965





16:50:24 HBMASTER: Trying to run another job!
16:50:24 job_callback for (4, 0, 16) finished
16:50:24 start sampling a new configuration.
16:50:24 done sampling a new configuration.
16:50:24 HBMASTER: schedule new run for iteration 4
16:50:24 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
16:50:24 HBMASTER: submitting job (4, 0, 17) to dispatcher
16:50:24 DISPATCHER: trying to submit job (4, 0, 17)
16:50:24 DISPATCHER: trying to notify the job_runner thread.
16:50:24 HBMASTER: job (4, 0, 17) submitted to dispatcher
16:50:24 DISPATCHER: Trying to submit another job.
16:50:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:50:24 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:50:24 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:50:24 WORKER: start processing job (4, 0, 17)
16:50:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:50:24 WORKER: args: ()
16:50:24 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.01741214019988208, 'num_filters_1': 39, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 10, 'weight_decay': 0.013267827814065734, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 34, 'num_filters_3': 78, 'num_filters_4': 56}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:51:18 DISPATCHER: Starting worker discovery
16:51:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:51:18 DISPATCHER: Finished worker discovery
16:52:07 WORKER: done with job (4, 0, 17), trying to register it.
16:52:07 WORKER: registered result for job (4, 0, 17) with dispatcher
16:52:07 DISPATCHER: job (4, 0, 17) finished
16:52:07 DISPATCHER: register_result: lock acquired
16:52:07 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
16:52:07 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.01741214019988208, 'num_filters_1': 39, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 10, 'weight_decay': 0.013267827814065734, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 34, 'num_filters_3': 78, 'num_filters_4': 56}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.01741214019988208, 'num_filters_1': 39, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 10, 'weight_decay': 0.013267827814065734, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 34, 'num_filters_3': 78, 'num_filters_4': 56}"}}
exception: None

16:52:07 job_callback for (4, 0, 17) started
16:52:07 DISPATCHER: Trying to submit another job.
16:52:07 job_callback for (4, 0, 17) got condition
16:52:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:52:07 done building a new model for budget 44.444444 based on 17/38 split
Best loss for this budget:-0.549965





16:52:07 HBMASTER: Trying to run another job!
16:52:07 job_callback for (4, 0, 17) finished
16:52:07 start sampling a new configuration.
16:52:07 best_vector: [1, 1, 0.6187585143105218, 0.21866529854731448, 0.6717015078837946, 1, 0.7565444102337996, 0.043752262331595675, 2, 2, 1, 1, 0.9320327627232328, 0.8010336358269128, 0.12932100962141183, 0.44903782471396503], 7.312890131982893e-31, 0.013674484122583826, 1.9236587117093792e-54
16:52:07 done sampling a new configuration.
16:52:07 HBMASTER: schedule new run for iteration 4
16:52:07 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
16:52:07 HBMASTER: submitting job (4, 0, 18) to dispatcher
16:52:07 DISPATCHER: trying to submit job (4, 0, 18)
16:52:07 DISPATCHER: trying to notify the job_runner thread.
16:52:07 HBMASTER: job (4, 0, 18) submitted to dispatcher
16:52:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:52:07 DISPATCHER: Trying to submit another job.
16:52:07 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:52:07 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:52:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:52:07 WORKER: start processing job (4, 0, 18)
16:52:07 WORKER: args: ()
16:52:07 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.017278937296318124, 'num_filters_1': 25, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.0114004765516358, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 111, 'num_filters_3': 84, 'num_filters_4': 20}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:52:18 DISPATCHER: Starting worker discovery
16:52:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:52:18 DISPATCHER: Finished worker discovery
16:53:18 DISPATCHER: Starting worker discovery
16:53:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:53:18 DISPATCHER: Finished worker discovery
16:53:46 WORKER: done with job (4, 0, 18), trying to register it.
16:53:46 WORKER: registered result for job (4, 0, 18) with dispatcher
16:53:46 DISPATCHER: job (4, 0, 18) finished
16:53:46 DISPATCHER: register_result: lock acquired
16:53:46 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
16:53:46 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.017278937296318124, 'num_filters_1': 25, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.0114004765516358, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 111, 'num_filters_3': 84, 'num_filters_4': 20}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.521519864737884, 'info': {'music_genre': 0.521519864737884, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.017278937296318124, 'num_filters_1': 25, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.0114004765516358, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 111, 'num_filters_3': 84, 'num_filters_4': 20}"}}
exception: None

16:53:46 job_callback for (4, 0, 18) started
16:53:46 DISPATCHER: Trying to submit another job.
16:53:46 job_callback for (4, 0, 18) got condition
16:53:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:53:46 done building a new model for budget 44.444444 based on 17/39 split
Best loss for this budget:-0.549965





16:53:46 HBMASTER: Trying to run another job!
16:53:46 job_callback for (4, 0, 18) finished
16:53:46 start sampling a new configuration.
16:53:46 done sampling a new configuration.
16:53:46 HBMASTER: schedule new run for iteration 4
16:53:46 HBMASTER: trying submitting job (4, 0, 19) to dispatcher
16:53:46 HBMASTER: submitting job (4, 0, 19) to dispatcher
16:53:46 DISPATCHER: trying to submit job (4, 0, 19)
16:53:46 DISPATCHER: trying to notify the job_runner thread.
16:53:46 HBMASTER: job (4, 0, 19) submitted to dispatcher
16:53:46 DISPATCHER: Trying to submit another job.
16:53:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:53:46 DISPATCHER: starting job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:53:46 DISPATCHER: job (4, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:53:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:53:46 WORKER: start processing job (4, 0, 19)
16:53:46 WORKER: args: ()
16:53:46 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.08167411758774869, 'num_filters_1': 47, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.08036836998508788, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 99, 'num_filters_3': 42, 'num_filters_4': 29, 'num_filters_5': 38}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:54:18 DISPATCHER: Starting worker discovery
16:54:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:54:18 DISPATCHER: Finished worker discovery
16:55:18 DISPATCHER: Starting worker discovery
16:55:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:55:18 DISPATCHER: Finished worker discovery
16:55:28 WORKER: done with job (4, 0, 19), trying to register it.
16:55:28 WORKER: registered result for job (4, 0, 19) with dispatcher
16:55:28 DISPATCHER: job (4, 0, 19) finished
16:55:28 DISPATCHER: register_result: lock acquired
16:55:28 DISPATCHER: job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
16:55:28 job_id: (4, 0, 19)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.08167411758774869, 'num_filters_1': 47, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.08036836998508788, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 99, 'num_filters_3': 42, 'num_filters_4': 29, 'num_filters_5': 38}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.0037375738014866194, 'info': {'music_genre': -0.0037375738014866194, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.08167411758774869, 'num_filters_1': 47, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.08036836998508788, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 99, 'num_filters_3': 42, 'num_filters_4': 29, 'num_filters_5': 38}"}}
exception: None

16:55:28 job_callback for (4, 0, 19) started
16:55:28 DISPATCHER: Trying to submit another job.
16:55:28 job_callback for (4, 0, 19) got condition
16:55:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:55:28 done building a new model for budget 44.444444 based on 17/39 split
Best loss for this budget:-0.549965





16:55:28 HBMASTER: Trying to run another job!
16:55:28 job_callback for (4, 0, 19) finished
16:55:28 start sampling a new configuration.
16:55:28 done sampling a new configuration.
16:55:28 HBMASTER: schedule new run for iteration 4
16:55:28 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
16:55:28 HBMASTER: submitting job (4, 0, 20) to dispatcher
16:55:28 DISPATCHER: trying to submit job (4, 0, 20)
16:55:28 DISPATCHER: trying to notify the job_runner thread.
16:55:28 HBMASTER: job (4, 0, 20) submitted to dispatcher
16:55:28 DISPATCHER: Trying to submit another job.
16:55:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:55:28 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:55:28 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:55:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:55:28 WORKER: start processing job (4, 0, 20)
16:55:28 WORKER: args: ()
16:55:28 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.04765251832686281, 'num_filters_1': 54, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.022711131990114476}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:56:18 DISPATCHER: Starting worker discovery
16:56:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:56:18 DISPATCHER: Finished worker discovery
16:57:10 WORKER: done with job (4, 0, 20), trying to register it.
16:57:10 WORKER: registered result for job (4, 0, 20) with dispatcher
16:57:10 DISPATCHER: job (4, 0, 20) finished
16:57:10 DISPATCHER: register_result: lock acquired
16:57:10 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
16:57:10 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.04765251832686281, 'num_filters_1': 54, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.022711131990114476}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.31426385703706916, 'info': {'music_genre': 0.31426385703706916, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.04765251832686281, 'num_filters_1': 54, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.022711131990114476}"}}
exception: None

16:57:10 job_callback for (4, 0, 20) started
16:57:10 DISPATCHER: Trying to submit another job.
16:57:10 job_callback for (4, 0, 20) got condition
16:57:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:57:10 done building a new model for budget 44.444444 based on 17/40 split
Best loss for this budget:-0.549965





16:57:10 HBMASTER: Trying to run another job!
16:57:10 job_callback for (4, 0, 20) finished
16:57:10 start sampling a new configuration.
16:57:10 best_vector: [0, 0, 0.2217178875494873, 0.45711525787553575, 0.2914660517340475, 0, 0.73464476920217, 0.268095785137057, 1, 0, 0, 1, 0.2294407130866194, 0.6332746254805974, 0.6147336771636349, 0.007221222972451535], 4.828380524609956e-06, 0.000555639656700877, 2.6828396971154766e-09
16:57:10 done sampling a new configuration.
16:57:10 HBMASTER: schedule new run for iteration 4
16:57:10 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
16:57:10 HBMASTER: submitting job (4, 0, 21) to dispatcher
16:57:10 DISPATCHER: trying to submit job (4, 0, 21)
16:57:10 DISPATCHER: trying to notify the job_runner thread.
16:57:10 HBMASTER: job (4, 0, 21) submitted to dispatcher
16:57:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:57:10 DISPATCHER: Trying to submit another job.
16:57:10 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:57:10 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:57:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:57:10 WORKER: start processing job (4, 0, 21)
16:57:10 WORKER: args: ()
16:57:10 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0027761042762873595, 'num_filters_1': 41, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.022325472450452338, 'kernel_size_2': 5, 'num_filters_2': 25}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:57:18 DISPATCHER: Starting worker discovery
16:57:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:57:18 DISPATCHER: Finished worker discovery
16:58:18 DISPATCHER: Starting worker discovery
16:58:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:58:18 DISPATCHER: Finished worker discovery
16:58:51 WORKER: done with job (4, 0, 21), trying to register it.
16:58:51 WORKER: registered result for job (4, 0, 21) with dispatcher
16:58:51 DISPATCHER: job (4, 0, 21) finished
16:58:51 DISPATCHER: register_result: lock acquired
16:58:51 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
16:58:51 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0027761042762873595, 'num_filters_1': 41, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.022325472450452338, 'kernel_size_2': 5, 'num_filters_2': 25}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2946873844828941, 'info': {'music_genre': 0.2946873844828941, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0027761042762873595, 'num_filters_1': 41, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.022325472450452338, 'kernel_size_2': 5, 'num_filters_2': 25}"}}
exception: None

16:58:51 job_callback for (4, 0, 21) started
16:58:51 job_callback for (4, 0, 21) got condition
16:58:51 DISPATCHER: Trying to submit another job.
16:58:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:58:51 done building a new model for budget 44.444444 based on 17/41 split
Best loss for this budget:-0.549965





16:58:51 HBMASTER: Trying to run another job!
16:58:51 job_callback for (4, 0, 21) finished
16:58:51 start sampling a new configuration.
16:58:52 best_vector: [0, 2, 0.1007238389168246, 0.28754704337169945, 0.8270651449964637, 0, 0.5710114122692616, 0.48662095959488927, 2, 2, 0, 1, 0.9519125285377299, 0.6428298361026588, 0.5746121476308874, 0.16009763240191305], 0.0007383836701852772, 8.238959622813106e-05, 6.083513244801049e-08
16:58:52 done sampling a new configuration.
16:58:52 HBMASTER: schedule new run for iteration 4
16:58:52 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
16:58:52 HBMASTER: submitting job (4, 0, 22) to dispatcher
16:58:52 DISPATCHER: trying to submit job (4, 0, 22)
16:58:52 DISPATCHER: trying to notify the job_runner thread.
16:58:52 HBMASTER: job (4, 0, 22) submitted to dispatcher
16:58:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:58:52 DISPATCHER: Trying to submit another job.
16:58:52 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:58:52 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:58:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:58:52 WORKER: start processing job (4, 0, 22)
16:58:52 WORKER: args: ()
16:58:52 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0015901850927602993, 'num_filters_1': 28, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.042964371679067234, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 116, 'num_filters_3': 60, 'num_filters_4': 52, 'num_filters_5': 22}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:59:18 DISPATCHER: Starting worker discovery
16:59:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:59:18 DISPATCHER: Finished worker discovery
17:00:18 DISPATCHER: Starting worker discovery
17:00:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:00:18 DISPATCHER: Finished worker discovery
17:00:33 WORKER: done with job (4, 0, 22), trying to register it.
17:00:33 WORKER: registered result for job (4, 0, 22) with dispatcher
17:00:33 DISPATCHER: job (4, 0, 22) finished
17:00:33 DISPATCHER: register_result: lock acquired
17:00:33 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
17:00:33 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0015901850927602993, 'num_filters_1': 28, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.042964371679067234, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 116, 'num_filters_3': 60, 'num_filters_4': 52, 'num_filters_5': 22}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.26752273871932053, 'info': {'music_genre': 0.26752273871932053, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0015901850927602993, 'num_filters_1': 28, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.042964371679067234, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 116, 'num_filters_3': 60, 'num_filters_4': 52, 'num_filters_5': 22}"}}
exception: None

17:00:33 job_callback for (4, 0, 22) started
17:00:33 DISPATCHER: Trying to submit another job.
17:00:33 job_callback for (4, 0, 22) got condition
17:00:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:00:33 done building a new model for budget 44.444444 based on 17/42 split
Best loss for this budget:-0.549965





17:00:33 HBMASTER: Trying to run another job!
17:00:33 job_callback for (4, 0, 22) finished
17:00:33 start sampling a new configuration.
17:00:33 best_vector: [1, 0, 0.21551873461934237, 0.724544608781131, 0.6583056268340923, 1, 0.3855873591835994, 0.5000453278223547, 0, 2, 2, 1, 0.7879736069030563, 0.7716508021437135, 0.935896562605506, 0.5454243877150298], 0.04333552418632004, 0.0014171185989164889, 6.141157731822948e-05
17:00:33 done sampling a new configuration.
17:00:33 HBMASTER: schedule new run for iteration 4
17:00:33 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
17:00:33 HBMASTER: submitting job (4, 0, 23) to dispatcher
17:00:33 DISPATCHER: trying to submit job (4, 0, 23)
17:00:33 DISPATCHER: trying to notify the job_runner thread.
17:00:33 HBMASTER: job (4, 0, 23) submitted to dispatcher
17:00:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:00:33 DISPATCHER: Trying to submit another job.
17:00:33 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:00:33 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:00:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:00:33 WORKER: start processing job (4, 0, 23)
17:00:33 WORKER: args: ()
17:00:33 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.002697972192950829, 'num_filters_1': 72, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.0447274326766434, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 82, 'num_filters_3': 79, 'num_filters_4': 112}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:01:18 DISPATCHER: Starting worker discovery
17:01:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:01:18 DISPATCHER: Finished worker discovery
17:02:14 WORKER: done with job (4, 0, 23), trying to register it.
17:02:14 WORKER: registered result for job (4, 0, 23) with dispatcher
17:02:14 DISPATCHER: job (4, 0, 23) finished
17:02:14 DISPATCHER: register_result: lock acquired
17:02:14 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
17:02:14 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.002697972192950829, 'num_filters_1': 72, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.0447274326766434, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 82, 'num_filters_3': 79, 'num_filters_4': 112}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5333325717724862, 'info': {'music_genre': 0.5333325717724862, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.002697972192950829, 'num_filters_1': 72, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.0447274326766434, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 82, 'num_filters_3': 79, 'num_filters_4': 112}"}}
exception: None

17:02:14 job_callback for (4, 0, 23) started
17:02:14 job_callback for (4, 0, 23) got condition
17:02:14 DISPATCHER: Trying to submit another job.
17:02:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:02:14 done building a new model for budget 44.444444 based on 17/43 split
Best loss for this budget:-0.549965





17:02:14 HBMASTER: Trying to run another job!
17:02:14 job_callback for (4, 0, 23) finished
17:02:14 start sampling a new configuration.
17:02:14 best_vector: [1, 0, 0.24911041689010938, 0.7349035125869804, 0.0376893112890081, 1, 0.9294720954352562, 0.22555392270314814, 1, 2, 1, 1, 0.872266046090479, 0.9870115576626914, 0.9963853793604125, 0.08013996427978254], 0.025622938020390857, 1.3723594787512878e-05, 3.516388186574015e-07
17:02:14 done sampling a new configuration.
17:02:14 HBMASTER: schedule new run for iteration 4
17:02:14 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
17:02:14 HBMASTER: submitting job (4, 0, 24) to dispatcher
17:02:14 DISPATCHER: trying to submit job (4, 0, 24)
17:02:14 DISPATCHER: trying to notify the job_runner thread.
17:02:14 HBMASTER: job (4, 0, 24) submitted to dispatcher
17:02:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:02:14 DISPATCHER: Trying to submit another job.
17:02:14 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:02:14 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:02:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:02:14 WORKER: start processing job (4, 0, 24)
17:02:14 WORKER: args: ()
17:02:14 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.003149349315152282, 'num_filters_1': 73, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.019654066405520938}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:02:18 DISPATCHER: Starting worker discovery
17:02:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:02:18 DISPATCHER: Finished worker discovery
17:03:18 DISPATCHER: Starting worker discovery
17:03:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:03:18 DISPATCHER: Finished worker discovery
17:03:56 WORKER: done with job (4, 0, 24), trying to register it.
17:03:56 WORKER: registered result for job (4, 0, 24) with dispatcher
17:03:56 DISPATCHER: job (4, 0, 24) finished
17:03:56 DISPATCHER: register_result: lock acquired
17:03:56 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
17:03:56 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.003149349315152282, 'num_filters_1': 73, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.019654066405520938}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.46304555717952717, 'info': {'music_genre': 0.46304555717952717, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.003149349315152282, 'num_filters_1': 73, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.019654066405520938}"}}
exception: None

17:03:56 job_callback for (4, 0, 24) started
17:03:56 job_callback for (4, 0, 24) got condition
17:03:56 DISPATCHER: Trying to submit another job.
17:03:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:03:56 done building a new model for budget 44.444444 based on 17/44 split
Best loss for this budget:-0.549965





17:03:56 HBMASTER: Trying to run another job!
17:03:56 job_callback for (4, 0, 24) finished
17:03:56 start sampling a new configuration.
17:03:56 sampled vector: [1, 1, 0.16698812688313944, 0.5401601839644338, 0.31135482325584607, 0, 0.6980907928926612, 0.8398120610350965, 0, 1, 0, 2, 0.15131698861317427, 0.795712211124217, 0.4217877892462346, 0.2962717546819633] has EI value nan
17:03:56 data in the KDEs:
[[2.         2.         0.47178123 0.92218719 0.5        1.
  0.9065935  0.31381917 0.         1.         1.         1.
  0.89998624 0.66299556 0.1205111  0.62389945]
 [1.         0.         0.40211343 0.20671155 0.9000016  1.
  0.39010987 0.12877876 2.         2.         2.         1.
  0.56308999 0.56308999 0.38509383 0.39841284]
 [1.         0.         0.21551873 0.72612834 0.7000008  1.
  0.39010987 0.50004533 0.         2.         2.         1.
  0.78761662 0.76999494 0.93502401 0.45990111]
 [1.         1.         0.61875851 0.22601193 0.7000008  1.
  0.75274731 0.04375226 2.         2.         1.         1.
  0.93078368 0.79900978 0.1205111  0.39841284]
 [2.         2.         0.49336157 0.09625996 0.9000016  1.
  0.91758251 0.12543787 2.         1.         2.         1.
  0.45990111 0.59878947 0.18658964 0.45990111]
 [2.         1.         0.10234533 0.85218865 0.7000008  0.
  0.37912085 0.22472575 1.         1.         0.         1.
  0.37138871 0.67777156 0.7390824  0.62389945]
 [1.         0.         0.24911042 0.73264973 0.0999984  1.
  0.92857152 0.22555392 0.         0.         2.         1.
  0.99444858 0.76397201 0.38509383 0.62389945]
 [3.         2.         0.33321198 0.38509383 0.5        1.
  0.32417579 0.38960097 2.         1.         1.         1.
  0.16557314 0.51430515 0.38509383 0.62389945]
 [2.         2.         0.28384397 0.1205111  0.7000008  1.
  0.35714283 0.02296792 0.         1.         1.         1.
  0.09625996 0.76999494 0.88144294 0.39841284]
 [3.         0.         0.25794399 0.20671155 0.2999992  1.
  0.86263744 0.34920724 1.         2.         2.         1.
  0.16557314 0.76999494 0.93502401 0.45990111]
 [1.         0.         0.10809289 0.22601193 0.0999984  1.
  0.81868139 0.16223803 0.         2.         2.         1.
  0.78761662 0.76999494 0.93502401 0.45990111]
 [3.         0.         0.28404341 0.29618395 0.2999992  1.
  0.62087915 0.25929901 1.         1.         2.         1.
  0.37138871 0.59878947 0.18658964 0.45990111]
 [0.         2.         0.66961843 0.24455523 0.7000008  1.
  0.84065942 0.18088591 0.         2.         1.         1.
  0.8766912  0.75169097 0.38509383 0.62389945]
 [0.         2.         0.4786384  0.01501027 0.9000016  1.
  0.52197803 0.37669659 0.         0.         2.         1.
  0.99444858 0.76397201 0.38509383 0.62389945]
 [0.         2.         0.17234471 0.279593   0.0999984  1.
  0.60989013 0.27034836 0.         2.         2.         1.
  0.78761662 0.76999494 0.93502401 0.62389945]
 [2.         1.         0.12554175 0.279593   0.5        0.
  0.31318677 0.31350927 0.         1.         1.         1.
  0.38509383 0.44822661 0.38509383 0.39841284]
 [3.         2.         0.08132434 0.57227073 0.7000008  0.
  0.31318677 0.55195758 2.         2.         1.         1.
  0.39841284 0.35727442 0.22601193 0.62389945]]
[[1.         2.         0.02288415 0.68498992 0.9000016  1.
  0.19230762 0.74121025 2.         0.         0.         1.
  0.18658964 0.1205111  0.64774283 0.94752148]
 [3.         1.         0.37972115 0.20671155 0.7000008  0.
  0.73076928 0.03072078 0.         2.         0.         1.
  0.90451061 0.20671155 0.26239861 0.94752148]
 [1.         0.         0.68686678 0.6073085  0.7000008  1.
  0.56593408 0.08266582 2.         2.         2.         1.
  0.35727442 0.5812766  0.59011412 0.71951573]
 [3.         1.         0.10181832 0.1205111  0.5        0.
  0.73076928 0.07018462 1.         1.         0.         1.
  0.56308999 0.67044128 0.6073085  0.42397547]
 [2.         1.         0.83904293 0.59011412 0.0999984  1.
  0.6648352  0.27381289 1.         1.         1.         1.
  0.3277152  0.61567675 0.63992789 0.68498992]
 [0.         1.         0.26438288 0.16557314 0.7000008  0.
  0.48901099 0.11896678 2.         2.         0.         1.
  0.18658964 0.38509383 0.69910421 0.68498992]
 [0.         0.         0.22171789 0.45990111 0.2999992  0.
  0.73076928 0.26809579 1.         2.         2.         1.
  0.22601193 0.5812766  0.59011412 0.71951573]
 [0.         2.         0.16395    0.59011412 0.0999984  0.
  0.20329664 0.00507952 2.         2.         2.         1.
  0.35727442 0.5812766  0.59011412 0.68498992]
 [3.         2.         0.97367855 0.85218865 0.2999992  1.
  0.78571435 0.63488564 0.         1.         1.         1.
  0.92218719 0.63198159 0.98694376 0.71951573]
 [0.         2.         0.10072384 0.279593   0.9000016  0.
  0.56593408 0.48662096 2.         2.         0.         1.
  0.95161496 0.63992789 0.57227073 0.16557314]
 [0.         1.         0.82932305 0.09625996 0.0999984  1.
  0.77472534 0.52464527 2.         2.         0.         1.
  0.18658964 0.38509383 0.69910421 0.94752148]
 [0.         2.         0.16714666 0.279593   0.2999992  0.
  0.13736256 0.45682047 2.         0.         0.         1.
  0.49328864 0.1205111  0.64774283 0.94752148]
 [1.         1.         0.24392054 0.31221238 0.0999984  0.
  0.80769238 0.27596995 0.         0.         1.         1.
  0.81013485 0.92650497 0.98694376 0.71951573]
 [2.         2.         0.62307138 0.20671155 0.2999992  1.
  0.71978027 0.57380186 2.         1.         1.         1.
  0.29618395 0.31221238 0.71280933 0.68498992]
 [0.         0.         0.20811128 0.68498992 0.5        0.
  0.64285717 0.74066251 2.         2.         1.         1.
  0.09625996 0.14357878 0.63992789 0.68498992]
 [0.         2.         0.55918764 0.71280933 0.5        1.
  0.60989013 0.68602037 0.         0.         0.         1.
  0.87189123 0.29618395 0.57227073 0.16557314]
 [0.         0.         0.22394689 0.18658964 0.5        0.
  0.35714283 0.52866879 1.         1.         1.         1.
  0.3277152  0.61567675 0.07069733 0.71951573]
 [1.         1.         0.90899673 0.01501027 0.9000016  1.
  0.71978027 0.68002337 0.         1.         1.         1.
  0.69209973 0.31221238 0.71280933 0.68498992]
 [1.         1.         0.25794406 0.22601193 0.5        1.
  0.42307691 0.87462906 0.         1.         0.         1.
  0.29618395 0.75169097 0.57227073 0.16557314]
 [0.         0.         0.83164766 0.7390824  0.0999984  0.
  0.39010987 0.24930638 0.         2.         1.         1.
  0.22601193 0.44822661 0.07069733 0.16557314]
 [0.         0.         0.08471182 0.91782962 0.7000008  0.
  0.5        0.71779976 0.         1.         1.         1.
  0.1205111  0.279593   0.5812766  0.94752148]
 [2.         2.         0.82721129 0.1205111  0.5        1.
  0.76373632 0.96039278 0.         2.         0.         1.
  0.45990111 0.97156701 0.6073085  0.42397547]
 [2.         2.         0.61923926 0.70600643 0.0999984  0.
  0.32417579 0.42065225 0.         0.         1.         1.
  0.81013485 0.92650497 0.98694376 0.71951573]
 [2.         2.         0.35167692 0.66299556 0.7000008  1.
  0.5        0.90870562 0.         2.         1.         1.
  0.22601193 0.44822661 0.07069733 0.68498992]
 [2.         1.         0.65364187 0.9089921  0.0999984  0.
  0.10439552 0.67729902 0.         0.         1.         1.
  0.81013485 0.92650497 0.98694376 0.71951573]
 [1.         1.         0.76754601 0.39841284 0.7000008  1.
  0.84065942 0.97725023 0.         2.         1.         1.
  0.75169097 0.29618395 0.63992789 0.68498992]
 [2.         2.         0.85308842 0.61567675 0.5        0.
  0.57692309 0.46977571 2.         0.         1.         1.
  0.35727442 0.14357878 0.09625996 0.68498992]
 [3.         2.         0.55678623 0.38509383 0.5        0.
  0.11538453 0.55362796 0.         1.         1.         1.
  0.71951573 0.63198159 0.71280933 0.68498992]
 [0.         2.         0.5003095  0.07069733 0.5        0.
  0.03846144 0.46998802 0.         2.         0.         1.
  0.18658964 0.39841284 0.6073085  0.42397547]
 [0.         0.         0.63300178 0.45990111 0.7000008  0.
  0.20329664 0.08590925 0.         2.         1.         1.
  0.93922664 0.18658964 0.09625996 0.16557314]
 [0.         2.         0.62042608 0.43625651 0.7000008  0.
  0.0054944  0.09438662 2.         0.         0.         1.
  0.37138871 0.76397201 0.6073085  0.42397547]
 [2.         2.         0.57408355 0.89998624 0.7000008  0.
  0.80769238 0.3118426  1.         0.         1.         1.
  0.14357878 0.69910421 0.83685346 0.71951573]
 [2.         1.         0.61207106 0.88144294 0.9000016  0.
  0.89560448 0.09117699 0.         0.         1.         1.
  0.81013485 0.92650497 0.98694376 0.71951573]
 [1.         2.         0.43572106 0.50391366 0.7000008  0.
  0.55494507 0.63326409 0.         1.         2.         1.
  0.5812766  0.67777156 0.29618395 0.68498992]
 [0.         0.         0.95604223 0.52447314 0.9000016  0.
  0.48901099 0.69566817 0.         2.         0.         1.
  0.8766912  0.47129428 0.29618395 0.42397547]]
17:03:56 bandwidth of the KDEs:
[0.94975121 0.82783241 0.16204493 0.24765058 0.24870424 0.35071888
 0.21677374 0.13079339 0.8063266  0.6264507  0.55716962 0.001
 0.27642155 0.11886414 0.28209917 0.09020606]
[0.94727729 0.70626109 0.25015173 0.23791053 0.23599097 0.42120058
 0.2249843  0.25065169 0.79610963 0.73916923 0.57479897 0.001
 0.25261679 0.22480596 0.23748252 0.2065642 ]
17:03:56 l(x) = inf
17:03:56 g(x) = inf
17:03:56 best_vector: [0, 1, 0.12830373858274863, 0.0066335020394851785, 0.4066097630385309, 1, 0.41374656490745204, 0.2107297319189943, 0, 2, 2, 1, 0.9257169464832962, 0.5856585279566016, 0.26396865922347124, 0.41041418757284465], 0.020066618950642826, 0.009054695676541604, 0.00018169712785519342
17:03:56 done sampling a new configuration.
17:03:56 HBMASTER: schedule new run for iteration 4
17:03:56 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
17:03:56 HBMASTER: submitting job (4, 0, 25) to dispatcher
17:03:56 DISPATCHER: trying to submit job (4, 0, 25)
17:03:56 DISPATCHER: trying to notify the job_runner thread.
17:03:56 HBMASTER: job (4, 0, 25) submitted to dispatcher
17:03:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:03:56 DISPATCHER: Trying to submit another job.
17:03:56 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:03:56 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:03:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:03:56 WORKER: start processing job (4, 0, 25)
17:03:56 WORKER: args: ()
17:03:56 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0018055415088078688, 'num_filters_1': 16, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.01880033994590023, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 110, 'num_filters_3': 53}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:04:18 DISPATCHER: Starting worker discovery
17:04:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:04:18 DISPATCHER: Finished worker discovery
17:05:18 DISPATCHER: Starting worker discovery
17:05:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:05:18 DISPATCHER: Finished worker discovery
17:05:37 WORKER: done with job (4, 0, 25), trying to register it.
17:05:37 WORKER: registered result for job (4, 0, 25) with dispatcher
17:05:37 DISPATCHER: job (4, 0, 25) finished
17:05:37 DISPATCHER: register_result: lock acquired
17:05:37 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
17:05:37 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0018055415088078688, 'num_filters_1': 16, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.01880033994590023, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 110, 'num_filters_3': 53}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5225078064341554, 'info': {'music_genre': 0.5225078064341554, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0018055415088078688, 'num_filters_1': 16, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.01880033994590023, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 110, 'num_filters_3': 53}"}}
exception: None

17:05:37 job_callback for (4, 0, 25) started
17:05:37 DISPATCHER: Trying to submit another job.
17:05:37 job_callback for (4, 0, 25) got condition
17:05:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:05:37 done building a new model for budget 44.444444 based on 17/45 split
Best loss for this budget:-0.549965





17:05:37 HBMASTER: Trying to run another job!
17:05:37 job_callback for (4, 0, 25) finished
17:05:37 start sampling a new configuration.
17:05:37 best_vector: [1, 2, 0.28208624296795026, 0.17058796608997245, 0.6403861467937986, 1, 0.8847293256974454, 0.36036127490134495, 0, 0, 2, 1, 0.7786130803272326, 0.811357621393785, 0.1740047370648996, 0.563830610458909], 0.003365571799133842, 0.011137706436387814, 3.74847506893383e-05
17:05:37 done sampling a new configuration.
17:05:37 HBMASTER: schedule new run for iteration 4
17:05:37 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
17:05:37 HBMASTER: submitting job (4, 0, 26) to dispatcher
17:05:37 DISPATCHER: trying to submit job (4, 0, 26)
17:05:37 DISPATCHER: trying to notify the job_runner thread.
17:05:37 HBMASTER: job (4, 0, 26) submitted to dispatcher
17:05:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:05:37 DISPATCHER: Trying to submit another job.
17:05:37 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:05:37 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:05:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:05:37 WORKER: start processing job (4, 0, 26)
17:05:37 WORKER: args: ()
17:05:37 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0036658313919846535, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.02943342679647875, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 80, 'num_filters_3': 86, 'num_filters_4': 22}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:06:18 DISPATCHER: Starting worker discovery
17:06:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:06:18 DISPATCHER: Finished worker discovery
17:07:18 WORKER: done with job (4, 0, 26), trying to register it.
17:07:18 WORKER: registered result for job (4, 0, 26) with dispatcher
17:07:18 DISPATCHER: job (4, 0, 26) finished
17:07:18 DISPATCHER: register_result: lock acquired
17:07:18 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
17:07:18 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0036658313919846535, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.02943342679647875, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 80, 'num_filters_3': 86, 'num_filters_4': 22}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4993504663738403, 'info': {'music_genre': 0.4993504663738403, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0036658313919846535, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.02943342679647875, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 80, 'num_filters_3': 86, 'num_filters_4': 22}"}}
exception: None

17:07:18 job_callback for (4, 0, 26) started
17:07:18 DISPATCHER: Trying to submit another job.
17:07:18 job_callback for (4, 0, 26) got condition
17:07:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:07:18 done building a new model for budget 44.444444 based on 17/45 split
Best loss for this budget:-0.549965





17:07:18 HBMASTER: Trying to run another job!
17:07:18 job_callback for (4, 0, 26) finished
17:07:18 ITERATION: Advancing config (4, 0, 4) to next budget 133.333333
17:07:18 ITERATION: Advancing config (4, 0, 7) to next budget 133.333333
17:07:18 ITERATION: Advancing config (4, 0, 10) to next budget 133.333333
17:07:18 ITERATION: Advancing config (4, 0, 12) to next budget 133.333333
17:07:18 ITERATION: Advancing config (4, 0, 18) to next budget 133.333333
17:07:18 ITERATION: Advancing config (4, 0, 23) to next budget 133.333333
17:07:18 ITERATION: Advancing config (4, 0, 24) to next budget 133.333333
17:07:18 ITERATION: Advancing config (4, 0, 25) to next budget 133.333333
17:07:18 ITERATION: Advancing config (4, 0, 26) to next budget 133.333333
17:07:18 HBMASTER: schedule new run for iteration 4
17:07:18 HBMASTER: trying submitting job (4, 0, 4) to dispatcher
17:07:18 HBMASTER: submitting job (4, 0, 4) to dispatcher
17:07:18 DISPATCHER: trying to submit job (4, 0, 4)
17:07:18 DISPATCHER: trying to notify the job_runner thread.
17:07:18 HBMASTER: job (4, 0, 4) submitted to dispatcher
17:07:18 DISPATCHER: Trying to submit another job.
17:07:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:07:18 DISPATCHER: starting job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:07:18 DISPATCHER: job (4, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:07:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:07:18 WORKER: start processing job (4, 0, 4)
17:07:18 WORKER: args: ()
17:07:18 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0022115126271076363, 'num_filters_1': 28, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.022476636590969195}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:07:18 DISPATCHER: Starting worker discovery
17:07:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:07:18 DISPATCHER: Finished worker discovery
17:08:18 DISPATCHER: Starting worker discovery
17:08:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:08:18 DISPATCHER: Finished worker discovery
17:09:18 DISPATCHER: Starting worker discovery
17:09:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:09:18 DISPATCHER: Finished worker discovery
17:10:18 DISPATCHER: Starting worker discovery
17:10:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:10:19 DISPATCHER: Finished worker discovery
17:10:30 WORKER: done with job (4, 0, 4), trying to register it.
17:10:30 WORKER: registered result for job (4, 0, 4) with dispatcher
17:10:30 DISPATCHER: job (4, 0, 4) finished
17:10:30 DISPATCHER: register_result: lock acquired
17:10:30 DISPATCHER: job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
17:10:30 job_id: (4, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0022115126271076363, 'num_filters_1': 28, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.022476636590969195}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3702502455411898, 'info': {'music_genre': 0.3702502455411898, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0022115126271076363, 'num_filters_1': 28, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.022476636590969195}"}}
exception: None

17:10:30 job_callback for (4, 0, 4) started
17:10:30 job_callback for (4, 0, 4) got condition
17:10:30 DISPATCHER: Trying to submit another job.
17:10:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:10:30 HBMASTER: Trying to run another job!
17:10:30 job_callback for (4, 0, 4) finished
17:10:30 HBMASTER: schedule new run for iteration 4
17:10:30 HBMASTER: trying submitting job (4, 0, 7) to dispatcher
17:10:30 HBMASTER: submitting job (4, 0, 7) to dispatcher
17:10:30 DISPATCHER: trying to submit job (4, 0, 7)
17:10:30 DISPATCHER: trying to notify the job_runner thread.
17:10:30 HBMASTER: job (4, 0, 7) submitted to dispatcher
17:10:30 DISPATCHER: Trying to submit another job.
17:10:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:10:30 DISPATCHER: starting job (4, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:10:30 DISPATCHER: job (4, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:10:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:10:30 WORKER: start processing job (4, 0, 7)
17:10:30 WORKER: args: ()
17:10:30 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0016450753224302986, 'num_filters_1': 25, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.01625835303684367}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:11:19 DISPATCHER: Starting worker discovery
17:11:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:11:19 DISPATCHER: Finished worker discovery
17:12:19 DISPATCHER: Starting worker discovery
17:12:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:12:19 DISPATCHER: Finished worker discovery
17:13:19 DISPATCHER: Starting worker discovery
17:13:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:13:19 DISPATCHER: Finished worker discovery
17:13:41 WORKER: done with job (4, 0, 7), trying to register it.
17:13:41 WORKER: registered result for job (4, 0, 7) with dispatcher
17:13:41 DISPATCHER: job (4, 0, 7) finished
17:13:41 DISPATCHER: register_result: lock acquired
17:13:41 DISPATCHER: job (4, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
17:13:41 job_id: (4, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0016450753224302986, 'num_filters_1': 25, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.01625835303684367}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.39339666474532875, 'info': {'music_genre': 0.39339666474532875, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0016450753224302986, 'num_filters_1': 25, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.01625835303684367}"}}
exception: None

17:13:41 job_callback for (4, 0, 7) started
17:13:41 DISPATCHER: Trying to submit another job.
17:13:41 job_callback for (4, 0, 7) got condition
17:13:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:13:41 HBMASTER: Trying to run another job!
17:13:41 job_callback for (4, 0, 7) finished
17:13:41 HBMASTER: schedule new run for iteration 4
17:13:41 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
17:13:41 HBMASTER: submitting job (4, 0, 10) to dispatcher
17:13:41 DISPATCHER: trying to submit job (4, 0, 10)
17:13:41 DISPATCHER: trying to notify the job_runner thread.
17:13:41 HBMASTER: job (4, 0, 10) submitted to dispatcher
17:13:41 DISPATCHER: Trying to submit another job.
17:13:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:13:41 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:13:41 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:13:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:13:41 WORKER: start processing job (4, 0, 10)
17:13:41 WORKER: args: ()
17:13:41 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004638995494069737, 'num_filters_1': 35, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.032127915772929345, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 22, 'num_filters_3': 46}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:14:19 DISPATCHER: Starting worker discovery
17:14:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:14:19 DISPATCHER: Finished worker discovery
17:15:19 DISPATCHER: Starting worker discovery
17:15:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:15:19 DISPATCHER: Finished worker discovery
17:16:19 DISPATCHER: Starting worker discovery
17:16:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:16:19 DISPATCHER: Finished worker discovery
17:16:52 WORKER: done with job (4, 0, 10), trying to register it.
17:16:52 WORKER: registered result for job (4, 0, 10) with dispatcher
17:16:52 DISPATCHER: job (4, 0, 10) finished
17:16:52 DISPATCHER: register_result: lock acquired
17:16:52 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
17:16:52 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004638995494069737, 'num_filters_1': 35, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.032127915772929345, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 22, 'num_filters_3': 46}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4522125008878763, 'info': {'music_genre': 0.4522125008878763, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004638995494069737, 'num_filters_1': 35, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.032127915772929345, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 22, 'num_filters_3': 46}"}}
exception: None

17:16:52 job_callback for (4, 0, 10) started
17:16:52 job_callback for (4, 0, 10) got condition
17:16:52 DISPATCHER: Trying to submit another job.
17:16:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:16:52 HBMASTER: Trying to run another job!
17:16:52 job_callback for (4, 0, 10) finished
17:16:52 HBMASTER: schedule new run for iteration 4
17:16:52 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
17:16:52 HBMASTER: submitting job (4, 0, 12) to dispatcher
17:16:52 DISPATCHER: trying to submit job (4, 0, 12)
17:16:52 DISPATCHER: trying to notify the job_runner thread.
17:16:52 HBMASTER: job (4, 0, 12) submitted to dispatcher
17:16:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:16:52 DISPATCHER: Trying to submit another job.
17:16:52 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:16:52 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:16:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:16:52 WORKER: start processing job (4, 0, 12)
17:16:52 WORKER: args: ()
17:16:52 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.009698914487701592, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.014561242268050925, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 41, 'num_filters_3': 55, 'num_filters_4': 23, 'num_filters_5': 41}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:17:19 DISPATCHER: Starting worker discovery
17:17:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:17:19 DISPATCHER: Finished worker discovery
17:18:19 DISPATCHER: Starting worker discovery
17:18:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:18:19 DISPATCHER: Finished worker discovery
17:19:19 DISPATCHER: Starting worker discovery
17:19:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:19:19 DISPATCHER: Finished worker discovery
17:20:03 WORKER: done with job (4, 0, 12), trying to register it.
17:20:03 WORKER: registered result for job (4, 0, 12) with dispatcher
17:20:03 DISPATCHER: job (4, 0, 12) finished
17:20:03 DISPATCHER: register_result: lock acquired
17:20:03 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
17:20:03 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.009698914487701592, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.014561242268050925, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 41, 'num_filters_3': 55, 'num_filters_4': 23, 'num_filters_5': 41}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5430416236871235, 'info': {'music_genre': 0.5430416236871235, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.009698914487701592, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.014561242268050925, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 41, 'num_filters_3': 55, 'num_filters_4': 23, 'num_filters_5': 41}"}}
exception: None

17:20:03 job_callback for (4, 0, 12) started
17:20:03 DISPATCHER: Trying to submit another job.
17:20:03 job_callback for (4, 0, 12) got condition
17:20:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:20:03 HBMASTER: Trying to run another job!
17:20:03 job_callback for (4, 0, 12) finished
17:20:03 HBMASTER: schedule new run for iteration 4
17:20:03 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
17:20:03 HBMASTER: submitting job (4, 0, 18) to dispatcher
17:20:03 DISPATCHER: trying to submit job (4, 0, 18)
17:20:03 DISPATCHER: trying to notify the job_runner thread.
17:20:03 HBMASTER: job (4, 0, 18) submitted to dispatcher
17:20:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:20:03 DISPATCHER: Trying to submit another job.
17:20:03 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:20:03 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:20:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:20:03 WORKER: start processing job (4, 0, 18)
17:20:03 WORKER: args: ()
17:20:03 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.017278937296318124, 'num_filters_1': 25, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.0114004765516358, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 111, 'num_filters_3': 84, 'num_filters_4': 20}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:20:19 DISPATCHER: Starting worker discovery
17:20:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:20:19 DISPATCHER: Finished worker discovery
17:21:19 DISPATCHER: Starting worker discovery
17:21:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:21:19 DISPATCHER: Finished worker discovery
17:22:19 DISPATCHER: Starting worker discovery
17:22:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:22:19 DISPATCHER: Finished worker discovery
17:23:14 WORKER: done with job (4, 0, 18), trying to register it.
17:23:14 WORKER: registered result for job (4, 0, 18) with dispatcher
17:23:14 DISPATCHER: job (4, 0, 18) finished
17:23:14 DISPATCHER: register_result: lock acquired
17:23:14 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
17:23:14 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.017278937296318124, 'num_filters_1': 25, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.0114004765516358, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 111, 'num_filters_3': 84, 'num_filters_4': 20}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.374025620328149, 'info': {'music_genre': 0.374025620328149, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.017278937296318124, 'num_filters_1': 25, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.0114004765516358, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 111, 'num_filters_3': 84, 'num_filters_4': 20}"}}
exception: None

17:23:14 job_callback for (4, 0, 18) started
17:23:14 DISPATCHER: Trying to submit another job.
17:23:14 job_callback for (4, 0, 18) got condition
17:23:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:23:14 HBMASTER: Trying to run another job!
17:23:14 job_callback for (4, 0, 18) finished
17:23:14 HBMASTER: schedule new run for iteration 4
17:23:14 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
17:23:14 HBMASTER: submitting job (4, 0, 23) to dispatcher
17:23:14 DISPATCHER: trying to submit job (4, 0, 23)
17:23:14 DISPATCHER: trying to notify the job_runner thread.
17:23:14 HBMASTER: job (4, 0, 23) submitted to dispatcher
17:23:14 DISPATCHER: Trying to submit another job.
17:23:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:23:14 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:23:14 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:23:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:23:14 WORKER: start processing job (4, 0, 23)
17:23:14 WORKER: args: ()
17:23:14 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.002697972192950829, 'num_filters_1': 72, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.0447274326766434, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 82, 'num_filters_3': 79, 'num_filters_4': 112}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:23:19 DISPATCHER: Starting worker discovery
17:23:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:23:19 DISPATCHER: Finished worker discovery
17:24:19 DISPATCHER: Starting worker discovery
17:24:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:24:19 DISPATCHER: Finished worker discovery
17:25:19 DISPATCHER: Starting worker discovery
17:25:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:25:19 DISPATCHER: Finished worker discovery
17:26:19 DISPATCHER: Starting worker discovery
17:26:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:26:19 DISPATCHER: Finished worker discovery
17:26:26 WORKER: done with job (4, 0, 23), trying to register it.
17:26:26 WORKER: registered result for job (4, 0, 23) with dispatcher
17:26:26 DISPATCHER: job (4, 0, 23) finished
17:26:26 DISPATCHER: register_result: lock acquired
17:26:26 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
17:26:26 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.002697972192950829, 'num_filters_1': 72, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.0447274326766434, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 82, 'num_filters_3': 79, 'num_filters_4': 112}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.47464648960744854, 'info': {'music_genre': 0.47464648960744854, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.002697972192950829, 'num_filters_1': 72, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.0447274326766434, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 82, 'num_filters_3': 79, 'num_filters_4': 112}"}}
exception: None

17:26:26 job_callback for (4, 0, 23) started
17:26:26 DISPATCHER: Trying to submit another job.
17:26:26 job_callback for (4, 0, 23) got condition
17:26:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:26:26 HBMASTER: Trying to run another job!
17:26:26 job_callback for (4, 0, 23) finished
17:26:26 HBMASTER: schedule new run for iteration 4
17:26:26 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
17:26:26 HBMASTER: submitting job (4, 0, 24) to dispatcher
17:26:26 DISPATCHER: trying to submit job (4, 0, 24)
17:26:26 DISPATCHER: trying to notify the job_runner thread.
17:26:26 HBMASTER: job (4, 0, 24) submitted to dispatcher
17:26:26 DISPATCHER: Trying to submit another job.
17:26:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:26:26 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:26:26 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:26:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:26:26 WORKER: start processing job (4, 0, 24)
17:26:26 WORKER: args: ()
17:26:26 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.003149349315152282, 'num_filters_1': 73, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.019654066405520938}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:27:19 DISPATCHER: Starting worker discovery
17:27:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:27:19 DISPATCHER: Finished worker discovery
17:28:19 DISPATCHER: Starting worker discovery
17:28:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:28:19 DISPATCHER: Finished worker discovery
17:29:19 DISPATCHER: Starting worker discovery
17:29:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:29:19 DISPATCHER: Finished worker discovery
17:29:37 WORKER: done with job (4, 0, 24), trying to register it.
17:29:37 WORKER: registered result for job (4, 0, 24) with dispatcher
17:29:37 DISPATCHER: job (4, 0, 24) finished
17:29:37 DISPATCHER: register_result: lock acquired
17:29:37 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
17:29:37 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.003149349315152282, 'num_filters_1': 73, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.019654066405520938}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.44279127480033864, 'info': {'music_genre': 0.44279127480033864, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.003149349315152282, 'num_filters_1': 73, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.019654066405520938}"}}
exception: None

17:29:37 job_callback for (4, 0, 24) started
17:29:37 DISPATCHER: Trying to submit another job.
17:29:37 job_callback for (4, 0, 24) got condition
17:29:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:29:37 HBMASTER: Trying to run another job!
17:29:37 job_callback for (4, 0, 24) finished
17:29:37 HBMASTER: schedule new run for iteration 4
17:29:37 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
17:29:37 HBMASTER: submitting job (4, 0, 25) to dispatcher
17:29:37 DISPATCHER: trying to submit job (4, 0, 25)
17:29:37 DISPATCHER: trying to notify the job_runner thread.
17:29:37 HBMASTER: job (4, 0, 25) submitted to dispatcher
17:29:37 DISPATCHER: Trying to submit another job.
17:29:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:29:37 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:29:37 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:29:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:29:37 WORKER: start processing job (4, 0, 25)
17:29:37 WORKER: args: ()
17:29:37 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0018055415088078688, 'num_filters_1': 16, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.01880033994590023, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 110, 'num_filters_3': 53}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:30:19 DISPATCHER: Starting worker discovery
17:30:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:30:19 DISPATCHER: Finished worker discovery
17:31:19 DISPATCHER: Starting worker discovery
17:31:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:31:19 DISPATCHER: Finished worker discovery
17:32:19 DISPATCHER: Starting worker discovery
17:32:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:32:19 DISPATCHER: Finished worker discovery
17:32:50 WORKER: done with job (4, 0, 25), trying to register it.
17:32:50 WORKER: registered result for job (4, 0, 25) with dispatcher
17:32:50 DISPATCHER: job (4, 0, 25) finished
17:32:50 DISPATCHER: register_result: lock acquired
17:32:50 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
17:32:50 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0018055415088078688, 'num_filters_1': 16, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.01880033994590023, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 110, 'num_filters_3': 53}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5117041415755035, 'info': {'music_genre': 0.5117041415755035, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0018055415088078688, 'num_filters_1': 16, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.01880033994590023, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 110, 'num_filters_3': 53}"}}
exception: None

17:32:50 job_callback for (4, 0, 25) started
17:32:50 DISPATCHER: Trying to submit another job.
17:32:50 job_callback for (4, 0, 25) got condition
17:32:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:32:50 HBMASTER: Trying to run another job!
17:32:50 job_callback for (4, 0, 25) finished
17:32:50 HBMASTER: schedule new run for iteration 4
17:32:50 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
17:32:50 HBMASTER: submitting job (4, 0, 26) to dispatcher
17:32:50 DISPATCHER: trying to submit job (4, 0, 26)
17:32:50 DISPATCHER: trying to notify the job_runner thread.
17:32:50 HBMASTER: job (4, 0, 26) submitted to dispatcher
17:32:50 DISPATCHER: Trying to submit another job.
17:32:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:32:50 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:32:50 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:32:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:32:50 WORKER: start processing job (4, 0, 26)
17:32:50 WORKER: args: ()
17:32:50 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0036658313919846535, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.02943342679647875, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 80, 'num_filters_3': 86, 'num_filters_4': 22}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:33:19 DISPATCHER: Starting worker discovery
17:33:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:33:19 DISPATCHER: Finished worker discovery
17:34:19 DISPATCHER: Starting worker discovery
17:34:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:34:19 DISPATCHER: Finished worker discovery
17:35:19 DISPATCHER: Starting worker discovery
17:35:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:35:19 DISPATCHER: Finished worker discovery
17:36:01 WORKER: done with job (4, 0, 26), trying to register it.
17:36:01 WORKER: registered result for job (4, 0, 26) with dispatcher
17:36:01 DISPATCHER: job (4, 0, 26) finished
17:36:01 DISPATCHER: register_result: lock acquired
17:36:01 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
17:36:01 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0036658313919846535, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.02943342679647875, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 80, 'num_filters_3': 86, 'num_filters_4': 22}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4729694241521525, 'info': {'music_genre': 0.4729694241521525, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0036658313919846535, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.02943342679647875, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 80, 'num_filters_3': 86, 'num_filters_4': 22}"}}
exception: None

17:36:02 job_callback for (4, 0, 26) started
17:36:02 DISPATCHER: Trying to submit another job.
17:36:02 job_callback for (4, 0, 26) got condition
17:36:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:36:02 HBMASTER: Trying to run another job!
17:36:02 job_callback for (4, 0, 26) finished
17:36:02 ITERATION: Advancing config (4, 0, 12) to next budget 400.000000
17:36:02 ITERATION: Advancing config (4, 0, 23) to next budget 400.000000
17:36:02 ITERATION: Advancing config (4, 0, 25) to next budget 400.000000
17:36:02 HBMASTER: schedule new run for iteration 4
17:36:02 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
17:36:02 HBMASTER: submitting job (4, 0, 12) to dispatcher
17:36:02 DISPATCHER: trying to submit job (4, 0, 12)
17:36:02 DISPATCHER: trying to notify the job_runner thread.
17:36:02 HBMASTER: job (4, 0, 12) submitted to dispatcher
17:36:02 DISPATCHER: Trying to submit another job.
17:36:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:36:02 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:36:02 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:36:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:36:02 WORKER: start processing job (4, 0, 12)
17:36:02 WORKER: args: ()
17:36:02 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.009698914487701592, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.014561242268050925, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 41, 'num_filters_3': 55, 'num_filters_4': 23, 'num_filters_5': 41}, 'budget': 400.0, 'working_directory': '.'}
17:36:19 DISPATCHER: Starting worker discovery
17:36:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:36:19 DISPATCHER: Finished worker discovery
17:37:19 DISPATCHER: Starting worker discovery
17:37:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:37:19 DISPATCHER: Finished worker discovery
17:38:19 DISPATCHER: Starting worker discovery
17:38:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:38:19 DISPATCHER: Finished worker discovery
17:39:19 DISPATCHER: Starting worker discovery
17:39:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:39:19 DISPATCHER: Finished worker discovery
17:40:19 DISPATCHER: Starting worker discovery
17:40:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:40:19 DISPATCHER: Finished worker discovery
17:41:19 DISPATCHER: Starting worker discovery
17:41:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:41:19 DISPATCHER: Finished worker discovery
17:42:19 DISPATCHER: Starting worker discovery
17:42:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:42:19 DISPATCHER: Finished worker discovery
17:43:19 DISPATCHER: Starting worker discovery
17:43:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:43:19 DISPATCHER: Finished worker discovery
17:43:43 WORKER: done with job (4, 0, 12), trying to register it.
17:43:43 WORKER: registered result for job (4, 0, 12) with dispatcher
17:43:43 DISPATCHER: job (4, 0, 12) finished
17:43:43 DISPATCHER: register_result: lock acquired
17:43:43 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
17:43:43 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.009698914487701592, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.014561242268050925, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 41, 'num_filters_3': 55, 'num_filters_4': 23, 'num_filters_5': 41}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.4843100268904608, 'info': {'music_genre': 0.4843100268904608, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.009698914487701592, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.014561242268050925, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 41, 'num_filters_3': 55, 'num_filters_4': 23, 'num_filters_5': 41}"}}
exception: None

17:43:43 job_callback for (4, 0, 12) started
17:43:43 DISPATCHER: Trying to submit another job.
17:43:43 job_callback for (4, 0, 12) got condition
17:43:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:43:43 Only 13 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
17:43:43 HBMASTER: Trying to run another job!
17:43:43 job_callback for (4, 0, 12) finished
17:43:43 HBMASTER: schedule new run for iteration 4
17:43:43 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
17:43:43 HBMASTER: submitting job (4, 0, 23) to dispatcher
17:43:43 DISPATCHER: trying to submit job (4, 0, 23)
17:43:43 DISPATCHER: trying to notify the job_runner thread.
17:43:43 HBMASTER: job (4, 0, 23) submitted to dispatcher
17:43:43 DISPATCHER: Trying to submit another job.
17:43:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:43:43 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:43:43 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:43:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:43:43 WORKER: start processing job (4, 0, 23)
17:43:43 WORKER: args: ()
17:43:43 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.002697972192950829, 'num_filters_1': 72, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.0447274326766434, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 82, 'num_filters_3': 79, 'num_filters_4': 112}, 'budget': 400.0, 'working_directory': '.'}
17:44:19 DISPATCHER: Starting worker discovery
17:44:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:44:19 DISPATCHER: Finished worker discovery
17:45:19 DISPATCHER: Starting worker discovery
17:45:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:45:19 DISPATCHER: Finished worker discovery
17:46:19 DISPATCHER: Starting worker discovery
17:46:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:46:19 DISPATCHER: Finished worker discovery
17:47:19 DISPATCHER: Starting worker discovery
17:47:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:47:19 DISPATCHER: Finished worker discovery
17:48:19 DISPATCHER: Starting worker discovery
17:48:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:48:19 DISPATCHER: Finished worker discovery
17:49:19 DISPATCHER: Starting worker discovery
17:49:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:49:19 DISPATCHER: Finished worker discovery
17:50:19 DISPATCHER: Starting worker discovery
17:50:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:50:19 DISPATCHER: Finished worker discovery
17:51:19 DISPATCHER: Starting worker discovery
17:51:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:51:19 DISPATCHER: Finished worker discovery
17:51:24 WORKER: done with job (4, 0, 23), trying to register it.
17:51:24 WORKER: registered result for job (4, 0, 23) with dispatcher
17:51:24 DISPATCHER: job (4, 0, 23) finished
17:51:24 DISPATCHER: register_result: lock acquired
17:51:24 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
17:51:24 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.002697972192950829, 'num_filters_1': 72, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.0447274326766434, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 82, 'num_filters_3': 79, 'num_filters_4': 112}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3349131573814494, 'info': {'music_genre': 0.3349131573814494, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.002697972192950829, 'num_filters_1': 72, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.0447274326766434, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 82, 'num_filters_3': 79, 'num_filters_4': 112}"}}
exception: None

17:51:24 job_callback for (4, 0, 23) started
17:51:24 DISPATCHER: Trying to submit another job.
17:51:24 job_callback for (4, 0, 23) got condition
17:51:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:51:24 Only 14 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
17:51:24 HBMASTER: Trying to run another job!
17:51:24 job_callback for (4, 0, 23) finished
17:51:24 HBMASTER: schedule new run for iteration 4
17:51:24 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
17:51:24 HBMASTER: submitting job (4, 0, 25) to dispatcher
17:51:24 DISPATCHER: trying to submit job (4, 0, 25)
17:51:24 DISPATCHER: trying to notify the job_runner thread.
17:51:24 HBMASTER: job (4, 0, 25) submitted to dispatcher
17:51:24 DISPATCHER: Trying to submit another job.
17:51:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:51:24 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:51:24 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:51:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:51:24 WORKER: start processing job (4, 0, 25)
17:51:24 WORKER: args: ()
17:51:24 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0018055415088078688, 'num_filters_1': 16, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.01880033994590023, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 110, 'num_filters_3': 53}, 'budget': 400.0, 'working_directory': '.'}
17:52:19 DISPATCHER: Starting worker discovery
17:52:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:52:19 DISPATCHER: Finished worker discovery
17:53:19 DISPATCHER: Starting worker discovery
17:53:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:53:19 DISPATCHER: Finished worker discovery
17:54:19 DISPATCHER: Starting worker discovery
17:54:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:54:19 DISPATCHER: Finished worker discovery
17:55:19 DISPATCHER: Starting worker discovery
17:55:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:55:19 DISPATCHER: Finished worker discovery
17:56:19 DISPATCHER: Starting worker discovery
17:56:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:56:19 DISPATCHER: Finished worker discovery
17:57:19 DISPATCHER: Starting worker discovery
17:57:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:57:19 DISPATCHER: Finished worker discovery
17:58:19 DISPATCHER: Starting worker discovery
17:58:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:58:19 DISPATCHER: Finished worker discovery
17:59:07 WORKER: done with job (4, 0, 25), trying to register it.
17:59:07 WORKER: registered result for job (4, 0, 25) with dispatcher
17:59:07 DISPATCHER: job (4, 0, 25) finished
17:59:07 DISPATCHER: register_result: lock acquired
17:59:07 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
17:59:07 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0018055415088078688, 'num_filters_1': 16, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.01880033994590023, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 110, 'num_filters_3': 53}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.4514902000203446, 'info': {'music_genre': 0.4514902000203446, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0018055415088078688, 'num_filters_1': 16, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.01880033994590023, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 110, 'num_filters_3': 53}"}}
exception: None

17:59:07 job_callback for (4, 0, 25) started
17:59:07 job_callback for (4, 0, 25) got condition
17:59:07 DISPATCHER: Trying to submit another job.
17:59:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:59:07 Only 15 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
17:59:07 HBMASTER: Trying to run another job!
17:59:07 job_callback for (4, 0, 25) finished
17:59:07 ITERATION: Advancing config (4, 0, 12) to next budget 1200.000000
17:59:07 HBMASTER: schedule new run for iteration 4
17:59:07 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
17:59:07 HBMASTER: submitting job (4, 0, 12) to dispatcher
17:59:07 DISPATCHER: trying to submit job (4, 0, 12)
17:59:07 DISPATCHER: trying to notify the job_runner thread.
17:59:07 HBMASTER: job (4, 0, 12) submitted to dispatcher
17:59:07 DISPATCHER: Trying to submit another job.
17:59:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:59:07 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:59:07 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:59:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:59:07 WORKER: start processing job (4, 0, 12)
17:59:07 WORKER: args: ()
17:59:07 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.009698914487701592, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.014561242268050925, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 41, 'num_filters_3': 55, 'num_filters_4': 23, 'num_filters_5': 41}, 'budget': 1200.0, 'working_directory': '.'}
17:59:19 DISPATCHER: Starting worker discovery
17:59:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:59:19 DISPATCHER: Finished worker discovery
18:00:19 DISPATCHER: Starting worker discovery
18:00:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:00:19 DISPATCHER: Finished worker discovery
18:01:19 DISPATCHER: Starting worker discovery
18:01:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:01:19 DISPATCHER: Finished worker discovery
18:02:19 DISPATCHER: Starting worker discovery
18:02:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:02:19 DISPATCHER: Finished worker discovery
18:03:19 DISPATCHER: Starting worker discovery
18:03:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:03:19 DISPATCHER: Finished worker discovery
18:04:19 DISPATCHER: Starting worker discovery
18:04:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:04:19 DISPATCHER: Finished worker discovery
18:05:19 DISPATCHER: Starting worker discovery
18:05:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:05:19 DISPATCHER: Finished worker discovery
18:06:19 DISPATCHER: Starting worker discovery
18:06:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:06:19 DISPATCHER: Finished worker discovery
18:07:19 DISPATCHER: Starting worker discovery
18:07:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:07:19 DISPATCHER: Finished worker discovery
18:08:19 DISPATCHER: Starting worker discovery
18:08:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:08:19 DISPATCHER: Finished worker discovery
18:09:19 DISPATCHER: Starting worker discovery
18:09:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:09:19 DISPATCHER: Finished worker discovery
18:10:19 DISPATCHER: Starting worker discovery
18:10:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:10:19 DISPATCHER: Finished worker discovery
18:11:19 DISPATCHER: Starting worker discovery
18:11:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:11:19 DISPATCHER: Finished worker discovery
18:12:19 DISPATCHER: Starting worker discovery
18:12:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:12:19 DISPATCHER: Finished worker discovery
18:13:19 DISPATCHER: Starting worker discovery
18:13:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:13:19 DISPATCHER: Finished worker discovery
18:14:19 DISPATCHER: Starting worker discovery
18:14:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:14:19 DISPATCHER: Finished worker discovery
18:15:19 DISPATCHER: Starting worker discovery
18:15:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:15:19 DISPATCHER: Finished worker discovery
18:16:19 DISPATCHER: Starting worker discovery
18:16:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:16:19 DISPATCHER: Finished worker discovery
18:17:19 DISPATCHER: Starting worker discovery
18:17:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:17:19 DISPATCHER: Finished worker discovery
18:18:19 DISPATCHER: Starting worker discovery
18:18:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:18:19 DISPATCHER: Finished worker discovery
18:19:19 DISPATCHER: Starting worker discovery
18:19:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:19:19 DISPATCHER: Finished worker discovery
18:20:10 WORKER: done with job (4, 0, 12), trying to register it.
18:20:10 WORKER: registered result for job (4, 0, 12) with dispatcher
18:20:10 DISPATCHER: job (4, 0, 12) finished
18:20:10 DISPATCHER: register_result: lock acquired
18:20:10 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
18:20:10 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.009698914487701592, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.014561242268050925, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 41, 'num_filters_3': 55, 'num_filters_4': 23, 'num_filters_5': 41}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.42533886616136696, 'info': {'music_genre': 0.42533886616136696, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.009698914487701592, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.014561242268050925, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 41, 'num_filters_3': 55, 'num_filters_4': 23, 'num_filters_5': 41}"}}
exception: None

18:20:10 job_callback for (4, 0, 12) started
18:20:10 DISPATCHER: Trying to submit another job.
18:20:10 job_callback for (4, 0, 12) got condition
18:20:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:20:10 Only 9 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
18:20:10 HBMASTER: Trying to run another job!
18:20:10 job_callback for (4, 0, 12) finished
18:20:10 start sampling a new configuration.
18:20:10 done sampling a new configuration.
18:20:10 HBMASTER: schedule new run for iteration 5
18:20:10 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
18:20:10 HBMASTER: submitting job (5, 0, 0) to dispatcher
18:20:10 DISPATCHER: trying to submit job (5, 0, 0)
18:20:10 DISPATCHER: trying to notify the job_runner thread.
18:20:10 HBMASTER: job (5, 0, 0) submitted to dispatcher
18:20:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:20:10 DISPATCHER: Trying to submit another job.
18:20:10 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:20:10 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:20:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:20:10 WORKER: start processing job (5, 0, 0)
18:20:10 WORKER: args: ()
18:20:10 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.015488899005406518, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.014994349164675447, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 55, 'num_filters_3': 22, 'num_filters_4': 36}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:20:19 DISPATCHER: Starting worker discovery
18:20:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:20:19 DISPATCHER: Finished worker discovery
18:21:19 DISPATCHER: Starting worker discovery
18:21:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:21:19 DISPATCHER: Finished worker discovery
18:22:19 DISPATCHER: Starting worker discovery
18:22:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:22:19 DISPATCHER: Finished worker discovery
18:23:19 DISPATCHER: Starting worker discovery
18:23:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:23:19 DISPATCHER: Finished worker discovery
18:23:21 WORKER: done with job (5, 0, 0), trying to register it.
18:23:21 WORKER: registered result for job (5, 0, 0) with dispatcher
18:23:21 DISPATCHER: job (5, 0, 0) finished
18:23:21 DISPATCHER: register_result: lock acquired
18:23:21 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
18:23:21 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.015488899005406518, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.014994349164675447, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 55, 'num_filters_3': 22, 'num_filters_4': 36}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.41146420484766866, 'info': {'music_genre': 0.41146420484766866, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.015488899005406518, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.014994349164675447, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 55, 'num_filters_3': 22, 'num_filters_4': 36}"}}
exception: None

18:23:21 job_callback for (5, 0, 0) started
18:23:21 DISPATCHER: Trying to submit another job.
18:23:21 job_callback for (5, 0, 0) got condition
18:23:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:23:21 HBMASTER: Trying to run another job!
18:23:21 job_callback for (5, 0, 0) finished
18:23:21 start sampling a new configuration.
18:23:21 done sampling a new configuration.
18:23:21 HBMASTER: schedule new run for iteration 5
18:23:21 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
18:23:21 HBMASTER: submitting job (5, 0, 1) to dispatcher
18:23:21 DISPATCHER: trying to submit job (5, 0, 1)
18:23:21 DISPATCHER: trying to notify the job_runner thread.
18:23:21 HBMASTER: job (5, 0, 1) submitted to dispatcher
18:23:21 DISPATCHER: Trying to submit another job.
18:23:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:23:21 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:23:21 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:23:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:23:21 WORKER: start processing job (5, 0, 1)
18:23:21 WORKER: args: ()
18:23:21 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.08441622403407505, 'num_filters_1': 82, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.011275187035029442, 'kernel_size_2': 3, 'num_filters_2': 32}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:24:19 DISPATCHER: Starting worker discovery
18:24:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:24:19 DISPATCHER: Finished worker discovery
18:25:19 DISPATCHER: Starting worker discovery
18:25:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:25:19 DISPATCHER: Finished worker discovery
18:26:19 DISPATCHER: Starting worker discovery
18:26:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:26:19 DISPATCHER: Finished worker discovery
18:26:35 WORKER: done with job (5, 0, 1), trying to register it.
18:26:35 WORKER: registered result for job (5, 0, 1) with dispatcher
18:26:35 DISPATCHER: job (5, 0, 1) finished
18:26:35 DISPATCHER: register_result: lock acquired
18:26:35 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
18:26:35 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.08441622403407505, 'num_filters_1': 82, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.011275187035029442, 'kernel_size_2': 3, 'num_filters_2': 32}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2674148167315118, 'info': {'music_genre': 0.2674148167315118, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.08441622403407505, 'num_filters_1': 82, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.011275187035029442, 'kernel_size_2': 3, 'num_filters_2': 32}"}}
exception: None

18:26:35 job_callback for (5, 0, 1) started
18:26:35 job_callback for (5, 0, 1) got condition
18:26:35 DISPATCHER: Trying to submit another job.
18:26:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:26:35 HBMASTER: Trying to run another job!
18:26:35 job_callback for (5, 0, 1) finished
18:26:35 start sampling a new configuration.
18:26:35 best_vector: [1, 1, 0.2407581797380966, 0.773422943154741, 0.33307395864560413, 1, 0.9362078874634693, 0.1691926448372, 1, 1, 0, 1, 0.7991095458751956, 0.6765684504819834, 0.07024529056414724, 0.4372608022398713], 9.450337800113484e-05, 0.059610175012413405, 5.6333629019119065e-06
18:26:35 done sampling a new configuration.
18:26:35 HBMASTER: schedule new run for iteration 5
18:26:35 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
18:26:35 HBMASTER: submitting job (5, 0, 2) to dispatcher
18:26:35 DISPATCHER: trying to submit job (5, 0, 2)
18:26:35 DISPATCHER: trying to notify the job_runner thread.
18:26:35 HBMASTER: job (5, 0, 2) submitted to dispatcher
18:26:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:26:35 DISPATCHER: Trying to submit another job.
18:26:35 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:26:35 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:26:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:26:35 WORKER: start processing job (5, 0, 2)
18:26:35 WORKER: args: ()
18:26:35 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.00303051445234787, 'num_filters_1': 80, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.016600635198176488, 'kernel_size_2': 5, 'num_filters_2': 84}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:27:19 DISPATCHER: Starting worker discovery
18:27:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:27:19 DISPATCHER: Finished worker discovery
18:28:19 DISPATCHER: Starting worker discovery
18:28:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:28:19 DISPATCHER: Finished worker discovery
18:29:19 DISPATCHER: Starting worker discovery
18:29:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:29:19 DISPATCHER: Finished worker discovery
18:29:45 WORKER: done with job (5, 0, 2), trying to register it.
18:29:45 WORKER: registered result for job (5, 0, 2) with dispatcher
18:29:45 DISPATCHER: job (5, 0, 2) finished
18:29:45 DISPATCHER: register_result: lock acquired
18:29:45 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
18:29:45 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.00303051445234787, 'num_filters_1': 80, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.016600635198176488, 'kernel_size_2': 5, 'num_filters_2': 84}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4546673458941054, 'info': {'music_genre': 0.4546673458941054, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.00303051445234787, 'num_filters_1': 80, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.016600635198176488, 'kernel_size_2': 5, 'num_filters_2': 84}"}}
exception: None

18:29:45 job_callback for (5, 0, 2) started
18:29:45 DISPATCHER: Trying to submit another job.
18:29:45 job_callback for (5, 0, 2) got condition
18:29:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:29:45 HBMASTER: Trying to run another job!
18:29:45 job_callback for (5, 0, 2) finished
18:29:45 start sampling a new configuration.
18:29:45 done sampling a new configuration.
18:29:45 HBMASTER: schedule new run for iteration 5
18:29:45 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
18:29:45 HBMASTER: submitting job (5, 0, 3) to dispatcher
18:29:45 DISPATCHER: trying to submit job (5, 0, 3)
18:29:45 DISPATCHER: trying to notify the job_runner thread.
18:29:45 HBMASTER: job (5, 0, 3) submitted to dispatcher
18:29:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:29:45 DISPATCHER: Trying to submit another job.
18:29:45 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:29:45 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:29:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:29:45 WORKER: start processing job (5, 0, 3)
18:29:45 WORKER: args: ()
18:29:45 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.010322135620414254, 'num_filters_1': 64, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.06024192615676381, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 38, 'num_filters_3': 19}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:30:19 DISPATCHER: Starting worker discovery
18:30:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:30:19 DISPATCHER: Finished worker discovery
18:31:19 DISPATCHER: Starting worker discovery
18:31:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:31:19 DISPATCHER: Finished worker discovery
18:32:19 DISPATCHER: Starting worker discovery
18:32:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:32:19 DISPATCHER: Finished worker discovery
18:32:57 WORKER: done with job (5, 0, 3), trying to register it.
18:32:57 WORKER: registered result for job (5, 0, 3) with dispatcher
18:32:57 DISPATCHER: job (5, 0, 3) finished
18:32:57 DISPATCHER: register_result: lock acquired
18:32:57 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
18:32:57 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.010322135620414254, 'num_filters_1': 64, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.06024192615676381, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 38, 'num_filters_3': 19}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.001444407521903786, 'info': {'music_genre': 0.001444407521903786, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.010322135620414254, 'num_filters_1': 64, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.06024192615676381, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 38, 'num_filters_3': 19}"}}
exception: None

18:32:57 job_callback for (5, 0, 3) started
18:32:57 job_callback for (5, 0, 3) got condition
18:32:57 DISPATCHER: Trying to submit another job.
18:32:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:32:57 HBMASTER: Trying to run another job!
18:32:57 job_callback for (5, 0, 3) finished
18:32:57 start sampling a new configuration.
18:32:57 done sampling a new configuration.
18:32:57 HBMASTER: schedule new run for iteration 5
18:32:57 HBMASTER: trying submitting job (5, 0, 4) to dispatcher
18:32:57 HBMASTER: submitting job (5, 0, 4) to dispatcher
18:32:57 DISPATCHER: trying to submit job (5, 0, 4)
18:32:57 DISPATCHER: trying to notify the job_runner thread.
18:32:57 HBMASTER: job (5, 0, 4) submitted to dispatcher
18:32:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:32:57 DISPATCHER: Trying to submit another job.
18:32:57 DISPATCHER: starting job (5, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:32:57 DISPATCHER: job (5, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:32:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:32:57 WORKER: start processing job (5, 0, 4)
18:32:57 WORKER: args: ()
18:32:57 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.009827584423317317, 'num_filters_1': 83, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.05493129089562775, 'kernel_size_2': 7, 'num_filters_2': 119}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:33:19 DISPATCHER: Starting worker discovery
18:33:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:33:19 DISPATCHER: Finished worker discovery
18:34:19 DISPATCHER: Starting worker discovery
18:34:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:34:19 DISPATCHER: Finished worker discovery
18:35:19 DISPATCHER: Starting worker discovery
18:35:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:35:19 DISPATCHER: Finished worker discovery
18:36:09 WORKER: done with job (5, 0, 4), trying to register it.
18:36:09 WORKER: registered result for job (5, 0, 4) with dispatcher
18:36:09 DISPATCHER: job (5, 0, 4) finished
18:36:09 DISPATCHER: register_result: lock acquired
18:36:09 DISPATCHER: job (5, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
18:36:09 job_id: (5, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.009827584423317317, 'num_filters_1': 83, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.05493129089562775, 'kernel_size_2': 7, 'num_filters_2': 119}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.007789032473547963, 'info': {'music_genre': 0.007789032473547963, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.009827584423317317, 'num_filters_1': 83, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.05493129089562775, 'kernel_size_2': 7, 'num_filters_2': 119}"}}
exception: None

18:36:09 job_callback for (5, 0, 4) started
18:36:09 job_callback for (5, 0, 4) got condition
18:36:09 DISPATCHER: Trying to submit another job.
18:36:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:36:09 HBMASTER: Trying to run another job!
18:36:09 job_callback for (5, 0, 4) finished
18:36:09 start sampling a new configuration.
18:36:09 done sampling a new configuration.
18:36:09 HBMASTER: schedule new run for iteration 5
18:36:09 HBMASTER: trying submitting job (5, 0, 5) to dispatcher
18:36:09 HBMASTER: submitting job (5, 0, 5) to dispatcher
18:36:09 DISPATCHER: trying to submit job (5, 0, 5)
18:36:09 DISPATCHER: trying to notify the job_runner thread.
18:36:09 HBMASTER: job (5, 0, 5) submitted to dispatcher
18:36:09 DISPATCHER: Trying to submit another job.
18:36:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:36:09 DISPATCHER: starting job (5, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:36:09 DISPATCHER: job (5, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:36:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:36:09 WORKER: start processing job (5, 0, 5)
18:36:09 WORKER: args: ()
18:36:09 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002148966736239157, 'num_filters_1': 42, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.07522008635880745, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 115, 'num_filters_3': 33}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:36:19 DISPATCHER: Starting worker discovery
18:36:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:36:19 DISPATCHER: Finished worker discovery
18:37:19 DISPATCHER: Starting worker discovery
18:37:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:37:19 DISPATCHER: Finished worker discovery
18:38:19 DISPATCHER: Starting worker discovery
18:38:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:38:19 DISPATCHER: Finished worker discovery
18:39:17 WORKER: done with job (5, 0, 5), trying to register it.
18:39:17 WORKER: registered result for job (5, 0, 5) with dispatcher
18:39:17 DISPATCHER: job (5, 0, 5) finished
18:39:17 DISPATCHER: register_result: lock acquired
18:39:17 DISPATCHER: job (5, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
18:39:17 job_id: (5, 0, 5)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002148966736239157, 'num_filters_1': 42, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.07522008635880745, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 115, 'num_filters_3': 33}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3157317941811768, 'info': {'music_genre': 0.3157317941811768, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002148966736239157, 'num_filters_1': 42, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.07522008635880745, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 115, 'num_filters_3': 33}"}}
exception: None

18:39:17 job_callback for (5, 0, 5) started
18:39:17 job_callback for (5, 0, 5) got condition
18:39:17 DISPATCHER: Trying to submit another job.
18:39:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:39:17 HBMASTER: Trying to run another job!
18:39:17 job_callback for (5, 0, 5) finished
18:39:17 start sampling a new configuration.
18:39:17 best_vector: [1, 0, 0.05061363148680617, 0.976593178755837, 0.02083240439674, 1, 0.9083456622427151, 0.528234017758026, 2, 2, 1, 1, 0.6023219439077906, 0.6263439222907576, 0.3291447280903226, 0.504044651716294], 0.01954319979604686, 0.0002205498699921977, 4.31025017424968e-06
18:39:17 done sampling a new configuration.
18:39:17 HBMASTER: schedule new run for iteration 5
18:39:17 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
18:39:17 HBMASTER: submitting job (5, 0, 6) to dispatcher
18:39:17 DISPATCHER: trying to submit job (5, 0, 6)
18:39:17 DISPATCHER: trying to notify the job_runner thread.
18:39:17 HBMASTER: job (5, 0, 6) submitted to dispatcher
18:39:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:39:17 DISPATCHER: Trying to submit another job.
18:39:17 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:39:17 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:39:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:39:17 WORKER: start processing job (5, 0, 6)
18:39:17 WORKER: args: ()
18:39:17 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.001262488012064231, 'num_filters_1': 122, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.048668538176428154}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:39:19 DISPATCHER: Starting worker discovery
18:39:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:39:19 DISPATCHER: Finished worker discovery
18:40:19 DISPATCHER: Starting worker discovery
18:40:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:40:19 DISPATCHER: Finished worker discovery
18:41:19 DISPATCHER: Starting worker discovery
18:41:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:41:19 DISPATCHER: Finished worker discovery
18:42:19 DISPATCHER: Starting worker discovery
18:42:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:42:19 DISPATCHER: Finished worker discovery
18:42:29 WORKER: done with job (5, 0, 6), trying to register it.
18:42:29 WORKER: registered result for job (5, 0, 6) with dispatcher
18:42:29 DISPATCHER: job (5, 0, 6) finished
18:42:29 DISPATCHER: register_result: lock acquired
18:42:29 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
18:42:29 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.001262488012064231, 'num_filters_1': 122, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.048668538176428154}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.447944110112129, 'info': {'music_genre': 0.447944110112129, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.001262488012064231, 'num_filters_1': 122, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.048668538176428154}"}}
exception: None

18:42:29 job_callback for (5, 0, 6) started
18:42:29 DISPATCHER: Trying to submit another job.
18:42:29 job_callback for (5, 0, 6) got condition
18:42:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:42:29 done building a new model for budget 133.333333 based on 17/28 split
Best loss for this budget:-0.543042





18:42:29 HBMASTER: Trying to run another job!
18:42:29 job_callback for (5, 0, 6) finished
18:42:29 start sampling a new configuration.
18:42:29 best_vector: [2, 0, 0.25982094497494557, 0.10147853678743624, 0.908389549597867, 1, 0.578347304635518, 0.41936517400386725, 1, 2, 0, 1, 0.2967450068139362, 0.7495306682902961, 0.49850946067191715, 0.4302369295229508], 2.4493842430322627e-30, 0.004082658745130289, -5.930415664011176e-06
18:42:29 done sampling a new configuration.
18:42:29 HBMASTER: schedule new run for iteration 5
18:42:29 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
18:42:29 HBMASTER: submitting job (5, 0, 7) to dispatcher
18:42:29 DISPATCHER: trying to submit job (5, 0, 7)
18:42:29 DISPATCHER: trying to notify the job_runner thread.
18:42:29 HBMASTER: job (5, 0, 7) submitted to dispatcher
18:42:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:42:29 DISPATCHER: Trying to submit another job.
18:42:29 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:42:29 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:42:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:42:29 WORKER: start processing job (5, 0, 7)
18:42:29 WORKER: args: ()
18:42:29 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003308581903010309, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.03512421853041553, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 29, 'num_filters_3': 76, 'num_filters_4': 44, 'num_filters_5': 39}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:43:19 DISPATCHER: Starting worker discovery
18:43:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:43:19 DISPATCHER: Finished worker discovery
18:44:19 DISPATCHER: Starting worker discovery
18:44:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:44:19 DISPATCHER: Finished worker discovery
18:45:19 DISPATCHER: Starting worker discovery
18:45:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:45:19 DISPATCHER: Finished worker discovery
18:45:39 WORKER: done with job (5, 0, 7), trying to register it.
18:45:39 WORKER: registered result for job (5, 0, 7) with dispatcher
18:45:39 DISPATCHER: job (5, 0, 7) finished
18:45:39 DISPATCHER: register_result: lock acquired
18:45:39 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
18:45:39 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003308581903010309, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.03512421853041553, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 29, 'num_filters_3': 76, 'num_filters_4': 44, 'num_filters_5': 39}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4615546534294304, 'info': {'music_genre': 0.4615546534294304, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003308581903010309, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.03512421853041553, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 29, 'num_filters_3': 76, 'num_filters_4': 44, 'num_filters_5': 39}"}}
exception: None

18:45:39 job_callback for (5, 0, 7) started
18:45:39 DISPATCHER: Trying to submit another job.
18:45:39 job_callback for (5, 0, 7) got condition
18:45:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:45:39 done building a new model for budget 133.333333 based on 17/29 split
Best loss for this budget:-0.543042





18:45:39 HBMASTER: Trying to run another job!
18:45:39 job_callback for (5, 0, 7) finished
18:45:39 start sampling a new configuration.
18:45:39 best_vector: [2, 1, 0.186606462747783, 0.17267687168428159, 0.9291385639228043, 0, 0.4144260720223615, 0.20347385399383425, 0, 1, 0, 1, 0.41559003394794336, 0.5301981790091376, 0.3441700230294932, 0.5645708383966526], 3.271205624593303e-30, 0.0030569768909721974, -7.989892019841106e-06
18:45:39 done sampling a new configuration.
18:45:39 HBMASTER: schedule new run for iteration 5
18:45:39 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
18:45:39 HBMASTER: submitting job (5, 0, 8) to dispatcher
18:45:39 DISPATCHER: trying to submit job (5, 0, 8)
18:45:39 DISPATCHER: trying to notify the job_runner thread.
18:45:39 HBMASTER: job (5, 0, 8) submitted to dispatcher
18:45:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:45:39 DISPATCHER: Trying to submit another job.
18:45:39 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:45:39 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:45:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:45:39 WORKER: start processing job (5, 0, 8)
18:45:39 WORKER: args: ()
18:45:39 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0023616358100028954, 'num_filters_1': 22, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.018396092615816973, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 37, 'num_filters_3': 48, 'num_filters_4': 32, 'num_filters_5': 51}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:46:19 DISPATCHER: Starting worker discovery
18:46:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:46:19 DISPATCHER: Finished worker discovery
18:47:19 DISPATCHER: Starting worker discovery
18:47:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:47:19 DISPATCHER: Finished worker discovery
18:48:19 DISPATCHER: Starting worker discovery
18:48:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:48:19 DISPATCHER: Finished worker discovery
18:48:51 WORKER: done with job (5, 0, 8), trying to register it.
18:48:51 WORKER: registered result for job (5, 0, 8) with dispatcher
18:48:51 DISPATCHER: job (5, 0, 8) finished
18:48:51 DISPATCHER: register_result: lock acquired
18:48:51 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
18:48:51 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0023616358100028954, 'num_filters_1': 22, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.018396092615816973, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 37, 'num_filters_3': 48, 'num_filters_4': 32, 'num_filters_5': 51}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.42825205172629033, 'info': {'music_genre': 0.42825205172629033, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0023616358100028954, 'num_filters_1': 22, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.018396092615816973, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 37, 'num_filters_3': 48, 'num_filters_4': 32, 'num_filters_5': 51}"}}
exception: None

18:48:51 job_callback for (5, 0, 8) started
18:48:51 job_callback for (5, 0, 8) got condition
18:48:51 DISPATCHER: Trying to submit another job.
18:48:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:48:51 done building a new model for budget 133.333333 based on 17/30 split
Best loss for this budget:-0.543042





18:48:51 HBMASTER: Trying to run another job!
18:48:51 job_callback for (5, 0, 8) finished
18:48:51 ITERATION: Advancing config (5, 0, 2) to next budget 400.000000
18:48:51 ITERATION: Advancing config (5, 0, 6) to next budget 400.000000
18:48:51 ITERATION: Advancing config (5, 0, 7) to next budget 400.000000
18:48:51 HBMASTER: schedule new run for iteration 5
18:48:51 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
18:48:51 HBMASTER: submitting job (5, 0, 2) to dispatcher
18:48:51 DISPATCHER: trying to submit job (5, 0, 2)
18:48:51 DISPATCHER: trying to notify the job_runner thread.
18:48:51 HBMASTER: job (5, 0, 2) submitted to dispatcher
18:48:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:48:51 DISPATCHER: Trying to submit another job.
18:48:51 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:48:51 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:48:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:48:51 WORKER: start processing job (5, 0, 2)
18:48:51 WORKER: args: ()
18:48:51 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.00303051445234787, 'num_filters_1': 80, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.016600635198176488, 'kernel_size_2': 5, 'num_filters_2': 84}, 'budget': 400.0, 'working_directory': '.'}
18:49:19 DISPATCHER: Starting worker discovery
18:49:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:49:19 DISPATCHER: Finished worker discovery
18:50:19 DISPATCHER: Starting worker discovery
18:50:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:50:19 DISPATCHER: Finished worker discovery
18:51:19 DISPATCHER: Starting worker discovery
18:51:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:51:19 DISPATCHER: Finished worker discovery
18:52:19 DISPATCHER: Starting worker discovery
18:52:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:52:19 DISPATCHER: Finished worker discovery
18:53:19 DISPATCHER: Starting worker discovery
18:53:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:53:19 DISPATCHER: Finished worker discovery
18:54:19 DISPATCHER: Starting worker discovery
18:54:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:54:19 DISPATCHER: Finished worker discovery
18:55:19 DISPATCHER: Starting worker discovery
18:55:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:55:19 DISPATCHER: Finished worker discovery
18:56:19 DISPATCHER: Starting worker discovery
18:56:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:56:19 DISPATCHER: Finished worker discovery
18:56:31 WORKER: done with job (5, 0, 2), trying to register it.
18:56:31 WORKER: registered result for job (5, 0, 2) with dispatcher
18:56:31 DISPATCHER: job (5, 0, 2) finished
18:56:31 DISPATCHER: register_result: lock acquired
18:56:31 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
18:56:31 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.00303051445234787, 'num_filters_1': 80, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.016600635198176488, 'kernel_size_2': 5, 'num_filters_2': 84}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.39102726913158864, 'info': {'music_genre': 0.39102726913158864, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.00303051445234787, 'num_filters_1': 80, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.016600635198176488, 'kernel_size_2': 5, 'num_filters_2': 84}"}}
exception: None

18:56:31 job_callback for (5, 0, 2) started
18:56:31 DISPATCHER: Trying to submit another job.
18:56:31 job_callback for (5, 0, 2) got condition
18:56:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:56:31 Only 16 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
18:56:31 HBMASTER: Trying to run another job!
18:56:31 job_callback for (5, 0, 2) finished
18:56:31 HBMASTER: schedule new run for iteration 5
18:56:31 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
18:56:31 HBMASTER: submitting job (5, 0, 6) to dispatcher
18:56:31 DISPATCHER: trying to submit job (5, 0, 6)
18:56:31 DISPATCHER: trying to notify the job_runner thread.
18:56:31 HBMASTER: job (5, 0, 6) submitted to dispatcher
18:56:31 DISPATCHER: Trying to submit another job.
18:56:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:56:31 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:56:31 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:56:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:56:31 WORKER: start processing job (5, 0, 6)
18:56:31 WORKER: args: ()
18:56:31 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.001262488012064231, 'num_filters_1': 122, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.048668538176428154}, 'budget': 400.0, 'working_directory': '.'}
18:57:19 DISPATCHER: Starting worker discovery
18:57:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:57:19 DISPATCHER: Finished worker discovery
18:58:19 DISPATCHER: Starting worker discovery
18:58:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:58:19 DISPATCHER: Finished worker discovery
18:59:19 DISPATCHER: Starting worker discovery
18:59:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:59:19 DISPATCHER: Finished worker discovery
19:00:19 DISPATCHER: Starting worker discovery
19:00:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:00:19 DISPATCHER: Finished worker discovery
19:01:19 DISPATCHER: Starting worker discovery
19:01:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:01:19 DISPATCHER: Finished worker discovery
19:02:19 DISPATCHER: Starting worker discovery
19:02:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:02:20 DISPATCHER: Finished worker discovery
19:03:20 DISPATCHER: Starting worker discovery
19:03:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:03:20 DISPATCHER: Finished worker discovery
19:04:10 WORKER: done with job (5, 0, 6), trying to register it.
19:04:10 WORKER: registered result for job (5, 0, 6) with dispatcher
19:04:10 DISPATCHER: job (5, 0, 6) finished
19:04:10 DISPATCHER: register_result: lock acquired
19:04:10 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
19:04:10 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.001262488012064231, 'num_filters_1': 122, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.048668538176428154}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3803023525382305, 'info': {'music_genre': 0.3803023525382305, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.001262488012064231, 'num_filters_1': 122, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.048668538176428154}"}}
exception: None

19:04:10 DISPATCHER: Trying to submit another job.
19:04:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:04:10 job_callback for (5, 0, 6) started
19:04:10 job_callback for (5, 0, 6) got condition
19:04:10 HBMASTER: Trying to run another job!
19:04:10 job_callback for (5, 0, 6) finished
19:04:10 HBMASTER: schedule new run for iteration 5
19:04:10 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
19:04:10 HBMASTER: submitting job (5, 0, 7) to dispatcher
19:04:10 DISPATCHER: trying to submit job (5, 0, 7)
19:04:10 DISPATCHER: trying to notify the job_runner thread.
19:04:10 HBMASTER: job (5, 0, 7) submitted to dispatcher
19:04:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:04:10 DISPATCHER: Trying to submit another job.
19:04:10 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:04:10 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:04:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:04:10 WORKER: start processing job (5, 0, 7)
19:04:10 WORKER: args: ()
19:04:10 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003308581903010309, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.03512421853041553, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 29, 'num_filters_3': 76, 'num_filters_4': 44, 'num_filters_5': 39}, 'budget': 400.0, 'working_directory': '.'}
19:04:20 DISPATCHER: Starting worker discovery
19:04:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:04:20 DISPATCHER: Finished worker discovery
19:05:20 DISPATCHER: Starting worker discovery
19:05:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:05:20 DISPATCHER: Finished worker discovery
19:06:20 DISPATCHER: Starting worker discovery
19:06:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:06:20 DISPATCHER: Finished worker discovery
19:07:20 DISPATCHER: Starting worker discovery
19:07:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:07:20 DISPATCHER: Finished worker discovery
19:08:20 DISPATCHER: Starting worker discovery
19:08:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:08:20 DISPATCHER: Finished worker discovery
19:09:20 DISPATCHER: Starting worker discovery
19:09:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:09:20 DISPATCHER: Finished worker discovery
19:10:20 DISPATCHER: Starting worker discovery
19:10:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:10:20 DISPATCHER: Finished worker discovery
19:11:20 DISPATCHER: Starting worker discovery
19:11:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:11:20 DISPATCHER: Finished worker discovery
19:11:49 WORKER: done with job (5, 0, 7), trying to register it.
19:11:49 WORKER: registered result for job (5, 0, 7) with dispatcher
19:11:49 DISPATCHER: job (5, 0, 7) finished
19:11:49 DISPATCHER: register_result: lock acquired
19:11:49 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
19:11:49 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003308581903010309, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.03512421853041553, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 29, 'num_filters_3': 76, 'num_filters_4': 44, 'num_filters_5': 39}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.40993263316443573, 'info': {'music_genre': 0.40993263316443573, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003308581903010309, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.03512421853041553, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 29, 'num_filters_3': 76, 'num_filters_4': 44, 'num_filters_5': 39}"}}
exception: None

19:11:49 job_callback for (5, 0, 7) started
19:11:49 job_callback for (5, 0, 7) got condition
19:11:49 DISPATCHER: Trying to submit another job.
19:11:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:11:49 HBMASTER: Trying to run another job!
19:11:49 job_callback for (5, 0, 7) finished
19:11:49 ITERATION: Advancing config (5, 0, 7) to next budget 1200.000000
19:11:49 HBMASTER: schedule new run for iteration 5
19:11:49 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
19:11:49 HBMASTER: submitting job (5, 0, 7) to dispatcher
19:11:49 DISPATCHER: trying to submit job (5, 0, 7)
19:11:49 DISPATCHER: trying to notify the job_runner thread.
19:11:49 HBMASTER: job (5, 0, 7) submitted to dispatcher
19:11:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:11:49 DISPATCHER: Trying to submit another job.
19:11:49 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:11:49 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:11:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:11:49 WORKER: start processing job (5, 0, 7)
19:11:49 WORKER: args: ()
19:11:49 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003308581903010309, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.03512421853041553, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 29, 'num_filters_3': 76, 'num_filters_4': 44, 'num_filters_5': 39}, 'budget': 1200.0, 'working_directory': '.'}
19:12:20 DISPATCHER: Starting worker discovery
19:12:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:12:20 DISPATCHER: Finished worker discovery
19:13:20 DISPATCHER: Starting worker discovery
19:13:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:13:20 DISPATCHER: Finished worker discovery
19:14:20 DISPATCHER: Starting worker discovery
19:14:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:14:20 DISPATCHER: Finished worker discovery
19:15:20 DISPATCHER: Starting worker discovery
19:15:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:15:20 DISPATCHER: Finished worker discovery
19:16:20 DISPATCHER: Starting worker discovery
19:16:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:16:20 DISPATCHER: Finished worker discovery
19:17:20 DISPATCHER: Starting worker discovery
19:17:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:17:20 DISPATCHER: Finished worker discovery
19:18:20 DISPATCHER: Starting worker discovery
19:18:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:18:20 DISPATCHER: Finished worker discovery
19:19:20 DISPATCHER: Starting worker discovery
19:19:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:19:20 DISPATCHER: Finished worker discovery
19:20:20 DISPATCHER: Starting worker discovery
19:20:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:20:20 DISPATCHER: Finished worker discovery
19:21:20 DISPATCHER: Starting worker discovery
19:21:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:21:20 DISPATCHER: Finished worker discovery
19:22:20 DISPATCHER: Starting worker discovery
19:22:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:22:20 DISPATCHER: Finished worker discovery
19:23:20 DISPATCHER: Starting worker discovery
19:23:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:23:20 DISPATCHER: Finished worker discovery
19:24:20 DISPATCHER: Starting worker discovery
19:24:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:24:20 DISPATCHER: Finished worker discovery
19:25:20 DISPATCHER: Starting worker discovery
19:25:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:25:20 DISPATCHER: Finished worker discovery
19:26:20 DISPATCHER: Starting worker discovery
19:26:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:26:20 DISPATCHER: Finished worker discovery
19:27:20 DISPATCHER: Starting worker discovery
19:27:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:27:20 DISPATCHER: Finished worker discovery
19:28:20 DISPATCHER: Starting worker discovery
19:28:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:28:20 DISPATCHER: Finished worker discovery
19:29:20 DISPATCHER: Starting worker discovery
19:29:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:29:20 DISPATCHER: Finished worker discovery
19:30:20 DISPATCHER: Starting worker discovery
19:30:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:30:20 DISPATCHER: Finished worker discovery
19:31:20 DISPATCHER: Starting worker discovery
19:31:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:31:20 DISPATCHER: Finished worker discovery
19:32:20 DISPATCHER: Starting worker discovery
19:32:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:32:20 DISPATCHER: Finished worker discovery
19:32:56 WORKER: done with job (5, 0, 7), trying to register it.
19:32:56 WORKER: registered result for job (5, 0, 7) with dispatcher
19:32:56 DISPATCHER: job (5, 0, 7) finished
19:32:56 DISPATCHER: register_result: lock acquired
19:32:56 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
19:32:56 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003308581903010309, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.03512421853041553, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 29, 'num_filters_3': 76, 'num_filters_4': 44, 'num_filters_5': 39}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.4186263894525492, 'info': {'music_genre': 0.4186263894525492, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003308581903010309, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.03512421853041553, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 29, 'num_filters_3': 76, 'num_filters_4': 44, 'num_filters_5': 39}"}}
exception: None

19:32:56 job_callback for (5, 0, 7) started
19:32:56 DISPATCHER: Trying to submit another job.
19:32:56 job_callback for (5, 0, 7) got condition
19:32:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:32:56 Only 10 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
19:32:56 HBMASTER: Trying to run another job!
19:32:56 job_callback for (5, 0, 7) finished
19:32:56 start sampling a new configuration.
19:32:56 done sampling a new configuration.
19:32:56 HBMASTER: schedule new run for iteration 6
19:32:56 HBMASTER: trying submitting job (6, 0, 0) to dispatcher
19:32:56 HBMASTER: submitting job (6, 0, 0) to dispatcher
19:32:56 DISPATCHER: trying to submit job (6, 0, 0)
19:32:56 DISPATCHER: trying to notify the job_runner thread.
19:32:56 HBMASTER: job (6, 0, 0) submitted to dispatcher
19:32:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:32:56 DISPATCHER: Trying to submit another job.
19:32:56 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:32:56 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:32:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:32:56 WORKER: start processing job (6, 0, 0)
19:32:56 WORKER: args: ()
19:32:56 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.030409025621706522, 'num_filters_1': 75, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.03869250132589115, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 24, 'num_filters_3': 43, 'num_filters_4': 70}, 'budget': 400.0, 'working_directory': '.'}
19:33:20 DISPATCHER: Starting worker discovery
19:33:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:33:20 DISPATCHER: Finished worker discovery
19:34:20 DISPATCHER: Starting worker discovery
19:34:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:34:20 DISPATCHER: Finished worker discovery
19:35:20 DISPATCHER: Starting worker discovery
19:35:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:35:20 DISPATCHER: Finished worker discovery
19:36:20 DISPATCHER: Starting worker discovery
19:36:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:36:20 DISPATCHER: Finished worker discovery
19:37:20 DISPATCHER: Starting worker discovery
19:37:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:37:20 DISPATCHER: Finished worker discovery
19:38:20 DISPATCHER: Starting worker discovery
19:38:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:38:20 DISPATCHER: Finished worker discovery
19:39:20 DISPATCHER: Starting worker discovery
19:39:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:39:20 DISPATCHER: Finished worker discovery
19:40:20 DISPATCHER: Starting worker discovery
19:40:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:40:20 DISPATCHER: Finished worker discovery
19:40:35 WORKER: done with job (6, 0, 0), trying to register it.
19:40:35 WORKER: registered result for job (6, 0, 0) with dispatcher
19:40:35 DISPATCHER: job (6, 0, 0) finished
19:40:35 DISPATCHER: register_result: lock acquired
19:40:35 DISPATCHER: job (6, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
19:40:35 job_id: (6, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.030409025621706522, 'num_filters_1': 75, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.03869250132589115, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 24, 'num_filters_3': 43, 'num_filters_4': 70}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.2641572963618572, 'info': {'music_genre': 0.2641572963618572, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.030409025621706522, 'num_filters_1': 75, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.03869250132589115, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 24, 'num_filters_3': 43, 'num_filters_4': 70}"}}
exception: None

19:40:35 job_callback for (6, 0, 0) started
19:40:35 DISPATCHER: Trying to submit another job.
19:40:35 job_callback for (6, 0, 0) got condition
19:40:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:40:35 HBMASTER: Trying to run another job!
19:40:35 job_callback for (6, 0, 0) finished
19:40:35 start sampling a new configuration.
19:40:35 best_vector: [2, 2, 0.027244600117045784, 0.6773341492679614, 0.6047554941620166, 1, 0.36909269031206593, 0.1597851778084425, 2, 2, 0, 1, 0.6715720231499893, 0.6786107738066548, 0.6778659346556897, 0.36300426530554547], 6.297584650971527e-30, 0.0015879103742507538, -0.0002276934475625555
19:40:35 done sampling a new configuration.
19:40:35 HBMASTER: schedule new run for iteration 6
19:40:35 HBMASTER: trying submitting job (6, 0, 1) to dispatcher
19:40:35 HBMASTER: submitting job (6, 0, 1) to dispatcher
19:40:35 DISPATCHER: trying to submit job (6, 0, 1)
19:40:35 DISPATCHER: trying to notify the job_runner thread.
19:40:35 HBMASTER: job (6, 0, 1) submitted to dispatcher
19:40:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:40:35 DISPATCHER: Trying to submit another job.
19:40:35 DISPATCHER: starting job (6, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:40:35 DISPATCHER: job (6, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:40:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:40:35 WORKER: start processing job (6, 0, 1)
19:40:35 WORKER: args: ()
19:40:35 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0011336766461869374, 'num_filters_1': 65, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.016139322846763084, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 64, 'num_filters_3': 65, 'num_filters_4': 65}, 'budget': 400.0, 'working_directory': '.'}
19:41:20 DISPATCHER: Starting worker discovery
19:41:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:41:20 DISPATCHER: Finished worker discovery
19:42:20 DISPATCHER: Starting worker discovery
19:42:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:42:20 DISPATCHER: Finished worker discovery
19:43:20 DISPATCHER: Starting worker discovery
19:43:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:43:20 DISPATCHER: Finished worker discovery
19:44:20 DISPATCHER: Starting worker discovery
19:44:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:44:20 DISPATCHER: Finished worker discovery
19:45:20 DISPATCHER: Starting worker discovery
19:45:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:45:20 DISPATCHER: Finished worker discovery
19:46:20 DISPATCHER: Starting worker discovery
19:46:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:46:20 DISPATCHER: Finished worker discovery
19:47:20 DISPATCHER: Starting worker discovery
19:47:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:47:20 DISPATCHER: Finished worker discovery
19:48:15 WORKER: done with job (6, 0, 1), trying to register it.
19:48:15 WORKER: registered result for job (6, 0, 1) with dispatcher
19:48:15 DISPATCHER: job (6, 0, 1) finished
19:48:15 DISPATCHER: register_result: lock acquired
19:48:15 DISPATCHER: job (6, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
19:48:15 job_id: (6, 0, 1)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0011336766461869374, 'num_filters_1': 65, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.016139322846763084, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 64, 'num_filters_3': 65, 'num_filters_4': 65}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5254974412977976, 'info': {'music_genre': 0.5254974412977976, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0011336766461869374, 'num_filters_1': 65, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.016139322846763084, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 64, 'num_filters_3': 65, 'num_filters_4': 65}"}}
exception: None

19:48:15 job_callback for (6, 0, 1) started
19:48:15 job_callback for (6, 0, 1) got condition
19:48:15 DISPATCHER: Trying to submit another job.
19:48:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:48:15 HBMASTER: Trying to run another job!
19:48:15 job_callback for (6, 0, 1) finished
19:48:15 start sampling a new configuration.
19:48:15 best_vector: [2, 0, 0.4542023019795326, 0.5578517425184096, 0.936372278180547, 0, 0.3448594073193159, 0.41000652235119783, 0, 1, 2, 1, 0.2909655234354374, 0.548689974584073, 0.13668603235612764, 0.37002792715635235], 1.916983742784256e-29, 0.0005216528328756638, -1.0623715662236268e-07
19:48:15 done sampling a new configuration.
19:48:15 HBMASTER: schedule new run for iteration 6
19:48:15 HBMASTER: trying submitting job (6, 0, 2) to dispatcher
19:48:15 HBMASTER: submitting job (6, 0, 2) to dispatcher
19:48:15 DISPATCHER: trying to submit job (6, 0, 2)
19:48:15 DISPATCHER: trying to notify the job_runner thread.
19:48:15 HBMASTER: job (6, 0, 2) submitted to dispatcher
19:48:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:48:15 DISPATCHER: Trying to submit another job.
19:48:15 DISPATCHER: starting job (6, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:48:15 DISPATCHER: job (6, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:48:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:48:15 WORKER: start processing job (6, 0, 2)
19:48:15 WORKER: args: ()
19:48:15 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.008098500325065615, 'num_filters_1': 50, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.03415315145113642, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 29, 'num_filters_3': 49, 'num_filters_4': 21, 'num_filters_5': 34}, 'budget': 400.0, 'working_directory': '.'}
19:48:20 DISPATCHER: Starting worker discovery
19:48:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:48:20 DISPATCHER: Finished worker discovery
19:49:20 DISPATCHER: Starting worker discovery
19:49:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:49:20 DISPATCHER: Finished worker discovery
19:50:20 DISPATCHER: Starting worker discovery
19:50:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:50:20 DISPATCHER: Finished worker discovery
19:51:20 DISPATCHER: Starting worker discovery
19:51:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:51:20 DISPATCHER: Finished worker discovery
19:52:20 DISPATCHER: Starting worker discovery
19:52:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:52:20 DISPATCHER: Finished worker discovery
19:53:20 DISPATCHER: Starting worker discovery
19:53:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:53:20 DISPATCHER: Finished worker discovery
19:54:20 DISPATCHER: Starting worker discovery
19:54:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:54:20 DISPATCHER: Finished worker discovery
19:55:20 DISPATCHER: Starting worker discovery
19:55:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:55:20 DISPATCHER: Finished worker discovery
19:55:54 WORKER: done with job (6, 0, 2), trying to register it.
19:55:54 WORKER: registered result for job (6, 0, 2) with dispatcher
19:55:54 DISPATCHER: job (6, 0, 2) finished
19:55:54 DISPATCHER: register_result: lock acquired
19:55:54 DISPATCHER: job (6, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
19:55:54 job_id: (6, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.008098500325065615, 'num_filters_1': 50, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.03415315145113642, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 29, 'num_filters_3': 49, 'num_filters_4': 21, 'num_filters_5': 34}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.14717389527019248, 'info': {'music_genre': 0.14717389527019248, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.008098500325065615, 'num_filters_1': 50, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.03415315145113642, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 29, 'num_filters_3': 49, 'num_filters_4': 21, 'num_filters_5': 34}"}}
exception: None

19:55:54 job_callback for (6, 0, 2) started
19:55:54 job_callback for (6, 0, 2) got condition
19:55:54 DISPATCHER: Trying to submit another job.
19:55:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:55:54 HBMASTER: Trying to run another job!
19:55:54 job_callback for (6, 0, 2) finished
19:55:54 start sampling a new configuration.
19:55:54 best_vector: [0, 2, 0.3086377038545656, 0.46175700535868625, 0.03977291630004676, 1, 0.819179219693394, 0.14897287077529395, 1, 2, 2, 1, 0.8660202231994903, 0.768391051913106, 0.7072636303607611, 0.3292125062849064], 1.5182091163694607e-30, 0.006586707912750058, -7.182461536431014e-07
19:55:54 done sampling a new configuration.
19:55:54 HBMASTER: schedule new run for iteration 6
19:55:54 HBMASTER: trying submitting job (6, 0, 3) to dispatcher
19:55:54 HBMASTER: submitting job (6, 0, 3) to dispatcher
19:55:54 DISPATCHER: trying to submit job (6, 0, 3)
19:55:54 DISPATCHER: trying to notify the job_runner thread.
19:55:54 HBMASTER: job (6, 0, 3) submitted to dispatcher
19:55:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:55:54 DISPATCHER: Trying to submit another job.
19:55:54 DISPATCHER: starting job (6, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:55:54 DISPATCHER: job (6, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:55:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:55:54 WORKER: start processing job (6, 0, 3)
19:55:54 WORKER: args: ()
19:55:54 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0041426229584505085, 'num_filters_1': 41, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.015624933347597115}, 'budget': 400.0, 'working_directory': '.'}
19:56:20 DISPATCHER: Starting worker discovery
19:56:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:56:20 DISPATCHER: Finished worker discovery
19:57:20 DISPATCHER: Starting worker discovery
19:57:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:57:20 DISPATCHER: Finished worker discovery
19:58:20 DISPATCHER: Starting worker discovery
19:58:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:58:20 DISPATCHER: Finished worker discovery
19:59:20 DISPATCHER: Starting worker discovery
19:59:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:59:20 DISPATCHER: Finished worker discovery
20:00:20 DISPATCHER: Starting worker discovery
20:00:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:00:20 DISPATCHER: Finished worker discovery
20:01:20 DISPATCHER: Starting worker discovery
20:01:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:01:20 DISPATCHER: Finished worker discovery
20:02:20 DISPATCHER: Starting worker discovery
20:02:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:02:20 DISPATCHER: Finished worker discovery
20:03:20 DISPATCHER: Starting worker discovery
20:03:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:03:20 DISPATCHER: Finished worker discovery
20:03:37 WORKER: done with job (6, 0, 3), trying to register it.
20:03:37 WORKER: registered result for job (6, 0, 3) with dispatcher
20:03:37 DISPATCHER: job (6, 0, 3) finished
20:03:37 DISPATCHER: register_result: lock acquired
20:03:37 DISPATCHER: job (6, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
20:03:37 job_id: (6, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0041426229584505085, 'num_filters_1': 41, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.015624933347597115}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3142852691573064, 'info': {'music_genre': 0.3142852691573064, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0041426229584505085, 'num_filters_1': 41, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.015624933347597115}"}}
exception: None

20:03:37 job_callback for (6, 0, 3) started
20:03:37 job_callback for (6, 0, 3) got condition
20:03:37 DISPATCHER: Trying to submit another job.
20:03:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:03:37 HBMASTER: Trying to run another job!
20:03:37 job_callback for (6, 0, 3) finished
20:03:37 start sampling a new configuration.
20:03:37 best_vector: [2, 2, 0.08013696044523588, 0.08668787210027765, 0.4499537799274137, 1, 0.7327175383989245, 0.0879563224870206, 2, 0, 2, 1, 0.9699335148234609, 0.716436161330447, 0.3968411651702503, 0.32413131824698194], 2.3859670715861028e-30, 0.0041911726775643934, -3.16331055429736e-07
20:03:37 done sampling a new configuration.
20:03:37 HBMASTER: schedule new run for iteration 6
20:03:37 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
20:03:37 HBMASTER: submitting job (6, 0, 4) to dispatcher
20:03:37 DISPATCHER: trying to submit job (6, 0, 4)
20:03:37 DISPATCHER: trying to notify the job_runner thread.
20:03:37 HBMASTER: job (6, 0, 4) submitted to dispatcher
20:03:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:03:37 DISPATCHER: Trying to submit another job.
20:03:37 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
20:03:37 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
20:03:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:03:37 WORKER: start processing job (6, 0, 4)
20:03:37 WORKER: args: ()
20:03:37 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0014463517349903032, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.013014689576234422, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 121, 'num_filters_3': 71}, 'budget': 400.0, 'working_directory': '.'}
20:04:20 DISPATCHER: Starting worker discovery
20:04:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:04:20 DISPATCHER: Finished worker discovery
20:05:20 DISPATCHER: Starting worker discovery
20:05:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:05:20 DISPATCHER: Finished worker discovery
20:06:20 DISPATCHER: Starting worker discovery
20:06:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:06:20 DISPATCHER: Finished worker discovery
20:07:20 DISPATCHER: Starting worker discovery
20:07:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:07:20 DISPATCHER: Finished worker discovery
20:08:20 DISPATCHER: Starting worker discovery
20:08:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:08:20 DISPATCHER: Finished worker discovery
20:09:20 DISPATCHER: Starting worker discovery
20:09:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:09:20 DISPATCHER: Finished worker discovery
20:10:20 DISPATCHER: Starting worker discovery
20:10:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:10:20 DISPATCHER: Finished worker discovery
20:11:17 WORKER: done with job (6, 0, 4), trying to register it.
20:11:17 WORKER: registered result for job (6, 0, 4) with dispatcher
20:11:17 DISPATCHER: job (6, 0, 4) finished
20:11:17 DISPATCHER: register_result: lock acquired
20:11:17 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
20:11:17 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0014463517349903032, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.013014689576234422, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 121, 'num_filters_3': 71}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.445461630726924, 'info': {'music_genre': 0.445461630726924, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0014463517349903032, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.013014689576234422, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 121, 'num_filters_3': 71}"}}
exception: None

20:11:17 job_callback for (6, 0, 4) started
20:11:17 job_callback for (6, 0, 4) got condition
20:11:17 DISPATCHER: Trying to submit another job.
20:11:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:11:17 HBMASTER: Trying to run another job!
20:11:17 job_callback for (6, 0, 4) finished
20:11:17 start sampling a new configuration.
20:11:17 best_vector: [2, 2, 0.10759029525569214, 0.8883336820813403, 0.9541547540961757, 1, 0.621334411494376, 0.2627998963575047, 2, 2, 0, 1, 0.9403385029349843, 0.5380899225950755, 0.5158886035114788, 0.37199151295730576], 4.914974963721802e-30, 0.0020345983598719346, -1.446771698530939e-05
20:11:17 done sampling a new configuration.
20:11:17 HBMASTER: schedule new run for iteration 6
20:11:17 HBMASTER: trying submitting job (6, 0, 5) to dispatcher
20:11:17 HBMASTER: submitting job (6, 0, 5) to dispatcher
20:11:17 DISPATCHER: trying to submit job (6, 0, 5)
20:11:17 DISPATCHER: trying to notify the job_runner thread.
20:11:17 HBMASTER: job (6, 0, 5) submitted to dispatcher
20:11:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:11:17 DISPATCHER: Trying to submit another job.
20:11:17 DISPATCHER: starting job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952
20:11:17 DISPATCHER: job (6, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
20:11:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:11:17 WORKER: start processing job (6, 0, 5)
20:11:17 WORKER: args: ()
20:11:17 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0016412721133311073, 'num_filters_1': 101, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.02197407224448195, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 113, 'num_filters_3': 48, 'num_filters_4': 46, 'num_filters_5': 34}, 'budget': 400.0, 'working_directory': '.'}
20:11:20 DISPATCHER: Starting worker discovery
20:11:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:11:20 DISPATCHER: Finished worker discovery
20:12:20 DISPATCHER: Starting worker discovery
20:12:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:12:20 DISPATCHER: Finished worker discovery
20:13:20 DISPATCHER: Starting worker discovery
20:13:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:13:20 DISPATCHER: Finished worker discovery
20:14:20 DISPATCHER: Starting worker discovery
20:14:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:14:20 DISPATCHER: Finished worker discovery
20:15:20 DISPATCHER: Starting worker discovery
20:15:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:15:20 DISPATCHER: Finished worker discovery
20:16:20 DISPATCHER: Starting worker discovery
20:16:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:16:20 DISPATCHER: Finished worker discovery
20:17:20 DISPATCHER: Starting worker discovery
20:17:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:17:20 DISPATCHER: Finished worker discovery
20:18:20 DISPATCHER: Starting worker discovery
20:18:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:18:20 DISPATCHER: Finished worker discovery
20:18:55 WORKER: done with job (6, 0, 5), trying to register it.
20:18:55 WORKER: registered result for job (6, 0, 5) with dispatcher
20:18:55 DISPATCHER: job (6, 0, 5) finished
20:18:55 DISPATCHER: register_result: lock acquired
20:18:55 DISPATCHER: job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
20:18:55 job_id: (6, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0016412721133311073, 'num_filters_1': 101, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.02197407224448195, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 113, 'num_filters_3': 48, 'num_filters_4': 46, 'num_filters_5': 34}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5723660311443981, 'info': {'music_genre': 0.5723660311443981, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0016412721133311073, 'num_filters_1': 101, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.02197407224448195, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 113, 'num_filters_3': 48, 'num_filters_4': 46, 'num_filters_5': 34}"}}
exception: None

20:18:55 job_callback for (6, 0, 5) started
20:18:55 job_callback for (6, 0, 5) got condition
20:18:55 DISPATCHER: Trying to submit another job.
20:18:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:18:55 HBMASTER: Trying to run another job!
20:18:55 job_callback for (6, 0, 5) finished
20:18:55 ITERATION: Advancing config (6, 0, 1) to next budget 1200.000000
20:18:55 ITERATION: Advancing config (6, 0, 5) to next budget 1200.000000
20:18:55 HBMASTER: schedule new run for iteration 6
20:18:55 HBMASTER: trying submitting job (6, 0, 1) to dispatcher
20:18:55 HBMASTER: submitting job (6, 0, 1) to dispatcher
20:18:55 DISPATCHER: trying to submit job (6, 0, 1)
20:18:55 DISPATCHER: trying to notify the job_runner thread.
20:18:55 HBMASTER: job (6, 0, 1) submitted to dispatcher
20:18:55 DISPATCHER: Trying to submit another job.
20:18:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:18:55 DISPATCHER: starting job (6, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
20:18:55 DISPATCHER: job (6, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
20:18:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:18:55 WORKER: start processing job (6, 0, 1)
20:18:55 WORKER: args: ()
20:18:55 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0011336766461869374, 'num_filters_1': 65, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.016139322846763084, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 64, 'num_filters_3': 65, 'num_filters_4': 65}, 'budget': 1200.0, 'working_directory': '.'}
20:19:20 DISPATCHER: Starting worker discovery
20:19:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:19:20 DISPATCHER: Finished worker discovery
20:20:20 DISPATCHER: Starting worker discovery
20:20:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:20:20 DISPATCHER: Finished worker discovery
20:21:20 DISPATCHER: Starting worker discovery
20:21:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:21:20 DISPATCHER: Finished worker discovery
20:22:20 DISPATCHER: Starting worker discovery
20:22:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:22:20 DISPATCHER: Finished worker discovery
20:23:20 DISPATCHER: Starting worker discovery
20:23:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:23:20 DISPATCHER: Finished worker discovery
20:24:20 DISPATCHER: Starting worker discovery
20:24:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:24:20 DISPATCHER: Finished worker discovery
20:25:20 DISPATCHER: Starting worker discovery
20:25:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:25:20 DISPATCHER: Finished worker discovery
20:26:20 DISPATCHER: Starting worker discovery
20:26:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:26:20 DISPATCHER: Finished worker discovery
20:27:20 DISPATCHER: Starting worker discovery
20:27:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:27:20 DISPATCHER: Finished worker discovery
20:28:20 DISPATCHER: Starting worker discovery
20:28:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:28:20 DISPATCHER: Finished worker discovery
20:29:20 DISPATCHER: Starting worker discovery
20:29:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:29:20 DISPATCHER: Finished worker discovery
20:30:20 DISPATCHER: Starting worker discovery
20:30:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:30:20 DISPATCHER: Finished worker discovery
20:31:20 DISPATCHER: Starting worker discovery
20:31:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:31:20 DISPATCHER: Finished worker discovery
20:32:20 DISPATCHER: Starting worker discovery
20:32:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:32:20 DISPATCHER: Finished worker discovery
20:33:20 DISPATCHER: Starting worker discovery
20:33:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:33:20 DISPATCHER: Finished worker discovery
20:34:20 DISPATCHER: Starting worker discovery
20:34:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:34:20 DISPATCHER: Finished worker discovery
20:35:20 DISPATCHER: Starting worker discovery
20:35:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:35:20 DISPATCHER: Finished worker discovery
20:36:20 DISPATCHER: Starting worker discovery
20:36:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:36:20 DISPATCHER: Finished worker discovery
20:37:20 DISPATCHER: Starting worker discovery
20:37:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:37:20 DISPATCHER: Finished worker discovery
20:38:20 DISPATCHER: Starting worker discovery
20:38:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:38:20 DISPATCHER: Finished worker discovery
20:39:20 DISPATCHER: Starting worker discovery
20:39:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:39:20 DISPATCHER: Finished worker discovery
20:40:02 WORKER: done with job (6, 0, 1), trying to register it.
20:40:02 WORKER: registered result for job (6, 0, 1) with dispatcher
20:40:02 DISPATCHER: job (6, 0, 1) finished
20:40:02 DISPATCHER: register_result: lock acquired
20:40:02 DISPATCHER: job (6, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
20:40:02 job_id: (6, 0, 1)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0011336766461869374, 'num_filters_1': 65, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.016139322846763084, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 64, 'num_filters_3': 65, 'num_filters_4': 65}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.4715606076725841, 'info': {'music_genre': 0.4715606076725841, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0011336766461869374, 'num_filters_1': 65, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.016139322846763084, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 64, 'num_filters_3': 65, 'num_filters_4': 65}"}}
exception: None

20:40:02 job_callback for (6, 0, 1) started
20:40:02 job_callback for (6, 0, 1) got condition
20:40:02 DISPATCHER: Trying to submit another job.
20:40:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:40:02 Only 11 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
20:40:02 HBMASTER: Trying to run another job!
20:40:02 job_callback for (6, 0, 1) finished
20:40:02 HBMASTER: schedule new run for iteration 6
20:40:02 HBMASTER: trying submitting job (6, 0, 5) to dispatcher
20:40:02 HBMASTER: submitting job (6, 0, 5) to dispatcher
20:40:02 DISPATCHER: trying to submit job (6, 0, 5)
20:40:02 DISPATCHER: trying to notify the job_runner thread.
20:40:02 HBMASTER: job (6, 0, 5) submitted to dispatcher
20:40:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:40:02 DISPATCHER: Trying to submit another job.
20:40:02 DISPATCHER: starting job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952
20:40:02 DISPATCHER: job (6, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
20:40:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:40:02 WORKER: start processing job (6, 0, 5)
20:40:02 WORKER: args: ()
20:40:02 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0016412721133311073, 'num_filters_1': 101, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.02197407224448195, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 113, 'num_filters_3': 48, 'num_filters_4': 46, 'num_filters_5': 34}, 'budget': 1200.0, 'working_directory': '.'}
20:40:20 DISPATCHER: Starting worker discovery
20:40:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:40:20 DISPATCHER: Finished worker discovery
20:41:20 DISPATCHER: Starting worker discovery
20:41:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:41:20 DISPATCHER: Finished worker discovery
20:42:20 DISPATCHER: Starting worker discovery
20:42:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:42:20 DISPATCHER: Finished worker discovery
20:43:20 DISPATCHER: Starting worker discovery
20:43:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:43:20 DISPATCHER: Finished worker discovery
20:44:20 DISPATCHER: Starting worker discovery
20:44:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:44:20 DISPATCHER: Finished worker discovery
20:45:20 DISPATCHER: Starting worker discovery
20:45:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:45:20 DISPATCHER: Finished worker discovery
20:46:20 DISPATCHER: Starting worker discovery
20:46:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:46:20 DISPATCHER: Finished worker discovery
20:47:20 DISPATCHER: Starting worker discovery
20:47:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:47:20 DISPATCHER: Finished worker discovery
20:48:20 DISPATCHER: Starting worker discovery
20:48:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:48:20 DISPATCHER: Finished worker discovery
20:49:20 DISPATCHER: Starting worker discovery
20:49:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:49:20 DISPATCHER: Finished worker discovery
20:50:20 DISPATCHER: Starting worker discovery
20:50:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:50:20 DISPATCHER: Finished worker discovery
20:51:20 DISPATCHER: Starting worker discovery
20:51:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:51:20 DISPATCHER: Finished worker discovery
20:52:20 DISPATCHER: Starting worker discovery
20:52:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:52:20 DISPATCHER: Finished worker discovery
20:53:20 DISPATCHER: Starting worker discovery
20:53:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:53:20 DISPATCHER: Finished worker discovery
20:54:20 DISPATCHER: Starting worker discovery
20:54:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:54:20 DISPATCHER: Finished worker discovery
20:55:20 DISPATCHER: Starting worker discovery
20:55:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:55:20 DISPATCHER: Finished worker discovery
20:56:20 DISPATCHER: Starting worker discovery
20:56:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:56:20 DISPATCHER: Finished worker discovery
20:57:20 DISPATCHER: Starting worker discovery
20:57:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:57:20 DISPATCHER: Finished worker discovery
20:58:20 DISPATCHER: Starting worker discovery
20:58:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:58:20 DISPATCHER: Finished worker discovery
20:59:20 DISPATCHER: Starting worker discovery
20:59:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:59:20 DISPATCHER: Finished worker discovery
21:00:20 DISPATCHER: Starting worker discovery
21:00:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:00:20 DISPATCHER: Finished worker discovery
21:01:04 WORKER: done with job (6, 0, 5), trying to register it.
21:01:04 WORKER: registered result for job (6, 0, 5) with dispatcher
21:01:04 DISPATCHER: job (6, 0, 5) finished
21:01:04 DISPATCHER: register_result: lock acquired
21:01:04 DISPATCHER: job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
21:01:04 job_id: (6, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0016412721133311073, 'num_filters_1': 101, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.02197407224448195, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 113, 'num_filters_3': 48, 'num_filters_4': 46, 'num_filters_5': 34}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5259760599095928, 'info': {'music_genre': 0.5259760599095928, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0016412721133311073, 'num_filters_1': 101, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.02197407224448195, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 113, 'num_filters_3': 48, 'num_filters_4': 46, 'num_filters_5': 34}"}}
exception: None

21:01:04 job_callback for (6, 0, 5) started
21:01:04 job_callback for (6, 0, 5) got condition
21:01:04 DISPATCHER: Trying to submit another job.
21:01:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:01:04 Only 12 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
21:01:04 HBMASTER: Trying to run another job!
21:01:04 job_callback for (6, 0, 5) finished
21:01:04 start sampling a new configuration.
21:01:04 best_vector: [2, 0, 0.21162324481565442, 0.53812067167268, 0.9148777187954272, 1, 0.5561121105560586, 0.045580320358246676, 1, 2, 0, 1, 0.05936617752788542, 0.6775316603774507, 0.17683688005212544, 0.5768658494280148], 4.4482634452557485e-30, 0.002248068290709131, -2.2793047603704866e-05
21:01:04 done sampling a new configuration.
21:01:04 HBMASTER: schedule new run for iteration 7
21:01:04 HBMASTER: trying submitting job (7, 0, 0) to dispatcher
21:01:04 HBMASTER: submitting job (7, 0, 0) to dispatcher
21:01:04 DISPATCHER: trying to submit job (7, 0, 0)
21:01:04 DISPATCHER: trying to notify the job_runner thread.
21:01:04 HBMASTER: job (7, 0, 0) submitted to dispatcher
21:01:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:01:04 DISPATCHER: Trying to submit another job.
21:01:04 DISPATCHER: starting job (7, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
21:01:04 DISPATCHER: job (7, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
21:01:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:01:04 WORKER: start processing job (7, 0, 0)
21:01:04 WORKER: args: ()
21:01:04 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0026500037568784602, 'num_filters_1': 48, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.01146308107346959, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 18, 'num_filters_3': 65, 'num_filters_4': 23, 'num_filters_5': 53}, 'budget': 1200.0, 'working_directory': '.'}
21:01:20 DISPATCHER: Starting worker discovery
21:01:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:01:20 DISPATCHER: Finished worker discovery
21:02:20 DISPATCHER: Starting worker discovery
21:02:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:02:20 DISPATCHER: Finished worker discovery
21:03:20 DISPATCHER: Starting worker discovery
21:03:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:03:20 DISPATCHER: Finished worker discovery
21:04:20 DISPATCHER: Starting worker discovery
21:04:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:04:20 DISPATCHER: Finished worker discovery
21:05:20 DISPATCHER: Starting worker discovery
21:05:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:05:20 DISPATCHER: Finished worker discovery
21:06:20 DISPATCHER: Starting worker discovery
21:06:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:06:21 DISPATCHER: Finished worker discovery
21:07:21 DISPATCHER: Starting worker discovery
21:07:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:07:21 DISPATCHER: Finished worker discovery
21:08:21 DISPATCHER: Starting worker discovery
21:08:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:08:21 DISPATCHER: Finished worker discovery
21:09:21 DISPATCHER: Starting worker discovery
21:09:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:09:21 DISPATCHER: Finished worker discovery
21:10:21 DISPATCHER: Starting worker discovery
21:10:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:10:21 DISPATCHER: Finished worker discovery
21:11:21 DISPATCHER: Starting worker discovery
21:11:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:11:21 DISPATCHER: Finished worker discovery
21:12:21 DISPATCHER: Starting worker discovery
21:12:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:12:21 DISPATCHER: Finished worker discovery
21:13:21 DISPATCHER: Starting worker discovery
21:13:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:13:21 DISPATCHER: Finished worker discovery
21:14:21 DISPATCHER: Starting worker discovery
21:14:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:14:21 DISPATCHER: Finished worker discovery
21:15:21 DISPATCHER: Starting worker discovery
21:15:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:15:21 DISPATCHER: Finished worker discovery
21:16:21 DISPATCHER: Starting worker discovery
21:16:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:16:21 DISPATCHER: Finished worker discovery
21:17:21 DISPATCHER: Starting worker discovery
21:17:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:17:21 DISPATCHER: Finished worker discovery
21:18:21 DISPATCHER: Starting worker discovery
21:18:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:18:21 DISPATCHER: Finished worker discovery
21:19:21 DISPATCHER: Starting worker discovery
21:19:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:19:21 DISPATCHER: Finished worker discovery
21:20:21 DISPATCHER: Starting worker discovery
21:20:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:20:21 DISPATCHER: Finished worker discovery
21:21:21 DISPATCHER: Starting worker discovery
21:21:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:21:21 DISPATCHER: Finished worker discovery
21:22:08 WORKER: done with job (7, 0, 0), trying to register it.
21:22:08 WORKER: registered result for job (7, 0, 0) with dispatcher
21:22:08 DISPATCHER: job (7, 0, 0) finished
21:22:08 DISPATCHER: register_result: lock acquired
21:22:08 DISPATCHER: job (7, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
21:22:08 job_id: (7, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0026500037568784602, 'num_filters_1': 48, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.01146308107346959, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 18, 'num_filters_3': 65, 'num_filters_4': 23, 'num_filters_5': 53}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.4474659743502573, 'info': {'music_genre': 0.4474659743502573, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0026500037568784602, 'num_filters_1': 48, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.01146308107346959, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 18, 'num_filters_3': 65, 'num_filters_4': 23, 'num_filters_5': 53}"}}
exception: None

21:22:08 job_callback for (7, 0, 0) started
21:22:08 DISPATCHER: Trying to submit another job.
21:22:08 job_callback for (7, 0, 0) got condition
21:22:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:22:08 Only 13 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
21:22:08 HBMASTER: Trying to run another job!
21:22:08 job_callback for (7, 0, 0) finished
21:22:08 start sampling a new configuration.
21:22:08 done sampling a new configuration.
21:22:08 HBMASTER: schedule new run for iteration 7
21:22:08 HBMASTER: trying submitting job (7, 0, 1) to dispatcher
21:22:08 HBMASTER: submitting job (7, 0, 1) to dispatcher
21:22:08 DISPATCHER: trying to submit job (7, 0, 1)
21:22:08 DISPATCHER: trying to notify the job_runner thread.
21:22:08 HBMASTER: job (7, 0, 1) submitted to dispatcher
21:22:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:22:08 DISPATCHER: Trying to submit another job.
21:22:08 DISPATCHER: starting job (7, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
21:22:08 DISPATCHER: job (7, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
21:22:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:22:08 WORKER: start processing job (7, 0, 1)
21:22:08 WORKER: args: ()
21:22:08 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.08619852217704443, 'num_filters_1': 47, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.11744504198324278, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 82, 'num_filters_3': 39, 'num_filters_4': 21, 'num_filters_5': 69}, 'budget': 1200.0, 'working_directory': '.'}
21:22:21 DISPATCHER: Starting worker discovery
21:22:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:22:21 DISPATCHER: Finished worker discovery
21:23:21 DISPATCHER: Starting worker discovery
21:23:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:23:21 DISPATCHER: Finished worker discovery
21:24:21 DISPATCHER: Starting worker discovery
21:24:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:24:21 DISPATCHER: Finished worker discovery
21:25:21 DISPATCHER: Starting worker discovery
21:25:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:25:21 DISPATCHER: Finished worker discovery
21:26:21 DISPATCHER: Starting worker discovery
21:26:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:26:21 DISPATCHER: Finished worker discovery
21:27:21 DISPATCHER: Starting worker discovery
21:27:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:27:21 DISPATCHER: Finished worker discovery
21:28:21 DISPATCHER: Starting worker discovery
21:28:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:28:21 DISPATCHER: Finished worker discovery
21:29:21 DISPATCHER: Starting worker discovery
21:29:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:29:21 DISPATCHER: Finished worker discovery
21:30:21 DISPATCHER: Starting worker discovery
21:30:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:30:21 DISPATCHER: Finished worker discovery
21:31:21 DISPATCHER: Starting worker discovery
21:31:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:31:21 DISPATCHER: Finished worker discovery
21:32:21 DISPATCHER: Starting worker discovery
21:32:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:32:21 DISPATCHER: Finished worker discovery
21:33:21 DISPATCHER: Starting worker discovery
21:33:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:33:21 DISPATCHER: Finished worker discovery
21:34:21 DISPATCHER: Starting worker discovery
21:34:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:34:21 DISPATCHER: Finished worker discovery
21:35:21 DISPATCHER: Starting worker discovery
21:35:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:35:21 DISPATCHER: Finished worker discovery
21:36:21 DISPATCHER: Starting worker discovery
21:36:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:36:21 DISPATCHER: Finished worker discovery
21:37:21 DISPATCHER: Starting worker discovery
21:37:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:37:21 DISPATCHER: Finished worker discovery
21:38:21 DISPATCHER: Starting worker discovery
21:38:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:38:21 DISPATCHER: Finished worker discovery
21:39:21 DISPATCHER: Starting worker discovery
21:39:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:39:21 DISPATCHER: Finished worker discovery
21:40:21 DISPATCHER: Starting worker discovery
21:40:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:40:21 DISPATCHER: Finished worker discovery
21:41:21 DISPATCHER: Starting worker discovery
21:41:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:41:21 DISPATCHER: Finished worker discovery
21:42:21 DISPATCHER: Starting worker discovery
21:42:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:42:21 DISPATCHER: Finished worker discovery
21:43:13 WORKER: done with job (7, 0, 1), trying to register it.
21:43:13 WORKER: registered result for job (7, 0, 1) with dispatcher
21:43:13 DISPATCHER: job (7, 0, 1) finished
21:43:13 DISPATCHER: register_result: lock acquired
21:43:13 DISPATCHER: job (7, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
21:43:13 job_id: (7, 0, 1)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.08619852217704443, 'num_filters_1': 47, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.11744504198324278, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 82, 'num_filters_3': 39, 'num_filters_4': 21, 'num_filters_5': 69}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.00105861830201738, 'info': {'music_genre': 0.00105861830201738, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.08619852217704443, 'num_filters_1': 47, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.11744504198324278, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 82, 'num_filters_3': 39, 'num_filters_4': 21, 'num_filters_5': 69}"}}
exception: None

21:43:13 job_callback for (7, 0, 1) started
21:43:13 job_callback for (7, 0, 1) got condition
21:43:13 DISPATCHER: Trying to submit another job.
21:43:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:43:13 Only 14 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
21:43:13 HBMASTER: Trying to run another job!
21:43:13 job_callback for (7, 0, 1) finished
21:43:13 start sampling a new configuration.
21:43:13 done sampling a new configuration.
21:43:13 HBMASTER: schedule new run for iteration 7
21:43:13 HBMASTER: trying submitting job (7, 0, 2) to dispatcher
21:43:13 HBMASTER: submitting job (7, 0, 2) to dispatcher
21:43:13 DISPATCHER: trying to submit job (7, 0, 2)
21:43:13 DISPATCHER: trying to notify the job_runner thread.
21:43:13 HBMASTER: job (7, 0, 2) submitted to dispatcher
21:43:13 DISPATCHER: Trying to submit another job.
21:43:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:43:13 DISPATCHER: starting job (7, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
21:43:13 DISPATCHER: job (7, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
21:43:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:43:13 WORKER: start processing job (7, 0, 2)
21:43:13 WORKER: args: ()
21:43:13 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.09287765293633207, 'num_filters_1': 111, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.05020036986156845}, 'budget': 1200.0, 'working_directory': '.'}
21:43:21 DISPATCHER: Starting worker discovery
21:43:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:43:21 DISPATCHER: Finished worker discovery
21:44:21 DISPATCHER: Starting worker discovery
21:44:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:44:21 DISPATCHER: Finished worker discovery
21:45:21 DISPATCHER: Starting worker discovery
21:45:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:45:21 DISPATCHER: Finished worker discovery
21:46:21 DISPATCHER: Starting worker discovery
21:46:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:46:21 DISPATCHER: Finished worker discovery
21:47:21 DISPATCHER: Starting worker discovery
21:47:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:47:21 DISPATCHER: Finished worker discovery
21:48:21 DISPATCHER: Starting worker discovery
21:48:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:48:21 DISPATCHER: Finished worker discovery
21:49:21 DISPATCHER: Starting worker discovery
21:49:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:49:21 DISPATCHER: Finished worker discovery
21:50:21 DISPATCHER: Starting worker discovery
21:50:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:50:21 DISPATCHER: Finished worker discovery
21:51:21 DISPATCHER: Starting worker discovery
21:51:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:51:21 DISPATCHER: Finished worker discovery
21:52:21 DISPATCHER: Starting worker discovery
21:52:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:52:21 DISPATCHER: Finished worker discovery
21:53:21 DISPATCHER: Starting worker discovery
21:53:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:53:21 DISPATCHER: Finished worker discovery
21:54:21 DISPATCHER: Starting worker discovery
21:54:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:54:21 DISPATCHER: Finished worker discovery
21:55:21 DISPATCHER: Starting worker discovery
21:55:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:55:21 DISPATCHER: Finished worker discovery
21:56:21 DISPATCHER: Starting worker discovery
21:56:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:56:21 DISPATCHER: Finished worker discovery
21:57:21 DISPATCHER: Starting worker discovery
21:57:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:57:21 DISPATCHER: Finished worker discovery
21:58:21 DISPATCHER: Starting worker discovery
21:58:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:58:21 DISPATCHER: Finished worker discovery
21:59:21 DISPATCHER: Starting worker discovery
21:59:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:59:21 DISPATCHER: Finished worker discovery
22:00:21 DISPATCHER: Starting worker discovery
22:00:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:00:21 DISPATCHER: Finished worker discovery
22:01:21 DISPATCHER: Starting worker discovery
22:01:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:01:21 DISPATCHER: Finished worker discovery
22:02:21 DISPATCHER: Starting worker discovery
22:02:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:02:21 DISPATCHER: Finished worker discovery
22:03:21 DISPATCHER: Starting worker discovery
22:03:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:03:21 DISPATCHER: Finished worker discovery
22:04:21 DISPATCHER: Starting worker discovery
22:04:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:04:21 DISPATCHER: Finished worker discovery
22:04:51 WORKER: done with job (7, 0, 2), trying to register it.
22:04:51 WORKER: registered result for job (7, 0, 2) with dispatcher
22:04:51 DISPATCHER: job (7, 0, 2) finished
22:04:51 DISPATCHER: register_result: lock acquired
22:04:51 DISPATCHER: job (7, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
22:04:51 job_id: (7, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.09287765293633207, 'num_filters_1': 111, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.05020036986156845}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.09001778676199014, 'info': {'music_genre': 0.09001778676199014, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.09287765293633207, 'num_filters_1': 111, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.05020036986156845}"}}
exception: None

22:04:51 job_callback for (7, 0, 2) started
22:04:51 job_callback for (7, 0, 2) got condition
22:04:51 DISPATCHER: Trying to submit another job.
22:04:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:04:51 Only 15 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
22:04:51 HBMASTER: Trying to run another job!
22:04:51 job_callback for (7, 0, 2) finished
22:04:51 start sampling a new configuration.
22:04:51 best_vector: [2, 1, 0.37160857566192845, 0.9849864106576646, 0.6611655048675196, 1, 0.8840237532950204, 0.6431735165642704, 2, 2, 1, 1, 0.6921659733676282, 0.3324486422700961, 0.4455808053766214, 0.5016175337431825], 2.2033017758679595e-29, 0.00045386429174281594, -1.3280677448381917e-05
22:04:51 done sampling a new configuration.
22:04:51 HBMASTER: schedule new run for iteration 7
22:04:51 HBMASTER: trying submitting job (7, 0, 3) to dispatcher
22:04:51 HBMASTER: submitting job (7, 0, 3) to dispatcher
22:04:51 DISPATCHER: trying to submit job (7, 0, 3)
22:04:51 DISPATCHER: trying to notify the job_runner thread.
22:04:51 HBMASTER: job (7, 0, 3) submitted to dispatcher
22:04:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:04:51 DISPATCHER: Trying to submit another job.
22:04:51 DISPATCHER: starting job (7, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:04:51 DISPATCHER: job (7, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:04:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:04:51 WORKER: start processing job (7, 0, 3)
22:04:51 WORKER: args: ()
22:04:51 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.005536268586554153, 'num_filters_1': 124, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.06867331899938382, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 67, 'num_filters_3': 31, 'num_filters_4': 40}, 'budget': 1200.0, 'working_directory': '.'}
22:05:21 DISPATCHER: Starting worker discovery
22:05:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:05:21 DISPATCHER: Finished worker discovery
22:06:21 DISPATCHER: Starting worker discovery
22:06:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:06:21 DISPATCHER: Finished worker discovery
22:07:21 DISPATCHER: Starting worker discovery
22:07:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:07:21 DISPATCHER: Finished worker discovery
22:08:21 DISPATCHER: Starting worker discovery
22:08:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:08:21 DISPATCHER: Finished worker discovery
22:09:21 DISPATCHER: Starting worker discovery
22:09:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:09:21 DISPATCHER: Finished worker discovery
22:10:21 DISPATCHER: Starting worker discovery
22:10:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:10:21 DISPATCHER: Finished worker discovery
22:11:21 DISPATCHER: Starting worker discovery
22:11:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:11:21 DISPATCHER: Finished worker discovery
22:12:21 DISPATCHER: Starting worker discovery
22:12:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:12:21 DISPATCHER: Finished worker discovery
22:13:21 DISPATCHER: Starting worker discovery
22:13:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:13:21 DISPATCHER: Finished worker discovery
22:14:21 DISPATCHER: Starting worker discovery
22:14:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:14:21 DISPATCHER: Finished worker discovery
22:15:21 DISPATCHER: Starting worker discovery
22:15:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:15:21 DISPATCHER: Finished worker discovery
22:16:21 DISPATCHER: Starting worker discovery
22:16:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:16:21 DISPATCHER: Finished worker discovery
22:17:21 DISPATCHER: Starting worker discovery
22:17:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:17:21 DISPATCHER: Finished worker discovery
22:18:21 DISPATCHER: Starting worker discovery
22:18:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:18:21 DISPATCHER: Finished worker discovery
22:19:21 DISPATCHER: Starting worker discovery
22:19:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:19:21 DISPATCHER: Finished worker discovery
22:20:21 DISPATCHER: Starting worker discovery
22:20:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:20:21 DISPATCHER: Finished worker discovery
22:21:21 DISPATCHER: Starting worker discovery
22:21:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:21:21 DISPATCHER: Finished worker discovery
22:22:21 DISPATCHER: Starting worker discovery
22:22:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:22:21 DISPATCHER: Finished worker discovery
22:23:21 DISPATCHER: Starting worker discovery
22:23:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:23:21 DISPATCHER: Finished worker discovery
22:24:21 DISPATCHER: Starting worker discovery
22:24:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:24:21 DISPATCHER: Finished worker discovery
22:25:21 DISPATCHER: Starting worker discovery
22:25:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:25:21 DISPATCHER: Finished worker discovery
22:26:15 WORKER: done with job (7, 0, 3), trying to register it.
22:26:15 WORKER: registered result for job (7, 0, 3) with dispatcher
22:26:15 DISPATCHER: job (7, 0, 3) finished
22:26:15 DISPATCHER: register_result: lock acquired
22:26:15 DISPATCHER: job (7, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
22:26:15 job_id: (7, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.005536268586554153, 'num_filters_1': 124, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.06867331899938382, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 67, 'num_filters_3': 31, 'num_filters_4': 40}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.28574088706697054, 'info': {'music_genre': 0.28574088706697054, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.005536268586554153, 'num_filters_1': 124, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.06867331899938382, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 67, 'num_filters_3': 31, 'num_filters_4': 40}"}}
exception: None

22:26:15 job_callback for (7, 0, 3) started
22:26:15 DISPATCHER: Trying to submit another job.
22:26:15 job_callback for (7, 0, 3) got condition
22:26:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:26:15 Only 16 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
22:26:15 HBMASTER: Trying to run another job!
22:26:15 job_callback for (7, 0, 3) finished
22:26:15 start sampling a new configuration.
22:26:15 best_vector: [2, 1, 0.8193764792174183, 0.08688825516316617, 0.8441270139135804, 1, 0.124157005841488, 0.07968268183764027, 2, 1, 0, 1, 0.408289529617358, 0.25363447421135465, 0.10752999395341045, 0.38633706784250643], 4.741466532478765e-30, 0.0021090521110927584, -5.512421208051081e-08
22:26:15 done sampling a new configuration.
22:26:15 HBMASTER: schedule new run for iteration 8
22:26:15 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
22:26:15 HBMASTER: submitting job (8, 0, 0) to dispatcher
22:26:15 DISPATCHER: trying to submit job (8, 0, 0)
22:26:15 DISPATCHER: trying to notify the job_runner thread.
22:26:15 HBMASTER: job (8, 0, 0) submitted to dispatcher
22:26:15 DISPATCHER: Trying to submit another job.
22:26:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:26:15 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:26:15 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:26:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:26:15 WORKER: start processing job (8, 0, 0)
22:26:15 WORKER: args: ()
22:26:15 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.04352642100727418, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.012696077336577466, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 37, 'num_filters_3': 27, 'num_filters_4': 19, 'num_filters_5': 35}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:26:21 DISPATCHER: Starting worker discovery
22:26:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:26:21 DISPATCHER: Finished worker discovery
22:27:21 DISPATCHER: Starting worker discovery
22:27:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:27:21 DISPATCHER: Finished worker discovery
22:27:57 WORKER: done with job (8, 0, 0), trying to register it.
22:27:57 WORKER: registered result for job (8, 0, 0) with dispatcher
22:27:57 DISPATCHER: job (8, 0, 0) finished
22:27:57 DISPATCHER: register_result: lock acquired
22:27:57 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
22:27:57 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.04352642100727418, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.012696077336577466, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 37, 'num_filters_3': 27, 'num_filters_4': 19, 'num_filters_5': 35}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4795968509971484, 'info': {'music_genre': 0.4795968509971484, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.04352642100727418, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.012696077336577466, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 37, 'num_filters_3': 27, 'num_filters_4': 19, 'num_filters_5': 35}"}}
exception: None

22:27:57 job_callback for (8, 0, 0) started
22:27:57 DISPATCHER: Trying to submit another job.
22:27:57 job_callback for (8, 0, 0) got condition
22:27:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:27:57 HBMASTER: Trying to run another job!
22:27:57 job_callback for (8, 0, 0) finished
22:27:57 start sampling a new configuration.
22:27:57 done sampling a new configuration.
22:27:57 HBMASTER: schedule new run for iteration 8
22:27:57 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
22:27:57 HBMASTER: submitting job (8, 0, 1) to dispatcher
22:27:57 DISPATCHER: trying to submit job (8, 0, 1)
22:27:57 DISPATCHER: trying to notify the job_runner thread.
22:27:57 HBMASTER: job (8, 0, 1) submitted to dispatcher
22:27:57 DISPATCHER: Trying to submit another job.
22:27:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:27:57 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:27:57 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:27:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:27:57 WORKER: start processing job (8, 0, 1)
22:27:57 WORKER: args: ()
22:27:57 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.05405545026530561, 'num_filters_1': 107, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.09408123129131753, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 63, 'num_filters_3': 20}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:28:21 DISPATCHER: Starting worker discovery
22:28:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:28:21 DISPATCHER: Finished worker discovery
22:29:21 DISPATCHER: Starting worker discovery
22:29:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:29:21 DISPATCHER: Finished worker discovery
22:29:38 WORKER: done with job (8, 0, 1), trying to register it.
22:29:38 WORKER: registered result for job (8, 0, 1) with dispatcher
22:29:38 DISPATCHER: job (8, 0, 1) finished
22:29:38 DISPATCHER: register_result: lock acquired
22:29:38 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
22:29:38 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.05405545026530561, 'num_filters_1': 107, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.09408123129131753, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 63, 'num_filters_3': 20}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0014325882665596832, 'info': {'music_genre': 0.0014325882665596832, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.05405545026530561, 'num_filters_1': 107, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.09408123129131753, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 63, 'num_filters_3': 20}"}}
exception: None

22:29:38 job_callback for (8, 0, 1) started
22:29:38 job_callback for (8, 0, 1) got condition
22:29:38 DISPATCHER: Trying to submit another job.
22:29:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:29:38 HBMASTER: Trying to run another job!
22:29:38 job_callback for (8, 0, 1) finished
22:29:38 start sampling a new configuration.
22:29:38 done sampling a new configuration.
22:29:38 HBMASTER: schedule new run for iteration 8
22:29:38 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
22:29:38 HBMASTER: submitting job (8, 0, 2) to dispatcher
22:29:38 DISPATCHER: trying to submit job (8, 0, 2)
22:29:38 DISPATCHER: trying to notify the job_runner thread.
22:29:38 HBMASTER: job (8, 0, 2) submitted to dispatcher
22:29:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:29:38 DISPATCHER: Trying to submit another job.
22:29:38 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:29:38 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:29:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:29:38 WORKER: start processing job (8, 0, 2)
22:29:38 WORKER: args: ()
22:29:38 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.009663556815134656, 'num_filters_1': 38, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.099230390393884, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 57, 'num_filters_3': 22}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:30:21 DISPATCHER: Starting worker discovery
22:30:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:30:21 DISPATCHER: Finished worker discovery
22:31:19 WORKER: done with job (8, 0, 2), trying to register it.
22:31:19 WORKER: registered result for job (8, 0, 2) with dispatcher
22:31:19 DISPATCHER: job (8, 0, 2) finished
22:31:19 DISPATCHER: register_result: lock acquired
22:31:19 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
22:31:19 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.009663556815134656, 'num_filters_1': 38, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.099230390393884, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 57, 'num_filters_3': 22}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.13182002345476007, 'info': {'music_genre': 0.13182002345476007, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.009663556815134656, 'num_filters_1': 38, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.099230390393884, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 57, 'num_filters_3': 22}"}}
exception: None

22:31:19 job_callback for (8, 0, 2) started
22:31:19 job_callback for (8, 0, 2) got condition
22:31:19 DISPATCHER: Trying to submit another job.
22:31:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:31:19 HBMASTER: Trying to run another job!
22:31:19 job_callback for (8, 0, 2) finished
22:31:19 start sampling a new configuration.
22:31:19 done sampling a new configuration.
22:31:19 HBMASTER: schedule new run for iteration 8
22:31:19 HBMASTER: trying submitting job (8, 0, 3) to dispatcher
22:31:19 HBMASTER: submitting job (8, 0, 3) to dispatcher
22:31:19 DISPATCHER: trying to submit job (8, 0, 3)
22:31:19 DISPATCHER: trying to notify the job_runner thread.
22:31:19 HBMASTER: job (8, 0, 3) submitted to dispatcher
22:31:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:31:19 DISPATCHER: Trying to submit another job.
22:31:19 DISPATCHER: starting job (8, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:31:19 DISPATCHER: job (8, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:31:19 WORKER: start processing job (8, 0, 3)
22:31:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:31:19 WORKER: args: ()
22:31:19 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.07872223722782787, 'num_filters_1': 67, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.04549210637565898, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 39, 'num_filters_3': 56, 'num_filters_4': 120}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:31:21 DISPATCHER: Starting worker discovery
22:31:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:31:21 DISPATCHER: Finished worker discovery
22:32:21 DISPATCHER: Starting worker discovery
22:32:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:32:21 DISPATCHER: Finished worker discovery
22:33:02 WORKER: done with job (8, 0, 3), trying to register it.
22:33:02 WORKER: registered result for job (8, 0, 3) with dispatcher
22:33:02 DISPATCHER: job (8, 0, 3) finished
22:33:02 DISPATCHER: register_result: lock acquired
22:33:02 DISPATCHER: job (8, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
22:33:02 job_id: (8, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.07872223722782787, 'num_filters_1': 67, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.04549210637565898, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 39, 'num_filters_3': 56, 'num_filters_4': 120}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.07872223722782787, 'num_filters_1': 67, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.04549210637565898, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 39, 'num_filters_3': 56, 'num_filters_4': 120}"}}
exception: None

22:33:02 job_callback for (8, 0, 3) started
22:33:02 job_callback for (8, 0, 3) got condition
22:33:02 DISPATCHER: Trying to submit another job.
22:33:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:33:02 HBMASTER: Trying to run another job!
22:33:02 job_callback for (8, 0, 3) finished
22:33:02 start sampling a new configuration.
22:33:02 best_vector: [2, 1, 0.7223961083066915, 0.29718051646255633, 0.8961775188287233, 1, 0.8266437695294426, 0.23019854135779053, 1, 2, 2, 1, 0.5859736219404184, 0.518998088320677, 0.3733500066457512, 0.24095502228585913], 1.5608067286544902e-29, 0.0006406943163693691, -1.1228679896850818e-06
22:33:02 done sampling a new configuration.
22:33:02 HBMASTER: schedule new run for iteration 8
22:33:02 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
22:33:02 HBMASTER: submitting job (8, 0, 4) to dispatcher
22:33:02 DISPATCHER: trying to submit job (8, 0, 4)
22:33:02 DISPATCHER: trying to notify the job_runner thread.
22:33:02 HBMASTER: job (8, 0, 4) submitted to dispatcher
22:33:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:33:02 DISPATCHER: Trying to submit another job.
22:33:02 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:33:02 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:33:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:33:02 WORKER: start processing job (8, 0, 4)
22:33:02 WORKER: args: ()
22:33:02 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.027847884986289394, 'num_filters_1': 29, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.01992944512543211, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 54, 'num_filters_3': 46, 'num_filters_4': 34, 'num_filters_5': 26}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:33:21 DISPATCHER: Starting worker discovery
22:33:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:33:21 DISPATCHER: Finished worker discovery
22:34:21 DISPATCHER: Starting worker discovery
22:34:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:34:21 DISPATCHER: Finished worker discovery
22:34:44 WORKER: done with job (8, 0, 4), trying to register it.
22:34:44 WORKER: registered result for job (8, 0, 4) with dispatcher
22:34:44 DISPATCHER: job (8, 0, 4) finished
22:34:44 DISPATCHER: register_result: lock acquired
22:34:44 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
22:34:44 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.027847884986289394, 'num_filters_1': 29, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.01992944512543211, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 54, 'num_filters_3': 46, 'num_filters_4': 34, 'num_filters_5': 26}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.46937214515540016, 'info': {'music_genre': 0.46937214515540016, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.027847884986289394, 'num_filters_1': 29, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.01992944512543211, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 54, 'num_filters_3': 46, 'num_filters_4': 34, 'num_filters_5': 26}"}}
exception: None

22:34:44 job_callback for (8, 0, 4) started
22:34:44 DISPATCHER: Trying to submit another job.
22:34:44 job_callback for (8, 0, 4) got condition
22:34:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:34:44 HBMASTER: Trying to run another job!
22:34:44 job_callback for (8, 0, 4) finished
22:34:44 start sampling a new configuration.
22:34:44 done sampling a new configuration.
22:34:44 HBMASTER: schedule new run for iteration 8
22:34:44 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
22:34:44 HBMASTER: submitting job (8, 0, 5) to dispatcher
22:34:44 DISPATCHER: trying to submit job (8, 0, 5)
22:34:44 DISPATCHER: trying to notify the job_runner thread.
22:34:44 HBMASTER: job (8, 0, 5) submitted to dispatcher
22:34:44 DISPATCHER: Trying to submit another job.
22:34:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:34:44 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:34:44 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:34:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:34:44 WORKER: start processing job (8, 0, 5)
22:34:44 WORKER: args: ()
22:34:44 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0016815304713223454, 'num_filters_1': 20, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.12149554504298067, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 36, 'num_filters_3': 30, 'num_filters_4': 66, 'num_filters_5': 25}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:35:21 DISPATCHER: Starting worker discovery
22:35:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:35:21 DISPATCHER: Finished worker discovery
22:36:21 DISPATCHER: Starting worker discovery
22:36:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:36:21 DISPATCHER: Finished worker discovery
22:36:26 WORKER: done with job (8, 0, 5), trying to register it.
22:36:26 WORKER: registered result for job (8, 0, 5) with dispatcher
22:36:26 DISPATCHER: job (8, 0, 5) finished
22:36:26 DISPATCHER: register_result: lock acquired
22:36:26 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
22:36:26 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0016815304713223454, 'num_filters_1': 20, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.12149554504298067, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 36, 'num_filters_3': 30, 'num_filters_4': 66, 'num_filters_5': 25}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.32146448452784204, 'info': {'music_genre': 0.32146448452784204, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0016815304713223454, 'num_filters_1': 20, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.12149554504298067, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 36, 'num_filters_3': 30, 'num_filters_4': 66, 'num_filters_5': 25}"}}
exception: None

22:36:26 job_callback for (8, 0, 5) started
22:36:26 DISPATCHER: Trying to submit another job.
22:36:26 job_callback for (8, 0, 5) got condition
22:36:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:36:26 HBMASTER: Trying to run another job!
22:36:26 job_callback for (8, 0, 5) finished
22:36:26 start sampling a new configuration.
22:36:26 done sampling a new configuration.
22:36:26 HBMASTER: schedule new run for iteration 8
22:36:26 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
22:36:26 HBMASTER: submitting job (8, 0, 6) to dispatcher
22:36:26 DISPATCHER: trying to submit job (8, 0, 6)
22:36:26 DISPATCHER: trying to notify the job_runner thread.
22:36:26 HBMASTER: job (8, 0, 6) submitted to dispatcher
22:36:26 DISPATCHER: Trying to submit another job.
22:36:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:36:26 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:36:26 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:36:26 WORKER: start processing job (8, 0, 6)
22:36:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:36:26 WORKER: args: ()
22:36:26 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.03371987059696191, 'num_filters_1': 30, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.06130850224690261, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 22, 'num_filters_3': 52}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:37:21 DISPATCHER: Starting worker discovery
22:37:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:37:21 DISPATCHER: Finished worker discovery
22:38:07 WORKER: done with job (8, 0, 6), trying to register it.
22:38:07 WORKER: registered result for job (8, 0, 6) with dispatcher
22:38:07 DISPATCHER: job (8, 0, 6) finished
22:38:07 DISPATCHER: register_result: lock acquired
22:38:07 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
22:38:07 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.03371987059696191, 'num_filters_1': 30, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.06130850224690261, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 22, 'num_filters_3': 52}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.03371987059696191, 'num_filters_1': 30, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.06130850224690261, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 22, 'num_filters_3': 52}"}}
exception: None

22:38:07 job_callback for (8, 0, 6) started
22:38:07 job_callback for (8, 0, 6) got condition
22:38:07 DISPATCHER: Trying to submit another job.
22:38:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:38:07 HBMASTER: Trying to run another job!
22:38:07 job_callback for (8, 0, 6) finished
22:38:07 start sampling a new configuration.
22:38:07 best_vector: [2, 0, 0.87359357999105, 0.07183997747595056, 0.38469489446750116, 1, 0.8394083638080061, 0.6166810043189397, 2, 1, 0, 1, 0.29372058156420355, 0.7117380012950738, 0.514019921167342, 0.48786941956184376], 4.642232090685659e-26, 2.154136157919454e-07, -1.6906804489498297e-06
22:38:07 done sampling a new configuration.
22:38:07 HBMASTER: schedule new run for iteration 8
22:38:07 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
22:38:07 HBMASTER: submitting job (8, 0, 7) to dispatcher
22:38:07 DISPATCHER: trying to submit job (8, 0, 7)
22:38:07 DISPATCHER: trying to notify the job_runner thread.
22:38:07 HBMASTER: job (8, 0, 7) submitted to dispatcher
22:38:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:38:07 DISPATCHER: Trying to submit another job.
22:38:07 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:38:07 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:38:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:38:07 WORKER: start processing job (8, 0, 7)
22:38:07 WORKER: args: ()
22:38:07 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.05587109203308409, 'num_filters_1': 18, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.063433764331692, 'kernel_size_2': 7, 'num_filters_2': 29}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:38:21 DISPATCHER: Starting worker discovery
22:38:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:38:21 DISPATCHER: Finished worker discovery
22:39:21 DISPATCHER: Starting worker discovery
22:39:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:39:21 DISPATCHER: Finished worker discovery
22:39:46 WORKER: done with job (8, 0, 7), trying to register it.
22:39:46 WORKER: registered result for job (8, 0, 7) with dispatcher
22:39:46 DISPATCHER: job (8, 0, 7) finished
22:39:46 DISPATCHER: register_result: lock acquired
22:39:46 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
22:39:46 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.05587109203308409, 'num_filters_1': 18, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.063433764331692, 'kernel_size_2': 7, 'num_filters_2': 29}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.32607018036521634, 'info': {'music_genre': 0.32607018036521634, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.05587109203308409, 'num_filters_1': 18, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.063433764331692, 'kernel_size_2': 7, 'num_filters_2': 29}"}}
exception: None

22:39:46 job_callback for (8, 0, 7) started
22:39:46 job_callback for (8, 0, 7) got condition
22:39:46 DISPATCHER: Trying to submit another job.
22:39:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:39:46 HBMASTER: Trying to run another job!
22:39:46 job_callback for (8, 0, 7) finished
22:39:46 start sampling a new configuration.
22:39:46 done sampling a new configuration.
22:39:46 HBMASTER: schedule new run for iteration 8
22:39:46 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
22:39:46 HBMASTER: submitting job (8, 0, 8) to dispatcher
22:39:46 DISPATCHER: trying to submit job (8, 0, 8)
22:39:46 DISPATCHER: trying to notify the job_runner thread.
22:39:46 HBMASTER: job (8, 0, 8) submitted to dispatcher
22:39:46 DISPATCHER: Trying to submit another job.
22:39:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:39:46 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:39:46 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:39:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:39:46 WORKER: start processing job (8, 0, 8)
22:39:46 WORKER: args: ()
22:39:46 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.002273911077574492, 'num_filters_1': 26, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.04466374842017211, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 61, 'num_filters_3': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:40:21 DISPATCHER: Starting worker discovery
22:40:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:40:21 DISPATCHER: Finished worker discovery
22:41:21 DISPATCHER: Starting worker discovery
22:41:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:41:21 DISPATCHER: Finished worker discovery
22:41:29 WORKER: done with job (8, 0, 8), trying to register it.
22:41:29 WORKER: registered result for job (8, 0, 8) with dispatcher
22:41:29 DISPATCHER: job (8, 0, 8) finished
22:41:29 DISPATCHER: register_result: lock acquired
22:41:29 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
22:41:29 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.002273911077574492, 'num_filters_1': 26, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.04466374842017211, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 61, 'num_filters_3': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.49043795396971274, 'info': {'music_genre': 0.49043795396971274, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.002273911077574492, 'num_filters_1': 26, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.04466374842017211, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 61, 'num_filters_3': 19}"}}
exception: None

22:41:29 job_callback for (8, 0, 8) started
22:41:29 DISPATCHER: Trying to submit another job.
22:41:29 job_callback for (8, 0, 8) got condition
22:41:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:41:29 HBMASTER: Trying to run another job!
22:41:29 job_callback for (8, 0, 8) finished
22:41:29 start sampling a new configuration.
22:41:29 done sampling a new configuration.
22:41:29 HBMASTER: schedule new run for iteration 8
22:41:29 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
22:41:29 HBMASTER: submitting job (8, 0, 9) to dispatcher
22:41:29 DISPATCHER: trying to submit job (8, 0, 9)
22:41:29 DISPATCHER: trying to notify the job_runner thread.
22:41:29 HBMASTER: job (8, 0, 9) submitted to dispatcher
22:41:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:41:29 DISPATCHER: Trying to submit another job.
22:41:29 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:41:29 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:41:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:41:29 WORKER: start processing job (8, 0, 9)
22:41:29 WORKER: args: ()
22:41:29 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0029452930639319863, 'num_filters_1': 30, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.184217473960214, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 33, 'num_filters_3': 37, 'num_filters_4': 23}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:42:21 DISPATCHER: Starting worker discovery
22:42:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:42:21 DISPATCHER: Finished worker discovery
22:43:10 WORKER: done with job (8, 0, 9), trying to register it.
22:43:10 WORKER: registered result for job (8, 0, 9) with dispatcher
22:43:10 DISPATCHER: job (8, 0, 9) finished
22:43:10 DISPATCHER: register_result: lock acquired
22:43:10 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
22:43:10 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0029452930639319863, 'num_filters_1': 30, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.184217473960214, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 33, 'num_filters_3': 37, 'num_filters_4': 23}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.06039219834748808, 'info': {'music_genre': 0.06039219834748808, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0029452930639319863, 'num_filters_1': 30, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.184217473960214, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 33, 'num_filters_3': 37, 'num_filters_4': 23}"}}
exception: None

22:43:10 job_callback for (8, 0, 9) started
22:43:10 job_callback for (8, 0, 9) got condition
22:43:10 DISPATCHER: Trying to submit another job.
22:43:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:43:10 HBMASTER: Trying to run another job!
22:43:10 job_callback for (8, 0, 9) finished
22:43:10 start sampling a new configuration.
22:43:10 best_vector: [0, 1, 0.23202404596206022, 0.597983182575999, 0.06284996808836035, 1, 0.8969804817301611, 0.18773080218578023, 2, 0, 0, 1, 0.5459776270459814, 0.6741489312601254, 0.5455055488919616, 0.3352313220216224], 3.074860360248658e-31, 0.03252180206060258, -9.829764743311618e-06
22:43:10 done sampling a new configuration.
22:43:10 HBMASTER: schedule new run for iteration 8
22:43:10 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
22:43:10 HBMASTER: submitting job (8, 0, 10) to dispatcher
22:43:10 DISPATCHER: trying to submit job (8, 0, 10)
22:43:10 DISPATCHER: trying to notify the job_runner thread.
22:43:10 HBMASTER: job (8, 0, 10) submitted to dispatcher
22:43:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:43:10 DISPATCHER: Trying to submit another job.
22:43:10 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:43:10 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:43:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:43:10 WORKER: start processing job (8, 0, 10)
22:43:10 WORKER: args: ()
22:43:10 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002911039456349506, 'num_filters_1': 55, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.017548637574962632}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:43:21 DISPATCHER: Starting worker discovery
22:43:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:43:21 DISPATCHER: Finished worker discovery
22:44:21 DISPATCHER: Starting worker discovery
22:44:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:44:21 DISPATCHER: Finished worker discovery
22:44:50 WORKER: done with job (8, 0, 10), trying to register it.
22:44:50 WORKER: registered result for job (8, 0, 10) with dispatcher
22:44:50 DISPATCHER: job (8, 0, 10) finished
22:44:50 DISPATCHER: register_result: lock acquired
22:44:50 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
22:44:50 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002911039456349506, 'num_filters_1': 55, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.017548637574962632}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4560264964159723, 'info': {'music_genre': 0.4560264964159723, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002911039456349506, 'num_filters_1': 55, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.017548637574962632}"}}
exception: None

22:44:50 job_callback for (8, 0, 10) started
22:44:50 DISPATCHER: Trying to submit another job.
22:44:50 job_callback for (8, 0, 10) got condition
22:44:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:44:50 HBMASTER: Trying to run another job!
22:44:50 job_callback for (8, 0, 10) finished
22:44:50 start sampling a new configuration.
22:44:50 best_vector: [2, 0, 0.2993284275677242, 0.3140391204129448, 0.39314233735804643, 1, 0.3215032087012367, 0.03699324853442071, 0, 1, 2, 1, 0.6547258783316041, 0.28131797022699273, 0.19143736258767863, 0.36249213408484904], 2.5759846406481414e-30, 0.0038820107240561453, -2.5583288485627413e-06
22:44:50 done sampling a new configuration.
22:44:50 HBMASTER: schedule new run for iteration 8
22:44:50 HBMASTER: trying submitting job (8, 0, 11) to dispatcher
22:44:50 HBMASTER: submitting job (8, 0, 11) to dispatcher
22:44:50 DISPATCHER: trying to submit job (8, 0, 11)
22:44:50 DISPATCHER: trying to notify the job_runner thread.
22:44:50 HBMASTER: job (8, 0, 11) submitted to dispatcher
22:44:50 DISPATCHER: Trying to submit another job.
22:44:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:44:50 DISPATCHER: starting job (8, 0, 11) on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:44:50 DISPATCHER: job (8, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:44:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:44:50 WORKER: start processing job (8, 0, 11)
22:44:50 WORKER: args: ()
22:44:50 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003968778443318448, 'num_filters_1': 30, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.011171958813931317, 'kernel_size_2': 3, 'num_filters_2': 62}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:45:21 DISPATCHER: Starting worker discovery
22:45:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:45:21 DISPATCHER: Finished worker discovery
22:46:21 DISPATCHER: Starting worker discovery
22:46:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:46:21 DISPATCHER: Finished worker discovery
22:46:33 WORKER: done with job (8, 0, 11), trying to register it.
22:46:33 WORKER: registered result for job (8, 0, 11) with dispatcher
22:46:33 DISPATCHER: job (8, 0, 11) finished
22:46:33 DISPATCHER: register_result: lock acquired
22:46:33 DISPATCHER: job (8, 0, 11) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
22:46:33 job_id: (8, 0, 11)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003968778443318448, 'num_filters_1': 30, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.011171958813931317, 'kernel_size_2': 3, 'num_filters_2': 62}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4687996711448847, 'info': {'music_genre': 0.4687996711448847, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003968778443318448, 'num_filters_1': 30, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.011171958813931317, 'kernel_size_2': 3, 'num_filters_2': 62}"}}
exception: None

22:46:33 job_callback for (8, 0, 11) started
22:46:33 job_callback for (8, 0, 11) got condition
22:46:33 DISPATCHER: Trying to submit another job.
22:46:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:46:33 HBMASTER: Trying to run another job!
22:46:33 job_callback for (8, 0, 11) finished
22:46:33 start sampling a new configuration.
22:46:33 best_vector: [2, 2, 0.4838862819702455, 0.173580059399086, 0.5525215043528873, 1, 0.26768477421472386, 0.44667406340197685, 2, 0, 0, 1, 0.13711948157642076, 0.813773403615708, 0.10086799008093783, 0.5439320796989735], 1.591868811090723e-29, 0.0006281924697769636, -1.7016273454460262e-05
22:46:33 done sampling a new configuration.
22:46:33 HBMASTER: schedule new run for iteration 8
22:46:33 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
22:46:33 HBMASTER: submitting job (8, 0, 12) to dispatcher
22:46:33 DISPATCHER: trying to submit job (8, 0, 12)
22:46:33 DISPATCHER: trying to notify the job_runner thread.
22:46:33 HBMASTER: job (8, 0, 12) submitted to dispatcher
22:46:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:46:33 DISPATCHER: Trying to submit another job.
22:46:33 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:46:33 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:46:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:46:33 WORKER: start processing job (8, 0, 12)
22:46:33 WORKER: args: ()
22:46:33 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.009284800229184107, 'num_filters_1': 22, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.038118548482872154, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 21, 'num_filters_3': 87}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:47:21 DISPATCHER: Starting worker discovery
22:47:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:47:21 DISPATCHER: Finished worker discovery
22:48:15 WORKER: done with job (8, 0, 12), trying to register it.
22:48:15 WORKER: registered result for job (8, 0, 12) with dispatcher
22:48:15 DISPATCHER: job (8, 0, 12) finished
22:48:15 DISPATCHER: register_result: lock acquired
22:48:15 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
22:48:15 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.009284800229184107, 'num_filters_1': 22, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.038118548482872154, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 21, 'num_filters_3': 87}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4651338760430262, 'info': {'music_genre': 0.4651338760430262, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.009284800229184107, 'num_filters_1': 22, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.038118548482872154, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 21, 'num_filters_3': 87}"}}
exception: None

22:48:15 job_callback for (8, 0, 12) started
22:48:15 DISPATCHER: Trying to submit another job.
22:48:15 job_callback for (8, 0, 12) got condition
22:48:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:48:15 HBMASTER: Trying to run another job!
22:48:15 job_callback for (8, 0, 12) finished
22:48:15 start sampling a new configuration.
22:48:15 best_vector: [0, 1, 0.23377707845340595, 0.07177402360917, 0.2572578108895295, 1, 0.9660575889790693, 0.2666524798607912, 0, 1, 1, 1, 0.4958827950042215, 0.207838089776753, 0.34181191180723874, 0.6004616951029916], 2.9921323435028024e-31, 0.03342098160101198, -0.00011137439394447785
22:48:15 done sampling a new configuration.
22:48:15 HBMASTER: schedule new run for iteration 8
22:48:15 HBMASTER: trying submitting job (8, 0, 13) to dispatcher
22:48:15 HBMASTER: submitting job (8, 0, 13) to dispatcher
22:48:15 DISPATCHER: trying to submit job (8, 0, 13)
22:48:15 DISPATCHER: trying to notify the job_runner thread.
22:48:15 HBMASTER: job (8, 0, 13) submitted to dispatcher
22:48:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:48:15 DISPATCHER: Trying to submit another job.
22:48:15 DISPATCHER: starting job (8, 0, 13) on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:48:15 DISPATCHER: job (8, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:48:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:48:15 WORKER: start processing job (8, 0, 13)
22:48:15 WORKER: args: ()
22:48:15 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002934635432779128, 'num_filters_1': 18, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.022229150936032643, 'kernel_size_2': 3, 'num_filters_2': 44}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:48:21 DISPATCHER: Starting worker discovery
22:48:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:48:21 DISPATCHER: Finished worker discovery
22:49:21 DISPATCHER: Starting worker discovery
22:49:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:49:21 DISPATCHER: Finished worker discovery
22:49:56 WORKER: done with job (8, 0, 13), trying to register it.
22:49:56 WORKER: registered result for job (8, 0, 13) with dispatcher
22:49:56 DISPATCHER: job (8, 0, 13) finished
22:49:56 DISPATCHER: register_result: lock acquired
22:49:56 DISPATCHER: job (8, 0, 13) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
22:49:56 job_id: (8, 0, 13)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002934635432779128, 'num_filters_1': 18, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.022229150936032643, 'kernel_size_2': 3, 'num_filters_2': 44}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.36421792160664695, 'info': {'music_genre': 0.36421792160664695, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002934635432779128, 'num_filters_1': 18, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.022229150936032643, 'kernel_size_2': 3, 'num_filters_2': 44}"}}
exception: None

22:49:56 job_callback for (8, 0, 13) started
22:49:56 job_callback for (8, 0, 13) got condition
22:49:56 DISPATCHER: Trying to submit another job.
22:49:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:49:56 HBMASTER: Trying to run another job!
22:49:56 job_callback for (8, 0, 13) finished
22:49:56 start sampling a new configuration.
22:49:56 done sampling a new configuration.
22:49:56 HBMASTER: schedule new run for iteration 8
22:49:56 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
22:49:56 HBMASTER: submitting job (8, 0, 14) to dispatcher
22:49:56 DISPATCHER: trying to submit job (8, 0, 14)
22:49:56 DISPATCHER: trying to notify the job_runner thread.
22:49:56 HBMASTER: job (8, 0, 14) submitted to dispatcher
22:49:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:49:56 DISPATCHER: Trying to submit another job.
22:49:56 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:49:56 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:49:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:49:56 WORKER: start processing job (8, 0, 14)
22:49:56 WORKER: args: ()
22:49:56 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.010432030170555351, 'num_filters_1': 108, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.01089336629113482, 'kernel_size_2': 5, 'num_filters_2': 35}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:50:21 DISPATCHER: Starting worker discovery
22:50:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:50:21 DISPATCHER: Finished worker discovery
22:51:21 DISPATCHER: Starting worker discovery
22:51:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:51:21 DISPATCHER: Finished worker discovery
22:51:38 WORKER: done with job (8, 0, 14), trying to register it.
22:51:38 WORKER: registered result for job (8, 0, 14) with dispatcher
22:51:38 DISPATCHER: job (8, 0, 14) finished
22:51:38 DISPATCHER: register_result: lock acquired
22:51:38 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
22:51:38 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.010432030170555351, 'num_filters_1': 108, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.01089336629113482, 'kernel_size_2': 5, 'num_filters_2': 35}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.24012366419967046, 'info': {'music_genre': 0.24012366419967046, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.010432030170555351, 'num_filters_1': 108, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.01089336629113482, 'kernel_size_2': 5, 'num_filters_2': 35}"}}
exception: None

22:51:38 job_callback for (8, 0, 14) started
22:51:38 DISPATCHER: Trying to submit another job.
22:51:38 job_callback for (8, 0, 14) got condition
22:51:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:51:38 HBMASTER: Trying to run another job!
22:51:38 job_callback for (8, 0, 14) finished
22:51:38 start sampling a new configuration.
22:51:38 best_vector: [0, 0, 0.1383338710510589, 0.2990907865256286, 0.1829807149457402, 1, 0.7302645336594318, 0.18901189209007402, 0, 2, 0, 1, 0.24323698311989295, 0.46431442336682527, 0.518538621671046, 0.3502465618198771], 5.0483519155313625e-31, 0.01980844475052301, -0.00011649314871845969
22:51:38 done sampling a new configuration.
22:51:38 HBMASTER: schedule new run for iteration 8
22:51:38 HBMASTER: trying submitting job (8, 0, 15) to dispatcher
22:51:38 HBMASTER: submitting job (8, 0, 15) to dispatcher
22:51:38 DISPATCHER: trying to submit job (8, 0, 15)
22:51:38 DISPATCHER: trying to notify the job_runner thread.
22:51:38 HBMASTER: job (8, 0, 15) submitted to dispatcher
22:51:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:51:38 DISPATCHER: Trying to submit another job.
22:51:38 DISPATCHER: starting job (8, 0, 15) on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:51:38 DISPATCHER: job (8, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:51:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:51:38 WORKER: start processing job (8, 0, 15)
22:51:38 WORKER: args: ()
22:51:38 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0018908964308759569, 'num_filters_1': 29, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.017616115177897178}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:52:21 DISPATCHER: Starting worker discovery
22:52:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:52:21 DISPATCHER: Finished worker discovery
22:53:21 WORKER: done with job (8, 0, 15), trying to register it.
22:53:21 WORKER: registered result for job (8, 0, 15) with dispatcher
22:53:21 DISPATCHER: job (8, 0, 15) finished
22:53:21 DISPATCHER: register_result: lock acquired
22:53:21 DISPATCHER: job (8, 0, 15) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
22:53:21 job_id: (8, 0, 15)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0018908964308759569, 'num_filters_1': 29, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.017616115177897178}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4521444767590893, 'info': {'music_genre': 0.4521444767590893, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0018908964308759569, 'num_filters_1': 29, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.017616115177897178}"}}
exception: None

22:53:21 job_callback for (8, 0, 15) started
22:53:21 job_callback for (8, 0, 15) got condition
22:53:21 DISPATCHER: Trying to submit another job.
22:53:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:53:21 HBMASTER: Trying to run another job!
22:53:21 job_callback for (8, 0, 15) finished
22:53:21 start sampling a new configuration.
22:53:21 done sampling a new configuration.
22:53:21 HBMASTER: schedule new run for iteration 8
22:53:21 HBMASTER: trying submitting job (8, 0, 16) to dispatcher
22:53:21 HBMASTER: submitting job (8, 0, 16) to dispatcher
22:53:21 DISPATCHER: trying to submit job (8, 0, 16)
22:53:21 DISPATCHER: trying to notify the job_runner thread.
22:53:21 HBMASTER: job (8, 0, 16) submitted to dispatcher
22:53:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:53:21 DISPATCHER: Trying to submit another job.
22:53:21 DISPATCHER: starting job (8, 0, 16) on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:53:21 DISPATCHER: job (8, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:53:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:53:21 WORKER: start processing job (8, 0, 16)
22:53:21 WORKER: args: ()
22:53:21 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.002687577824568163, 'num_filters_1': 19, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.025456040776597508, 'kernel_size_2': 7, 'num_filters_2': 31}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:53:21 DISPATCHER: Starting worker discovery
22:53:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:53:21 DISPATCHER: Finished worker discovery
22:54:21 DISPATCHER: Starting worker discovery
22:54:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:54:21 DISPATCHER: Finished worker discovery
22:55:03 WORKER: done with job (8, 0, 16), trying to register it.
22:55:03 WORKER: registered result for job (8, 0, 16) with dispatcher
22:55:03 DISPATCHER: job (8, 0, 16) finished
22:55:03 DISPATCHER: register_result: lock acquired
22:55:03 DISPATCHER: job (8, 0, 16) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
22:55:03 job_id: (8, 0, 16)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.002687577824568163, 'num_filters_1': 19, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.025456040776597508, 'kernel_size_2': 7, 'num_filters_2': 31}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3147922181241719, 'info': {'music_genre': 0.3147922181241719, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.002687577824568163, 'num_filters_1': 19, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.025456040776597508, 'kernel_size_2': 7, 'num_filters_2': 31}"}}
exception: None

22:55:03 job_callback for (8, 0, 16) started
22:55:03 DISPATCHER: Trying to submit another job.
22:55:03 job_callback for (8, 0, 16) got condition
22:55:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:55:03 HBMASTER: Trying to run another job!
22:55:03 job_callback for (8, 0, 16) finished
22:55:03 start sampling a new configuration.
22:55:03 best_vector: [2, 1, 0.6075877143150633, 0.05093025171068944, 0.715796871857701, 1, 0.5788166691530804, 0.15634486572268125, 0, 2, 2, 1, 0.03602343788323903, 0.6207773458905752, 0.04010022853707823, 0.5179894091915773], 2.3827036770235886e-30, 0.004196912984367297, -7.227974669510141e-07
22:55:03 done sampling a new configuration.
22:55:03 HBMASTER: schedule new run for iteration 8
22:55:03 HBMASTER: trying submitting job (8, 0, 17) to dispatcher
22:55:03 HBMASTER: submitting job (8, 0, 17) to dispatcher
22:55:03 DISPATCHER: trying to submit job (8, 0, 17)
22:55:03 DISPATCHER: trying to notify the job_runner thread.
22:55:03 HBMASTER: job (8, 0, 17) submitted to dispatcher
22:55:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:55:03 DISPATCHER: Trying to submit another job.
22:55:03 DISPATCHER: starting job (8, 0, 17) on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:55:03 DISPATCHER: job (8, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:55:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:55:03 WORKER: start processing job (8, 0, 17)
22:55:03 WORKER: args: ()
22:55:03 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.016412526058269462, 'num_filters_1': 17, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.015973841100204066, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 17, 'num_filters_3': 58, 'num_filters_4': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:55:21 DISPATCHER: Starting worker discovery
22:55:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:55:21 DISPATCHER: Finished worker discovery
22:56:21 DISPATCHER: Starting worker discovery
22:56:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:56:21 DISPATCHER: Finished worker discovery
22:56:46 WORKER: done with job (8, 0, 17), trying to register it.
22:56:46 WORKER: registered result for job (8, 0, 17) with dispatcher
22:56:46 DISPATCHER: job (8, 0, 17) finished
22:56:46 DISPATCHER: register_result: lock acquired
22:56:46 DISPATCHER: job (8, 0, 17) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
22:56:46 job_id: (8, 0, 17)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.016412526058269462, 'num_filters_1': 17, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.015973841100204066, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 17, 'num_filters_3': 58, 'num_filters_4': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5276578801874663, 'info': {'music_genre': 0.5276578801874663, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.016412526058269462, 'num_filters_1': 17, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.015973841100204066, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 17, 'num_filters_3': 58, 'num_filters_4': 17}"}}
exception: None

22:56:46 job_callback for (8, 0, 17) started
22:56:46 job_callback for (8, 0, 17) got condition
22:56:46 DISPATCHER: Trying to submit another job.
22:56:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:56:46 HBMASTER: Trying to run another job!
22:56:46 job_callback for (8, 0, 17) finished
22:56:46 start sampling a new configuration.
22:56:46 best_vector: [0, 0, 0.10231130262660482, 0.2906414934879156, 0.007640878418115782, 1, 0.5920441404500977, 0.15244292046796581, 1, 0, 0, 1, 0.5139486146993962, 0.5357269640382277, 0.7766773068404778, 0.5405888028790375], 1.839773958846181e-30, 0.005435450345362822, -0.0003691348841655718
22:56:46 done sampling a new configuration.
22:56:46 HBMASTER: schedule new run for iteration 8
22:56:46 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
22:56:46 HBMASTER: submitting job (8, 0, 18) to dispatcher
22:56:46 DISPATCHER: trying to submit job (8, 0, 18)
22:56:46 DISPATCHER: trying to notify the job_runner thread.
22:56:46 HBMASTER: job (8, 0, 18) submitted to dispatcher
22:56:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:56:46 DISPATCHER: Trying to submit another job.
22:56:46 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:56:46 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:56:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:56:46 WORKER: start processing job (8, 0, 18)
22:56:46 WORKER: args: ()
22:56:46 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0016018528020259395, 'num_filters_1': 29, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.015788207012257836}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:57:21 DISPATCHER: Starting worker discovery
22:57:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:57:21 DISPATCHER: Finished worker discovery
22:58:21 DISPATCHER: Starting worker discovery
22:58:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:58:21 DISPATCHER: Finished worker discovery
22:58:29 WORKER: done with job (8, 0, 18), trying to register it.
22:58:29 WORKER: registered result for job (8, 0, 18) with dispatcher
22:58:29 DISPATCHER: job (8, 0, 18) finished
22:58:29 DISPATCHER: register_result: lock acquired
22:58:29 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
22:58:29 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0016018528020259395, 'num_filters_1': 29, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.015788207012257836}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.44020948508438684, 'info': {'music_genre': 0.44020948508438684, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0016018528020259395, 'num_filters_1': 29, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.015788207012257836}"}}
exception: None

22:58:29 job_callback for (8, 0, 18) started
22:58:29 job_callback for (8, 0, 18) got condition
22:58:29 DISPATCHER: Trying to submit another job.
22:58:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:58:29 HBMASTER: Trying to run another job!
22:58:29 job_callback for (8, 0, 18) finished
22:58:29 start sampling a new configuration.
22:58:29 done sampling a new configuration.
22:58:29 HBMASTER: schedule new run for iteration 8
22:58:29 HBMASTER: trying submitting job (8, 0, 19) to dispatcher
22:58:29 HBMASTER: submitting job (8, 0, 19) to dispatcher
22:58:29 DISPATCHER: trying to submit job (8, 0, 19)
22:58:29 DISPATCHER: trying to notify the job_runner thread.
22:58:29 HBMASTER: job (8, 0, 19) submitted to dispatcher
22:58:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:58:29 DISPATCHER: Trying to submit another job.
22:58:29 DISPATCHER: starting job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:58:29 DISPATCHER: job (8, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:58:29 WORKER: start processing job (8, 0, 19)
22:58:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:58:29 WORKER: args: ()
22:58:29 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.004990855049956972, 'num_filters_1': 36, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.08665948160153232, 'kernel_size_2': 3, 'num_filters_2': 21}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:59:21 DISPATCHER: Starting worker discovery
22:59:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:59:22 DISPATCHER: Finished worker discovery
23:00:12 WORKER: done with job (8, 0, 19), trying to register it.
23:00:12 WORKER: registered result for job (8, 0, 19) with dispatcher
23:00:12 DISPATCHER: job (8, 0, 19) finished
23:00:12 DISPATCHER: register_result: lock acquired
23:00:12 DISPATCHER: job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:00:12 job_id: (8, 0, 19)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.004990855049956972, 'num_filters_1': 36, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.08665948160153232, 'kernel_size_2': 3, 'num_filters_2': 21}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.30421513334869343, 'info': {'music_genre': 0.30421513334869343, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.004990855049956972, 'num_filters_1': 36, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.08665948160153232, 'kernel_size_2': 3, 'num_filters_2': 21}"}}
exception: None

23:00:12 job_callback for (8, 0, 19) started
23:00:12 job_callback for (8, 0, 19) got condition
23:00:12 DISPATCHER: Trying to submit another job.
23:00:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:00:12 HBMASTER: Trying to run another job!
23:00:12 job_callback for (8, 0, 19) finished
23:00:12 start sampling a new configuration.
23:00:12 done sampling a new configuration.
23:00:12 HBMASTER: schedule new run for iteration 8
23:00:12 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
23:00:12 HBMASTER: submitting job (8, 0, 20) to dispatcher
23:00:12 DISPATCHER: trying to submit job (8, 0, 20)
23:00:12 DISPATCHER: trying to notify the job_runner thread.
23:00:12 HBMASTER: job (8, 0, 20) submitted to dispatcher
23:00:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:00:12 DISPATCHER: Trying to submit another job.
23:00:12 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:00:12 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:00:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:00:12 WORKER: start processing job (8, 0, 20)
23:00:12 WORKER: args: ()
23:00:12 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0011284490192673112, 'num_filters_1': 112, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.018931780397129356, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 94, 'num_filters_3': 24, 'num_filters_4': 50, 'num_filters_5': 26}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:00:22 DISPATCHER: Starting worker discovery
23:00:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:00:22 DISPATCHER: Finished worker discovery
23:01:22 DISPATCHER: Starting worker discovery
23:01:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:01:22 DISPATCHER: Finished worker discovery
23:01:52 WORKER: done with job (8, 0, 20), trying to register it.
23:01:52 WORKER: registered result for job (8, 0, 20) with dispatcher
23:01:52 DISPATCHER: job (8, 0, 20) finished
23:01:52 DISPATCHER: register_result: lock acquired
23:01:52 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:01:52 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0011284490192673112, 'num_filters_1': 112, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.018931780397129356, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 94, 'num_filters_3': 24, 'num_filters_4': 50, 'num_filters_5': 26}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.40892967295081, 'info': {'music_genre': 0.40892967295081, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0011284490192673112, 'num_filters_1': 112, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.018931780397129356, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 94, 'num_filters_3': 24, 'num_filters_4': 50, 'num_filters_5': 26}"}}
exception: None

23:01:52 job_callback for (8, 0, 20) started
23:01:52 DISPATCHER: Trying to submit another job.
23:01:52 job_callback for (8, 0, 20) got condition
23:01:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:01:52 HBMASTER: Trying to run another job!
23:01:52 job_callback for (8, 0, 20) finished
23:01:52 start sampling a new configuration.
23:01:52 done sampling a new configuration.
23:01:52 HBMASTER: schedule new run for iteration 8
23:01:52 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
23:01:52 HBMASTER: submitting job (8, 0, 21) to dispatcher
23:01:52 DISPATCHER: trying to submit job (8, 0, 21)
23:01:52 DISPATCHER: trying to notify the job_runner thread.
23:01:52 HBMASTER: job (8, 0, 21) submitted to dispatcher
23:01:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:01:52 DISPATCHER: Trying to submit another job.
23:01:52 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:01:52 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:01:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:01:52 WORKER: start processing job (8, 0, 21)
23:01:52 WORKER: args: ()
23:01:52 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.054975332500495605, 'num_filters_1': 42, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.017053122870641407, 'kernel_size_2': 7, 'num_filters_2': 26}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:02:22 DISPATCHER: Starting worker discovery
23:02:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:02:22 DISPATCHER: Finished worker discovery
23:03:22 DISPATCHER: Starting worker discovery
23:03:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:03:22 DISPATCHER: Finished worker discovery
23:03:33 WORKER: done with job (8, 0, 21), trying to register it.
23:03:33 WORKER: registered result for job (8, 0, 21) with dispatcher
23:03:33 DISPATCHER: job (8, 0, 21) finished
23:03:33 DISPATCHER: register_result: lock acquired
23:03:33 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:03:33 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.054975332500495605, 'num_filters_1': 42, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.017053122870641407, 'kernel_size_2': 7, 'num_filters_2': 26}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2767447413096192, 'info': {'music_genre': 0.2767447413096192, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.054975332500495605, 'num_filters_1': 42, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.017053122870641407, 'kernel_size_2': 7, 'num_filters_2': 26}"}}
exception: None

23:03:33 job_callback for (8, 0, 21) started
23:03:33 job_callback for (8, 0, 21) got condition
23:03:33 DISPATCHER: Trying to submit another job.
23:03:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:03:33 HBMASTER: Trying to run another job!
23:03:33 job_callback for (8, 0, 21) finished
23:03:33 start sampling a new configuration.
23:03:33 best_vector: [0, 1, 0.014930847814213027, 0.11253308930274653, 0.4860487461534863, 0, 0.7179447193148211, 0.15469239542292745, 0, 1, 2, 2, 0.18396069407300641, 0.8070632196682143, 0.6959434216031031, 0.6982089374799625], 0.0, inf, 6.569487051022072e-05
23:03:33 done sampling a new configuration.
23:03:33 HBMASTER: schedule new run for iteration 8
23:03:33 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
23:03:33 HBMASTER: submitting job (8, 0, 22) to dispatcher
23:03:33 DISPATCHER: trying to submit job (8, 0, 22)
23:03:33 DISPATCHER: trying to notify the job_runner thread.
23:03:33 HBMASTER: job (8, 0, 22) submitted to dispatcher
23:03:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:03:33 DISPATCHER: Trying to submit another job.
23:03:33 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:03:33 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:03:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:03:33 WORKER: start processing job (8, 0, 22)
23:03:33 WORKER: args: ()
23:03:33 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001071178126116572, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.015894960263711903, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 23, 'num_filters_3': 85}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:04:22 DISPATCHER: Starting worker discovery
23:04:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:04:22 DISPATCHER: Finished worker discovery
23:05:15 WORKER: done with job (8, 0, 22), trying to register it.
23:05:15 WORKER: registered result for job (8, 0, 22) with dispatcher
23:05:15 DISPATCHER: job (8, 0, 22) finished
23:05:15 DISPATCHER: register_result: lock acquired
23:05:15 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:05:15 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001071178126116572, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.015894960263711903, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 23, 'num_filters_3': 85}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.38022863935286383, 'info': {'music_genre': 0.38022863935286383, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001071178126116572, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.015894960263711903, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 23, 'num_filters_3': 85}"}}
exception: None

23:05:15 job_callback for (8, 0, 22) started
23:05:15 DISPATCHER: Trying to submit another job.
23:05:15 job_callback for (8, 0, 22) got condition
23:05:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:05:15 HBMASTER: Trying to run another job!
23:05:15 job_callback for (8, 0, 22) finished
23:05:15 start sampling a new configuration.
23:05:15 best_vector: [2, 1, 0.11998390441323484, 0.8451071380930965, 0.39465326119191746, 1, 0.6770038920197321, 0.4459166013193356, 0, 2, 0, 1, 0.8130080949589943, 0.78919467568968, 0.347738195911691, 0.30833764382966516], 2.214507286737483e-30, 0.004515677171120297, -1.618860017172172e-06
23:05:15 done sampling a new configuration.
23:05:15 HBMASTER: schedule new run for iteration 8
23:05:15 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
23:05:15 HBMASTER: submitting job (8, 0, 23) to dispatcher
23:05:15 DISPATCHER: trying to submit job (8, 0, 23)
23:05:15 DISPATCHER: trying to notify the job_runner thread.
23:05:15 HBMASTER: job (8, 0, 23) submitted to dispatcher
23:05:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:05:15 DISPATCHER: Trying to submit another job.
23:05:15 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:05:15 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:05:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:05:15 WORKER: start processing job (8, 0, 23)
23:05:15 WORKER: args: ()
23:05:15 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0017376720226578064, 'num_filters_1': 93, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.038032149704212904, 'kernel_size_2': 3, 'num_filters_2': 87}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:05:22 DISPATCHER: Starting worker discovery
23:05:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:05:22 DISPATCHER: Finished worker discovery
23:06:22 DISPATCHER: Starting worker discovery
23:06:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:06:22 DISPATCHER: Finished worker discovery
23:06:57 WORKER: done with job (8, 0, 23), trying to register it.
23:06:57 WORKER: registered result for job (8, 0, 23) with dispatcher
23:06:57 DISPATCHER: job (8, 0, 23) finished
23:06:57 DISPATCHER: register_result: lock acquired
23:06:57 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:06:57 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0017376720226578064, 'num_filters_1': 93, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.038032149704212904, 'kernel_size_2': 3, 'num_filters_2': 87}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4995051614435277, 'info': {'music_genre': 0.4995051614435277, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0017376720226578064, 'num_filters_1': 93, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.038032149704212904, 'kernel_size_2': 3, 'num_filters_2': 87}"}}
exception: None

23:06:57 job_callback for (8, 0, 23) started
23:06:57 DISPATCHER: Trying to submit another job.
23:06:57 job_callback for (8, 0, 23) got condition
23:06:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:06:57 HBMASTER: Trying to run another job!
23:06:57 job_callback for (8, 0, 23) finished
23:06:57 start sampling a new configuration.
23:06:57 best_vector: [0, 0, 0.4091030077155712, 0.40542220315467126, 0.6464171150666188, 1, 0.4460836664721065, 0.29182396662857635, 1, 1, 2, 1, 0.31605154056606627, 0.9302031269859595, 0.6206869154784896, 0.3949395409066317], 2.7221733733154608e-30, 0.0036735353074960606, -3.965119440281215e-05
23:06:57 done sampling a new configuration.
23:06:57 HBMASTER: schedule new run for iteration 8
23:06:57 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
23:06:57 HBMASTER: submitting job (8, 0, 24) to dispatcher
23:06:57 DISPATCHER: trying to submit job (8, 0, 24)
23:06:57 DISPATCHER: trying to notify the job_runner thread.
23:06:57 HBMASTER: job (8, 0, 24) submitted to dispatcher
23:06:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:06:57 DISPATCHER: Trying to submit another job.
23:06:57 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:06:57 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:06:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:06:57 WORKER: start processing job (8, 0, 24)
23:06:57 WORKER: args: ()
23:06:57 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.006579698832347628, 'num_filters_1': 37, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.02397020421504724, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 30, 'num_filters_3': 111, 'num_filters_4': 58}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:07:22 DISPATCHER: Starting worker discovery
23:07:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:07:22 DISPATCHER: Finished worker discovery
23:08:22 DISPATCHER: Starting worker discovery
23:08:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:08:22 DISPATCHER: Finished worker discovery
23:08:39 WORKER: done with job (8, 0, 24), trying to register it.
23:08:39 WORKER: registered result for job (8, 0, 24) with dispatcher
23:08:39 DISPATCHER: job (8, 0, 24) finished
23:08:39 DISPATCHER: register_result: lock acquired
23:08:39 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:08:39 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.006579698832347628, 'num_filters_1': 37, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.02397020421504724, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 30, 'num_filters_3': 111, 'num_filters_4': 58}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5303083635970852, 'info': {'music_genre': 0.5303083635970852, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.006579698832347628, 'num_filters_1': 37, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.02397020421504724, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 30, 'num_filters_3': 111, 'num_filters_4': 58}"}}
exception: None

23:08:39 job_callback for (8, 0, 24) started
23:08:39 DISPATCHER: Trying to submit another job.
23:08:39 job_callback for (8, 0, 24) got condition
23:08:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:08:39 HBMASTER: Trying to run another job!
23:08:39 job_callback for (8, 0, 24) finished
23:08:39 start sampling a new configuration.
23:08:39 best_vector: [2, 1, 0.274761074728661, 0.1487528707176563, 0.9474155585705524, 0, 0.17690861318920667, 0.37726291898374614, 2, 0, 2, 1, 0.6925729499085936, 0.7190094035561215, 0.2766446155401037, 0.775821983637706], 2.49699699393791e-29, 0.00040048105881895427, -5.548901410901136e-07
23:08:39 done sampling a new configuration.
23:08:39 HBMASTER: schedule new run for iteration 8
23:08:39 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
23:08:39 HBMASTER: submitting job (8, 0, 25) to dispatcher
23:08:39 DISPATCHER: trying to submit job (8, 0, 25)
23:08:39 DISPATCHER: trying to notify the job_runner thread.
23:08:39 HBMASTER: job (8, 0, 25) submitted to dispatcher
23:08:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:08:39 DISPATCHER: Trying to submit another job.
23:08:39 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:08:39 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:08:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:08:39 WORKER: start processing job (8, 0, 25)
23:08:39 WORKER: args: ()
23:08:39 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0035442320576160413, 'num_filters_1': 21, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.030962097496103184, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 67, 'num_filters_3': 71, 'num_filters_4': 28, 'num_filters_5': 80}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:09:22 DISPATCHER: Starting worker discovery
23:09:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:09:22 DISPATCHER: Finished worker discovery
23:10:21 WORKER: done with job (8, 0, 25), trying to register it.
23:10:21 WORKER: registered result for job (8, 0, 25) with dispatcher
23:10:21 DISPATCHER: job (8, 0, 25) finished
23:10:21 DISPATCHER: register_result: lock acquired
23:10:21 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:10:21 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0035442320576160413, 'num_filters_1': 21, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.030962097496103184, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 67, 'num_filters_3': 71, 'num_filters_4': 28, 'num_filters_5': 80}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.12766172738928294, 'info': {'music_genre': 0.12766172738928294, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0035442320576160413, 'num_filters_1': 21, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.030962097496103184, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 67, 'num_filters_3': 71, 'num_filters_4': 28, 'num_filters_5': 80}"}}
exception: None

23:10:21 job_callback for (8, 0, 25) started
23:10:21 job_callback for (8, 0, 25) got condition
23:10:21 DISPATCHER: Trying to submit another job.
23:10:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:10:21 HBMASTER: Trying to run another job!
23:10:21 job_callback for (8, 0, 25) finished
23:10:21 start sampling a new configuration.
23:10:21 done sampling a new configuration.
23:10:21 HBMASTER: schedule new run for iteration 8
23:10:21 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
23:10:21 HBMASTER: submitting job (8, 0, 26) to dispatcher
23:10:21 DISPATCHER: trying to submit job (8, 0, 26)
23:10:21 DISPATCHER: trying to notify the job_runner thread.
23:10:21 HBMASTER: job (8, 0, 26) submitted to dispatcher
23:10:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:10:21 DISPATCHER: Trying to submit another job.
23:10:21 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:10:21 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:10:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:10:21 WORKER: start processing job (8, 0, 26)
23:10:21 WORKER: args: ()
23:10:21 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.01811825384728161, 'num_filters_1': 21, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.11791855886672295, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 42, 'num_filters_3': 115}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:10:22 DISPATCHER: Starting worker discovery
23:10:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:10:22 DISPATCHER: Finished worker discovery
23:11:22 DISPATCHER: Starting worker discovery
23:11:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:11:22 DISPATCHER: Finished worker discovery
23:12:03 WORKER: done with job (8, 0, 26), trying to register it.
23:12:03 WORKER: registered result for job (8, 0, 26) with dispatcher
23:12:03 DISPATCHER: job (8, 0, 26) finished
23:12:03 DISPATCHER: register_result: lock acquired
23:12:03 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:12:03 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.01811825384728161, 'num_filters_1': 21, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.11791855886672295, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 42, 'num_filters_3': 115}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.13560213950207348, 'info': {'music_genre': 0.13560213950207348, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.01811825384728161, 'num_filters_1': 21, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.11791855886672295, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 42, 'num_filters_3': 115}"}}
exception: None

23:12:03 job_callback for (8, 0, 26) started
23:12:03 DISPATCHER: Trying to submit another job.
23:12:03 job_callback for (8, 0, 26) got condition
23:12:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:12:03 HBMASTER: Trying to run another job!
23:12:03 job_callback for (8, 0, 26) finished
23:12:03 ITERATION: Advancing config (8, 0, 0) to next budget 133.333333
23:12:03 ITERATION: Advancing config (8, 0, 4) to next budget 133.333333
23:12:03 ITERATION: Advancing config (8, 0, 8) to next budget 133.333333
23:12:03 ITERATION: Advancing config (8, 0, 10) to next budget 133.333333
23:12:03 ITERATION: Advancing config (8, 0, 11) to next budget 133.333333
23:12:03 ITERATION: Advancing config (8, 0, 12) to next budget 133.333333
23:12:03 ITERATION: Advancing config (8, 0, 17) to next budget 133.333333
23:12:03 ITERATION: Advancing config (8, 0, 23) to next budget 133.333333
23:12:03 ITERATION: Advancing config (8, 0, 24) to next budget 133.333333
23:12:03 HBMASTER: schedule new run for iteration 8
23:12:03 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
23:12:03 HBMASTER: submitting job (8, 0, 0) to dispatcher
23:12:03 DISPATCHER: trying to submit job (8, 0, 0)
23:12:03 DISPATCHER: trying to notify the job_runner thread.
23:12:03 HBMASTER: job (8, 0, 0) submitted to dispatcher
23:12:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:12:03 DISPATCHER: Trying to submit another job.
23:12:03 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:12:03 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:12:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:12:03 WORKER: start processing job (8, 0, 0)
23:12:03 WORKER: args: ()
23:12:03 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.04352642100727418, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.012696077336577466, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 37, 'num_filters_3': 27, 'num_filters_4': 19, 'num_filters_5': 35}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:12:22 DISPATCHER: Starting worker discovery
23:12:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:12:22 DISPATCHER: Finished worker discovery
23:13:22 DISPATCHER: Starting worker discovery
23:13:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:13:22 DISPATCHER: Finished worker discovery
23:14:22 DISPATCHER: Starting worker discovery
23:14:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:14:22 DISPATCHER: Finished worker discovery
23:15:14 WORKER: done with job (8, 0, 0), trying to register it.
23:15:14 WORKER: registered result for job (8, 0, 0) with dispatcher
23:15:14 DISPATCHER: job (8, 0, 0) finished
23:15:14 DISPATCHER: register_result: lock acquired
23:15:14 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:15:14 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.04352642100727418, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.012696077336577466, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 37, 'num_filters_3': 27, 'num_filters_4': 19, 'num_filters_5': 35}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.438213346355927, 'info': {'music_genre': 0.438213346355927, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.04352642100727418, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.012696077336577466, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 37, 'num_filters_3': 27, 'num_filters_4': 19, 'num_filters_5': 35}"}}
exception: None

23:15:14 job_callback for (8, 0, 0) started
23:15:14 DISPATCHER: Trying to submit another job.
23:15:14 job_callback for (8, 0, 0) got condition
23:15:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:15:15 done building a new model for budget 133.333333 based on 17/31 split
Best loss for this budget:-0.543042





23:15:15 HBMASTER: Trying to run another job!
23:15:15 job_callback for (8, 0, 0) finished
23:15:15 HBMASTER: schedule new run for iteration 8
23:15:15 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
23:15:15 HBMASTER: submitting job (8, 0, 4) to dispatcher
23:15:15 DISPATCHER: trying to submit job (8, 0, 4)
23:15:15 DISPATCHER: trying to notify the job_runner thread.
23:15:15 HBMASTER: job (8, 0, 4) submitted to dispatcher
23:15:15 DISPATCHER: Trying to submit another job.
23:15:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:15:15 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:15:15 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:15:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:15:15 WORKER: start processing job (8, 0, 4)
23:15:15 WORKER: args: ()
23:15:15 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.027847884986289394, 'num_filters_1': 29, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.01992944512543211, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 54, 'num_filters_3': 46, 'num_filters_4': 34, 'num_filters_5': 26}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:15:22 DISPATCHER: Starting worker discovery
23:15:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:15:22 DISPATCHER: Finished worker discovery
23:16:22 DISPATCHER: Starting worker discovery
23:16:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:16:22 DISPATCHER: Finished worker discovery
23:17:22 DISPATCHER: Starting worker discovery
23:17:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:17:22 DISPATCHER: Finished worker discovery
23:18:22 DISPATCHER: Starting worker discovery
23:18:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:18:22 DISPATCHER: Finished worker discovery
23:18:25 WORKER: done with job (8, 0, 4), trying to register it.
23:18:25 WORKER: registered result for job (8, 0, 4) with dispatcher
23:18:25 DISPATCHER: job (8, 0, 4) finished
23:18:25 DISPATCHER: register_result: lock acquired
23:18:25 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:18:25 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.027847884986289394, 'num_filters_1': 29, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.01992944512543211, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 54, 'num_filters_3': 46, 'num_filters_4': 34, 'num_filters_5': 26}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4931289353308534, 'info': {'music_genre': 0.4931289353308534, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.027847884986289394, 'num_filters_1': 29, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.01992944512543211, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 54, 'num_filters_3': 46, 'num_filters_4': 34, 'num_filters_5': 26}"}}
exception: None

23:18:25 job_callback for (8, 0, 4) started
23:18:25 DISPATCHER: Trying to submit another job.
23:18:25 job_callback for (8, 0, 4) got condition
23:18:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:18:25 done building a new model for budget 133.333333 based on 17/32 split
Best loss for this budget:-0.543042





23:18:25 HBMASTER: Trying to run another job!
23:18:25 job_callback for (8, 0, 4) finished
23:18:25 HBMASTER: schedule new run for iteration 8
23:18:25 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
23:18:25 HBMASTER: submitting job (8, 0, 8) to dispatcher
23:18:25 DISPATCHER: trying to submit job (8, 0, 8)
23:18:25 DISPATCHER: trying to notify the job_runner thread.
23:18:25 HBMASTER: job (8, 0, 8) submitted to dispatcher
23:18:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:18:25 DISPATCHER: Trying to submit another job.
23:18:25 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:18:25 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:18:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:18:25 WORKER: start processing job (8, 0, 8)
23:18:25 WORKER: args: ()
23:18:25 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.002273911077574492, 'num_filters_1': 26, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.04466374842017211, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 61, 'num_filters_3': 19}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:19:22 DISPATCHER: Starting worker discovery
23:19:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:19:22 DISPATCHER: Finished worker discovery
23:20:22 DISPATCHER: Starting worker discovery
23:20:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:20:22 DISPATCHER: Finished worker discovery
23:21:22 DISPATCHER: Starting worker discovery
23:21:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:21:22 DISPATCHER: Finished worker discovery
23:21:36 WORKER: done with job (8, 0, 8), trying to register it.
23:21:36 WORKER: registered result for job (8, 0, 8) with dispatcher
23:21:36 DISPATCHER: job (8, 0, 8) finished
23:21:36 DISPATCHER: register_result: lock acquired
23:21:36 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:21:36 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.002273911077574492, 'num_filters_1': 26, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.04466374842017211, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 61, 'num_filters_3': 19}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.43081963735421525, 'info': {'music_genre': 0.43081963735421525, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.002273911077574492, 'num_filters_1': 26, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.04466374842017211, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 61, 'num_filters_3': 19}"}}
exception: None

23:21:36 job_callback for (8, 0, 8) started
23:21:36 job_callback for (8, 0, 8) got condition
23:21:36 DISPATCHER: Trying to submit another job.
23:21:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:21:36 done building a new model for budget 133.333333 based on 17/33 split
Best loss for this budget:-0.543042





23:21:36 HBMASTER: Trying to run another job!
23:21:36 job_callback for (8, 0, 8) finished
23:21:36 HBMASTER: schedule new run for iteration 8
23:21:36 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
23:21:36 HBMASTER: submitting job (8, 0, 10) to dispatcher
23:21:36 DISPATCHER: trying to submit job (8, 0, 10)
23:21:36 DISPATCHER: trying to notify the job_runner thread.
23:21:36 HBMASTER: job (8, 0, 10) submitted to dispatcher
23:21:36 DISPATCHER: Trying to submit another job.
23:21:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:21:36 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:21:36 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:21:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:21:36 WORKER: start processing job (8, 0, 10)
23:21:36 WORKER: args: ()
23:21:36 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002911039456349506, 'num_filters_1': 55, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.017548637574962632}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:22:22 DISPATCHER: Starting worker discovery
23:22:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:22:22 DISPATCHER: Finished worker discovery
23:23:22 DISPATCHER: Starting worker discovery
23:23:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:23:22 DISPATCHER: Finished worker discovery
23:24:22 DISPATCHER: Starting worker discovery
23:24:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:24:22 DISPATCHER: Finished worker discovery
23:24:47 WORKER: done with job (8, 0, 10), trying to register it.
23:24:47 WORKER: registered result for job (8, 0, 10) with dispatcher
23:24:47 DISPATCHER: job (8, 0, 10) finished
23:24:47 DISPATCHER: register_result: lock acquired
23:24:47 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:24:47 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002911039456349506, 'num_filters_1': 55, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.017548637574962632}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4498534364479246, 'info': {'music_genre': 0.4498534364479246, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002911039456349506, 'num_filters_1': 55, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.017548637574962632}"}}
exception: None

23:24:47 job_callback for (8, 0, 10) started
23:24:47 job_callback for (8, 0, 10) got condition
23:24:47 DISPATCHER: Trying to submit another job.
23:24:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:24:47 done building a new model for budget 133.333333 based on 17/34 split
Best loss for this budget:-0.543042





23:24:47 HBMASTER: Trying to run another job!
23:24:47 job_callback for (8, 0, 10) finished
23:24:47 HBMASTER: schedule new run for iteration 8
23:24:47 HBMASTER: trying submitting job (8, 0, 11) to dispatcher
23:24:47 HBMASTER: submitting job (8, 0, 11) to dispatcher
23:24:47 DISPATCHER: trying to submit job (8, 0, 11)
23:24:47 DISPATCHER: trying to notify the job_runner thread.
23:24:47 HBMASTER: job (8, 0, 11) submitted to dispatcher
23:24:47 DISPATCHER: Trying to submit another job.
23:24:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:24:47 DISPATCHER: starting job (8, 0, 11) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:24:47 DISPATCHER: job (8, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:24:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:24:47 WORKER: start processing job (8, 0, 11)
23:24:47 WORKER: args: ()
23:24:47 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003968778443318448, 'num_filters_1': 30, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.011171958813931317, 'kernel_size_2': 3, 'num_filters_2': 62}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:25:22 DISPATCHER: Starting worker discovery
23:25:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:25:22 DISPATCHER: Finished worker discovery
23:26:22 DISPATCHER: Starting worker discovery
23:26:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:26:22 DISPATCHER: Finished worker discovery
23:27:22 DISPATCHER: Starting worker discovery
23:27:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:27:22 DISPATCHER: Finished worker discovery
23:27:59 WORKER: done with job (8, 0, 11), trying to register it.
23:27:59 WORKER: registered result for job (8, 0, 11) with dispatcher
23:27:59 DISPATCHER: job (8, 0, 11) finished
23:27:59 DISPATCHER: register_result: lock acquired
23:27:59 DISPATCHER: job (8, 0, 11) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:27:59 job_id: (8, 0, 11)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003968778443318448, 'num_filters_1': 30, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.011171958813931317, 'kernel_size_2': 3, 'num_filters_2': 62}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.438238703475043, 'info': {'music_genre': 0.438238703475043, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003968778443318448, 'num_filters_1': 30, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.011171958813931317, 'kernel_size_2': 3, 'num_filters_2': 62}"}}
exception: None

23:27:59 job_callback for (8, 0, 11) started
23:27:59 DISPATCHER: Trying to submit another job.
23:27:59 job_callback for (8, 0, 11) got condition
23:27:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:27:59 done building a new model for budget 133.333333 based on 17/34 split
Best loss for this budget:-0.543042





23:27:59 HBMASTER: Trying to run another job!
23:27:59 job_callback for (8, 0, 11) finished
23:27:59 HBMASTER: schedule new run for iteration 8
23:27:59 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
23:27:59 HBMASTER: submitting job (8, 0, 12) to dispatcher
23:27:59 DISPATCHER: trying to submit job (8, 0, 12)
23:27:59 DISPATCHER: trying to notify the job_runner thread.
23:27:59 HBMASTER: job (8, 0, 12) submitted to dispatcher
23:27:59 DISPATCHER: Trying to submit another job.
23:27:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:27:59 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:27:59 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:27:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:27:59 WORKER: start processing job (8, 0, 12)
23:27:59 WORKER: args: ()
23:27:59 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.009284800229184107, 'num_filters_1': 22, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.038118548482872154, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 21, 'num_filters_3': 87}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:28:22 DISPATCHER: Starting worker discovery
23:28:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:28:22 DISPATCHER: Finished worker discovery
23:29:22 DISPATCHER: Starting worker discovery
23:29:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:29:22 DISPATCHER: Finished worker discovery
23:30:22 DISPATCHER: Starting worker discovery
23:30:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:30:22 DISPATCHER: Finished worker discovery
23:31:10 WORKER: done with job (8, 0, 12), trying to register it.
23:31:10 WORKER: registered result for job (8, 0, 12) with dispatcher
23:31:10 DISPATCHER: job (8, 0, 12) finished
23:31:10 DISPATCHER: register_result: lock acquired
23:31:10 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:31:10 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.009284800229184107, 'num_filters_1': 22, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.038118548482872154, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 21, 'num_filters_3': 87}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.24875234750558375, 'info': {'music_genre': 0.24875234750558375, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.009284800229184107, 'num_filters_1': 22, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.038118548482872154, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 21, 'num_filters_3': 87}"}}
exception: None

23:31:10 job_callback for (8, 0, 12) started
23:31:10 DISPATCHER: Trying to submit another job.
23:31:10 job_callback for (8, 0, 12) got condition
23:31:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:31:10 done building a new model for budget 133.333333 based on 17/35 split
Best loss for this budget:-0.543042





23:31:10 HBMASTER: Trying to run another job!
23:31:10 job_callback for (8, 0, 12) finished
23:31:10 HBMASTER: schedule new run for iteration 8
23:31:10 HBMASTER: trying submitting job (8, 0, 17) to dispatcher
23:31:10 HBMASTER: submitting job (8, 0, 17) to dispatcher
23:31:10 DISPATCHER: trying to submit job (8, 0, 17)
23:31:10 DISPATCHER: trying to notify the job_runner thread.
23:31:10 HBMASTER: job (8, 0, 17) submitted to dispatcher
23:31:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:31:10 DISPATCHER: Trying to submit another job.
23:31:10 DISPATCHER: starting job (8, 0, 17) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:31:10 DISPATCHER: job (8, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:31:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:31:10 WORKER: start processing job (8, 0, 17)
23:31:10 WORKER: args: ()
23:31:10 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.016412526058269462, 'num_filters_1': 17, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.015973841100204066, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 17, 'num_filters_3': 58, 'num_filters_4': 17}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:31:22 DISPATCHER: Starting worker discovery
23:31:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:31:22 DISPATCHER: Finished worker discovery
23:32:22 DISPATCHER: Starting worker discovery
23:32:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:32:22 DISPATCHER: Finished worker discovery
23:33:22 DISPATCHER: Starting worker discovery
23:33:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:33:22 DISPATCHER: Finished worker discovery
23:34:20 WORKER: done with job (8, 0, 17), trying to register it.
23:34:20 WORKER: registered result for job (8, 0, 17) with dispatcher
23:34:20 DISPATCHER: job (8, 0, 17) finished
23:34:20 DISPATCHER: register_result: lock acquired
23:34:20 DISPATCHER: job (8, 0, 17) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:34:20 job_id: (8, 0, 17)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.016412526058269462, 'num_filters_1': 17, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.015973841100204066, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 17, 'num_filters_3': 58, 'num_filters_4': 17}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4024216105866314, 'info': {'music_genre': 0.4024216105866314, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.016412526058269462, 'num_filters_1': 17, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.015973841100204066, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 17, 'num_filters_3': 58, 'num_filters_4': 17}"}}
exception: None

23:34:20 job_callback for (8, 0, 17) started
23:34:20 job_callback for (8, 0, 17) got condition
23:34:20 DISPATCHER: Trying to submit another job.
23:34:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:34:20 done building a new model for budget 133.333333 based on 17/36 split
Best loss for this budget:-0.543042





23:34:20 HBMASTER: Trying to run another job!
23:34:20 job_callback for (8, 0, 17) finished
23:34:20 HBMASTER: schedule new run for iteration 8
23:34:20 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
23:34:20 HBMASTER: submitting job (8, 0, 23) to dispatcher
23:34:20 DISPATCHER: trying to submit job (8, 0, 23)
23:34:20 DISPATCHER: trying to notify the job_runner thread.
23:34:20 HBMASTER: job (8, 0, 23) submitted to dispatcher
23:34:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:34:20 DISPATCHER: Trying to submit another job.
23:34:20 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:34:20 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:34:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:34:20 WORKER: start processing job (8, 0, 23)
23:34:20 WORKER: args: ()
23:34:20 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0017376720226578064, 'num_filters_1': 93, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.038032149704212904, 'kernel_size_2': 3, 'num_filters_2': 87}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:34:22 DISPATCHER: Starting worker discovery
23:34:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:34:22 DISPATCHER: Finished worker discovery
23:35:22 DISPATCHER: Starting worker discovery
23:35:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:35:22 DISPATCHER: Finished worker discovery
23:36:22 DISPATCHER: Starting worker discovery
23:36:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:36:22 DISPATCHER: Finished worker discovery
23:37:22 DISPATCHER: Starting worker discovery
23:37:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:37:22 DISPATCHER: Finished worker discovery
23:37:30 WORKER: done with job (8, 0, 23), trying to register it.
23:37:30 WORKER: registered result for job (8, 0, 23) with dispatcher
23:37:30 DISPATCHER: job (8, 0, 23) finished
23:37:30 DISPATCHER: register_result: lock acquired
23:37:30 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:37:30 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0017376720226578064, 'num_filters_1': 93, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.038032149704212904, 'kernel_size_2': 3, 'num_filters_2': 87}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4890856529064374, 'info': {'music_genre': 0.4890856529064374, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0017376720226578064, 'num_filters_1': 93, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.038032149704212904, 'kernel_size_2': 3, 'num_filters_2': 87}"}}
exception: None

23:37:30 job_callback for (8, 0, 23) started
23:37:30 DISPATCHER: Trying to submit another job.
23:37:30 job_callback for (8, 0, 23) got condition
23:37:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:37:30 done building a new model for budget 133.333333 based on 17/37 split
Best loss for this budget:-0.543042





23:37:30 HBMASTER: Trying to run another job!
23:37:30 job_callback for (8, 0, 23) finished
23:37:30 HBMASTER: schedule new run for iteration 8
23:37:30 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
23:37:30 HBMASTER: submitting job (8, 0, 24) to dispatcher
23:37:30 DISPATCHER: trying to submit job (8, 0, 24)
23:37:30 DISPATCHER: trying to notify the job_runner thread.
23:37:30 HBMASTER: job (8, 0, 24) submitted to dispatcher
23:37:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:37:30 DISPATCHER: Trying to submit another job.
23:37:30 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:37:30 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:37:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:37:30 WORKER: start processing job (8, 0, 24)
23:37:30 WORKER: args: ()
23:37:30 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.006579698832347628, 'num_filters_1': 37, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.02397020421504724, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 30, 'num_filters_3': 111, 'num_filters_4': 58}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:38:22 DISPATCHER: Starting worker discovery
23:38:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:38:22 DISPATCHER: Finished worker discovery
23:39:22 DISPATCHER: Starting worker discovery
23:39:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:39:22 DISPATCHER: Finished worker discovery
23:40:22 DISPATCHER: Starting worker discovery
23:40:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:40:22 DISPATCHER: Finished worker discovery
23:40:40 WORKER: done with job (8, 0, 24), trying to register it.
23:40:40 WORKER: registered result for job (8, 0, 24) with dispatcher
23:40:40 DISPATCHER: job (8, 0, 24) finished
23:40:40 DISPATCHER: register_result: lock acquired
23:40:40 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:40:40 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.006579698832347628, 'num_filters_1': 37, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.02397020421504724, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 30, 'num_filters_3': 111, 'num_filters_4': 58}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.44651398645480445, 'info': {'music_genre': 0.44651398645480445, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.006579698832347628, 'num_filters_1': 37, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.02397020421504724, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 30, 'num_filters_3': 111, 'num_filters_4': 58}"}}
exception: None

23:40:40 job_callback for (8, 0, 24) started
23:40:40 job_callback for (8, 0, 24) got condition
23:40:40 DISPATCHER: Trying to submit another job.
23:40:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:40:40 done building a new model for budget 133.333333 based on 17/38 split
Best loss for this budget:-0.543042





23:40:40 HBMASTER: Trying to run another job!
23:40:40 job_callback for (8, 0, 24) finished
23:40:40 ITERATION: Advancing config (8, 0, 4) to next budget 400.000000
23:40:40 ITERATION: Advancing config (8, 0, 10) to next budget 400.000000
23:40:40 ITERATION: Advancing config (8, 0, 23) to next budget 400.000000
23:40:40 HBMASTER: schedule new run for iteration 8
23:40:40 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
23:40:40 HBMASTER: submitting job (8, 0, 4) to dispatcher
23:40:40 DISPATCHER: trying to submit job (8, 0, 4)
23:40:40 DISPATCHER: trying to notify the job_runner thread.
23:40:40 HBMASTER: job (8, 0, 4) submitted to dispatcher
23:40:40 DISPATCHER: Trying to submit another job.
23:40:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:40:40 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:40:40 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:40:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:40:40 WORKER: start processing job (8, 0, 4)
23:40:40 WORKER: args: ()
23:40:40 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.027847884986289394, 'num_filters_1': 29, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.01992944512543211, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 54, 'num_filters_3': 46, 'num_filters_4': 34, 'num_filters_5': 26}, 'budget': 400.0, 'working_directory': '.'}
23:41:22 DISPATCHER: Starting worker discovery
23:41:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:41:22 DISPATCHER: Finished worker discovery
23:42:22 DISPATCHER: Starting worker discovery
23:42:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:42:22 DISPATCHER: Finished worker discovery
23:43:22 DISPATCHER: Starting worker discovery
23:43:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:43:22 DISPATCHER: Finished worker discovery
23:44:22 DISPATCHER: Starting worker discovery
23:44:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:44:22 DISPATCHER: Finished worker discovery
23:45:22 DISPATCHER: Starting worker discovery
23:45:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:45:22 DISPATCHER: Finished worker discovery
23:46:22 DISPATCHER: Starting worker discovery
23:46:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:46:22 DISPATCHER: Finished worker discovery
23:47:22 DISPATCHER: Starting worker discovery
23:47:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:47:22 DISPATCHER: Finished worker discovery
23:48:20 WORKER: done with job (8, 0, 4), trying to register it.
23:48:20 WORKER: registered result for job (8, 0, 4) with dispatcher
23:48:20 DISPATCHER: job (8, 0, 4) finished
23:48:20 DISPATCHER: register_result: lock acquired
23:48:20 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:48:20 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.027847884986289394, 'num_filters_1': 29, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.01992944512543211, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 54, 'num_filters_3': 46, 'num_filters_4': 34, 'num_filters_5': 26}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.42620214709884074, 'info': {'music_genre': 0.42620214709884074, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.027847884986289394, 'num_filters_1': 29, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.01992944512543211, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 54, 'num_filters_3': 46, 'num_filters_4': 34, 'num_filters_5': 26}"}}
exception: None

23:48:20 job_callback for (8, 0, 4) started
23:48:20 DISPATCHER: Trying to submit another job.
23:48:20 job_callback for (8, 0, 4) got condition
23:48:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:48:20 HBMASTER: Trying to run another job!
23:48:20 job_callback for (8, 0, 4) finished
23:48:20 HBMASTER: schedule new run for iteration 8
23:48:20 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
23:48:20 HBMASTER: submitting job (8, 0, 10) to dispatcher
23:48:20 DISPATCHER: trying to submit job (8, 0, 10)
23:48:20 DISPATCHER: trying to notify the job_runner thread.
23:48:20 HBMASTER: job (8, 0, 10) submitted to dispatcher
23:48:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:48:20 DISPATCHER: Trying to submit another job.
23:48:20 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:48:20 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:48:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:48:20 WORKER: start processing job (8, 0, 10)
23:48:20 WORKER: args: ()
23:48:20 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002911039456349506, 'num_filters_1': 55, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.017548637574962632}, 'budget': 400.0, 'working_directory': '.'}
23:48:22 DISPATCHER: Starting worker discovery
23:48:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:48:22 DISPATCHER: Finished worker discovery
23:49:22 DISPATCHER: Starting worker discovery
23:49:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:49:22 DISPATCHER: Finished worker discovery
23:50:22 DISPATCHER: Starting worker discovery
23:50:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:50:22 DISPATCHER: Finished worker discovery
23:51:22 DISPATCHER: Starting worker discovery
23:51:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:51:22 DISPATCHER: Finished worker discovery
23:52:22 DISPATCHER: Starting worker discovery
23:52:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:52:22 DISPATCHER: Finished worker discovery
23:53:22 DISPATCHER: Starting worker discovery
23:53:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:53:22 DISPATCHER: Finished worker discovery
23:54:22 DISPATCHER: Starting worker discovery
23:54:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:54:22 DISPATCHER: Finished worker discovery
23:55:22 DISPATCHER: Starting worker discovery
23:55:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:55:22 DISPATCHER: Finished worker discovery
23:56:01 WORKER: done with job (8, 0, 10), trying to register it.
23:56:01 WORKER: registered result for job (8, 0, 10) with dispatcher
23:56:01 DISPATCHER: job (8, 0, 10) finished
23:56:01 DISPATCHER: register_result: lock acquired
23:56:01 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:56:01 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002911039456349506, 'num_filters_1': 55, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.017548637574962632}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.33298397756029896, 'info': {'music_genre': 0.33298397756029896, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002911039456349506, 'num_filters_1': 55, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.017548637574962632}"}}
exception: None

23:56:01 job_callback for (8, 0, 10) started
23:56:01 job_callback for (8, 0, 10) got condition
23:56:01 DISPATCHER: Trying to submit another job.
23:56:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:56:01 HBMASTER: Trying to run another job!
23:56:01 job_callback for (8, 0, 10) finished
23:56:01 HBMASTER: schedule new run for iteration 8
23:56:01 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
23:56:01 HBMASTER: submitting job (8, 0, 23) to dispatcher
23:56:01 DISPATCHER: trying to submit job (8, 0, 23)
23:56:01 DISPATCHER: trying to notify the job_runner thread.
23:56:01 HBMASTER: job (8, 0, 23) submitted to dispatcher
23:56:01 DISPATCHER: Trying to submit another job.
23:56:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:56:01 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:56:01 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:56:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:56:01 WORKER: start processing job (8, 0, 23)
23:56:01 WORKER: args: ()
23:56:01 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0017376720226578064, 'num_filters_1': 93, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.038032149704212904, 'kernel_size_2': 3, 'num_filters_2': 87}, 'budget': 400.0, 'working_directory': '.'}
23:56:22 DISPATCHER: Starting worker discovery
23:56:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:56:22 DISPATCHER: Finished worker discovery
23:57:22 DISPATCHER: Starting worker discovery
23:57:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:57:22 DISPATCHER: Finished worker discovery
23:58:22 DISPATCHER: Starting worker discovery
23:58:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:58:22 DISPATCHER: Finished worker discovery
23:59:22 DISPATCHER: Starting worker discovery
23:59:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:59:22 DISPATCHER: Finished worker discovery
00:00:22 DISPATCHER: Starting worker discovery
00:00:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:00:22 DISPATCHER: Finished worker discovery
00:01:22 DISPATCHER: Starting worker discovery
00:01:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:01:22 DISPATCHER: Finished worker discovery
00:02:22 DISPATCHER: Starting worker discovery
00:02:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:02:22 DISPATCHER: Finished worker discovery
00:03:22 DISPATCHER: Starting worker discovery
00:03:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:03:22 DISPATCHER: Finished worker discovery
00:03:40 WORKER: done with job (8, 0, 23), trying to register it.
00:03:40 WORKER: registered result for job (8, 0, 23) with dispatcher
00:03:40 DISPATCHER: job (8, 0, 23) finished
00:03:40 DISPATCHER: register_result: lock acquired
00:03:40 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
00:03:40 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0017376720226578064, 'num_filters_1': 93, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.038032149704212904, 'kernel_size_2': 3, 'num_filters_2': 87}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3816431183839769, 'info': {'music_genre': 0.3816431183839769, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0017376720226578064, 'num_filters_1': 93, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.038032149704212904, 'kernel_size_2': 3, 'num_filters_2': 87}"}}
exception: None

00:03:40 job_callback for (8, 0, 23) started
00:03:40 DISPATCHER: Trying to submit another job.
00:03:40 job_callback for (8, 0, 23) got condition
00:03:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:03:40 HBMASTER: Trying to run another job!
00:03:40 job_callback for (8, 0, 23) finished
00:03:40 ITERATION: Advancing config (8, 0, 4) to next budget 1200.000000
00:03:40 HBMASTER: schedule new run for iteration 8
00:03:40 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
00:03:40 HBMASTER: submitting job (8, 0, 4) to dispatcher
00:03:40 DISPATCHER: trying to submit job (8, 0, 4)
00:03:40 DISPATCHER: trying to notify the job_runner thread.
00:03:40 HBMASTER: job (8, 0, 4) submitted to dispatcher
00:03:40 DISPATCHER: Trying to submit another job.
00:03:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:03:40 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:03:40 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:03:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:03:40 WORKER: start processing job (8, 0, 4)
00:03:40 WORKER: args: ()
00:03:40 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.027847884986289394, 'num_filters_1': 29, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.01992944512543211, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 54, 'num_filters_3': 46, 'num_filters_4': 34, 'num_filters_5': 26}, 'budget': 1200.0, 'working_directory': '.'}
00:04:22 DISPATCHER: Starting worker discovery
00:04:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:04:22 DISPATCHER: Finished worker discovery
00:05:22 DISPATCHER: Starting worker discovery
00:05:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:05:22 DISPATCHER: Finished worker discovery
00:06:22 DISPATCHER: Starting worker discovery
00:06:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:06:22 DISPATCHER: Finished worker discovery
00:07:22 DISPATCHER: Starting worker discovery
00:07:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:07:22 DISPATCHER: Finished worker discovery
00:08:22 DISPATCHER: Starting worker discovery
00:08:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:08:22 DISPATCHER: Finished worker discovery
00:09:22 DISPATCHER: Starting worker discovery
00:09:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:09:22 DISPATCHER: Finished worker discovery
00:10:22 DISPATCHER: Starting worker discovery
00:10:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:10:22 DISPATCHER: Finished worker discovery
00:11:22 DISPATCHER: Starting worker discovery
00:11:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:11:22 DISPATCHER: Finished worker discovery
00:12:22 DISPATCHER: Starting worker discovery
00:12:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:12:22 DISPATCHER: Finished worker discovery
00:13:22 DISPATCHER: Starting worker discovery
00:13:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:13:22 DISPATCHER: Finished worker discovery
00:14:22 DISPATCHER: Starting worker discovery
00:14:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:14:22 DISPATCHER: Finished worker discovery
00:15:22 DISPATCHER: Starting worker discovery
00:15:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:15:22 DISPATCHER: Finished worker discovery
00:16:22 DISPATCHER: Starting worker discovery
00:16:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:16:22 DISPATCHER: Finished worker discovery
00:17:22 DISPATCHER: Starting worker discovery
00:17:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:17:22 DISPATCHER: Finished worker discovery
00:18:22 DISPATCHER: Starting worker discovery
00:18:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:18:22 DISPATCHER: Finished worker discovery
00:19:22 DISPATCHER: Starting worker discovery
00:19:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:19:22 DISPATCHER: Finished worker discovery
00:20:22 DISPATCHER: Starting worker discovery
00:20:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:20:22 DISPATCHER: Finished worker discovery
00:21:22 DISPATCHER: Starting worker discovery
00:21:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:21:22 DISPATCHER: Finished worker discovery
00:22:22 DISPATCHER: Starting worker discovery
00:22:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:22:22 DISPATCHER: Finished worker discovery
00:23:22 DISPATCHER: Starting worker discovery
00:23:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:23:22 DISPATCHER: Finished worker discovery
00:24:22 DISPATCHER: Starting worker discovery
00:24:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:24:22 DISPATCHER: Finished worker discovery
00:24:43 WORKER: done with job (8, 0, 4), trying to register it.
00:24:43 WORKER: registered result for job (8, 0, 4) with dispatcher
00:24:43 DISPATCHER: job (8, 0, 4) finished
00:24:43 DISPATCHER: register_result: lock acquired
00:24:43 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
00:24:43 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.027847884986289394, 'num_filters_1': 29, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.01992944512543211, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 54, 'num_filters_3': 46, 'num_filters_4': 34, 'num_filters_5': 26}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.31494006003835306, 'info': {'music_genre': 0.31494006003835306, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.027847884986289394, 'num_filters_1': 29, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.01992944512543211, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 54, 'num_filters_3': 46, 'num_filters_4': 34, 'num_filters_5': 26}"}}
exception: None

00:24:43 job_callback for (8, 0, 4) started
00:24:43 job_callback for (8, 0, 4) got condition
00:24:43 DISPATCHER: Trying to submit another job.
00:24:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:24:43 HBMASTER: Trying to run another job!
00:24:43 job_callback for (8, 0, 4) finished
00:24:43 start sampling a new configuration.
00:24:43 best_vector: [2, 2, 0.055044060481332924, 0.3209613998969704, 0.8329212152613905, 1, 0.762568506982929, 0.0032023677646604368, 0, 1, 1, 1, 0.24147069465759308, 0.689537273569006, 0.8630069047590923, 0.2390285725338062], 0.0007304482908442502, 0.002306552841826668, 1.684817581054238e-06
00:24:43 done sampling a new configuration.
00:24:43 HBMASTER: schedule new run for iteration 9
00:24:43 HBMASTER: trying submitting job (9, 0, 0) to dispatcher
00:24:43 HBMASTER: submitting job (9, 0, 0) to dispatcher
00:24:43 DISPATCHER: trying to submit job (9, 0, 0)
00:24:43 DISPATCHER: trying to notify the job_runner thread.
00:24:43 HBMASTER: job (9, 0, 0) submitted to dispatcher
00:24:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:24:43 DISPATCHER: Trying to submit another job.
00:24:43 DISPATCHER: starting job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:24:43 DISPATCHER: job (9, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:24:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:24:43 WORKER: start processing job (9, 0, 0)
00:24:43 WORKER: args: ()
00:24:43 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0012885109717969715, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.01009639600983346, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 26, 'num_filters_3': 67, 'num_filters_4': 96, 'num_filters_5': 26}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:25:22 DISPATCHER: Starting worker discovery
00:25:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:25:22 DISPATCHER: Finished worker discovery
00:26:22 DISPATCHER: Starting worker discovery
00:26:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:26:22 DISPATCHER: Finished worker discovery
00:27:22 DISPATCHER: Starting worker discovery
00:27:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:27:22 DISPATCHER: Finished worker discovery
00:27:56 WORKER: done with job (9, 0, 0), trying to register it.
00:27:56 WORKER: registered result for job (9, 0, 0) with dispatcher
00:27:56 DISPATCHER: job (9, 0, 0) finished
00:27:56 DISPATCHER: register_result: lock acquired
00:27:56 DISPATCHER: job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
00:27:56 job_id: (9, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0012885109717969715, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.01009639600983346, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 26, 'num_filters_3': 67, 'num_filters_4': 96, 'num_filters_5': 26}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.519655799222978, 'info': {'music_genre': 0.519655799222978, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0012885109717969715, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.01009639600983346, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 26, 'num_filters_3': 67, 'num_filters_4': 96, 'num_filters_5': 26}"}}
exception: None

00:27:56 job_callback for (9, 0, 0) started
00:27:56 DISPATCHER: Trying to submit another job.
00:27:56 job_callback for (9, 0, 0) got condition
00:27:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:27:56 done building a new model for budget 133.333333 based on 17/39 split
Best loss for this budget:-0.543042





00:27:56 HBMASTER: Trying to run another job!
00:27:56 job_callback for (9, 0, 0) finished
00:27:56 start sampling a new configuration.
00:27:56 best_vector: [0, 0, 0.3541546026844524, 0.9338676156524, 0.07150710217110218, 1, 0.818801070790447, 0.24688280828491732, 2, 1, 2, 1, 0.6896651116148278, 0.4996746987214912, 0.4887546294483148, 0.14613313333585803], 0.0004409748624346706, 0.014949302366048963, 6.592266554362738e-06
00:27:56 done sampling a new configuration.
00:27:56 HBMASTER: schedule new run for iteration 9
00:27:56 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
00:27:56 HBMASTER: submitting job (9, 0, 1) to dispatcher
00:27:56 DISPATCHER: trying to submit job (9, 0, 1)
00:27:56 DISPATCHER: trying to notify the job_runner thread.
00:27:56 HBMASTER: job (9, 0, 1) submitted to dispatcher
00:27:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:27:56 DISPATCHER: Trying to submit another job.
00:27:56 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:27:56 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:27:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:27:56 WORKER: start processing job (9, 0, 1)
00:27:56 WORKER: args: ()
00:27:56 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.005108685944935117, 'num_filters_1': 112, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.020950864062662732}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:28:22 DISPATCHER: Starting worker discovery
00:28:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:28:22 DISPATCHER: Finished worker discovery
00:29:22 DISPATCHER: Starting worker discovery
00:29:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:29:22 DISPATCHER: Finished worker discovery
00:30:22 DISPATCHER: Starting worker discovery
00:30:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:30:22 DISPATCHER: Finished worker discovery
00:31:09 WORKER: done with job (9, 0, 1), trying to register it.
00:31:09 WORKER: registered result for job (9, 0, 1) with dispatcher
00:31:09 DISPATCHER: job (9, 0, 1) finished
00:31:09 DISPATCHER: register_result: lock acquired
00:31:09 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
00:31:09 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.005108685944935117, 'num_filters_1': 112, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.020950864062662732}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3884638964343814, 'info': {'music_genre': 0.3884638964343814, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.005108685944935117, 'num_filters_1': 112, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.020950864062662732}"}}
exception: None

00:31:09 job_callback for (9, 0, 1) started
00:31:09 job_callback for (9, 0, 1) got condition
00:31:09 DISPATCHER: Trying to submit another job.
00:31:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:31:09 done building a new model for budget 133.333333 based on 17/39 split
Best loss for this budget:-0.543042





00:31:09 HBMASTER: Trying to run another job!
00:31:09 job_callback for (9, 0, 1) finished
00:31:09 start sampling a new configuration.
00:31:09 best_vector: [0, 2, 0.27258521004799635, 0.3689171029316166, 0.007291152177481747, 1, 0.026724523655950794, 0.39473757777292706, 2, 0, 0, 1, 0.08406871454519915, 0.5737840586883949, 0.35895288620444316, 0.182414265450289], 0.001167903551218928, 0.004377410514760728, 5.11239328533213e-06
00:31:09 done sampling a new configuration.
00:31:09 HBMASTER: schedule new run for iteration 9
00:31:09 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
00:31:09 HBMASTER: submitting job (9, 0, 2) to dispatcher
00:31:09 DISPATCHER: trying to submit job (9, 0, 2)
00:31:09 DISPATCHER: trying to notify the job_runner thread.
00:31:09 HBMASTER: job (9, 0, 2) submitted to dispatcher
00:31:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:31:09 DISPATCHER: Trying to submit another job.
00:31:09 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:31:09 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:31:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:31:09 WORKER: start processing job (9, 0, 2)
00:31:09 WORKER: args: ()
00:31:09 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.003508895383718609, 'num_filters_1': 34, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.032626119992085}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:31:22 DISPATCHER: Starting worker discovery
00:31:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:31:22 DISPATCHER: Finished worker discovery
00:32:22 DISPATCHER: Starting worker discovery
00:32:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:32:22 DISPATCHER: Finished worker discovery
00:33:22 DISPATCHER: Starting worker discovery
00:33:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:33:22 DISPATCHER: Finished worker discovery
00:34:22 DISPATCHER: Starting worker discovery
00:34:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:34:22 DISPATCHER: Finished worker discovery
00:34:33 WORKER: done with job (9, 0, 2), trying to register it.
00:34:33 WORKER: registered result for job (9, 0, 2) with dispatcher
00:34:33 DISPATCHER: job (9, 0, 2) finished
00:34:33 DISPATCHER: register_result: lock acquired
00:34:33 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
00:34:33 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.003508895383718609, 'num_filters_1': 34, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.032626119992085}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.341571559633353, 'info': {'music_genre': 0.341571559633353, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.003508895383718609, 'num_filters_1': 34, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.032626119992085}"}}
exception: None

00:34:33 job_callback for (9, 0, 2) started
00:34:33 DISPATCHER: Trying to submit another job.
00:34:33 job_callback for (9, 0, 2) got condition
00:34:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:34:33 done building a new model for budget 133.333333 based on 17/40 split
Best loss for this budget:-0.543042





00:34:33 HBMASTER: Trying to run another job!
00:34:33 job_callback for (9, 0, 2) finished
00:34:33 start sampling a new configuration.
00:34:33 best_vector: [2, 0, 0.1784725600242828, 0.08644288285289192, 0.8833848026325635, 1, 0.14605981584669836, 0.35876397443984887, 0, 0, 1, 1, 0.005424279907758817, 0.2966400918270653, 0.31760034176776264, 0.3844585685820904], 0.00107577328627887, 0.0015713820962926866, 1.6904508817285633e-06
00:34:33 done sampling a new configuration.
00:34:33 HBMASTER: schedule new run for iteration 9
00:34:33 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
00:34:33 HBMASTER: submitting job (9, 0, 3) to dispatcher
00:34:33 DISPATCHER: trying to submit job (9, 0, 3)
00:34:33 DISPATCHER: trying to notify the job_runner thread.
00:34:33 HBMASTER: job (9, 0, 3) submitted to dispatcher
00:34:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:34:33 DISPATCHER: Trying to submit another job.
00:34:33 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:34:33 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:34:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:34:33 WORKER: start processing job (9, 0, 3)
00:34:33 WORKER: args: ()
00:34:33 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0022748099545244916, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.029292921793120878, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 16, 'num_filters_3': 29, 'num_filters_4': 30, 'num_filters_5': 35}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:35:22 DISPATCHER: Starting worker discovery
00:35:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:35:22 DISPATCHER: Finished worker discovery
00:36:22 DISPATCHER: Starting worker discovery
00:36:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:36:22 DISPATCHER: Finished worker discovery
00:37:22 DISPATCHER: Starting worker discovery
00:37:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:37:22 DISPATCHER: Finished worker discovery
00:37:45 WORKER: done with job (9, 0, 3), trying to register it.
00:37:45 WORKER: registered result for job (9, 0, 3) with dispatcher
00:37:45 DISPATCHER: job (9, 0, 3) finished
00:37:45 DISPATCHER: register_result: lock acquired
00:37:45 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
00:37:45 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0022748099545244916, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.029292921793120878, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 16, 'num_filters_3': 29, 'num_filters_4': 30, 'num_filters_5': 35}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.363258047269349, 'info': {'music_genre': 0.363258047269349, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0022748099545244916, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.029292921793120878, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 16, 'num_filters_3': 29, 'num_filters_4': 30, 'num_filters_5': 35}"}}
exception: None

00:37:45 job_callback for (9, 0, 3) started
00:37:45 DISPATCHER: Trying to submit another job.
00:37:45 job_callback for (9, 0, 3) got condition
00:37:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:37:45 done building a new model for budget 133.333333 based on 17/41 split
Best loss for this budget:-0.543042





00:37:45 HBMASTER: Trying to run another job!
00:37:45 job_callback for (9, 0, 3) finished
00:37:45 start sampling a new configuration.
00:37:45 best_vector: [3, 0, 0.4575591364859584, 0.9586989905361992, 0.5133709193751876, 1, 0.7798277798804109, 0.25372893543972935, 0, 2, 2, 1, 0.9573427128361828, 0.8388755132470591, 0.6188228662385121, 0.3593044170963738], 0.0014594995920051488, 0.009780653663767914, 1.4274860031812935e-05
00:37:45 done sampling a new configuration.
00:37:45 HBMASTER: schedule new run for iteration 9
00:37:45 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
00:37:45 HBMASTER: submitting job (9, 0, 4) to dispatcher
00:37:45 DISPATCHER: trying to submit job (9, 0, 4)
00:37:45 DISPATCHER: trying to notify the job_runner thread.
00:37:45 HBMASTER: job (9, 0, 4) submitted to dispatcher
00:37:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:37:45 DISPATCHER: Trying to submit another job.
00:37:45 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:37:45 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:37:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:37:45 WORKER: start processing job (9, 0, 4)
00:37:45 WORKER: args: ()
00:37:45 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.008224666047270571, 'num_filters_1': 118, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.021384985285980287, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 117, 'num_filters_3': 91}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:38:22 DISPATCHER: Starting worker discovery
00:38:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:38:22 DISPATCHER: Finished worker discovery
00:39:22 DISPATCHER: Starting worker discovery
00:39:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:39:22 DISPATCHER: Finished worker discovery
00:40:22 DISPATCHER: Starting worker discovery
00:40:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:40:22 DISPATCHER: Finished worker discovery
00:40:57 WORKER: done with job (9, 0, 4), trying to register it.
00:40:57 WORKER: registered result for job (9, 0, 4) with dispatcher
00:40:57 DISPATCHER: job (9, 0, 4) finished
00:40:57 DISPATCHER: register_result: lock acquired
00:40:57 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
00:40:57 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.008224666047270571, 'num_filters_1': 118, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.021384985285980287, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 117, 'num_filters_3': 91}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5009229096586219, 'info': {'music_genre': 0.5009229096586219, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.008224666047270571, 'num_filters_1': 118, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.021384985285980287, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 117, 'num_filters_3': 91}"}}
exception: None

00:40:57 job_callback for (9, 0, 4) started
00:40:57 DISPATCHER: Trying to submit another job.
00:40:57 job_callback for (9, 0, 4) got condition
00:40:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:40:57 done building a new model for budget 133.333333 based on 17/42 split
Best loss for this budget:-0.543042





00:40:57 HBMASTER: Trying to run another job!
00:40:57 job_callback for (9, 0, 4) finished
00:40:57 start sampling a new configuration.
00:40:57 best_vector: [0, 2, 0.06279049535254477, 0.717655244249368, 0.1362378234999198, 1, 0.925341759936666, 0.8084046610411915, 1, 1, 1, 1, 0.6413650862865133, 0.644756856183216, 0.11931923469360528, 0.09852730398275172], 0.0016236344336581058, 0.0005834113625536831, 9.472467772295531e-07
00:40:57 done sampling a new configuration.
00:40:57 HBMASTER: schedule new run for iteration 9
00:40:57 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
00:40:57 HBMASTER: submitting job (9, 0, 5) to dispatcher
00:40:57 DISPATCHER: trying to submit job (9, 0, 5)
00:40:57 DISPATCHER: trying to notify the job_runner thread.
00:40:57 HBMASTER: job (9, 0, 5) submitted to dispatcher
00:40:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:40:57 DISPATCHER: Trying to submit another job.
00:40:57 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:40:57 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:40:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:40:57 WORKER: start processing job (9, 0, 5)
00:40:57 WORKER: args: ()
00:40:57 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0013353065849856707, 'num_filters_1': 71, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.11265713764995006}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:41:22 DISPATCHER: Starting worker discovery
00:41:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:41:22 DISPATCHER: Finished worker discovery
00:42:22 DISPATCHER: Starting worker discovery
00:42:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:42:22 DISPATCHER: Finished worker discovery
00:43:22 DISPATCHER: Starting worker discovery
00:43:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:43:22 DISPATCHER: Finished worker discovery
00:44:08 WORKER: done with job (9, 0, 5), trying to register it.
00:44:08 WORKER: registered result for job (9, 0, 5) with dispatcher
00:44:08 DISPATCHER: job (9, 0, 5) finished
00:44:08 DISPATCHER: register_result: lock acquired
00:44:08 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
00:44:08 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0013353065849856707, 'num_filters_1': 71, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.11265713764995006}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3859226089266012, 'info': {'music_genre': 0.3859226089266012, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0013353065849856707, 'num_filters_1': 71, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.11265713764995006}"}}
exception: None

00:44:08 job_callback for (9, 0, 5) started
00:44:08 job_callback for (9, 0, 5) got condition
00:44:08 DISPATCHER: Trying to submit another job.
00:44:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:44:08 done building a new model for budget 133.333333 based on 17/43 split
Best loss for this budget:-0.543042





00:44:08 HBMASTER: Trying to run another job!
00:44:08 job_callback for (9, 0, 5) finished
00:44:08 start sampling a new configuration.
00:44:09 best_vector: [2, 2, 0.11441941087018495, 0.7778834622633377, 0.7221455801080974, 1, 0.7037589367238697, 0.5570401833658656, 0, 2, 1, 1, 0.6362224987308003, 0.9002137904785903, 0.47404547206291875, 0.3120142196783083], 0.0010789928839857563, 0.012868046615173457, 1.3884530728569156e-05
00:44:09 done sampling a new configuration.
00:44:09 HBMASTER: schedule new run for iteration 9
00:44:09 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
00:44:09 HBMASTER: submitting job (9, 0, 6) to dispatcher
00:44:09 DISPATCHER: trying to submit job (9, 0, 6)
00:44:09 DISPATCHER: trying to notify the job_runner thread.
00:44:09 HBMASTER: job (9, 0, 6) submitted to dispatcher
00:44:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:44:09 DISPATCHER: Trying to submit another job.
00:44:09 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:44:09 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:44:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:44:09 WORKER: start processing job (9, 0, 6)
00:44:09 WORKER: args: ()
00:44:09 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0016937091031924009, 'num_filters_1': 80, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.05305495950016547, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 60, 'num_filters_3': 104, 'num_filters_4': 42}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:44:22 DISPATCHER: Starting worker discovery
00:44:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:44:22 DISPATCHER: Finished worker discovery
00:45:22 DISPATCHER: Starting worker discovery
00:45:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:45:22 DISPATCHER: Finished worker discovery
00:46:22 DISPATCHER: Starting worker discovery
00:46:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:46:22 DISPATCHER: Finished worker discovery
00:47:19 WORKER: done with job (9, 0, 6), trying to register it.
00:47:19 WORKER: registered result for job (9, 0, 6) with dispatcher
00:47:19 DISPATCHER: job (9, 0, 6) finished
00:47:19 DISPATCHER: register_result: lock acquired
00:47:19 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
00:47:19 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0016937091031924009, 'num_filters_1': 80, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.05305495950016547, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 60, 'num_filters_3': 104, 'num_filters_4': 42}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4890515462352987, 'info': {'music_genre': 0.4890515462352987, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0016937091031924009, 'num_filters_1': 80, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.05305495950016547, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 60, 'num_filters_3': 104, 'num_filters_4': 42}"}}
exception: None

00:47:19 job_callback for (9, 0, 6) started
00:47:19 DISPATCHER: Trying to submit another job.
00:47:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:47:19 job_callback for (9, 0, 6) got condition
00:47:19 done building a new model for budget 133.333333 based on 17/44 split
Best loss for this budget:-0.543042





00:47:19 HBMASTER: Trying to run another job!
00:47:19 job_callback for (9, 0, 6) finished
00:47:19 start sampling a new configuration.
00:47:19 best_vector: [1, 2, 0.4520707213447875, 0.05562821811965102, 0.6243134944294764, 1, 0.5462391335166635, 0.12856385426545533, 0, 2, 1, 1, 0.8351243070709694, 0.6144839542919844, 0.9060221273096563, 0.1646251272693509], 0.00126902221825552, 0.009696971944881085, 1.2305672847854539e-05
00:47:19 done sampling a new configuration.
00:47:19 HBMASTER: schedule new run for iteration 9
00:47:19 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
00:47:19 HBMASTER: submitting job (9, 0, 7) to dispatcher
00:47:19 DISPATCHER: trying to submit job (9, 0, 7)
00:47:19 DISPATCHER: trying to notify the job_runner thread.
00:47:19 HBMASTER: job (9, 0, 7) submitted to dispatcher
00:47:19 DISPATCHER: Trying to submit another job.
00:47:19 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:47:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:47:19 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:47:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:47:19 WORKER: start processing job (9, 0, 7)
00:47:19 WORKER: args: ()
00:47:19 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.008019391994902054, 'num_filters_1': 17, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.014698243258658733, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 91, 'num_filters_3': 57, 'num_filters_4': 105}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:47:22 DISPATCHER: Starting worker discovery
00:47:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:47:22 DISPATCHER: Finished worker discovery
00:48:22 DISPATCHER: Starting worker discovery
00:48:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:48:22 DISPATCHER: Finished worker discovery
00:49:22 DISPATCHER: Starting worker discovery
00:49:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:49:22 DISPATCHER: Finished worker discovery
00:50:22 DISPATCHER: Starting worker discovery
00:50:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:50:22 DISPATCHER: Finished worker discovery
00:50:30 WORKER: done with job (9, 0, 7), trying to register it.
00:50:30 WORKER: registered result for job (9, 0, 7) with dispatcher
00:50:30 DISPATCHER: job (9, 0, 7) finished
00:50:30 DISPATCHER: register_result: lock acquired
00:50:30 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
00:50:30 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.008019391994902054, 'num_filters_1': 17, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.014698243258658733, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 91, 'num_filters_3': 57, 'num_filters_4': 105}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4706501511366824, 'info': {'music_genre': 0.4706501511366824, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.008019391994902054, 'num_filters_1': 17, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.014698243258658733, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 91, 'num_filters_3': 57, 'num_filters_4': 105}"}}
exception: None

00:50:30 job_callback for (9, 0, 7) started
00:50:30 DISPATCHER: Trying to submit another job.
00:50:30 job_callback for (9, 0, 7) got condition
00:50:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:50:30 done building a new model for budget 133.333333 based on 17/45 split
Best loss for this budget:-0.543042





00:50:30 HBMASTER: Trying to run another job!
00:50:30 job_callback for (9, 0, 7) finished
00:50:30 start sampling a new configuration.
00:50:30 done sampling a new configuration.
00:50:30 HBMASTER: schedule new run for iteration 9
00:50:30 HBMASTER: trying submitting job (9, 0, 8) to dispatcher
00:50:30 HBMASTER: submitting job (9, 0, 8) to dispatcher
00:50:30 DISPATCHER: trying to submit job (9, 0, 8)
00:50:30 DISPATCHER: trying to notify the job_runner thread.
00:50:30 HBMASTER: job (9, 0, 8) submitted to dispatcher
00:50:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:50:30 DISPATCHER: Trying to submit another job.
00:50:30 DISPATCHER: starting job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:50:30 DISPATCHER: job (9, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:50:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:50:30 WORKER: start processing job (9, 0, 8)
00:50:30 WORKER: args: ()
00:50:30 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.022195196245020567, 'num_filters_1': 88, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.015445323730269779, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 38, 'num_filters_3': 75, 'num_filters_4': 36}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:51:22 DISPATCHER: Starting worker discovery
00:51:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:51:22 DISPATCHER: Finished worker discovery
00:52:22 DISPATCHER: Starting worker discovery
00:52:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:52:22 DISPATCHER: Finished worker discovery
00:53:22 DISPATCHER: Starting worker discovery
00:53:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:53:23 DISPATCHER: Finished worker discovery
00:53:42 WORKER: done with job (9, 0, 8), trying to register it.
00:53:42 WORKER: registered result for job (9, 0, 8) with dispatcher
00:53:42 DISPATCHER: job (9, 0, 8) finished
00:53:42 DISPATCHER: register_result: lock acquired
00:53:42 DISPATCHER: job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
00:53:42 job_id: (9, 0, 8)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.022195196245020567, 'num_filters_1': 88, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.015445323730269779, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 38, 'num_filters_3': 75, 'num_filters_4': 36}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.00026030609257101766, 'info': {'music_genre': 0.00026030609257101766, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.022195196245020567, 'num_filters_1': 88, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.015445323730269779, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 38, 'num_filters_3': 75, 'num_filters_4': 36}"}}
exception: None

00:53:42 job_callback for (9, 0, 8) started
00:53:42 DISPATCHER: Trying to submit another job.
00:53:42 job_callback for (9, 0, 8) got condition
00:53:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:53:42 done building a new model for budget 133.333333 based on 17/45 split
Best loss for this budget:-0.543042





00:53:42 HBMASTER: Trying to run another job!
00:53:42 job_callback for (9, 0, 8) finished
00:53:42 ITERATION: Advancing config (9, 0, 0) to next budget 400.000000
00:53:42 ITERATION: Advancing config (9, 0, 4) to next budget 400.000000
00:53:42 ITERATION: Advancing config (9, 0, 6) to next budget 400.000000
00:53:42 HBMASTER: schedule new run for iteration 9
00:53:42 HBMASTER: trying submitting job (9, 0, 0) to dispatcher
00:53:42 HBMASTER: submitting job (9, 0, 0) to dispatcher
00:53:42 DISPATCHER: trying to submit job (9, 0, 0)
00:53:42 DISPATCHER: trying to notify the job_runner thread.
00:53:42 HBMASTER: job (9, 0, 0) submitted to dispatcher
00:53:42 DISPATCHER: Trying to submit another job.
00:53:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:53:42 DISPATCHER: starting job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:53:42 DISPATCHER: job (9, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:53:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:53:42 WORKER: start processing job (9, 0, 0)
00:53:42 WORKER: args: ()
00:53:42 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0012885109717969715, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.01009639600983346, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 26, 'num_filters_3': 67, 'num_filters_4': 96, 'num_filters_5': 26}, 'budget': 400.0, 'working_directory': '.'}
00:54:23 DISPATCHER: Starting worker discovery
00:54:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:54:23 DISPATCHER: Finished worker discovery
00:55:23 DISPATCHER: Starting worker discovery
00:55:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:55:23 DISPATCHER: Finished worker discovery
00:56:23 DISPATCHER: Starting worker discovery
00:56:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:56:23 DISPATCHER: Finished worker discovery
00:57:23 DISPATCHER: Starting worker discovery
00:57:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:57:23 DISPATCHER: Finished worker discovery
00:58:23 DISPATCHER: Starting worker discovery
00:58:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:58:23 DISPATCHER: Finished worker discovery
00:59:23 DISPATCHER: Starting worker discovery
00:59:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:59:23 DISPATCHER: Finished worker discovery
01:00:23 DISPATCHER: Starting worker discovery
01:00:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:00:23 DISPATCHER: Finished worker discovery
01:01:22 WORKER: done with job (9, 0, 0), trying to register it.
01:01:22 WORKER: registered result for job (9, 0, 0) with dispatcher
01:01:22 DISPATCHER: job (9, 0, 0) finished
01:01:22 DISPATCHER: register_result: lock acquired
01:01:22 DISPATCHER: job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:01:22 job_id: (9, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0012885109717969715, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.01009639600983346, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 26, 'num_filters_3': 67, 'num_filters_4': 96, 'num_filters_5': 26}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5184559890936971, 'info': {'music_genre': 0.5184559890936971, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0012885109717969715, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.01009639600983346, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 26, 'num_filters_3': 67, 'num_filters_4': 96, 'num_filters_5': 26}"}}
exception: None

01:01:22 job_callback for (9, 0, 0) started
01:01:22 job_callback for (9, 0, 0) got condition
01:01:22 DISPATCHER: Trying to submit another job.
01:01:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:01:22 HBMASTER: Trying to run another job!
01:01:22 job_callback for (9, 0, 0) finished
01:01:22 HBMASTER: schedule new run for iteration 9
01:01:22 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
01:01:22 HBMASTER: submitting job (9, 0, 4) to dispatcher
01:01:22 DISPATCHER: trying to submit job (9, 0, 4)
01:01:22 DISPATCHER: trying to notify the job_runner thread.
01:01:22 HBMASTER: job (9, 0, 4) submitted to dispatcher
01:01:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:01:22 DISPATCHER: Trying to submit another job.
01:01:22 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:01:22 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:01:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:01:22 WORKER: start processing job (9, 0, 4)
01:01:22 WORKER: args: ()
01:01:22 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.008224666047270571, 'num_filters_1': 118, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.021384985285980287, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 117, 'num_filters_3': 91}, 'budget': 400.0, 'working_directory': '.'}
01:01:23 DISPATCHER: Starting worker discovery
01:01:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:01:23 DISPATCHER: Finished worker discovery
01:02:23 DISPATCHER: Starting worker discovery
01:02:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:02:23 DISPATCHER: Finished worker discovery
01:03:23 DISPATCHER: Starting worker discovery
01:03:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:03:23 DISPATCHER: Finished worker discovery
01:04:23 DISPATCHER: Starting worker discovery
01:04:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:04:23 DISPATCHER: Finished worker discovery
01:05:23 DISPATCHER: Starting worker discovery
01:05:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:05:23 DISPATCHER: Finished worker discovery
01:06:23 DISPATCHER: Starting worker discovery
01:06:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:06:23 DISPATCHER: Finished worker discovery
01:07:23 DISPATCHER: Starting worker discovery
01:07:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:07:23 DISPATCHER: Finished worker discovery
01:08:23 DISPATCHER: Starting worker discovery
01:08:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:08:23 DISPATCHER: Finished worker discovery
01:08:58 WORKER: done with job (9, 0, 4), trying to register it.
01:08:58 WORKER: registered result for job (9, 0, 4) with dispatcher
01:08:58 DISPATCHER: job (9, 0, 4) finished
01:08:58 DISPATCHER: register_result: lock acquired
01:08:58 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:08:58 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.008224666047270571, 'num_filters_1': 118, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.021384985285980287, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 117, 'num_filters_3': 91}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.37617450058258406, 'info': {'music_genre': 0.37617450058258406, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.008224666047270571, 'num_filters_1': 118, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.021384985285980287, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 117, 'num_filters_3': 91}"}}
exception: None

01:08:58 job_callback for (9, 0, 4) started
01:08:58 job_callback for (9, 0, 4) got condition
01:08:58 DISPATCHER: Trying to submit another job.
01:08:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:08:58 HBMASTER: Trying to run another job!
01:08:58 job_callback for (9, 0, 4) finished
01:08:58 HBMASTER: schedule new run for iteration 9
01:08:58 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
01:08:58 HBMASTER: submitting job (9, 0, 6) to dispatcher
01:08:58 DISPATCHER: trying to submit job (9, 0, 6)
01:08:58 DISPATCHER: trying to notify the job_runner thread.
01:08:58 HBMASTER: job (9, 0, 6) submitted to dispatcher
01:08:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:08:58 DISPATCHER: Trying to submit another job.
01:08:58 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:08:58 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:08:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:08:58 WORKER: start processing job (9, 0, 6)
01:08:58 WORKER: args: ()
01:08:58 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0016937091031924009, 'num_filters_1': 80, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.05305495950016547, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 60, 'num_filters_3': 104, 'num_filters_4': 42}, 'budget': 400.0, 'working_directory': '.'}
01:09:23 DISPATCHER: Starting worker discovery
01:09:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:09:23 DISPATCHER: Finished worker discovery
01:10:23 DISPATCHER: Starting worker discovery
01:10:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:10:23 DISPATCHER: Finished worker discovery
01:11:23 DISPATCHER: Starting worker discovery
01:11:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:11:23 DISPATCHER: Finished worker discovery
01:12:23 DISPATCHER: Starting worker discovery
01:12:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:12:23 DISPATCHER: Finished worker discovery
01:13:23 DISPATCHER: Starting worker discovery
01:13:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:13:23 DISPATCHER: Finished worker discovery
01:14:23 DISPATCHER: Starting worker discovery
01:14:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:14:23 DISPATCHER: Finished worker discovery
01:15:23 DISPATCHER: Starting worker discovery
01:15:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:15:23 DISPATCHER: Finished worker discovery
01:16:23 DISPATCHER: Starting worker discovery
01:16:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:16:23 DISPATCHER: Finished worker discovery
01:16:36 WORKER: done with job (9, 0, 6), trying to register it.
01:16:36 WORKER: registered result for job (9, 0, 6) with dispatcher
01:16:36 DISPATCHER: job (9, 0, 6) finished
01:16:36 DISPATCHER: register_result: lock acquired
01:16:36 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:16:36 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0016937091031924009, 'num_filters_1': 80, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.05305495950016547, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 60, 'num_filters_3': 104, 'num_filters_4': 42}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.41356115613731276, 'info': {'music_genre': 0.41356115613731276, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0016937091031924009, 'num_filters_1': 80, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.05305495950016547, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 60, 'num_filters_3': 104, 'num_filters_4': 42}"}}
exception: None

01:16:36 job_callback for (9, 0, 6) started
01:16:36 DISPATCHER: Trying to submit another job.
01:16:36 job_callback for (9, 0, 6) got condition
01:16:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:16:36 HBMASTER: Trying to run another job!
01:16:36 job_callback for (9, 0, 6) finished
01:16:36 ITERATION: Advancing config (9, 0, 0) to next budget 1200.000000
01:16:36 HBMASTER: schedule new run for iteration 9
01:16:36 HBMASTER: trying submitting job (9, 0, 0) to dispatcher
01:16:36 HBMASTER: submitting job (9, 0, 0) to dispatcher
01:16:36 DISPATCHER: trying to submit job (9, 0, 0)
01:16:36 DISPATCHER: trying to notify the job_runner thread.
01:16:36 HBMASTER: job (9, 0, 0) submitted to dispatcher
01:16:36 DISPATCHER: Trying to submit another job.
01:16:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:16:36 DISPATCHER: starting job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:16:36 DISPATCHER: job (9, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:16:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:16:36 WORKER: start processing job (9, 0, 0)
01:16:36 WORKER: args: ()
01:16:36 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0012885109717969715, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.01009639600983346, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 26, 'num_filters_3': 67, 'num_filters_4': 96, 'num_filters_5': 26}, 'budget': 1200.0, 'working_directory': '.'}
01:17:23 DISPATCHER: Starting worker discovery
01:17:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:17:23 DISPATCHER: Finished worker discovery
01:18:23 DISPATCHER: Starting worker discovery
01:18:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:18:23 DISPATCHER: Finished worker discovery
01:19:23 DISPATCHER: Starting worker discovery
01:19:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:19:23 DISPATCHER: Finished worker discovery
01:20:23 DISPATCHER: Starting worker discovery
01:20:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:20:23 DISPATCHER: Finished worker discovery
01:21:23 DISPATCHER: Starting worker discovery
01:21:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:21:23 DISPATCHER: Finished worker discovery
01:22:23 DISPATCHER: Starting worker discovery
01:22:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:22:23 DISPATCHER: Finished worker discovery
01:23:23 DISPATCHER: Starting worker discovery
01:23:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:23:23 DISPATCHER: Finished worker discovery
01:24:23 DISPATCHER: Starting worker discovery
01:24:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:24:23 DISPATCHER: Finished worker discovery
01:25:23 DISPATCHER: Starting worker discovery
01:25:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:25:23 DISPATCHER: Finished worker discovery
01:26:23 DISPATCHER: Starting worker discovery
01:26:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:26:23 DISPATCHER: Finished worker discovery
01:27:23 DISPATCHER: Starting worker discovery
01:27:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:27:23 DISPATCHER: Finished worker discovery
01:28:23 DISPATCHER: Starting worker discovery
01:28:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:28:23 DISPATCHER: Finished worker discovery
01:29:23 DISPATCHER: Starting worker discovery
01:29:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:29:23 DISPATCHER: Finished worker discovery
01:30:23 DISPATCHER: Starting worker discovery
01:30:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:30:23 DISPATCHER: Finished worker discovery
01:31:23 DISPATCHER: Starting worker discovery
01:31:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:31:23 DISPATCHER: Finished worker discovery
01:32:23 DISPATCHER: Starting worker discovery
01:32:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:32:23 DISPATCHER: Finished worker discovery
01:33:23 DISPATCHER: Starting worker discovery
01:33:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:33:23 DISPATCHER: Finished worker discovery
01:34:23 DISPATCHER: Starting worker discovery
01:34:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:34:23 DISPATCHER: Finished worker discovery
01:35:23 DISPATCHER: Starting worker discovery
01:35:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:35:23 DISPATCHER: Finished worker discovery
01:36:23 DISPATCHER: Starting worker discovery
01:36:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:36:23 DISPATCHER: Finished worker discovery
01:37:23 DISPATCHER: Starting worker discovery
01:37:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:37:23 DISPATCHER: Finished worker discovery
01:37:39 WORKER: done with job (9, 0, 0), trying to register it.
01:37:39 WORKER: registered result for job (9, 0, 0) with dispatcher
01:37:39 DISPATCHER: job (9, 0, 0) finished
01:37:39 DISPATCHER: register_result: lock acquired
01:37:39 DISPATCHER: job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:37:39 job_id: (9, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0012885109717969715, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.01009639600983346, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 26, 'num_filters_3': 67, 'num_filters_4': 96, 'num_filters_5': 26}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.49222922788083084, 'info': {'music_genre': 0.49222922788083084, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0012885109717969715, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.01009639600983346, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 26, 'num_filters_3': 67, 'num_filters_4': 96, 'num_filters_5': 26}"}}
exception: None

01:37:39 job_callback for (9, 0, 0) started
01:37:39 DISPATCHER: Trying to submit another job.
01:37:39 job_callback for (9, 0, 0) got condition
01:37:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:37:39 HBMASTER: Trying to run another job!
01:37:39 job_callback for (9, 0, 0) finished
01:37:39 HBMASTER: shutdown initiated, shutdown_workers = True
01:37:39 WORKER: shutting down now!
01:37:39 DISPATCHER: Dispatcher shutting down
01:37:39 DISPATCHER: Trying to submit another job.
01:37:39 DISPATCHER: job_runner shutting down
01:37:39 DISPATCHER: discover_workers shutting down
01:37:39 DISPATCHER: 'discover_worker' thread exited
01:37:39 DISPATCHER: 'job_runner' thread exited
01:37:39 DISPATCHER: shut down complete
01:37:39 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7fac6c05b748; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:38908>
01:37:39 WORKER: No dispatcher found. Waiting for one to initiate contact.
01:37:39 WORKER: start listening for jobs
01:37:39 wait_for_workers trying to get the condition
01:37:39 DISPATCHER: started the 'discover_worker' thread
01:37:39 DISPATCHER: started the 'job_runner' thread
01:37:39 DISPATCHER: Pyro daemon running on localhost:34515
01:37:39 DISPATCHER: Starting worker discovery
01:37:39 DISPATCHER: Found 1 potential workers, 0 currently in the pool.
01:37:39 DISPATCHER: discovered new worker, hpbandster.run_0.worker.metagpuj.30597140382006277952
01:37:39 HBMASTER: number of workers changed to 1
01:37:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:37:39 HBMASTER: only 1 worker(s) available, waiting for at least 1.
01:37:39 adjust_queue_size: lock accquired
01:37:39 HBMASTER: adjusted queue size to (0, 1)
01:37:39 DISPATCHER: Finished worker discovery
01:37:39 DISPATCHER: A new worker triggered discover_worker
01:37:39 DISPATCHER: Trying to submit another job.
01:37:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:37:39 Enough workers to start this run!
01:37:39 DISPATCHER: Starting worker discovery
01:37:39 HBMASTER: starting run at 1583887059.5473194
01:37:39 start sampling a new configuration.
01:37:39 done sampling a new configuration.
01:37:39 HBMASTER: schedule new run for iteration 0
01:37:39 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
01:37:39 HBMASTER: submitting job (0, 0, 0) to dispatcher
01:37:39 DISPATCHER: trying to submit job (0, 0, 0)
01:37:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:37:39 DISPATCHER: Finished worker discovery
01:37:39 DISPATCHER: trying to notify the job_runner thread.
01:37:39 HBMASTER: job (0, 0, 0) submitted to dispatcher
01:37:39 DISPATCHER: Trying to submit another job.
01:37:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:37:39 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:37:39 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:37:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:37:39 WORKER: start processing job (0, 0, 0)
01:37:39 WORKER: args: ()
01:37:39 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 83, 'last_n_outputs': 10, 'lr': 0.0020828258441284225, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.03947591926994309}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-406:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:38:39 DISPATCHER: Starting worker discovery
01:38:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:38:39 DISPATCHER: Finished worker discovery
01:39:18 WORKER: done with job (0, 0, 0), trying to register it.
01:39:18 WORKER: registered result for job (0, 0, 0) with dispatcher
01:39:18 DISPATCHER: job (0, 0, 0) finished
01:39:18 DISPATCHER: register_result: lock acquired
01:39:18 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:39:18 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 83, 'last_n_outputs': 10, 'lr': 0.0020828258441284225, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.03947591926994309}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.015557801124582289, 'info': {'music_genre': -0.015557801124582289, 'config': "{'batch_size': 32, 'hidden_dim': 83, 'last_n_outputs': 10, 'lr': 0.0020828258441284225, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.03947591926994309}"}}
exception: None

01:39:18 job_callback for (0, 0, 0) started
01:39:18 DISPATCHER: Trying to submit another job.
01:39:18 job_callback for (0, 0, 0) got condition
01:39:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:39:18 Only 1 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
01:39:18 HBMASTER: Trying to run another job!
01:39:18 job_callback for (0, 0, 0) finished
01:39:18 start sampling a new configuration.
01:39:18 done sampling a new configuration.
01:39:18 HBMASTER: schedule new run for iteration 0
01:39:18 HBMASTER: trying submitting job (0, 0, 1) to dispatcher
01:39:18 HBMASTER: submitting job (0, 0, 1) to dispatcher
01:39:18 DISPATCHER: trying to submit job (0, 0, 1)
01:39:18 DISPATCHER: trying to notify the job_runner thread.
01:39:18 HBMASTER: job (0, 0, 1) submitted to dispatcher
01:39:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:39:18 DISPATCHER: Trying to submit another job.
01:39:18 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:39:18 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:39:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:39:18 WORKER: start processing job (0, 0, 1)
01:39:18 WORKER: args: ()
01:39:18 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 62, 'last_n_outputs': 31, 'lr': 0.021709430277666402, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.045338961514216305}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:39:39 DISPATCHER: Starting worker discovery
01:39:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:39:39 DISPATCHER: Finished worker discovery
Exception in thread Thread-407:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:40:39 DISPATCHER: Starting worker discovery
01:40:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:40:39 DISPATCHER: Finished worker discovery
01:41:01 WORKER: done with job (0, 0, 1), trying to register it.
01:41:01 WORKER: registered result for job (0, 0, 1) with dispatcher
01:41:01 DISPATCHER: job (0, 0, 1) finished
01:41:01 DISPATCHER: register_result: lock acquired
01:41:01 DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:41:01 job_id: (0, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 62, 'last_n_outputs': 31, 'lr': 0.021709430277666402, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.045338961514216305}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 62, 'last_n_outputs': 31, 'lr': 0.021709430277666402, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.045338961514216305}"}}
exception: None

01:41:01 job_callback for (0, 0, 1) started
01:41:01 job_callback for (0, 0, 1) got condition
01:41:01 DISPATCHER: Trying to submit another job.
01:41:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:41:01 Only 2 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
01:41:01 HBMASTER: Trying to run another job!
01:41:01 job_callback for (0, 0, 1) finished
01:41:01 start sampling a new configuration.
01:41:01 done sampling a new configuration.
01:41:01 HBMASTER: schedule new run for iteration 0
01:41:01 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
01:41:01 HBMASTER: submitting job (0, 0, 2) to dispatcher
01:41:01 DISPATCHER: trying to submit job (0, 0, 2)
01:41:01 DISPATCHER: trying to notify the job_runner thread.
01:41:01 HBMASTER: job (0, 0, 2) submitted to dispatcher
01:41:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:41:01 DISPATCHER: Trying to submit another job.
01:41:01 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:41:01 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:41:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:41:01 WORKER: start processing job (0, 0, 2)
01:41:01 WORKER: args: ()
01:41:01 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 35, 'last_n_outputs': 30, 'lr': 0.003353983267619106, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.18883534871434077}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:41:39 DISPATCHER: Starting worker discovery
01:41:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:41:39 DISPATCHER: Finished worker discovery
Exception in thread Thread-408:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:42:39 DISPATCHER: Starting worker discovery
01:42:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:42:39 DISPATCHER: Finished worker discovery
01:42:40 WORKER: done with job (0, 0, 2), trying to register it.
01:42:40 WORKER: registered result for job (0, 0, 2) with dispatcher
01:42:40 DISPATCHER: job (0, 0, 2) finished
01:42:40 DISPATCHER: register_result: lock acquired
01:42:40 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:42:40 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 35, 'last_n_outputs': 30, 'lr': 0.003353983267619106, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.18883534871434077}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2878164250286606, 'info': {'music_genre': 0.2878164250286606, 'config': "{'batch_size': 64, 'hidden_dim': 35, 'last_n_outputs': 30, 'lr': 0.003353983267619106, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.18883534871434077}"}}
exception: None

01:42:40 job_callback for (0, 0, 2) started
01:42:40 job_callback for (0, 0, 2) got condition
01:42:40 DISPATCHER: Trying to submit another job.
01:42:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:42:40 Only 3 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
01:42:40 HBMASTER: Trying to run another job!
01:42:40 job_callback for (0, 0, 2) finished
01:42:40 start sampling a new configuration.
01:42:40 done sampling a new configuration.
01:42:40 HBMASTER: schedule new run for iteration 0
01:42:40 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
01:42:40 HBMASTER: submitting job (0, 0, 3) to dispatcher
01:42:40 DISPATCHER: trying to submit job (0, 0, 3)
01:42:40 DISPATCHER: trying to notify the job_runner thread.
01:42:40 HBMASTER: job (0, 0, 3) submitted to dispatcher
01:42:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:42:40 DISPATCHER: Trying to submit another job.
01:42:40 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:42:40 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:42:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:42:40 WORKER: start processing job (0, 0, 3)
01:42:40 WORKER: args: ()
01:42:40 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 74, 'last_n_outputs': 37, 'lr': 0.0028894851888361705, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.16117063376565682}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-409:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:43:39 DISPATCHER: Starting worker discovery
01:43:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:43:39 DISPATCHER: Finished worker discovery
01:44:19 WORKER: done with job (0, 0, 3), trying to register it.
01:44:19 WORKER: registered result for job (0, 0, 3) with dispatcher
01:44:19 DISPATCHER: job (0, 0, 3) finished
01:44:19 DISPATCHER: register_result: lock acquired
01:44:19 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:44:19 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 74, 'last_n_outputs': 37, 'lr': 0.0028894851888361705, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.16117063376565682}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.02999590384785219, 'info': {'music_genre': 0.02999590384785219, 'config': "{'batch_size': 32, 'hidden_dim': 74, 'last_n_outputs': 37, 'lr': 0.0028894851888361705, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.16117063376565682}"}}
exception: None

01:44:19 job_callback for (0, 0, 3) started
01:44:19 DISPATCHER: Trying to submit another job.
01:44:19 job_callback for (0, 0, 3) got condition
01:44:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:44:19 Only 4 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
01:44:19 HBMASTER: Trying to run another job!
01:44:19 job_callback for (0, 0, 3) finished
01:44:19 start sampling a new configuration.
01:44:19 done sampling a new configuration.
01:44:19 HBMASTER: schedule new run for iteration 0
01:44:19 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
01:44:19 HBMASTER: submitting job (0, 0, 4) to dispatcher
01:44:19 DISPATCHER: trying to submit job (0, 0, 4)
01:44:19 DISPATCHER: trying to notify the job_runner thread.
01:44:19 HBMASTER: job (0, 0, 4) submitted to dispatcher
01:44:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:44:19 DISPATCHER: Trying to submit another job.
01:44:19 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:44:19 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:44:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:44:19 WORKER: start processing job (0, 0, 4)
01:44:19 WORKER: args: ()
01:44:19 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 86, 'last_n_outputs': 36, 'lr': 0.009265333076720958, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.028834696917574707}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:44:39 DISPATCHER: Starting worker discovery
01:44:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:44:39 DISPATCHER: Finished worker discovery
Exception in thread Thread-410:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:45:39 DISPATCHER: Starting worker discovery
01:45:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:45:39 DISPATCHER: Finished worker discovery
01:45:58 WORKER: done with job (0, 0, 4), trying to register it.
01:45:58 WORKER: registered result for job (0, 0, 4) with dispatcher
01:45:58 DISPATCHER: job (0, 0, 4) finished
01:45:58 DISPATCHER: register_result: lock acquired
01:45:58 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:45:58 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 86, 'last_n_outputs': 36, 'lr': 0.009265333076720958, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.028834696917574707}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.004686255131283454, 'info': {'music_genre': 0.004686255131283454, 'config': "{'batch_size': 16, 'hidden_dim': 86, 'last_n_outputs': 36, 'lr': 0.009265333076720958, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.028834696917574707}"}}
exception: None

01:45:58 job_callback for (0, 0, 4) started
01:45:58 DISPATCHER: Trying to submit another job.
01:45:58 job_callback for (0, 0, 4) got condition
01:45:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:45:58 Only 5 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
01:45:58 HBMASTER: Trying to run another job!
01:45:58 job_callback for (0, 0, 4) finished
01:45:58 start sampling a new configuration.
01:45:58 done sampling a new configuration.
01:45:58 HBMASTER: schedule new run for iteration 0
01:45:58 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
01:45:58 HBMASTER: submitting job (0, 0, 5) to dispatcher
01:45:58 DISPATCHER: trying to submit job (0, 0, 5)
01:45:58 DISPATCHER: trying to notify the job_runner thread.
01:45:58 HBMASTER: job (0, 0, 5) submitted to dispatcher
01:45:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:45:58 DISPATCHER: Trying to submit another job.
01:45:58 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:45:58 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:45:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:45:58 WORKER: start processing job (0, 0, 5)
01:45:58 WORKER: args: ()
01:45:58 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 94, 'last_n_outputs': 7, 'lr': 0.0013005439889754128, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.07965969177492642}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:46:39 DISPATCHER: Starting worker discovery
01:46:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:46:39 DISPATCHER: Finished worker discovery
Exception in thread Thread-411:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:47:36 WORKER: done with job (0, 0, 5), trying to register it.
01:47:36 WORKER: registered result for job (0, 0, 5) with dispatcher
01:47:36 DISPATCHER: job (0, 0, 5) finished
01:47:36 DISPATCHER: register_result: lock acquired
01:47:36 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:47:36 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 94, 'last_n_outputs': 7, 'lr': 0.0013005439889754128, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.07965969177492642}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 94, 'last_n_outputs': 7, 'lr': 0.0013005439889754128, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.07965969177492642}"}}
exception: None

01:47:36 job_callback for (0, 0, 5) started
01:47:36 job_callback for (0, 0, 5) got condition
01:47:36 DISPATCHER: Trying to submit another job.
01:47:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:47:36 Only 6 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
01:47:36 HBMASTER: Trying to run another job!
01:47:36 job_callback for (0, 0, 5) finished
01:47:36 start sampling a new configuration.
01:47:36 done sampling a new configuration.
01:47:36 HBMASTER: schedule new run for iteration 0
01:47:36 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
01:47:36 HBMASTER: submitting job (0, 0, 6) to dispatcher
01:47:36 DISPATCHER: trying to submit job (0, 0, 6)
01:47:36 DISPATCHER: trying to notify the job_runner thread.
01:47:36 HBMASTER: job (0, 0, 6) submitted to dispatcher
01:47:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:47:36 DISPATCHER: Trying to submit another job.
01:47:36 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:47:36 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:47:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:47:36 WORKER: start processing job (0, 0, 6)
01:47:36 WORKER: args: ()
01:47:36 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 35, 'last_n_outputs': 30, 'lr': 0.030319904195599063, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.055607618288938114}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:47:39 DISPATCHER: Starting worker discovery
01:47:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:47:39 DISPATCHER: Finished worker discovery
01:48:39 DISPATCHER: Starting worker discovery
01:48:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:48:39 DISPATCHER: Finished worker discovery
Exception in thread Thread-412:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:49:14 WORKER: done with job (0, 0, 6), trying to register it.
01:49:14 WORKER: registered result for job (0, 0, 6) with dispatcher
01:49:14 DISPATCHER: job (0, 0, 6) finished
01:49:14 DISPATCHER: register_result: lock acquired
01:49:14 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:49:14 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 35, 'last_n_outputs': 30, 'lr': 0.030319904195599063, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.055607618288938114}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 35, 'last_n_outputs': 30, 'lr': 0.030319904195599063, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.055607618288938114}"}}
exception: None

01:49:14 job_callback for (0, 0, 6) started
01:49:14 DISPATCHER: Trying to submit another job.
01:49:14 job_callback for (0, 0, 6) got condition
01:49:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:49:14 Only 7 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
01:49:14 HBMASTER: Trying to run another job!
01:49:14 job_callback for (0, 0, 6) finished
01:49:14 start sampling a new configuration.
01:49:14 done sampling a new configuration.
01:49:14 HBMASTER: schedule new run for iteration 0
01:49:14 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
01:49:14 HBMASTER: submitting job (0, 0, 7) to dispatcher
01:49:14 DISPATCHER: trying to submit job (0, 0, 7)
01:49:14 DISPATCHER: trying to notify the job_runner thread.
01:49:14 HBMASTER: job (0, 0, 7) submitted to dispatcher
01:49:14 DISPATCHER: Trying to submit another job.
01:49:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:49:14 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:49:14 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:49:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:49:14 WORKER: start processing job (0, 0, 7)
01:49:14 WORKER: args: ()
01:49:14 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 92, 'last_n_outputs': 17, 'lr': 0.09111240681174083, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.11734051934868718}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:49:39 DISPATCHER: Starting worker discovery
01:49:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:49:39 DISPATCHER: Finished worker discovery
Exception in thread Thread-413:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:50:39 DISPATCHER: Starting worker discovery
01:50:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:50:39 DISPATCHER: Finished worker discovery
01:50:53 WORKER: done with job (0, 0, 7), trying to register it.
01:50:53 WORKER: registered result for job (0, 0, 7) with dispatcher
01:50:53 DISPATCHER: job (0, 0, 7) finished
01:50:53 DISPATCHER: register_result: lock acquired
01:50:53 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:50:53 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 92, 'last_n_outputs': 17, 'lr': 0.09111240681174083, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.11734051934868718}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 92, 'last_n_outputs': 17, 'lr': 0.09111240681174083, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.11734051934868718}"}}
exception: None

01:50:53 job_callback for (0, 0, 7) started
01:50:53 DISPATCHER: Trying to submit another job.
01:50:53 job_callback for (0, 0, 7) got condition
01:50:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:50:53 Only 8 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
01:50:53 HBMASTER: Trying to run another job!
01:50:53 job_callback for (0, 0, 7) finished
01:50:53 start sampling a new configuration.
01:50:53 done sampling a new configuration.
01:50:53 HBMASTER: schedule new run for iteration 0
01:50:53 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
01:50:53 HBMASTER: submitting job (0, 0, 8) to dispatcher
01:50:53 DISPATCHER: trying to submit job (0, 0, 8)
01:50:53 DISPATCHER: trying to notify the job_runner thread.
01:50:53 HBMASTER: job (0, 0, 8) submitted to dispatcher
01:50:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:50:53 DISPATCHER: Trying to submit another job.
01:50:53 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:50:53 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:50:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:50:53 WORKER: start processing job (0, 0, 8)
01:50:53 WORKER: args: ()
01:50:53 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 96, 'last_n_outputs': 28, 'lr': 0.0024547627800927795, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.186699654851592}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:51:39 DISPATCHER: Starting worker discovery
01:51:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:51:39 DISPATCHER: Finished worker discovery
Exception in thread Thread-414:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:52:31 WORKER: done with job (0, 0, 8), trying to register it.
01:52:31 WORKER: registered result for job (0, 0, 8) with dispatcher
01:52:31 DISPATCHER: job (0, 0, 8) finished
01:52:31 DISPATCHER: register_result: lock acquired
01:52:31 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:52:31 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 96, 'last_n_outputs': 28, 'lr': 0.0024547627800927795, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.186699654851592}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.21884402448639856, 'info': {'music_genre': 0.21884402448639856, 'config': "{'batch_size': 32, 'hidden_dim': 96, 'last_n_outputs': 28, 'lr': 0.0024547627800927795, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.186699654851592}"}}
exception: None

01:52:31 job_callback for (0, 0, 8) started
01:52:31 job_callback for (0, 0, 8) got condition
01:52:31 DISPATCHER: Trying to submit another job.
01:52:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:52:31 HBMASTER: Trying to run another job!
01:52:31 job_callback for (0, 0, 8) finished
01:52:31 start sampling a new configuration.
01:52:31 done sampling a new configuration.
01:52:31 HBMASTER: schedule new run for iteration 0
01:52:31 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
01:52:31 HBMASTER: submitting job (0, 0, 9) to dispatcher
01:52:31 DISPATCHER: trying to submit job (0, 0, 9)
01:52:31 DISPATCHER: trying to notify the job_runner thread.
01:52:31 HBMASTER: job (0, 0, 9) submitted to dispatcher
01:52:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:52:31 DISPATCHER: Trying to submit another job.
01:52:31 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:52:31 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:52:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:52:31 WORKER: start processing job (0, 0, 9)
01:52:31 WORKER: args: ()
01:52:31 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 37, 'last_n_outputs': 44, 'lr': 0.007985581466689314, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.03721091437312681}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:52:39 DISPATCHER: Starting worker discovery
01:52:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:52:39 DISPATCHER: Finished worker discovery
Exception in thread Thread-415:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:53:39 DISPATCHER: Starting worker discovery
01:53:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:53:39 DISPATCHER: Finished worker discovery
01:54:10 WORKER: done with job (0, 0, 9), trying to register it.
01:54:10 WORKER: registered result for job (0, 0, 9) with dispatcher
01:54:10 DISPATCHER: job (0, 0, 9) finished
01:54:10 DISPATCHER: register_result: lock acquired
01:54:10 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:54:10 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 37, 'last_n_outputs': 44, 'lr': 0.007985581466689314, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.03721091437312681}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.04469329985472775, 'info': {'music_genre': -0.04469329985472775, 'config': "{'batch_size': 128, 'hidden_dim': 37, 'last_n_outputs': 44, 'lr': 0.007985581466689314, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.03721091437312681}"}}
exception: None

01:54:10 job_callback for (0, 0, 9) started
01:54:10 DISPATCHER: Trying to submit another job.
01:54:10 job_callback for (0, 0, 9) got condition
01:54:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:54:10 HBMASTER: Trying to run another job!
01:54:10 job_callback for (0, 0, 9) finished
01:54:10 start sampling a new configuration.
01:54:10 done sampling a new configuration.
01:54:10 HBMASTER: schedule new run for iteration 0
01:54:10 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
01:54:10 HBMASTER: submitting job (0, 0, 10) to dispatcher
01:54:10 DISPATCHER: trying to submit job (0, 0, 10)
01:54:10 DISPATCHER: trying to notify the job_runner thread.
01:54:10 HBMASTER: job (0, 0, 10) submitted to dispatcher
01:54:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:54:10 DISPATCHER: Trying to submit another job.
01:54:10 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:54:10 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:54:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:54:10 WORKER: start processing job (0, 0, 10)
01:54:10 WORKER: args: ()
01:54:10 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 95, 'last_n_outputs': 3, 'lr': 0.011319600631179066, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.057630701465215615}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:54:39 DISPATCHER: Starting worker discovery
01:54:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:54:39 DISPATCHER: Finished worker discovery
Exception in thread Thread-416:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:55:39 DISPATCHER: Starting worker discovery
01:55:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:55:39 DISPATCHER: Finished worker discovery
01:55:47 WORKER: done with job (0, 0, 10), trying to register it.
01:55:47 WORKER: registered result for job (0, 0, 10) with dispatcher
01:55:47 DISPATCHER: job (0, 0, 10) finished
01:55:47 DISPATCHER: register_result: lock acquired
01:55:47 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:55:47 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 95, 'last_n_outputs': 3, 'lr': 0.011319600631179066, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.057630701465215615}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 95, 'last_n_outputs': 3, 'lr': 0.011319600631179066, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.057630701465215615}"}}
exception: None

01:55:47 job_callback for (0, 0, 10) started
01:55:47 job_callback for (0, 0, 10) got condition
01:55:47 DISPATCHER: Trying to submit another job.
01:55:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:55:47 HBMASTER: Trying to run another job!
01:55:47 job_callback for (0, 0, 10) finished
01:55:47 start sampling a new configuration.
01:55:47 done sampling a new configuration.
01:55:47 HBMASTER: schedule new run for iteration 0
01:55:47 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
01:55:47 HBMASTER: submitting job (0, 0, 11) to dispatcher
01:55:47 DISPATCHER: trying to submit job (0, 0, 11)
01:55:47 DISPATCHER: trying to notify the job_runner thread.
01:55:47 HBMASTER: job (0, 0, 11) submitted to dispatcher
01:55:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:55:47 DISPATCHER: Trying to submit another job.
01:55:47 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:55:47 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:55:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:55:47 WORKER: start processing job (0, 0, 11)
01:55:47 WORKER: args: ()
01:55:47 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 80, 'last_n_outputs': 47, 'lr': 0.0926160263712341, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.0825694136395445}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:56:39 DISPATCHER: Starting worker discovery
01:56:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:56:39 DISPATCHER: Finished worker discovery
Exception in thread Thread-417:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:57:26 WORKER: done with job (0, 0, 11), trying to register it.
01:57:26 WORKER: registered result for job (0, 0, 11) with dispatcher
01:57:26 DISPATCHER: job (0, 0, 11) finished
01:57:26 DISPATCHER: register_result: lock acquired
01:57:26 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:57:26 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 80, 'last_n_outputs': 47, 'lr': 0.0926160263712341, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.0825694136395445}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 80, 'last_n_outputs': 47, 'lr': 0.0926160263712341, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.0825694136395445}"}}
exception: None

01:57:26 job_callback for (0, 0, 11) started
01:57:26 job_callback for (0, 0, 11) got condition
01:57:26 DISPATCHER: Trying to submit another job.
01:57:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:57:26 HBMASTER: Trying to run another job!
01:57:26 job_callback for (0, 0, 11) finished
01:57:26 start sampling a new configuration.
01:57:26 done sampling a new configuration.
01:57:26 HBMASTER: schedule new run for iteration 0
01:57:26 HBMASTER: trying submitting job (0, 0, 12) to dispatcher
01:57:26 HBMASTER: submitting job (0, 0, 12) to dispatcher
01:57:26 DISPATCHER: trying to submit job (0, 0, 12)
01:57:26 DISPATCHER: trying to notify the job_runner thread.
01:57:26 HBMASTER: job (0, 0, 12) submitted to dispatcher
01:57:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:57:26 DISPATCHER: Trying to submit another job.
01:57:26 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:57:26 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:57:26 WORKER: start processing job (0, 0, 12)
01:57:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:57:26 WORKER: args: ()
01:57:26 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 31, 'last_n_outputs': 43, 'lr': 0.002093283389593394, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.014606900340384626}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:57:39 DISPATCHER: Starting worker discovery
01:57:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:57:39 DISPATCHER: Finished worker discovery
Exception in thread Thread-418:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:58:39 DISPATCHER: Starting worker discovery
01:58:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:58:39 DISPATCHER: Finished worker discovery
01:59:04 WORKER: done with job (0, 0, 12), trying to register it.
01:59:04 WORKER: registered result for job (0, 0, 12) with dispatcher
01:59:04 DISPATCHER: job (0, 0, 12) finished
01:59:04 DISPATCHER: register_result: lock acquired
01:59:04 DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:59:04 job_id: (0, 0, 12)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 31, 'last_n_outputs': 43, 'lr': 0.002093283389593394, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.014606900340384626}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 31, 'last_n_outputs': 43, 'lr': 0.002093283389593394, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.014606900340384626}"}}
exception: None

01:59:04 job_callback for (0, 0, 12) started
01:59:04 job_callback for (0, 0, 12) got condition
01:59:04 DISPATCHER: Trying to submit another job.
01:59:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:59:04 HBMASTER: Trying to run another job!
01:59:04 job_callback for (0, 0, 12) finished
01:59:04 start sampling a new configuration.
01:59:04 done sampling a new configuration.
01:59:04 HBMASTER: schedule new run for iteration 0
01:59:04 HBMASTER: trying submitting job (0, 0, 13) to dispatcher
01:59:04 HBMASTER: submitting job (0, 0, 13) to dispatcher
01:59:04 DISPATCHER: trying to submit job (0, 0, 13)
01:59:04 DISPATCHER: trying to notify the job_runner thread.
01:59:04 HBMASTER: job (0, 0, 13) submitted to dispatcher
01:59:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:59:04 DISPATCHER: Trying to submit another job.
01:59:04 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:59:04 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:59:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:59:04 WORKER: start processing job (0, 0, 13)
01:59:04 WORKER: args: ()
01:59:04 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 48, 'last_n_outputs': 20, 'lr': 0.002666174020962009, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.018490000293258386}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:59:39 DISPATCHER: Starting worker discovery
01:59:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:59:39 DISPATCHER: Finished worker discovery
Exception in thread Thread-419:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:00:39 DISPATCHER: Starting worker discovery
02:00:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:00:39 DISPATCHER: Finished worker discovery
02:00:44 WORKER: done with job (0, 0, 13), trying to register it.
02:00:44 WORKER: registered result for job (0, 0, 13) with dispatcher
02:00:44 DISPATCHER: job (0, 0, 13) finished
02:00:44 DISPATCHER: register_result: lock acquired
02:00:44 DISPATCHER: job (0, 0, 13) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
02:00:44 job_id: (0, 0, 13)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 48, 'last_n_outputs': 20, 'lr': 0.002666174020962009, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.018490000293258386}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2082390107511594, 'info': {'music_genre': 0.2082390107511594, 'config': "{'batch_size': 32, 'hidden_dim': 48, 'last_n_outputs': 20, 'lr': 0.002666174020962009, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.018490000293258386}"}}
exception: None

02:00:44 job_callback for (0, 0, 13) started
02:00:44 job_callback for (0, 0, 13) got condition
02:00:44 DISPATCHER: Trying to submit another job.
02:00:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:00:44 HBMASTER: Trying to run another job!
02:00:44 job_callback for (0, 0, 13) finished
02:00:44 start sampling a new configuration.
02:00:44 done sampling a new configuration.
02:00:44 HBMASTER: schedule new run for iteration 0
02:00:44 HBMASTER: trying submitting job (0, 0, 14) to dispatcher
02:00:44 HBMASTER: submitting job (0, 0, 14) to dispatcher
02:00:44 DISPATCHER: trying to submit job (0, 0, 14)
02:00:44 DISPATCHER: trying to notify the job_runner thread.
02:00:44 HBMASTER: job (0, 0, 14) submitted to dispatcher
02:00:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:00:44 DISPATCHER: Trying to submit another job.
02:00:44 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:00:44 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:00:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:00:44 WORKER: start processing job (0, 0, 14)
02:00:44 WORKER: args: ()
02:00:44 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 44, 'last_n_outputs': 45, 'lr': 0.0014650688355582015, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.196400192002357}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:01:39 DISPATCHER: Starting worker discovery
02:01:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:01:39 DISPATCHER: Finished worker discovery
Exception in thread Thread-420:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:02:22 WORKER: done with job (0, 0, 14), trying to register it.
02:02:22 WORKER: registered result for job (0, 0, 14) with dispatcher
02:02:22 DISPATCHER: job (0, 0, 14) finished
02:02:22 DISPATCHER: register_result: lock acquired
02:02:22 DISPATCHER: job (0, 0, 14) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
02:02:22 job_id: (0, 0, 14)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 44, 'last_n_outputs': 45, 'lr': 0.0014650688355582015, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.196400192002357}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.010403448973226204, 'info': {'music_genre': 0.010403448973226204, 'config': "{'batch_size': 16, 'hidden_dim': 44, 'last_n_outputs': 45, 'lr': 0.0014650688355582015, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.196400192002357}"}}
exception: None

02:02:22 job_callback for (0, 0, 14) started
02:02:22 job_callback for (0, 0, 14) got condition
02:02:22 DISPATCHER: Trying to submit another job.
02:02:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:02:22 HBMASTER: Trying to run another job!
02:02:22 job_callback for (0, 0, 14) finished
02:02:22 start sampling a new configuration.
02:02:22 done sampling a new configuration.
02:02:22 HBMASTER: schedule new run for iteration 0
02:02:22 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
02:02:22 HBMASTER: submitting job (0, 0, 15) to dispatcher
02:02:22 DISPATCHER: trying to submit job (0, 0, 15)
02:02:22 DISPATCHER: trying to notify the job_runner thread.
02:02:22 HBMASTER: job (0, 0, 15) submitted to dispatcher
02:02:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:02:22 DISPATCHER: Trying to submit another job.
02:02:22 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:02:22 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:02:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:02:22 WORKER: start processing job (0, 0, 15)
02:02:22 WORKER: args: ()
02:02:22 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 30, 'last_n_outputs': 47, 'lr': 0.002141610852418508, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.053835791768678795}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:02:39 DISPATCHER: Starting worker discovery
02:02:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:02:39 DISPATCHER: Finished worker discovery
Exception in thread Thread-421:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:03:39 DISPATCHER: Starting worker discovery
02:03:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:03:39 DISPATCHER: Finished worker discovery
02:04:01 WORKER: done with job (0, 0, 15), trying to register it.
02:04:01 WORKER: registered result for job (0, 0, 15) with dispatcher
02:04:01 DISPATCHER: job (0, 0, 15) finished
02:04:01 DISPATCHER: register_result: lock acquired
02:04:01 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
02:04:01 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 30, 'last_n_outputs': 47, 'lr': 0.002141610852418508, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.053835791768678795}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.013602413548336304, 'info': {'music_genre': -0.013602413548336304, 'config': "{'batch_size': 64, 'hidden_dim': 30, 'last_n_outputs': 47, 'lr': 0.002141610852418508, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.053835791768678795}"}}
exception: None

02:04:01 job_callback for (0, 0, 15) started
02:04:01 job_callback for (0, 0, 15) got condition
02:04:01 DISPATCHER: Trying to submit another job.
02:04:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:04:01 HBMASTER: Trying to run another job!
02:04:01 job_callback for (0, 0, 15) finished
02:04:01 start sampling a new configuration.
02:04:01 done sampling a new configuration.
02:04:01 HBMASTER: schedule new run for iteration 0
02:04:01 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
02:04:01 HBMASTER: submitting job (0, 0, 16) to dispatcher
02:04:01 DISPATCHER: trying to submit job (0, 0, 16)
02:04:01 DISPATCHER: trying to notify the job_runner thread.
02:04:01 HBMASTER: job (0, 0, 16) submitted to dispatcher
02:04:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:04:01 DISPATCHER: Trying to submit another job.
02:04:01 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:04:01 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:04:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:04:01 WORKER: start processing job (0, 0, 16)
02:04:01 WORKER: args: ()
02:04:01 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 70, 'last_n_outputs': 40, 'lr': 0.012984906750364419, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.029440918844035543}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:04:39 DISPATCHER: Starting worker discovery
02:04:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:04:39 DISPATCHER: Finished worker discovery
Exception in thread Thread-422:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:05:39 DISPATCHER: Starting worker discovery
02:05:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:05:39 DISPATCHER: Finished worker discovery
02:05:40 WORKER: done with job (0, 0, 16), trying to register it.
02:05:40 WORKER: registered result for job (0, 0, 16) with dispatcher
02:05:40 DISPATCHER: job (0, 0, 16) finished
02:05:40 DISPATCHER: register_result: lock acquired
02:05:40 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
02:05:40 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 70, 'last_n_outputs': 40, 'lr': 0.012984906750364419, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.029440918844035543}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.22309588990107596, 'info': {'music_genre': 0.22309588990107596, 'config': "{'batch_size': 32, 'hidden_dim': 70, 'last_n_outputs': 40, 'lr': 0.012984906750364419, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.029440918844035543}"}}
exception: None

02:05:40 job_callback for (0, 0, 16) started
02:05:40 job_callback for (0, 0, 16) got condition
02:05:40 DISPATCHER: Trying to submit another job.
02:05:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:05:40 HBMASTER: Trying to run another job!
02:05:40 job_callback for (0, 0, 16) finished
02:05:40 start sampling a new configuration.
02:05:40 done sampling a new configuration.
02:05:40 HBMASTER: schedule new run for iteration 0
02:05:40 HBMASTER: trying submitting job (0, 0, 17) to dispatcher
02:05:40 HBMASTER: submitting job (0, 0, 17) to dispatcher
02:05:40 DISPATCHER: trying to submit job (0, 0, 17)
02:05:40 DISPATCHER: trying to notify the job_runner thread.
02:05:40 HBMASTER: job (0, 0, 17) submitted to dispatcher
02:05:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:05:40 DISPATCHER: Trying to submit another job.
02:05:40 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:05:40 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:05:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:05:40 WORKER: start processing job (0, 0, 17)
02:05:40 WORKER: args: ()
02:05:40 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 80, 'last_n_outputs': 21, 'lr': 0.015099793443660133, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.024043604887177668}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:06:39 DISPATCHER: Starting worker discovery
02:06:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:06:39 DISPATCHER: Finished worker discovery
Exception in thread Thread-423:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:07:18 WORKER: done with job (0, 0, 17), trying to register it.
02:07:18 WORKER: registered result for job (0, 0, 17) with dispatcher
02:07:18 DISPATCHER: job (0, 0, 17) finished
02:07:18 DISPATCHER: register_result: lock acquired
02:07:18 DISPATCHER: job (0, 0, 17) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
02:07:18 job_id: (0, 0, 17)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 80, 'last_n_outputs': 21, 'lr': 0.015099793443660133, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.024043604887177668}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.026032907762561012, 'info': {'music_genre': -0.026032907762561012, 'config': "{'batch_size': 32, 'hidden_dim': 80, 'last_n_outputs': 21, 'lr': 0.015099793443660133, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.024043604887177668}"}}
exception: None

02:07:18 job_callback for (0, 0, 17) started
02:07:18 DISPATCHER: Trying to submit another job.
02:07:18 job_callback for (0, 0, 17) got condition
02:07:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:07:18 done building a new model for budget 44.444444 based on 9/15 split
Best loss for this budget:-0.287816





02:07:18 HBMASTER: Trying to run another job!
02:07:18 job_callback for (0, 0, 17) finished
02:07:18 start sampling a new configuration.
02:07:18 done sampling a new configuration.
02:07:18 HBMASTER: schedule new run for iteration 0
02:07:18 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
02:07:18 HBMASTER: submitting job (0, 0, 18) to dispatcher
02:07:18 DISPATCHER: trying to submit job (0, 0, 18)
02:07:18 DISPATCHER: trying to notify the job_runner thread.
02:07:18 HBMASTER: job (0, 0, 18) submitted to dispatcher
02:07:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:07:18 DISPATCHER: Trying to submit another job.
02:07:18 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:07:18 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:07:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:07:18 WORKER: start processing job (0, 0, 18)
02:07:18 WORKER: args: ()
02:07:18 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 26, 'last_n_outputs': 27, 'lr': 0.002699453253096985, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.0398711499435781}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:07:39 DISPATCHER: Starting worker discovery
02:07:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:07:39 DISPATCHER: Finished worker discovery
Exception in thread Thread-424:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:08:39 DISPATCHER: Starting worker discovery
02:08:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:08:39 DISPATCHER: Finished worker discovery
02:08:57 WORKER: done with job (0, 0, 18), trying to register it.
02:08:57 WORKER: registered result for job (0, 0, 18) with dispatcher
02:08:57 DISPATCHER: job (0, 0, 18) finished
02:08:57 DISPATCHER: register_result: lock acquired
02:08:57 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
02:08:57 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 26, 'last_n_outputs': 27, 'lr': 0.002699453253096985, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.0398711499435781}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 26, 'last_n_outputs': 27, 'lr': 0.002699453253096985, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.0398711499435781}"}}
exception: None

02:08:57 job_callback for (0, 0, 18) started
02:08:57 DISPATCHER: Trying to submit another job.
02:08:57 job_callback for (0, 0, 18) got condition
02:08:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:08:57 done building a new model for budget 44.444444 based on 9/16 split
Best loss for this budget:-0.287816





02:08:57 HBMASTER: Trying to run another job!
02:08:57 job_callback for (0, 0, 18) finished
02:08:57 start sampling a new configuration.
02:08:57 best_vector: [1, 0.807837742826487, 0.8149889065261284, 0.19531373730999385, 0.6202709811398293, 0, 0.9100893422579763, 0.27511459110640457], 0.04020792914365819, 0.09070177087573311, 0.003646930376575797
02:08:57 done sampling a new configuration.
02:08:57 HBMASTER: schedule new run for iteration 0
02:08:57 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
02:08:57 HBMASTER: submitting job (0, 0, 19) to dispatcher
02:08:57 DISPATCHER: trying to submit job (0, 0, 19)
02:08:57 DISPATCHER: trying to notify the job_runner thread.
02:08:57 HBMASTER: job (0, 0, 19) submitted to dispatcher
02:08:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:08:57 DISPATCHER: Trying to submit another job.
02:08:57 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:08:57 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:08:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:08:57 WORKER: start processing job (0, 0, 19)
02:08:57 WORKER: args: ()
02:08:57 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 85, 'last_n_outputs': 41, 'lr': 0.0024582580760915823, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.022799868137418456}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:09:39 DISPATCHER: Starting worker discovery
02:09:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:09:39 DISPATCHER: Finished worker discovery
Exception in thread Thread-425:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:10:35 WORKER: done with job (0, 0, 19), trying to register it.
02:10:35 WORKER: registered result for job (0, 0, 19) with dispatcher
02:10:35 DISPATCHER: job (0, 0, 19) finished
02:10:35 DISPATCHER: register_result: lock acquired
02:10:35 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
02:10:35 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 85, 'last_n_outputs': 41, 'lr': 0.0024582580760915823, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.022799868137418456}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 85, 'last_n_outputs': 41, 'lr': 0.0024582580760915823, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.022799868137418456}"}}
exception: None

02:10:35 job_callback for (0, 0, 19) started
02:10:35 job_callback for (0, 0, 19) got condition
02:10:35 DISPATCHER: Trying to submit another job.
02:10:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:10:35 done building a new model for budget 44.444444 based on 9/17 split
Best loss for this budget:-0.287816





02:10:35 HBMASTER: Trying to run another job!
02:10:35 job_callback for (0, 0, 19) finished
02:10:35 start sampling a new configuration.
02:10:35 best_vector: [3, 0.12783068543575457, 0.5229603797758992, 0.46913185544367364, 0.0010458513690975307, 1, 0.8708240854128793, 0.9679032501743485], 0.0013556421534864885, 0.09105599248766501, 0.00012343934174382772
02:10:35 done sampling a new configuration.
02:10:35 HBMASTER: schedule new run for iteration 0
02:10:35 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
02:10:35 HBMASTER: submitting job (0, 0, 20) to dispatcher
02:10:35 DISPATCHER: trying to submit job (0, 0, 20)
02:10:35 DISPATCHER: trying to notify the job_runner thread.
02:10:35 HBMASTER: job (0, 0, 20) submitted to dispatcher
02:10:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:10:35 DISPATCHER: Trying to submit another job.
02:10:35 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:10:35 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:10:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:10:35 WORKER: start processing job (0, 0, 20)
02:10:35 WORKER: args: ()
02:10:35 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 30, 'last_n_outputs': 27, 'lr': 0.008674884693998438, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.18166495741373606}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:10:39 DISPATCHER: Starting worker discovery
02:10:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:10:39 DISPATCHER: Finished worker discovery
Exception in thread Thread-426:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:11:39 DISPATCHER: Starting worker discovery
02:11:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:11:39 DISPATCHER: Finished worker discovery
02:12:13 WORKER: done with job (0, 0, 20), trying to register it.
02:12:13 WORKER: registered result for job (0, 0, 20) with dispatcher
02:12:13 DISPATCHER: job (0, 0, 20) finished
02:12:13 DISPATCHER: register_result: lock acquired
02:12:13 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
02:12:13 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 30, 'last_n_outputs': 27, 'lr': 0.008674884693998438, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.18166495741373606}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.06808223416333906, 'info': {'music_genre': 0.06808223416333906, 'config': "{'batch_size': 128, 'hidden_dim': 30, 'last_n_outputs': 27, 'lr': 0.008674884693998438, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.18166495741373606}"}}
exception: None

02:12:13 job_callback for (0, 0, 20) started
02:12:13 DISPATCHER: Trying to submit another job.
02:12:13 job_callback for (0, 0, 20) got condition
02:12:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:12:13 done building a new model for budget 44.444444 based on 9/17 split
Best loss for this budget:-0.287816





02:12:13 HBMASTER: Trying to run another job!
02:12:13 job_callback for (0, 0, 20) finished
02:12:13 start sampling a new configuration.
02:12:13 best_vector: [0, 0.34300633115377577, 0.5571857682023686, 0.22005000116086648, 0.19726344142020763, 0, 0.4527884869529154, 0.815875946050282], 0.012758834246150229, 0.8273528238870013, 0.010556057543058571
02:12:13 done sampling a new configuration.
02:12:13 HBMASTER: schedule new run for iteration 0
02:12:13 HBMASTER: trying submitting job (0, 0, 21) to dispatcher
02:12:13 HBMASTER: submitting job (0, 0, 21) to dispatcher
02:12:13 DISPATCHER: trying to submit job (0, 0, 21)
02:12:13 DISPATCHER: trying to notify the job_runner thread.
02:12:13 HBMASTER: job (0, 0, 21) submitted to dispatcher
02:12:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:12:13 DISPATCHER: Trying to submit another job.
02:12:13 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:12:13 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:12:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:12:13 WORKER: start processing job (0, 0, 21)
02:12:13 WORKER: args: ()
02:12:13 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 47, 'last_n_outputs': 28, 'lr': 0.0027548629756799356, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.11520705593170341}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:12:39 DISPATCHER: Starting worker discovery
02:12:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:12:39 DISPATCHER: Finished worker discovery
Exception in thread Thread-427:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:13:39 DISPATCHER: Starting worker discovery
02:13:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:13:39 DISPATCHER: Finished worker discovery
02:13:53 WORKER: done with job (0, 0, 21), trying to register it.
02:13:53 WORKER: registered result for job (0, 0, 21) with dispatcher
02:13:53 DISPATCHER: job (0, 0, 21) finished
02:13:53 DISPATCHER: register_result: lock acquired
02:13:53 DISPATCHER: job (0, 0, 21) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
02:13:53 job_id: (0, 0, 21)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 47, 'last_n_outputs': 28, 'lr': 0.0027548629756799356, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.11520705593170341}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.19112706749084463, 'info': {'music_genre': 0.19112706749084463, 'config': "{'batch_size': 16, 'hidden_dim': 47, 'last_n_outputs': 28, 'lr': 0.0027548629756799356, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.11520705593170341}"}}
exception: None

02:13:53 DISPATCHER: Trying to submit another job.
02:13:53 job_callback for (0, 0, 21) started
02:13:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:13:53 job_callback for (0, 0, 21) got condition
02:13:53 done building a new model for budget 44.444444 based on 9/18 split
Best loss for this budget:-0.287816





02:13:53 HBMASTER: Trying to run another job!
02:13:53 job_callback for (0, 0, 21) finished
02:13:53 start sampling a new configuration.
02:13:53 best_vector: [0, 0.21300212845167552, 0.43717942078431016, 0.17202424274715136, 0.17011115689469575, 0, 0.24601623141267814, 0.881916500172667], 0.0018142907116815792, 0.7028781758818967, 0.0012752253459462166
02:13:53 done sampling a new configuration.
02:13:53 HBMASTER: schedule new run for iteration 0
02:13:53 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
02:13:53 HBMASTER: submitting job (0, 0, 22) to dispatcher
02:13:53 DISPATCHER: trying to submit job (0, 0, 22)
02:13:53 DISPATCHER: trying to notify the job_runner thread.
02:13:53 HBMASTER: job (0, 0, 22) submitted to dispatcher
02:13:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:13:53 DISPATCHER: Trying to submit another job.
02:13:53 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:13:53 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:13:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:13:53 WORKER: start processing job (0, 0, 22)
02:13:53 WORKER: args: ()
02:13:53 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 37, 'last_n_outputs': 22, 'lr': 0.002208251252791934, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.14041057582463187}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:14:39 DISPATCHER: Starting worker discovery
02:14:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:14:39 DISPATCHER: Finished worker discovery
Exception in thread Thread-428:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:15:32 WORKER: done with job (0, 0, 22), trying to register it.
02:15:32 WORKER: registered result for job (0, 0, 22) with dispatcher
02:15:32 DISPATCHER: job (0, 0, 22) finished
02:15:32 DISPATCHER: register_result: lock acquired
02:15:32 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
02:15:32 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 37, 'last_n_outputs': 22, 'lr': 0.002208251252791934, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.14041057582463187}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.11231355408852643, 'info': {'music_genre': 0.11231355408852643, 'config': "{'batch_size': 16, 'hidden_dim': 37, 'last_n_outputs': 22, 'lr': 0.002208251252791934, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.14041057582463187}"}}
exception: None

02:15:32 job_callback for (0, 0, 22) started
02:15:32 DISPATCHER: Trying to submit another job.
02:15:32 job_callback for (0, 0, 22) got condition
02:15:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:15:32 done building a new model for budget 44.444444 based on 9/19 split
Best loss for this budget:-0.287816





02:15:32 HBMASTER: Trying to run another job!
02:15:32 job_callback for (0, 0, 22) finished
02:15:32 start sampling a new configuration.
02:15:32 done sampling a new configuration.
02:15:32 HBMASTER: schedule new run for iteration 0
02:15:32 HBMASTER: trying submitting job (0, 0, 23) to dispatcher
02:15:32 HBMASTER: submitting job (0, 0, 23) to dispatcher
02:15:32 DISPATCHER: trying to submit job (0, 0, 23)
02:15:32 DISPATCHER: trying to notify the job_runner thread.
02:15:32 HBMASTER: job (0, 0, 23) submitted to dispatcher
02:15:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:15:32 DISPATCHER: Trying to submit another job.
02:15:32 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:15:32 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:15:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:15:32 WORKER: start processing job (0, 0, 23)
02:15:32 WORKER: args: ()
02:15:32 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 63, 'last_n_outputs': 30, 'lr': 0.0027899905478533066, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.16992219288024132}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:15:39 DISPATCHER: Starting worker discovery
02:15:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:15:39 DISPATCHER: Finished worker discovery
Exception in thread Thread-429:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:16:39 DISPATCHER: Starting worker discovery
02:16:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:16:39 DISPATCHER: Finished worker discovery
02:17:10 WORKER: done with job (0, 0, 23), trying to register it.
02:17:10 WORKER: registered result for job (0, 0, 23) with dispatcher
02:17:10 DISPATCHER: job (0, 0, 23) finished
02:17:10 DISPATCHER: register_result: lock acquired
02:17:10 DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
02:17:10 job_id: (0, 0, 23)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 63, 'last_n_outputs': 30, 'lr': 0.0027899905478533066, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.16992219288024132}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 63, 'last_n_outputs': 30, 'lr': 0.0027899905478533066, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.16992219288024132}"}}
exception: None

02:17:10 job_callback for (0, 0, 23) started
02:17:10 job_callback for (0, 0, 23) got condition
02:17:10 DISPATCHER: Trying to submit another job.
02:17:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:17:10 done building a new model for budget 44.444444 based on 9/20 split
Best loss for this budget:-0.287816





02:17:10 HBMASTER: Trying to run another job!
02:17:10 job_callback for (0, 0, 23) finished
02:17:10 start sampling a new configuration.
02:17:10 best_vector: [1, 0.41236062328895473, 0.44640414931764016, 0.26396222672275116, 0.10852356908816453, 1, 0.7285269656562864, 0.9722191138563991], 0.00024302083901800656, 3.2428560041653287, 0.0007880815869468384
02:17:10 done sampling a new configuration.
02:17:10 HBMASTER: schedule new run for iteration 0
02:17:10 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
02:17:10 HBMASTER: submitting job (0, 0, 24) to dispatcher
02:17:10 DISPATCHER: trying to submit job (0, 0, 24)
02:17:10 DISPATCHER: trying to notify the job_runner thread.
02:17:10 HBMASTER: job (0, 0, 24) submitted to dispatcher
02:17:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:17:10 DISPATCHER: Trying to submit another job.
02:17:10 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:17:10 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:17:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:17:10 WORKER: start processing job (0, 0, 24)
02:17:10 WORKER: args: ()
02:17:10 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 53, 'last_n_outputs': 23, 'lr': 0.0033722864183484934, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.18402898444109045}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:17:39 DISPATCHER: Starting worker discovery
02:17:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:17:39 DISPATCHER: Finished worker discovery
Exception in thread Thread-430:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:18:39 DISPATCHER: Starting worker discovery
02:18:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:18:39 DISPATCHER: Finished worker discovery
02:18:49 WORKER: done with job (0, 0, 24), trying to register it.
02:18:49 WORKER: registered result for job (0, 0, 24) with dispatcher
02:18:49 DISPATCHER: job (0, 0, 24) finished
02:18:49 DISPATCHER: register_result: lock acquired
02:18:49 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
02:18:49 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 53, 'last_n_outputs': 23, 'lr': 0.0033722864183484934, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.18402898444109045}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.007748934895312837, 'info': {'music_genre': 0.007748934895312837, 'config': "{'batch_size': 32, 'hidden_dim': 53, 'last_n_outputs': 23, 'lr': 0.0033722864183484934, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.18402898444109045}"}}
exception: None

02:18:49 job_callback for (0, 0, 24) started
02:18:49 job_callback for (0, 0, 24) got condition
02:18:49 DISPATCHER: Trying to submit another job.
02:18:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:18:49 done building a new model for budget 44.444444 based on 9/21 split
Best loss for this budget:-0.287816





02:18:49 HBMASTER: Trying to run another job!
02:18:49 job_callback for (0, 0, 24) finished
02:18:49 start sampling a new configuration.
02:18:49 best_vector: [1, 0.27940748871283927, 0.5236991985992191, 0.09561489201842727, 0.13086406623537236, 0, 0.2580687929223898, 0.9617005004625441], 0.0030489772659313646, 5.5398369433106405, 0.016890836897120846
02:18:49 done sampling a new configuration.
02:18:49 HBMASTER: schedule new run for iteration 0
02:18:49 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
02:18:49 HBMASTER: submitting job (0, 0, 25) to dispatcher
02:18:49 DISPATCHER: trying to submit job (0, 0, 25)
02:18:49 DISPATCHER: trying to notify the job_runner thread.
02:18:49 HBMASTER: job (0, 0, 25) submitted to dispatcher
02:18:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:18:49 DISPATCHER: Trying to submit another job.
02:18:49 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:18:49 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:18:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:18:49 WORKER: start processing job (0, 0, 25)
02:18:49 WORKER: args: ()
02:18:49 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 42, 'last_n_outputs': 27, 'lr': 0.0015532085910593028, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 33, 'weight_decay': 0.1783204690972513}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:19:39 DISPATCHER: Starting worker discovery
02:19:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:19:39 DISPATCHER: Finished worker discovery
Exception in thread Thread-431:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:20:28 WORKER: done with job (0, 0, 25), trying to register it.
02:20:28 WORKER: registered result for job (0, 0, 25) with dispatcher
02:20:28 DISPATCHER: job (0, 0, 25) finished
02:20:28 DISPATCHER: register_result: lock acquired
02:20:28 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
02:20:28 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 42, 'last_n_outputs': 27, 'lr': 0.0015532085910593028, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 33, 'weight_decay': 0.1783204690972513}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3034206703081457, 'info': {'music_genre': 0.3034206703081457, 'config': "{'batch_size': 32, 'hidden_dim': 42, 'last_n_outputs': 27, 'lr': 0.0015532085910593028, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 33, 'weight_decay': 0.1783204690972513}"}}
exception: None

02:20:28 job_callback for (0, 0, 25) started
02:20:28 DISPATCHER: Trying to submit another job.
02:20:28 job_callback for (0, 0, 25) got condition
02:20:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:20:28 done building a new model for budget 44.444444 based on 9/22 split
Best loss for this budget:-0.303421





02:20:28 HBMASTER: Trying to run another job!
02:20:28 job_callback for (0, 0, 25) finished
02:20:28 start sampling a new configuration.
02:20:28 best_vector: [1, 0.7348662649327853, 0.8126608207637186, 0.4764485033441687, 0.0999223182931095, 0, 0.28443762956791274, 0.2766284843106], 3.269514422607073e-05, 288.9356616881605, 0.009446793130949586
02:20:28 done sampling a new configuration.
02:20:28 HBMASTER: schedule new run for iteration 0
02:20:28 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
02:20:28 HBMASTER: submitting job (0, 0, 26) to dispatcher
02:20:28 DISPATCHER: trying to submit job (0, 0, 26)
02:20:28 DISPATCHER: trying to notify the job_runner thread.
02:20:28 HBMASTER: job (0, 0, 26) submitted to dispatcher
02:20:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:20:28 DISPATCHER: Trying to submit another job.
02:20:28 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:20:28 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:20:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:20:28 WORKER: start processing job (0, 0, 26)
02:20:28 WORKER: args: ()
02:20:28 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 79, 'last_n_outputs': 41, 'lr': 0.008972159937205952, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.022903505357543725}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:20:39 DISPATCHER: Starting worker discovery
02:20:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:20:39 DISPATCHER: Finished worker discovery
Exception in thread Thread-432:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:21:39 DISPATCHER: Starting worker discovery
02:21:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:21:39 DISPATCHER: Finished worker discovery
02:22:08 WORKER: done with job (0, 0, 26), trying to register it.
02:22:08 WORKER: registered result for job (0, 0, 26) with dispatcher
02:22:08 DISPATCHER: job (0, 0, 26) finished
02:22:08 DISPATCHER: register_result: lock acquired
02:22:08 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
02:22:08 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 79, 'last_n_outputs': 41, 'lr': 0.008972159937205952, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.022903505357543725}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2631902654732292, 'info': {'music_genre': 0.2631902654732292, 'config': "{'batch_size': 32, 'hidden_dim': 79, 'last_n_outputs': 41, 'lr': 0.008972159937205952, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.022903505357543725}"}}
exception: None

02:22:08 job_callback for (0, 0, 26) started
02:22:08 job_callback for (0, 0, 26) got condition
02:22:08 DISPATCHER: Trying to submit another job.
02:22:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:22:08 done building a new model for budget 44.444444 based on 9/22 split
Best loss for this budget:-0.303421





02:22:08 HBMASTER: Trying to run another job!
02:22:08 job_callback for (0, 0, 26) finished
02:22:08 ITERATION: Advancing config (0, 0, 2) to next budget 133.333333
02:22:08 ITERATION: Advancing config (0, 0, 8) to next budget 133.333333
02:22:08 ITERATION: Advancing config (0, 0, 13) to next budget 133.333333
02:22:08 ITERATION: Advancing config (0, 0, 16) to next budget 133.333333
02:22:08 ITERATION: Advancing config (0, 0, 20) to next budget 133.333333
02:22:08 ITERATION: Advancing config (0, 0, 21) to next budget 133.333333
02:22:08 ITERATION: Advancing config (0, 0, 22) to next budget 133.333333
02:22:08 ITERATION: Advancing config (0, 0, 25) to next budget 133.333333
02:22:08 ITERATION: Advancing config (0, 0, 26) to next budget 133.333333
02:22:08 HBMASTER: schedule new run for iteration 0
02:22:08 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
02:22:08 HBMASTER: submitting job (0, 0, 2) to dispatcher
02:22:08 DISPATCHER: trying to submit job (0, 0, 2)
02:22:08 DISPATCHER: trying to notify the job_runner thread.
02:22:08 HBMASTER: job (0, 0, 2) submitted to dispatcher
02:22:08 DISPATCHER: Trying to submit another job.
02:22:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:22:08 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:22:08 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:22:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:22:08 WORKER: start processing job (0, 0, 2)
02:22:08 WORKER: args: ()
02:22:08 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 35, 'last_n_outputs': 30, 'lr': 0.003353983267619106, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.18883534871434077}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:22:39 DISPATCHER: Starting worker discovery
02:22:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:22:39 DISPATCHER: Finished worker discovery
Exception in thread Thread-433:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:23:39 DISPATCHER: Starting worker discovery
02:23:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:23:39 DISPATCHER: Finished worker discovery
02:24:39 DISPATCHER: Starting worker discovery
02:24:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:24:39 DISPATCHER: Finished worker discovery
02:25:16 WORKER: done with job (0, 0, 2), trying to register it.
02:25:16 WORKER: registered result for job (0, 0, 2) with dispatcher
02:25:16 DISPATCHER: job (0, 0, 2) finished
02:25:16 DISPATCHER: register_result: lock acquired
02:25:16 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
02:25:16 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 35, 'last_n_outputs': 30, 'lr': 0.003353983267619106, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.18883534871434077}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2887334376205616, 'info': {'music_genre': 0.2887334376205616, 'config': "{'batch_size': 64, 'hidden_dim': 35, 'last_n_outputs': 30, 'lr': 0.003353983267619106, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.18883534871434077}"}}
exception: None

02:25:16 job_callback for (0, 0, 2) started
02:25:16 job_callback for (0, 0, 2) got condition
02:25:16 DISPATCHER: Trying to submit another job.
02:25:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:25:16 Only 1 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
02:25:16 HBMASTER: Trying to run another job!
02:25:16 job_callback for (0, 0, 2) finished
02:25:16 HBMASTER: schedule new run for iteration 0
02:25:16 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
02:25:16 HBMASTER: submitting job (0, 0, 8) to dispatcher
02:25:16 DISPATCHER: trying to submit job (0, 0, 8)
02:25:16 DISPATCHER: trying to notify the job_runner thread.
02:25:16 HBMASTER: job (0, 0, 8) submitted to dispatcher
02:25:16 DISPATCHER: Trying to submit another job.
02:25:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:25:16 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:25:16 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:25:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:25:16 WORKER: start processing job (0, 0, 8)
02:25:16 WORKER: args: ()
02:25:16 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 96, 'last_n_outputs': 28, 'lr': 0.0024547627800927795, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.186699654851592}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:25:39 DISPATCHER: Starting worker discovery
02:25:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:25:39 DISPATCHER: Finished worker discovery
Exception in thread Thread-434:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:26:39 DISPATCHER: Starting worker discovery
02:26:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:26:39 DISPATCHER: Finished worker discovery
02:27:39 DISPATCHER: Starting worker discovery
02:27:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:27:39 DISPATCHER: Finished worker discovery
02:28:24 WORKER: done with job (0, 0, 8), trying to register it.
02:28:24 WORKER: registered result for job (0, 0, 8) with dispatcher
02:28:24 DISPATCHER: job (0, 0, 8) finished
02:28:24 DISPATCHER: register_result: lock acquired
02:28:24 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
02:28:24 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 96, 'last_n_outputs': 28, 'lr': 0.0024547627800927795, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.186699654851592}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.28573430743279593, 'info': {'music_genre': 0.28573430743279593, 'config': "{'batch_size': 32, 'hidden_dim': 96, 'last_n_outputs': 28, 'lr': 0.0024547627800927795, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.186699654851592}"}}
exception: None

02:28:24 job_callback for (0, 0, 8) started
02:28:24 job_callback for (0, 0, 8) got condition
02:28:24 DISPATCHER: Trying to submit another job.
02:28:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:28:24 Only 2 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
02:28:24 HBMASTER: Trying to run another job!
02:28:24 job_callback for (0, 0, 8) finished
02:28:24 HBMASTER: schedule new run for iteration 0
02:28:24 HBMASTER: trying submitting job (0, 0, 13) to dispatcher
02:28:24 HBMASTER: submitting job (0, 0, 13) to dispatcher
02:28:24 DISPATCHER: trying to submit job (0, 0, 13)
02:28:24 DISPATCHER: trying to notify the job_runner thread.
02:28:24 HBMASTER: job (0, 0, 13) submitted to dispatcher
02:28:24 DISPATCHER: Trying to submit another job.
02:28:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:28:24 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:28:24 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:28:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:28:24 WORKER: start processing job (0, 0, 13)
02:28:24 WORKER: args: ()
02:28:24 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 48, 'last_n_outputs': 20, 'lr': 0.002666174020962009, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.018490000293258386}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:28:39 DISPATCHER: Starting worker discovery
02:28:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:28:39 DISPATCHER: Finished worker discovery
Exception in thread Thread-435:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:29:39 DISPATCHER: Starting worker discovery
02:29:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:29:39 DISPATCHER: Finished worker discovery
02:30:39 DISPATCHER: Starting worker discovery
02:30:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:30:39 DISPATCHER: Finished worker discovery
02:31:32 WORKER: done with job (0, 0, 13), trying to register it.
02:31:32 WORKER: registered result for job (0, 0, 13) with dispatcher
02:31:32 DISPATCHER: job (0, 0, 13) finished
02:31:32 DISPATCHER: register_result: lock acquired
02:31:32 DISPATCHER: job (0, 0, 13) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
02:31:32 job_id: (0, 0, 13)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 48, 'last_n_outputs': 20, 'lr': 0.002666174020962009, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.018490000293258386}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2533840432019401, 'info': {'music_genre': 0.2533840432019401, 'config': "{'batch_size': 32, 'hidden_dim': 48, 'last_n_outputs': 20, 'lr': 0.002666174020962009, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.018490000293258386}"}}
exception: None

02:31:32 job_callback for (0, 0, 13) started
02:31:32 DISPATCHER: Trying to submit another job.
02:31:32 job_callback for (0, 0, 13) got condition
02:31:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:31:32 Only 3 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
02:31:32 HBMASTER: Trying to run another job!
02:31:32 job_callback for (0, 0, 13) finished
02:31:32 HBMASTER: schedule new run for iteration 0
02:31:32 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
02:31:32 HBMASTER: submitting job (0, 0, 16) to dispatcher
02:31:32 DISPATCHER: trying to submit job (0, 0, 16)
02:31:32 DISPATCHER: trying to notify the job_runner thread.
02:31:32 HBMASTER: job (0, 0, 16) submitted to dispatcher
02:31:32 DISPATCHER: Trying to submit another job.
02:31:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:31:32 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:31:32 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:31:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:31:32 WORKER: start processing job (0, 0, 16)
02:31:32 WORKER: args: ()
02:31:32 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 70, 'last_n_outputs': 40, 'lr': 0.012984906750364419, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.029440918844035543}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:31:39 DISPATCHER: Starting worker discovery
02:31:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:31:39 DISPATCHER: Finished worker discovery
Exception in thread Thread-436:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:32:39 DISPATCHER: Starting worker discovery
02:32:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:32:39 DISPATCHER: Finished worker discovery
02:33:39 DISPATCHER: Starting worker discovery
02:33:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:33:39 DISPATCHER: Finished worker discovery
02:34:38 WORKER: done with job (0, 0, 16), trying to register it.
02:34:38 WORKER: registered result for job (0, 0, 16) with dispatcher
02:34:38 DISPATCHER: job (0, 0, 16) finished
02:34:38 DISPATCHER: register_result: lock acquired
02:34:38 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
02:34:38 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 70, 'last_n_outputs': 40, 'lr': 0.012984906750364419, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.029440918844035543}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2962838066050355, 'info': {'music_genre': 0.2962838066050355, 'config': "{'batch_size': 32, 'hidden_dim': 70, 'last_n_outputs': 40, 'lr': 0.012984906750364419, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.029440918844035543}"}}
exception: None

02:34:38 job_callback for (0, 0, 16) started
02:34:38 DISPATCHER: Trying to submit another job.
02:34:38 job_callback for (0, 0, 16) got condition
02:34:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:34:38 Only 4 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
02:34:38 HBMASTER: Trying to run another job!
02:34:38 job_callback for (0, 0, 16) finished
02:34:38 HBMASTER: schedule new run for iteration 0
02:34:38 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
02:34:38 HBMASTER: submitting job (0, 0, 20) to dispatcher
02:34:38 DISPATCHER: trying to submit job (0, 0, 20)
02:34:38 DISPATCHER: trying to notify the job_runner thread.
02:34:38 HBMASTER: job (0, 0, 20) submitted to dispatcher
02:34:38 DISPATCHER: Trying to submit another job.
02:34:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:34:38 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:34:38 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:34:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:34:38 WORKER: start processing job (0, 0, 20)
02:34:38 WORKER: args: ()
02:34:38 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 30, 'last_n_outputs': 27, 'lr': 0.008674884693998438, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.18166495741373606}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:34:39 DISPATCHER: Starting worker discovery
02:34:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:34:39 DISPATCHER: Finished worker discovery
Exception in thread Thread-437:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:35:39 DISPATCHER: Starting worker discovery
02:35:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:35:39 DISPATCHER: Finished worker discovery
02:36:39 DISPATCHER: Starting worker discovery
02:36:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:36:39 DISPATCHER: Finished worker discovery
02:37:39 DISPATCHER: Starting worker discovery
02:37:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:37:39 DISPATCHER: Finished worker discovery
02:37:45 WORKER: done with job (0, 0, 20), trying to register it.
02:37:45 WORKER: registered result for job (0, 0, 20) with dispatcher
02:37:45 DISPATCHER: job (0, 0, 20) finished
02:37:45 DISPATCHER: register_result: lock acquired
02:37:45 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
02:37:45 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 30, 'last_n_outputs': 27, 'lr': 0.008674884693998438, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.18166495741373606}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.06909624595179502, 'info': {'music_genre': 0.06909624595179502, 'config': "{'batch_size': 128, 'hidden_dim': 30, 'last_n_outputs': 27, 'lr': 0.008674884693998438, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.18166495741373606}"}}
exception: None

02:37:45 job_callback for (0, 0, 20) started
02:37:45 DISPATCHER: Trying to submit another job.
02:37:45 job_callback for (0, 0, 20) got condition
02:37:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:37:45 Only 5 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
02:37:45 HBMASTER: Trying to run another job!
02:37:45 job_callback for (0, 0, 20) finished
02:37:45 HBMASTER: schedule new run for iteration 0
02:37:45 HBMASTER: trying submitting job (0, 0, 21) to dispatcher
02:37:45 HBMASTER: submitting job (0, 0, 21) to dispatcher
02:37:45 DISPATCHER: trying to submit job (0, 0, 21)
02:37:45 DISPATCHER: trying to notify the job_runner thread.
02:37:45 HBMASTER: job (0, 0, 21) submitted to dispatcher
02:37:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:37:45 DISPATCHER: Trying to submit another job.
02:37:45 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:37:45 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:37:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:37:45 WORKER: start processing job (0, 0, 21)
02:37:45 WORKER: args: ()
02:37:45 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 47, 'last_n_outputs': 28, 'lr': 0.0027548629756799356, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.11520705593170341}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:38:39 DISPATCHER: Starting worker discovery
02:38:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:38:39 DISPATCHER: Finished worker discovery
Exception in thread Thread-438:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:39:39 DISPATCHER: Starting worker discovery
02:39:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:39:39 DISPATCHER: Finished worker discovery
02:40:39 DISPATCHER: Starting worker discovery
02:40:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:40:39 DISPATCHER: Finished worker discovery
02:40:52 WORKER: done with job (0, 0, 21), trying to register it.
02:40:52 WORKER: registered result for job (0, 0, 21) with dispatcher
02:40:52 DISPATCHER: job (0, 0, 21) finished
02:40:52 DISPATCHER: register_result: lock acquired
02:40:52 DISPATCHER: job (0, 0, 21) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
02:40:52 job_id: (0, 0, 21)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 47, 'last_n_outputs': 28, 'lr': 0.0027548629756799356, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.11520705593170341}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.21934721275386257, 'info': {'music_genre': 0.21934721275386257, 'config': "{'batch_size': 16, 'hidden_dim': 47, 'last_n_outputs': 28, 'lr': 0.0027548629756799356, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.11520705593170341}"}}
exception: None

02:40:52 job_callback for (0, 0, 21) started
02:40:52 DISPATCHER: Trying to submit another job.
02:40:52 job_callback for (0, 0, 21) got condition
02:40:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:40:52 Only 6 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
02:40:52 HBMASTER: Trying to run another job!
02:40:52 job_callback for (0, 0, 21) finished
02:40:52 HBMASTER: schedule new run for iteration 0
02:40:52 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
02:40:52 HBMASTER: submitting job (0, 0, 22) to dispatcher
02:40:52 DISPATCHER: trying to submit job (0, 0, 22)
02:40:52 DISPATCHER: trying to notify the job_runner thread.
02:40:52 HBMASTER: job (0, 0, 22) submitted to dispatcher
02:40:52 DISPATCHER: Trying to submit another job.
02:40:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:40:52 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:40:52 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:40:52 WORKER: start processing job (0, 0, 22)
02:40:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:40:52 WORKER: args: ()
02:40:52 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 37, 'last_n_outputs': 22, 'lr': 0.002208251252791934, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.14041057582463187}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:41:39 DISPATCHER: Starting worker discovery
02:41:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:41:39 DISPATCHER: Finished worker discovery
Exception in thread Thread-439:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:42:39 DISPATCHER: Starting worker discovery
02:42:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:42:39 DISPATCHER: Finished worker discovery
02:43:39 DISPATCHER: Starting worker discovery
02:43:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:43:39 DISPATCHER: Finished worker discovery
02:43:58 WORKER: done with job (0, 0, 22), trying to register it.
02:43:58 WORKER: registered result for job (0, 0, 22) with dispatcher
02:43:58 DISPATCHER: job (0, 0, 22) finished
02:43:58 DISPATCHER: register_result: lock acquired
02:43:58 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
02:43:58 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 37, 'last_n_outputs': 22, 'lr': 0.002208251252791934, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.14041057582463187}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.18187902485007634, 'info': {'music_genre': 0.18187902485007634, 'config': "{'batch_size': 16, 'hidden_dim': 37, 'last_n_outputs': 22, 'lr': 0.002208251252791934, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.14041057582463187}"}}
exception: None

02:43:58 job_callback for (0, 0, 22) started
02:43:58 job_callback for (0, 0, 22) got condition
02:43:58 DISPATCHER: Trying to submit another job.
02:43:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:43:58 Only 7 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
02:43:58 HBMASTER: Trying to run another job!
02:43:58 job_callback for (0, 0, 22) finished
02:43:58 HBMASTER: schedule new run for iteration 0
02:43:58 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
02:43:58 HBMASTER: submitting job (0, 0, 25) to dispatcher
02:43:58 DISPATCHER: trying to submit job (0, 0, 25)
02:43:58 DISPATCHER: trying to notify the job_runner thread.
02:43:58 HBMASTER: job (0, 0, 25) submitted to dispatcher
02:43:58 DISPATCHER: Trying to submit another job.
02:43:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:43:58 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:43:58 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:43:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:43:58 WORKER: start processing job (0, 0, 25)
02:43:58 WORKER: args: ()
02:43:58 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 42, 'last_n_outputs': 27, 'lr': 0.0015532085910593028, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 33, 'weight_decay': 0.1783204690972513}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:44:39 DISPATCHER: Starting worker discovery
02:44:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:44:39 DISPATCHER: Finished worker discovery
Exception in thread Thread-440:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:45:39 DISPATCHER: Starting worker discovery
02:45:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:45:39 DISPATCHER: Finished worker discovery
02:46:39 DISPATCHER: Starting worker discovery
02:46:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:46:39 DISPATCHER: Finished worker discovery
02:47:03 WORKER: done with job (0, 0, 25), trying to register it.
02:47:03 WORKER: registered result for job (0, 0, 25) with dispatcher
02:47:03 DISPATCHER: job (0, 0, 25) finished
02:47:03 DISPATCHER: register_result: lock acquired
02:47:03 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
02:47:03 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 42, 'last_n_outputs': 27, 'lr': 0.0015532085910593028, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 33, 'weight_decay': 0.1783204690972513}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.25005563360528693, 'info': {'music_genre': 0.25005563360528693, 'config': "{'batch_size': 32, 'hidden_dim': 42, 'last_n_outputs': 27, 'lr': 0.0015532085910593028, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 33, 'weight_decay': 0.1783204690972513}"}}
exception: None

02:47:03 job_callback for (0, 0, 25) started
02:47:03 job_callback for (0, 0, 25) got condition
02:47:03 DISPATCHER: Trying to submit another job.
02:47:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:47:03 Only 8 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
02:47:03 HBMASTER: Trying to run another job!
02:47:03 job_callback for (0, 0, 25) finished
02:47:03 HBMASTER: schedule new run for iteration 0
02:47:03 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
02:47:03 HBMASTER: submitting job (0, 0, 26) to dispatcher
02:47:03 DISPATCHER: trying to submit job (0, 0, 26)
02:47:03 DISPATCHER: trying to notify the job_runner thread.
02:47:03 HBMASTER: job (0, 0, 26) submitted to dispatcher
02:47:03 DISPATCHER: Trying to submit another job.
02:47:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:47:03 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:47:03 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:47:03 WORKER: start processing job (0, 0, 26)
02:47:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:47:03 WORKER: args: ()
02:47:03 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 79, 'last_n_outputs': 41, 'lr': 0.008972159937205952, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.022903505357543725}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:47:39 DISPATCHER: Starting worker discovery
02:47:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:47:39 DISPATCHER: Finished worker discovery
Exception in thread Thread-441:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:48:39 DISPATCHER: Starting worker discovery
02:48:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:48:39 DISPATCHER: Finished worker discovery
02:49:39 DISPATCHER: Starting worker discovery
02:49:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:49:39 DISPATCHER: Finished worker discovery
02:50:12 WORKER: done with job (0, 0, 26), trying to register it.
02:50:12 WORKER: registered result for job (0, 0, 26) with dispatcher
02:50:12 DISPATCHER: job (0, 0, 26) finished
02:50:12 DISPATCHER: register_result: lock acquired
02:50:12 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
02:50:12 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 79, 'last_n_outputs': 41, 'lr': 0.008972159937205952, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.022903505357543725}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2748566853590036, 'info': {'music_genre': 0.2748566853590036, 'config': "{'batch_size': 32, 'hidden_dim': 79, 'last_n_outputs': 41, 'lr': 0.008972159937205952, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.022903505357543725}"}}
exception: None

02:50:12 job_callback for (0, 0, 26) started
02:50:12 job_callback for (0, 0, 26) got condition
02:50:12 DISPATCHER: Trying to submit another job.
02:50:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:50:12 HBMASTER: Trying to run another job!
02:50:12 job_callback for (0, 0, 26) finished
02:50:12 ITERATION: Advancing config (0, 0, 2) to next budget 400.000000
02:50:12 ITERATION: Advancing config (0, 0, 8) to next budget 400.000000
02:50:12 ITERATION: Advancing config (0, 0, 16) to next budget 400.000000
02:50:12 HBMASTER: schedule new run for iteration 0
02:50:12 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
02:50:12 HBMASTER: submitting job (0, 0, 2) to dispatcher
02:50:12 DISPATCHER: trying to submit job (0, 0, 2)
02:50:12 DISPATCHER: trying to notify the job_runner thread.
02:50:12 HBMASTER: job (0, 0, 2) submitted to dispatcher
02:50:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:50:12 DISPATCHER: Trying to submit another job.
02:50:12 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:50:12 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:50:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:50:12 WORKER: start processing job (0, 0, 2)
02:50:12 WORKER: args: ()
02:50:12 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 35, 'last_n_outputs': 30, 'lr': 0.003353983267619106, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.18883534871434077}, 'budget': 400.0, 'working_directory': '.'}
02:50:39 DISPATCHER: Starting worker discovery
02:50:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:50:39 DISPATCHER: Finished worker discovery
Exception in thread Thread-442:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:51:39 DISPATCHER: Starting worker discovery
02:51:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:51:40 DISPATCHER: Finished worker discovery
02:52:40 DISPATCHER: Starting worker discovery
02:52:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:52:40 DISPATCHER: Finished worker discovery
02:53:40 DISPATCHER: Starting worker discovery
02:53:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:53:40 DISPATCHER: Finished worker discovery
02:54:40 DISPATCHER: Starting worker discovery
02:54:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:54:40 DISPATCHER: Finished worker discovery
02:55:40 DISPATCHER: Starting worker discovery
02:55:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:55:40 DISPATCHER: Finished worker discovery
02:56:40 DISPATCHER: Starting worker discovery
02:56:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:56:40 DISPATCHER: Finished worker discovery
02:57:40 DISPATCHER: Starting worker discovery
02:57:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:57:40 DISPATCHER: Finished worker discovery
02:57:47 WORKER: done with job (0, 0, 2), trying to register it.
02:57:47 WORKER: registered result for job (0, 0, 2) with dispatcher
02:57:47 DISPATCHER: job (0, 0, 2) finished
02:57:47 DISPATCHER: register_result: lock acquired
02:57:47 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
02:57:47 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 35, 'last_n_outputs': 30, 'lr': 0.003353983267619106, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.18883534871434077}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.29487315864751734, 'info': {'music_genre': 0.29487315864751734, 'config': "{'batch_size': 64, 'hidden_dim': 35, 'last_n_outputs': 30, 'lr': 0.003353983267619106, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.18883534871434077}"}}
exception: None

02:57:47 job_callback for (0, 0, 2) started
02:57:47 job_callback for (0, 0, 2) got condition
02:57:47 DISPATCHER: Trying to submit another job.
02:57:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:57:47 Only 1 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
02:57:47 HBMASTER: Trying to run another job!
02:57:47 job_callback for (0, 0, 2) finished
02:57:47 HBMASTER: schedule new run for iteration 0
02:57:47 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
02:57:47 HBMASTER: submitting job (0, 0, 8) to dispatcher
02:57:47 DISPATCHER: trying to submit job (0, 0, 8)
02:57:47 DISPATCHER: trying to notify the job_runner thread.
02:57:47 HBMASTER: job (0, 0, 8) submitted to dispatcher
02:57:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:57:47 DISPATCHER: Trying to submit another job.
02:57:47 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:57:47 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:57:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:57:47 WORKER: start processing job (0, 0, 8)
02:57:47 WORKER: args: ()
02:57:47 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 96, 'last_n_outputs': 28, 'lr': 0.0024547627800927795, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.186699654851592}, 'budget': 400.0, 'working_directory': '.'}
02:58:40 DISPATCHER: Starting worker discovery
02:58:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:58:40 DISPATCHER: Finished worker discovery
Exception in thread Thread-443:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:59:40 DISPATCHER: Starting worker discovery
02:59:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:59:40 DISPATCHER: Finished worker discovery
03:00:40 DISPATCHER: Starting worker discovery
03:00:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:00:40 DISPATCHER: Finished worker discovery
03:01:40 DISPATCHER: Starting worker discovery
03:01:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:01:40 DISPATCHER: Finished worker discovery
03:02:40 DISPATCHER: Starting worker discovery
03:02:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:02:40 DISPATCHER: Finished worker discovery
03:03:40 DISPATCHER: Starting worker discovery
03:03:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:03:40 DISPATCHER: Finished worker discovery
03:04:40 DISPATCHER: Starting worker discovery
03:04:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:04:40 DISPATCHER: Finished worker discovery
03:05:21 WORKER: done with job (0, 0, 8), trying to register it.
03:05:21 WORKER: registered result for job (0, 0, 8) with dispatcher
03:05:21 DISPATCHER: job (0, 0, 8) finished
03:05:21 DISPATCHER: register_result: lock acquired
03:05:21 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
03:05:21 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 96, 'last_n_outputs': 28, 'lr': 0.0024547627800927795, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.186699654851592}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.2025934230415085, 'info': {'music_genre': 0.2025934230415085, 'config': "{'batch_size': 32, 'hidden_dim': 96, 'last_n_outputs': 28, 'lr': 0.0024547627800927795, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.186699654851592}"}}
exception: None

03:05:21 job_callback for (0, 0, 8) started
03:05:21 DISPATCHER: Trying to submit another job.
03:05:21 job_callback for (0, 0, 8) got condition
03:05:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:05:21 Only 2 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
03:05:21 HBMASTER: Trying to run another job!
03:05:21 job_callback for (0, 0, 8) finished
03:05:21 HBMASTER: schedule new run for iteration 0
03:05:21 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
03:05:21 HBMASTER: submitting job (0, 0, 16) to dispatcher
03:05:21 DISPATCHER: trying to submit job (0, 0, 16)
03:05:21 DISPATCHER: trying to notify the job_runner thread.
03:05:21 HBMASTER: job (0, 0, 16) submitted to dispatcher
03:05:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:05:21 DISPATCHER: Trying to submit another job.
03:05:21 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:05:21 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:05:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:05:21 WORKER: start processing job (0, 0, 16)
03:05:21 WORKER: args: ()
03:05:21 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 70, 'last_n_outputs': 40, 'lr': 0.012984906750364419, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.029440918844035543}, 'budget': 400.0, 'working_directory': '.'}
03:05:40 DISPATCHER: Starting worker discovery
03:05:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:05:40 DISPATCHER: Finished worker discovery
Exception in thread Thread-444:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:06:40 DISPATCHER: Starting worker discovery
03:06:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:06:40 DISPATCHER: Finished worker discovery
03:07:40 DISPATCHER: Starting worker discovery
03:07:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:07:40 DISPATCHER: Finished worker discovery
03:08:40 DISPATCHER: Starting worker discovery
03:08:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:08:40 DISPATCHER: Finished worker discovery
03:09:40 DISPATCHER: Starting worker discovery
03:09:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:09:40 DISPATCHER: Finished worker discovery
03:10:40 DISPATCHER: Starting worker discovery
03:10:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:10:40 DISPATCHER: Finished worker discovery
03:11:40 DISPATCHER: Starting worker discovery
03:11:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:11:40 DISPATCHER: Finished worker discovery
03:12:40 DISPATCHER: Starting worker discovery
03:12:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:12:40 DISPATCHER: Finished worker discovery
03:12:53 WORKER: done with job (0, 0, 16), trying to register it.
03:12:53 WORKER: registered result for job (0, 0, 16) with dispatcher
03:12:53 DISPATCHER: job (0, 0, 16) finished
03:12:53 DISPATCHER: register_result: lock acquired
03:12:53 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
03:12:53 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 70, 'last_n_outputs': 40, 'lr': 0.012984906750364419, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.029440918844035543}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.24534845145507875, 'info': {'music_genre': 0.24534845145507875, 'config': "{'batch_size': 32, 'hidden_dim': 70, 'last_n_outputs': 40, 'lr': 0.012984906750364419, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.029440918844035543}"}}
exception: None

03:12:53 job_callback for (0, 0, 16) started
03:12:53 job_callback for (0, 0, 16) got condition
03:12:53 DISPATCHER: Trying to submit another job.
03:12:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:12:53 Only 3 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
03:12:53 HBMASTER: Trying to run another job!
03:12:53 job_callback for (0, 0, 16) finished
03:12:53 ITERATION: Advancing config (0, 0, 2) to next budget 1200.000000
03:12:53 HBMASTER: schedule new run for iteration 0
03:12:53 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
03:12:53 HBMASTER: submitting job (0, 0, 2) to dispatcher
03:12:53 DISPATCHER: trying to submit job (0, 0, 2)
03:12:53 DISPATCHER: trying to notify the job_runner thread.
03:12:53 HBMASTER: job (0, 0, 2) submitted to dispatcher
03:12:53 DISPATCHER: Trying to submit another job.
03:12:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:12:53 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:12:53 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:12:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:12:53 WORKER: start processing job (0, 0, 2)
03:12:53 WORKER: args: ()
03:12:53 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 35, 'last_n_outputs': 30, 'lr': 0.003353983267619106, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.18883534871434077}, 'budget': 1200.0, 'working_directory': '.'}
03:13:40 DISPATCHER: Starting worker discovery
03:13:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:13:40 DISPATCHER: Finished worker discovery
Exception in thread Thread-445:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:14:40 DISPATCHER: Starting worker discovery
03:14:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:14:40 DISPATCHER: Finished worker discovery
03:15:40 DISPATCHER: Starting worker discovery
03:15:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:15:40 DISPATCHER: Finished worker discovery
03:16:40 DISPATCHER: Starting worker discovery
03:16:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:16:40 DISPATCHER: Finished worker discovery
03:17:40 DISPATCHER: Starting worker discovery
03:17:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:17:40 DISPATCHER: Finished worker discovery
03:18:40 DISPATCHER: Starting worker discovery
03:18:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:18:40 DISPATCHER: Finished worker discovery
03:19:40 DISPATCHER: Starting worker discovery
03:19:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:19:40 DISPATCHER: Finished worker discovery
03:20:40 DISPATCHER: Starting worker discovery
03:20:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:20:40 DISPATCHER: Finished worker discovery
03:21:40 DISPATCHER: Starting worker discovery
03:21:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:21:40 DISPATCHER: Finished worker discovery
03:22:40 DISPATCHER: Starting worker discovery
03:22:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:22:40 DISPATCHER: Finished worker discovery
03:23:40 DISPATCHER: Starting worker discovery
03:23:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:23:40 DISPATCHER: Finished worker discovery
03:24:40 DISPATCHER: Starting worker discovery
03:24:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:24:40 DISPATCHER: Finished worker discovery
03:25:40 DISPATCHER: Starting worker discovery
03:25:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:25:40 DISPATCHER: Finished worker discovery
03:26:40 DISPATCHER: Starting worker discovery
03:26:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:26:40 DISPATCHER: Finished worker discovery
03:27:40 DISPATCHER: Starting worker discovery
03:27:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:27:40 DISPATCHER: Finished worker discovery
03:28:40 DISPATCHER: Starting worker discovery
03:28:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:28:40 DISPATCHER: Finished worker discovery
03:29:40 DISPATCHER: Starting worker discovery
03:29:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:29:40 DISPATCHER: Finished worker discovery
03:30:40 DISPATCHER: Starting worker discovery
03:30:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:30:40 DISPATCHER: Finished worker discovery
03:31:40 DISPATCHER: Starting worker discovery
03:31:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:31:40 DISPATCHER: Finished worker discovery
03:32:40 DISPATCHER: Starting worker discovery
03:32:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:32:40 DISPATCHER: Finished worker discovery
03:33:40 DISPATCHER: Starting worker discovery
03:33:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:33:40 DISPATCHER: Finished worker discovery
03:33:46 WORKER: done with job (0, 0, 2), trying to register it.
03:33:46 WORKER: registered result for job (0, 0, 2) with dispatcher
03:33:46 DISPATCHER: job (0, 0, 2) finished
03:33:46 DISPATCHER: register_result: lock acquired
03:33:46 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
03:33:46 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 35, 'last_n_outputs': 30, 'lr': 0.003353983267619106, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.18883534871434077}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.23349403540930905, 'info': {'music_genre': 0.23349403540930905, 'config': "{'batch_size': 64, 'hidden_dim': 35, 'last_n_outputs': 30, 'lr': 0.003353983267619106, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.18883534871434077}"}}
exception: None

03:33:46 job_callback for (0, 0, 2) started
03:33:46 DISPATCHER: Trying to submit another job.
03:33:46 job_callback for (0, 0, 2) got condition
03:33:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:33:46 Only 1 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
03:33:46 HBMASTER: Trying to run another job!
03:33:46 job_callback for (0, 0, 2) finished
03:33:46 start sampling a new configuration.
03:33:46 best_vector: [0, 0.003847909058428217, 0.49625496978705425, 0.5241270776040476, 0.10153226761860401, 1, 0.9306448927091634, 0.8425764369939176], 0.00026637531929421375, 82.30260082878647, 0.021923381574512218
03:33:46 done sampling a new configuration.
03:33:46 HBMASTER: schedule new run for iteration 1
03:33:46 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
03:33:46 HBMASTER: submitting job (1, 0, 0) to dispatcher
03:33:46 DISPATCHER: trying to submit job (1, 0, 0)
03:33:46 DISPATCHER: trying to notify the job_runner thread.
03:33:46 HBMASTER: job (1, 0, 0) submitted to dispatcher
03:33:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:33:46 DISPATCHER: Trying to submit another job.
03:33:46 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:33:46 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:33:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:33:46 WORKER: start processing job (1, 0, 0)
03:33:46 WORKER: args: ()
03:33:46 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 20, 'last_n_outputs': 25, 'lr': 0.011175170430683678, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.12480075657702483}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:34:40 DISPATCHER: Starting worker discovery
03:34:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:34:40 DISPATCHER: Finished worker discovery
Exception in thread Thread-446:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:35:40 DISPATCHER: Starting worker discovery
03:35:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:35:40 DISPATCHER: Finished worker discovery
03:36:40 DISPATCHER: Starting worker discovery
03:36:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:36:40 DISPATCHER: Finished worker discovery
03:36:51 WORKER: done with job (1, 0, 0), trying to register it.
03:36:51 WORKER: registered result for job (1, 0, 0) with dispatcher
03:36:51 DISPATCHER: job (1, 0, 0) finished
03:36:51 DISPATCHER: register_result: lock acquired
03:36:51 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
03:36:51 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 20, 'last_n_outputs': 25, 'lr': 0.011175170430683678, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.12480075657702483}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0036853901111161373, 'info': {'music_genre': 0.0036853901111161373, 'config': "{'batch_size': 16, 'hidden_dim': 20, 'last_n_outputs': 25, 'lr': 0.011175170430683678, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.12480075657702483}"}}
exception: None

03:36:51 job_callback for (1, 0, 0) started
03:36:51 job_callback for (1, 0, 0) got condition
03:36:51 DISPATCHER: Trying to submit another job.
03:36:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:36:51 HBMASTER: Trying to run another job!
03:36:51 job_callback for (1, 0, 0) finished
03:36:51 start sampling a new configuration.
03:36:51 done sampling a new configuration.
03:36:51 HBMASTER: schedule new run for iteration 1
03:36:51 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
03:36:51 HBMASTER: submitting job (1, 0, 1) to dispatcher
03:36:51 DISPATCHER: trying to submit job (1, 0, 1)
03:36:51 DISPATCHER: trying to notify the job_runner thread.
03:36:51 HBMASTER: job (1, 0, 1) submitted to dispatcher
03:36:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:36:51 DISPATCHER: Trying to submit another job.
03:36:51 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:36:51 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:36:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:36:51 WORKER: start processing job (1, 0, 1)
03:36:51 WORKER: args: ()
03:36:51 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 63, 'last_n_outputs': 50, 'lr': 0.03428165397534898, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.07499089940596738}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:37:40 DISPATCHER: Starting worker discovery
03:37:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:37:40 DISPATCHER: Finished worker discovery
Exception in thread Thread-447:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:38:40 DISPATCHER: Starting worker discovery
03:38:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:38:40 DISPATCHER: Finished worker discovery
03:39:40 DISPATCHER: Starting worker discovery
03:39:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:39:40 DISPATCHER: Finished worker discovery
03:39:55 WORKER: done with job (1, 0, 1), trying to register it.
03:39:55 WORKER: registered result for job (1, 0, 1) with dispatcher
03:39:55 DISPATCHER: job (1, 0, 1) finished
03:39:55 DISPATCHER: register_result: lock acquired
03:39:55 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
03:39:55 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 63, 'last_n_outputs': 50, 'lr': 0.03428165397534898, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.07499089940596738}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.08194824061350986, 'info': {'music_genre': 0.08194824061350986, 'config': "{'batch_size': 16, 'hidden_dim': 63, 'last_n_outputs': 50, 'lr': 0.03428165397534898, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.07499089940596738}"}}
exception: None

03:39:55 job_callback for (1, 0, 1) started
03:39:55 DISPATCHER: Trying to submit another job.
03:39:55 job_callback for (1, 0, 1) got condition
03:39:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:39:55 HBMASTER: Trying to run another job!
03:39:55 job_callback for (1, 0, 1) finished
03:39:55 start sampling a new configuration.
03:39:55 done sampling a new configuration.
03:39:55 HBMASTER: schedule new run for iteration 1
03:39:55 HBMASTER: trying submitting job (1, 0, 2) to dispatcher
03:39:55 HBMASTER: submitting job (1, 0, 2) to dispatcher
03:39:55 DISPATCHER: trying to submit job (1, 0, 2)
03:39:55 DISPATCHER: trying to notify the job_runner thread.
03:39:55 HBMASTER: job (1, 0, 2) submitted to dispatcher
03:39:55 DISPATCHER: Trying to submit another job.
03:39:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:39:55 DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:39:55 DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:39:55 WORKER: start processing job (1, 0, 2)
03:39:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:39:55 WORKER: args: ()
03:39:55 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 32, 'last_n_outputs': 17, 'lr': 0.04069393629084747, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.01595179937266284}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:40:40 DISPATCHER: Starting worker discovery
03:40:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:40:40 DISPATCHER: Finished worker discovery
Exception in thread Thread-448:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:41:40 DISPATCHER: Starting worker discovery
03:41:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:41:40 DISPATCHER: Finished worker discovery
03:42:40 DISPATCHER: Starting worker discovery
03:42:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:42:40 DISPATCHER: Finished worker discovery
03:43:02 WORKER: done with job (1, 0, 2), trying to register it.
03:43:02 WORKER: registered result for job (1, 0, 2) with dispatcher
03:43:02 DISPATCHER: job (1, 0, 2) finished
03:43:02 DISPATCHER: register_result: lock acquired
03:43:02 DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
03:43:02 job_id: (1, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 32, 'last_n_outputs': 17, 'lr': 0.04069393629084747, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.01595179937266284}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.06649293339008672, 'info': {'music_genre': 0.06649293339008672, 'config': "{'batch_size': 64, 'hidden_dim': 32, 'last_n_outputs': 17, 'lr': 0.04069393629084747, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.01595179937266284}"}}
exception: None

03:43:02 job_callback for (1, 0, 2) started
03:43:02 job_callback for (1, 0, 2) got condition
03:43:02 DISPATCHER: Trying to submit another job.
03:43:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:43:02 HBMASTER: Trying to run another job!
03:43:02 job_callback for (1, 0, 2) finished
03:43:02 start sampling a new configuration.
03:43:02 done sampling a new configuration.
03:43:02 HBMASTER: schedule new run for iteration 1
03:43:02 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
03:43:02 HBMASTER: submitting job (1, 0, 3) to dispatcher
03:43:02 DISPATCHER: trying to submit job (1, 0, 3)
03:43:02 DISPATCHER: trying to notify the job_runner thread.
03:43:02 HBMASTER: job (1, 0, 3) submitted to dispatcher
03:43:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:43:02 DISPATCHER: Trying to submit another job.
03:43:02 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:43:02 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:43:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:43:02 WORKER: start processing job (1, 0, 3)
03:43:02 WORKER: args: ()
03:43:02 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 33, 'last_n_outputs': 10, 'lr': 0.0017736366915996067, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.0999158929428797}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:43:40 DISPATCHER: Starting worker discovery
03:43:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:43:40 DISPATCHER: Finished worker discovery
Exception in thread Thread-449:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:44:40 DISPATCHER: Starting worker discovery
03:44:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:44:40 DISPATCHER: Finished worker discovery
03:45:40 DISPATCHER: Starting worker discovery
03:45:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:45:40 DISPATCHER: Finished worker discovery
03:46:07 WORKER: done with job (1, 0, 3), trying to register it.
03:46:07 WORKER: registered result for job (1, 0, 3) with dispatcher
03:46:07 DISPATCHER: job (1, 0, 3) finished
03:46:07 DISPATCHER: register_result: lock acquired
03:46:07 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
03:46:07 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 33, 'last_n_outputs': 10, 'lr': 0.0017736366915996067, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.0999158929428797}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 33, 'last_n_outputs': 10, 'lr': 0.0017736366915996067, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.0999158929428797}"}}
exception: None

03:46:07 job_callback for (1, 0, 3) started
03:46:07 DISPATCHER: Trying to submit another job.
03:46:07 job_callback for (1, 0, 3) got condition
03:46:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:46:07 HBMASTER: Trying to run another job!
03:46:07 job_callback for (1, 0, 3) finished
03:46:07 start sampling a new configuration.
03:46:07 best_vector: [1, 0.09786722197432332, 0.453255870334946, 0.20523630478661817, 0.099024736212958, 0, 0.18945352254146514, 0.8932913891229258], 2.4102476605768873e-05, 344.4708385535112, 0.00830260032760559
03:46:07 done sampling a new configuration.
03:46:07 HBMASTER: schedule new run for iteration 1
03:46:07 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
03:46:07 HBMASTER: submitting job (1, 0, 4) to dispatcher
03:46:07 DISPATCHER: trying to submit job (1, 0, 4)
03:46:07 DISPATCHER: trying to notify the job_runner thread.
03:46:07 HBMASTER: job (1, 0, 4) submitted to dispatcher
03:46:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:46:07 DISPATCHER: Trying to submit another job.
03:46:07 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:46:07 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:46:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:46:07 WORKER: start processing job (1, 0, 4)
03:46:07 WORKER: args: ()
03:46:07 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 27, 'last_n_outputs': 23, 'lr': 0.002573194471050847, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.1452776787673177}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:46:40 DISPATCHER: Starting worker discovery
03:46:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:46:40 DISPATCHER: Finished worker discovery
Exception in thread Thread-450:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:47:40 DISPATCHER: Starting worker discovery
03:47:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:47:40 DISPATCHER: Finished worker discovery
03:48:40 DISPATCHER: Starting worker discovery
03:48:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:48:40 DISPATCHER: Finished worker discovery
03:49:12 WORKER: done with job (1, 0, 4), trying to register it.
03:49:12 WORKER: registered result for job (1, 0, 4) with dispatcher
03:49:12 DISPATCHER: job (1, 0, 4) finished
03:49:12 DISPATCHER: register_result: lock acquired
03:49:12 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
03:49:12 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 27, 'last_n_outputs': 23, 'lr': 0.002573194471050847, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.1452776787673177}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.20775707675025593, 'info': {'music_genre': 0.20775707675025593, 'config': "{'batch_size': 32, 'hidden_dim': 27, 'last_n_outputs': 23, 'lr': 0.002573194471050847, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.1452776787673177}"}}
exception: None

03:49:12 job_callback for (1, 0, 4) started
03:49:12 DISPATCHER: Trying to submit another job.
03:49:12 job_callback for (1, 0, 4) got condition
03:49:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:49:12 HBMASTER: Trying to run another job!
03:49:12 job_callback for (1, 0, 4) finished
03:49:12 start sampling a new configuration.
03:49:12 best_vector: [2, 0.15644441859475552, 0.568267690171934, 0.048154329618694536, 0.10141472947881576, 0, 0.17129473385898758, 0.34206580656778635], 0.0005344274463510972, 32.2684585789453, 0.01724514991603189
03:49:12 done sampling a new configuration.
03:49:12 HBMASTER: schedule new run for iteration 1
03:49:12 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
03:49:12 HBMASTER: submitting job (1, 0, 5) to dispatcher
03:49:12 DISPATCHER: trying to submit job (1, 0, 5)
03:49:12 DISPATCHER: trying to notify the job_runner thread.
03:49:12 HBMASTER: job (1, 0, 5) submitted to dispatcher
03:49:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:49:12 DISPATCHER: Trying to submit another job.
03:49:12 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:49:12 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:49:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:49:12 WORKER: start processing job (1, 0, 5)
03:49:12 WORKER: args: ()
03:49:12 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 32, 'last_n_outputs': 29, 'lr': 0.0012482703624784716, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.027863641569415207}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:49:40 DISPATCHER: Starting worker discovery
03:49:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:49:40 DISPATCHER: Finished worker discovery
Exception in thread Thread-451:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:50:40 DISPATCHER: Starting worker discovery
03:50:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:50:40 DISPATCHER: Finished worker discovery
03:51:40 DISPATCHER: Starting worker discovery
03:51:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:51:40 DISPATCHER: Finished worker discovery
03:52:17 WORKER: done with job (1, 0, 5), trying to register it.
03:52:17 WORKER: registered result for job (1, 0, 5) with dispatcher
03:52:17 DISPATCHER: job (1, 0, 5) finished
03:52:17 DISPATCHER: register_result: lock acquired
03:52:17 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
03:52:17 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 32, 'last_n_outputs': 29, 'lr': 0.0012482703624784716, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.027863641569415207}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.21346352977436456, 'info': {'music_genre': 0.21346352977436456, 'config': "{'batch_size': 64, 'hidden_dim': 32, 'last_n_outputs': 29, 'lr': 0.0012482703624784716, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.027863641569415207}"}}
exception: None

03:52:17 job_callback for (1, 0, 5) started
03:52:17 job_callback for (1, 0, 5) got condition
03:52:17 DISPATCHER: Trying to submit another job.
03:52:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:52:17 HBMASTER: Trying to run another job!
03:52:17 job_callback for (1, 0, 5) finished
03:52:17 start sampling a new configuration.
03:52:17 best_vector: [1, 0.10191931320307157, 0.3003359014291926, 0.1998196222323588, 0.10092837989648078, 0, 0.2023972398925133, 0.26744573457607074], 5.064437020128497e-05, 95.2696406496892, 0.004824870950006247
03:52:17 done sampling a new configuration.
03:52:17 HBMASTER: schedule new run for iteration 1
03:52:17 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
03:52:17 HBMASTER: submitting job (1, 0, 6) to dispatcher
03:52:17 DISPATCHER: trying to submit job (1, 0, 6)
03:52:17 DISPATCHER: trying to notify the job_runner thread.
03:52:17 HBMASTER: job (1, 0, 6) submitted to dispatcher
03:52:17 DISPATCHER: Trying to submit another job.
03:52:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:52:17 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:52:17 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:52:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:52:17 WORKER: start processing job (1, 0, 6)
03:52:17 WORKER: args: ()
03:52:17 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 28, 'last_n_outputs': 16, 'lr': 0.002509800748386812, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.02228203863369726}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:52:40 DISPATCHER: Starting worker discovery
03:52:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:52:40 DISPATCHER: Finished worker discovery
Exception in thread Thread-452:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:53:40 DISPATCHER: Starting worker discovery
03:53:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:53:40 DISPATCHER: Finished worker discovery
03:54:40 DISPATCHER: Starting worker discovery
03:54:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:54:40 DISPATCHER: Finished worker discovery
03:55:23 WORKER: done with job (1, 0, 6), trying to register it.
03:55:23 WORKER: registered result for job (1, 0, 6) with dispatcher
03:55:23 DISPATCHER: job (1, 0, 6) finished
03:55:23 DISPATCHER: register_result: lock acquired
03:55:23 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
03:55:23 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 28, 'last_n_outputs': 16, 'lr': 0.002509800748386812, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.02228203863369726}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.20320557327420383, 'info': {'music_genre': 0.20320557327420383, 'config': "{'batch_size': 32, 'hidden_dim': 28, 'last_n_outputs': 16, 'lr': 0.002509800748386812, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.02228203863369726}"}}
exception: None

03:55:23 job_callback for (1, 0, 6) started
03:55:23 job_callback for (1, 0, 6) got condition
03:55:23 DISPATCHER: Trying to submit another job.
03:55:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:55:23 HBMASTER: Trying to run another job!
03:55:23 job_callback for (1, 0, 6) finished
03:55:23 start sampling a new configuration.
03:55:24 best_vector: [0, 0.15149426000938393, 0.45265934330253915, 0.3953127699093175, 0.10081792174600418, 0, 0.2355117331568126, 0.8510649584814863], 9.437371136915039e-05, 125.12021258489179, 0.011808058828933316
03:55:24 done sampling a new configuration.
03:55:24 HBMASTER: schedule new run for iteration 1
03:55:24 HBMASTER: trying submitting job (1, 0, 7) to dispatcher
03:55:24 HBMASTER: submitting job (1, 0, 7) to dispatcher
03:55:24 DISPATCHER: trying to submit job (1, 0, 7)
03:55:24 DISPATCHER: trying to notify the job_runner thread.
03:55:24 HBMASTER: job (1, 0, 7) submitted to dispatcher
03:55:24 DISPATCHER: Trying to submit another job.
03:55:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:55:24 DISPATCHER: starting job (1, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:55:24 DISPATCHER: job (1, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:55:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:55:24 WORKER: start processing job (1, 0, 7)
03:55:24 WORKER: args: ()
03:55:24 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 32, 'last_n_outputs': 23, 'lr': 0.006174837597244175, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.12801505267232322}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:55:40 DISPATCHER: Starting worker discovery
03:55:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:55:40 DISPATCHER: Finished worker discovery
Exception in thread Thread-453:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:56:40 DISPATCHER: Starting worker discovery
03:56:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:56:40 DISPATCHER: Finished worker discovery
03:57:40 DISPATCHER: Starting worker discovery
03:57:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:57:40 DISPATCHER: Finished worker discovery
03:58:28 WORKER: done with job (1, 0, 7), trying to register it.
03:58:28 WORKER: registered result for job (1, 0, 7) with dispatcher
03:58:28 DISPATCHER: job (1, 0, 7) finished
03:58:28 DISPATCHER: register_result: lock acquired
03:58:28 DISPATCHER: job (1, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
03:58:28 job_id: (1, 0, 7)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 32, 'last_n_outputs': 23, 'lr': 0.006174837597244175, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.12801505267232322}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.12713910024427322, 'info': {'music_genre': 0.12713910024427322, 'config': "{'batch_size': 16, 'hidden_dim': 32, 'last_n_outputs': 23, 'lr': 0.006174837597244175, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.12801505267232322}"}}
exception: None

03:58:28 job_callback for (1, 0, 7) started
03:58:28 DISPATCHER: Trying to submit another job.
03:58:28 job_callback for (1, 0, 7) got condition
03:58:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:58:28 HBMASTER: Trying to run another job!
03:58:28 job_callback for (1, 0, 7) finished
03:58:28 start sampling a new configuration.
03:58:28 done sampling a new configuration.
03:58:28 HBMASTER: schedule new run for iteration 1
03:58:28 HBMASTER: trying submitting job (1, 0, 8) to dispatcher
03:58:28 HBMASTER: submitting job (1, 0, 8) to dispatcher
03:58:28 DISPATCHER: trying to submit job (1, 0, 8)
03:58:28 DISPATCHER: trying to notify the job_runner thread.
03:58:28 HBMASTER: job (1, 0, 8) submitted to dispatcher
03:58:28 DISPATCHER: Trying to submit another job.
03:58:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:58:28 DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:58:28 DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:58:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:58:28 WORKER: start processing job (1, 0, 8)
03:58:28 WORKER: args: ()
03:58:28 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 41, 'lr': 0.012177936440078443, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.010201463296021087}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:58:40 DISPATCHER: Starting worker discovery
03:58:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:58:40 DISPATCHER: Finished worker discovery
Exception in thread Thread-454:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:59:40 DISPATCHER: Starting worker discovery
03:59:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:59:40 DISPATCHER: Finished worker discovery
04:00:40 DISPATCHER: Starting worker discovery
04:00:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:00:40 DISPATCHER: Finished worker discovery
04:01:32 WORKER: done with job (1, 0, 8), trying to register it.
04:01:32 WORKER: registered result for job (1, 0, 8) with dispatcher
04:01:32 DISPATCHER: job (1, 0, 8) finished
04:01:32 DISPATCHER: register_result: lock acquired
04:01:32 DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
04:01:32 job_id: (1, 0, 8)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 41, 'lr': 0.012177936440078443, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.010201463296021087}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 41, 'lr': 0.012177936440078443, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.010201463296021087}"}}
exception: None

04:01:32 job_callback for (1, 0, 8) started
04:01:32 DISPATCHER: Trying to submit another job.
04:01:32 job_callback for (1, 0, 8) got condition
04:01:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:01:32 done building a new model for budget 133.333333 based on 9/15 split
Best loss for this budget:-0.296284





04:01:32 HBMASTER: Trying to run another job!
04:01:32 job_callback for (1, 0, 8) finished
04:01:32 ITERATION: Advancing config (1, 0, 4) to next budget 400.000000
04:01:32 ITERATION: Advancing config (1, 0, 5) to next budget 400.000000
04:01:32 ITERATION: Advancing config (1, 0, 6) to next budget 400.000000
04:01:32 HBMASTER: schedule new run for iteration 1
04:01:32 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
04:01:32 HBMASTER: submitting job (1, 0, 4) to dispatcher
04:01:32 DISPATCHER: trying to submit job (1, 0, 4)
04:01:32 DISPATCHER: trying to notify the job_runner thread.
04:01:32 HBMASTER: job (1, 0, 4) submitted to dispatcher
04:01:32 DISPATCHER: Trying to submit another job.
04:01:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:01:32 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:01:32 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:01:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:01:32 WORKER: start processing job (1, 0, 4)
04:01:32 WORKER: args: ()
04:01:32 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 27, 'last_n_outputs': 23, 'lr': 0.002573194471050847, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.1452776787673177}, 'budget': 400.0, 'working_directory': '.'}
04:01:40 DISPATCHER: Starting worker discovery
04:01:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:01:40 DISPATCHER: Finished worker discovery
Exception in thread Thread-455:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:02:40 DISPATCHER: Starting worker discovery
04:02:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:02:40 DISPATCHER: Finished worker discovery
04:03:40 DISPATCHER: Starting worker discovery
04:03:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:03:40 DISPATCHER: Finished worker discovery
04:04:40 DISPATCHER: Starting worker discovery
04:04:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:04:40 DISPATCHER: Finished worker discovery
04:05:40 DISPATCHER: Starting worker discovery
04:05:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:05:40 DISPATCHER: Finished worker discovery
04:06:40 DISPATCHER: Starting worker discovery
04:06:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:06:40 DISPATCHER: Finished worker discovery
04:07:40 DISPATCHER: Starting worker discovery
04:07:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:07:40 DISPATCHER: Finished worker discovery
04:08:40 DISPATCHER: Starting worker discovery
04:08:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:08:40 DISPATCHER: Finished worker discovery
04:09:05 WORKER: done with job (1, 0, 4), trying to register it.
04:09:05 WORKER: registered result for job (1, 0, 4) with dispatcher
04:09:05 DISPATCHER: job (1, 0, 4) finished
04:09:05 DISPATCHER: register_result: lock acquired
04:09:05 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
04:09:05 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 27, 'last_n_outputs': 23, 'lr': 0.002573194471050847, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.1452776787673177}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.2605992895272718, 'info': {'music_genre': 0.2605992895272718, 'config': "{'batch_size': 32, 'hidden_dim': 27, 'last_n_outputs': 23, 'lr': 0.002573194471050847, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.1452776787673177}"}}
exception: None

04:09:05 job_callback for (1, 0, 4) started
04:09:05 DISPATCHER: Trying to submit another job.
04:09:05 job_callback for (1, 0, 4) got condition
04:09:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:09:05 Only 4 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
04:09:05 HBMASTER: Trying to run another job!
04:09:05 job_callback for (1, 0, 4) finished
04:09:05 HBMASTER: schedule new run for iteration 1
04:09:05 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
04:09:05 HBMASTER: submitting job (1, 0, 5) to dispatcher
04:09:05 DISPATCHER: trying to submit job (1, 0, 5)
04:09:05 DISPATCHER: trying to notify the job_runner thread.
04:09:05 HBMASTER: job (1, 0, 5) submitted to dispatcher
04:09:05 DISPATCHER: Trying to submit another job.
04:09:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:09:05 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:09:05 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:09:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:09:05 WORKER: start processing job (1, 0, 5)
04:09:05 WORKER: args: ()
04:09:05 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 32, 'last_n_outputs': 29, 'lr': 0.0012482703624784716, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.027863641569415207}, 'budget': 400.0, 'working_directory': '.'}
04:09:40 DISPATCHER: Starting worker discovery
04:09:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:09:40 DISPATCHER: Finished worker discovery
Exception in thread Thread-456:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:10:40 DISPATCHER: Starting worker discovery
04:10:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:10:40 DISPATCHER: Finished worker discovery
04:11:40 DISPATCHER: Starting worker discovery
04:11:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:11:40 DISPATCHER: Finished worker discovery
04:12:40 DISPATCHER: Starting worker discovery
04:12:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:12:40 DISPATCHER: Finished worker discovery
04:13:40 DISPATCHER: Starting worker discovery
04:13:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:13:40 DISPATCHER: Finished worker discovery
04:14:40 DISPATCHER: Starting worker discovery
04:14:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:14:40 DISPATCHER: Finished worker discovery
04:15:40 DISPATCHER: Starting worker discovery
04:15:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:15:40 DISPATCHER: Finished worker discovery
04:16:37 WORKER: done with job (1, 0, 5), trying to register it.
04:16:37 WORKER: registered result for job (1, 0, 5) with dispatcher
04:16:37 DISPATCHER: job (1, 0, 5) finished
04:16:37 DISPATCHER: register_result: lock acquired
04:16:37 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
04:16:37 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 32, 'last_n_outputs': 29, 'lr': 0.0012482703624784716, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.027863641569415207}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.2509738506297199, 'info': {'music_genre': 0.2509738506297199, 'config': "{'batch_size': 64, 'hidden_dim': 32, 'last_n_outputs': 29, 'lr': 0.0012482703624784716, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.027863641569415207}"}}
exception: None

04:16:37 job_callback for (1, 0, 5) started
04:16:37 job_callback for (1, 0, 5) got condition
04:16:37 DISPATCHER: Trying to submit another job.
04:16:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:16:37 Only 5 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
04:16:37 HBMASTER: Trying to run another job!
04:16:37 job_callback for (1, 0, 5) finished
04:16:37 HBMASTER: schedule new run for iteration 1
04:16:37 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
04:16:37 HBMASTER: submitting job (1, 0, 6) to dispatcher
04:16:37 DISPATCHER: trying to submit job (1, 0, 6)
04:16:37 DISPATCHER: trying to notify the job_runner thread.
04:16:37 HBMASTER: job (1, 0, 6) submitted to dispatcher
04:16:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:16:37 DISPATCHER: Trying to submit another job.
04:16:37 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:16:37 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:16:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:16:37 WORKER: start processing job (1, 0, 6)
04:16:37 WORKER: args: ()
04:16:37 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 28, 'last_n_outputs': 16, 'lr': 0.002509800748386812, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.02228203863369726}, 'budget': 400.0, 'working_directory': '.'}
04:16:40 DISPATCHER: Starting worker discovery
04:16:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:16:40 DISPATCHER: Finished worker discovery
Exception in thread Thread-457:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:17:40 DISPATCHER: Starting worker discovery
04:17:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:17:40 DISPATCHER: Finished worker discovery
04:18:40 DISPATCHER: Starting worker discovery
04:18:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:18:40 DISPATCHER: Finished worker discovery
04:19:40 DISPATCHER: Starting worker discovery
04:19:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:19:40 DISPATCHER: Finished worker discovery
04:20:40 DISPATCHER: Starting worker discovery
04:20:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:20:40 DISPATCHER: Finished worker discovery
04:21:40 DISPATCHER: Starting worker discovery
04:21:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:21:40 DISPATCHER: Finished worker discovery
04:22:40 DISPATCHER: Starting worker discovery
04:22:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:22:40 DISPATCHER: Finished worker discovery
04:23:40 DISPATCHER: Starting worker discovery
04:23:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:23:40 DISPATCHER: Finished worker discovery
04:24:09 WORKER: done with job (1, 0, 6), trying to register it.
04:24:09 WORKER: registered result for job (1, 0, 6) with dispatcher
04:24:09 DISPATCHER: job (1, 0, 6) finished
04:24:09 DISPATCHER: register_result: lock acquired
04:24:09 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
04:24:09 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 28, 'last_n_outputs': 16, 'lr': 0.002509800748386812, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.02228203863369726}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.18177539701476628, 'info': {'music_genre': 0.18177539701476628, 'config': "{'batch_size': 32, 'hidden_dim': 28, 'last_n_outputs': 16, 'lr': 0.002509800748386812, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.02228203863369726}"}}
exception: None

04:24:09 job_callback for (1, 0, 6) started
04:24:09 job_callback for (1, 0, 6) got condition
04:24:09 DISPATCHER: Trying to submit another job.
04:24:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:24:09 Only 6 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
04:24:09 HBMASTER: Trying to run another job!
04:24:09 job_callback for (1, 0, 6) finished
04:24:09 ITERATION: Advancing config (1, 0, 4) to next budget 1200.000000
04:24:09 HBMASTER: schedule new run for iteration 1
04:24:09 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
04:24:09 HBMASTER: submitting job (1, 0, 4) to dispatcher
04:24:09 DISPATCHER: trying to submit job (1, 0, 4)
04:24:09 DISPATCHER: trying to notify the job_runner thread.
04:24:09 HBMASTER: job (1, 0, 4) submitted to dispatcher
04:24:09 DISPATCHER: Trying to submit another job.
04:24:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:24:09 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:24:09 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:24:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:24:09 WORKER: start processing job (1, 0, 4)
04:24:09 WORKER: args: ()
04:24:09 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 27, 'last_n_outputs': 23, 'lr': 0.002573194471050847, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.1452776787673177}, 'budget': 1200.0, 'working_directory': '.'}
04:24:40 DISPATCHER: Starting worker discovery
04:24:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:24:40 DISPATCHER: Finished worker discovery
Exception in thread Thread-458:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:25:40 DISPATCHER: Starting worker discovery
04:25:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:25:40 DISPATCHER: Finished worker discovery
04:26:40 DISPATCHER: Starting worker discovery
04:26:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:26:40 DISPATCHER: Finished worker discovery
04:27:40 DISPATCHER: Starting worker discovery
04:27:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:27:40 DISPATCHER: Finished worker discovery
04:28:40 DISPATCHER: Starting worker discovery
04:28:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:28:40 DISPATCHER: Finished worker discovery
04:29:40 DISPATCHER: Starting worker discovery
04:29:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:29:40 DISPATCHER: Finished worker discovery
04:30:40 DISPATCHER: Starting worker discovery
04:30:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:30:40 DISPATCHER: Finished worker discovery
04:31:40 DISPATCHER: Starting worker discovery
04:31:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:31:40 DISPATCHER: Finished worker discovery
04:32:40 DISPATCHER: Starting worker discovery
04:32:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:32:40 DISPATCHER: Finished worker discovery
04:33:40 DISPATCHER: Starting worker discovery
04:33:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:33:40 DISPATCHER: Finished worker discovery
04:34:40 DISPATCHER: Starting worker discovery
04:34:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:34:40 DISPATCHER: Finished worker discovery
04:35:40 DISPATCHER: Starting worker discovery
04:35:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:35:40 DISPATCHER: Finished worker discovery
04:36:40 DISPATCHER: Starting worker discovery
04:36:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:36:40 DISPATCHER: Finished worker discovery
04:37:40 DISPATCHER: Starting worker discovery
04:37:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:37:40 DISPATCHER: Finished worker discovery
04:38:40 DISPATCHER: Starting worker discovery
04:38:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:38:40 DISPATCHER: Finished worker discovery
04:39:40 DISPATCHER: Starting worker discovery
04:39:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:39:40 DISPATCHER: Finished worker discovery
04:40:40 DISPATCHER: Starting worker discovery
04:40:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:40:40 DISPATCHER: Finished worker discovery
04:41:40 DISPATCHER: Starting worker discovery
04:41:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:41:40 DISPATCHER: Finished worker discovery
04:42:40 DISPATCHER: Starting worker discovery
04:42:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:42:40 DISPATCHER: Finished worker discovery
04:43:40 DISPATCHER: Starting worker discovery
04:43:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:43:40 DISPATCHER: Finished worker discovery
04:44:40 DISPATCHER: Starting worker discovery
04:44:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:44:40 DISPATCHER: Finished worker discovery
04:45:02 WORKER: done with job (1, 0, 4), trying to register it.
04:45:02 WORKER: registered result for job (1, 0, 4) with dispatcher
04:45:02 DISPATCHER: job (1, 0, 4) finished
04:45:02 DISPATCHER: register_result: lock acquired
04:45:02 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
04:45:02 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 27, 'last_n_outputs': 23, 'lr': 0.002573194471050847, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.1452776787673177}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.2513115724965156, 'info': {'music_genre': 0.2513115724965156, 'config': "{'batch_size': 32, 'hidden_dim': 27, 'last_n_outputs': 23, 'lr': 0.002573194471050847, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.1452776787673177}"}}
exception: None

04:45:02 job_callback for (1, 0, 4) started
04:45:02 DISPATCHER: Trying to submit another job.
04:45:02 job_callback for (1, 0, 4) got condition
04:45:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:45:02 Only 2 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
04:45:02 HBMASTER: Trying to run another job!
04:45:02 job_callback for (1, 0, 4) finished
04:45:02 start sampling a new configuration.
04:45:02 best_vector: [0, 0.4856155548348693, 0.8738682510511602, 0.27332389644423793, 0.10324497245156461, 0, 0.42379077327461645, 0.5297367053828355], 1.9286278568108994e-32, 0.5185033475838928, -0.0008343098154938563
04:45:02 done sampling a new configuration.
04:45:02 HBMASTER: schedule new run for iteration 2
04:45:02 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
04:45:02 HBMASTER: submitting job (2, 0, 0) to dispatcher
04:45:02 DISPATCHER: trying to submit job (2, 0, 0)
04:45:02 DISPATCHER: trying to notify the job_runner thread.
04:45:02 HBMASTER: job (2, 0, 0) submitted to dispatcher
04:45:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:45:02 DISPATCHER: Trying to submit another job.
04:45:02 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:45:02 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:45:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:45:02 WORKER: start processing job (2, 0, 0)
04:45:02 WORKER: args: ()
04:45:02 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 59, 'last_n_outputs': 44, 'lr': 0.003520852187474198, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.048888120763431166}, 'budget': 400.0, 'working_directory': '.'}
04:45:40 DISPATCHER: Starting worker discovery
04:45:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:45:40 DISPATCHER: Finished worker discovery
Exception in thread Thread-459:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:46:40 DISPATCHER: Starting worker discovery
04:46:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:46:40 DISPATCHER: Finished worker discovery
04:47:40 DISPATCHER: Starting worker discovery
04:47:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:47:40 DISPATCHER: Finished worker discovery
04:48:40 DISPATCHER: Starting worker discovery
04:48:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:48:40 DISPATCHER: Finished worker discovery
04:49:40 DISPATCHER: Starting worker discovery
04:49:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:49:40 DISPATCHER: Finished worker discovery
04:50:40 DISPATCHER: Starting worker discovery
04:50:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:50:40 DISPATCHER: Finished worker discovery
04:51:40 DISPATCHER: Starting worker discovery
04:51:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:51:40 DISPATCHER: Finished worker discovery
04:52:32 WORKER: done with job (2, 0, 0), trying to register it.
04:52:32 WORKER: registered result for job (2, 0, 0) with dispatcher
04:52:32 DISPATCHER: job (2, 0, 0) finished
04:52:32 DISPATCHER: register_result: lock acquired
04:52:32 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
04:52:32 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 59, 'last_n_outputs': 44, 'lr': 0.003520852187474198, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.048888120763431166}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3401271537335187, 'info': {'music_genre': 0.3401271537335187, 'config': "{'batch_size': 16, 'hidden_dim': 59, 'last_n_outputs': 44, 'lr': 0.003520852187474198, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.048888120763431166}"}}
exception: None

04:52:32 job_callback for (2, 0, 0) started
04:52:32 job_callback for (2, 0, 0) got condition
04:52:32 DISPATCHER: Trying to submit another job.
04:52:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:52:32 Only 7 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
04:52:32 HBMASTER: Trying to run another job!
04:52:32 job_callback for (2, 0, 0) finished
04:52:32 start sampling a new configuration.
04:52:32 best_vector: [0, 0.9479181032342332, 0.5100385396973363, 0.144120214636986, 0.09954701636936573, 0, 0.3965951007651806, 0.7719272359846874], 7.992444078351169e-35, 125.11817288889918, -9.439516361179953e-05
04:52:32 done sampling a new configuration.
04:52:32 HBMASTER: schedule new run for iteration 2
04:52:32 HBMASTER: trying submitting job (2, 0, 1) to dispatcher
04:52:32 HBMASTER: submitting job (2, 0, 1) to dispatcher
04:52:32 DISPATCHER: trying to submit job (2, 0, 1)
04:52:32 DISPATCHER: trying to notify the job_runner thread.
04:52:32 HBMASTER: job (2, 0, 1) submitted to dispatcher
04:52:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:52:32 DISPATCHER: Trying to submit another job.
04:52:32 DISPATCHER: starting job (2, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:52:32 DISPATCHER: job (2, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:52:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:52:32 WORKER: start processing job (2, 0, 1)
04:52:32 WORKER: args: ()
04:52:32 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 96, 'last_n_outputs': 26, 'lr': 0.0019419606666940044, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.1009951430093593}, 'budget': 400.0, 'working_directory': '.'}
04:52:40 DISPATCHER: Starting worker discovery
04:52:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:52:40 DISPATCHER: Finished worker discovery
Exception in thread Thread-460:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:53:40 DISPATCHER: Starting worker discovery
04:53:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:53:40 DISPATCHER: Finished worker discovery
04:54:40 DISPATCHER: Starting worker discovery
04:54:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:54:40 DISPATCHER: Finished worker discovery
04:55:40 DISPATCHER: Starting worker discovery
04:55:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:55:40 DISPATCHER: Finished worker discovery
04:56:40 DISPATCHER: Starting worker discovery
04:56:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:56:40 DISPATCHER: Finished worker discovery
04:57:40 DISPATCHER: Starting worker discovery
04:57:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:57:40 DISPATCHER: Finished worker discovery
04:58:40 DISPATCHER: Starting worker discovery
04:58:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:58:40 DISPATCHER: Finished worker discovery
04:59:40 DISPATCHER: Starting worker discovery
04:59:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:59:40 DISPATCHER: Finished worker discovery
05:00:04 WORKER: done with job (2, 0, 1), trying to register it.
05:00:04 WORKER: registered result for job (2, 0, 1) with dispatcher
05:00:04 DISPATCHER: job (2, 0, 1) finished
05:00:04 DISPATCHER: register_result: lock acquired
05:00:04 DISPATCHER: job (2, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
05:00:04 job_id: (2, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 96, 'last_n_outputs': 26, 'lr': 0.0019419606666940044, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.1009951430093593}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.2871674987376189, 'info': {'music_genre': 0.2871674987376189, 'config': "{'batch_size': 16, 'hidden_dim': 96, 'last_n_outputs': 26, 'lr': 0.0019419606666940044, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.1009951430093593}"}}
exception: None

05:00:04 job_callback for (2, 0, 1) started
05:00:04 job_callback for (2, 0, 1) got condition
05:00:04 DISPATCHER: Trying to submit another job.
05:00:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:00:04 Only 8 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
05:00:04 HBMASTER: Trying to run another job!
05:00:04 job_callback for (2, 0, 1) finished
05:00:04 start sampling a new configuration.
05:00:04 done sampling a new configuration.
05:00:04 HBMASTER: schedule new run for iteration 2
05:00:04 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
05:00:04 HBMASTER: submitting job (2, 0, 2) to dispatcher
05:00:04 DISPATCHER: trying to submit job (2, 0, 2)
05:00:04 DISPATCHER: trying to notify the job_runner thread.
05:00:04 HBMASTER: job (2, 0, 2) submitted to dispatcher
05:00:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:00:04 DISPATCHER: Trying to submit another job.
05:00:04 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:00:04 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:00:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:00:04 WORKER: start processing job (2, 0, 2)
05:00:04 WORKER: args: ()
05:00:04 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 1, 'lr': 0.0046842893971279645, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.05562135268957406}, 'budget': 400.0, 'working_directory': '.'}
05:00:40 DISPATCHER: Starting worker discovery
05:00:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:00:40 DISPATCHER: Finished worker discovery
Exception in thread Thread-461:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:01:40 DISPATCHER: Starting worker discovery
05:01:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:01:40 DISPATCHER: Finished worker discovery
05:02:40 DISPATCHER: Starting worker discovery
05:02:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:02:40 DISPATCHER: Finished worker discovery
05:03:40 DISPATCHER: Starting worker discovery
05:03:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:03:40 DISPATCHER: Finished worker discovery
05:04:40 DISPATCHER: Starting worker discovery
05:04:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:04:40 DISPATCHER: Finished worker discovery
05:05:40 DISPATCHER: Starting worker discovery
05:05:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:05:40 DISPATCHER: Finished worker discovery
05:06:40 DISPATCHER: Starting worker discovery
05:06:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:06:40 DISPATCHER: Finished worker discovery
05:07:35 WORKER: done with job (2, 0, 2), trying to register it.
05:07:35 WORKER: registered result for job (2, 0, 2) with dispatcher
05:07:35 DISPATCHER: job (2, 0, 2) finished
05:07:35 DISPATCHER: register_result: lock acquired
05:07:35 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
05:07:35 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 1, 'lr': 0.0046842893971279645, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.05562135268957406}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.23723639391678486, 'info': {'music_genre': 0.23723639391678486, 'config': "{'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 1, 'lr': 0.0046842893971279645, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.05562135268957406}"}}
exception: None

05:07:35 job_callback for (2, 0, 2) started
05:07:35 DISPATCHER: Trying to submit another job.
05:07:35 job_callback for (2, 0, 2) got condition
05:07:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:07:35 HBMASTER: Trying to run another job!
05:07:35 job_callback for (2, 0, 2) finished
05:07:35 start sampling a new configuration.
05:07:35 best_vector: [0, 0.8548756994142046, 0.9078957712345498, 0.5442841138748928, 0.09749172496197607, 0, 0.3352384292395306, 0.6368438478588838], 6.723364660295952e-34, 14.873505313572887, -0.0064297943748531945
05:07:35 done sampling a new configuration.
05:07:35 HBMASTER: schedule new run for iteration 2
05:07:35 HBMASTER: trying submitting job (2, 0, 3) to dispatcher
05:07:35 HBMASTER: submitting job (2, 0, 3) to dispatcher
05:07:35 DISPATCHER: trying to submit job (2, 0, 3)
05:07:35 DISPATCHER: trying to notify the job_runner thread.
05:07:35 HBMASTER: job (2, 0, 3) submitted to dispatcher
05:07:35 DISPATCHER: Trying to submit another job.
05:07:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:07:35 DISPATCHER: starting job (2, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:07:35 DISPATCHER: job (2, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:07:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:07:35 WORKER: start processing job (2, 0, 3)
05:07:35 WORKER: args: ()
05:07:35 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 89, 'last_n_outputs': 46, 'lr': 0.012262195268792854, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.0673834043433116}, 'budget': 400.0, 'working_directory': '.'}
05:07:40 DISPATCHER: Starting worker discovery
05:07:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:07:40 DISPATCHER: Finished worker discovery
Exception in thread Thread-462:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:08:40 DISPATCHER: Starting worker discovery
05:08:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:08:40 DISPATCHER: Finished worker discovery
05:09:40 DISPATCHER: Starting worker discovery
05:09:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:09:40 DISPATCHER: Finished worker discovery
05:10:40 DISPATCHER: Starting worker discovery
05:10:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:10:40 DISPATCHER: Finished worker discovery
05:11:40 DISPATCHER: Starting worker discovery
05:11:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:11:40 DISPATCHER: Finished worker discovery
05:12:40 DISPATCHER: Starting worker discovery
05:12:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:12:40 DISPATCHER: Finished worker discovery
05:13:40 DISPATCHER: Starting worker discovery
05:13:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:13:40 DISPATCHER: Finished worker discovery
05:14:40 DISPATCHER: Starting worker discovery
05:14:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:14:40 DISPATCHER: Finished worker discovery
05:15:05 WORKER: done with job (2, 0, 3), trying to register it.
05:15:05 WORKER: registered result for job (2, 0, 3) with dispatcher
05:15:05 DISPATCHER: job (2, 0, 3) finished
05:15:05 DISPATCHER: register_result: lock acquired
05:15:05 DISPATCHER: job (2, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
05:15:05 job_id: (2, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 89, 'last_n_outputs': 46, 'lr': 0.012262195268792854, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.0673834043433116}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.13234137955109093, 'info': {'music_genre': 0.13234137955109093, 'config': "{'batch_size': 16, 'hidden_dim': 89, 'last_n_outputs': 46, 'lr': 0.012262195268792854, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.0673834043433116}"}}
exception: None

05:15:05 job_callback for (2, 0, 3) started
05:15:05 DISPATCHER: Trying to submit another job.
05:15:05 job_callback for (2, 0, 3) got condition
05:15:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:15:05 HBMASTER: Trying to run another job!
05:15:05 job_callback for (2, 0, 3) finished
05:15:05 start sampling a new configuration.
05:15:05 best_vector: [1, 0.31598410047400294, 0.39285500274207397, 0.08868729098545801, 0.09914673984605375, 0, 0.03748879853098076, 0.017363669379693802], 1.8642052458059225e-35, 536.4216210901637, -0.016344904770535296
05:15:05 done sampling a new configuration.
05:15:06 HBMASTER: schedule new run for iteration 2
05:15:06 HBMASTER: trying submitting job (2, 0, 4) to dispatcher
05:15:06 HBMASTER: submitting job (2, 0, 4) to dispatcher
05:15:06 DISPATCHER: trying to submit job (2, 0, 4)
05:15:06 DISPATCHER: trying to notify the job_runner thread.
05:15:06 HBMASTER: job (2, 0, 4) submitted to dispatcher
05:15:06 DISPATCHER: Trying to submit another job.
05:15:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:15:06 DISPATCHER: starting job (2, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:15:06 DISPATCHER: job (2, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:15:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:15:06 WORKER: start processing job (2, 0, 4)
05:15:06 WORKER: args: ()
05:15:06 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 45, 'last_n_outputs': 20, 'lr': 0.0015044389956188674, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.010533935497154284}, 'budget': 400.0, 'working_directory': '.'}
05:15:40 DISPATCHER: Starting worker discovery
05:15:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:15:40 DISPATCHER: Finished worker discovery
Exception in thread Thread-463:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:16:40 DISPATCHER: Starting worker discovery
05:16:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:16:40 DISPATCHER: Finished worker discovery
05:17:40 DISPATCHER: Starting worker discovery
05:17:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:17:40 DISPATCHER: Finished worker discovery
05:18:40 DISPATCHER: Starting worker discovery
05:18:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:18:40 DISPATCHER: Finished worker discovery
05:19:40 DISPATCHER: Starting worker discovery
05:19:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:19:40 DISPATCHER: Finished worker discovery
05:20:40 DISPATCHER: Starting worker discovery
05:20:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:20:40 DISPATCHER: Finished worker discovery
05:21:40 DISPATCHER: Starting worker discovery
05:21:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:21:41 DISPATCHER: Finished worker discovery
05:22:36 WORKER: done with job (2, 0, 4), trying to register it.
05:22:36 WORKER: registered result for job (2, 0, 4) with dispatcher
05:22:36 DISPATCHER: job (2, 0, 4) finished
05:22:36 DISPATCHER: register_result: lock acquired
05:22:36 DISPATCHER: job (2, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
05:22:36 job_id: (2, 0, 4)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 45, 'last_n_outputs': 20, 'lr': 0.0015044389956188674, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.010533935497154284}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.21183874244479542, 'info': {'music_genre': 0.21183874244479542, 'config': "{'batch_size': 32, 'hidden_dim': 45, 'last_n_outputs': 20, 'lr': 0.0015044389956188674, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.010533935497154284}"}}
exception: None

05:22:36 job_callback for (2, 0, 4) started
05:22:36 job_callback for (2, 0, 4) got condition
05:22:36 DISPATCHER: Trying to submit another job.
05:22:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:22:36 HBMASTER: Trying to run another job!
05:22:36 job_callback for (2, 0, 4) finished
05:22:36 start sampling a new configuration.
05:22:36 best_vector: [0, 0.39422578683266496, 0.5544265568528574, 0.8122808720334258, 0.10135425652865247, 0, 0.2582097749734745, 0.5888390870162831], 3.1905702223479754e-33, 3.1342359838865703, -0.004980818455769276
05:22:36 done sampling a new configuration.
05:22:36 HBMASTER: schedule new run for iteration 2
05:22:36 HBMASTER: trying submitting job (2, 0, 5) to dispatcher
05:22:36 HBMASTER: submitting job (2, 0, 5) to dispatcher
05:22:36 DISPATCHER: trying to submit job (2, 0, 5)
05:22:36 DISPATCHER: trying to notify the job_runner thread.
05:22:36 HBMASTER: job (2, 0, 5) submitted to dispatcher
05:22:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:22:36 DISPATCHER: Trying to submit another job.
05:22:36 DISPATCHER: starting job (2, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:22:36 DISPATCHER: job (2, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:22:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:22:36 WORKER: start processing job (2, 0, 5)
05:22:36 WORKER: args: ()
05:22:36 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 51, 'last_n_outputs': 28, 'lr': 0.042127117502748675, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 33, 'weight_decay': 0.058357585477561175}, 'budget': 400.0, 'working_directory': '.'}
05:22:41 DISPATCHER: Starting worker discovery
05:22:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:22:41 DISPATCHER: Finished worker discovery
Exception in thread Thread-464:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:23:41 DISPATCHER: Starting worker discovery
05:23:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:23:41 DISPATCHER: Finished worker discovery
05:24:41 DISPATCHER: Starting worker discovery
05:24:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:24:41 DISPATCHER: Finished worker discovery
05:25:41 DISPATCHER: Starting worker discovery
05:25:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:25:41 DISPATCHER: Finished worker discovery
05:26:41 DISPATCHER: Starting worker discovery
05:26:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:26:41 DISPATCHER: Finished worker discovery
05:27:41 DISPATCHER: Starting worker discovery
05:27:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:27:41 DISPATCHER: Finished worker discovery
05:28:41 DISPATCHER: Starting worker discovery
05:28:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:28:41 DISPATCHER: Finished worker discovery
05:29:41 DISPATCHER: Starting worker discovery
05:29:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:29:41 DISPATCHER: Finished worker discovery
05:30:07 WORKER: done with job (2, 0, 5), trying to register it.
05:30:07 WORKER: registered result for job (2, 0, 5) with dispatcher
05:30:07 DISPATCHER: job (2, 0, 5) finished
05:30:07 DISPATCHER: register_result: lock acquired
05:30:07 DISPATCHER: job (2, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
05:30:07 job_id: (2, 0, 5)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 51, 'last_n_outputs': 28, 'lr': 0.042127117502748675, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 33, 'weight_decay': 0.058357585477561175}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.034500779768252936, 'info': {'music_genre': 0.034500779768252936, 'config': "{'batch_size': 16, 'hidden_dim': 51, 'last_n_outputs': 28, 'lr': 0.042127117502748675, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 33, 'weight_decay': 0.058357585477561175}"}}
exception: None

05:30:07 job_callback for (2, 0, 5) started
05:30:07 DISPATCHER: Trying to submit another job.
05:30:07 job_callback for (2, 0, 5) got condition
05:30:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:30:07 HBMASTER: Trying to run another job!
05:30:07 job_callback for (2, 0, 5) finished
05:30:07 ITERATION: Advancing config (2, 0, 0) to next budget 1200.000000
05:30:07 ITERATION: Advancing config (2, 0, 1) to next budget 1200.000000
05:30:07 HBMASTER: schedule new run for iteration 2
05:30:07 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
05:30:07 HBMASTER: submitting job (2, 0, 0) to dispatcher
05:30:07 DISPATCHER: trying to submit job (2, 0, 0)
05:30:07 DISPATCHER: trying to notify the job_runner thread.
05:30:07 HBMASTER: job (2, 0, 0) submitted to dispatcher
05:30:07 DISPATCHER: Trying to submit another job.
05:30:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:30:07 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:30:07 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:30:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:30:07 WORKER: start processing job (2, 0, 0)
05:30:07 WORKER: args: ()
05:30:07 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 59, 'last_n_outputs': 44, 'lr': 0.003520852187474198, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.048888120763431166}, 'budget': 1200.0, 'working_directory': '.'}
05:30:41 DISPATCHER: Starting worker discovery
05:30:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:30:41 DISPATCHER: Finished worker discovery
Exception in thread Thread-465:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:31:41 DISPATCHER: Starting worker discovery
05:31:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:31:41 DISPATCHER: Finished worker discovery
05:32:41 DISPATCHER: Starting worker discovery
05:32:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:32:41 DISPATCHER: Finished worker discovery
05:33:41 DISPATCHER: Starting worker discovery
05:33:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:33:41 DISPATCHER: Finished worker discovery
05:34:41 DISPATCHER: Starting worker discovery
05:34:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:34:41 DISPATCHER: Finished worker discovery
05:35:41 DISPATCHER: Starting worker discovery
05:35:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:35:41 DISPATCHER: Finished worker discovery
05:36:41 DISPATCHER: Starting worker discovery
05:36:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:36:41 DISPATCHER: Finished worker discovery
05:37:41 DISPATCHER: Starting worker discovery
05:37:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:37:41 DISPATCHER: Finished worker discovery
05:38:41 DISPATCHER: Starting worker discovery
05:38:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:38:41 DISPATCHER: Finished worker discovery
05:39:41 DISPATCHER: Starting worker discovery
05:39:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:39:41 DISPATCHER: Finished worker discovery
05:40:41 DISPATCHER: Starting worker discovery
05:40:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:40:41 DISPATCHER: Finished worker discovery
05:41:41 DISPATCHER: Starting worker discovery
05:41:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:41:41 DISPATCHER: Finished worker discovery
05:42:41 DISPATCHER: Starting worker discovery
05:42:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:42:41 DISPATCHER: Finished worker discovery
05:43:41 DISPATCHER: Starting worker discovery
05:43:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:43:41 DISPATCHER: Finished worker discovery
05:44:41 DISPATCHER: Starting worker discovery
05:44:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:44:41 DISPATCHER: Finished worker discovery
05:45:41 DISPATCHER: Starting worker discovery
05:45:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:45:41 DISPATCHER: Finished worker discovery
05:46:41 DISPATCHER: Starting worker discovery
05:46:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:46:41 DISPATCHER: Finished worker discovery
05:47:41 DISPATCHER: Starting worker discovery
05:47:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:47:41 DISPATCHER: Finished worker discovery
05:48:41 DISPATCHER: Starting worker discovery
05:48:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:48:41 DISPATCHER: Finished worker discovery
05:49:41 DISPATCHER: Starting worker discovery
05:49:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:49:41 DISPATCHER: Finished worker discovery
05:50:41 DISPATCHER: Starting worker discovery
05:50:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:50:41 DISPATCHER: Finished worker discovery
05:50:58 WORKER: done with job (2, 0, 0), trying to register it.
05:50:58 WORKER: registered result for job (2, 0, 0) with dispatcher
05:50:58 DISPATCHER: job (2, 0, 0) finished
05:50:58 DISPATCHER: register_result: lock acquired
05:50:58 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
05:50:58 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 59, 'last_n_outputs': 44, 'lr': 0.003520852187474198, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.048888120763431166}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.2381748473419504, 'info': {'music_genre': 0.2381748473419504, 'config': "{'batch_size': 16, 'hidden_dim': 59, 'last_n_outputs': 44, 'lr': 0.003520852187474198, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.048888120763431166}"}}
exception: None

05:50:58 job_callback for (2, 0, 0) started
05:50:58 DISPATCHER: Trying to submit another job.
05:50:58 job_callback for (2, 0, 0) got condition
05:50:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:50:58 Only 3 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
05:50:58 HBMASTER: Trying to run another job!
05:50:58 job_callback for (2, 0, 0) finished
05:50:58 HBMASTER: schedule new run for iteration 2
05:50:58 HBMASTER: trying submitting job (2, 0, 1) to dispatcher
05:50:58 HBMASTER: submitting job (2, 0, 1) to dispatcher
05:50:58 DISPATCHER: trying to submit job (2, 0, 1)
05:50:58 DISPATCHER: trying to notify the job_runner thread.
05:50:58 HBMASTER: job (2, 0, 1) submitted to dispatcher
05:50:58 DISPATCHER: Trying to submit another job.
05:50:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:50:58 DISPATCHER: starting job (2, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:50:58 DISPATCHER: job (2, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:50:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:50:58 WORKER: start processing job (2, 0, 1)
05:50:58 WORKER: args: ()
05:50:58 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 96, 'last_n_outputs': 26, 'lr': 0.0019419606666940044, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.1009951430093593}, 'budget': 1200.0, 'working_directory': '.'}
05:51:41 DISPATCHER: Starting worker discovery
05:51:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:51:41 DISPATCHER: Finished worker discovery
Exception in thread Thread-466:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:52:41 DISPATCHER: Starting worker discovery
05:52:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:52:41 DISPATCHER: Finished worker discovery
05:53:41 DISPATCHER: Starting worker discovery
05:53:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:53:41 DISPATCHER: Finished worker discovery
05:54:41 DISPATCHER: Starting worker discovery
05:54:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:54:41 DISPATCHER: Finished worker discovery
05:55:41 DISPATCHER: Starting worker discovery
05:55:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:55:41 DISPATCHER: Finished worker discovery
05:56:41 DISPATCHER: Starting worker discovery
05:56:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:56:41 DISPATCHER: Finished worker discovery
05:57:41 DISPATCHER: Starting worker discovery
05:57:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:57:41 DISPATCHER: Finished worker discovery
05:58:41 DISPATCHER: Starting worker discovery
05:58:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:58:41 DISPATCHER: Finished worker discovery
05:59:41 DISPATCHER: Starting worker discovery
05:59:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:59:41 DISPATCHER: Finished worker discovery
06:00:41 DISPATCHER: Starting worker discovery
06:00:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:00:41 DISPATCHER: Finished worker discovery
06:01:41 DISPATCHER: Starting worker discovery
06:01:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:01:41 DISPATCHER: Finished worker discovery
06:02:41 DISPATCHER: Starting worker discovery
06:02:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:02:41 DISPATCHER: Finished worker discovery
06:03:41 DISPATCHER: Starting worker discovery
06:03:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:03:41 DISPATCHER: Finished worker discovery
06:04:41 DISPATCHER: Starting worker discovery
06:04:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:04:41 DISPATCHER: Finished worker discovery
06:05:41 DISPATCHER: Starting worker discovery
06:05:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:05:41 DISPATCHER: Finished worker discovery
06:06:41 DISPATCHER: Starting worker discovery
06:06:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:06:41 DISPATCHER: Finished worker discovery
06:07:41 DISPATCHER: Starting worker discovery
06:07:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:07:41 DISPATCHER: Finished worker discovery
06:08:41 DISPATCHER: Starting worker discovery
06:08:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:08:41 DISPATCHER: Finished worker discovery
06:09:41 DISPATCHER: Starting worker discovery
06:09:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:09:41 DISPATCHER: Finished worker discovery
06:10:41 DISPATCHER: Starting worker discovery
06:10:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:10:41 DISPATCHER: Finished worker discovery
06:11:41 DISPATCHER: Starting worker discovery
06:11:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:11:41 DISPATCHER: Finished worker discovery
06:11:51 WORKER: done with job (2, 0, 1), trying to register it.
06:11:51 WORKER: registered result for job (2, 0, 1) with dispatcher
06:11:51 DISPATCHER: job (2, 0, 1) finished
06:11:51 DISPATCHER: register_result: lock acquired
06:11:51 DISPATCHER: job (2, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
06:11:51 job_id: (2, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 96, 'last_n_outputs': 26, 'lr': 0.0019419606666940044, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.1009951430093593}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.24564936230438558, 'info': {'music_genre': 0.24564936230438558, 'config': "{'batch_size': 16, 'hidden_dim': 96, 'last_n_outputs': 26, 'lr': 0.0019419606666940044, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.1009951430093593}"}}
exception: None

06:11:51 job_callback for (2, 0, 1) started
06:11:51 DISPATCHER: Trying to submit another job.
06:11:51 job_callback for (2, 0, 1) got condition
06:11:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:11:51 Only 4 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
06:11:51 HBMASTER: Trying to run another job!
06:11:51 job_callback for (2, 0, 1) finished
06:11:51 start sampling a new configuration.
06:11:51 done sampling a new configuration.
06:11:51 HBMASTER: schedule new run for iteration 3
06:11:51 HBMASTER: trying submitting job (3, 0, 0) to dispatcher
06:11:51 HBMASTER: submitting job (3, 0, 0) to dispatcher
06:11:51 DISPATCHER: trying to submit job (3, 0, 0)
06:11:51 DISPATCHER: trying to notify the job_runner thread.
06:11:51 HBMASTER: job (3, 0, 0) submitted to dispatcher
06:11:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:11:51 DISPATCHER: Trying to submit another job.
06:11:51 DISPATCHER: starting job (3, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
06:11:51 DISPATCHER: job (3, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
06:11:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:11:51 WORKER: start processing job (3, 0, 0)
06:11:51 WORKER: args: ()
06:11:51 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 44, 'last_n_outputs': 30, 'lr': 0.04987710115520406, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.08361959463027858}, 'budget': 1200.0, 'working_directory': '.'}
06:12:41 DISPATCHER: Starting worker discovery
06:12:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:12:41 DISPATCHER: Finished worker discovery
Exception in thread Thread-467:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:13:41 DISPATCHER: Starting worker discovery
06:13:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:13:41 DISPATCHER: Finished worker discovery
06:14:41 DISPATCHER: Starting worker discovery
06:14:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:14:41 DISPATCHER: Finished worker discovery
06:15:41 DISPATCHER: Starting worker discovery
06:15:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:15:41 DISPATCHER: Finished worker discovery
06:16:41 DISPATCHER: Starting worker discovery
06:16:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:16:41 DISPATCHER: Finished worker discovery
06:17:41 DISPATCHER: Starting worker discovery
06:17:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:17:41 DISPATCHER: Finished worker discovery
06:18:41 DISPATCHER: Starting worker discovery
06:18:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:18:41 DISPATCHER: Finished worker discovery
06:19:41 DISPATCHER: Starting worker discovery
06:19:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:19:41 DISPATCHER: Finished worker discovery
06:20:41 DISPATCHER: Starting worker discovery
06:20:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:20:41 DISPATCHER: Finished worker discovery
06:21:41 DISPATCHER: Starting worker discovery
06:21:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:21:41 DISPATCHER: Finished worker discovery
06:22:41 DISPATCHER: Starting worker discovery
06:22:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:22:41 DISPATCHER: Finished worker discovery
06:23:41 DISPATCHER: Starting worker discovery
06:23:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:23:41 DISPATCHER: Finished worker discovery
06:24:41 DISPATCHER: Starting worker discovery
06:24:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:24:41 DISPATCHER: Finished worker discovery
06:25:41 DISPATCHER: Starting worker discovery
06:25:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:25:41 DISPATCHER: Finished worker discovery
06:26:41 DISPATCHER: Starting worker discovery
06:26:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:26:41 DISPATCHER: Finished worker discovery
06:27:41 DISPATCHER: Starting worker discovery
06:27:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:27:41 DISPATCHER: Finished worker discovery
06:28:41 DISPATCHER: Starting worker discovery
06:28:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:28:41 DISPATCHER: Finished worker discovery
06:29:41 DISPATCHER: Starting worker discovery
06:29:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:29:41 DISPATCHER: Finished worker discovery
06:30:41 DISPATCHER: Starting worker discovery
06:30:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:30:41 DISPATCHER: Finished worker discovery
06:31:41 DISPATCHER: Starting worker discovery
06:31:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:31:41 DISPATCHER: Finished worker discovery
06:32:41 DISPATCHER: Starting worker discovery
06:32:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:32:41 DISPATCHER: Finished worker discovery
06:32:43 WORKER: done with job (3, 0, 0), trying to register it.
06:32:43 WORKER: registered result for job (3, 0, 0) with dispatcher
06:32:43 DISPATCHER: job (3, 0, 0) finished
06:32:43 DISPATCHER: register_result: lock acquired
06:32:43 DISPATCHER: job (3, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
06:32:43 job_id: (3, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 44, 'last_n_outputs': 30, 'lr': 0.04987710115520406, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.08361959463027858}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 44, 'last_n_outputs': 30, 'lr': 0.04987710115520406, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.08361959463027858}"}}
exception: None

06:32:43 job_callback for (3, 0, 0) started
06:32:43 job_callback for (3, 0, 0) got condition
06:32:43 DISPATCHER: Trying to submit another job.
06:32:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:32:43 Only 5 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
06:32:43 HBMASTER: Trying to run another job!
06:32:43 job_callback for (3, 0, 0) finished
06:32:43 start sampling a new configuration.
06:32:43 best_vector: [0, 0.1261257893865528, 0.4366314488130732, 0.3449560839682493, 0.09853573243710098, 0, 0.12458720015051927, 0.8751801505585178], 5.953249955377204e-35, 167.9754768396314, -0.05433605291058782
06:32:43 done sampling a new configuration.
06:32:43 HBMASTER: schedule new run for iteration 3
06:32:43 HBMASTER: trying submitting job (3, 0, 1) to dispatcher
06:32:43 HBMASTER: submitting job (3, 0, 1) to dispatcher
06:32:43 DISPATCHER: trying to submit job (3, 0, 1)
06:32:43 DISPATCHER: trying to notify the job_runner thread.
06:32:43 HBMASTER: job (3, 0, 1) submitted to dispatcher
06:32:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:32:43 DISPATCHER: Trying to submit another job.
06:32:43 DISPATCHER: starting job (3, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
06:32:43 DISPATCHER: job (3, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
06:32:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:32:43 WORKER: start processing job (3, 0, 1)
06:32:43 WORKER: args: ()
06:32:43 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 30, 'last_n_outputs': 22, 'lr': 0.004896797761237727, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.1376054476501137}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-468:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:33:41 DISPATCHER: Starting worker discovery
06:33:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:33:41 DISPATCHER: Finished worker discovery
06:34:41 DISPATCHER: Starting worker discovery
06:34:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:34:41 DISPATCHER: Finished worker discovery
06:35:41 DISPATCHER: Starting worker discovery
06:35:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:35:41 DISPATCHER: Finished worker discovery
06:36:41 DISPATCHER: Starting worker discovery
06:36:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:36:41 DISPATCHER: Finished worker discovery
06:37:41 DISPATCHER: Starting worker discovery
06:37:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:37:41 DISPATCHER: Finished worker discovery
06:38:41 DISPATCHER: Starting worker discovery
06:38:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:38:41 DISPATCHER: Finished worker discovery
06:39:41 DISPATCHER: Starting worker discovery
06:39:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:39:41 DISPATCHER: Finished worker discovery
06:40:41 DISPATCHER: Starting worker discovery
06:40:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:40:41 DISPATCHER: Finished worker discovery
06:41:41 DISPATCHER: Starting worker discovery
06:41:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:41:41 DISPATCHER: Finished worker discovery
06:42:41 DISPATCHER: Starting worker discovery
06:42:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:42:41 DISPATCHER: Finished worker discovery
06:43:41 DISPATCHER: Starting worker discovery
06:43:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:43:41 DISPATCHER: Finished worker discovery
06:44:41 DISPATCHER: Starting worker discovery
06:44:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:44:41 DISPATCHER: Finished worker discovery
06:45:41 DISPATCHER: Starting worker discovery
06:45:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:45:41 DISPATCHER: Finished worker discovery
06:46:41 DISPATCHER: Starting worker discovery
06:46:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:46:41 DISPATCHER: Finished worker discovery
06:47:41 DISPATCHER: Starting worker discovery
06:47:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:47:41 DISPATCHER: Finished worker discovery
06:48:41 DISPATCHER: Starting worker discovery
06:48:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:48:41 DISPATCHER: Finished worker discovery
06:49:41 DISPATCHER: Starting worker discovery
06:49:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:49:41 DISPATCHER: Finished worker discovery
06:50:41 DISPATCHER: Starting worker discovery
06:50:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:50:41 DISPATCHER: Finished worker discovery
06:51:41 DISPATCHER: Starting worker discovery
06:51:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:51:41 DISPATCHER: Finished worker discovery
06:52:41 DISPATCHER: Starting worker discovery
06:52:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:52:41 DISPATCHER: Finished worker discovery
06:53:36 WORKER: done with job (3, 0, 1), trying to register it.
06:53:36 WORKER: registered result for job (3, 0, 1) with dispatcher
06:53:36 DISPATCHER: job (3, 0, 1) finished
06:53:36 DISPATCHER: register_result: lock acquired
06:53:36 DISPATCHER: job (3, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
06:53:36 job_id: (3, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 30, 'last_n_outputs': 22, 'lr': 0.004896797761237727, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.1376054476501137}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.19035506720732737, 'info': {'music_genre': 0.19035506720732737, 'config': "{'batch_size': 16, 'hidden_dim': 30, 'last_n_outputs': 22, 'lr': 0.004896797761237727, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.1376054476501137}"}}
exception: None

06:53:36 job_callback for (3, 0, 1) started
06:53:36 job_callback for (3, 0, 1) got condition
06:53:36 DISPATCHER: Trying to submit another job.
06:53:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:53:36 Only 6 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
06:53:36 HBMASTER: Trying to run another job!
06:53:36 job_callback for (3, 0, 1) finished
06:53:36 start sampling a new configuration.
06:53:36 best_vector: [0, 0.5575524050245024, 0.5473504703797133, 0.09284397465472341, 0.09945653139912425, 0, 0.3940060764582827, 0.9798648381820485], 1.418958044709466e-35, 704.742471934575, -0.00689051348880785
06:53:36 done sampling a new configuration.
06:53:36 HBMASTER: schedule new run for iteration 3
06:53:36 HBMASTER: trying submitting job (3, 0, 2) to dispatcher
06:53:36 HBMASTER: submitting job (3, 0, 2) to dispatcher
06:53:36 DISPATCHER: trying to submit job (3, 0, 2)
06:53:36 DISPATCHER: trying to notify the job_runner thread.
06:53:36 HBMASTER: job (3, 0, 2) submitted to dispatcher
06:53:36 DISPATCHER: Trying to submit another job.
06:53:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:53:36 DISPATCHER: starting job (3, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
06:53:36 DISPATCHER: job (3, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
06:53:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:53:36 WORKER: start processing job (3, 0, 2)
06:53:36 WORKER: args: ()
06:53:36 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 65, 'last_n_outputs': 28, 'lr': 0.0015335147208370406, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.1882927273906929}, 'budget': 1200.0, 'working_directory': '.'}
06:53:41 DISPATCHER: Starting worker discovery
06:53:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:53:41 DISPATCHER: Finished worker discovery
Exception in thread Thread-469:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:54:41 DISPATCHER: Starting worker discovery
06:54:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:54:41 DISPATCHER: Finished worker discovery
06:55:41 DISPATCHER: Starting worker discovery
06:55:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:55:41 DISPATCHER: Finished worker discovery
06:56:41 DISPATCHER: Starting worker discovery
06:56:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:56:41 DISPATCHER: Finished worker discovery
06:57:41 DISPATCHER: Starting worker discovery
06:57:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:57:41 DISPATCHER: Finished worker discovery
06:58:41 DISPATCHER: Starting worker discovery
06:58:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:58:41 DISPATCHER: Finished worker discovery
06:59:41 DISPATCHER: Starting worker discovery
06:59:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:59:41 DISPATCHER: Finished worker discovery
07:00:41 DISPATCHER: Starting worker discovery
07:00:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:00:41 DISPATCHER: Finished worker discovery
07:01:41 DISPATCHER: Starting worker discovery
07:01:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:01:41 DISPATCHER: Finished worker discovery
07:02:41 DISPATCHER: Starting worker discovery
07:02:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:02:41 DISPATCHER: Finished worker discovery
07:03:41 DISPATCHER: Starting worker discovery
07:03:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:03:41 DISPATCHER: Finished worker discovery
07:04:41 DISPATCHER: Starting worker discovery
07:04:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:04:41 DISPATCHER: Finished worker discovery
07:05:41 DISPATCHER: Starting worker discovery
07:05:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:05:41 DISPATCHER: Finished worker discovery
07:06:41 DISPATCHER: Starting worker discovery
07:06:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:06:41 DISPATCHER: Finished worker discovery
07:07:41 DISPATCHER: Starting worker discovery
07:07:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:07:41 DISPATCHER: Finished worker discovery
07:08:41 DISPATCHER: Starting worker discovery
07:08:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:08:41 DISPATCHER: Finished worker discovery
07:09:41 DISPATCHER: Starting worker discovery
07:09:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:09:41 DISPATCHER: Finished worker discovery
07:10:41 DISPATCHER: Starting worker discovery
07:10:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:10:41 DISPATCHER: Finished worker discovery
07:11:41 DISPATCHER: Starting worker discovery
07:11:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:11:41 DISPATCHER: Finished worker discovery
07:12:41 DISPATCHER: Starting worker discovery
07:12:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:12:41 DISPATCHER: Finished worker discovery
07:13:41 DISPATCHER: Starting worker discovery
07:13:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:13:41 DISPATCHER: Finished worker discovery
07:14:29 WORKER: done with job (3, 0, 2), trying to register it.
07:14:29 WORKER: registered result for job (3, 0, 2) with dispatcher
07:14:29 DISPATCHER: job (3, 0, 2) finished
07:14:29 DISPATCHER: register_result: lock acquired
07:14:29 DISPATCHER: job (3, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:14:29 job_id: (3, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 65, 'last_n_outputs': 28, 'lr': 0.0015335147208370406, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.1882927273906929}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.26423331353352136, 'info': {'music_genre': 0.26423331353352136, 'config': "{'batch_size': 16, 'hidden_dim': 65, 'last_n_outputs': 28, 'lr': 0.0015335147208370406, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.1882927273906929}"}}
exception: None

07:14:29 job_callback for (3, 0, 2) started
07:14:29 DISPATCHER: Trying to submit another job.
07:14:29 job_callback for (3, 0, 2) got condition
07:14:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:14:29 Only 7 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
07:14:29 HBMASTER: Trying to run another job!
07:14:29 job_callback for (3, 0, 2) finished
07:14:29 start sampling a new configuration.
07:14:29 best_vector: [0, 0.1448360152963623, 0.3368173448804429, 0.04134467106074011, 0.09834240244005037, 0, 0.13156952076133935, 0.9333266453382878], 1.2220580173211589e-34, 81.82917552409448, -0.0019398639557070922
07:14:29 done sampling a new configuration.
07:14:29 HBMASTER: schedule new run for iteration 3
07:14:29 HBMASTER: trying submitting job (3, 0, 3) to dispatcher
07:14:29 HBMASTER: submitting job (3, 0, 3) to dispatcher
07:14:29 DISPATCHER: trying to submit job (3, 0, 3)
07:14:29 DISPATCHER: trying to notify the job_runner thread.
07:14:29 HBMASTER: job (3, 0, 3) submitted to dispatcher
07:14:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:14:29 DISPATCHER: Trying to submit another job.
07:14:29 DISPATCHER: starting job (3, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:14:29 DISPATCHER: job (3, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:14:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:14:29 WORKER: start processing job (3, 0, 3)
07:14:29 WORKER: args: ()
07:14:29 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 31, 'last_n_outputs': 17, 'lr': 0.0012097324827376784, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.1637894638683064}, 'budget': 1200.0, 'working_directory': '.'}
07:14:41 DISPATCHER: Starting worker discovery
07:14:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:14:41 DISPATCHER: Finished worker discovery
Exception in thread Thread-470:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:15:41 DISPATCHER: Starting worker discovery
07:15:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:15:41 DISPATCHER: Finished worker discovery
07:16:41 DISPATCHER: Starting worker discovery
07:16:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:16:41 DISPATCHER: Finished worker discovery
07:17:41 DISPATCHER: Starting worker discovery
07:17:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:17:41 DISPATCHER: Finished worker discovery
07:18:41 DISPATCHER: Starting worker discovery
07:18:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:18:41 DISPATCHER: Finished worker discovery
07:19:41 DISPATCHER: Starting worker discovery
07:19:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:19:41 DISPATCHER: Finished worker discovery
07:20:41 DISPATCHER: Starting worker discovery
07:20:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:20:41 DISPATCHER: Finished worker discovery
07:21:41 DISPATCHER: Starting worker discovery
07:21:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:21:41 DISPATCHER: Finished worker discovery
07:22:41 DISPATCHER: Starting worker discovery
07:22:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:22:41 DISPATCHER: Finished worker discovery
07:23:41 DISPATCHER: Starting worker discovery
07:23:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:23:41 DISPATCHER: Finished worker discovery
07:24:41 DISPATCHER: Starting worker discovery
07:24:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:24:41 DISPATCHER: Finished worker discovery
07:25:41 DISPATCHER: Starting worker discovery
07:25:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:25:41 DISPATCHER: Finished worker discovery
07:26:41 DISPATCHER: Starting worker discovery
07:26:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:26:41 DISPATCHER: Finished worker discovery
07:27:41 DISPATCHER: Starting worker discovery
07:27:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:27:41 DISPATCHER: Finished worker discovery
07:28:41 DISPATCHER: Starting worker discovery
07:28:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:28:41 DISPATCHER: Finished worker discovery
07:29:41 DISPATCHER: Starting worker discovery
07:29:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:29:41 DISPATCHER: Finished worker discovery
07:30:41 DISPATCHER: Starting worker discovery
07:30:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:30:41 DISPATCHER: Finished worker discovery
07:31:41 DISPATCHER: Starting worker discovery
07:31:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:31:41 DISPATCHER: Finished worker discovery
07:32:41 DISPATCHER: Starting worker discovery
07:32:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:32:41 DISPATCHER: Finished worker discovery
07:33:41 DISPATCHER: Starting worker discovery
07:33:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:33:41 DISPATCHER: Finished worker discovery
07:34:41 DISPATCHER: Starting worker discovery
07:34:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:34:41 DISPATCHER: Finished worker discovery
07:35:20 WORKER: done with job (3, 0, 3), trying to register it.
07:35:20 WORKER: registered result for job (3, 0, 3) with dispatcher
07:35:20 DISPATCHER: job (3, 0, 3) finished
07:35:20 DISPATCHER: register_result: lock acquired
07:35:20 DISPATCHER: job (3, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:35:20 job_id: (3, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 31, 'last_n_outputs': 17, 'lr': 0.0012097324827376784, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.1637894638683064}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.16885673032409623, 'info': {'music_genre': 0.16885673032409623, 'config': "{'batch_size': 16, 'hidden_dim': 31, 'last_n_outputs': 17, 'lr': 0.0012097324827376784, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.1637894638683064}"}}
exception: None

07:35:20 job_callback for (3, 0, 3) started
07:35:20 job_callback for (3, 0, 3) got condition
07:35:20 DISPATCHER: Trying to submit another job.
07:35:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:35:20 Only 8 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
07:35:20 HBMASTER: Trying to run another job!
07:35:20 job_callback for (3, 0, 3) finished
07:35:20 start sampling a new configuration.
07:35:20 best_vector: [0, 0.43427039744318363, 0.5899518808055368, 0.535970286186951, 0.10090122956752716, 0, 0.412612977314022, 0.6773773210917304], 1.8135124891630412e-05, 104.26220388986799, 0.0018908080890193903
07:35:20 done sampling a new configuration.
07:35:20 HBMASTER: schedule new run for iteration 4
07:35:20 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
07:35:20 HBMASTER: submitting job (4, 0, 0) to dispatcher
07:35:20 DISPATCHER: trying to submit job (4, 0, 0)
07:35:20 DISPATCHER: trying to notify the job_runner thread.
07:35:20 HBMASTER: job (4, 0, 0) submitted to dispatcher
07:35:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:35:20 DISPATCHER: Trying to submit another job.
07:35:20 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:35:20 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:35:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:35:20 WORKER: start processing job (4, 0, 0)
07:35:20 WORKER: args: ()
07:35:20 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 55, 'last_n_outputs': 30, 'lr': 0.011801591349709168, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.07608310237170253}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:35:41 DISPATCHER: Starting worker discovery
07:35:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:35:41 DISPATCHER: Finished worker discovery
Exception in thread Thread-471:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:36:41 DISPATCHER: Starting worker discovery
07:36:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:36:41 DISPATCHER: Finished worker discovery
07:36:55 WORKER: done with job (4, 0, 0), trying to register it.
07:36:55 WORKER: registered result for job (4, 0, 0) with dispatcher
07:36:55 DISPATCHER: job (4, 0, 0) finished
07:36:55 DISPATCHER: register_result: lock acquired
07:36:55 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:36:55 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 55, 'last_n_outputs': 30, 'lr': 0.011801591349709168, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.07608310237170253}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.07701127063697451, 'info': {'music_genre': 0.07701127063697451, 'config': "{'batch_size': 16, 'hidden_dim': 55, 'last_n_outputs': 30, 'lr': 0.011801591349709168, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.07608310237170253}"}}
exception: None

07:36:55 job_callback for (4, 0, 0) started
07:36:55 DISPATCHER: Trying to submit another job.
07:36:55 job_callback for (4, 0, 0) got condition
07:36:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:36:55 HBMASTER: Trying to run another job!
07:36:55 job_callback for (4, 0, 0) finished
07:36:55 start sampling a new configuration.
07:36:55 best_vector: [0, 0.6674267388226385, 0.7835799414088875, 0.13453635265681113, 0.09909236955228624, 0, 0.4660213105321019, 0.7828267185275993], 1.8165592794396766e-34, 55.04912563648642, -0.0009184259682969778
07:36:55 done sampling a new configuration.
07:36:55 HBMASTER: schedule new run for iteration 4
07:36:55 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
07:36:55 HBMASTER: submitting job (4, 0, 1) to dispatcher
07:36:55 DISPATCHER: trying to submit job (4, 0, 1)
07:36:55 DISPATCHER: trying to notify the job_runner thread.
07:36:55 HBMASTER: job (4, 0, 1) submitted to dispatcher
07:36:55 DISPATCHER: Trying to submit another job.
07:36:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:36:55 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:36:55 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:36:55 WORKER: start processing job (4, 0, 1)
07:36:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:36:55 WORKER: args: ()
07:36:55 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 74, 'last_n_outputs': 40, 'lr': 0.0018581154964888394, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.10434725821517864}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:37:41 DISPATCHER: Starting worker discovery
07:37:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:37:41 DISPATCHER: Finished worker discovery
Exception in thread Thread-472:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:38:30 WORKER: done with job (4, 0, 1), trying to register it.
07:38:30 WORKER: registered result for job (4, 0, 1) with dispatcher
07:38:30 DISPATCHER: job (4, 0, 1) finished
07:38:30 DISPATCHER: register_result: lock acquired
07:38:30 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:38:30 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 74, 'last_n_outputs': 40, 'lr': 0.0018581154964888394, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.10434725821517864}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2649377830299406, 'info': {'music_genre': 0.2649377830299406, 'config': "{'batch_size': 16, 'hidden_dim': 74, 'last_n_outputs': 40, 'lr': 0.0018581154964888394, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.10434725821517864}"}}
exception: None

07:38:30 job_callback for (4, 0, 1) started
07:38:30 DISPATCHER: Trying to submit another job.
07:38:30 job_callback for (4, 0, 1) got condition
07:38:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:38:30 HBMASTER: Trying to run another job!
07:38:30 job_callback for (4, 0, 1) finished
07:38:30 start sampling a new configuration.
07:38:30 best_vector: [0, 0.9157244180326417, 0.909775002762067, 0.6703998447960487, 0.1001317007194859, 0, 0.42510505397078335, 0.40980958876536355], 5.577177567964271e-35, 179.3021627541636, -0.0006067692123133884
07:38:30 done sampling a new configuration.
07:38:30 HBMASTER: schedule new run for iteration 4
07:38:30 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
07:38:30 HBMASTER: submitting job (4, 0, 2) to dispatcher
07:38:30 DISPATCHER: trying to submit job (4, 0, 2)
07:38:30 DISPATCHER: trying to notify the job_runner thread.
07:38:30 HBMASTER: job (4, 0, 2) submitted to dispatcher
07:38:30 DISPATCHER: Trying to submit another job.
07:38:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:38:30 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:38:30 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:38:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:38:30 WORKER: start processing job (4, 0, 2)
07:38:30 WORKER: args: ()
07:38:30 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 94, 'last_n_outputs': 46, 'lr': 0.02191793777279552, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.03413300839008769}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:38:41 DISPATCHER: Starting worker discovery
07:38:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:38:41 DISPATCHER: Finished worker discovery
Exception in thread Thread-473:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:39:41 DISPATCHER: Starting worker discovery
07:39:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:39:41 DISPATCHER: Finished worker discovery
07:40:07 WORKER: done with job (4, 0, 2), trying to register it.
07:40:07 WORKER: registered result for job (4, 0, 2) with dispatcher
07:40:07 DISPATCHER: job (4, 0, 2) finished
07:40:07 DISPATCHER: register_result: lock acquired
07:40:07 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:40:07 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 94, 'last_n_outputs': 46, 'lr': 0.02191793777279552, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.03413300839008769}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.19070887426409286, 'info': {'music_genre': 0.19070887426409286, 'config': "{'batch_size': 16, 'hidden_dim': 94, 'last_n_outputs': 46, 'lr': 0.02191793777279552, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.03413300839008769}"}}
exception: None

07:40:07 job_callback for (4, 0, 2) started
07:40:07 job_callback for (4, 0, 2) got condition
07:40:07 DISPATCHER: Trying to submit another job.
07:40:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:40:07 HBMASTER: Trying to run another job!
07:40:07 job_callback for (4, 0, 2) finished
07:40:07 start sampling a new configuration.
07:40:07 done sampling a new configuration.
07:40:07 HBMASTER: schedule new run for iteration 4
07:40:07 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
07:40:07 HBMASTER: submitting job (4, 0, 3) to dispatcher
07:40:07 DISPATCHER: trying to submit job (4, 0, 3)
07:40:07 DISPATCHER: trying to notify the job_runner thread.
07:40:07 HBMASTER: job (4, 0, 3) submitted to dispatcher
07:40:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:40:07 DISPATCHER: Trying to submit another job.
07:40:07 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:40:07 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:40:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:40:07 WORKER: start processing job (4, 0, 3)
07:40:07 WORKER: args: ()
07:40:07 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 45, 'lr': 0.0028448249161392184, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.02975502405402875}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:40:41 DISPATCHER: Starting worker discovery
07:40:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:40:41 DISPATCHER: Finished worker discovery
Exception in thread Thread-474:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:41:41 DISPATCHER: Starting worker discovery
07:41:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:41:41 DISPATCHER: Finished worker discovery
07:41:43 WORKER: done with job (4, 0, 3), trying to register it.
07:41:43 WORKER: registered result for job (4, 0, 3) with dispatcher
07:41:43 DISPATCHER: job (4, 0, 3) finished
07:41:43 DISPATCHER: register_result: lock acquired
07:41:43 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:41:43 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 45, 'lr': 0.0028448249161392184, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.02975502405402875}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.37184894622915604, 'info': {'music_genre': 0.37184894622915604, 'config': "{'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 45, 'lr': 0.0028448249161392184, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.02975502405402875}"}}
exception: None

07:41:43 job_callback for (4, 0, 3) started
07:41:43 job_callback for (4, 0, 3) got condition
07:41:43 DISPATCHER: Trying to submit another job.
07:41:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:41:43 HBMASTER: Trying to run another job!
07:41:43 job_callback for (4, 0, 3) finished
07:41:43 start sampling a new configuration.
07:41:43 best_vector: [0, 0.3856236119072746, 0.9607264386105868, 0.8899939288982873, 0.10176950334118967, 0, 0.14233494044261896, 0.1077228484618038], 1.5427504571971414e-32, 0.6481929694688234, -0.0035634390594582316
07:41:43 done sampling a new configuration.
07:41:43 HBMASTER: schedule new run for iteration 4
07:41:43 HBMASTER: trying submitting job (4, 0, 4) to dispatcher
07:41:43 HBMASTER: submitting job (4, 0, 4) to dispatcher
07:41:43 DISPATCHER: trying to submit job (4, 0, 4)
07:41:43 DISPATCHER: trying to notify the job_runner thread.
07:41:43 HBMASTER: job (4, 0, 4) submitted to dispatcher
07:41:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:41:43 DISPATCHER: Trying to submit another job.
07:41:43 DISPATCHER: starting job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:41:43 DISPATCHER: job (4, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:41:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:41:43 WORKER: start processing job (4, 0, 4)
07:41:43 WORKER: args: ()
07:41:43 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 51, 'last_n_outputs': 49, 'lr': 0.06025427396738205, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.013808632039614473}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-475:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:42:41 DISPATCHER: Starting worker discovery
07:42:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:42:41 DISPATCHER: Finished worker discovery
07:43:19 WORKER: done with job (4, 0, 4), trying to register it.
07:43:19 WORKER: registered result for job (4, 0, 4) with dispatcher
07:43:19 DISPATCHER: job (4, 0, 4) finished
07:43:19 DISPATCHER: register_result: lock acquired
07:43:19 DISPATCHER: job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:43:19 job_id: (4, 0, 4)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 51, 'last_n_outputs': 49, 'lr': 0.06025427396738205, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.013808632039614473}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.008653383977339592, 'info': {'music_genre': 0.008653383977339592, 'config': "{'batch_size': 16, 'hidden_dim': 51, 'last_n_outputs': 49, 'lr': 0.06025427396738205, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.013808632039614473}"}}
exception: None

07:43:19 job_callback for (4, 0, 4) started
07:43:19 job_callback for (4, 0, 4) got condition
07:43:19 DISPATCHER: Trying to submit another job.
07:43:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:43:19 HBMASTER: Trying to run another job!
07:43:19 job_callback for (4, 0, 4) finished
07:43:19 start sampling a new configuration.
07:43:19 best_vector: [1, 0.5213824606889925, 0.15698667316830262, 0.2756633059780387, 0.09977393425335883, 0, 0.29765798069917937, 0.22157851658381678], 1.9806382926109197e-34, 50.488774438556305, -0.0001230126185288124
07:43:19 done sampling a new configuration.
07:43:19 HBMASTER: schedule new run for iteration 4
07:43:19 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
07:43:19 HBMASTER: submitting job (4, 0, 5) to dispatcher
07:43:19 DISPATCHER: trying to submit job (4, 0, 5)
07:43:19 DISPATCHER: trying to notify the job_runner thread.
07:43:19 HBMASTER: job (4, 0, 5) submitted to dispatcher
07:43:19 DISPATCHER: Trying to submit another job.
07:43:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:43:19 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:43:19 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:43:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:43:19 WORKER: start processing job (4, 0, 5)
07:43:19 WORKER: args: ()
07:43:19 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 62, 'last_n_outputs': 8, 'lr': 0.0035589887234435324, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.01942138942228131}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:43:41 DISPATCHER: Starting worker discovery
07:43:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:43:41 DISPATCHER: Finished worker discovery
Exception in thread Thread-476:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:44:41 DISPATCHER: Starting worker discovery
07:44:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:44:41 DISPATCHER: Finished worker discovery
07:44:53 WORKER: done with job (4, 0, 5), trying to register it.
07:44:53 WORKER: registered result for job (4, 0, 5) with dispatcher
07:44:53 DISPATCHER: job (4, 0, 5) finished
07:44:53 DISPATCHER: register_result: lock acquired
07:44:53 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:44:53 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 62, 'last_n_outputs': 8, 'lr': 0.0035589887234435324, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.01942138942228131}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2877395188081855, 'info': {'music_genre': 0.2877395188081855, 'config': "{'batch_size': 32, 'hidden_dim': 62, 'last_n_outputs': 8, 'lr': 0.0035589887234435324, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.01942138942228131}"}}
exception: None

07:44:53 job_callback for (4, 0, 5) started
07:44:53 DISPATCHER: Trying to submit another job.
07:44:53 job_callback for (4, 0, 5) got condition
07:44:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:44:53 HBMASTER: Trying to run another job!
07:44:53 job_callback for (4, 0, 5) finished
07:44:53 start sampling a new configuration.
07:44:53 done sampling a new configuration.
07:44:53 HBMASTER: schedule new run for iteration 4
07:44:53 HBMASTER: trying submitting job (4, 0, 6) to dispatcher
07:44:53 HBMASTER: submitting job (4, 0, 6) to dispatcher
07:44:53 DISPATCHER: trying to submit job (4, 0, 6)
07:44:53 DISPATCHER: trying to notify the job_runner thread.
07:44:53 HBMASTER: job (4, 0, 6) submitted to dispatcher
07:44:53 DISPATCHER: Trying to submit another job.
07:44:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:44:53 DISPATCHER: starting job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:44:53 DISPATCHER: job (4, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:44:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:44:53 WORKER: start processing job (4, 0, 6)
07:44:53 WORKER: args: ()
07:44:53 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 80, 'last_n_outputs': 14, 'lr': 0.013598382218610669, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.013570119951997299}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:45:41 DISPATCHER: Starting worker discovery
07:45:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:45:41 DISPATCHER: Finished worker discovery
Exception in thread Thread-477:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:46:29 WORKER: done with job (4, 0, 6), trying to register it.
07:46:29 WORKER: registered result for job (4, 0, 6) with dispatcher
07:46:29 DISPATCHER: job (4, 0, 6) finished
07:46:29 DISPATCHER: register_result: lock acquired
07:46:29 DISPATCHER: job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:46:29 job_id: (4, 0, 6)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 80, 'last_n_outputs': 14, 'lr': 0.013598382218610669, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.013570119951997299}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.16534448144011923, 'info': {'music_genre': 0.16534448144011923, 'config': "{'batch_size': 16, 'hidden_dim': 80, 'last_n_outputs': 14, 'lr': 0.013598382218610669, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.013570119951997299}"}}
exception: None

07:46:29 job_callback for (4, 0, 6) started
07:46:29 job_callback for (4, 0, 6) got condition
07:46:29 DISPATCHER: Trying to submit another job.
07:46:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:46:29 HBMASTER: Trying to run another job!
07:46:29 job_callback for (4, 0, 6) finished
07:46:29 start sampling a new configuration.
07:46:29 done sampling a new configuration.
07:46:29 HBMASTER: schedule new run for iteration 4
07:46:29 HBMASTER: trying submitting job (4, 0, 7) to dispatcher
07:46:29 HBMASTER: submitting job (4, 0, 7) to dispatcher
07:46:29 DISPATCHER: trying to submit job (4, 0, 7)
07:46:29 DISPATCHER: trying to notify the job_runner thread.
07:46:29 HBMASTER: job (4, 0, 7) submitted to dispatcher
07:46:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:46:29 DISPATCHER: Trying to submit another job.
07:46:29 DISPATCHER: starting job (4, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:46:29 DISPATCHER: job (4, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:46:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:46:29 WORKER: start processing job (4, 0, 7)
07:46:29 WORKER: args: ()
07:46:29 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 62, 'last_n_outputs': 42, 'lr': 0.010483435773555712, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.017151084802059652}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:46:41 DISPATCHER: Starting worker discovery
07:46:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:46:41 DISPATCHER: Finished worker discovery
Exception in thread Thread-478:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:47:41 DISPATCHER: Starting worker discovery
07:47:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:47:41 DISPATCHER: Finished worker discovery
07:48:04 WORKER: done with job (4, 0, 7), trying to register it.
07:48:04 WORKER: registered result for job (4, 0, 7) with dispatcher
07:48:04 DISPATCHER: job (4, 0, 7) finished
07:48:04 DISPATCHER: register_result: lock acquired
07:48:04 DISPATCHER: job (4, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:48:04 job_id: (4, 0, 7)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 62, 'last_n_outputs': 42, 'lr': 0.010483435773555712, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.017151084802059652}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 62, 'last_n_outputs': 42, 'lr': 0.010483435773555712, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.017151084802059652}"}}
exception: None

07:48:04 job_callback for (4, 0, 7) started
07:48:04 DISPATCHER: Trying to submit another job.
07:48:04 job_callback for (4, 0, 7) got condition
07:48:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:48:04 HBMASTER: Trying to run another job!
07:48:04 job_callback for (4, 0, 7) finished
07:48:04 start sampling a new configuration.
07:48:04 best_vector: [0, 0.8264287148113958, 0.7723972083816546, 0.7877210153455765, 0.09934947752202568, 0, 0.18177022335024628, 0.7558080239128268], 3.1430618540055357e-34, 31.816109464266333, -0.00920816256095877
07:48:04 done sampling a new configuration.
07:48:04 HBMASTER: schedule new run for iteration 4
07:48:04 HBMASTER: trying submitting job (4, 0, 8) to dispatcher
07:48:04 HBMASTER: submitting job (4, 0, 8) to dispatcher
07:48:04 DISPATCHER: trying to submit job (4, 0, 8)
07:48:04 DISPATCHER: trying to notify the job_runner thread.
07:48:04 HBMASTER: job (4, 0, 8) submitted to dispatcher
07:48:04 DISPATCHER: Trying to submit another job.
07:48:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:48:04 DISPATCHER: starting job (4, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:48:04 DISPATCHER: job (4, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:48:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:48:04 WORKER: start processing job (4, 0, 8)
07:48:04 WORKER: args: ()
07:48:04 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 86, 'last_n_outputs': 39, 'lr': 0.03762201313289774, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.09623408249735088}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:48:41 DISPATCHER: Starting worker discovery
07:48:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:48:41 DISPATCHER: Finished worker discovery
Exception in thread Thread-479:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:49:40 WORKER: done with job (4, 0, 8), trying to register it.
07:49:40 WORKER: registered result for job (4, 0, 8) with dispatcher
07:49:40 DISPATCHER: job (4, 0, 8) finished
07:49:40 DISPATCHER: register_result: lock acquired
07:49:40 DISPATCHER: job (4, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:49:40 job_id: (4, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 86, 'last_n_outputs': 39, 'lr': 0.03762201313289774, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.09623408249735088}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.041050015921230636, 'info': {'music_genre': 0.041050015921230636, 'config': "{'batch_size': 16, 'hidden_dim': 86, 'last_n_outputs': 39, 'lr': 0.03762201313289774, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.09623408249735088}"}}
exception: None

07:49:40 job_callback for (4, 0, 8) started
07:49:40 job_callback for (4, 0, 8) got condition
07:49:40 DISPATCHER: Trying to submit another job.
07:49:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:49:40 HBMASTER: Trying to run another job!
07:49:40 job_callback for (4, 0, 8) finished
07:49:40 start sampling a new configuration.
07:49:40 best_vector: [1, 0.28122772798802587, 0.26571337570001147, 0.03039698845241906, 0.10050390129903851, 0, 0.03382870916979286, 0.06845656427803215], 4.1793477286748153e-35, 239.27178711140155, -0.018987789786207673
07:49:40 done sampling a new configuration.
07:49:40 HBMASTER: schedule new run for iteration 4
07:49:40 HBMASTER: trying submitting job (4, 0, 9) to dispatcher
07:49:40 HBMASTER: submitting job (4, 0, 9) to dispatcher
07:49:40 DISPATCHER: trying to submit job (4, 0, 9)
07:49:40 DISPATCHER: trying to notify the job_runner thread.
07:49:40 HBMASTER: job (4, 0, 9) submitted to dispatcher
07:49:40 DISPATCHER: Trying to submit another job.
07:49:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:49:40 DISPATCHER: starting job (4, 0, 9) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:49:40 DISPATCHER: job (4, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:49:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:49:40 WORKER: start processing job (4, 0, 9)
07:49:40 WORKER: args: ()
07:49:40 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 42, 'last_n_outputs': 14, 'lr': 0.0011502545951560903, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.012276202496510591}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:49:41 DISPATCHER: Starting worker discovery
07:49:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:49:42 DISPATCHER: Finished worker discovery
Exception in thread Thread-480:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:50:42 DISPATCHER: Starting worker discovery
07:50:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:50:42 DISPATCHER: Finished worker discovery
07:51:16 WORKER: done with job (4, 0, 9), trying to register it.
07:51:16 WORKER: registered result for job (4, 0, 9) with dispatcher
07:51:16 DISPATCHER: job (4, 0, 9) finished
07:51:16 DISPATCHER: register_result: lock acquired
07:51:16 DISPATCHER: job (4, 0, 9) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:51:16 job_id: (4, 0, 9)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 42, 'last_n_outputs': 14, 'lr': 0.0011502545951560903, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.012276202496510591}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.13937231053839066, 'info': {'music_genre': 0.13937231053839066, 'config': "{'batch_size': 32, 'hidden_dim': 42, 'last_n_outputs': 14, 'lr': 0.0011502545951560903, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.012276202496510591}"}}
exception: None

07:51:16 job_callback for (4, 0, 9) started
07:51:16 DISPATCHER: Trying to submit another job.
07:51:16 job_callback for (4, 0, 9) got condition
07:51:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:51:16 HBMASTER: Trying to run another job!
07:51:16 job_callback for (4, 0, 9) finished
07:51:16 start sampling a new configuration.
07:51:16 best_vector: [1, 0.04366231066163456, 0.2448790365707353, 0.27102793293201843, 0.10036934586272792, 0, 0.32291575504181963, 0.244082634180811], 1.1675655661498853e-34, 85.64829496450102, -0.013064992317297387
07:51:16 done sampling a new configuration.
07:51:16 HBMASTER: schedule new run for iteration 4
07:51:16 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
07:51:16 HBMASTER: submitting job (4, 0, 10) to dispatcher
07:51:16 DISPATCHER: trying to submit job (4, 0, 10)
07:51:16 DISPATCHER: trying to notify the job_runner thread.
07:51:16 HBMASTER: job (4, 0, 10) submitted to dispatcher
07:51:16 DISPATCHER: Trying to submit another job.
07:51:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:51:16 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:51:16 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:51:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:51:16 WORKER: start processing job (4, 0, 10)
07:51:16 WORKER: args: ()
07:51:16 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 23, 'last_n_outputs': 13, 'lr': 0.0034838212660416065, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.020775851312166776}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:51:42 DISPATCHER: Starting worker discovery
07:51:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:51:42 DISPATCHER: Finished worker discovery
Exception in thread Thread-481:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:52:42 DISPATCHER: Starting worker discovery
07:52:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:52:42 DISPATCHER: Finished worker discovery
07:52:51 WORKER: done with job (4, 0, 10), trying to register it.
07:52:51 WORKER: registered result for job (4, 0, 10) with dispatcher
07:52:51 DISPATCHER: job (4, 0, 10) finished
07:52:51 DISPATCHER: register_result: lock acquired
07:52:51 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:52:51 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 23, 'last_n_outputs': 13, 'lr': 0.0034838212660416065, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.020775851312166776}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3015527884669816, 'info': {'music_genre': 0.3015527884669816, 'config': "{'batch_size': 32, 'hidden_dim': 23, 'last_n_outputs': 13, 'lr': 0.0034838212660416065, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.020775851312166776}"}}
exception: None

07:52:51 job_callback for (4, 0, 10) started
07:52:51 job_callback for (4, 0, 10) got condition
07:52:51 DISPATCHER: Trying to submit another job.
07:52:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:52:51 HBMASTER: Trying to run another job!
07:52:51 job_callback for (4, 0, 10) finished
07:52:51 start sampling a new configuration.
07:52:51 done sampling a new configuration.
07:52:51 HBMASTER: schedule new run for iteration 4
07:52:51 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
07:52:51 HBMASTER: submitting job (4, 0, 11) to dispatcher
07:52:51 DISPATCHER: trying to submit job (4, 0, 11)
07:52:51 DISPATCHER: trying to notify the job_runner thread.
07:52:51 HBMASTER: job (4, 0, 11) submitted to dispatcher
07:52:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:52:51 DISPATCHER: Trying to submit another job.
07:52:51 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:52:51 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:52:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:52:51 WORKER: start processing job (4, 0, 11)
07:52:51 WORKER: args: ()
07:52:51 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 66, 'last_n_outputs': 3, 'lr': 0.001109113084881096, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.05861011727255118}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:53:42 DISPATCHER: Starting worker discovery
07:53:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:53:42 DISPATCHER: Finished worker discovery
Exception in thread Thread-482:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:54:26 WORKER: done with job (4, 0, 11), trying to register it.
07:54:26 WORKER: registered result for job (4, 0, 11) with dispatcher
07:54:26 DISPATCHER: job (4, 0, 11) finished
07:54:26 DISPATCHER: register_result: lock acquired
07:54:26 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:54:26 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 66, 'last_n_outputs': 3, 'lr': 0.001109113084881096, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.05861011727255118}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 66, 'last_n_outputs': 3, 'lr': 0.001109113084881096, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.05861011727255118}"}}
exception: None

07:54:26 job_callback for (4, 0, 11) started
07:54:26 DISPATCHER: Trying to submit another job.
07:54:26 job_callback for (4, 0, 11) got condition
07:54:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:54:26 HBMASTER: Trying to run another job!
07:54:26 job_callback for (4, 0, 11) finished
07:54:26 start sampling a new configuration.
07:54:26 done sampling a new configuration.
07:54:26 HBMASTER: schedule new run for iteration 4
07:54:26 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
07:54:26 HBMASTER: submitting job (4, 0, 12) to dispatcher
07:54:26 DISPATCHER: trying to submit job (4, 0, 12)
07:54:26 DISPATCHER: trying to notify the job_runner thread.
07:54:26 HBMASTER: job (4, 0, 12) submitted to dispatcher
07:54:26 DISPATCHER: Trying to submit another job.
07:54:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:54:26 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:54:26 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:54:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:54:26 WORKER: start processing job (4, 0, 12)
07:54:26 WORKER: args: ()
07:54:26 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 73, 'last_n_outputs': 18, 'lr': 0.06287527198248395, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.07320387244684895}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:54:42 DISPATCHER: Starting worker discovery
07:54:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:54:42 DISPATCHER: Finished worker discovery
Exception in thread Thread-483:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:55:42 DISPATCHER: Starting worker discovery
07:55:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:55:42 DISPATCHER: Finished worker discovery
07:56:02 WORKER: done with job (4, 0, 12), trying to register it.
07:56:02 WORKER: registered result for job (4, 0, 12) with dispatcher
07:56:02 DISPATCHER: job (4, 0, 12) finished
07:56:02 DISPATCHER: register_result: lock acquired
07:56:02 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:56:02 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 73, 'last_n_outputs': 18, 'lr': 0.06287527198248395, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.07320387244684895}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 73, 'last_n_outputs': 18, 'lr': 0.06287527198248395, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.07320387244684895}"}}
exception: None

07:56:02 job_callback for (4, 0, 12) started
07:56:02 job_callback for (4, 0, 12) got condition
07:56:02 DISPATCHER: Trying to submit another job.
07:56:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:56:02 HBMASTER: Trying to run another job!
07:56:02 job_callback for (4, 0, 12) finished
07:56:02 start sampling a new configuration.
07:56:02 best_vector: [1, 0.49591253853784695, 0.34883426985009114, 0.2537325426635576, 0.10148855091071513, 0, 0.46230677997149716, 0.11773460521624779], 7.17359591131119e-34, 13.940010175694717, -0.0007861908674639123
07:56:02 done sampling a new configuration.
07:56:02 HBMASTER: schedule new run for iteration 4
07:56:02 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
07:56:02 HBMASTER: submitting job (4, 0, 13) to dispatcher
07:56:02 DISPATCHER: trying to submit job (4, 0, 13)
07:56:02 DISPATCHER: trying to notify the job_runner thread.
07:56:02 HBMASTER: job (4, 0, 13) submitted to dispatcher
07:56:02 DISPATCHER: Trying to submit another job.
07:56:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:56:02 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:56:02 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:56:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:56:02 WORKER: start processing job (4, 0, 13)
07:56:02 WORKER: args: ()
07:56:02 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 60, 'last_n_outputs': 18, 'lr': 0.0032171038864320023, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.01422906138390953}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:56:42 DISPATCHER: Starting worker discovery
07:56:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:56:42 DISPATCHER: Finished worker discovery
Exception in thread Thread-484:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:57:37 WORKER: done with job (4, 0, 13), trying to register it.
07:57:37 WORKER: registered result for job (4, 0, 13) with dispatcher
07:57:37 DISPATCHER: job (4, 0, 13) finished
07:57:37 DISPATCHER: register_result: lock acquired
07:57:37 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:57:37 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 60, 'last_n_outputs': 18, 'lr': 0.0032171038864320023, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.01422906138390953}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.31610725518035665, 'info': {'music_genre': 0.31610725518035665, 'config': "{'batch_size': 32, 'hidden_dim': 60, 'last_n_outputs': 18, 'lr': 0.0032171038864320023, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.01422906138390953}"}}
exception: None

07:57:37 job_callback for (4, 0, 13) started
07:57:37 DISPATCHER: Trying to submit another job.
07:57:37 job_callback for (4, 0, 13) got condition
07:57:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:57:37 HBMASTER: Trying to run another job!
07:57:37 job_callback for (4, 0, 13) finished
07:57:37 start sampling a new configuration.
07:57:37 best_vector: [0, 0.7846393694931042, 0.6267495409670218, 0.42960496970376394, 0.0998435815519425, 0, 0.30007943946290355, 0.5676563087749893], 3.680295254080106e-35, 271.71732998632774, -1.3972182754024703e-05
07:57:37 done sampling a new configuration.
07:57:37 HBMASTER: schedule new run for iteration 4
07:57:37 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
07:57:37 HBMASTER: submitting job (4, 0, 14) to dispatcher
07:57:37 DISPATCHER: trying to submit job (4, 0, 14)
07:57:37 DISPATCHER: trying to notify the job_runner thread.
07:57:37 HBMASTER: job (4, 0, 14) submitted to dispatcher
07:57:37 DISPATCHER: Trying to submit another job.
07:57:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:57:37 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:57:37 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:57:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:57:37 WORKER: start processing job (4, 0, 14)
07:57:37 WORKER: args: ()
07:57:37 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 83, 'last_n_outputs': 32, 'lr': 0.007231192774082582, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.05476938760264674}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:57:42 DISPATCHER: Starting worker discovery
07:57:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:57:42 DISPATCHER: Finished worker discovery
Exception in thread Thread-485:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:58:42 DISPATCHER: Starting worker discovery
07:58:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:58:42 DISPATCHER: Finished worker discovery
07:59:13 WORKER: done with job (4, 0, 14), trying to register it.
07:59:13 WORKER: registered result for job (4, 0, 14) with dispatcher
07:59:13 DISPATCHER: job (4, 0, 14) finished
07:59:13 DISPATCHER: register_result: lock acquired
07:59:13 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:59:13 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 83, 'last_n_outputs': 32, 'lr': 0.007231192774082582, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.05476938760264674}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2444295854059165, 'info': {'music_genre': 0.2444295854059165, 'config': "{'batch_size': 16, 'hidden_dim': 83, 'last_n_outputs': 32, 'lr': 0.007231192774082582, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.05476938760264674}"}}
exception: None

07:59:13 job_callback for (4, 0, 14) started
07:59:13 DISPATCHER: Trying to submit another job.
07:59:13 job_callback for (4, 0, 14) got condition
07:59:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:59:13 HBMASTER: Trying to run another job!
07:59:13 job_callback for (4, 0, 14) finished
07:59:13 start sampling a new configuration.
07:59:13 best_vector: [1, 0.3229359536649735, 0.620330515693649, 0.03768328466078463, 0.09852292567925201, 0, 0.09525551137454374, 0.043134014147586386], 8.548383718179729e-35, 116.981178310154, -0.003115535378626433
07:59:13 done sampling a new configuration.
07:59:13 HBMASTER: schedule new run for iteration 4
07:59:13 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
07:59:13 HBMASTER: submitting job (4, 0, 15) to dispatcher
07:59:13 DISPATCHER: trying to submit job (4, 0, 15)
07:59:13 DISPATCHER: trying to notify the job_runner thread.
07:59:13 HBMASTER: job (4, 0, 15) submitted to dispatcher
07:59:13 DISPATCHER: Trying to submit another job.
07:59:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:59:13 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:59:13 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:59:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:59:13 WORKER: start processing job (4, 0, 15)
07:59:13 WORKER: args: ()
07:59:13 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 46, 'last_n_outputs': 32, 'lr': 0.0011895058146102735, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.01137938120162238}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:59:42 DISPATCHER: Starting worker discovery
07:59:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:59:42 DISPATCHER: Finished worker discovery
Exception in thread Thread-486:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:00:42 DISPATCHER: Starting worker discovery
08:00:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:00:42 DISPATCHER: Finished worker discovery
08:00:48 WORKER: done with job (4, 0, 15), trying to register it.
08:00:48 WORKER: registered result for job (4, 0, 15) with dispatcher
08:00:48 DISPATCHER: job (4, 0, 15) finished
08:00:48 DISPATCHER: register_result: lock acquired
08:00:48 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
08:00:48 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 46, 'last_n_outputs': 32, 'lr': 0.0011895058146102735, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.01137938120162238}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.230263302469593, 'info': {'music_genre': 0.230263302469593, 'config': "{'batch_size': 32, 'hidden_dim': 46, 'last_n_outputs': 32, 'lr': 0.0011895058146102735, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.01137938120162238}"}}
exception: None

08:00:48 job_callback for (4, 0, 15) started
08:00:48 DISPATCHER: Trying to submit another job.
08:00:48 job_callback for (4, 0, 15) got condition
08:00:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:00:48 HBMASTER: Trying to run another job!
08:00:48 job_callback for (4, 0, 15) finished
08:00:48 start sampling a new configuration.
08:00:48 done sampling a new configuration.
08:00:48 HBMASTER: schedule new run for iteration 4
08:00:48 HBMASTER: trying submitting job (4, 0, 16) to dispatcher
08:00:48 HBMASTER: submitting job (4, 0, 16) to dispatcher
08:00:48 DISPATCHER: trying to submit job (4, 0, 16)
08:00:48 DISPATCHER: trying to notify the job_runner thread.
08:00:48 HBMASTER: job (4, 0, 16) submitted to dispatcher
08:00:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:00:48 DISPATCHER: Trying to submit another job.
08:00:48 DISPATCHER: starting job (4, 0, 16) on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:00:48 DISPATCHER: job (4, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:00:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:00:48 WORKER: start processing job (4, 0, 16)
08:00:48 WORKER: args: ()
08:00:48 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 96, 'last_n_outputs': 2, 'lr': 0.0037176167320461437, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.09340241789634464}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:01:42 DISPATCHER: Starting worker discovery
08:01:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:01:42 DISPATCHER: Finished worker discovery
Exception in thread Thread-487:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:02:27 WORKER: done with job (4, 0, 16), trying to register it.
08:02:27 WORKER: registered result for job (4, 0, 16) with dispatcher
08:02:27 DISPATCHER: job (4, 0, 16) finished
08:02:27 DISPATCHER: register_result: lock acquired
08:02:27 DISPATCHER: job (4, 0, 16) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
08:02:27 job_id: (4, 0, 16)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 96, 'last_n_outputs': 2, 'lr': 0.0037176167320461437, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.09340241789634464}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.0030120528899602976, 'info': {'music_genre': -0.0030120528899602976, 'config': "{'batch_size': 32, 'hidden_dim': 96, 'last_n_outputs': 2, 'lr': 0.0037176167320461437, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.09340241789634464}"}}
exception: None

08:02:27 job_callback for (4, 0, 16) started
08:02:27 job_callback for (4, 0, 16) got condition
08:02:27 DISPATCHER: Trying to submit another job.
08:02:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:02:27 HBMASTER: Trying to run another job!
08:02:27 job_callback for (4, 0, 16) finished
08:02:27 start sampling a new configuration.
08:02:27 best_vector: [0, 0.22919021610266183, 0.39780335445325465, 0.1528474692848724, 0.09836265120859165, 0, 0.2744843192752441, 0.9527186633121498], 3.754705810364044e-35, 266.33245066490133, -0.01166881863604783
08:02:27 done sampling a new configuration.
08:02:27 HBMASTER: schedule new run for iteration 4
08:02:27 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
08:02:27 HBMASTER: submitting job (4, 0, 17) to dispatcher
08:02:27 DISPATCHER: trying to submit job (4, 0, 17)
08:02:27 DISPATCHER: trying to notify the job_runner thread.
08:02:27 HBMASTER: job (4, 0, 17) submitted to dispatcher
08:02:27 DISPATCHER: Trying to submit another job.
08:02:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:02:27 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:02:27 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:02:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:02:27 WORKER: start processing job (4, 0, 17)
08:02:27 WORKER: args: ()
08:02:27 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 38, 'last_n_outputs': 20, 'lr': 0.0020215986484851986, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.17358634482589508}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:02:42 DISPATCHER: Starting worker discovery
08:02:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:02:42 DISPATCHER: Finished worker discovery
Exception in thread Thread-488:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:03:42 DISPATCHER: Starting worker discovery
08:03:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:03:42 DISPATCHER: Finished worker discovery
08:04:02 WORKER: done with job (4, 0, 17), trying to register it.
08:04:02 WORKER: registered result for job (4, 0, 17) with dispatcher
08:04:02 DISPATCHER: job (4, 0, 17) finished
08:04:02 DISPATCHER: register_result: lock acquired
08:04:02 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
08:04:02 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 38, 'last_n_outputs': 20, 'lr': 0.0020215986484851986, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.17358634482589508}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1918003056845258, 'info': {'music_genre': 0.1918003056845258, 'config': "{'batch_size': 16, 'hidden_dim': 38, 'last_n_outputs': 20, 'lr': 0.0020215986484851986, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.17358634482589508}"}}
exception: None

08:04:02 job_callback for (4, 0, 17) started
08:04:02 job_callback for (4, 0, 17) got condition
08:04:02 DISPATCHER: Trying to submit another job.
08:04:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:04:02 HBMASTER: Trying to run another job!
08:04:02 job_callback for (4, 0, 17) finished
08:04:02 start sampling a new configuration.
08:04:02 best_vector: [0, 0.0654083847593474, 0.42267568758536306, 0.16079763120828364, 0.09898850620994971, 0, 0.21786634791873208, 0.8843242723771745], 1.5168962319177797e-35, 659.2408755183743, -0.005371141360553064
08:04:02 done sampling a new configuration.
08:04:02 HBMASTER: schedule new run for iteration 4
08:04:02 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
08:04:02 HBMASTER: submitting job (4, 0, 18) to dispatcher
08:04:02 DISPATCHER: trying to submit job (4, 0, 18)
08:04:02 DISPATCHER: trying to notify the job_runner thread.
08:04:02 HBMASTER: job (4, 0, 18) submitted to dispatcher
08:04:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:04:02 DISPATCHER: Trying to submit another job.
08:04:02 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:04:02 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:04:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:04:02 WORKER: start processing job (4, 0, 18)
08:04:02 WORKER: args: ()
08:04:02 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 25, 'last_n_outputs': 22, 'lr': 0.0020969847030659376, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.14142702448681643}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:04:42 DISPATCHER: Starting worker discovery
08:04:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:04:42 DISPATCHER: Finished worker discovery
Exception in thread Thread-489:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:05:38 WORKER: done with job (4, 0, 18), trying to register it.
08:05:38 WORKER: registered result for job (4, 0, 18) with dispatcher
08:05:38 DISPATCHER: job (4, 0, 18) finished
08:05:38 DISPATCHER: register_result: lock acquired
08:05:38 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
08:05:38 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 25, 'last_n_outputs': 22, 'lr': 0.0020969847030659376, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.14142702448681643}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.12071170648739697, 'info': {'music_genre': 0.12071170648739697, 'config': "{'batch_size': 16, 'hidden_dim': 25, 'last_n_outputs': 22, 'lr': 0.0020969847030659376, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.14142702448681643}"}}
exception: None

08:05:38 job_callback for (4, 0, 18) started
08:05:38 job_callback for (4, 0, 18) got condition
08:05:38 DISPATCHER: Trying to submit another job.
08:05:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:05:38 HBMASTER: Trying to run another job!
08:05:38 job_callback for (4, 0, 18) finished
08:05:38 start sampling a new configuration.
08:05:38 best_vector: [0, 0.4368964133943879, 0.5060084590901479, 0.23865471919125342, 0.09714811152243558, 0, 0.1993966952159927, 0.9013956247923369], 6.769514320260489e-34, 14.772108495392331, -0.041442038934617474
08:05:38 done sampling a new configuration.
08:05:38 HBMASTER: schedule new run for iteration 4
08:05:38 HBMASTER: trying submitting job (4, 0, 19) to dispatcher
08:05:38 HBMASTER: submitting job (4, 0, 19) to dispatcher
08:05:38 DISPATCHER: trying to submit job (4, 0, 19)
08:05:38 DISPATCHER: trying to notify the job_runner thread.
08:05:38 HBMASTER: job (4, 0, 19) submitted to dispatcher
08:05:38 DISPATCHER: Trying to submit another job.
08:05:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:05:38 DISPATCHER: starting job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:05:38 DISPATCHER: job (4, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:05:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:05:38 WORKER: start processing job (4, 0, 19)
08:05:38 WORKER: args: ()
08:05:38 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 55, 'last_n_outputs': 26, 'lr': 0.003001300208366016, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.1488479116436466}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:05:42 DISPATCHER: Starting worker discovery
08:05:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:05:42 DISPATCHER: Finished worker discovery
Exception in thread Thread-490:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:06:42 DISPATCHER: Starting worker discovery
08:06:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:06:42 DISPATCHER: Finished worker discovery
08:07:16 WORKER: done with job (4, 0, 19), trying to register it.
08:07:16 WORKER: registered result for job (4, 0, 19) with dispatcher
08:07:16 DISPATCHER: job (4, 0, 19) finished
08:07:16 DISPATCHER: register_result: lock acquired
08:07:16 DISPATCHER: job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
08:07:16 job_id: (4, 0, 19)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 55, 'last_n_outputs': 26, 'lr': 0.003001300208366016, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.1488479116436466}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.24840173033252969, 'info': {'music_genre': 0.24840173033252969, 'config': "{'batch_size': 16, 'hidden_dim': 55, 'last_n_outputs': 26, 'lr': 0.003001300208366016, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.1488479116436466}"}}
exception: None

08:07:16 job_callback for (4, 0, 19) started
08:07:16 DISPATCHER: Trying to submit another job.
08:07:16 job_callback for (4, 0, 19) got condition
08:07:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:07:16 HBMASTER: Trying to run another job!
08:07:16 job_callback for (4, 0, 19) finished
08:07:16 start sampling a new configuration.
08:07:16 done sampling a new configuration.
08:07:16 HBMASTER: schedule new run for iteration 4
08:07:16 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
08:07:16 HBMASTER: submitting job (4, 0, 20) to dispatcher
08:07:16 DISPATCHER: trying to submit job (4, 0, 20)
08:07:16 DISPATCHER: trying to notify the job_runner thread.
08:07:16 HBMASTER: job (4, 0, 20) submitted to dispatcher
08:07:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:07:16 DISPATCHER: Trying to submit another job.
08:07:16 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:07:16 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:07:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:07:16 WORKER: start processing job (4, 0, 20)
08:07:16 WORKER: args: ()
08:07:16 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 74, 'last_n_outputs': 34, 'lr': 0.034216200962014706, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.02063393934030602}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:07:42 DISPATCHER: Starting worker discovery
08:07:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:07:42 DISPATCHER: Finished worker discovery
Exception in thread Thread-491:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:08:42 DISPATCHER: Starting worker discovery
08:08:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:08:42 DISPATCHER: Finished worker discovery
08:08:51 WORKER: done with job (4, 0, 20), trying to register it.
08:08:51 WORKER: registered result for job (4, 0, 20) with dispatcher
08:08:51 DISPATCHER: job (4, 0, 20) finished
08:08:51 DISPATCHER: register_result: lock acquired
08:08:51 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
08:08:51 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 74, 'last_n_outputs': 34, 'lr': 0.034216200962014706, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.02063393934030602}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.015254337272553752, 'info': {'music_genre': 0.015254337272553752, 'config': "{'batch_size': 32, 'hidden_dim': 74, 'last_n_outputs': 34, 'lr': 0.034216200962014706, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.02063393934030602}"}}
exception: None

08:08:51 job_callback for (4, 0, 20) started
08:08:51 DISPATCHER: Trying to submit another job.
08:08:51 job_callback for (4, 0, 20) got condition
08:08:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:08:51 HBMASTER: Trying to run another job!
08:08:51 job_callback for (4, 0, 20) finished
08:08:51 start sampling a new configuration.
08:08:51 best_vector: [1, 0.42045472260198635, 0.4019370647110582, 0.22278038612059078, 0.09967290620008212, 0, 0.4904978350894779, 0.09812028382742609], 2.5879023609965173e-34, 38.64133419681771, -0.002264485896049881
08:08:51 done sampling a new configuration.
08:08:51 HBMASTER: schedule new run for iteration 4
08:08:51 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
08:08:51 HBMASTER: submitting job (4, 0, 21) to dispatcher
08:08:51 DISPATCHER: trying to submit job (4, 0, 21)
08:08:51 DISPATCHER: trying to notify the job_runner thread.
08:08:51 HBMASTER: job (4, 0, 21) submitted to dispatcher
08:08:51 DISPATCHER: Trying to submit another job.
08:08:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:08:51 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:08:51 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:08:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:08:51 WORKER: start processing job (4, 0, 21)
08:08:51 WORKER: args: ()
08:08:51 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 54, 'last_n_outputs': 21, 'lr': 0.002789721003773152, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.013417062179054466}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:09:42 DISPATCHER: Starting worker discovery
08:09:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:09:42 DISPATCHER: Finished worker discovery
Exception in thread Thread-492:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:10:26 WORKER: done with job (4, 0, 21), trying to register it.
08:10:26 WORKER: registered result for job (4, 0, 21) with dispatcher
08:10:26 DISPATCHER: job (4, 0, 21) finished
08:10:26 DISPATCHER: register_result: lock acquired
08:10:26 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
08:10:26 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 54, 'last_n_outputs': 21, 'lr': 0.002789721003773152, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.013417062179054466}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3552997842796221, 'info': {'music_genre': 0.3552997842796221, 'config': "{'batch_size': 32, 'hidden_dim': 54, 'last_n_outputs': 21, 'lr': 0.002789721003773152, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.013417062179054466}"}}
exception: None

08:10:26 job_callback for (4, 0, 21) started
08:10:26 job_callback for (4, 0, 21) got condition
08:10:26 DISPATCHER: Trying to submit another job.
08:10:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:10:26 HBMASTER: Trying to run another job!
08:10:26 job_callback for (4, 0, 21) finished
08:10:26 start sampling a new configuration.
08:10:26 done sampling a new configuration.
08:10:26 HBMASTER: schedule new run for iteration 4
08:10:26 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
08:10:26 HBMASTER: submitting job (4, 0, 22) to dispatcher
08:10:26 DISPATCHER: trying to submit job (4, 0, 22)
08:10:26 DISPATCHER: trying to notify the job_runner thread.
08:10:26 HBMASTER: job (4, 0, 22) submitted to dispatcher
08:10:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:10:26 DISPATCHER: Trying to submit another job.
08:10:26 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:10:26 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:10:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:10:26 WORKER: start processing job (4, 0, 22)
08:10:26 WORKER: args: ()
08:10:26 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 77, 'last_n_outputs': 41, 'lr': 0.0026248567236219367, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.055793856452078155}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:10:42 DISPATCHER: Starting worker discovery
08:10:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:10:42 DISPATCHER: Finished worker discovery
Exception in thread Thread-493:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:11:42 DISPATCHER: Starting worker discovery
08:11:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:11:42 DISPATCHER: Finished worker discovery
08:12:04 WORKER: done with job (4, 0, 22), trying to register it.
08:12:04 WORKER: registered result for job (4, 0, 22) with dispatcher
08:12:04 DISPATCHER: job (4, 0, 22) finished
08:12:04 DISPATCHER: register_result: lock acquired
08:12:04 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
08:12:04 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 77, 'last_n_outputs': 41, 'lr': 0.0026248567236219367, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.055793856452078155}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 77, 'last_n_outputs': 41, 'lr': 0.0026248567236219367, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.055793856452078155}"}}
exception: None

08:12:04 job_callback for (4, 0, 22) started
08:12:04 DISPATCHER: Trying to submit another job.
08:12:04 job_callback for (4, 0, 22) got condition
08:12:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:12:04 HBMASTER: Trying to run another job!
08:12:04 job_callback for (4, 0, 22) finished
08:12:04 start sampling a new configuration.
08:12:04 best_vector: [0, 0.6297052967833152, 0.630799985987792, 0.23776026162659675, 0.09855296281678594, 0, 0.12497444909508186, 0.899365736615744], 8.045488599348005e-35, 124.29325921623189, -0.010603297046431488
08:12:04 done sampling a new configuration.
08:12:04 HBMASTER: schedule new run for iteration 4
08:12:04 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
08:12:04 HBMASTER: submitting job (4, 0, 23) to dispatcher
08:12:04 DISPATCHER: trying to submit job (4, 0, 23)
08:12:04 DISPATCHER: trying to notify the job_runner thread.
08:12:04 HBMASTER: job (4, 0, 23) submitted to dispatcher
08:12:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:12:04 DISPATCHER: Trying to submit another job.
08:12:04 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:12:04 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:12:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:12:04 WORKER: start processing job (4, 0, 23)
08:12:04 WORKER: args: ()
08:12:04 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 71, 'last_n_outputs': 32, 'lr': 0.002988962891657055, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.14794551378849305}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:12:42 DISPATCHER: Starting worker discovery
08:12:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:12:42 DISPATCHER: Finished worker discovery
Exception in thread Thread-494:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:13:38 WORKER: done with job (4, 0, 23), trying to register it.
08:13:38 WORKER: registered result for job (4, 0, 23) with dispatcher
08:13:38 DISPATCHER: job (4, 0, 23) finished
08:13:38 DISPATCHER: register_result: lock acquired
08:13:38 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
08:13:38 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 71, 'last_n_outputs': 32, 'lr': 0.002988962891657055, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.14794551378849305}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2654526608776548, 'info': {'music_genre': 0.2654526608776548, 'config': "{'batch_size': 16, 'hidden_dim': 71, 'last_n_outputs': 32, 'lr': 0.002988962891657055, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.14794551378849305}"}}
exception: None

08:13:38 job_callback for (4, 0, 23) started
08:13:38 job_callback for (4, 0, 23) got condition
08:13:38 DISPATCHER: Trying to submit another job.
08:13:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:13:38 HBMASTER: Trying to run another job!
08:13:38 job_callback for (4, 0, 23) finished
08:13:38 start sampling a new configuration.
08:13:38 best_vector: [0, 0.8299096667832118, 0.6756729018182868, 0.14124723296351746, 0.10164762962817468, 0, 0.13270830956439106, 0.6468076257249326], 1.945839157078575e-34, 51.391709143183775, -0.00043581767222212423
08:13:38 done sampling a new configuration.
08:13:38 HBMASTER: schedule new run for iteration 4
08:13:38 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
08:13:38 HBMASTER: submitting job (4, 0, 24) to dispatcher
08:13:38 DISPATCHER: trying to submit job (4, 0, 24)
08:13:38 DISPATCHER: trying to notify the job_runner thread.
08:13:38 HBMASTER: job (4, 0, 24) submitted to dispatcher
08:13:38 DISPATCHER: Trying to submit another job.
08:13:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:13:38 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:13:38 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:13:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:13:38 WORKER: start processing job (4, 0, 24)
08:13:38 WORKER: args: ()
08:13:38 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 87, 'last_n_outputs': 34, 'lr': 0.001916436642052591, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.06942503741773808}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:13:42 DISPATCHER: Starting worker discovery
08:13:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:13:42 DISPATCHER: Finished worker discovery
Exception in thread Thread-495:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:14:42 DISPATCHER: Starting worker discovery
08:14:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:14:42 DISPATCHER: Finished worker discovery
08:15:13 WORKER: done with job (4, 0, 24), trying to register it.
08:15:13 WORKER: registered result for job (4, 0, 24) with dispatcher
08:15:13 DISPATCHER: job (4, 0, 24) finished
08:15:13 DISPATCHER: register_result: lock acquired
08:15:13 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
08:15:13 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 87, 'last_n_outputs': 34, 'lr': 0.001916436642052591, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.06942503741773808}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.26703044245202945, 'info': {'music_genre': 0.26703044245202945, 'config': "{'batch_size': 16, 'hidden_dim': 87, 'last_n_outputs': 34, 'lr': 0.001916436642052591, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.06942503741773808}"}}
exception: None

08:15:13 job_callback for (4, 0, 24) started
08:15:13 DISPATCHER: Trying to submit another job.
08:15:13 job_callback for (4, 0, 24) got condition
08:15:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:15:13 HBMASTER: Trying to run another job!
08:15:13 job_callback for (4, 0, 24) finished
08:15:13 start sampling a new configuration.
08:15:13 best_vector: [0, 0.9179037387303364, 0.6425753592464861, 0.4445113444902896, 0.10038741423862241, 0, 0.30199981591348235, 0.7619934276905078], 8.147623233866203e-35, 122.73517948687484, -0.0005066792886756692
08:15:13 done sampling a new configuration.
08:15:13 HBMASTER: schedule new run for iteration 4
08:15:13 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
08:15:13 HBMASTER: submitting job (4, 0, 25) to dispatcher
08:15:13 DISPATCHER: trying to submit job (4, 0, 25)
08:15:13 DISPATCHER: trying to notify the job_runner thread.
08:15:13 HBMASTER: job (4, 0, 25) submitted to dispatcher
08:15:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:15:13 DISPATCHER: Trying to submit another job.
08:15:13 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:15:13 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:15:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:15:13 WORKER: start processing job (4, 0, 25)
08:15:13 WORKER: args: ()
08:15:13 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 94, 'last_n_outputs': 33, 'lr': 0.007745022593060224, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.09803390581738819}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:15:42 DISPATCHER: Starting worker discovery
08:15:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:15:42 DISPATCHER: Finished worker discovery
Exception in thread Thread-496:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:16:42 DISPATCHER: Starting worker discovery
08:16:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:16:42 DISPATCHER: Finished worker discovery
08:16:50 WORKER: done with job (4, 0, 25), trying to register it.
08:16:50 WORKER: registered result for job (4, 0, 25) with dispatcher
08:16:50 DISPATCHER: job (4, 0, 25) finished
08:16:50 DISPATCHER: register_result: lock acquired
08:16:50 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
08:16:50 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 94, 'last_n_outputs': 33, 'lr': 0.007745022593060224, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.09803390581738819}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.18415302287584975, 'info': {'music_genre': 0.18415302287584975, 'config': "{'batch_size': 16, 'hidden_dim': 94, 'last_n_outputs': 33, 'lr': 0.007745022593060224, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.09803390581738819}"}}
exception: None

08:16:50 job_callback for (4, 0, 25) started
08:16:50 job_callback for (4, 0, 25) got condition
08:16:50 DISPATCHER: Trying to submit another job.
08:16:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:16:50 HBMASTER: Trying to run another job!
08:16:50 job_callback for (4, 0, 25) finished
08:16:50 start sampling a new configuration.
08:16:50 best_vector: [1, 0.31668893610162263, 0.4986609954411348, 0.09304102436899678, 0.0967261956539201, 0, 0.2402073858732002, 0.12126727737559875], 2.8984026913769356e-33, 3.450176205587682, -0.004745115139012556
08:16:50 done sampling a new configuration.
08:16:50 HBMASTER: schedule new run for iteration 4
08:16:50 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
08:16:50 HBMASTER: submitting job (4, 0, 26) to dispatcher
08:16:50 DISPATCHER: trying to submit job (4, 0, 26)
08:16:50 DISPATCHER: trying to notify the job_runner thread.
08:16:50 HBMASTER: job (4, 0, 26) submitted to dispatcher
08:16:50 DISPATCHER: Trying to submit another job.
08:16:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:16:50 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:16:50 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:16:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:16:50 WORKER: start processing job (4, 0, 26)
08:16:50 WORKER: args: ()
08:16:50 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 45, 'last_n_outputs': 25, 'lr': 0.0015349069364753868, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.01438044632274306}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:17:42 DISPATCHER: Starting worker discovery
08:17:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:17:42 DISPATCHER: Finished worker discovery
Exception in thread Thread-497:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:18:25 WORKER: done with job (4, 0, 26), trying to register it.
08:18:25 WORKER: registered result for job (4, 0, 26) with dispatcher
08:18:25 DISPATCHER: job (4, 0, 26) finished
08:18:25 DISPATCHER: register_result: lock acquired
08:18:25 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
08:18:25 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 45, 'last_n_outputs': 25, 'lr': 0.0015349069364753868, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.01438044632274306}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.31018981226630293, 'info': {'music_genre': 0.31018981226630293, 'config': "{'batch_size': 32, 'hidden_dim': 45, 'last_n_outputs': 25, 'lr': 0.0015349069364753868, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.01438044632274306}"}}
exception: None

08:18:25 job_callback for (4, 0, 26) started
08:18:25 job_callback for (4, 0, 26) got condition
08:18:25 DISPATCHER: Trying to submit another job.
08:18:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:18:25 HBMASTER: Trying to run another job!
08:18:25 job_callback for (4, 0, 26) finished
08:18:25 ITERATION: Advancing config (4, 0, 1) to next budget 133.333333
08:18:25 ITERATION: Advancing config (4, 0, 3) to next budget 133.333333
08:18:25 ITERATION: Advancing config (4, 0, 5) to next budget 133.333333
08:18:25 ITERATION: Advancing config (4, 0, 10) to next budget 133.333333
08:18:25 ITERATION: Advancing config (4, 0, 13) to next budget 133.333333
08:18:25 ITERATION: Advancing config (4, 0, 21) to next budget 133.333333
08:18:25 ITERATION: Advancing config (4, 0, 23) to next budget 133.333333
08:18:25 ITERATION: Advancing config (4, 0, 24) to next budget 133.333333
08:18:25 ITERATION: Advancing config (4, 0, 26) to next budget 133.333333
08:18:25 HBMASTER: schedule new run for iteration 4
08:18:25 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
08:18:25 HBMASTER: submitting job (4, 0, 1) to dispatcher
08:18:25 DISPATCHER: trying to submit job (4, 0, 1)
08:18:25 DISPATCHER: trying to notify the job_runner thread.
08:18:25 HBMASTER: job (4, 0, 1) submitted to dispatcher
08:18:25 DISPATCHER: Trying to submit another job.
08:18:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:18:25 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:18:25 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:18:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:18:25 WORKER: start processing job (4, 0, 1)
08:18:25 WORKER: args: ()
08:18:25 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 74, 'last_n_outputs': 40, 'lr': 0.0018581154964888394, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.10434725821517864}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:18:42 DISPATCHER: Starting worker discovery
08:18:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:18:42 DISPATCHER: Finished worker discovery
Exception in thread Thread-498:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:19:42 DISPATCHER: Starting worker discovery
08:19:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:19:42 DISPATCHER: Finished worker discovery
08:20:42 DISPATCHER: Starting worker discovery
08:20:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:20:42 DISPATCHER: Finished worker discovery
08:21:29 WORKER: done with job (4, 0, 1), trying to register it.
08:21:29 WORKER: registered result for job (4, 0, 1) with dispatcher
08:21:29 DISPATCHER: job (4, 0, 1) finished
08:21:29 DISPATCHER: register_result: lock acquired
08:21:29 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
08:21:29 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 74, 'last_n_outputs': 40, 'lr': 0.0018581154964888394, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.10434725821517864}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2255344439128314, 'info': {'music_genre': 0.2255344439128314, 'config': "{'batch_size': 16, 'hidden_dim': 74, 'last_n_outputs': 40, 'lr': 0.0018581154964888394, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.10434725821517864}"}}
exception: None

08:21:29 job_callback for (4, 0, 1) started
08:21:29 job_callback for (4, 0, 1) got condition
08:21:29 DISPATCHER: Trying to submit another job.
08:21:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:21:29 done building a new model for budget 133.333333 based on 9/16 split
Best loss for this budget:-0.296284





08:21:29 HBMASTER: Trying to run another job!
08:21:29 job_callback for (4, 0, 1) finished
08:21:29 HBMASTER: schedule new run for iteration 4
08:21:29 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
08:21:29 HBMASTER: submitting job (4, 0, 3) to dispatcher
08:21:29 DISPATCHER: trying to submit job (4, 0, 3)
08:21:29 DISPATCHER: trying to notify the job_runner thread.
08:21:29 HBMASTER: job (4, 0, 3) submitted to dispatcher
08:21:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:21:29 DISPATCHER: Trying to submit another job.
08:21:29 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:21:29 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:21:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:21:29 WORKER: start processing job (4, 0, 3)
08:21:29 WORKER: args: ()
08:21:29 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 45, 'lr': 0.0028448249161392184, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.02975502405402875}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:21:42 DISPATCHER: Starting worker discovery
08:21:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:21:42 DISPATCHER: Finished worker discovery
Exception in thread Thread-499:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:22:42 DISPATCHER: Starting worker discovery
08:22:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:22:42 DISPATCHER: Finished worker discovery
08:23:42 DISPATCHER: Starting worker discovery
08:23:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:23:42 DISPATCHER: Finished worker discovery
08:24:34 WORKER: done with job (4, 0, 3), trying to register it.
08:24:34 WORKER: registered result for job (4, 0, 3) with dispatcher
08:24:34 DISPATCHER: job (4, 0, 3) finished
08:24:34 DISPATCHER: register_result: lock acquired
08:24:34 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
08:24:34 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 45, 'lr': 0.0028448249161392184, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.02975502405402875}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3651948485352613, 'info': {'music_genre': 0.3651948485352613, 'config': "{'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 45, 'lr': 0.0028448249161392184, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.02975502405402875}"}}
exception: None

08:24:34 job_callback for (4, 0, 3) started
08:24:34 job_callback for (4, 0, 3) got condition
08:24:34 DISPATCHER: Trying to submit another job.
08:24:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:24:34 done building a new model for budget 133.333333 based on 9/17 split
Best loss for this budget:-0.365195





08:24:34 HBMASTER: Trying to run another job!
08:24:34 job_callback for (4, 0, 3) finished
08:24:34 HBMASTER: schedule new run for iteration 4
08:24:34 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
08:24:34 HBMASTER: submitting job (4, 0, 5) to dispatcher
08:24:34 DISPATCHER: trying to submit job (4, 0, 5)
08:24:34 DISPATCHER: trying to notify the job_runner thread.
08:24:34 HBMASTER: job (4, 0, 5) submitted to dispatcher
08:24:34 DISPATCHER: Trying to submit another job.
08:24:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:24:34 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:24:34 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:24:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:24:34 WORKER: start processing job (4, 0, 5)
08:24:34 WORKER: args: ()
08:24:34 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 62, 'last_n_outputs': 8, 'lr': 0.0035589887234435324, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.01942138942228131}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:24:42 DISPATCHER: Starting worker discovery
08:24:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:24:42 DISPATCHER: Finished worker discovery
Exception in thread Thread-500:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:25:42 DISPATCHER: Starting worker discovery
08:25:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:25:42 DISPATCHER: Finished worker discovery
08:26:42 DISPATCHER: Starting worker discovery
08:26:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:26:42 DISPATCHER: Finished worker discovery
08:27:41 WORKER: done with job (4, 0, 5), trying to register it.
08:27:41 WORKER: registered result for job (4, 0, 5) with dispatcher
08:27:41 DISPATCHER: job (4, 0, 5) finished
08:27:41 DISPATCHER: register_result: lock acquired
08:27:41 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
08:27:41 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 62, 'last_n_outputs': 8, 'lr': 0.0035589887234435324, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.01942138942228131}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.325593682934252, 'info': {'music_genre': 0.325593682934252, 'config': "{'batch_size': 32, 'hidden_dim': 62, 'last_n_outputs': 8, 'lr': 0.0035589887234435324, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.01942138942228131}"}}
exception: None

08:27:41 job_callback for (4, 0, 5) started
08:27:41 job_callback for (4, 0, 5) got condition
08:27:41 DISPATCHER: Trying to submit another job.
08:27:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:27:41 done building a new model for budget 133.333333 based on 9/17 split
Best loss for this budget:-0.365195





08:27:41 HBMASTER: Trying to run another job!
08:27:41 job_callback for (4, 0, 5) finished
08:27:41 HBMASTER: schedule new run for iteration 4
08:27:41 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
08:27:41 HBMASTER: submitting job (4, 0, 10) to dispatcher
08:27:41 DISPATCHER: trying to submit job (4, 0, 10)
08:27:41 DISPATCHER: trying to notify the job_runner thread.
08:27:41 HBMASTER: job (4, 0, 10) submitted to dispatcher
08:27:41 DISPATCHER: Trying to submit another job.
08:27:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:27:41 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:27:41 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:27:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:27:41 WORKER: start processing job (4, 0, 10)
08:27:41 WORKER: args: ()
08:27:41 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 23, 'last_n_outputs': 13, 'lr': 0.0034838212660416065, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.020775851312166776}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:27:42 DISPATCHER: Starting worker discovery
08:27:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:27:42 DISPATCHER: Finished worker discovery
Exception in thread Thread-501:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:28:42 DISPATCHER: Starting worker discovery
08:28:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:28:42 DISPATCHER: Finished worker discovery
08:29:42 DISPATCHER: Starting worker discovery
08:29:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:29:42 DISPATCHER: Finished worker discovery
08:30:42 DISPATCHER: Starting worker discovery
08:30:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:30:42 DISPATCHER: Finished worker discovery
08:30:46 WORKER: done with job (4, 0, 10), trying to register it.
08:30:46 WORKER: registered result for job (4, 0, 10) with dispatcher
08:30:46 DISPATCHER: job (4, 0, 10) finished
08:30:46 DISPATCHER: register_result: lock acquired
08:30:46 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
08:30:46 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 23, 'last_n_outputs': 13, 'lr': 0.0034838212660416065, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.020775851312166776}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.26804677377510305, 'info': {'music_genre': 0.26804677377510305, 'config': "{'batch_size': 32, 'hidden_dim': 23, 'last_n_outputs': 13, 'lr': 0.0034838212660416065, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.020775851312166776}"}}
exception: None

08:30:46 job_callback for (4, 0, 10) started
08:30:46 DISPATCHER: Trying to submit another job.
08:30:46 job_callback for (4, 0, 10) got condition
08:30:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:30:46 done building a new model for budget 133.333333 based on 9/18 split
Best loss for this budget:-0.365195





08:30:46 HBMASTER: Trying to run another job!
08:30:46 job_callback for (4, 0, 10) finished
08:30:46 HBMASTER: schedule new run for iteration 4
08:30:46 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
08:30:46 HBMASTER: submitting job (4, 0, 13) to dispatcher
08:30:46 DISPATCHER: trying to submit job (4, 0, 13)
08:30:46 DISPATCHER: trying to notify the job_runner thread.
08:30:46 HBMASTER: job (4, 0, 13) submitted to dispatcher
08:30:46 DISPATCHER: Trying to submit another job.
08:30:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:30:46 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:30:46 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:30:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:30:46 WORKER: start processing job (4, 0, 13)
08:30:46 WORKER: args: ()
08:30:46 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 60, 'last_n_outputs': 18, 'lr': 0.0032171038864320023, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.01422906138390953}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:31:42 DISPATCHER: Starting worker discovery
08:31:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:31:42 DISPATCHER: Finished worker discovery
Exception in thread Thread-502:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:32:42 DISPATCHER: Starting worker discovery
08:32:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:32:42 DISPATCHER: Finished worker discovery
08:33:42 DISPATCHER: Starting worker discovery
08:33:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:33:42 DISPATCHER: Finished worker discovery
08:33:52 WORKER: done with job (4, 0, 13), trying to register it.
08:33:52 WORKER: registered result for job (4, 0, 13) with dispatcher
08:33:52 DISPATCHER: job (4, 0, 13) finished
08:33:52 DISPATCHER: register_result: lock acquired
08:33:52 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
08:33:52 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 60, 'last_n_outputs': 18, 'lr': 0.0032171038864320023, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.01422906138390953}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.278457610267753, 'info': {'music_genre': 0.278457610267753, 'config': "{'batch_size': 32, 'hidden_dim': 60, 'last_n_outputs': 18, 'lr': 0.0032171038864320023, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.01422906138390953}"}}
exception: None

08:33:52 job_callback for (4, 0, 13) started
08:33:52 DISPATCHER: Trying to submit another job.
08:33:52 job_callback for (4, 0, 13) got condition
08:33:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:33:52 done building a new model for budget 133.333333 based on 9/19 split
Best loss for this budget:-0.365195





08:33:52 HBMASTER: Trying to run another job!
08:33:52 job_callback for (4, 0, 13) finished
08:33:52 HBMASTER: schedule new run for iteration 4
08:33:52 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
08:33:52 HBMASTER: submitting job (4, 0, 21) to dispatcher
08:33:52 DISPATCHER: trying to submit job (4, 0, 21)
08:33:52 DISPATCHER: trying to notify the job_runner thread.
08:33:52 HBMASTER: job (4, 0, 21) submitted to dispatcher
08:33:52 DISPATCHER: Trying to submit another job.
08:33:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:33:52 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:33:52 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:33:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:33:52 WORKER: start processing job (4, 0, 21)
08:33:52 WORKER: args: ()
08:33:52 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 54, 'last_n_outputs': 21, 'lr': 0.002789721003773152, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.013417062179054466}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:34:42 DISPATCHER: Starting worker discovery
08:34:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:34:42 DISPATCHER: Finished worker discovery
Exception in thread Thread-503:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:35:42 DISPATCHER: Starting worker discovery
08:35:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:35:42 DISPATCHER: Finished worker discovery
08:36:42 DISPATCHER: Starting worker discovery
08:36:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:36:42 DISPATCHER: Finished worker discovery
08:36:58 WORKER: done with job (4, 0, 21), trying to register it.
08:36:58 WORKER: registered result for job (4, 0, 21) with dispatcher
08:36:58 DISPATCHER: job (4, 0, 21) finished
08:36:58 DISPATCHER: register_result: lock acquired
08:36:58 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
08:36:58 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 54, 'last_n_outputs': 21, 'lr': 0.002789721003773152, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.013417062179054466}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.35785160292498275, 'info': {'music_genre': 0.35785160292498275, 'config': "{'batch_size': 32, 'hidden_dim': 54, 'last_n_outputs': 21, 'lr': 0.002789721003773152, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.013417062179054466}"}}
exception: None

08:36:58 job_callback for (4, 0, 21) started
08:36:58 DISPATCHER: Trying to submit another job.
08:36:58 job_callback for (4, 0, 21) got condition
08:36:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:36:58 done building a new model for budget 133.333333 based on 9/20 split
Best loss for this budget:-0.365195





08:36:58 HBMASTER: Trying to run another job!
08:36:58 job_callback for (4, 0, 21) finished
08:36:58 HBMASTER: schedule new run for iteration 4
08:36:58 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
08:36:58 HBMASTER: submitting job (4, 0, 23) to dispatcher
08:36:58 DISPATCHER: trying to submit job (4, 0, 23)
08:36:58 DISPATCHER: trying to notify the job_runner thread.
08:36:58 HBMASTER: job (4, 0, 23) submitted to dispatcher
08:36:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:36:58 DISPATCHER: Trying to submit another job.
08:36:58 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:36:58 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:36:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:36:58 WORKER: start processing job (4, 0, 23)
08:36:58 WORKER: args: ()
08:36:58 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 71, 'last_n_outputs': 32, 'lr': 0.002988962891657055, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.14794551378849305}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:37:42 DISPATCHER: Starting worker discovery
08:37:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:37:42 DISPATCHER: Finished worker discovery
Exception in thread Thread-504:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:38:42 DISPATCHER: Starting worker discovery
08:38:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:38:42 DISPATCHER: Finished worker discovery
08:39:42 DISPATCHER: Starting worker discovery
08:39:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:39:42 DISPATCHER: Finished worker discovery
08:40:05 WORKER: done with job (4, 0, 23), trying to register it.
08:40:05 WORKER: registered result for job (4, 0, 23) with dispatcher
08:40:05 DISPATCHER: job (4, 0, 23) finished
08:40:05 DISPATCHER: register_result: lock acquired
08:40:05 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
08:40:05 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 71, 'last_n_outputs': 32, 'lr': 0.002988962891657055, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.14794551378849305}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.16698602569657126, 'info': {'music_genre': 0.16698602569657126, 'config': "{'batch_size': 16, 'hidden_dim': 71, 'last_n_outputs': 32, 'lr': 0.002988962891657055, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.14794551378849305}"}}
exception: None

08:40:05 job_callback for (4, 0, 23) started
08:40:05 job_callback for (4, 0, 23) got condition
08:40:05 DISPATCHER: Trying to submit another job.
08:40:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:40:05 done building a new model for budget 133.333333 based on 9/21 split
Best loss for this budget:-0.365195





08:40:05 HBMASTER: Trying to run another job!
08:40:05 job_callback for (4, 0, 23) finished
08:40:05 HBMASTER: schedule new run for iteration 4
08:40:05 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
08:40:05 HBMASTER: submitting job (4, 0, 24) to dispatcher
08:40:05 DISPATCHER: trying to submit job (4, 0, 24)
08:40:05 DISPATCHER: trying to notify the job_runner thread.
08:40:05 HBMASTER: job (4, 0, 24) submitted to dispatcher
08:40:05 DISPATCHER: Trying to submit another job.
08:40:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:40:05 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:40:05 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:40:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:40:05 WORKER: start processing job (4, 0, 24)
08:40:05 WORKER: args: ()
08:40:05 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 87, 'last_n_outputs': 34, 'lr': 0.001916436642052591, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.06942503741773808}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:40:42 DISPATCHER: Starting worker discovery
08:40:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:40:42 DISPATCHER: Finished worker discovery
Exception in thread Thread-505:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:41:42 DISPATCHER: Starting worker discovery
08:41:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:41:42 DISPATCHER: Finished worker discovery
08:42:42 DISPATCHER: Starting worker discovery
08:42:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:42:42 DISPATCHER: Finished worker discovery
08:43:11 WORKER: done with job (4, 0, 24), trying to register it.
08:43:11 WORKER: registered result for job (4, 0, 24) with dispatcher
08:43:11 DISPATCHER: job (4, 0, 24) finished
08:43:11 DISPATCHER: register_result: lock acquired
08:43:11 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
08:43:11 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 87, 'last_n_outputs': 34, 'lr': 0.001916436642052591, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.06942503741773808}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.22713524637184285, 'info': {'music_genre': 0.22713524637184285, 'config': "{'batch_size': 16, 'hidden_dim': 87, 'last_n_outputs': 34, 'lr': 0.001916436642052591, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.06942503741773808}"}}
exception: None

08:43:11 job_callback for (4, 0, 24) started
08:43:11 job_callback for (4, 0, 24) got condition
08:43:11 DISPATCHER: Trying to submit another job.
08:43:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:43:11 done building a new model for budget 133.333333 based on 9/22 split
Best loss for this budget:-0.365195





08:43:11 HBMASTER: Trying to run another job!
08:43:11 job_callback for (4, 0, 24) finished
08:43:11 HBMASTER: schedule new run for iteration 4
08:43:11 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
08:43:11 HBMASTER: submitting job (4, 0, 26) to dispatcher
08:43:11 DISPATCHER: trying to submit job (4, 0, 26)
08:43:11 DISPATCHER: trying to notify the job_runner thread.
08:43:11 HBMASTER: job (4, 0, 26) submitted to dispatcher
08:43:11 DISPATCHER: Trying to submit another job.
08:43:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:43:11 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:43:11 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:43:11 WORKER: start processing job (4, 0, 26)
08:43:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:43:11 WORKER: args: ()
08:43:11 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 45, 'last_n_outputs': 25, 'lr': 0.0015349069364753868, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.01438044632274306}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:43:42 DISPATCHER: Starting worker discovery
08:43:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:43:42 DISPATCHER: Finished worker discovery
Exception in thread Thread-506:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:44:42 DISPATCHER: Starting worker discovery
08:44:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:44:42 DISPATCHER: Finished worker discovery
08:45:42 DISPATCHER: Starting worker discovery
08:45:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:45:42 DISPATCHER: Finished worker discovery
08:46:16 WORKER: done with job (4, 0, 26), trying to register it.
08:46:16 WORKER: registered result for job (4, 0, 26) with dispatcher
08:46:16 DISPATCHER: job (4, 0, 26) finished
08:46:16 DISPATCHER: register_result: lock acquired
08:46:16 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
08:46:16 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 45, 'last_n_outputs': 25, 'lr': 0.0015349069364753868, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.01438044632274306}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2849867803074708, 'info': {'music_genre': 0.2849867803074708, 'config': "{'batch_size': 32, 'hidden_dim': 45, 'last_n_outputs': 25, 'lr': 0.0015349069364753868, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.01438044632274306}"}}
exception: None

08:46:16 job_callback for (4, 0, 26) started
08:46:16 job_callback for (4, 0, 26) got condition
08:46:16 DISPATCHER: Trying to submit another job.
08:46:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:46:16 done building a new model for budget 133.333333 based on 9/22 split
Best loss for this budget:-0.365195





08:46:16 HBMASTER: Trying to run another job!
08:46:16 job_callback for (4, 0, 26) finished
08:46:16 ITERATION: Advancing config (4, 0, 3) to next budget 400.000000
08:46:16 ITERATION: Advancing config (4, 0, 5) to next budget 400.000000
08:46:16 ITERATION: Advancing config (4, 0, 21) to next budget 400.000000
08:46:16 HBMASTER: schedule new run for iteration 4
08:46:16 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
08:46:16 HBMASTER: submitting job (4, 0, 3) to dispatcher
08:46:16 DISPATCHER: trying to submit job (4, 0, 3)
08:46:16 DISPATCHER: trying to notify the job_runner thread.
08:46:16 HBMASTER: job (4, 0, 3) submitted to dispatcher
08:46:16 DISPATCHER: Trying to submit another job.
08:46:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:46:16 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:46:16 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:46:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:46:16 WORKER: start processing job (4, 0, 3)
08:46:16 WORKER: args: ()
08:46:16 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 45, 'lr': 0.0028448249161392184, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.02975502405402875}, 'budget': 400.0, 'working_directory': '.'}
08:46:42 DISPATCHER: Starting worker discovery
08:46:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:46:42 DISPATCHER: Finished worker discovery
Exception in thread Thread-507:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:47:42 DISPATCHER: Starting worker discovery
08:47:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:47:42 DISPATCHER: Finished worker discovery
08:48:42 DISPATCHER: Starting worker discovery
08:48:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:48:42 DISPATCHER: Finished worker discovery
08:49:42 DISPATCHER: Starting worker discovery
08:49:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:49:42 DISPATCHER: Finished worker discovery
08:50:42 DISPATCHER: Starting worker discovery
08:50:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:50:42 DISPATCHER: Finished worker discovery
08:51:42 DISPATCHER: Starting worker discovery
08:51:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:51:42 DISPATCHER: Finished worker discovery
08:52:42 DISPATCHER: Starting worker discovery
08:52:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:52:42 DISPATCHER: Finished worker discovery
08:53:42 DISPATCHER: Starting worker discovery
08:53:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:53:42 DISPATCHER: Finished worker discovery
08:53:49 WORKER: done with job (4, 0, 3), trying to register it.
08:53:49 WORKER: registered result for job (4, 0, 3) with dispatcher
08:53:49 DISPATCHER: job (4, 0, 3) finished
08:53:49 DISPATCHER: register_result: lock acquired
08:53:49 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
08:53:49 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 45, 'lr': 0.0028448249161392184, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.02975502405402875}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3514512892123392, 'info': {'music_genre': 0.3514512892123392, 'config': "{'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 45, 'lr': 0.0028448249161392184, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.02975502405402875}"}}
exception: None

08:53:49 job_callback for (4, 0, 3) started
08:53:49 DISPATCHER: Trying to submit another job.
08:53:49 job_callback for (4, 0, 3) got condition
08:53:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:53:49 HBMASTER: Trying to run another job!
08:53:49 job_callback for (4, 0, 3) finished
08:53:49 HBMASTER: schedule new run for iteration 4
08:53:49 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
08:53:49 HBMASTER: submitting job (4, 0, 5) to dispatcher
08:53:49 DISPATCHER: trying to submit job (4, 0, 5)
08:53:49 DISPATCHER: trying to notify the job_runner thread.
08:53:49 HBMASTER: job (4, 0, 5) submitted to dispatcher
08:53:49 DISPATCHER: Trying to submit another job.
08:53:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:53:49 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:53:49 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
08:53:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:53:49 WORKER: start processing job (4, 0, 5)
08:53:49 WORKER: args: ()
08:53:49 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 62, 'last_n_outputs': 8, 'lr': 0.0035589887234435324, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.01942138942228131}, 'budget': 400.0, 'working_directory': '.'}
08:54:42 DISPATCHER: Starting worker discovery
08:54:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:54:42 DISPATCHER: Finished worker discovery
Exception in thread Thread-508:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:55:42 DISPATCHER: Starting worker discovery
08:55:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:55:42 DISPATCHER: Finished worker discovery
08:56:42 DISPATCHER: Starting worker discovery
08:56:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:56:42 DISPATCHER: Finished worker discovery
08:57:42 DISPATCHER: Starting worker discovery
08:57:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:57:42 DISPATCHER: Finished worker discovery
08:58:42 DISPATCHER: Starting worker discovery
08:58:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:58:42 DISPATCHER: Finished worker discovery
08:59:42 DISPATCHER: Starting worker discovery
08:59:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:59:42 DISPATCHER: Finished worker discovery
09:00:42 DISPATCHER: Starting worker discovery
09:00:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:00:42 DISPATCHER: Finished worker discovery
09:01:20 WORKER: done with job (4, 0, 5), trying to register it.
09:01:20 WORKER: registered result for job (4, 0, 5) with dispatcher
09:01:20 DISPATCHER: job (4, 0, 5) finished
09:01:20 DISPATCHER: register_result: lock acquired
09:01:20 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
09:01:20 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 62, 'last_n_outputs': 8, 'lr': 0.0035589887234435324, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.01942138942228131}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.27462594840816557, 'info': {'music_genre': 0.27462594840816557, 'config': "{'batch_size': 32, 'hidden_dim': 62, 'last_n_outputs': 8, 'lr': 0.0035589887234435324, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.01942138942228131}"}}
exception: None

09:01:20 job_callback for (4, 0, 5) started
09:01:20 DISPATCHER: Trying to submit another job.
09:01:20 job_callback for (4, 0, 5) got condition
09:01:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:01:20 HBMASTER: Trying to run another job!
09:01:20 job_callback for (4, 0, 5) finished
09:01:20 HBMASTER: schedule new run for iteration 4
09:01:20 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
09:01:20 HBMASTER: submitting job (4, 0, 21) to dispatcher
09:01:20 DISPATCHER: trying to submit job (4, 0, 21)
09:01:20 DISPATCHER: trying to notify the job_runner thread.
09:01:20 HBMASTER: job (4, 0, 21) submitted to dispatcher
09:01:20 DISPATCHER: Trying to submit another job.
09:01:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:01:20 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:01:20 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:01:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:01:20 WORKER: start processing job (4, 0, 21)
09:01:20 WORKER: args: ()
09:01:20 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 54, 'last_n_outputs': 21, 'lr': 0.002789721003773152, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.013417062179054466}, 'budget': 400.0, 'working_directory': '.'}
09:01:42 DISPATCHER: Starting worker discovery
09:01:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:01:42 DISPATCHER: Finished worker discovery
Exception in thread Thread-509:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:02:42 DISPATCHER: Starting worker discovery
09:02:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:02:42 DISPATCHER: Finished worker discovery
09:03:42 DISPATCHER: Starting worker discovery
09:03:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:03:42 DISPATCHER: Finished worker discovery
09:04:42 DISPATCHER: Starting worker discovery
09:04:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:04:42 DISPATCHER: Finished worker discovery
09:05:42 DISPATCHER: Starting worker discovery
09:05:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:05:42 DISPATCHER: Finished worker discovery
09:06:42 DISPATCHER: Starting worker discovery
09:06:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:06:42 DISPATCHER: Finished worker discovery
09:07:42 DISPATCHER: Starting worker discovery
09:07:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:07:42 DISPATCHER: Finished worker discovery
09:08:42 DISPATCHER: Starting worker discovery
09:08:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:08:42 DISPATCHER: Finished worker discovery
09:08:50 WORKER: done with job (4, 0, 21), trying to register it.
09:08:50 WORKER: registered result for job (4, 0, 21) with dispatcher
09:08:50 DISPATCHER: job (4, 0, 21) finished
09:08:50 DISPATCHER: register_result: lock acquired
09:08:50 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
09:08:50 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 54, 'last_n_outputs': 21, 'lr': 0.002789721003773152, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.013417062179054466}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3442983978934932, 'info': {'music_genre': 0.3442983978934932, 'config': "{'batch_size': 32, 'hidden_dim': 54, 'last_n_outputs': 21, 'lr': 0.002789721003773152, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.013417062179054466}"}}
exception: None

09:08:50 job_callback for (4, 0, 21) started
09:08:50 DISPATCHER: Trying to submit another job.
09:08:50 job_callback for (4, 0, 21) got condition
09:08:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:08:50 HBMASTER: Trying to run another job!
09:08:50 job_callback for (4, 0, 21) finished
09:08:50 ITERATION: Advancing config (4, 0, 3) to next budget 1200.000000
09:08:50 HBMASTER: schedule new run for iteration 4
09:08:50 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
09:08:50 HBMASTER: submitting job (4, 0, 3) to dispatcher
09:08:50 DISPATCHER: trying to submit job (4, 0, 3)
09:08:50 DISPATCHER: trying to notify the job_runner thread.
09:08:50 HBMASTER: job (4, 0, 3) submitted to dispatcher
09:08:50 DISPATCHER: Trying to submit another job.
09:08:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:08:50 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:08:50 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:08:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:08:50 WORKER: start processing job (4, 0, 3)
09:08:50 WORKER: args: ()
09:08:50 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 45, 'lr': 0.0028448249161392184, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.02975502405402875}, 'budget': 1200.0, 'working_directory': '.'}
09:09:42 DISPATCHER: Starting worker discovery
09:09:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:09:42 DISPATCHER: Finished worker discovery
Exception in thread Thread-510:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:10:42 DISPATCHER: Starting worker discovery
09:10:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:10:42 DISPATCHER: Finished worker discovery
09:11:42 DISPATCHER: Starting worker discovery
09:11:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:11:42 DISPATCHER: Finished worker discovery
09:12:42 DISPATCHER: Starting worker discovery
09:12:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:12:42 DISPATCHER: Finished worker discovery
09:13:42 DISPATCHER: Starting worker discovery
09:13:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:13:42 DISPATCHER: Finished worker discovery
09:14:42 DISPATCHER: Starting worker discovery
09:14:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:14:42 DISPATCHER: Finished worker discovery
09:15:42 DISPATCHER: Starting worker discovery
09:15:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:15:42 DISPATCHER: Finished worker discovery
09:16:42 DISPATCHER: Starting worker discovery
09:16:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:16:42 DISPATCHER: Finished worker discovery
09:17:42 DISPATCHER: Starting worker discovery
09:17:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:17:42 DISPATCHER: Finished worker discovery
09:18:42 DISPATCHER: Starting worker discovery
09:18:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:18:42 DISPATCHER: Finished worker discovery
09:19:42 DISPATCHER: Starting worker discovery
09:19:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:19:42 DISPATCHER: Finished worker discovery
09:20:42 DISPATCHER: Starting worker discovery
09:20:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:20:42 DISPATCHER: Finished worker discovery
09:21:42 DISPATCHER: Starting worker discovery
09:21:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:21:42 DISPATCHER: Finished worker discovery
09:22:42 DISPATCHER: Starting worker discovery
09:22:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:22:42 DISPATCHER: Finished worker discovery
09:23:42 DISPATCHER: Starting worker discovery
09:23:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:23:42 DISPATCHER: Finished worker discovery
09:24:42 DISPATCHER: Starting worker discovery
09:24:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:24:42 DISPATCHER: Finished worker discovery
09:25:42 DISPATCHER: Starting worker discovery
09:25:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:25:42 DISPATCHER: Finished worker discovery
09:26:42 DISPATCHER: Starting worker discovery
09:26:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:26:42 DISPATCHER: Finished worker discovery
09:27:42 DISPATCHER: Starting worker discovery
09:27:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:27:42 DISPATCHER: Finished worker discovery
09:28:42 DISPATCHER: Starting worker discovery
09:28:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:28:42 DISPATCHER: Finished worker discovery
09:29:40 WORKER: done with job (4, 0, 3), trying to register it.
09:29:40 WORKER: registered result for job (4, 0, 3) with dispatcher
09:29:40 DISPATCHER: job (4, 0, 3) finished
09:29:40 DISPATCHER: register_result: lock acquired
09:29:40 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
09:29:40 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 45, 'lr': 0.0028448249161392184, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.02975502405402875}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.36795307466957294, 'info': {'music_genre': 0.36795307466957294, 'config': "{'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 45, 'lr': 0.0028448249161392184, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.02975502405402875}"}}
exception: None

09:29:40 job_callback for (4, 0, 3) started
09:29:40 DISPATCHER: Trying to submit another job.
09:29:40 job_callback for (4, 0, 3) got condition
09:29:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:29:40 HBMASTER: Trying to run another job!
09:29:40 job_callback for (4, 0, 3) finished
09:29:40 start sampling a new configuration.
09:29:40 best_vector: [1, 0.9481795280574163, 0.7288046702993252, 0.44452774033505604, 0.10027017922497981, 0, 0.4422652285904718, 0.0022855224664194707], 1.0819470472434642e-05, 354.5322872725779, 0.0038358516136703727
09:29:40 done sampling a new configuration.
09:29:40 HBMASTER: schedule new run for iteration 5
09:29:40 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
09:29:40 HBMASTER: submitting job (5, 0, 0) to dispatcher
09:29:40 DISPATCHER: trying to submit job (5, 0, 0)
09:29:40 DISPATCHER: trying to notify the job_runner thread.
09:29:40 HBMASTER: job (5, 0, 0) submitted to dispatcher
09:29:40 DISPATCHER: Trying to submit another job.
09:29:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:29:40 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:29:40 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:29:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:29:40 WORKER: start processing job (5, 0, 0)
09:29:40 WORKER: args: ()
09:29:40 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 96, 'last_n_outputs': 37, 'lr': 0.007745607408146055, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.010068703064283743}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:29:42 DISPATCHER: Starting worker discovery
09:29:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:29:42 DISPATCHER: Finished worker discovery
Exception in thread Thread-511:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:30:42 DISPATCHER: Starting worker discovery
09:30:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:30:42 DISPATCHER: Finished worker discovery
09:31:42 DISPATCHER: Starting worker discovery
09:31:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:31:42 DISPATCHER: Finished worker discovery
09:32:42 DISPATCHER: Starting worker discovery
09:32:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:32:42 DISPATCHER: Finished worker discovery
09:32:44 WORKER: done with job (5, 0, 0), trying to register it.
09:32:44 WORKER: registered result for job (5, 0, 0) with dispatcher
09:32:44 DISPATCHER: job (5, 0, 0) finished
09:32:44 DISPATCHER: register_result: lock acquired
09:32:44 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
09:32:44 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 96, 'last_n_outputs': 37, 'lr': 0.007745607408146055, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.010068703064283743}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2877548192866964, 'info': {'music_genre': 0.2877548192866964, 'config': "{'batch_size': 32, 'hidden_dim': 96, 'last_n_outputs': 37, 'lr': 0.007745607408146055, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.010068703064283743}"}}
exception: None

09:32:44 job_callback for (5, 0, 0) started
09:32:44 job_callback for (5, 0, 0) got condition
09:32:44 DISPATCHER: Trying to submit another job.
09:32:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:32:44 done building a new model for budget 133.333333 based on 9/23 split
Best loss for this budget:-0.365195





09:32:44 HBMASTER: Trying to run another job!
09:32:44 job_callback for (5, 0, 0) finished
09:32:44 start sampling a new configuration.
09:32:44 best_vector: [1, 0.9064823390107333, 0.20695811698188793, 0.3008141264764301, 0.10000586242120853, 0, 0.3871349927830639, 0.5348883852502891], 4.376419598392561e-05, 254.77363198990042, 0.011149963161942542
09:32:44 done sampling a new configuration.
09:32:44 HBMASTER: schedule new run for iteration 5
09:32:44 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
09:32:44 HBMASTER: submitting job (5, 0, 1) to dispatcher
09:32:44 DISPATCHER: trying to submit job (5, 0, 1)
09:32:44 DISPATCHER: trying to notify the job_runner thread.
09:32:44 HBMASTER: job (5, 0, 1) submitted to dispatcher
09:32:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:32:44 DISPATCHER: Trying to submit another job.
09:32:44 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:32:44 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:32:44 WORKER: start processing job (5, 0, 1)
09:32:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:32:44 WORKER: args: ()
09:32:44 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 93, 'last_n_outputs': 11, 'lr': 0.003996025518485532, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.04964846588568705}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-512:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:33:42 DISPATCHER: Starting worker discovery
09:33:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:33:42 DISPATCHER: Finished worker discovery
09:34:42 DISPATCHER: Starting worker discovery
09:34:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:34:42 DISPATCHER: Finished worker discovery
09:35:42 DISPATCHER: Starting worker discovery
09:35:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:35:42 DISPATCHER: Finished worker discovery
09:35:49 WORKER: done with job (5, 0, 1), trying to register it.
09:35:49 WORKER: registered result for job (5, 0, 1) with dispatcher
09:35:49 DISPATCHER: job (5, 0, 1) finished
09:35:49 DISPATCHER: register_result: lock acquired
09:35:49 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
09:35:49 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 93, 'last_n_outputs': 11, 'lr': 0.003996025518485532, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.04964846588568705}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2266914845085903, 'info': {'music_genre': 0.2266914845085903, 'config': "{'batch_size': 32, 'hidden_dim': 93, 'last_n_outputs': 11, 'lr': 0.003996025518485532, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.04964846588568705}"}}
exception: None

09:35:49 job_callback for (5, 0, 1) started
09:35:49 DISPATCHER: Trying to submit another job.
09:35:49 job_callback for (5, 0, 1) got condition
09:35:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:35:49 done building a new model for budget 133.333333 based on 9/24 split
Best loss for this budget:-0.365195





09:35:49 HBMASTER: Trying to run another job!
09:35:49 job_callback for (5, 0, 1) finished
09:35:49 start sampling a new configuration.
09:35:49 done sampling a new configuration.
09:35:49 HBMASTER: schedule new run for iteration 5
09:35:49 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
09:35:49 HBMASTER: submitting job (5, 0, 2) to dispatcher
09:35:49 DISPATCHER: trying to submit job (5, 0, 2)
09:35:49 DISPATCHER: trying to notify the job_runner thread.
09:35:49 HBMASTER: job (5, 0, 2) submitted to dispatcher
09:35:49 DISPATCHER: Trying to submit another job.
09:35:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:35:49 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:35:49 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:35:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:35:49 WORKER: start processing job (5, 0, 2)
09:35:49 WORKER: args: ()
09:35:49 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 20, 'last_n_outputs': 27, 'lr': 0.0015076109846090255, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.07760117977726395}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:36:42 DISPATCHER: Starting worker discovery
09:36:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:36:42 DISPATCHER: Finished worker discovery
Exception in thread Thread-513:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:37:42 DISPATCHER: Starting worker discovery
09:37:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:37:42 DISPATCHER: Finished worker discovery
09:38:42 DISPATCHER: Starting worker discovery
09:38:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:38:42 DISPATCHER: Finished worker discovery
09:38:53 WORKER: done with job (5, 0, 2), trying to register it.
09:38:53 WORKER: registered result for job (5, 0, 2) with dispatcher
09:38:53 DISPATCHER: job (5, 0, 2) finished
09:38:53 DISPATCHER: register_result: lock acquired
09:38:53 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
09:38:53 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 20, 'last_n_outputs': 27, 'lr': 0.0015076109846090255, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.07760117977726395}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 20, 'last_n_outputs': 27, 'lr': 0.0015076109846090255, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.07760117977726395}"}}
exception: None

09:38:53 job_callback for (5, 0, 2) started
09:38:53 DISPATCHER: Trying to submit another job.
09:38:53 job_callback for (5, 0, 2) got condition
09:38:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:38:53 done building a new model for budget 133.333333 based on 9/25 split
Best loss for this budget:-0.365195





09:38:53 HBMASTER: Trying to run another job!
09:38:53 job_callback for (5, 0, 2) finished
09:38:53 start sampling a new configuration.
09:38:53 best_vector: [1, 0.8749386431007704, 0.4635732339791973, 0.010937310200487577, 0.09956476145333679, 0, 0.9336024317352506, 0.010643728727969648], 2.1527901108425273e-05, 9.901862654205443, 0.00021316632000894416
09:38:53 done sampling a new configuration.
09:38:53 HBMASTER: schedule new run for iteration 5
09:38:53 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
09:38:53 HBMASTER: submitting job (5, 0, 3) to dispatcher
09:38:53 DISPATCHER: trying to submit job (5, 0, 3)
09:38:53 DISPATCHER: trying to notify the job_runner thread.
09:38:53 HBMASTER: job (5, 0, 3) submitted to dispatcher
09:38:53 DISPATCHER: Trying to submit another job.
09:38:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:38:53 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:38:53 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:38:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:38:53 WORKER: start processing job (5, 0, 3)
09:38:53 WORKER: args: ()
09:38:53 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 90, 'last_n_outputs': 24, 'lr': 0.0010516582192145144, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.01032399558957793}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:39:42 DISPATCHER: Starting worker discovery
09:39:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:39:42 DISPATCHER: Finished worker discovery
Exception in thread Thread-514:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:40:42 DISPATCHER: Starting worker discovery
09:40:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:40:42 DISPATCHER: Finished worker discovery
09:41:42 DISPATCHER: Starting worker discovery
09:41:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:41:42 DISPATCHER: Finished worker discovery
09:41:58 WORKER: done with job (5, 0, 3), trying to register it.
09:41:58 WORKER: registered result for job (5, 0, 3) with dispatcher
09:41:58 DISPATCHER: job (5, 0, 3) finished
09:41:58 DISPATCHER: register_result: lock acquired
09:41:58 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
09:41:58 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 90, 'last_n_outputs': 24, 'lr': 0.0010516582192145144, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.01032399558957793}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.39274026105037096, 'info': {'music_genre': 0.39274026105037096, 'config': "{'batch_size': 32, 'hidden_dim': 90, 'last_n_outputs': 24, 'lr': 0.0010516582192145144, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.01032399558957793}"}}
exception: None

09:41:58 job_callback for (5, 0, 3) started
09:41:58 DISPATCHER: Trying to submit another job.
09:41:58 job_callback for (5, 0, 3) got condition
09:41:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:41:58 done building a new model for budget 133.333333 based on 9/26 split
Best loss for this budget:-0.392740





09:41:58 HBMASTER: Trying to run another job!
09:41:58 job_callback for (5, 0, 3) finished
09:41:58 start sampling a new configuration.
09:41:58 best_vector: [1, 0.403487606890259, 0.8626415027611509, 0.5965961146989134, 0.09897353320809657, 0, 0.5349744797769912, 0.1803994339676902], 0.0004609641738576171, 145.95203916966264, 0.06727866115867812
09:41:58 done sampling a new configuration.
09:41:58 HBMASTER: schedule new run for iteration 5
09:41:58 HBMASTER: trying submitting job (5, 0, 4) to dispatcher
09:41:58 HBMASTER: submitting job (5, 0, 4) to dispatcher
09:41:58 DISPATCHER: trying to submit job (5, 0, 4)
09:41:58 DISPATCHER: trying to notify the job_runner thread.
09:41:58 HBMASTER: job (5, 0, 4) submitted to dispatcher
09:41:58 DISPATCHER: Trying to submit another job.
09:41:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:41:58 DISPATCHER: starting job (5, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:41:58 DISPATCHER: job (5, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:41:58 WORKER: start processing job (5, 0, 4)
09:41:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:41:58 WORKER: args: ()
09:41:58 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 52, 'last_n_outputs': 44, 'lr': 0.01560242951838849, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.0171674216811721}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:42:42 DISPATCHER: Starting worker discovery
09:42:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:42:42 DISPATCHER: Finished worker discovery
Exception in thread Thread-515:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:43:42 DISPATCHER: Starting worker discovery
09:43:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:43:42 DISPATCHER: Finished worker discovery
09:44:42 DISPATCHER: Starting worker discovery
09:44:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:44:42 DISPATCHER: Finished worker discovery
09:45:03 WORKER: done with job (5, 0, 4), trying to register it.
09:45:03 WORKER: registered result for job (5, 0, 4) with dispatcher
09:45:03 DISPATCHER: job (5, 0, 4) finished
09:45:03 DISPATCHER: register_result: lock acquired
09:45:03 DISPATCHER: job (5, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
09:45:03 job_id: (5, 0, 4)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 52, 'last_n_outputs': 44, 'lr': 0.01560242951838849, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.0171674216811721}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2624833151704895, 'info': {'music_genre': 0.2624833151704895, 'config': "{'batch_size': 32, 'hidden_dim': 52, 'last_n_outputs': 44, 'lr': 0.01560242951838849, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.0171674216811721}"}}
exception: None

09:45:03 job_callback for (5, 0, 4) started
09:45:03 DISPATCHER: Trying to submit another job.
09:45:03 job_callback for (5, 0, 4) got condition
09:45:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:45:03 done building a new model for budget 133.333333 based on 9/27 split
Best loss for this budget:-0.392740





09:45:03 HBMASTER: Trying to run another job!
09:45:03 job_callback for (5, 0, 4) finished
09:45:03 start sampling a new configuration.
09:45:03 best_vector: [1, 0.639969636559433, 0.44089001825062707, 0.10926045770932513, 0.1005510149750857, 0, 0.9556481277455239, 0.25915424167367085], 6.414651463845766e-05, 260.0624733356769, 0.0166821012527405
09:45:03 done sampling a new configuration.
09:45:03 HBMASTER: schedule new run for iteration 5
09:45:03 HBMASTER: trying submitting job (5, 0, 5) to dispatcher
09:45:03 HBMASTER: submitting job (5, 0, 5) to dispatcher
09:45:03 DISPATCHER: trying to submit job (5, 0, 5)
09:45:03 DISPATCHER: trying to notify the job_runner thread.
09:45:03 HBMASTER: job (5, 0, 5) submitted to dispatcher
09:45:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:45:03 DISPATCHER: Trying to submit another job.
09:45:03 DISPATCHER: starting job (5, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:45:03 DISPATCHER: job (5, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:45:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:45:03 WORKER: start processing job (5, 0, 5)
09:45:03 WORKER: args: ()
09:45:03 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 71, 'last_n_outputs': 23, 'lr': 0.0016539444360419969, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.021735390237247226}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:45:42 DISPATCHER: Starting worker discovery
09:45:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:45:42 DISPATCHER: Finished worker discovery
Exception in thread Thread-516:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:46:42 DISPATCHER: Starting worker discovery
09:46:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:46:42 DISPATCHER: Finished worker discovery
09:47:42 DISPATCHER: Starting worker discovery
09:47:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:47:42 DISPATCHER: Finished worker discovery
09:48:08 WORKER: done with job (5, 0, 5), trying to register it.
09:48:08 WORKER: registered result for job (5, 0, 5) with dispatcher
09:48:08 DISPATCHER: job (5, 0, 5) finished
09:48:08 DISPATCHER: register_result: lock acquired
09:48:08 DISPATCHER: job (5, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
09:48:08 job_id: (5, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 71, 'last_n_outputs': 23, 'lr': 0.0016539444360419969, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.021735390237247226}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.37821694319581073, 'info': {'music_genre': 0.37821694319581073, 'config': "{'batch_size': 32, 'hidden_dim': 71, 'last_n_outputs': 23, 'lr': 0.0016539444360419969, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.021735390237247226}"}}
exception: None

09:48:08 job_callback for (5, 0, 5) started
09:48:08 DISPATCHER: Trying to submit another job.
09:48:08 job_callback for (5, 0, 5) got condition
09:48:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:48:08 done building a new model for budget 133.333333 based on 9/28 split
Best loss for this budget:-0.392740





09:48:08 HBMASTER: Trying to run another job!
09:48:08 job_callback for (5, 0, 5) finished
09:48:08 start sampling a new configuration.
09:48:08 done sampling a new configuration.
09:48:08 HBMASTER: schedule new run for iteration 5
09:48:08 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
09:48:08 HBMASTER: submitting job (5, 0, 6) to dispatcher
09:48:08 DISPATCHER: trying to submit job (5, 0, 6)
09:48:08 DISPATCHER: trying to notify the job_runner thread.
09:48:08 HBMASTER: job (5, 0, 6) submitted to dispatcher
09:48:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:48:08 DISPATCHER: Trying to submit another job.
09:48:08 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:48:08 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:48:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:48:08 WORKER: start processing job (5, 0, 6)
09:48:08 WORKER: args: ()
09:48:08 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 90, 'last_n_outputs': 33, 'lr': 0.010310355471928252, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.1026127026876045}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:48:42 DISPATCHER: Starting worker discovery
09:48:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:48:42 DISPATCHER: Finished worker discovery
Exception in thread Thread-517:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:49:42 DISPATCHER: Starting worker discovery
09:49:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:49:42 DISPATCHER: Finished worker discovery
09:50:42 DISPATCHER: Starting worker discovery
09:50:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:50:42 DISPATCHER: Finished worker discovery
09:51:12 WORKER: done with job (5, 0, 6), trying to register it.
09:51:12 WORKER: registered result for job (5, 0, 6) with dispatcher
09:51:12 DISPATCHER: job (5, 0, 6) finished
09:51:12 DISPATCHER: register_result: lock acquired
09:51:12 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
09:51:12 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 90, 'last_n_outputs': 33, 'lr': 0.010310355471928252, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.1026127026876045}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 90, 'last_n_outputs': 33, 'lr': 0.010310355471928252, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.1026127026876045}"}}
exception: None

09:51:12 job_callback for (5, 0, 6) started
09:51:12 job_callback for (5, 0, 6) got condition
09:51:12 DISPATCHER: Trying to submit another job.
09:51:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:51:12 done building a new model for budget 133.333333 based on 9/28 split
Best loss for this budget:-0.392740





09:51:12 HBMASTER: Trying to run another job!
09:51:12 job_callback for (5, 0, 6) finished
09:51:12 start sampling a new configuration.
09:51:12 done sampling a new configuration.
09:51:12 HBMASTER: schedule new run for iteration 5
09:51:12 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
09:51:12 HBMASTER: submitting job (5, 0, 7) to dispatcher
09:51:12 DISPATCHER: trying to submit job (5, 0, 7)
09:51:12 DISPATCHER: trying to notify the job_runner thread.
09:51:12 HBMASTER: job (5, 0, 7) submitted to dispatcher
09:51:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:51:12 DISPATCHER: Trying to submit another job.
09:51:12 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:51:12 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:51:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:51:12 WORKER: start processing job (5, 0, 7)
09:51:12 WORKER: args: ()
09:51:12 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 95, 'last_n_outputs': 31, 'lr': 0.0023077624014958002, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.06784766570195717}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:51:42 DISPATCHER: Starting worker discovery
09:51:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:51:42 DISPATCHER: Finished worker discovery
Exception in thread Thread-518:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:52:42 DISPATCHER: Starting worker discovery
09:52:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:52:42 DISPATCHER: Finished worker discovery
09:53:42 DISPATCHER: Starting worker discovery
09:53:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:53:42 DISPATCHER: Finished worker discovery
09:54:16 WORKER: done with job (5, 0, 7), trying to register it.
09:54:16 WORKER: registered result for job (5, 0, 7) with dispatcher
09:54:16 DISPATCHER: job (5, 0, 7) finished
09:54:16 DISPATCHER: register_result: lock acquired
09:54:16 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
09:54:16 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 95, 'last_n_outputs': 31, 'lr': 0.0023077624014958002, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.06784766570195717}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': 0.022765333929236204, 'info': {'music_genre': -0.022765333929236204, 'config': "{'batch_size': 16, 'hidden_dim': 95, 'last_n_outputs': 31, 'lr': 0.0023077624014958002, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.06784766570195717}"}}
exception: None

09:54:16 job_callback for (5, 0, 7) started
09:54:16 DISPATCHER: Trying to submit another job.
09:54:16 job_callback for (5, 0, 7) got condition
09:54:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:54:16 done building a new model for budget 133.333333 based on 9/29 split
Best loss for this budget:-0.392740





09:54:16 HBMASTER: Trying to run another job!
09:54:16 job_callback for (5, 0, 7) finished
09:54:16 start sampling a new configuration.
09:54:16 done sampling a new configuration.
09:54:16 HBMASTER: schedule new run for iteration 5
09:54:16 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
09:54:16 HBMASTER: submitting job (5, 0, 8) to dispatcher
09:54:16 DISPATCHER: trying to submit job (5, 0, 8)
09:54:16 DISPATCHER: trying to notify the job_runner thread.
09:54:16 HBMASTER: job (5, 0, 8) submitted to dispatcher
09:54:16 DISPATCHER: Trying to submit another job.
09:54:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:54:16 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:54:16 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:54:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:54:16 WORKER: start processing job (5, 0, 8)
09:54:16 WORKER: args: ()
09:54:16 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 71, 'last_n_outputs': 18, 'lr': 0.01672000835843056, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.02581242646226683}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:54:42 DISPATCHER: Starting worker discovery
09:54:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:54:42 DISPATCHER: Finished worker discovery
Exception in thread Thread-519:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:55:42 DISPATCHER: Starting worker discovery
09:55:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:55:42 DISPATCHER: Finished worker discovery
09:56:42 DISPATCHER: Starting worker discovery
09:56:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:56:42 DISPATCHER: Finished worker discovery
09:57:20 WORKER: done with job (5, 0, 8), trying to register it.
09:57:20 WORKER: registered result for job (5, 0, 8) with dispatcher
09:57:20 DISPATCHER: job (5, 0, 8) finished
09:57:20 DISPATCHER: register_result: lock acquired
09:57:20 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
09:57:20 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 71, 'last_n_outputs': 18, 'lr': 0.01672000835843056, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.02581242646226683}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 71, 'last_n_outputs': 18, 'lr': 0.01672000835843056, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.02581242646226683}"}}
exception: None

09:57:20 job_callback for (5, 0, 8) started
09:57:20 DISPATCHER: Trying to submit another job.
09:57:20 job_callback for (5, 0, 8) got condition
09:57:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:57:20 done building a new model for budget 133.333333 based on 9/30 split
Best loss for this budget:-0.392740





09:57:20 HBMASTER: Trying to run another job!
09:57:20 job_callback for (5, 0, 8) finished
09:57:20 ITERATION: Advancing config (5, 0, 0) to next budget 400.000000
09:57:20 ITERATION: Advancing config (5, 0, 3) to next budget 400.000000
09:57:20 ITERATION: Advancing config (5, 0, 5) to next budget 400.000000
09:57:20 HBMASTER: schedule new run for iteration 5
09:57:20 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
09:57:20 HBMASTER: submitting job (5, 0, 0) to dispatcher
09:57:20 DISPATCHER: trying to submit job (5, 0, 0)
09:57:20 DISPATCHER: trying to notify the job_runner thread.
09:57:20 HBMASTER: job (5, 0, 0) submitted to dispatcher
09:57:20 DISPATCHER: Trying to submit another job.
09:57:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:57:20 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:57:20 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
09:57:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:57:20 WORKER: start processing job (5, 0, 0)
09:57:20 WORKER: args: ()
09:57:20 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 96, 'last_n_outputs': 37, 'lr': 0.007745607408146055, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.010068703064283743}, 'budget': 400.0, 'working_directory': '.'}
09:57:42 DISPATCHER: Starting worker discovery
09:57:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:57:42 DISPATCHER: Finished worker discovery
Exception in thread Thread-520:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:58:42 DISPATCHER: Starting worker discovery
09:58:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:58:42 DISPATCHER: Finished worker discovery
09:59:42 DISPATCHER: Starting worker discovery
09:59:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:59:42 DISPATCHER: Finished worker discovery
10:00:42 DISPATCHER: Starting worker discovery
10:00:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:00:42 DISPATCHER: Finished worker discovery
10:01:42 DISPATCHER: Starting worker discovery
10:01:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:01:42 DISPATCHER: Finished worker discovery
10:02:42 DISPATCHER: Starting worker discovery
10:02:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:02:42 DISPATCHER: Finished worker discovery
10:03:42 DISPATCHER: Starting worker discovery
10:03:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:03:42 DISPATCHER: Finished worker discovery
10:04:42 DISPATCHER: Starting worker discovery
10:04:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:04:42 DISPATCHER: Finished worker discovery
10:04:52 WORKER: done with job (5, 0, 0), trying to register it.
10:04:52 WORKER: registered result for job (5, 0, 0) with dispatcher
10:04:52 DISPATCHER: job (5, 0, 0) finished
10:04:52 DISPATCHER: register_result: lock acquired
10:04:52 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
10:04:52 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 96, 'last_n_outputs': 37, 'lr': 0.007745607408146055, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.010068703064283743}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.2833976256122392, 'info': {'music_genre': 0.2833976256122392, 'config': "{'batch_size': 32, 'hidden_dim': 96, 'last_n_outputs': 37, 'lr': 0.007745607408146055, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.010068703064283743}"}}
exception: None

10:04:52 job_callback for (5, 0, 0) started
10:04:52 job_callback for (5, 0, 0) got condition
10:04:52 DISPATCHER: Trying to submit another job.
10:04:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:04:52 HBMASTER: Trying to run another job!
10:04:52 job_callback for (5, 0, 0) finished
10:04:52 HBMASTER: schedule new run for iteration 5
10:04:52 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
10:04:52 HBMASTER: submitting job (5, 0, 3) to dispatcher
10:04:52 DISPATCHER: trying to submit job (5, 0, 3)
10:04:52 DISPATCHER: trying to notify the job_runner thread.
10:04:52 HBMASTER: job (5, 0, 3) submitted to dispatcher
10:04:52 DISPATCHER: Trying to submit another job.
10:04:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:04:52 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:04:52 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:04:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:04:52 WORKER: start processing job (5, 0, 3)
10:04:52 WORKER: args: ()
10:04:52 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 90, 'last_n_outputs': 24, 'lr': 0.0010516582192145144, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.01032399558957793}, 'budget': 400.0, 'working_directory': '.'}
10:05:42 DISPATCHER: Starting worker discovery
10:05:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:05:42 DISPATCHER: Finished worker discovery
Exception in thread Thread-521:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:06:42 DISPATCHER: Starting worker discovery
10:06:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:06:42 DISPATCHER: Finished worker discovery
10:07:42 DISPATCHER: Starting worker discovery
10:07:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:07:42 DISPATCHER: Finished worker discovery
10:08:42 DISPATCHER: Starting worker discovery
10:08:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:08:42 DISPATCHER: Finished worker discovery
10:09:42 DISPATCHER: Starting worker discovery
10:09:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:09:42 DISPATCHER: Finished worker discovery
10:10:42 DISPATCHER: Starting worker discovery
10:10:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:10:42 DISPATCHER: Finished worker discovery
10:11:42 DISPATCHER: Starting worker discovery
10:11:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:11:42 DISPATCHER: Finished worker discovery
10:12:25 WORKER: done with job (5, 0, 3), trying to register it.
10:12:25 WORKER: registered result for job (5, 0, 3) with dispatcher
10:12:25 DISPATCHER: job (5, 0, 3) finished
10:12:25 DISPATCHER: register_result: lock acquired
10:12:25 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
10:12:25 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 90, 'last_n_outputs': 24, 'lr': 0.0010516582192145144, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.01032399558957793}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3559408380111577, 'info': {'music_genre': 0.3559408380111577, 'config': "{'batch_size': 32, 'hidden_dim': 90, 'last_n_outputs': 24, 'lr': 0.0010516582192145144, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.01032399558957793}"}}
exception: None

10:12:25 job_callback for (5, 0, 3) started
10:12:25 job_callback for (5, 0, 3) got condition
10:12:25 DISPATCHER: Trying to submit another job.
10:12:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:12:25 HBMASTER: Trying to run another job!
10:12:25 job_callback for (5, 0, 3) finished
10:12:25 HBMASTER: schedule new run for iteration 5
10:12:25 HBMASTER: trying submitting job (5, 0, 5) to dispatcher
10:12:25 HBMASTER: submitting job (5, 0, 5) to dispatcher
10:12:25 DISPATCHER: trying to submit job (5, 0, 5)
10:12:25 DISPATCHER: trying to notify the job_runner thread.
10:12:25 HBMASTER: job (5, 0, 5) submitted to dispatcher
10:12:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:12:25 DISPATCHER: Trying to submit another job.
10:12:25 DISPATCHER: starting job (5, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:12:25 DISPATCHER: job (5, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:12:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:12:25 WORKER: start processing job (5, 0, 5)
10:12:25 WORKER: args: ()
10:12:25 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 71, 'last_n_outputs': 23, 'lr': 0.0016539444360419969, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.021735390237247226}, 'budget': 400.0, 'working_directory': '.'}
10:12:42 DISPATCHER: Starting worker discovery
10:12:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:12:42 DISPATCHER: Finished worker discovery
Exception in thread Thread-522:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:13:42 DISPATCHER: Starting worker discovery
10:13:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:13:42 DISPATCHER: Finished worker discovery
10:14:42 DISPATCHER: Starting worker discovery
10:14:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:14:43 DISPATCHER: Finished worker discovery
10:15:43 DISPATCHER: Starting worker discovery
10:15:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:15:43 DISPATCHER: Finished worker discovery
10:16:43 DISPATCHER: Starting worker discovery
10:16:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:16:43 DISPATCHER: Finished worker discovery
10:17:43 DISPATCHER: Starting worker discovery
10:17:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:17:43 DISPATCHER: Finished worker discovery
10:18:43 DISPATCHER: Starting worker discovery
10:18:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:18:43 DISPATCHER: Finished worker discovery
10:19:43 DISPATCHER: Starting worker discovery
10:19:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:19:43 DISPATCHER: Finished worker discovery
10:19:57 WORKER: done with job (5, 0, 5), trying to register it.
10:19:57 WORKER: registered result for job (5, 0, 5) with dispatcher
10:19:57 DISPATCHER: job (5, 0, 5) finished
10:19:57 DISPATCHER: register_result: lock acquired
10:19:57 DISPATCHER: job (5, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
10:19:57 job_id: (5, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 71, 'last_n_outputs': 23, 'lr': 0.0016539444360419969, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.021735390237247226}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.35006774012857894, 'info': {'music_genre': 0.35006774012857894, 'config': "{'batch_size': 32, 'hidden_dim': 71, 'last_n_outputs': 23, 'lr': 0.0016539444360419969, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.021735390237247226}"}}
exception: None

10:19:57 job_callback for (5, 0, 5) started
10:19:57 job_callback for (5, 0, 5) got condition
10:19:57 DISPATCHER: Trying to submit another job.
10:19:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:19:57 done building a new model for budget 400.000000 based on 9/15 split
Best loss for this budget:-0.355941





10:19:57 HBMASTER: Trying to run another job!
10:19:57 job_callback for (5, 0, 5) finished
10:19:57 ITERATION: Advancing config (5, 0, 3) to next budget 1200.000000
10:19:57 HBMASTER: schedule new run for iteration 5
10:19:57 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
10:19:57 HBMASTER: submitting job (5, 0, 3) to dispatcher
10:19:57 DISPATCHER: trying to submit job (5, 0, 3)
10:19:57 DISPATCHER: trying to notify the job_runner thread.
10:19:57 HBMASTER: job (5, 0, 3) submitted to dispatcher
10:19:57 DISPATCHER: Trying to submit another job.
10:19:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:19:57 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:19:57 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:19:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:19:57 WORKER: start processing job (5, 0, 3)
10:19:57 WORKER: args: ()
10:19:57 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 90, 'last_n_outputs': 24, 'lr': 0.0010516582192145144, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.01032399558957793}, 'budget': 1200.0, 'working_directory': '.'}
10:20:43 DISPATCHER: Starting worker discovery
10:20:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:20:43 DISPATCHER: Finished worker discovery
Exception in thread Thread-523:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:21:43 DISPATCHER: Starting worker discovery
10:21:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:21:43 DISPATCHER: Finished worker discovery
10:22:43 DISPATCHER: Starting worker discovery
10:22:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:22:43 DISPATCHER: Finished worker discovery
10:23:43 DISPATCHER: Starting worker discovery
10:23:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:23:43 DISPATCHER: Finished worker discovery
10:24:43 DISPATCHER: Starting worker discovery
10:24:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:24:43 DISPATCHER: Finished worker discovery
10:25:43 DISPATCHER: Starting worker discovery
10:25:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:25:43 DISPATCHER: Finished worker discovery
10:26:43 DISPATCHER: Starting worker discovery
10:26:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:26:43 DISPATCHER: Finished worker discovery
10:27:43 DISPATCHER: Starting worker discovery
10:27:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:27:43 DISPATCHER: Finished worker discovery
10:28:43 DISPATCHER: Starting worker discovery
10:28:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:28:43 DISPATCHER: Finished worker discovery
10:29:43 DISPATCHER: Starting worker discovery
10:29:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:29:43 DISPATCHER: Finished worker discovery
10:30:43 DISPATCHER: Starting worker discovery
10:30:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:30:43 DISPATCHER: Finished worker discovery
10:31:43 DISPATCHER: Starting worker discovery
10:31:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:31:43 DISPATCHER: Finished worker discovery
10:32:43 DISPATCHER: Starting worker discovery
10:32:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:32:43 DISPATCHER: Finished worker discovery
10:33:43 DISPATCHER: Starting worker discovery
10:33:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:33:43 DISPATCHER: Finished worker discovery
10:34:43 DISPATCHER: Starting worker discovery
10:34:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:34:43 DISPATCHER: Finished worker discovery
10:35:43 DISPATCHER: Starting worker discovery
10:35:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:35:43 DISPATCHER: Finished worker discovery
10:36:43 DISPATCHER: Starting worker discovery
10:36:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:36:43 DISPATCHER: Finished worker discovery
10:37:43 DISPATCHER: Starting worker discovery
10:37:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:37:43 DISPATCHER: Finished worker discovery
10:38:43 DISPATCHER: Starting worker discovery
10:38:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:38:43 DISPATCHER: Finished worker discovery
10:39:43 DISPATCHER: Starting worker discovery
10:39:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:39:43 DISPATCHER: Finished worker discovery
10:40:43 DISPATCHER: Starting worker discovery
10:40:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:40:43 DISPATCHER: Finished worker discovery
10:40:48 WORKER: done with job (5, 0, 3), trying to register it.
10:40:48 WORKER: registered result for job (5, 0, 3) with dispatcher
10:40:48 DISPATCHER: job (5, 0, 3) finished
10:40:48 DISPATCHER: register_result: lock acquired
10:40:48 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
10:40:48 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 90, 'last_n_outputs': 24, 'lr': 0.0010516582192145144, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.01032399558957793}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.38120933914943556, 'info': {'music_genre': 0.38120933914943556, 'config': "{'batch_size': 32, 'hidden_dim': 90, 'last_n_outputs': 24, 'lr': 0.0010516582192145144, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.01032399558957793}"}}
exception: None

10:40:48 job_callback for (5, 0, 3) started
10:40:48 job_callback for (5, 0, 3) got condition
10:40:48 DISPATCHER: Trying to submit another job.
10:40:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:40:48 HBMASTER: Trying to run another job!
10:40:48 job_callback for (5, 0, 3) finished
10:40:48 start sampling a new configuration.
10:40:48 best_vector: [1, 0.8414647972020094, 0.8660852867974472, 0.19384728275392749, 0.09536548799016108, 0, 0.8425769828254739, 0.261787552998623], 0.003692610844225265, 0.013006964555325276, 4.802965836744777e-05
10:40:48 done sampling a new configuration.
10:40:48 HBMASTER: schedule new run for iteration 6
10:40:48 HBMASTER: trying submitting job (6, 0, 0) to dispatcher
10:40:48 HBMASTER: submitting job (6, 0, 0) to dispatcher
10:40:48 DISPATCHER: trying to submit job (6, 0, 0)
10:40:48 DISPATCHER: trying to notify the job_runner thread.
10:40:48 HBMASTER: job (6, 0, 0) submitted to dispatcher
10:40:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:40:48 DISPATCHER: Trying to submit another job.
10:40:48 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:40:48 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:40:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:40:48 WORKER: start processing job (6, 0, 0)
10:40:48 WORKER: args: ()
10:40:48 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 88, 'last_n_outputs': 44, 'lr': 0.002441712719224993, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.021907532212348955}, 'budget': 400.0, 'working_directory': '.'}
10:41:43 DISPATCHER: Starting worker discovery
10:41:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:41:43 DISPATCHER: Finished worker discovery
Exception in thread Thread-524:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:42:43 DISPATCHER: Starting worker discovery
10:42:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:42:43 DISPATCHER: Finished worker discovery
10:43:43 DISPATCHER: Starting worker discovery
10:43:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:43:43 DISPATCHER: Finished worker discovery
10:44:43 DISPATCHER: Starting worker discovery
10:44:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:44:43 DISPATCHER: Finished worker discovery
10:45:43 DISPATCHER: Starting worker discovery
10:45:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:45:43 DISPATCHER: Finished worker discovery
10:46:43 DISPATCHER: Starting worker discovery
10:46:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:46:43 DISPATCHER: Finished worker discovery
10:47:43 DISPATCHER: Starting worker discovery
10:47:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:47:43 DISPATCHER: Finished worker discovery
10:48:20 WORKER: done with job (6, 0, 0), trying to register it.
10:48:20 WORKER: registered result for job (6, 0, 0) with dispatcher
10:48:20 DISPATCHER: job (6, 0, 0) finished
10:48:20 DISPATCHER: register_result: lock acquired
10:48:20 DISPATCHER: job (6, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
10:48:20 job_id: (6, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 88, 'last_n_outputs': 44, 'lr': 0.002441712719224993, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.021907532212348955}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3510806661209674, 'info': {'music_genre': 0.3510806661209674, 'config': "{'batch_size': 32, 'hidden_dim': 88, 'last_n_outputs': 44, 'lr': 0.002441712719224993, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.021907532212348955}"}}
exception: None

10:48:20 job_callback for (6, 0, 0) started
10:48:20 DISPATCHER: Trying to submit another job.
10:48:20 job_callback for (6, 0, 0) got condition
10:48:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:48:20 done building a new model for budget 400.000000 based on 9/16 split
Best loss for this budget:-0.355941





10:48:20 HBMASTER: Trying to run another job!
10:48:20 job_callback for (6, 0, 0) finished
10:48:20 start sampling a new configuration.
10:48:20 sampled vector: [2, 0.9234999657227299, 0.6858150099280748, 0.34421803949397733, 0.09699764304605256, 1, 0.28164112584166323, 0.45011528636232917] has EI value nan
10:48:20 data in the KDEs:
[[1.         0.87037046 0.46999999 0.01093731 0.0999984  0.
  0.92857152 0.01064373]
 [1.         0.9814816  0.89000016 0.22702777 0.0999984  0.
  0.92857152 0.36398877]
 [1.         0.8456791  0.87000015 0.19384728 0.0999984  0.
  0.84065942 0.26178755]
 [1.         0.6358025  0.44999998 0.10926046 0.0999984  0.
  0.95054955 0.25915424]
 [1.         0.42592591 0.40999996 0.22278039 0.0999984  0.
  0.48901099 0.09812028]
 [0.         0.48765432 0.87000015 0.2733239  0.0999984  0.
  0.42307691 0.52973671]
 [2.         0.19135795 0.59000004 0.26278045 0.0999984  0.
  0.60989013 0.98082542]
 [0.         0.94444455 0.51       0.14412021 0.0999984  0.
  0.40109888 0.77192724]
 [1.         0.94444455 0.73000009 0.44452774 0.0999984  0.
  0.44505493 0.00228552]]
[[1.         0.52469136 0.14999986 0.27566331 0.0999984  0.
  0.30219776 0.22157852]
 [1.         0.09259249 0.44999998 0.2052363  0.0999984  0.
  0.19230762 0.89329139]
 [2.         0.1543209  0.57000003 0.04815433 0.0999984  0.
  0.1703296  0.34206581]
 [1.         0.62345682 0.79000012 0.55671942 0.0999984  0.
  0.31318677 0.36044623]
 [3.         0.90740751 0.0099998  0.33532186 0.0999984  0.
  0.96153856 0.57280889]
 [1.         0.31481477 0.38999996 0.08868729 0.0999984  0.
  0.03846144 0.01736367]
 [1.         0.94444455 0.55000002 0.19500476 0.0999984  0.
  0.13736256 0.9770286 ]
 [1.         0.10493817 0.30999992 0.19981962 0.0999984  0.
  0.20329664 0.26744573]
 [0.         0.85802478 0.91000016 0.54428411 0.0999984  0.
  0.3351648  0.63684385]
 [0.         0.38888886 0.55000002 0.81228087 0.0999984  0.
  0.25824171 0.58883909]]
10:48:20 bandwidth of the KDEs:
[0.50006887 0.23388684 0.16476031 0.10047658 0.001      0.001
 0.19993188 0.28253443]
[0.72677014 0.27598217 0.22565022 0.19973481 0.001      0.001
 0.20936882 0.25078798]
10:48:20 l(x) = inf
10:48:20 g(x) = inf
10:48:20 best_vector: [1, 0.9436263600340218, 0.8943747431603444, 0.15342610951382993, 0.09601416164993508, 0, 0.8467421704765126, 0.2768384276000733], 0.0005041738856892507, 0.5539639224735637, 0.00027929414332515543
10:48:20 done sampling a new configuration.
10:48:20 HBMASTER: schedule new run for iteration 6
10:48:20 HBMASTER: trying submitting job (6, 0, 1) to dispatcher
10:48:20 HBMASTER: submitting job (6, 0, 1) to dispatcher
10:48:20 DISPATCHER: trying to submit job (6, 0, 1)
10:48:20 DISPATCHER: trying to notify the job_runner thread.
10:48:20 HBMASTER: job (6, 0, 1) submitted to dispatcher
10:48:20 DISPATCHER: Trying to submit another job.
10:48:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:48:20 DISPATCHER: starting job (6, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:48:20 DISPATCHER: job (6, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:48:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:48:20 WORKER: start processing job (6, 0, 1)
10:48:20 WORKER: args: ()
10:48:20 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 96, 'last_n_outputs': 45, 'lr': 0.0020269928605443303, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.022917914678994886}, 'budget': 400.0, 'working_directory': '.'}
10:48:43 DISPATCHER: Starting worker discovery
10:48:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:48:43 DISPATCHER: Finished worker discovery
Exception in thread Thread-525:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:49:43 DISPATCHER: Starting worker discovery
10:49:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:49:43 DISPATCHER: Finished worker discovery
10:50:43 DISPATCHER: Starting worker discovery
10:50:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:50:43 DISPATCHER: Finished worker discovery
10:51:43 DISPATCHER: Starting worker discovery
10:51:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:51:43 DISPATCHER: Finished worker discovery
10:52:43 DISPATCHER: Starting worker discovery
10:52:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:52:43 DISPATCHER: Finished worker discovery
10:53:43 DISPATCHER: Starting worker discovery
10:53:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:53:43 DISPATCHER: Finished worker discovery
10:54:43 DISPATCHER: Starting worker discovery
10:54:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:54:43 DISPATCHER: Finished worker discovery
10:55:43 DISPATCHER: Starting worker discovery
10:55:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:55:43 DISPATCHER: Finished worker discovery
10:55:50 WORKER: done with job (6, 0, 1), trying to register it.
10:55:50 WORKER: registered result for job (6, 0, 1) with dispatcher
10:55:50 DISPATCHER: job (6, 0, 1) finished
10:55:50 DISPATCHER: register_result: lock acquired
10:55:50 DISPATCHER: job (6, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
10:55:50 job_id: (6, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 96, 'last_n_outputs': 45, 'lr': 0.0020269928605443303, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.022917914678994886}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.367617425904928, 'info': {'music_genre': 0.367617425904928, 'config': "{'batch_size': 32, 'hidden_dim': 96, 'last_n_outputs': 45, 'lr': 0.0020269928605443303, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.022917914678994886}"}}
exception: None

10:55:50 job_callback for (6, 0, 1) started
10:55:50 DISPATCHER: Trying to submit another job.
10:55:50 job_callback for (6, 0, 1) got condition
10:55:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:55:50 done building a new model for budget 400.000000 based on 9/17 split
Best loss for this budget:-0.367617





10:55:50 HBMASTER: Trying to run another job!
10:55:50 job_callback for (6, 0, 1) finished
10:55:50 start sampling a new configuration.
10:55:50 best_vector: [1, 0.7975819981993503, 0.9215053702366978, 0.14341034123312116, 0.10167622919517506, 0, 0.9723132020665077, 0.4833953516762941], 0.00018745677094923592, 454.8234041118601, 0.08525972668694873
10:55:50 done sampling a new configuration.
10:55:50 HBMASTER: schedule new run for iteration 6
10:55:50 HBMASTER: trying submitting job (6, 0, 2) to dispatcher
10:55:50 HBMASTER: submitting job (6, 0, 2) to dispatcher
10:55:50 DISPATCHER: trying to submit job (6, 0, 2)
10:55:50 DISPATCHER: trying to notify the job_runner thread.
10:55:50 HBMASTER: job (6, 0, 2) submitted to dispatcher
10:55:50 DISPATCHER: Trying to submit another job.
10:55:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:55:50 DISPATCHER: starting job (6, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:55:50 DISPATCHER: job (6, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
10:55:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:55:50 WORKER: start processing job (6, 0, 2)
10:55:50 WORKER: args: ()
10:55:50 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 84, 'last_n_outputs': 47, 'lr': 0.0019356225922075262, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.04255120392151161}, 'budget': 400.0, 'working_directory': '.'}
10:56:43 DISPATCHER: Starting worker discovery
10:56:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:56:43 DISPATCHER: Finished worker discovery
Exception in thread Thread-526:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:57:43 DISPATCHER: Starting worker discovery
10:57:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:57:43 DISPATCHER: Finished worker discovery
10:58:43 DISPATCHER: Starting worker discovery
10:58:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:58:43 DISPATCHER: Finished worker discovery
10:59:43 DISPATCHER: Starting worker discovery
10:59:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:59:43 DISPATCHER: Finished worker discovery
11:00:43 DISPATCHER: Starting worker discovery
11:00:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:00:43 DISPATCHER: Finished worker discovery
11:01:43 DISPATCHER: Starting worker discovery
11:01:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:01:43 DISPATCHER: Finished worker discovery
11:02:43 DISPATCHER: Starting worker discovery
11:02:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:02:43 DISPATCHER: Finished worker discovery
11:03:21 WORKER: done with job (6, 0, 2), trying to register it.
11:03:21 WORKER: registered result for job (6, 0, 2) with dispatcher
11:03:21 DISPATCHER: job (6, 0, 2) finished
11:03:21 DISPATCHER: register_result: lock acquired
11:03:21 DISPATCHER: job (6, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
11:03:21 job_id: (6, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 84, 'last_n_outputs': 47, 'lr': 0.0019356225922075262, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.04255120392151161}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.40236813512350506, 'info': {'music_genre': 0.40236813512350506, 'config': "{'batch_size': 32, 'hidden_dim': 84, 'last_n_outputs': 47, 'lr': 0.0019356225922075262, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.04255120392151161}"}}
exception: None

11:03:21 job_callback for (6, 0, 2) started
11:03:21 job_callback for (6, 0, 2) got condition
11:03:21 DISPATCHER: Trying to submit another job.
11:03:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:03:21 done building a new model for budget 400.000000 based on 9/17 split
Best loss for this budget:-0.402368





11:03:21 HBMASTER: Trying to run another job!
11:03:21 job_callback for (6, 0, 2) finished
11:03:21 start sampling a new configuration.
11:03:21 best_vector: [1, 0.4692259905400813, 0.7850782826003699, 0.11764293347404868, 0.10203723141697864, 0, 0.9904655884289766, 0.12866104107304513], 0.0002540171193717174, 92.76136238840782, 0.023562974062899325
11:03:21 done sampling a new configuration.
11:03:21 HBMASTER: schedule new run for iteration 6
11:03:21 HBMASTER: trying submitting job (6, 0, 3) to dispatcher
11:03:21 HBMASTER: submitting job (6, 0, 3) to dispatcher
11:03:21 DISPATCHER: trying to submit job (6, 0, 3)
11:03:21 DISPATCHER: trying to notify the job_runner thread.
11:03:21 HBMASTER: job (6, 0, 3) submitted to dispatcher
11:03:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:03:21 DISPATCHER: Trying to submit another job.
11:03:21 DISPATCHER: starting job (6, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
11:03:21 DISPATCHER: job (6, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
11:03:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:03:21 WORKER: start processing job (6, 0, 3)
11:03:21 WORKER: args: ()
11:03:21 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 58, 'last_n_outputs': 40, 'lr': 0.0017190395433443783, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.014702523211349794}, 'budget': 400.0, 'working_directory': '.'}
11:03:43 DISPATCHER: Starting worker discovery
11:03:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:03:43 DISPATCHER: Finished worker discovery
Exception in thread Thread-527:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:04:43 DISPATCHER: Starting worker discovery
11:04:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:04:43 DISPATCHER: Finished worker discovery
11:05:43 DISPATCHER: Starting worker discovery
11:05:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:05:43 DISPATCHER: Finished worker discovery
11:06:43 DISPATCHER: Starting worker discovery
11:06:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:06:43 DISPATCHER: Finished worker discovery
11:07:43 DISPATCHER: Starting worker discovery
11:07:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:07:43 DISPATCHER: Finished worker discovery
11:08:43 DISPATCHER: Starting worker discovery
11:08:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:08:43 DISPATCHER: Finished worker discovery
11:09:43 DISPATCHER: Starting worker discovery
11:09:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:09:43 DISPATCHER: Finished worker discovery
11:10:43 DISPATCHER: Starting worker discovery
11:10:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:10:43 DISPATCHER: Finished worker discovery
11:10:52 WORKER: done with job (6, 0, 3), trying to register it.
11:10:52 WORKER: registered result for job (6, 0, 3) with dispatcher
11:10:52 DISPATCHER: job (6, 0, 3) finished
11:10:52 DISPATCHER: register_result: lock acquired
11:10:52 DISPATCHER: job (6, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
11:10:52 job_id: (6, 0, 3)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 58, 'last_n_outputs': 40, 'lr': 0.0017190395433443783, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.014702523211349794}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.32222541561747425, 'info': {'music_genre': 0.32222541561747425, 'config': "{'batch_size': 32, 'hidden_dim': 58, 'last_n_outputs': 40, 'lr': 0.0017190395433443783, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.014702523211349794}"}}
exception: None

11:10:52 job_callback for (6, 0, 3) started
11:10:52 DISPATCHER: Trying to submit another job.
11:10:52 job_callback for (6, 0, 3) got condition
11:10:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:10:52 done building a new model for budget 400.000000 based on 9/18 split
Best loss for this budget:-0.402368





11:10:52 HBMASTER: Trying to run another job!
11:10:52 job_callback for (6, 0, 3) finished
11:10:52 start sampling a new configuration.
11:10:52 best_vector: [1, 0.7403619541690576, 0.9978226180498254, 0.07907875309725916, 0.10333926930844134, 0, 0.9679031223857228, 0.23232220532259834], 5.268557536107198e-05, 12.134680916704262, 0.0006393226459195844
11:10:52 done sampling a new configuration.
11:10:52 HBMASTER: schedule new run for iteration 6
11:10:52 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
11:10:52 HBMASTER: submitting job (6, 0, 4) to dispatcher
11:10:52 DISPATCHER: trying to submit job (6, 0, 4)
11:10:52 DISPATCHER: trying to notify the job_runner thread.
11:10:52 HBMASTER: job (6, 0, 4) submitted to dispatcher
11:10:52 DISPATCHER: Trying to submit another job.
11:10:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:10:52 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
11:10:52 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
11:10:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:10:52 WORKER: start processing job (6, 0, 4)
11:10:52 WORKER: args: ()
11:10:52 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 79, 'last_n_outputs': 50, 'lr': 0.0014393204840073446, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.020056639004090628}, 'budget': 400.0, 'working_directory': '.'}
11:11:43 DISPATCHER: Starting worker discovery
11:11:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:11:43 DISPATCHER: Finished worker discovery
Exception in thread Thread-528:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:12:43 DISPATCHER: Starting worker discovery
11:12:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:12:43 DISPATCHER: Finished worker discovery
11:13:43 DISPATCHER: Starting worker discovery
11:13:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:13:43 DISPATCHER: Finished worker discovery
11:14:43 DISPATCHER: Starting worker discovery
11:14:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:14:43 DISPATCHER: Finished worker discovery
11:15:43 DISPATCHER: Starting worker discovery
11:15:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:15:43 DISPATCHER: Finished worker discovery
11:16:43 DISPATCHER: Starting worker discovery
11:16:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:16:43 DISPATCHER: Finished worker discovery
11:17:43 DISPATCHER: Starting worker discovery
11:17:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:17:43 DISPATCHER: Finished worker discovery
11:18:24 WORKER: done with job (6, 0, 4), trying to register it.
11:18:24 WORKER: registered result for job (6, 0, 4) with dispatcher
11:18:24 DISPATCHER: job (6, 0, 4) finished
11:18:24 DISPATCHER: register_result: lock acquired
11:18:24 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
11:18:24 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 79, 'last_n_outputs': 50, 'lr': 0.0014393204840073446, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.020056639004090628}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.39174110325534406, 'info': {'music_genre': 0.39174110325534406, 'config': "{'batch_size': 32, 'hidden_dim': 79, 'last_n_outputs': 50, 'lr': 0.0014393204840073446, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.020056639004090628}"}}
exception: None

11:18:24 job_callback for (6, 0, 4) started
11:18:24 job_callback for (6, 0, 4) got condition
11:18:24 DISPATCHER: Trying to submit another job.
11:18:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:18:24 done building a new model for budget 400.000000 based on 9/19 split
Best loss for this budget:-0.402368





11:18:24 HBMASTER: Trying to run another job!
11:18:24 job_callback for (6, 0, 4) finished
11:18:24 start sampling a new configuration.
11:18:24 done sampling a new configuration.
11:18:24 HBMASTER: schedule new run for iteration 6
11:18:24 HBMASTER: trying submitting job (6, 0, 5) to dispatcher
11:18:24 HBMASTER: submitting job (6, 0, 5) to dispatcher
11:18:24 DISPATCHER: trying to submit job (6, 0, 5)
11:18:24 DISPATCHER: trying to notify the job_runner thread.
11:18:24 HBMASTER: job (6, 0, 5) submitted to dispatcher
11:18:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:18:24 DISPATCHER: Trying to submit another job.
11:18:24 DISPATCHER: starting job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952
11:18:24 DISPATCHER: job (6, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
11:18:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:18:24 WORKER: start processing job (6, 0, 5)
11:18:24 WORKER: args: ()
11:18:24 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 22, 'last_n_outputs': 31, 'lr': 0.0014399888717701078, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.025662557161208965}, 'budget': 400.0, 'working_directory': '.'}
11:18:43 DISPATCHER: Starting worker discovery
11:18:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:18:43 DISPATCHER: Finished worker discovery
Exception in thread Thread-529:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:19:43 DISPATCHER: Starting worker discovery
11:19:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:19:43 DISPATCHER: Finished worker discovery
11:20:43 DISPATCHER: Starting worker discovery
11:20:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:20:43 DISPATCHER: Finished worker discovery
11:21:43 DISPATCHER: Starting worker discovery
11:21:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:21:43 DISPATCHER: Finished worker discovery
11:22:43 DISPATCHER: Starting worker discovery
11:22:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:22:43 DISPATCHER: Finished worker discovery
11:23:43 DISPATCHER: Starting worker discovery
11:23:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:23:43 DISPATCHER: Finished worker discovery
11:24:43 DISPATCHER: Starting worker discovery
11:24:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:24:43 DISPATCHER: Finished worker discovery
11:25:43 DISPATCHER: Starting worker discovery
11:25:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:25:43 DISPATCHER: Finished worker discovery
11:25:55 WORKER: done with job (6, 0, 5), trying to register it.
11:25:55 WORKER: registered result for job (6, 0, 5) with dispatcher
11:25:55 DISPATCHER: job (6, 0, 5) finished
11:25:55 DISPATCHER: register_result: lock acquired
11:25:55 DISPATCHER: job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
11:25:55 job_id: (6, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 22, 'last_n_outputs': 31, 'lr': 0.0014399888717701078, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.025662557161208965}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.2685585297096819, 'info': {'music_genre': 0.2685585297096819, 'config': "{'batch_size': 64, 'hidden_dim': 22, 'last_n_outputs': 31, 'lr': 0.0014399888717701078, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.025662557161208965}"}}
exception: None

11:25:55 job_callback for (6, 0, 5) started
11:25:55 job_callback for (6, 0, 5) got condition
11:25:55 DISPATCHER: Trying to submit another job.
11:25:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:25:55 done building a new model for budget 400.000000 based on 9/20 split
Best loss for this budget:-0.402368





11:25:55 HBMASTER: Trying to run another job!
11:25:55 job_callback for (6, 0, 5) finished
11:25:55 ITERATION: Advancing config (6, 0, 2) to next budget 1200.000000
11:25:55 ITERATION: Advancing config (6, 0, 4) to next budget 1200.000000
11:25:55 HBMASTER: schedule new run for iteration 6
11:25:55 HBMASTER: trying submitting job (6, 0, 2) to dispatcher
11:25:55 HBMASTER: submitting job (6, 0, 2) to dispatcher
11:25:55 DISPATCHER: trying to submit job (6, 0, 2)
11:25:55 DISPATCHER: trying to notify the job_runner thread.
11:25:55 HBMASTER: job (6, 0, 2) submitted to dispatcher
11:25:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:25:55 DISPATCHER: Trying to submit another job.
11:25:55 DISPATCHER: starting job (6, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
11:25:55 DISPATCHER: job (6, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
11:25:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:25:55 WORKER: start processing job (6, 0, 2)
11:25:55 WORKER: args: ()
11:25:55 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 84, 'last_n_outputs': 47, 'lr': 0.0019356225922075262, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.04255120392151161}, 'budget': 1200.0, 'working_directory': '.'}
11:26:43 DISPATCHER: Starting worker discovery
11:26:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:26:43 DISPATCHER: Finished worker discovery
Exception in thread Thread-530:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:27:43 DISPATCHER: Starting worker discovery
11:27:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:27:43 DISPATCHER: Finished worker discovery
11:28:43 DISPATCHER: Starting worker discovery
11:28:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:28:43 DISPATCHER: Finished worker discovery
11:29:43 DISPATCHER: Starting worker discovery
11:29:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:29:43 DISPATCHER: Finished worker discovery
11:30:43 DISPATCHER: Starting worker discovery
11:30:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:30:43 DISPATCHER: Finished worker discovery
11:31:43 DISPATCHER: Starting worker discovery
11:31:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:31:43 DISPATCHER: Finished worker discovery
11:32:43 DISPATCHER: Starting worker discovery
11:32:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:32:43 DISPATCHER: Finished worker discovery
11:33:43 DISPATCHER: Starting worker discovery
11:33:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:33:43 DISPATCHER: Finished worker discovery
11:34:43 DISPATCHER: Starting worker discovery
11:34:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:34:43 DISPATCHER: Finished worker discovery
11:35:43 DISPATCHER: Starting worker discovery
11:35:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:35:43 DISPATCHER: Finished worker discovery
11:36:43 DISPATCHER: Starting worker discovery
11:36:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:36:43 DISPATCHER: Finished worker discovery
11:37:43 DISPATCHER: Starting worker discovery
11:37:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:37:43 DISPATCHER: Finished worker discovery
11:38:43 DISPATCHER: Starting worker discovery
11:38:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:38:43 DISPATCHER: Finished worker discovery
11:39:43 DISPATCHER: Starting worker discovery
11:39:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:39:43 DISPATCHER: Finished worker discovery
11:40:43 DISPATCHER: Starting worker discovery
11:40:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:40:43 DISPATCHER: Finished worker discovery
11:41:43 DISPATCHER: Starting worker discovery
11:41:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:41:43 DISPATCHER: Finished worker discovery
11:42:43 DISPATCHER: Starting worker discovery
11:42:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:42:43 DISPATCHER: Finished worker discovery
11:43:43 DISPATCHER: Starting worker discovery
11:43:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:43:43 DISPATCHER: Finished worker discovery
11:44:43 DISPATCHER: Starting worker discovery
11:44:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:44:43 DISPATCHER: Finished worker discovery
11:45:43 DISPATCHER: Starting worker discovery
11:45:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:45:43 DISPATCHER: Finished worker discovery
11:46:43 DISPATCHER: Starting worker discovery
11:46:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:46:43 DISPATCHER: Finished worker discovery
11:46:46 WORKER: done with job (6, 0, 2), trying to register it.
11:46:46 WORKER: registered result for job (6, 0, 2) with dispatcher
11:46:46 DISPATCHER: job (6, 0, 2) finished
11:46:46 DISPATCHER: register_result: lock acquired
11:46:46 DISPATCHER: job (6, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
11:46:46 job_id: (6, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 84, 'last_n_outputs': 47, 'lr': 0.0019356225922075262, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.04255120392151161}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.3929391104731685, 'info': {'music_genre': 0.3929391104731685, 'config': "{'batch_size': 32, 'hidden_dim': 84, 'last_n_outputs': 47, 'lr': 0.0019356225922075262, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.04255120392151161}"}}
exception: None

11:46:46 job_callback for (6, 0, 2) started
11:46:46 DISPATCHER: Trying to submit another job.
11:46:46 job_callback for (6, 0, 2) got condition
11:46:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:46:46 HBMASTER: Trying to run another job!
11:46:46 job_callback for (6, 0, 2) finished
11:46:46 HBMASTER: schedule new run for iteration 6
11:46:46 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
11:46:46 HBMASTER: submitting job (6, 0, 4) to dispatcher
11:46:46 DISPATCHER: trying to submit job (6, 0, 4)
11:46:46 DISPATCHER: trying to notify the job_runner thread.
11:46:46 HBMASTER: job (6, 0, 4) submitted to dispatcher
11:46:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:46:46 DISPATCHER: Trying to submit another job.
11:46:46 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
11:46:46 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
11:46:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:46:46 WORKER: start processing job (6, 0, 4)
11:46:46 WORKER: args: ()
11:46:46 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 79, 'last_n_outputs': 50, 'lr': 0.0014393204840073446, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.020056639004090628}, 'budget': 1200.0, 'working_directory': '.'}
11:47:43 DISPATCHER: Starting worker discovery
11:47:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:47:43 DISPATCHER: Finished worker discovery
Exception in thread Thread-531:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:48:43 DISPATCHER: Starting worker discovery
11:48:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:48:43 DISPATCHER: Finished worker discovery
11:49:43 DISPATCHER: Starting worker discovery
11:49:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:49:43 DISPATCHER: Finished worker discovery
11:50:43 DISPATCHER: Starting worker discovery
11:50:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:50:43 DISPATCHER: Finished worker discovery
11:51:43 DISPATCHER: Starting worker discovery
11:51:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:51:43 DISPATCHER: Finished worker discovery
11:52:43 DISPATCHER: Starting worker discovery
11:52:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:52:43 DISPATCHER: Finished worker discovery
11:53:43 DISPATCHER: Starting worker discovery
11:53:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:53:43 DISPATCHER: Finished worker discovery
11:54:43 DISPATCHER: Starting worker discovery
11:54:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:54:43 DISPATCHER: Finished worker discovery
11:55:43 DISPATCHER: Starting worker discovery
11:55:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:55:43 DISPATCHER: Finished worker discovery
11:56:43 DISPATCHER: Starting worker discovery
11:56:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:56:43 DISPATCHER: Finished worker discovery
11:57:43 DISPATCHER: Starting worker discovery
11:57:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:57:43 DISPATCHER: Finished worker discovery
11:58:43 DISPATCHER: Starting worker discovery
11:58:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:58:43 DISPATCHER: Finished worker discovery
11:59:43 DISPATCHER: Starting worker discovery
11:59:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:59:43 DISPATCHER: Finished worker discovery
12:00:43 DISPATCHER: Starting worker discovery
12:00:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:00:43 DISPATCHER: Finished worker discovery
12:01:43 DISPATCHER: Starting worker discovery
12:01:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:01:43 DISPATCHER: Finished worker discovery
12:02:43 DISPATCHER: Starting worker discovery
12:02:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:02:43 DISPATCHER: Finished worker discovery
12:03:43 DISPATCHER: Starting worker discovery
12:03:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:03:43 DISPATCHER: Finished worker discovery
12:04:43 DISPATCHER: Starting worker discovery
12:04:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:04:43 DISPATCHER: Finished worker discovery
12:05:43 DISPATCHER: Starting worker discovery
12:05:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:05:43 DISPATCHER: Finished worker discovery
12:06:43 DISPATCHER: Starting worker discovery
12:06:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:06:43 DISPATCHER: Finished worker discovery
12:07:38 WORKER: done with job (6, 0, 4), trying to register it.
12:07:38 WORKER: registered result for job (6, 0, 4) with dispatcher
12:07:38 DISPATCHER: job (6, 0, 4) finished
12:07:38 DISPATCHER: register_result: lock acquired
12:07:38 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
12:07:38 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 79, 'last_n_outputs': 50, 'lr': 0.0014393204840073446, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.020056639004090628}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.363812307793821, 'info': {'music_genre': 0.363812307793821, 'config': "{'batch_size': 32, 'hidden_dim': 79, 'last_n_outputs': 50, 'lr': 0.0014393204840073446, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.020056639004090628}"}}
exception: None

12:07:38 job_callback for (6, 0, 4) started
12:07:38 job_callback for (6, 0, 4) got condition
12:07:38 DISPATCHER: Trying to submit another job.
12:07:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:07:38 HBMASTER: Trying to run another job!
12:07:38 job_callback for (6, 0, 4) finished
12:07:38 start sampling a new configuration.
12:07:38 best_vector: [1, 0.6962077227852032, 0.45384200312263345, 0.008646301027771364, 0.09467981570704262, 0, 0.8174988155132488, 0.010733749655961605], 0.0056306488468511615, 0.002256556081699416, 1.2705874899275793e-05
12:07:38 done sampling a new configuration.
12:07:38 HBMASTER: schedule new run for iteration 7
12:07:38 HBMASTER: trying submitting job (7, 0, 0) to dispatcher
12:07:38 HBMASTER: submitting job (7, 0, 0) to dispatcher
12:07:38 DISPATCHER: trying to submit job (7, 0, 0)
12:07:38 DISPATCHER: trying to notify the job_runner thread.
12:07:38 HBMASTER: job (7, 0, 0) submitted to dispatcher
12:07:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:07:38 DISPATCHER: Trying to submit another job.
12:07:38 DISPATCHER: starting job (7, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
12:07:38 DISPATCHER: job (7, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
12:07:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:07:38 WORKER: start processing job (7, 0, 0)
12:07:38 WORKER: args: ()
12:07:38 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 76, 'last_n_outputs': 23, 'lr': 0.001040621038895012, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.010326780125695536}, 'budget': 1200.0, 'working_directory': '.'}
12:07:43 DISPATCHER: Starting worker discovery
12:07:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:07:43 DISPATCHER: Finished worker discovery
Exception in thread Thread-532:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

12:08:43 DISPATCHER: Starting worker discovery
12:08:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:08:43 DISPATCHER: Finished worker discovery
12:09:43 DISPATCHER: Starting worker discovery
12:09:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:09:43 DISPATCHER: Finished worker discovery
12:10:43 DISPATCHER: Starting worker discovery
12:10:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:10:43 DISPATCHER: Finished worker discovery
12:11:43 DISPATCHER: Starting worker discovery
12:11:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:11:43 DISPATCHER: Finished worker discovery
12:12:43 DISPATCHER: Starting worker discovery
12:12:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:12:43 DISPATCHER: Finished worker discovery
12:13:43 DISPATCHER: Starting worker discovery
12:13:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:13:43 DISPATCHER: Finished worker discovery
12:14:43 DISPATCHER: Starting worker discovery
12:14:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:14:43 DISPATCHER: Finished worker discovery
12:15:43 DISPATCHER: Starting worker discovery
12:15:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:15:43 DISPATCHER: Finished worker discovery
12:16:43 DISPATCHER: Starting worker discovery
12:16:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:16:43 DISPATCHER: Finished worker discovery
12:17:43 DISPATCHER: Starting worker discovery
12:17:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:17:43 DISPATCHER: Finished worker discovery
12:18:43 DISPATCHER: Starting worker discovery
12:18:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:18:43 DISPATCHER: Finished worker discovery
12:19:43 DISPATCHER: Starting worker discovery
12:19:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:19:43 DISPATCHER: Finished worker discovery
12:20:43 DISPATCHER: Starting worker discovery
12:20:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:20:43 DISPATCHER: Finished worker discovery
12:21:43 DISPATCHER: Starting worker discovery
12:21:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:21:43 DISPATCHER: Finished worker discovery
12:22:43 DISPATCHER: Starting worker discovery
12:22:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:22:43 DISPATCHER: Finished worker discovery
12:23:43 DISPATCHER: Starting worker discovery
12:23:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:23:43 DISPATCHER: Finished worker discovery
12:24:43 DISPATCHER: Starting worker discovery
12:24:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:24:43 DISPATCHER: Finished worker discovery
12:25:43 DISPATCHER: Starting worker discovery
12:25:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:25:43 DISPATCHER: Finished worker discovery
12:26:43 DISPATCHER: Starting worker discovery
12:26:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:26:43 DISPATCHER: Finished worker discovery
12:27:43 DISPATCHER: Starting worker discovery
12:27:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:27:43 DISPATCHER: Finished worker discovery
12:28:30 WORKER: done with job (7, 0, 0), trying to register it.
12:28:30 WORKER: registered result for job (7, 0, 0) with dispatcher
12:28:30 DISPATCHER: job (7, 0, 0) finished
12:28:30 DISPATCHER: register_result: lock acquired
12:28:30 DISPATCHER: job (7, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
12:28:30 job_id: (7, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 76, 'last_n_outputs': 23, 'lr': 0.001040621038895012, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.010326780125695536}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.36304960650684853, 'info': {'music_genre': 0.36304960650684853, 'config': "{'batch_size': 32, 'hidden_dim': 76, 'last_n_outputs': 23, 'lr': 0.001040621038895012, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.010326780125695536}"}}
exception: None

12:28:30 job_callback for (7, 0, 0) started
12:28:30 job_callback for (7, 0, 0) got condition
12:28:30 DISPATCHER: Trying to submit another job.
12:28:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:28:30 HBMASTER: Trying to run another job!
12:28:30 job_callback for (7, 0, 0) finished
12:28:30 start sampling a new configuration.
12:28:30 done sampling a new configuration.
12:28:30 HBMASTER: schedule new run for iteration 7
12:28:30 HBMASTER: trying submitting job (7, 0, 1) to dispatcher
12:28:30 HBMASTER: submitting job (7, 0, 1) to dispatcher
12:28:30 DISPATCHER: trying to submit job (7, 0, 1)
12:28:30 DISPATCHER: trying to notify the job_runner thread.
12:28:30 HBMASTER: job (7, 0, 1) submitted to dispatcher
12:28:30 DISPATCHER: Trying to submit another job.
12:28:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:28:30 DISPATCHER: starting job (7, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
12:28:30 DISPATCHER: job (7, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
12:28:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:28:30 WORKER: start processing job (7, 0, 1)
12:28:30 WORKER: args: ()
12:28:30 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 82, 'last_n_outputs': 30, 'lr': 0.03324876830545362, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.03979036360843521}, 'budget': 1200.0, 'working_directory': '.'}
12:28:43 DISPATCHER: Starting worker discovery
12:28:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:28:43 DISPATCHER: Finished worker discovery
Exception in thread Thread-533:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

12:29:43 DISPATCHER: Starting worker discovery
12:29:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:29:43 DISPATCHER: Finished worker discovery
12:30:43 DISPATCHER: Starting worker discovery
12:30:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:30:43 DISPATCHER: Finished worker discovery
12:31:43 DISPATCHER: Starting worker discovery
12:31:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:31:43 DISPATCHER: Finished worker discovery
12:32:43 DISPATCHER: Starting worker discovery
12:32:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:32:43 DISPATCHER: Finished worker discovery
12:33:43 DISPATCHER: Starting worker discovery
12:33:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:33:43 DISPATCHER: Finished worker discovery
12:34:43 DISPATCHER: Starting worker discovery
12:34:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:34:43 DISPATCHER: Finished worker discovery
12:35:43 DISPATCHER: Starting worker discovery
12:35:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:35:43 DISPATCHER: Finished worker discovery
12:36:43 DISPATCHER: Starting worker discovery
12:36:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:36:43 DISPATCHER: Finished worker discovery
12:37:43 DISPATCHER: Starting worker discovery
12:37:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:37:43 DISPATCHER: Finished worker discovery
12:38:43 DISPATCHER: Starting worker discovery
12:38:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:38:43 DISPATCHER: Finished worker discovery
12:39:43 DISPATCHER: Starting worker discovery
12:39:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:39:43 DISPATCHER: Finished worker discovery
12:40:43 DISPATCHER: Starting worker discovery
12:40:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:40:43 DISPATCHER: Finished worker discovery
12:41:43 DISPATCHER: Starting worker discovery
12:41:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:41:43 DISPATCHER: Finished worker discovery
12:42:43 DISPATCHER: Starting worker discovery
12:42:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:42:43 DISPATCHER: Finished worker discovery
12:43:43 DISPATCHER: Starting worker discovery
12:43:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:43:44 DISPATCHER: Finished worker discovery
12:44:44 DISPATCHER: Starting worker discovery
12:44:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:44:44 DISPATCHER: Finished worker discovery
12:45:44 DISPATCHER: Starting worker discovery
12:45:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:45:44 DISPATCHER: Finished worker discovery
12:46:44 DISPATCHER: Starting worker discovery
12:46:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:46:44 DISPATCHER: Finished worker discovery
12:47:44 DISPATCHER: Starting worker discovery
12:47:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:47:44 DISPATCHER: Finished worker discovery
12:48:44 DISPATCHER: Starting worker discovery
12:48:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:48:44 DISPATCHER: Finished worker discovery
12:49:23 WORKER: done with job (7, 0, 1), trying to register it.
12:49:23 WORKER: registered result for job (7, 0, 1) with dispatcher
12:49:23 DISPATCHER: job (7, 0, 1) finished
12:49:23 DISPATCHER: register_result: lock acquired
12:49:23 DISPATCHER: job (7, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
12:49:23 job_id: (7, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 82, 'last_n_outputs': 30, 'lr': 0.03324876830545362, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.03979036360843521}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 82, 'last_n_outputs': 30, 'lr': 0.03324876830545362, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.03979036360843521}"}}
exception: None

12:49:23 job_callback for (7, 0, 1) started
12:49:23 DISPATCHER: Trying to submit another job.
12:49:23 job_callback for (7, 0, 1) got condition
12:49:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:49:23 HBMASTER: Trying to run another job!
12:49:23 job_callback for (7, 0, 1) finished
12:49:23 start sampling a new configuration.
12:49:23 best_vector: [1, 0.6445086041480825, 0.30664787577290686, 0.06416810820801175, 0.10198599224874838, 0, 0.8529828466284989, 0.04269063702544667], 0.005081788012113723, 284.1961424744726, 1.4442245499157385
12:49:23 done sampling a new configuration.
12:49:23 HBMASTER: schedule new run for iteration 7
12:49:23 HBMASTER: trying submitting job (7, 0, 2) to dispatcher
12:49:23 HBMASTER: submitting job (7, 0, 2) to dispatcher
12:49:23 DISPATCHER: trying to submit job (7, 0, 2)
12:49:23 DISPATCHER: trying to notify the job_runner thread.
12:49:23 HBMASTER: job (7, 0, 2) submitted to dispatcher
12:49:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:49:23 DISPATCHER: Trying to submit another job.
12:49:23 DISPATCHER: starting job (7, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
12:49:23 DISPATCHER: job (7, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
12:49:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:49:23 WORKER: start processing job (7, 0, 2)
12:49:23 WORKER: args: ()
12:49:23 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 72, 'last_n_outputs': 16, 'lr': 0.0013438048878218756, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.011364276695379335}, 'budget': 1200.0, 'working_directory': '.'}
12:49:44 DISPATCHER: Starting worker discovery
12:49:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:49:44 DISPATCHER: Finished worker discovery
Exception in thread Thread-534:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

12:50:44 DISPATCHER: Starting worker discovery
12:50:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:50:44 DISPATCHER: Finished worker discovery
12:51:44 DISPATCHER: Starting worker discovery
12:51:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:51:44 DISPATCHER: Finished worker discovery
12:52:44 DISPATCHER: Starting worker discovery
12:52:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:52:44 DISPATCHER: Finished worker discovery
12:53:44 DISPATCHER: Starting worker discovery
12:53:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:53:44 DISPATCHER: Finished worker discovery
12:54:44 DISPATCHER: Starting worker discovery
12:54:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:54:44 DISPATCHER: Finished worker discovery
12:55:44 DISPATCHER: Starting worker discovery
12:55:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:55:44 DISPATCHER: Finished worker discovery
12:56:44 DISPATCHER: Starting worker discovery
12:56:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:56:44 DISPATCHER: Finished worker discovery
12:57:44 DISPATCHER: Starting worker discovery
12:57:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:57:44 DISPATCHER: Finished worker discovery
12:58:44 DISPATCHER: Starting worker discovery
12:58:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:58:44 DISPATCHER: Finished worker discovery
12:59:44 DISPATCHER: Starting worker discovery
12:59:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:59:44 DISPATCHER: Finished worker discovery
13:00:44 DISPATCHER: Starting worker discovery
13:00:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:00:44 DISPATCHER: Finished worker discovery
13:01:44 DISPATCHER: Starting worker discovery
13:01:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:01:44 DISPATCHER: Finished worker discovery
13:02:44 DISPATCHER: Starting worker discovery
13:02:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:02:44 DISPATCHER: Finished worker discovery
13:03:44 DISPATCHER: Starting worker discovery
13:03:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:03:44 DISPATCHER: Finished worker discovery
13:04:44 DISPATCHER: Starting worker discovery
13:04:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:04:44 DISPATCHER: Finished worker discovery
13:05:44 DISPATCHER: Starting worker discovery
13:05:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:05:44 DISPATCHER: Finished worker discovery
13:06:44 DISPATCHER: Starting worker discovery
13:06:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:06:44 DISPATCHER: Finished worker discovery
13:07:44 DISPATCHER: Starting worker discovery
13:07:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:07:44 DISPATCHER: Finished worker discovery
13:08:44 DISPATCHER: Starting worker discovery
13:08:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:08:44 DISPATCHER: Finished worker discovery
13:09:44 DISPATCHER: Starting worker discovery
13:09:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:09:44 DISPATCHER: Finished worker discovery
13:10:16 WORKER: done with job (7, 0, 2), trying to register it.
13:10:16 WORKER: registered result for job (7, 0, 2) with dispatcher
13:10:16 DISPATCHER: job (7, 0, 2) finished
13:10:16 DISPATCHER: register_result: lock acquired
13:10:16 DISPATCHER: job (7, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
13:10:16 job_id: (7, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 72, 'last_n_outputs': 16, 'lr': 0.0013438048878218756, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.011364276695379335}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.319964545719632, 'info': {'music_genre': 0.319964545719632, 'config': "{'batch_size': 32, 'hidden_dim': 72, 'last_n_outputs': 16, 'lr': 0.0013438048878218756, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.011364276695379335}"}}
exception: None

13:10:16 job_callback for (7, 0, 2) started
13:10:16 job_callback for (7, 0, 2) got condition
13:10:16 DISPATCHER: Trying to submit another job.
13:10:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:10:16 HBMASTER: Trying to run another job!
13:10:16 job_callback for (7, 0, 2) finished
13:10:16 start sampling a new configuration.
13:10:16 best_vector: [1, 0.7510122183957637, 0.8582645916446003, 0.12332703989977847, 0.10213331615386823, 0, 0.8683852336732175, 0.4081194845343072], 0.004575554044304294, 986.4224682269012, 4.5134293138882216
13:10:16 done sampling a new configuration.
13:10:16 HBMASTER: schedule new run for iteration 7
13:10:16 HBMASTER: trying submitting job (7, 0, 3) to dispatcher
13:10:16 HBMASTER: submitting job (7, 0, 3) to dispatcher
13:10:16 DISPATCHER: trying to submit job (7, 0, 3)
13:10:16 DISPATCHER: trying to notify the job_runner thread.
13:10:16 HBMASTER: job (7, 0, 3) submitted to dispatcher
13:10:16 DISPATCHER: Trying to submit another job.
13:10:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:10:16 DISPATCHER: starting job (7, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:10:16 DISPATCHER: job (7, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:10:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:10:16 WORKER: start processing job (7, 0, 3)
13:10:16 WORKER: args: ()
13:10:16 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 80, 'last_n_outputs': 43, 'lr': 0.0017646317127352003, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.03396062632450456}, 'budget': 1200.0, 'working_directory': '.'}
13:10:44 DISPATCHER: Starting worker discovery
13:10:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:10:44 DISPATCHER: Finished worker discovery
Exception in thread Thread-535:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:11:44 DISPATCHER: Starting worker discovery
13:11:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:11:44 DISPATCHER: Finished worker discovery
13:12:44 DISPATCHER: Starting worker discovery
13:12:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:12:44 DISPATCHER: Finished worker discovery
13:13:44 DISPATCHER: Starting worker discovery
13:13:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:13:44 DISPATCHER: Finished worker discovery
13:14:44 DISPATCHER: Starting worker discovery
13:14:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:14:44 DISPATCHER: Finished worker discovery
13:15:44 DISPATCHER: Starting worker discovery
13:15:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:15:44 DISPATCHER: Finished worker discovery
13:16:44 DISPATCHER: Starting worker discovery
13:16:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:16:44 DISPATCHER: Finished worker discovery
13:17:44 DISPATCHER: Starting worker discovery
13:17:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:17:44 DISPATCHER: Finished worker discovery
13:18:44 DISPATCHER: Starting worker discovery
13:18:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:18:44 DISPATCHER: Finished worker discovery
13:19:44 DISPATCHER: Starting worker discovery
13:19:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:19:44 DISPATCHER: Finished worker discovery
13:20:44 DISPATCHER: Starting worker discovery
13:20:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:20:44 DISPATCHER: Finished worker discovery
13:21:44 DISPATCHER: Starting worker discovery
13:21:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:21:44 DISPATCHER: Finished worker discovery
13:22:44 DISPATCHER: Starting worker discovery
13:22:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:22:44 DISPATCHER: Finished worker discovery
13:23:44 DISPATCHER: Starting worker discovery
13:23:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:23:44 DISPATCHER: Finished worker discovery
13:24:44 DISPATCHER: Starting worker discovery
13:24:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:24:44 DISPATCHER: Finished worker discovery
13:25:44 DISPATCHER: Starting worker discovery
13:25:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:25:44 DISPATCHER: Finished worker discovery
13:26:44 DISPATCHER: Starting worker discovery
13:26:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:26:44 DISPATCHER: Finished worker discovery
13:27:44 DISPATCHER: Starting worker discovery
13:27:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:27:44 DISPATCHER: Finished worker discovery
13:28:44 DISPATCHER: Starting worker discovery
13:28:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:28:44 DISPATCHER: Finished worker discovery
13:29:44 DISPATCHER: Starting worker discovery
13:29:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:29:44 DISPATCHER: Finished worker discovery
13:30:44 DISPATCHER: Starting worker discovery
13:30:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:30:44 DISPATCHER: Finished worker discovery
13:31:07 WORKER: done with job (7, 0, 3), trying to register it.
13:31:07 WORKER: registered result for job (7, 0, 3) with dispatcher
13:31:07 DISPATCHER: job (7, 0, 3) finished
13:31:07 DISPATCHER: register_result: lock acquired
13:31:07 DISPATCHER: job (7, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
13:31:07 job_id: (7, 0, 3)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 80, 'last_n_outputs': 43, 'lr': 0.0017646317127352003, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.03396062632450456}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.384574610618715, 'info': {'music_genre': 0.384574610618715, 'config': "{'batch_size': 32, 'hidden_dim': 80, 'last_n_outputs': 43, 'lr': 0.0017646317127352003, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.03396062632450456}"}}
exception: None

13:31:07 job_callback for (7, 0, 3) started
13:31:07 DISPATCHER: Trying to submit another job.
13:31:07 job_callback for (7, 0, 3) got condition
13:31:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:31:07 HBMASTER: Trying to run another job!
13:31:07 job_callback for (7, 0, 3) finished
13:31:07 start sampling a new configuration.
13:31:07 best_vector: [1, 0.70754885052093, 0.48754275795968044, 0.15331806969530481, 0.10617547865187295, 0, 0.9515735365220156, 0.4714132651238457], 0.010688620504964032, 1.0798390054372167e-05, 1.1541989335576201e-07
13:31:07 done sampling a new configuration.
13:31:07 HBMASTER: schedule new run for iteration 8
13:31:07 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
13:31:07 HBMASTER: submitting job (8, 0, 0) to dispatcher
13:31:07 DISPATCHER: trying to submit job (8, 0, 0)
13:31:07 DISPATCHER: trying to notify the job_runner thread.
13:31:07 HBMASTER: job (8, 0, 0) submitted to dispatcher
13:31:07 DISPATCHER: Trying to submit another job.
13:31:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:31:07 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:31:07 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:31:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:31:07 WORKER: start processing job (8, 0, 0)
13:31:07 WORKER: args: ()
13:31:07 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 77, 'last_n_outputs': 25, 'lr': 0.002025984597814083, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.04105091089353824}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:31:44 DISPATCHER: Starting worker discovery
13:31:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:31:44 DISPATCHER: Finished worker discovery
Exception in thread Thread-536:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:32:44 WORKER: done with job (8, 0, 0), trying to register it.
13:32:44 WORKER: registered result for job (8, 0, 0) with dispatcher
13:32:44 DISPATCHER: job (8, 0, 0) finished
13:32:44 DISPATCHER: register_result: lock acquired
13:32:44 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
13:32:44 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 77, 'last_n_outputs': 25, 'lr': 0.002025984597814083, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.04105091089353824}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.358864184577977, 'info': {'music_genre': 0.358864184577977, 'config': "{'batch_size': 32, 'hidden_dim': 77, 'last_n_outputs': 25, 'lr': 0.002025984597814083, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.04105091089353824}"}}
exception: None

13:32:44 job_callback for (8, 0, 0) started
13:32:44 DISPATCHER: Trying to submit another job.
13:32:44 job_callback for (8, 0, 0) got condition
13:32:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:32:44 HBMASTER: Trying to run another job!
13:32:44 job_callback for (8, 0, 0) finished
13:32:44 start sampling a new configuration.
13:32:44 DISPATCHER: Starting worker discovery
13:32:44 best_vector: [1, 0.8748112920803636, 0.807345790211953, 0.11235444838339996, 0.09711759310459063, 0, 0.9281052996623276, 0.5527289132570894], 0.003501216750292045, 77.2202647567008, 0.2703648844281473
13:32:44 done sampling a new configuration.
13:32:44 HBMASTER: schedule new run for iteration 8
13:32:44 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
13:32:44 HBMASTER: submitting job (8, 0, 1) to dispatcher
13:32:44 DISPATCHER: trying to submit job (8, 0, 1)
13:32:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:32:44 DISPATCHER: Finished worker discovery
13:32:44 DISPATCHER: trying to notify the job_runner thread.
13:32:44 HBMASTER: job (8, 0, 1) submitted to dispatcher
13:32:44 DISPATCHER: Trying to submit another job.
13:32:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:32:44 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:32:44 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:32:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:32:44 WORKER: start processing job (8, 0, 1)
13:32:44 WORKER: args: ()
13:32:44 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 90, 'last_n_outputs': 41, 'lr': 0.0016776791096850625, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.05237413889516617}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-537:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:33:44 DISPATCHER: Starting worker discovery
13:33:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:33:44 DISPATCHER: Finished worker discovery
13:34:19 WORKER: done with job (8, 0, 1), trying to register it.
13:34:19 WORKER: registered result for job (8, 0, 1) with dispatcher
13:34:19 DISPATCHER: job (8, 0, 1) finished
13:34:19 DISPATCHER: register_result: lock acquired
13:34:19 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
13:34:19 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 90, 'last_n_outputs': 41, 'lr': 0.0016776791096850625, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.05237413889516617}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.374911528706248, 'info': {'music_genre': 0.374911528706248, 'config': "{'batch_size': 32, 'hidden_dim': 90, 'last_n_outputs': 41, 'lr': 0.0016776791096850625, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.05237413889516617}"}}
exception: None

13:34:19 job_callback for (8, 0, 1) started
13:34:19 job_callback for (8, 0, 1) got condition
13:34:19 DISPATCHER: Trying to submit another job.
13:34:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:34:19 HBMASTER: Trying to run another job!
13:34:19 job_callback for (8, 0, 1) finished
13:34:19 start sampling a new configuration.
13:34:19 done sampling a new configuration.
13:34:19 HBMASTER: schedule new run for iteration 8
13:34:19 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
13:34:19 HBMASTER: submitting job (8, 0, 2) to dispatcher
13:34:19 DISPATCHER: trying to submit job (8, 0, 2)
13:34:19 DISPATCHER: trying to notify the job_runner thread.
13:34:19 HBMASTER: job (8, 0, 2) submitted to dispatcher
13:34:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:34:19 DISPATCHER: Trying to submit another job.
13:34:19 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:34:19 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:34:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:34:19 WORKER: start processing job (8, 0, 2)
13:34:19 WORKER: args: ()
13:34:19 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 43, 'last_n_outputs': 2, 'lr': 0.0034316337616336606, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.18389945879061267}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:34:44 DISPATCHER: Starting worker discovery
13:34:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:34:44 DISPATCHER: Finished worker discovery
Exception in thread Thread-538:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:35:44 DISPATCHER: Starting worker discovery
13:35:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:35:44 DISPATCHER: Finished worker discovery
13:35:54 WORKER: done with job (8, 0, 2), trying to register it.
13:35:54 WORKER: registered result for job (8, 0, 2) with dispatcher
13:35:54 DISPATCHER: job (8, 0, 2) finished
13:35:54 DISPATCHER: register_result: lock acquired
13:35:54 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
13:35:54 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 43, 'last_n_outputs': 2, 'lr': 0.0034316337616336606, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.18389945879061267}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 43, 'last_n_outputs': 2, 'lr': 0.0034316337616336606, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.18389945879061267}"}}
exception: None

13:35:54 job_callback for (8, 0, 2) started
13:35:54 job_callback for (8, 0, 2) got condition
13:35:54 DISPATCHER: Trying to submit another job.
13:35:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:35:54 HBMASTER: Trying to run another job!
13:35:54 job_callback for (8, 0, 2) finished
13:35:54 start sampling a new configuration.
13:35:54 done sampling a new configuration.
13:35:54 HBMASTER: schedule new run for iteration 8
13:35:54 HBMASTER: trying submitting job (8, 0, 3) to dispatcher
13:35:54 HBMASTER: submitting job (8, 0, 3) to dispatcher
13:35:54 DISPATCHER: trying to submit job (8, 0, 3)
13:35:54 DISPATCHER: trying to notify the job_runner thread.
13:35:54 HBMASTER: job (8, 0, 3) submitted to dispatcher
13:35:54 DISPATCHER: Trying to submit another job.
13:35:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:35:54 DISPATCHER: starting job (8, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:35:54 DISPATCHER: job (8, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:35:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:35:54 WORKER: start processing job (8, 0, 3)
13:35:54 WORKER: args: ()
13:35:54 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 64, 'last_n_outputs': 10, 'lr': 0.0019133485914239437, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.05451608308447226}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:36:44 DISPATCHER: Starting worker discovery
13:36:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:36:44 DISPATCHER: Finished worker discovery
Exception in thread Thread-539:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:37:32 WORKER: done with job (8, 0, 3), trying to register it.
13:37:32 WORKER: registered result for job (8, 0, 3) with dispatcher
13:37:32 DISPATCHER: job (8, 0, 3) finished
13:37:32 DISPATCHER: register_result: lock acquired
13:37:32 DISPATCHER: job (8, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
13:37:32 job_id: (8, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 64, 'last_n_outputs': 10, 'lr': 0.0019133485914239437, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.05451608308447226}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.23441394742723604, 'info': {'music_genre': 0.23441394742723604, 'config': "{'batch_size': 16, 'hidden_dim': 64, 'last_n_outputs': 10, 'lr': 0.0019133485914239437, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.05451608308447226}"}}
exception: None

13:37:32 job_callback for (8, 0, 3) started
13:37:32 DISPATCHER: Trying to submit another job.
13:37:32 job_callback for (8, 0, 3) got condition
13:37:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:37:32 HBMASTER: Trying to run another job!
13:37:32 job_callback for (8, 0, 3) finished
13:37:32 start sampling a new configuration.
13:37:32 best_vector: [1, 0.9425441502574478, 0.6601813564599592, 0.22096568073122602, 0.09782114343563907, 0, 0.9545221749064496, 0.18353434389533865], 0.00610699519824547, 436.2869863902833, 2.664402530942447
13:37:32 done sampling a new configuration.
13:37:32 HBMASTER: schedule new run for iteration 8
13:37:32 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
13:37:32 HBMASTER: submitting job (8, 0, 4) to dispatcher
13:37:32 DISPATCHER: trying to submit job (8, 0, 4)
13:37:32 DISPATCHER: trying to notify the job_runner thread.
13:37:32 HBMASTER: job (8, 0, 4) submitted to dispatcher
13:37:32 DISPATCHER: Trying to submit another job.
13:37:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:37:32 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:37:32 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:37:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:37:32 WORKER: start processing job (8, 0, 4)
13:37:32 WORKER: args: ()
13:37:32 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 96, 'last_n_outputs': 34, 'lr': 0.002766504375704521, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.017329406398386704}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:37:44 DISPATCHER: Starting worker discovery
13:37:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:37:44 DISPATCHER: Finished worker discovery
Exception in thread Thread-540:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:38:44 DISPATCHER: Starting worker discovery
13:38:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:38:44 DISPATCHER: Finished worker discovery
13:39:08 WORKER: done with job (8, 0, 4), trying to register it.
13:39:08 WORKER: registered result for job (8, 0, 4) with dispatcher
13:39:08 DISPATCHER: job (8, 0, 4) finished
13:39:08 DISPATCHER: register_result: lock acquired
13:39:08 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
13:39:08 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 96, 'last_n_outputs': 34, 'lr': 0.002766504375704521, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.017329406398386704}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.39834973272381113, 'info': {'music_genre': 0.39834973272381113, 'config': "{'batch_size': 32, 'hidden_dim': 96, 'last_n_outputs': 34, 'lr': 0.002766504375704521, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.017329406398386704}"}}
exception: None

13:39:08 job_callback for (8, 0, 4) started
13:39:08 DISPATCHER: Trying to submit another job.
13:39:08 job_callback for (8, 0, 4) got condition
13:39:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:39:08 HBMASTER: Trying to run another job!
13:39:08 job_callback for (8, 0, 4) finished
13:39:08 start sampling a new configuration.
13:39:08 done sampling a new configuration.
13:39:08 HBMASTER: schedule new run for iteration 8
13:39:08 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
13:39:08 HBMASTER: submitting job (8, 0, 5) to dispatcher
13:39:08 DISPATCHER: trying to submit job (8, 0, 5)
13:39:08 DISPATCHER: trying to notify the job_runner thread.
13:39:08 HBMASTER: job (8, 0, 5) submitted to dispatcher
13:39:08 DISPATCHER: Trying to submit another job.
13:39:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:39:08 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:39:08 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:39:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:39:08 WORKER: start processing job (8, 0, 5)
13:39:08 WORKER: args: ()
13:39:08 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 46, 'lr': 0.004609370388941312, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.040971591070003144}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:39:44 DISPATCHER: Starting worker discovery
13:39:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:39:44 DISPATCHER: Finished worker discovery
Exception in thread Thread-541:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:40:44 DISPATCHER: Starting worker discovery
13:40:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:40:44 DISPATCHER: Finished worker discovery
13:40:45 WORKER: done with job (8, 0, 5), trying to register it.
13:40:45 WORKER: registered result for job (8, 0, 5) with dispatcher
13:40:45 DISPATCHER: job (8, 0, 5) finished
13:40:45 DISPATCHER: register_result: lock acquired
13:40:45 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
13:40:45 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 46, 'lr': 0.004609370388941312, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.040971591070003144}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.15452303691329836, 'info': {'music_genre': 0.15452303691329836, 'config': "{'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 46, 'lr': 0.004609370388941312, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.040971591070003144}"}}
exception: None

13:40:45 job_callback for (8, 0, 5) started
13:40:45 DISPATCHER: Trying to submit another job.
13:40:45 job_callback for (8, 0, 5) got condition
13:40:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:40:45 HBMASTER: Trying to run another job!
13:40:45 job_callback for (8, 0, 5) finished
13:40:45 start sampling a new configuration.
13:40:45 best_vector: [1, 0.8469435329661591, 0.4321035642589981, 0.1423032336098931, 0.09717909395534038, 0, 0.9083143014347476, 0.0024711142509112327], 0.0085095405247201, 27.502709939417272, 0.23403542476909356
13:40:45 done sampling a new configuration.
13:40:45 HBMASTER: schedule new run for iteration 8
13:40:45 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
13:40:45 HBMASTER: submitting job (8, 0, 6) to dispatcher
13:40:45 DISPATCHER: trying to submit job (8, 0, 6)
13:40:45 DISPATCHER: trying to notify the job_runner thread.
13:40:45 HBMASTER: job (8, 0, 6) submitted to dispatcher
13:40:45 DISPATCHER: Trying to submit another job.
13:40:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:40:45 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:40:45 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:40:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:40:45 WORKER: start processing job (8, 0, 6)
13:40:45 WORKER: args: ()
13:40:45 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 88, 'last_n_outputs': 22, 'lr': 0.0019257790916372942, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.010074302651519366}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:41:44 DISPATCHER: Starting worker discovery
13:41:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:41:44 DISPATCHER: Finished worker discovery
Exception in thread Thread-542:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:42:23 WORKER: done with job (8, 0, 6), trying to register it.
13:42:23 WORKER: registered result for job (8, 0, 6) with dispatcher
13:42:23 DISPATCHER: job (8, 0, 6) finished
13:42:23 DISPATCHER: register_result: lock acquired
13:42:23 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
13:42:23 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 88, 'last_n_outputs': 22, 'lr': 0.0019257790916372942, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.010074302651519366}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3660645971591606, 'info': {'music_genre': 0.3660645971591606, 'config': "{'batch_size': 32, 'hidden_dim': 88, 'last_n_outputs': 22, 'lr': 0.0019257790916372942, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.010074302651519366}"}}
exception: None

13:42:23 job_callback for (8, 0, 6) started
13:42:23 DISPATCHER: Trying to submit another job.
13:42:23 job_callback for (8, 0, 6) got condition
13:42:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:42:23 HBMASTER: Trying to run another job!
13:42:23 job_callback for (8, 0, 6) finished
13:42:23 start sampling a new configuration.
13:42:23 best_vector: [1, 0.5703095137882205, 0.3572128882699823, 0.025569449086238177, 0.0970936167402634, 0, 0.9729322429492478, 0.3405221935173161], 0.007384603696202806, 30.435608401308343, 0.2247549062964828
13:42:23 done sampling a new configuration.
13:42:23 HBMASTER: schedule new run for iteration 8
13:42:23 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
13:42:23 HBMASTER: submitting job (8, 0, 7) to dispatcher
13:42:23 DISPATCHER: trying to submit job (8, 0, 7)
13:42:23 DISPATCHER: trying to notify the job_runner thread.
13:42:23 HBMASTER: job (8, 0, 7) submitted to dispatcher
13:42:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:42:23 DISPATCHER: Trying to submit another job.
13:42:23 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:42:23 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:42:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:42:23 WORKER: start processing job (8, 0, 7)
13:42:23 WORKER: args: ()
13:42:23 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 66, 'last_n_outputs': 18, 'lr': 0.0011249647081197388, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.027735090540169694}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:42:44 DISPATCHER: Starting worker discovery
13:42:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:42:44 DISPATCHER: Finished worker discovery
Exception in thread Thread-543:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:43:44 DISPATCHER: Starting worker discovery
13:43:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:43:44 DISPATCHER: Finished worker discovery
13:43:58 WORKER: done with job (8, 0, 7), trying to register it.
13:43:58 WORKER: registered result for job (8, 0, 7) with dispatcher
13:43:58 DISPATCHER: job (8, 0, 7) finished
13:43:58 DISPATCHER: register_result: lock acquired
13:43:58 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
13:43:58 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 66, 'last_n_outputs': 18, 'lr': 0.0011249647081197388, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.027735090540169694}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3349778326153743, 'info': {'music_genre': 0.3349778326153743, 'config': "{'batch_size': 32, 'hidden_dim': 66, 'last_n_outputs': 18, 'lr': 0.0011249647081197388, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.027735090540169694}"}}
exception: None

13:43:58 job_callback for (8, 0, 7) started
13:43:58 job_callback for (8, 0, 7) got condition
13:43:58 DISPATCHER: Trying to submit another job.
13:43:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:43:58 HBMASTER: Trying to run another job!
13:43:58 job_callback for (8, 0, 7) finished
13:43:58 start sampling a new configuration.
13:43:58 best_vector: [1, 0.7636019760376769, 0.9339459823616715, 0.1251634981603878, 0.10055566766393778, 0, 0.8501612317916831, 0.45694738279596925], 0.003215814486392597, 7270.843626613188, 23.381684262757975
13:43:58 done sampling a new configuration.
13:43:58 HBMASTER: schedule new run for iteration 8
13:43:58 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
13:43:58 HBMASTER: submitting job (8, 0, 8) to dispatcher
13:43:58 DISPATCHER: trying to submit job (8, 0, 8)
13:43:58 DISPATCHER: trying to notify the job_runner thread.
13:43:58 HBMASTER: job (8, 0, 8) submitted to dispatcher
13:43:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:43:58 DISPATCHER: Trying to submit another job.
13:43:58 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:43:58 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:43:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:43:58 WORKER: start processing job (8, 0, 8)
13:43:58 WORKER: args: ()
13:43:58 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 81, 'last_n_outputs': 47, 'lr': 0.0017796188463350825, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.03930992827968554}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:44:44 DISPATCHER: Starting worker discovery
13:44:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:44:44 DISPATCHER: Finished worker discovery
Exception in thread Thread-544:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:45:35 WORKER: done with job (8, 0, 8), trying to register it.
13:45:35 WORKER: registered result for job (8, 0, 8) with dispatcher
13:45:35 DISPATCHER: job (8, 0, 8) finished
13:45:35 DISPATCHER: register_result: lock acquired
13:45:35 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
13:45:35 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 81, 'last_n_outputs': 47, 'lr': 0.0017796188463350825, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.03930992827968554}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.37406820168368465, 'info': {'music_genre': 0.37406820168368465, 'config': "{'batch_size': 32, 'hidden_dim': 81, 'last_n_outputs': 47, 'lr': 0.0017796188463350825, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.03930992827968554}"}}
exception: None

13:45:35 job_callback for (8, 0, 8) started
13:45:35 job_callback for (8, 0, 8) got condition
13:45:35 DISPATCHER: Trying to submit another job.
13:45:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:45:35 HBMASTER: Trying to run another job!
13:45:35 job_callback for (8, 0, 8) finished
13:45:35 start sampling a new configuration.
13:45:36 best_vector: [1, 0.6193707616031581, 0.2814747129706061, 0.12122454333954959, 0.09853234367817758, 0, 0.9764251762233584, 0.10801345729810785], 0.003914676760794514, 862.6735472881348, 3.3770880877210283
13:45:36 done sampling a new configuration.
13:45:36 HBMASTER: schedule new run for iteration 8
13:45:36 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
13:45:36 HBMASTER: submitting job (8, 0, 9) to dispatcher
13:45:36 DISPATCHER: trying to submit job (8, 0, 9)
13:45:36 DISPATCHER: trying to notify the job_runner thread.
13:45:36 HBMASTER: job (8, 0, 9) submitted to dispatcher
13:45:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:45:36 DISPATCHER: Trying to submit another job.
13:45:36 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:45:36 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:45:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:45:36 WORKER: start processing job (8, 0, 9)
13:45:36 WORKER: args: ()
13:45:36 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 70, 'last_n_outputs': 15, 'lr': 0.0017476283719958204, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.01382065887951543}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:45:44 DISPATCHER: Starting worker discovery
13:45:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:45:44 DISPATCHER: Finished worker discovery
Exception in thread Thread-545:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:46:44 DISPATCHER: Starting worker discovery
13:46:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:46:44 DISPATCHER: Finished worker discovery
13:47:13 WORKER: done with job (8, 0, 9), trying to register it.
13:47:13 WORKER: registered result for job (8, 0, 9) with dispatcher
13:47:13 DISPATCHER: job (8, 0, 9) finished
13:47:13 DISPATCHER: register_result: lock acquired
13:47:13 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
13:47:13 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 70, 'last_n_outputs': 15, 'lr': 0.0017476283719958204, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.01382065887951543}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3862506371368705, 'info': {'music_genre': 0.3862506371368705, 'config': "{'batch_size': 32, 'hidden_dim': 70, 'last_n_outputs': 15, 'lr': 0.0017476283719958204, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.01382065887951543}"}}
exception: None

13:47:13 job_callback for (8, 0, 9) started
13:47:13 job_callback for (8, 0, 9) got condition
13:47:13 DISPATCHER: Trying to submit another job.
13:47:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:47:13 HBMASTER: Trying to run another job!
13:47:13 job_callback for (8, 0, 9) finished
13:47:13 start sampling a new configuration.
13:47:14 best_vector: [1, 0.8953537271173567, 0.4482386833140133, 0.09014403981230823, 0.10029518090792472, 0, 0.7365329860972551, 0.04063633075549322], 0.006051062432911629, 1913.6526466569744, 11.579631639827928
13:47:14 done sampling a new configuration.
13:47:14 HBMASTER: schedule new run for iteration 8
13:47:14 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
13:47:14 HBMASTER: submitting job (8, 0, 10) to dispatcher
13:47:14 DISPATCHER: trying to submit job (8, 0, 10)
13:47:14 DISPATCHER: trying to notify the job_runner thread.
13:47:14 HBMASTER: job (8, 0, 10) submitted to dispatcher
13:47:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:47:14 DISPATCHER: Trying to submit another job.
13:47:14 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:47:14 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:47:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:47:14 WORKER: start processing job (8, 0, 10)
13:47:14 WORKER: args: ()
13:47:14 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 92, 'last_n_outputs': 23, 'lr': 0.0015145655688238381, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.011294553976001197}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:47:44 DISPATCHER: Starting worker discovery
13:47:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:47:44 DISPATCHER: Finished worker discovery
Exception in thread Thread-546:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:48:44 DISPATCHER: Starting worker discovery
13:48:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:48:44 DISPATCHER: Finished worker discovery
13:48:49 WORKER: done with job (8, 0, 10), trying to register it.
13:48:49 WORKER: registered result for job (8, 0, 10) with dispatcher
13:48:49 DISPATCHER: job (8, 0, 10) finished
13:48:49 DISPATCHER: register_result: lock acquired
13:48:49 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
13:48:49 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 92, 'last_n_outputs': 23, 'lr': 0.0015145655688238381, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.011294553976001197}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.32447088210108294, 'info': {'music_genre': 0.32447088210108294, 'config': "{'batch_size': 32, 'hidden_dim': 92, 'last_n_outputs': 23, 'lr': 0.0015145655688238381, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.011294553976001197}"}}
exception: None

13:48:49 job_callback for (8, 0, 10) started
13:48:49 job_callback for (8, 0, 10) got condition
13:48:49 DISPATCHER: Trying to submit another job.
13:48:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:48:49 HBMASTER: Trying to run another job!
13:48:49 job_callback for (8, 0, 10) finished
13:48:49 start sampling a new configuration.
13:48:49 best_vector: [1, 0.9283996245909054, 0.9747063522285809, 0.10150907028734991, 0.09532426236409301, 0, 0.9047547007796817, 0.5616486006566204], 0.0018400850180819827, 0.07145559839710974, 0.00013148437606860458
13:48:49 done sampling a new configuration.
13:48:49 HBMASTER: schedule new run for iteration 8
13:48:49 HBMASTER: trying submitting job (8, 0, 11) to dispatcher
13:48:49 HBMASTER: submitting job (8, 0, 11) to dispatcher
13:48:49 DISPATCHER: trying to submit job (8, 0, 11)
13:48:49 DISPATCHER: trying to notify the job_runner thread.
13:48:49 HBMASTER: job (8, 0, 11) submitted to dispatcher
13:48:49 DISPATCHER: Trying to submit another job.
13:48:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:48:49 DISPATCHER: starting job (8, 0, 11) on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:48:49 DISPATCHER: job (8, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:48:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:48:49 WORKER: start processing job (8, 0, 11)
13:48:49 WORKER: args: ()
13:48:49 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 95, 'last_n_outputs': 49, 'lr': 0.0015959458088470558, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.053792493552003766}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:49:44 DISPATCHER: Starting worker discovery
13:49:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:49:44 DISPATCHER: Finished worker discovery
Exception in thread Thread-547:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:50:26 WORKER: done with job (8, 0, 11), trying to register it.
13:50:26 WORKER: registered result for job (8, 0, 11) with dispatcher
13:50:26 DISPATCHER: job (8, 0, 11) finished
13:50:26 DISPATCHER: register_result: lock acquired
13:50:26 DISPATCHER: job (8, 0, 11) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
13:50:26 job_id: (8, 0, 11)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 95, 'last_n_outputs': 49, 'lr': 0.0015959458088470558, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.053792493552003766}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3602447271077232, 'info': {'music_genre': 0.3602447271077232, 'config': "{'batch_size': 32, 'hidden_dim': 95, 'last_n_outputs': 49, 'lr': 0.0015959458088470558, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.053792493552003766}"}}
exception: None

13:50:26 job_callback for (8, 0, 11) started
13:50:26 DISPATCHER: Trying to submit another job.
13:50:26 job_callback for (8, 0, 11) got condition
13:50:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:50:26 HBMASTER: Trying to run another job!
13:50:26 job_callback for (8, 0, 11) finished
13:50:26 start sampling a new configuration.
13:50:26 done sampling a new configuration.
13:50:26 HBMASTER: schedule new run for iteration 8
13:50:26 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
13:50:26 HBMASTER: submitting job (8, 0, 12) to dispatcher
13:50:26 DISPATCHER: trying to submit job (8, 0, 12)
13:50:26 DISPATCHER: trying to notify the job_runner thread.
13:50:26 HBMASTER: job (8, 0, 12) submitted to dispatcher
13:50:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:50:26 DISPATCHER: Trying to submit another job.
13:50:26 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:50:26 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:50:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:50:26 WORKER: start processing job (8, 0, 12)
13:50:26 WORKER: args: ()
13:50:26 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 75, 'last_n_outputs': 48, 'lr': 0.0010122110968931244, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.14438758854862033}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:50:44 DISPATCHER: Starting worker discovery
13:50:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:50:44 DISPATCHER: Finished worker discovery
Exception in thread Thread-548:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:51:44 DISPATCHER: Starting worker discovery
13:51:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:51:44 DISPATCHER: Finished worker discovery
13:52:03 WORKER: done with job (8, 0, 12), trying to register it.
13:52:03 WORKER: registered result for job (8, 0, 12) with dispatcher
13:52:03 DISPATCHER: job (8, 0, 12) finished
13:52:03 DISPATCHER: register_result: lock acquired
13:52:03 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
13:52:03 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 75, 'last_n_outputs': 48, 'lr': 0.0010122110968931244, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.14438758854862033}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.05085447682348279, 'info': {'music_genre': 0.05085447682348279, 'config': "{'batch_size': 16, 'hidden_dim': 75, 'last_n_outputs': 48, 'lr': 0.0010122110968931244, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.14438758854862033}"}}
exception: None

13:52:03 job_callback for (8, 0, 12) started
13:52:03 job_callback for (8, 0, 12) got condition
13:52:03 DISPATCHER: Trying to submit another job.
13:52:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:52:03 HBMASTER: Trying to run another job!
13:52:03 job_callback for (8, 0, 12) finished
13:52:03 start sampling a new configuration.
13:52:03 best_vector: [1, 0.9885761746867316, 0.693536741080165, 0.07888193281244767, 0.1012154715302566, 0, 0.8279902314682048, 0.487683404003195], 0.009110508293253482, 849.5432416974288, 7.739770748961872
13:52:03 done sampling a new configuration.
13:52:03 HBMASTER: schedule new run for iteration 8
13:52:03 HBMASTER: trying submitting job (8, 0, 13) to dispatcher
13:52:03 HBMASTER: submitting job (8, 0, 13) to dispatcher
13:52:03 DISPATCHER: trying to submit job (8, 0, 13)
13:52:03 DISPATCHER: trying to notify the job_runner thread.
13:52:03 HBMASTER: job (8, 0, 13) submitted to dispatcher
13:52:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:52:03 DISPATCHER: Trying to submit another job.
13:52:03 DISPATCHER: starting job (8, 0, 13) on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:52:03 DISPATCHER: job (8, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:52:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:52:03 WORKER: start processing job (8, 0, 13)
13:52:03 WORKER: args: ()
13:52:03 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 100, 'last_n_outputs': 35, 'lr': 0.0014380164880618096, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.04310133648851004}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:52:44 DISPATCHER: Starting worker discovery
13:52:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:52:44 DISPATCHER: Finished worker discovery
Exception in thread Thread-549:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:53:40 WORKER: done with job (8, 0, 13), trying to register it.
13:53:40 WORKER: registered result for job (8, 0, 13) with dispatcher
13:53:40 DISPATCHER: job (8, 0, 13) finished
13:53:40 DISPATCHER: register_result: lock acquired
13:53:40 DISPATCHER: job (8, 0, 13) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
13:53:40 job_id: (8, 0, 13)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 100, 'last_n_outputs': 35, 'lr': 0.0014380164880618096, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.04310133648851004}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3947233632229559, 'info': {'music_genre': 0.3947233632229559, 'config': "{'batch_size': 32, 'hidden_dim': 100, 'last_n_outputs': 35, 'lr': 0.0014380164880618096, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.04310133648851004}"}}
exception: None

13:53:40 job_callback for (8, 0, 13) started
13:53:40 job_callback for (8, 0, 13) got condition
13:53:40 DISPATCHER: Trying to submit another job.
13:53:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:53:40 HBMASTER: Trying to run another job!
13:53:40 job_callback for (8, 0, 13) finished
13:53:40 start sampling a new configuration.
13:53:40 best_vector: [1, 0.8770856821801979, 0.9081266447078359, 0.045337533167652044, 0.10051380544271346, 0, 0.7853850597081424, 0.30515370658353586], 0.005459449053017784, 3770.3150746764263, 20.58384306402089
13:53:40 done sampling a new configuration.
13:53:40 HBMASTER: schedule new run for iteration 8
13:53:40 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
13:53:40 HBMASTER: submitting job (8, 0, 14) to dispatcher
13:53:40 DISPATCHER: trying to submit job (8, 0, 14)
13:53:40 DISPATCHER: trying to notify the job_runner thread.
13:53:40 HBMASTER: job (8, 0, 14) submitted to dispatcher
13:53:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:53:40 DISPATCHER: Trying to submit another job.
13:53:40 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:53:40 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:53:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:53:40 WORKER: start processing job (8, 0, 14)
13:53:40 WORKER: args: ()
13:53:40 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 91, 'last_n_outputs': 46, 'lr': 0.0012321825847647124, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.02494675865675132}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:53:44 DISPATCHER: Starting worker discovery
13:53:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:53:44 DISPATCHER: Finished worker discovery
Exception in thread Thread-550:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:54:44 DISPATCHER: Starting worker discovery
13:54:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:54:44 DISPATCHER: Finished worker discovery
13:55:17 WORKER: done with job (8, 0, 14), trying to register it.
13:55:17 WORKER: registered result for job (8, 0, 14) with dispatcher
13:55:17 DISPATCHER: job (8, 0, 14) finished
13:55:17 DISPATCHER: register_result: lock acquired
13:55:17 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
13:55:17 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 91, 'last_n_outputs': 46, 'lr': 0.0012321825847647124, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.02494675865675132}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3390960609399734, 'info': {'music_genre': 0.3390960609399734, 'config': "{'batch_size': 32, 'hidden_dim': 91, 'last_n_outputs': 46, 'lr': 0.0012321825847647124, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.02494675865675132}"}}
exception: None

13:55:17 job_callback for (8, 0, 14) started
13:55:17 job_callback for (8, 0, 14) got condition
13:55:17 DISPATCHER: Trying to submit another job.
13:55:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:55:17 HBMASTER: Trying to run another job!
13:55:17 job_callback for (8, 0, 14) finished
13:55:17 start sampling a new configuration.
13:55:17 done sampling a new configuration.
13:55:17 HBMASTER: schedule new run for iteration 8
13:55:17 HBMASTER: trying submitting job (8, 0, 15) to dispatcher
13:55:17 HBMASTER: submitting job (8, 0, 15) to dispatcher
13:55:17 DISPATCHER: trying to submit job (8, 0, 15)
13:55:17 DISPATCHER: trying to notify the job_runner thread.
13:55:17 HBMASTER: job (8, 0, 15) submitted to dispatcher
13:55:17 DISPATCHER: Trying to submit another job.
13:55:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:55:17 DISPATCHER: starting job (8, 0, 15) on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:55:17 DISPATCHER: job (8, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:55:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:55:17 WORKER: start processing job (8, 0, 15)
13:55:17 WORKER: args: ()
13:55:17 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 91, 'last_n_outputs': 38, 'lr': 0.001656937619666004, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.016505707676465767}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:55:44 DISPATCHER: Starting worker discovery
13:55:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:55:44 DISPATCHER: Finished worker discovery
Exception in thread Thread-551:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:56:44 DISPATCHER: Starting worker discovery
13:56:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:56:44 DISPATCHER: Finished worker discovery
13:56:54 WORKER: done with job (8, 0, 15), trying to register it.
13:56:54 WORKER: registered result for job (8, 0, 15) with dispatcher
13:56:54 DISPATCHER: job (8, 0, 15) finished
13:56:54 DISPATCHER: register_result: lock acquired
13:56:54 DISPATCHER: job (8, 0, 15) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
13:56:54 job_id: (8, 0, 15)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 91, 'last_n_outputs': 38, 'lr': 0.001656937619666004, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.016505707676465767}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 91, 'last_n_outputs': 38, 'lr': 0.001656937619666004, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.016505707676465767}"}}
exception: None

13:56:54 job_callback for (8, 0, 15) started
13:56:54 DISPATCHER: Trying to submit another job.
13:56:54 job_callback for (8, 0, 15) got condition
13:56:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:56:54 HBMASTER: Trying to run another job!
13:56:54 job_callback for (8, 0, 15) finished
13:56:54 start sampling a new configuration.
13:56:54 best_vector: [1, 0.971042650702417, 0.8725627126201156, 0.11637433163904808, 0.10377035779038114, 0, 0.7059039215778122, 0.277679451646189], 0.0029334995585823627, 5.6172152786427745, 0.016478098540360683
13:56:54 done sampling a new configuration.
13:56:54 HBMASTER: schedule new run for iteration 8
13:56:54 HBMASTER: trying submitting job (8, 0, 16) to dispatcher
13:56:54 HBMASTER: submitting job (8, 0, 16) to dispatcher
13:56:54 DISPATCHER: trying to submit job (8, 0, 16)
13:56:54 DISPATCHER: trying to notify the job_runner thread.
13:56:54 HBMASTER: job (8, 0, 16) submitted to dispatcher
13:56:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:56:54 DISPATCHER: Trying to submit another job.
13:56:54 DISPATCHER: starting job (8, 0, 16) on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:56:54 DISPATCHER: job (8, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:56:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:56:54 WORKER: start processing job (8, 0, 16)
13:56:54 WORKER: args: ()
13:56:54 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 98, 'last_n_outputs': 44, 'lr': 0.0017090259741689544, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.02297572877285024}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:57:44 DISPATCHER: Starting worker discovery
13:57:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:57:44 DISPATCHER: Finished worker discovery
Exception in thread Thread-552:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:58:30 WORKER: done with job (8, 0, 16), trying to register it.
13:58:30 WORKER: registered result for job (8, 0, 16) with dispatcher
13:58:30 DISPATCHER: job (8, 0, 16) finished
13:58:30 DISPATCHER: register_result: lock acquired
13:58:30 DISPATCHER: job (8, 0, 16) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
13:58:30 job_id: (8, 0, 16)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 98, 'last_n_outputs': 44, 'lr': 0.0017090259741689544, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.02297572877285024}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3923091306053577, 'info': {'music_genre': 0.3923091306053577, 'config': "{'batch_size': 32, 'hidden_dim': 98, 'last_n_outputs': 44, 'lr': 0.0017090259741689544, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.02297572877285024}"}}
exception: None

13:58:30 job_callback for (8, 0, 16) started
13:58:30 DISPATCHER: Trying to submit another job.
13:58:30 job_callback for (8, 0, 16) got condition
13:58:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:58:30 HBMASTER: Trying to run another job!
13:58:30 job_callback for (8, 0, 16) finished
13:58:30 start sampling a new configuration.
13:58:30 best_vector: [1, 0.6792545466219644, 0.255423652957611, 0.1378374253388369, 0.099821208287107, 0, 0.9041484919376943, 0.29109995399108274], 0.005373241670018701, 3158.063831492352, 16.969040175953623
13:58:30 done sampling a new configuration.
13:58:30 HBMASTER: schedule new run for iteration 8
13:58:30 HBMASTER: trying submitting job (8, 0, 17) to dispatcher
13:58:30 HBMASTER: submitting job (8, 0, 17) to dispatcher
13:58:30 DISPATCHER: trying to submit job (8, 0, 17)
13:58:30 DISPATCHER: trying to notify the job_runner thread.
13:58:30 HBMASTER: job (8, 0, 17) submitted to dispatcher
13:58:30 DISPATCHER: Trying to submit another job.
13:58:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:58:30 DISPATCHER: starting job (8, 0, 17) on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:58:30 DISPATCHER: job (8, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
13:58:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:58:30 WORKER: start processing job (8, 0, 17)
13:58:30 WORKER: args: ()
13:58:30 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 75, 'last_n_outputs': 13, 'lr': 0.0018865783692176689, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.023918270429166378}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:58:44 DISPATCHER: Starting worker discovery
13:58:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:58:44 DISPATCHER: Finished worker discovery
Exception in thread Thread-553:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:59:44 DISPATCHER: Starting worker discovery
13:59:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:59:44 DISPATCHER: Finished worker discovery
14:00:08 WORKER: done with job (8, 0, 17), trying to register it.
14:00:08 WORKER: registered result for job (8, 0, 17) with dispatcher
14:00:08 DISPATCHER: job (8, 0, 17) finished
14:00:08 DISPATCHER: register_result: lock acquired
14:00:08 DISPATCHER: job (8, 0, 17) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
14:00:08 job_id: (8, 0, 17)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 75, 'last_n_outputs': 13, 'lr': 0.0018865783692176689, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.023918270429166378}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3581905187089878, 'info': {'music_genre': 0.3581905187089878, 'config': "{'batch_size': 32, 'hidden_dim': 75, 'last_n_outputs': 13, 'lr': 0.0018865783692176689, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.023918270429166378}"}}
exception: None

14:00:08 job_callback for (8, 0, 17) started
14:00:08 DISPATCHER: Trying to submit another job.
14:00:08 job_callback for (8, 0, 17) got condition
14:00:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:00:08 HBMASTER: Trying to run another job!
14:00:08 job_callback for (8, 0, 17) finished
14:00:08 start sampling a new configuration.
14:00:08 best_vector: [1, 0.9166374544714155, 0.6815927449164187, 0.20029633220759546, 0.09672962606313672, 0, 0.7301391668121315, 0.2011570992280324], 0.007402214774568189, 26.397548954294038, 0.19540032688186237
14:00:08 done sampling a new configuration.
14:00:08 HBMASTER: schedule new run for iteration 8
14:00:08 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
14:00:08 HBMASTER: submitting job (8, 0, 18) to dispatcher
14:00:08 DISPATCHER: trying to submit job (8, 0, 18)
14:00:08 DISPATCHER: trying to notify the job_runner thread.
14:00:08 HBMASTER: job (8, 0, 18) submitted to dispatcher
14:00:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:00:08 DISPATCHER: Trying to submit another job.
14:00:08 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:00:08 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:00:08 WORKER: start processing job (8, 0, 18)
14:00:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:00:08 WORKER: args: ()
14:00:08 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 94, 'last_n_outputs': 35, 'lr': 0.0025153166430734067, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.018268858833270053}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:00:44 DISPATCHER: Starting worker discovery
14:00:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:00:44 DISPATCHER: Finished worker discovery
Exception in thread Thread-554:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:01:44 DISPATCHER: Starting worker discovery
14:01:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:01:44 DISPATCHER: Finished worker discovery
14:01:45 WORKER: done with job (8, 0, 18), trying to register it.
14:01:45 WORKER: registered result for job (8, 0, 18) with dispatcher
14:01:45 DISPATCHER: job (8, 0, 18) finished
14:01:45 DISPATCHER: register_result: lock acquired
14:01:45 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
14:01:45 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 94, 'last_n_outputs': 35, 'lr': 0.0025153166430734067, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.018268858833270053}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3679694970607312, 'info': {'music_genre': 0.3679694970607312, 'config': "{'batch_size': 32, 'hidden_dim': 94, 'last_n_outputs': 35, 'lr': 0.0025153166430734067, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.018268858833270053}"}}
exception: None

14:01:45 job_callback for (8, 0, 18) started
14:01:45 job_callback for (8, 0, 18) got condition
14:01:45 DISPATCHER: Trying to submit another job.
14:01:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:01:45 HBMASTER: Trying to run another job!
14:01:45 job_callback for (8, 0, 18) finished
14:01:45 start sampling a new configuration.
14:01:45 done sampling a new configuration.
14:01:45 HBMASTER: schedule new run for iteration 8
14:01:45 HBMASTER: trying submitting job (8, 0, 19) to dispatcher
14:01:45 HBMASTER: submitting job (8, 0, 19) to dispatcher
14:01:45 DISPATCHER: trying to submit job (8, 0, 19)
14:01:45 DISPATCHER: trying to notify the job_runner thread.
14:01:45 HBMASTER: job (8, 0, 19) submitted to dispatcher
14:01:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:01:45 DISPATCHER: Trying to submit another job.
14:01:45 DISPATCHER: starting job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:01:45 DISPATCHER: job (8, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:01:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:01:45 WORKER: start processing job (8, 0, 19)
14:01:45 WORKER: args: ()
14:01:45 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 79, 'last_n_outputs': 17, 'lr': 0.005359899265850115, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.08279417318760765}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:02:44 DISPATCHER: Starting worker discovery
14:02:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:02:44 DISPATCHER: Finished worker discovery
Exception in thread Thread-555:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:03:21 WORKER: done with job (8, 0, 19), trying to register it.
14:03:21 WORKER: registered result for job (8, 0, 19) with dispatcher
14:03:21 DISPATCHER: job (8, 0, 19) finished
14:03:21 DISPATCHER: register_result: lock acquired
14:03:21 DISPATCHER: job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
14:03:21 job_id: (8, 0, 19)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 79, 'last_n_outputs': 17, 'lr': 0.005359899265850115, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.08279417318760765}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 79, 'last_n_outputs': 17, 'lr': 0.005359899265850115, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.08279417318760765}"}}
exception: None

14:03:21 job_callback for (8, 0, 19) started
14:03:21 job_callback for (8, 0, 19) got condition
14:03:21 DISPATCHER: Trying to submit another job.
14:03:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:03:21 HBMASTER: Trying to run another job!
14:03:21 job_callback for (8, 0, 19) finished
14:03:21 start sampling a new configuration.
14:03:21 done sampling a new configuration.
14:03:21 HBMASTER: schedule new run for iteration 8
14:03:21 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
14:03:21 HBMASTER: submitting job (8, 0, 20) to dispatcher
14:03:21 DISPATCHER: trying to submit job (8, 0, 20)
14:03:21 DISPATCHER: trying to notify the job_runner thread.
14:03:21 HBMASTER: job (8, 0, 20) submitted to dispatcher
14:03:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:03:21 DISPATCHER: Trying to submit another job.
14:03:21 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:03:21 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:03:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:03:21 WORKER: start processing job (8, 0, 20)
14:03:21 WORKER: args: ()
14:03:21 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 27, 'last_n_outputs': 36, 'lr': 0.0035435583586500125, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.08940390752862741}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:03:44 DISPATCHER: Starting worker discovery
14:03:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:03:44 DISPATCHER: Finished worker discovery
Exception in thread Thread-556:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:04:44 DISPATCHER: Starting worker discovery
14:04:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:04:44 DISPATCHER: Finished worker discovery
14:04:56 WORKER: done with job (8, 0, 20), trying to register it.
14:04:56 WORKER: registered result for job (8, 0, 20) with dispatcher
14:04:56 DISPATCHER: job (8, 0, 20) finished
14:04:56 DISPATCHER: register_result: lock acquired
14:04:56 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
14:04:56 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 27, 'last_n_outputs': 36, 'lr': 0.0035435583586500125, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.08940390752862741}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 27, 'last_n_outputs': 36, 'lr': 0.0035435583586500125, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.08940390752862741}"}}
exception: None

14:04:56 job_callback for (8, 0, 20) started
14:04:56 DISPATCHER: Trying to submit another job.
14:04:56 job_callback for (8, 0, 20) got condition
14:04:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:04:56 HBMASTER: Trying to run another job!
14:04:56 job_callback for (8, 0, 20) finished
14:04:56 start sampling a new configuration.
14:04:56 best_vector: [1, 0.9747959666966945, 0.8756125230331457, 0.23414701059938597, 0.0991773864241434, 0, 0.8147453699567054, 0.3642135108343806], 0.001953568368390623, 7756.512201955721, 15.152876886776596
14:04:56 done sampling a new configuration.
14:04:56 HBMASTER: schedule new run for iteration 8
14:04:56 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
14:04:56 HBMASTER: submitting job (8, 0, 21) to dispatcher
14:04:56 DISPATCHER: trying to submit job (8, 0, 21)
14:04:56 DISPATCHER: trying to notify the job_runner thread.
14:04:56 HBMASTER: job (8, 0, 21) submitted to dispatcher
14:04:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:04:56 DISPATCHER: Trying to submit another job.
14:04:56 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:04:56 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:04:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:04:56 WORKER: start processing job (8, 0, 21)
14:04:56 WORKER: args: ()
14:04:56 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 98, 'last_n_outputs': 44, 'lr': 0.0029396391400878736, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.02977506391578754}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:05:44 DISPATCHER: Starting worker discovery
14:05:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:05:44 DISPATCHER: Finished worker discovery
Exception in thread Thread-557:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:06:33 WORKER: done with job (8, 0, 21), trying to register it.
14:06:33 WORKER: registered result for job (8, 0, 21) with dispatcher
14:06:33 DISPATCHER: job (8, 0, 21) finished
14:06:33 DISPATCHER: register_result: lock acquired
14:06:33 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
14:06:33 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 98, 'last_n_outputs': 44, 'lr': 0.0029396391400878736, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.02977506391578754}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.32557271708213886, 'info': {'music_genre': 0.32557271708213886, 'config': "{'batch_size': 32, 'hidden_dim': 98, 'last_n_outputs': 44, 'lr': 0.0029396391400878736, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.02977506391578754}"}}
exception: None

14:06:33 job_callback for (8, 0, 21) started
14:06:33 job_callback for (8, 0, 21) got condition
14:06:33 DISPATCHER: Trying to submit another job.
14:06:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:06:33 HBMASTER: Trying to run another job!
14:06:33 job_callback for (8, 0, 21) finished
14:06:33 start sampling a new configuration.
14:06:33 best_vector: [1, 0.9810260736501083, 0.587993725693347, 0.2217000341435248, 0.10462143004999366, 0, 0.8792914352411784, 0.27750665612497877], 0.004684245462586876, 0.09575145122941864, 0.0004485233009575128
14:06:33 done sampling a new configuration.
14:06:33 HBMASTER: schedule new run for iteration 8
14:06:33 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
14:06:33 HBMASTER: submitting job (8, 0, 22) to dispatcher
14:06:33 DISPATCHER: trying to submit job (8, 0, 22)
14:06:33 DISPATCHER: trying to notify the job_runner thread.
14:06:33 HBMASTER: job (8, 0, 22) submitted to dispatcher
14:06:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:06:33 DISPATCHER: Trying to submit another job.
14:06:33 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:06:33 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:06:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:06:33 WORKER: start processing job (8, 0, 22)
14:06:33 WORKER: args: ()
14:06:33 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 30, 'lr': 0.0027758760400040158, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.022963838484842534}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:06:44 DISPATCHER: Starting worker discovery
14:06:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:06:44 DISPATCHER: Finished worker discovery
Exception in thread Thread-558:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:07:44 DISPATCHER: Starting worker discovery
14:07:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:07:44 DISPATCHER: Finished worker discovery
14:08:08 WORKER: done with job (8, 0, 22), trying to register it.
14:08:08 WORKER: registered result for job (8, 0, 22) with dispatcher
14:08:08 DISPATCHER: job (8, 0, 22) finished
14:08:08 DISPATCHER: register_result: lock acquired
14:08:08 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
14:08:08 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 30, 'lr': 0.0027758760400040158, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.022963838484842534}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.36743524080482226, 'info': {'music_genre': 0.36743524080482226, 'config': "{'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 30, 'lr': 0.0027758760400040158, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.022963838484842534}"}}
exception: None

14:08:08 job_callback for (8, 0, 22) started
14:08:08 job_callback for (8, 0, 22) got condition
14:08:08 DISPATCHER: Trying to submit another job.
14:08:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:08:08 HBMASTER: Trying to run another job!
14:08:08 job_callback for (8, 0, 22) finished
14:08:08 start sampling a new configuration.
14:08:08 best_vector: [1, 0.9792660640772954, 0.3427904446885188, 0.04486942200124497, 0.09522004301148045, 0, 0.9556026601917466, 0.1913527497252843], 0.0026773809760218927, 0.020210099567727232, 5.411013610614117e-05
14:08:08 done sampling a new configuration.
14:08:08 HBMASTER: schedule new run for iteration 8
14:08:08 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
14:08:08 HBMASTER: submitting job (8, 0, 23) to dispatcher
14:08:08 DISPATCHER: trying to submit job (8, 0, 23)
14:08:08 DISPATCHER: trying to notify the job_runner thread.
14:08:08 HBMASTER: job (8, 0, 23) submitted to dispatcher
14:08:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:08:08 DISPATCHER: Trying to submit another job.
14:08:08 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:08:08 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:08:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:08:08 WORKER: start processing job (8, 0, 23)
14:08:08 WORKER: args: ()
14:08:08 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 18, 'lr': 0.0012295291908755318, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.017740083805695517}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:08:44 DISPATCHER: Starting worker discovery
14:08:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:08:44 DISPATCHER: Finished worker discovery
Exception in thread Thread-559:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:09:43 WORKER: done with job (8, 0, 23), trying to register it.
14:09:43 WORKER: registered result for job (8, 0, 23) with dispatcher
14:09:43 DISPATCHER: job (8, 0, 23) finished
14:09:43 DISPATCHER: register_result: lock acquired
14:09:43 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
14:09:43 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 18, 'lr': 0.0012295291908755318, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.017740083805695517}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.37301277362687796, 'info': {'music_genre': 0.37301277362687796, 'config': "{'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 18, 'lr': 0.0012295291908755318, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.017740083805695517}"}}
exception: None

14:09:43 job_callback for (8, 0, 23) started
14:09:43 DISPATCHER: Trying to submit another job.
14:09:43 job_callback for (8, 0, 23) got condition
14:09:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:09:43 HBMASTER: Trying to run another job!
14:09:43 job_callback for (8, 0, 23) finished
14:09:43 start sampling a new configuration.
14:09:43 done sampling a new configuration.
14:09:43 HBMASTER: schedule new run for iteration 8
14:09:43 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
14:09:43 HBMASTER: submitting job (8, 0, 24) to dispatcher
14:09:43 DISPATCHER: trying to submit job (8, 0, 24)
14:09:43 DISPATCHER: trying to notify the job_runner thread.
14:09:43 HBMASTER: job (8, 0, 24) submitted to dispatcher
14:09:43 DISPATCHER: Trying to submit another job.
14:09:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:09:43 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:09:43 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:09:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:09:43 WORKER: start processing job (8, 0, 24)
14:09:43 WORKER: args: ()
14:09:43 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 86, 'last_n_outputs': 38, 'lr': 0.002269245437563601, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.017893327336240127}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:09:44 DISPATCHER: Starting worker discovery
14:09:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:09:44 DISPATCHER: Finished worker discovery
14:10:44 DISPATCHER: Starting worker discovery
14:10:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:10:44 DISPATCHER: Finished worker discovery
Exception in thread Thread-560:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:11:19 WORKER: done with job (8, 0, 24), trying to register it.
14:11:19 WORKER: registered result for job (8, 0, 24) with dispatcher
14:11:19 DISPATCHER: job (8, 0, 24) finished
14:11:19 DISPATCHER: register_result: lock acquired
14:11:19 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
14:11:19 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 86, 'last_n_outputs': 38, 'lr': 0.002269245437563601, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.017893327336240127}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 86, 'last_n_outputs': 38, 'lr': 0.002269245437563601, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.017893327336240127}"}}
exception: None

14:11:19 job_callback for (8, 0, 24) started
14:11:19 DISPATCHER: Trying to submit another job.
14:11:19 job_callback for (8, 0, 24) got condition
14:11:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:11:19 HBMASTER: Trying to run another job!
14:11:19 job_callback for (8, 0, 24) finished
14:11:19 start sampling a new configuration.
14:11:19 best_vector: [1, 0.8166020376174267, 0.9341939266488695, 0.17779342833971754, 0.09923747360623408, 0, 0.6316732992349607, 0.3758369478419251], 0.005264020113928506, 3647.017755464299, 19.197974820618462
14:11:19 done sampling a new configuration.
14:11:19 HBMASTER: schedule new run for iteration 8
14:11:19 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
14:11:19 HBMASTER: submitting job (8, 0, 25) to dispatcher
14:11:19 DISPATCHER: trying to submit job (8, 0, 25)
14:11:19 DISPATCHER: trying to notify the job_runner thread.
14:11:19 HBMASTER: job (8, 0, 25) submitted to dispatcher
14:11:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:11:19 DISPATCHER: Trying to submit another job.
14:11:19 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:11:19 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:11:19 WORKER: start processing job (8, 0, 25)
14:11:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:11:19 WORKER: args: ()
14:11:19 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 86, 'last_n_outputs': 47, 'lr': 0.002267706561532713, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.030830114852448295}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:11:44 DISPATCHER: Starting worker discovery
14:11:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:11:44 DISPATCHER: Finished worker discovery
Exception in thread Thread-561:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:12:44 DISPATCHER: Starting worker discovery
14:12:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:12:44 DISPATCHER: Finished worker discovery
14:12:55 WORKER: done with job (8, 0, 25), trying to register it.
14:12:55 WORKER: registered result for job (8, 0, 25) with dispatcher
14:12:55 DISPATCHER: job (8, 0, 25) finished
14:12:55 DISPATCHER: register_result: lock acquired
14:12:55 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
14:12:55 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 86, 'last_n_outputs': 47, 'lr': 0.002267706561532713, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.030830114852448295}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.32482573098081974, 'info': {'music_genre': 0.32482573098081974, 'config': "{'batch_size': 32, 'hidden_dim': 86, 'last_n_outputs': 47, 'lr': 0.002267706561532713, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.030830114852448295}"}}
exception: None

14:12:55 job_callback for (8, 0, 25) started
14:12:55 job_callback for (8, 0, 25) got condition
14:12:55 DISPATCHER: Trying to submit another job.
14:12:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:12:55 HBMASTER: Trying to run another job!
14:12:55 job_callback for (8, 0, 25) finished
14:12:55 start sampling a new configuration.
14:12:55 done sampling a new configuration.
14:12:55 HBMASTER: schedule new run for iteration 8
14:12:55 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
14:12:55 HBMASTER: submitting job (8, 0, 26) to dispatcher
14:12:55 DISPATCHER: trying to submit job (8, 0, 26)
14:12:55 DISPATCHER: trying to notify the job_runner thread.
14:12:55 HBMASTER: job (8, 0, 26) submitted to dispatcher
14:12:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:12:55 DISPATCHER: Trying to submit another job.
14:12:55 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:12:55 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:12:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:12:55 WORKER: start processing job (8, 0, 26)
14:12:55 WORKER: args: ()
14:12:55 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 90, 'last_n_outputs': 24, 'lr': 0.0010957577383558115, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.07647391160272826}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:13:44 DISPATCHER: Starting worker discovery
14:13:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:13:44 DISPATCHER: Finished worker discovery
Exception in thread Thread-562:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:14:33 WORKER: done with job (8, 0, 26), trying to register it.
14:14:33 WORKER: registered result for job (8, 0, 26) with dispatcher
14:14:33 DISPATCHER: job (8, 0, 26) finished
14:14:33 DISPATCHER: register_result: lock acquired
14:14:33 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
14:14:33 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 90, 'last_n_outputs': 24, 'lr': 0.0010957577383558115, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.07647391160272826}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 90, 'last_n_outputs': 24, 'lr': 0.0010957577383558115, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.07647391160272826}"}}
exception: None

14:14:33 job_callback for (8, 0, 26) started
14:14:33 DISPATCHER: Trying to submit another job.
14:14:33 job_callback for (8, 0, 26) got condition
14:14:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:14:33 HBMASTER: Trying to run another job!
14:14:33 job_callback for (8, 0, 26) finished
14:14:33 ITERATION: Advancing config (8, 0, 1) to next budget 133.333333
14:14:33 ITERATION: Advancing config (8, 0, 4) to next budget 133.333333
14:14:33 ITERATION: Advancing config (8, 0, 8) to next budget 133.333333
14:14:33 ITERATION: Advancing config (8, 0, 9) to next budget 133.333333
14:14:33 ITERATION: Advancing config (8, 0, 13) to next budget 133.333333
14:14:33 ITERATION: Advancing config (8, 0, 16) to next budget 133.333333
14:14:33 ITERATION: Advancing config (8, 0, 18) to next budget 133.333333
14:14:33 ITERATION: Advancing config (8, 0, 22) to next budget 133.333333
14:14:33 ITERATION: Advancing config (8, 0, 23) to next budget 133.333333
14:14:33 HBMASTER: schedule new run for iteration 8
14:14:33 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
14:14:33 HBMASTER: submitting job (8, 0, 1) to dispatcher
14:14:33 DISPATCHER: trying to submit job (8, 0, 1)
14:14:33 DISPATCHER: trying to notify the job_runner thread.
14:14:33 HBMASTER: job (8, 0, 1) submitted to dispatcher
14:14:33 DISPATCHER: Trying to submit another job.
14:14:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:14:33 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:14:33 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:14:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:14:33 WORKER: start processing job (8, 0, 1)
14:14:33 WORKER: args: ()
14:14:33 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 90, 'last_n_outputs': 41, 'lr': 0.0016776791096850625, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.05237413889516617}, 'budget': 133.33333333333331, 'working_directory': '.'}
14:14:44 DISPATCHER: Starting worker discovery
14:14:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:14:44 DISPATCHER: Finished worker discovery
Exception in thread Thread-563:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:15:44 DISPATCHER: Starting worker discovery
14:15:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:15:44 DISPATCHER: Finished worker discovery
14:16:44 DISPATCHER: Starting worker discovery
14:16:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:16:44 DISPATCHER: Finished worker discovery
14:17:43 WORKER: done with job (8, 0, 1), trying to register it.
14:17:43 WORKER: registered result for job (8, 0, 1) with dispatcher
14:17:43 DISPATCHER: job (8, 0, 1) finished
14:17:43 DISPATCHER: register_result: lock acquired
14:17:43 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
14:17:43 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 90, 'last_n_outputs': 41, 'lr': 0.0016776791096850625, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.05237413889516617}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.35186235259191967, 'info': {'music_genre': 0.35186235259191967, 'config': "{'batch_size': 32, 'hidden_dim': 90, 'last_n_outputs': 41, 'lr': 0.0016776791096850625, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.05237413889516617}"}}
exception: None

14:17:43 job_callback for (8, 0, 1) started
14:17:43 job_callback for (8, 0, 1) got condition
14:17:43 DISPATCHER: Trying to submit another job.
14:17:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:17:43 HBMASTER: Trying to run another job!
14:17:43 job_callback for (8, 0, 1) finished
14:17:43 HBMASTER: schedule new run for iteration 8
14:17:43 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
14:17:43 HBMASTER: submitting job (8, 0, 4) to dispatcher
14:17:43 DISPATCHER: trying to submit job (8, 0, 4)
14:17:43 DISPATCHER: trying to notify the job_runner thread.
14:17:43 HBMASTER: job (8, 0, 4) submitted to dispatcher
14:17:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:17:43 DISPATCHER: Trying to submit another job.
14:17:43 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:17:43 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:17:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:17:43 WORKER: start processing job (8, 0, 4)
14:17:43 WORKER: args: ()
14:17:43 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 96, 'last_n_outputs': 34, 'lr': 0.002766504375704521, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.017329406398386704}, 'budget': 133.33333333333331, 'working_directory': '.'}
14:17:44 DISPATCHER: Starting worker discovery
14:17:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:17:44 DISPATCHER: Finished worker discovery
14:18:44 DISPATCHER: Starting worker discovery
14:18:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:18:44 DISPATCHER: Finished worker discovery
Exception in thread Thread-564:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:19:44 DISPATCHER: Starting worker discovery
14:19:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:19:44 DISPATCHER: Finished worker discovery
14:20:44 DISPATCHER: Starting worker discovery
14:20:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:20:44 DISPATCHER: Finished worker discovery
14:20:51 WORKER: done with job (8, 0, 4), trying to register it.
14:20:51 WORKER: registered result for job (8, 0, 4) with dispatcher
14:20:51 DISPATCHER: job (8, 0, 4) finished
14:20:51 DISPATCHER: register_result: lock acquired
14:20:51 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
14:20:51 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 96, 'last_n_outputs': 34, 'lr': 0.002766504375704521, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.017329406398386704}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.36694602096081186, 'info': {'music_genre': 0.36694602096081186, 'config': "{'batch_size': 32, 'hidden_dim': 96, 'last_n_outputs': 34, 'lr': 0.002766504375704521, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.017329406398386704}"}}
exception: None

14:20:51 job_callback for (8, 0, 4) started
14:20:51 DISPATCHER: Trying to submit another job.
14:20:51 job_callback for (8, 0, 4) got condition
14:20:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:20:51 HBMASTER: Trying to run another job!
14:20:51 job_callback for (8, 0, 4) finished
14:20:51 HBMASTER: schedule new run for iteration 8
14:20:51 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
14:20:51 HBMASTER: submitting job (8, 0, 8) to dispatcher
14:20:51 DISPATCHER: trying to submit job (8, 0, 8)
14:20:51 DISPATCHER: trying to notify the job_runner thread.
14:20:51 HBMASTER: job (8, 0, 8) submitted to dispatcher
14:20:51 DISPATCHER: Trying to submit another job.
14:20:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:20:51 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:20:51 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:20:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:20:51 WORKER: start processing job (8, 0, 8)
14:20:51 WORKER: args: ()
14:20:51 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 81, 'last_n_outputs': 47, 'lr': 0.0017796188463350825, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.03930992827968554}, 'budget': 133.33333333333331, 'working_directory': '.'}
14:21:44 DISPATCHER: Starting worker discovery
14:21:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:21:44 DISPATCHER: Finished worker discovery
Exception in thread Thread-565:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:22:44 DISPATCHER: Starting worker discovery
14:22:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:22:44 DISPATCHER: Finished worker discovery
14:23:44 DISPATCHER: Starting worker discovery
14:23:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:23:44 DISPATCHER: Finished worker discovery
14:23:58 WORKER: done with job (8, 0, 8), trying to register it.
14:23:58 WORKER: registered result for job (8, 0, 8) with dispatcher
14:23:58 DISPATCHER: job (8, 0, 8) finished
14:23:58 DISPATCHER: register_result: lock acquired
14:23:58 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
14:23:58 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 81, 'last_n_outputs': 47, 'lr': 0.0017796188463350825, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.03930992827968554}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2669869629630646, 'info': {'music_genre': 0.2669869629630646, 'config': "{'batch_size': 32, 'hidden_dim': 81, 'last_n_outputs': 47, 'lr': 0.0017796188463350825, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.03930992827968554}"}}
exception: None

14:23:58 job_callback for (8, 0, 8) started
14:23:58 DISPATCHER: Trying to submit another job.
14:23:58 job_callback for (8, 0, 8) got condition
14:23:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:23:58 HBMASTER: Trying to run another job!
14:23:58 job_callback for (8, 0, 8) finished
14:23:58 HBMASTER: schedule new run for iteration 8
14:23:58 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
14:23:58 HBMASTER: submitting job (8, 0, 9) to dispatcher
14:23:58 DISPATCHER: trying to submit job (8, 0, 9)
14:23:58 DISPATCHER: trying to notify the job_runner thread.
14:23:58 HBMASTER: job (8, 0, 9) submitted to dispatcher
14:23:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:23:58 DISPATCHER: Trying to submit another job.
14:23:58 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:23:58 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:23:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:23:58 WORKER: start processing job (8, 0, 9)
14:23:58 WORKER: args: ()
14:23:58 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 70, 'last_n_outputs': 15, 'lr': 0.0017476283719958204, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.01382065887951543}, 'budget': 133.33333333333331, 'working_directory': '.'}
14:24:44 DISPATCHER: Starting worker discovery
14:24:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:24:44 DISPATCHER: Finished worker discovery
Exception in thread Thread-566:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:25:44 DISPATCHER: Starting worker discovery
14:25:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:25:44 DISPATCHER: Finished worker discovery
14:26:44 DISPATCHER: Starting worker discovery
14:26:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:26:44 DISPATCHER: Finished worker discovery
14:27:07 WORKER: done with job (8, 0, 9), trying to register it.
14:27:07 WORKER: registered result for job (8, 0, 9) with dispatcher
14:27:07 DISPATCHER: job (8, 0, 9) finished
14:27:07 DISPATCHER: register_result: lock acquired
14:27:07 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
14:27:07 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 70, 'last_n_outputs': 15, 'lr': 0.0017476283719958204, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.01382065887951543}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.38355753594208675, 'info': {'music_genre': 0.38355753594208675, 'config': "{'batch_size': 32, 'hidden_dim': 70, 'last_n_outputs': 15, 'lr': 0.0017476283719958204, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.01382065887951543}"}}
exception: None

14:27:07 job_callback for (8, 0, 9) started
14:27:07 job_callback for (8, 0, 9) got condition
14:27:07 DISPATCHER: Trying to submit another job.
14:27:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:27:07 HBMASTER: Trying to run another job!
14:27:07 job_callback for (8, 0, 9) finished
14:27:07 HBMASTER: schedule new run for iteration 8
14:27:07 HBMASTER: trying submitting job (8, 0, 13) to dispatcher
14:27:07 HBMASTER: submitting job (8, 0, 13) to dispatcher
14:27:07 DISPATCHER: trying to submit job (8, 0, 13)
14:27:07 DISPATCHER: trying to notify the job_runner thread.
14:27:07 HBMASTER: job (8, 0, 13) submitted to dispatcher
14:27:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:27:07 DISPATCHER: Trying to submit another job.
14:27:07 DISPATCHER: starting job (8, 0, 13) on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:27:07 DISPATCHER: job (8, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:27:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:27:07 WORKER: start processing job (8, 0, 13)
14:27:07 WORKER: args: ()
14:27:07 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 100, 'last_n_outputs': 35, 'lr': 0.0014380164880618096, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.04310133648851004}, 'budget': 133.33333333333331, 'working_directory': '.'}
14:27:44 DISPATCHER: Starting worker discovery
14:27:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:27:44 DISPATCHER: Finished worker discovery
Exception in thread Thread-567:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:28:44 DISPATCHER: Starting worker discovery
14:28:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:28:44 DISPATCHER: Finished worker discovery
14:29:44 DISPATCHER: Starting worker discovery
14:29:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:29:44 DISPATCHER: Finished worker discovery
14:30:14 WORKER: done with job (8, 0, 13), trying to register it.
14:30:14 WORKER: registered result for job (8, 0, 13) with dispatcher
14:30:14 DISPATCHER: job (8, 0, 13) finished
14:30:14 DISPATCHER: register_result: lock acquired
14:30:14 DISPATCHER: job (8, 0, 13) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
14:30:14 job_id: (8, 0, 13)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 100, 'last_n_outputs': 35, 'lr': 0.0014380164880618096, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.04310133648851004}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3680424548834629, 'info': {'music_genre': 0.3680424548834629, 'config': "{'batch_size': 32, 'hidden_dim': 100, 'last_n_outputs': 35, 'lr': 0.0014380164880618096, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.04310133648851004}"}}
exception: None

14:30:14 job_callback for (8, 0, 13) started
14:30:14 job_callback for (8, 0, 13) got condition
14:30:14 DISPATCHER: Trying to submit another job.
14:30:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:30:14 HBMASTER: Trying to run another job!
14:30:14 job_callback for (8, 0, 13) finished
14:30:14 HBMASTER: schedule new run for iteration 8
14:30:14 HBMASTER: trying submitting job (8, 0, 16) to dispatcher
14:30:14 HBMASTER: submitting job (8, 0, 16) to dispatcher
14:30:14 DISPATCHER: trying to submit job (8, 0, 16)
14:30:14 DISPATCHER: trying to notify the job_runner thread.
14:30:14 HBMASTER: job (8, 0, 16) submitted to dispatcher
14:30:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:30:14 DISPATCHER: Trying to submit another job.
14:30:14 DISPATCHER: starting job (8, 0, 16) on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:30:14 DISPATCHER: job (8, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:30:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:30:14 WORKER: start processing job (8, 0, 16)
14:30:14 WORKER: args: ()
14:30:14 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 98, 'last_n_outputs': 44, 'lr': 0.0017090259741689544, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.02297572877285024}, 'budget': 133.33333333333331, 'working_directory': '.'}
14:30:44 DISPATCHER: Starting worker discovery
14:30:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:30:44 DISPATCHER: Finished worker discovery
Exception in thread Thread-568:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:31:44 DISPATCHER: Starting worker discovery
14:31:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:31:44 DISPATCHER: Finished worker discovery
14:32:44 DISPATCHER: Starting worker discovery
14:32:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:32:44 DISPATCHER: Finished worker discovery
14:33:21 WORKER: done with job (8, 0, 16), trying to register it.
14:33:21 WORKER: registered result for job (8, 0, 16) with dispatcher
14:33:21 DISPATCHER: job (8, 0, 16) finished
14:33:21 DISPATCHER: register_result: lock acquired
14:33:21 DISPATCHER: job (8, 0, 16) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
14:33:21 job_id: (8, 0, 16)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 98, 'last_n_outputs': 44, 'lr': 0.0017090259741689544, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.02297572877285024}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.37637888809764763, 'info': {'music_genre': 0.37637888809764763, 'config': "{'batch_size': 32, 'hidden_dim': 98, 'last_n_outputs': 44, 'lr': 0.0017090259741689544, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.02297572877285024}"}}
exception: None

14:33:21 job_callback for (8, 0, 16) started
14:33:21 DISPATCHER: Trying to submit another job.
14:33:21 job_callback for (8, 0, 16) got condition
14:33:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:33:21 HBMASTER: Trying to run another job!
14:33:21 job_callback for (8, 0, 16) finished
14:33:21 HBMASTER: schedule new run for iteration 8
14:33:21 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
14:33:21 HBMASTER: submitting job (8, 0, 18) to dispatcher
14:33:21 DISPATCHER: trying to submit job (8, 0, 18)
14:33:21 DISPATCHER: trying to notify the job_runner thread.
14:33:21 HBMASTER: job (8, 0, 18) submitted to dispatcher
14:33:21 DISPATCHER: Trying to submit another job.
14:33:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:33:21 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:33:21 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:33:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:33:21 WORKER: start processing job (8, 0, 18)
14:33:21 WORKER: args: ()
14:33:21 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 94, 'last_n_outputs': 35, 'lr': 0.0025153166430734067, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.018268858833270053}, 'budget': 133.33333333333331, 'working_directory': '.'}
14:33:44 DISPATCHER: Starting worker discovery
14:33:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:33:44 DISPATCHER: Finished worker discovery
Exception in thread Thread-569:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:34:44 DISPATCHER: Starting worker discovery
14:34:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:34:44 DISPATCHER: Finished worker discovery
14:35:44 DISPATCHER: Starting worker discovery
14:35:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:35:44 DISPATCHER: Finished worker discovery
14:36:28 WORKER: done with job (8, 0, 18), trying to register it.
14:36:28 WORKER: registered result for job (8, 0, 18) with dispatcher
14:36:28 DISPATCHER: job (8, 0, 18) finished
14:36:28 DISPATCHER: register_result: lock acquired
14:36:28 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
14:36:28 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 94, 'last_n_outputs': 35, 'lr': 0.0025153166430734067, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.018268858833270053}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.33635051822531925, 'info': {'music_genre': 0.33635051822531925, 'config': "{'batch_size': 32, 'hidden_dim': 94, 'last_n_outputs': 35, 'lr': 0.0025153166430734067, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.018268858833270053}"}}
exception: None

14:36:28 job_callback for (8, 0, 18) started
14:36:28 DISPATCHER: Trying to submit another job.
14:36:28 job_callback for (8, 0, 18) got condition
14:36:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:36:28 HBMASTER: Trying to run another job!
14:36:28 job_callback for (8, 0, 18) finished
14:36:28 HBMASTER: schedule new run for iteration 8
14:36:28 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
14:36:28 HBMASTER: submitting job (8, 0, 22) to dispatcher
14:36:28 DISPATCHER: trying to submit job (8, 0, 22)
14:36:28 DISPATCHER: trying to notify the job_runner thread.
14:36:28 HBMASTER: job (8, 0, 22) submitted to dispatcher
14:36:28 DISPATCHER: Trying to submit another job.
14:36:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:36:28 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:36:28 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:36:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:36:28 WORKER: start processing job (8, 0, 22)
14:36:28 WORKER: args: ()
14:36:28 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 30, 'lr': 0.0027758760400040158, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.022963838484842534}, 'budget': 133.33333333333331, 'working_directory': '.'}
14:36:44 DISPATCHER: Starting worker discovery
14:36:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:36:44 DISPATCHER: Finished worker discovery
Exception in thread Thread-570:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:37:44 DISPATCHER: Starting worker discovery
14:37:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:37:44 DISPATCHER: Finished worker discovery
14:38:44 DISPATCHER: Starting worker discovery
14:38:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:38:44 DISPATCHER: Finished worker discovery
14:39:36 WORKER: done with job (8, 0, 22), trying to register it.
14:39:36 WORKER: registered result for job (8, 0, 22) with dispatcher
14:39:36 DISPATCHER: job (8, 0, 22) finished
14:39:36 DISPATCHER: register_result: lock acquired
14:39:36 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
14:39:36 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 30, 'lr': 0.0027758760400040158, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.022963838484842534}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.38758209636375873, 'info': {'music_genre': 0.38758209636375873, 'config': "{'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 30, 'lr': 0.0027758760400040158, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.022963838484842534}"}}
exception: None

14:39:36 job_callback for (8, 0, 22) started
14:39:36 DISPATCHER: Trying to submit another job.
14:39:36 job_callback for (8, 0, 22) got condition
14:39:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:39:36 HBMASTER: Trying to run another job!
14:39:36 job_callback for (8, 0, 22) finished
14:39:36 HBMASTER: schedule new run for iteration 8
14:39:36 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
14:39:36 HBMASTER: submitting job (8, 0, 23) to dispatcher
14:39:36 DISPATCHER: trying to submit job (8, 0, 23)
14:39:36 DISPATCHER: trying to notify the job_runner thread.
14:39:36 HBMASTER: job (8, 0, 23) submitted to dispatcher
14:39:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:39:36 DISPATCHER: Trying to submit another job.
14:39:36 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:39:36 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:39:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:39:36 WORKER: start processing job (8, 0, 23)
14:39:36 WORKER: args: ()
14:39:36 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 18, 'lr': 0.0012295291908755318, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.017740083805695517}, 'budget': 133.33333333333331, 'working_directory': '.'}
14:39:44 DISPATCHER: Starting worker discovery
14:39:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:39:44 DISPATCHER: Finished worker discovery
Exception in thread Thread-571:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:40:44 DISPATCHER: Starting worker discovery
14:40:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:40:44 DISPATCHER: Finished worker discovery
14:41:44 DISPATCHER: Starting worker discovery
14:41:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:41:44 DISPATCHER: Finished worker discovery
14:42:43 WORKER: done with job (8, 0, 23), trying to register it.
14:42:43 WORKER: registered result for job (8, 0, 23) with dispatcher
14:42:43 DISPATCHER: job (8, 0, 23) finished
14:42:43 DISPATCHER: register_result: lock acquired
14:42:43 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
14:42:43 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 18, 'lr': 0.0012295291908755318, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.017740083805695517}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.38978101268652166, 'info': {'music_genre': 0.38978101268652166, 'config': "{'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 18, 'lr': 0.0012295291908755318, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.017740083805695517}"}}
exception: None

14:42:43 job_callback for (8, 0, 23) started
14:42:43 job_callback for (8, 0, 23) got condition
14:42:43 DISPATCHER: Trying to submit another job.
14:42:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:42:43 HBMASTER: Trying to run another job!
14:42:43 job_callback for (8, 0, 23) finished
14:42:43 ITERATION: Advancing config (8, 0, 9) to next budget 400.000000
14:42:43 ITERATION: Advancing config (8, 0, 22) to next budget 400.000000
14:42:43 ITERATION: Advancing config (8, 0, 23) to next budget 400.000000
14:42:43 HBMASTER: schedule new run for iteration 8
14:42:43 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
14:42:43 HBMASTER: submitting job (8, 0, 9) to dispatcher
14:42:43 DISPATCHER: trying to submit job (8, 0, 9)
14:42:43 DISPATCHER: trying to notify the job_runner thread.
14:42:43 HBMASTER: job (8, 0, 9) submitted to dispatcher
14:42:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:42:43 DISPATCHER: Trying to submit another job.
14:42:43 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:42:43 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:42:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:42:43 WORKER: start processing job (8, 0, 9)
14:42:43 WORKER: args: ()
14:42:43 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 70, 'last_n_outputs': 15, 'lr': 0.0017476283719958204, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.01382065887951543}, 'budget': 400.0, 'working_directory': '.'}
14:42:44 DISPATCHER: Starting worker discovery
14:42:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:42:44 DISPATCHER: Finished worker discovery
Exception in thread Thread-572:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:43:44 DISPATCHER: Starting worker discovery
14:43:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:43:44 DISPATCHER: Finished worker discovery
14:44:44 DISPATCHER: Starting worker discovery
14:44:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:44:44 DISPATCHER: Finished worker discovery
14:45:44 DISPATCHER: Starting worker discovery
14:45:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:45:44 DISPATCHER: Finished worker discovery
14:46:44 DISPATCHER: Starting worker discovery
14:46:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:46:44 DISPATCHER: Finished worker discovery
14:47:44 DISPATCHER: Starting worker discovery
14:47:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:47:44 DISPATCHER: Finished worker discovery
14:48:44 DISPATCHER: Starting worker discovery
14:48:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:48:44 DISPATCHER: Finished worker discovery
14:49:44 DISPATCHER: Starting worker discovery
14:49:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:49:44 DISPATCHER: Finished worker discovery
14:50:17 WORKER: done with job (8, 0, 9), trying to register it.
14:50:17 WORKER: registered result for job (8, 0, 9) with dispatcher
14:50:17 DISPATCHER: job (8, 0, 9) finished
14:50:17 DISPATCHER: register_result: lock acquired
14:50:17 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
14:50:17 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 70, 'last_n_outputs': 15, 'lr': 0.0017476283719958204, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.01382065887951543}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.37595096249133486, 'info': {'music_genre': 0.37595096249133486, 'config': "{'batch_size': 32, 'hidden_dim': 70, 'last_n_outputs': 15, 'lr': 0.0017476283719958204, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.01382065887951543}"}}
exception: None

14:50:17 job_callback for (8, 0, 9) started
14:50:17 DISPATCHER: Trying to submit another job.
14:50:17 job_callback for (8, 0, 9) got condition
14:50:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:50:17 done building a new model for budget 400.000000 based on 9/21 split
Best loss for this budget:-0.402368





14:50:17 HBMASTER: Trying to run another job!
14:50:17 job_callback for (8, 0, 9) finished
14:50:17 HBMASTER: schedule new run for iteration 8
14:50:17 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
14:50:17 HBMASTER: submitting job (8, 0, 22) to dispatcher
14:50:17 DISPATCHER: trying to submit job (8, 0, 22)
14:50:17 DISPATCHER: trying to notify the job_runner thread.
14:50:17 HBMASTER: job (8, 0, 22) submitted to dispatcher
14:50:17 DISPATCHER: Trying to submit another job.
14:50:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:50:17 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:50:17 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:50:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:50:17 WORKER: start processing job (8, 0, 22)
14:50:17 WORKER: args: ()
14:50:17 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 30, 'lr': 0.0027758760400040158, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.022963838484842534}, 'budget': 400.0, 'working_directory': '.'}
14:50:44 DISPATCHER: Starting worker discovery
14:50:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:50:44 DISPATCHER: Finished worker discovery
Exception in thread Thread-573:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:51:44 DISPATCHER: Starting worker discovery
14:51:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:51:44 DISPATCHER: Finished worker discovery
14:52:44 DISPATCHER: Starting worker discovery
14:52:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:52:44 DISPATCHER: Finished worker discovery
14:53:44 DISPATCHER: Starting worker discovery
14:53:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:53:44 DISPATCHER: Finished worker discovery
14:54:44 DISPATCHER: Starting worker discovery
14:54:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:54:44 DISPATCHER: Finished worker discovery
14:55:44 DISPATCHER: Starting worker discovery
14:55:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:55:44 DISPATCHER: Finished worker discovery
14:56:44 DISPATCHER: Starting worker discovery
14:56:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:56:44 DISPATCHER: Finished worker discovery
14:57:44 DISPATCHER: Starting worker discovery
14:57:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:57:44 DISPATCHER: Finished worker discovery
14:57:51 WORKER: done with job (8, 0, 22), trying to register it.
14:57:51 WORKER: registered result for job (8, 0, 22) with dispatcher
14:57:51 DISPATCHER: job (8, 0, 22) finished
14:57:51 DISPATCHER: register_result: lock acquired
14:57:51 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
14:57:51 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 30, 'lr': 0.0027758760400040158, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.022963838484842534}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3481148828656169, 'info': {'music_genre': 0.3481148828656169, 'config': "{'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 30, 'lr': 0.0027758760400040158, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.022963838484842534}"}}
exception: None

14:57:51 job_callback for (8, 0, 22) started
14:57:51 DISPATCHER: Trying to submit another job.
14:57:51 job_callback for (8, 0, 22) got condition
14:57:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:57:51 done building a new model for budget 400.000000 based on 9/22 split
Best loss for this budget:-0.402368





14:57:51 HBMASTER: Trying to run another job!
14:57:51 job_callback for (8, 0, 22) finished
14:57:51 HBMASTER: schedule new run for iteration 8
14:57:51 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
14:57:51 HBMASTER: submitting job (8, 0, 23) to dispatcher
14:57:51 DISPATCHER: trying to submit job (8, 0, 23)
14:57:51 DISPATCHER: trying to notify the job_runner thread.
14:57:51 HBMASTER: job (8, 0, 23) submitted to dispatcher
14:57:51 DISPATCHER: Trying to submit another job.
14:57:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:57:51 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:57:51 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
14:57:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:57:51 WORKER: start processing job (8, 0, 23)
14:57:51 WORKER: args: ()
14:57:51 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 18, 'lr': 0.0012295291908755318, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.017740083805695517}, 'budget': 400.0, 'working_directory': '.'}
14:58:44 DISPATCHER: Starting worker discovery
14:58:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:58:44 DISPATCHER: Finished worker discovery
Exception in thread Thread-574:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:59:44 DISPATCHER: Starting worker discovery
14:59:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:59:44 DISPATCHER: Finished worker discovery
15:00:44 DISPATCHER: Starting worker discovery
15:00:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:00:44 DISPATCHER: Finished worker discovery
15:01:44 DISPATCHER: Starting worker discovery
15:01:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:01:44 DISPATCHER: Finished worker discovery
15:02:44 DISPATCHER: Starting worker discovery
15:02:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:02:44 DISPATCHER: Finished worker discovery
15:03:44 DISPATCHER: Starting worker discovery
15:03:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:03:44 DISPATCHER: Finished worker discovery
15:04:44 DISPATCHER: Starting worker discovery
15:04:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:04:44 DISPATCHER: Finished worker discovery
15:05:24 WORKER: done with job (8, 0, 23), trying to register it.
15:05:24 WORKER: registered result for job (8, 0, 23) with dispatcher
15:05:24 DISPATCHER: job (8, 0, 23) finished
15:05:24 DISPATCHER: register_result: lock acquired
15:05:24 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
15:05:24 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 18, 'lr': 0.0012295291908755318, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.017740083805695517}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3851484116100259, 'info': {'music_genre': 0.3851484116100259, 'config': "{'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 18, 'lr': 0.0012295291908755318, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.017740083805695517}"}}
exception: None

15:05:24 job_callback for (8, 0, 23) started
15:05:24 job_callback for (8, 0, 23) got condition
15:05:24 DISPATCHER: Trying to submit another job.
15:05:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:05:24 done building a new model for budget 400.000000 based on 9/22 split
Best loss for this budget:-0.402368





15:05:24 HBMASTER: Trying to run another job!
15:05:24 job_callback for (8, 0, 23) finished
15:05:24 ITERATION: Advancing config (8, 0, 23) to next budget 1200.000000
15:05:24 HBMASTER: schedule new run for iteration 8
15:05:24 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
15:05:24 HBMASTER: submitting job (8, 0, 23) to dispatcher
15:05:24 DISPATCHER: trying to submit job (8, 0, 23)
15:05:24 DISPATCHER: trying to notify the job_runner thread.
15:05:24 HBMASTER: job (8, 0, 23) submitted to dispatcher
15:05:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:05:24 DISPATCHER: Trying to submit another job.
15:05:24 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.30597140382006277952
15:05:24 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
15:05:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:05:24 WORKER: start processing job (8, 0, 23)
15:05:24 WORKER: args: ()
15:05:24 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 18, 'lr': 0.0012295291908755318, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.017740083805695517}, 'budget': 1200.0, 'working_directory': '.'}
15:05:44 DISPATCHER: Starting worker discovery
15:05:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:05:44 DISPATCHER: Finished worker discovery
Exception in thread Thread-575:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:06:44 DISPATCHER: Starting worker discovery
15:06:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:06:44 DISPATCHER: Finished worker discovery
15:07:44 DISPATCHER: Starting worker discovery
15:07:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:07:44 DISPATCHER: Finished worker discovery
15:08:45 DISPATCHER: Starting worker discovery
15:08:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:08:45 DISPATCHER: Finished worker discovery
15:09:45 DISPATCHER: Starting worker discovery
15:09:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:09:45 DISPATCHER: Finished worker discovery
15:10:45 DISPATCHER: Starting worker discovery
15:10:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:10:45 DISPATCHER: Finished worker discovery
15:11:45 DISPATCHER: Starting worker discovery
15:11:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:11:45 DISPATCHER: Finished worker discovery
15:12:45 DISPATCHER: Starting worker discovery
15:12:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:12:45 DISPATCHER: Finished worker discovery
15:13:45 DISPATCHER: Starting worker discovery
15:13:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:13:45 DISPATCHER: Finished worker discovery
15:14:45 DISPATCHER: Starting worker discovery
15:14:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:14:45 DISPATCHER: Finished worker discovery
15:15:45 DISPATCHER: Starting worker discovery
15:15:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:15:45 DISPATCHER: Finished worker discovery
15:16:45 DISPATCHER: Starting worker discovery
15:16:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:16:45 DISPATCHER: Finished worker discovery
15:17:45 DISPATCHER: Starting worker discovery
15:17:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:17:45 DISPATCHER: Finished worker discovery
15:18:45 DISPATCHER: Starting worker discovery
15:18:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:18:45 DISPATCHER: Finished worker discovery
15:19:45 DISPATCHER: Starting worker discovery
15:19:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:19:45 DISPATCHER: Finished worker discovery
15:20:45 DISPATCHER: Starting worker discovery
15:20:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:20:45 DISPATCHER: Finished worker discovery
15:21:45 DISPATCHER: Starting worker discovery
15:21:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:21:45 DISPATCHER: Finished worker discovery
15:22:45 DISPATCHER: Starting worker discovery
15:22:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:22:45 DISPATCHER: Finished worker discovery
15:23:45 DISPATCHER: Starting worker discovery
15:23:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:23:45 DISPATCHER: Finished worker discovery
15:24:45 DISPATCHER: Starting worker discovery
15:24:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:24:45 DISPATCHER: Finished worker discovery
15:25:45 DISPATCHER: Starting worker discovery
15:25:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:25:45 DISPATCHER: Finished worker discovery
15:26:19 WORKER: done with job (8, 0, 23), trying to register it.
15:26:19 WORKER: registered result for job (8, 0, 23) with dispatcher
15:26:19 DISPATCHER: job (8, 0, 23) finished
15:26:19 DISPATCHER: register_result: lock acquired
15:26:19 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
15:26:19 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 18, 'lr': 0.0012295291908755318, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.017740083805695517}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.37475711535704476, 'info': {'music_genre': 0.37475711535704476, 'config': "{'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 18, 'lr': 0.0012295291908755318, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.017740083805695517}"}}
exception: None

15:26:19 job_callback for (8, 0, 23) started
15:26:19 job_callback for (8, 0, 23) got condition
15:26:19 DISPATCHER: Trying to submit another job.
15:26:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:26:19 HBMASTER: Trying to run another job!
15:26:19 job_callback for (8, 0, 23) finished
15:26:19 start sampling a new configuration.
15:26:19 best_vector: [1, 0.8164784515730584, 0.336486361674893, 0.023692251754586793, 0.10173348470914825, 0, 0.960985311564826, 0.07684687912945234], 0.0005666227865618748, 9910.587528552029, 5.615564721893515
15:26:19 done sampling a new configuration.
15:26:19 HBMASTER: schedule new run for iteration 9
15:26:19 HBMASTER: trying submitting job (9, 0, 0) to dispatcher
15:26:19 HBMASTER: submitting job (9, 0, 0) to dispatcher
15:26:19 DISPATCHER: trying to submit job (9, 0, 0)
15:26:19 DISPATCHER: trying to notify the job_runner thread.
15:26:19 HBMASTER: job (9, 0, 0) submitted to dispatcher
15:26:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:26:19 DISPATCHER: Trying to submit another job.
15:26:19 DISPATCHER: starting job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
15:26:19 DISPATCHER: job (9, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
15:26:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:26:19 WORKER: start processing job (9, 0, 0)
15:26:19 WORKER: args: ()
15:26:19 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 86, 'last_n_outputs': 17, 'lr': 0.0011152815133874186, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.012588677123230111}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:26:45 DISPATCHER: Starting worker discovery
15:26:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:26:45 DISPATCHER: Finished worker discovery
Exception in thread Thread-576:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:27:45 DISPATCHER: Starting worker discovery
15:27:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:27:45 DISPATCHER: Finished worker discovery
15:28:45 DISPATCHER: Starting worker discovery
15:28:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:28:45 DISPATCHER: Finished worker discovery
15:29:27 WORKER: done with job (9, 0, 0), trying to register it.
15:29:27 WORKER: registered result for job (9, 0, 0) with dispatcher
15:29:27 DISPATCHER: job (9, 0, 0) finished
15:29:27 DISPATCHER: register_result: lock acquired
15:29:27 DISPATCHER: job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
15:29:27 job_id: (9, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 86, 'last_n_outputs': 17, 'lr': 0.0011152815133874186, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.012588677123230111}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3719630611413549, 'info': {'music_genre': 0.3719630611413549, 'config': "{'batch_size': 32, 'hidden_dim': 86, 'last_n_outputs': 17, 'lr': 0.0011152815133874186, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.012588677123230111}"}}
exception: None

15:29:27 job_callback for (9, 0, 0) started
15:29:27 job_callback for (9, 0, 0) got condition
15:29:27 DISPATCHER: Trying to submit another job.
15:29:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:29:27 HBMASTER: Trying to run another job!
15:29:27 job_callback for (9, 0, 0) finished
15:29:27 start sampling a new configuration.
15:29:27 done sampling a new configuration.
15:29:27 HBMASTER: schedule new run for iteration 9
15:29:27 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
15:29:27 HBMASTER: submitting job (9, 0, 1) to dispatcher
15:29:27 DISPATCHER: trying to submit job (9, 0, 1)
15:29:27 DISPATCHER: trying to notify the job_runner thread.
15:29:27 HBMASTER: job (9, 0, 1) submitted to dispatcher
15:29:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:29:27 DISPATCHER: Trying to submit another job.
15:29:27 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
15:29:27 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
15:29:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:29:27 WORKER: start processing job (9, 0, 1)
15:29:27 WORKER: args: ()
15:29:27 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 86, 'last_n_outputs': 41, 'lr': 0.005769738335666009, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.022223144524968926}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:29:45 DISPATCHER: Starting worker discovery
15:29:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:29:45 DISPATCHER: Finished worker discovery
Exception in thread Thread-577:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:30:45 DISPATCHER: Starting worker discovery
15:30:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:30:45 DISPATCHER: Finished worker discovery
15:31:45 DISPATCHER: Starting worker discovery
15:31:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:31:45 DISPATCHER: Finished worker discovery
15:32:34 WORKER: done with job (9, 0, 1), trying to register it.
15:32:34 WORKER: registered result for job (9, 0, 1) with dispatcher
15:32:34 DISPATCHER: job (9, 0, 1) finished
15:32:34 DISPATCHER: register_result: lock acquired
15:32:34 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
15:32:34 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 86, 'last_n_outputs': 41, 'lr': 0.005769738335666009, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.022223144524968926}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0570398530798602, 'info': {'music_genre': 0.0570398530798602, 'config': "{'batch_size': 16, 'hidden_dim': 86, 'last_n_outputs': 41, 'lr': 0.005769738335666009, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.022223144524968926}"}}
exception: None

15:32:34 job_callback for (9, 0, 1) started
15:32:34 job_callback for (9, 0, 1) got condition
15:32:34 DISPATCHER: Trying to submit another job.
15:32:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:32:34 HBMASTER: Trying to run another job!
15:32:34 job_callback for (9, 0, 1) finished
15:32:34 start sampling a new configuration.
15:32:34 done sampling a new configuration.
15:32:34 HBMASTER: schedule new run for iteration 9
15:32:34 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
15:32:34 HBMASTER: submitting job (9, 0, 2) to dispatcher
15:32:34 DISPATCHER: trying to submit job (9, 0, 2)
15:32:34 DISPATCHER: trying to notify the job_runner thread.
15:32:34 HBMASTER: job (9, 0, 2) submitted to dispatcher
15:32:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:32:34 DISPATCHER: Trying to submit another job.
15:32:34 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
15:32:34 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
15:32:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:32:34 WORKER: start processing job (9, 0, 2)
15:32:34 WORKER: args: ()
15:32:34 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 30, 'last_n_outputs': 13, 'lr': 0.03493485536302641, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.029469911974728466}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:32:45 DISPATCHER: Starting worker discovery
15:32:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:32:45 DISPATCHER: Finished worker discovery
Exception in thread Thread-578:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:33:45 DISPATCHER: Starting worker discovery
15:33:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:33:45 DISPATCHER: Finished worker discovery
15:34:45 DISPATCHER: Starting worker discovery
15:34:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:34:45 DISPATCHER: Finished worker discovery
15:35:42 WORKER: done with job (9, 0, 2), trying to register it.
15:35:42 WORKER: registered result for job (9, 0, 2) with dispatcher
15:35:42 DISPATCHER: job (9, 0, 2) finished
15:35:42 DISPATCHER: register_result: lock acquired
15:35:42 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
15:35:42 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 30, 'last_n_outputs': 13, 'lr': 0.03493485536302641, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.029469911974728466}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 30, 'last_n_outputs': 13, 'lr': 0.03493485536302641, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.029469911974728466}"}}
exception: None

15:35:42 job_callback for (9, 0, 2) started
15:35:42 job_callback for (9, 0, 2) got condition
15:35:42 DISPATCHER: Trying to submit another job.
15:35:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:35:42 HBMASTER: Trying to run another job!
15:35:42 job_callback for (9, 0, 2) finished
15:35:42 start sampling a new configuration.
15:35:42 done sampling a new configuration.
15:35:42 HBMASTER: schedule new run for iteration 9
15:35:42 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
15:35:42 HBMASTER: submitting job (9, 0, 3) to dispatcher
15:35:42 DISPATCHER: trying to submit job (9, 0, 3)
15:35:42 DISPATCHER: trying to notify the job_runner thread.
15:35:42 HBMASTER: job (9, 0, 3) submitted to dispatcher
15:35:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:35:42 DISPATCHER: Trying to submit another job.
15:35:42 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
15:35:42 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
15:35:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:35:42 WORKER: start processing job (9, 0, 3)
15:35:42 WORKER: args: ()
15:35:42 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 64, 'last_n_outputs': 45, 'lr': 0.03630883788568661, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.012215986963267911}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:35:45 DISPATCHER: Starting worker discovery
15:35:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:35:45 DISPATCHER: Finished worker discovery
15:36:45 DISPATCHER: Starting worker discovery
15:36:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:36:45 DISPATCHER: Finished worker discovery
Exception in thread Thread-579:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:37:45 DISPATCHER: Starting worker discovery
15:37:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:37:45 DISPATCHER: Finished worker discovery
15:38:45 DISPATCHER: Starting worker discovery
15:38:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:38:45 DISPATCHER: Finished worker discovery
15:38:48 WORKER: done with job (9, 0, 3), trying to register it.
15:38:48 WORKER: registered result for job (9, 0, 3) with dispatcher
15:38:48 DISPATCHER: job (9, 0, 3) finished
15:38:48 DISPATCHER: register_result: lock acquired
15:38:48 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
15:38:48 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 64, 'last_n_outputs': 45, 'lr': 0.03630883788568661, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.012215986963267911}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 64, 'last_n_outputs': 45, 'lr': 0.03630883788568661, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.012215986963267911}"}}
exception: None

15:38:48 job_callback for (9, 0, 3) started
15:38:48 job_callback for (9, 0, 3) got condition
15:38:48 DISPATCHER: Trying to submit another job.
15:38:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:38:48 HBMASTER: Trying to run another job!
15:38:48 job_callback for (9, 0, 3) finished
15:38:48 start sampling a new configuration.
15:38:48 best_vector: [3, 0.9568628878942557, 0.31853548786337793, 0.2542746168135827, 0.10272359674939593, 0, 0.9618561648397127, 0.25039494836976695], 0.0, inf, 1.2615860668970147
15:38:48 done sampling a new configuration.
15:38:48 HBMASTER: schedule new run for iteration 9
15:38:48 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
15:38:48 HBMASTER: submitting job (9, 0, 4) to dispatcher
15:38:48 DISPATCHER: trying to submit job (9, 0, 4)
15:38:48 DISPATCHER: trying to notify the job_runner thread.
15:38:48 HBMASTER: job (9, 0, 4) submitted to dispatcher
15:38:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:38:48 DISPATCHER: Trying to submit another job.
15:38:48 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
15:38:48 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
15:38:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:38:48 WORKER: start processing job (9, 0, 4)
15:38:48 WORKER: args: ()
15:38:48 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 97, 'last_n_outputs': 16, 'lr': 0.0032251449159080166, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.021172460855188105}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:39:45 DISPATCHER: Starting worker discovery
15:39:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:39:45 DISPATCHER: Finished worker discovery
Exception in thread Thread-580:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:40:45 DISPATCHER: Starting worker discovery
15:40:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:40:45 DISPATCHER: Finished worker discovery
15:41:45 DISPATCHER: Starting worker discovery
15:41:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:41:45 DISPATCHER: Finished worker discovery
15:41:56 WORKER: done with job (9, 0, 4), trying to register it.
15:41:56 WORKER: registered result for job (9, 0, 4) with dispatcher
15:41:56 DISPATCHER: job (9, 0, 4) finished
15:41:56 DISPATCHER: register_result: lock acquired
15:41:56 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
15:41:56 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 97, 'last_n_outputs': 16, 'lr': 0.0032251449159080166, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.021172460855188105}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4481854048298063, 'info': {'music_genre': 0.4481854048298063, 'config': "{'batch_size': 128, 'hidden_dim': 97, 'last_n_outputs': 16, 'lr': 0.0032251449159080166, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.021172460855188105}"}}
exception: None

15:41:56 job_callback for (9, 0, 4) started
15:41:56 DISPATCHER: Trying to submit another job.
15:41:56 job_callback for (9, 0, 4) got condition
15:41:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:41:56 HBMASTER: Trying to run another job!
15:41:56 job_callback for (9, 0, 4) finished
15:41:56 start sampling a new configuration.
15:41:56 best_vector: [1, 0.6219343289591357, 0.32122240990246886, 0.1487785865839271, 0.10665959580372826, 0, 0.9310278964993455, 0.1944370203241767], 0.0008846481565716458, 1.30257520783782e-05, 1.1523207564096558e-08
15:41:56 done sampling a new configuration.
15:41:56 HBMASTER: schedule new run for iteration 9
15:41:56 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
15:41:56 HBMASTER: submitting job (9, 0, 5) to dispatcher
15:41:56 DISPATCHER: trying to submit job (9, 0, 5)
15:41:56 DISPATCHER: trying to notify the job_runner thread.
15:41:56 HBMASTER: job (9, 0, 5) submitted to dispatcher
15:41:56 DISPATCHER: Trying to submit another job.
15:41:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:41:56 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952
15:41:56 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
15:41:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:41:56 WORKER: start processing job (9, 0, 5)
15:41:56 WORKER: args: ()
15:41:56 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 70, 'last_n_outputs': 17, 'lr': 0.0019840708348004216, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.017904755535795437}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:42:45 DISPATCHER: Starting worker discovery
15:42:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:42:45 DISPATCHER: Finished worker discovery
Exception in thread Thread-581:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:43:45 DISPATCHER: Starting worker discovery
15:43:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:43:45 DISPATCHER: Finished worker discovery
15:44:45 DISPATCHER: Starting worker discovery
15:44:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:44:45 DISPATCHER: Finished worker discovery
15:45:03 WORKER: done with job (9, 0, 5), trying to register it.
15:45:03 WORKER: registered result for job (9, 0, 5) with dispatcher
15:45:03 DISPATCHER: job (9, 0, 5) finished
15:45:03 DISPATCHER: register_result: lock acquired
15:45:03 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
15:45:03 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 70, 'last_n_outputs': 17, 'lr': 0.0019840708348004216, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.017904755535795437}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3217082687928237, 'info': {'music_genre': 0.3217082687928237, 'config': "{'batch_size': 32, 'hidden_dim': 70, 'last_n_outputs': 17, 'lr': 0.0019840708348004216, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.017904755535795437}"}}
exception: None

15:45:03 job_callback for (9, 0, 5) started
15:45:03 DISPATCHER: Trying to submit another job.
15:45:03 job_callback for (9, 0, 5) got condition
15:45:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:45:03 HBMASTER: Trying to run another job!
15:45:03 job_callback for (9, 0, 5) finished
15:45:03 start sampling a new configuration.
15:45:03 done sampling a new configuration.
15:45:03 HBMASTER: schedule new run for iteration 9
15:45:03 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
15:45:03 HBMASTER: submitting job (9, 0, 6) to dispatcher
15:45:03 DISPATCHER: trying to submit job (9, 0, 6)
15:45:03 DISPATCHER: trying to notify the job_runner thread.
15:45:03 HBMASTER: job (9, 0, 6) submitted to dispatcher
15:45:03 DISPATCHER: Trying to submit another job.
15:45:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:45:03 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952
15:45:03 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
15:45:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:45:03 WORKER: start processing job (9, 0, 6)
15:45:03 WORKER: args: ()
15:45:03 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 55, 'last_n_outputs': 20, 'lr': 0.0026842197846157663, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.07589078090003096}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:45:45 DISPATCHER: Starting worker discovery
15:45:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:45:45 DISPATCHER: Finished worker discovery
Exception in thread Thread-582:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:46:45 DISPATCHER: Starting worker discovery
15:46:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:46:45 DISPATCHER: Finished worker discovery
15:47:45 DISPATCHER: Starting worker discovery
15:47:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:47:45 DISPATCHER: Finished worker discovery
15:48:11 WORKER: done with job (9, 0, 6), trying to register it.
15:48:11 WORKER: registered result for job (9, 0, 6) with dispatcher
15:48:11 DISPATCHER: job (9, 0, 6) finished
15:48:11 DISPATCHER: register_result: lock acquired
15:48:11 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
15:48:11 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 55, 'last_n_outputs': 20, 'lr': 0.0026842197846157663, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.07589078090003096}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': 0.009303568413252207, 'info': {'music_genre': -0.009303568413252207, 'config': "{'batch_size': 16, 'hidden_dim': 55, 'last_n_outputs': 20, 'lr': 0.0026842197846157663, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.07589078090003096}"}}
exception: None

15:48:11 job_callback for (9, 0, 6) started
15:48:11 DISPATCHER: Trying to submit another job.
15:48:11 job_callback for (9, 0, 6) got condition
15:48:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:48:11 HBMASTER: Trying to run another job!
15:48:11 job_callback for (9, 0, 6) finished
15:48:11 start sampling a new configuration.
15:48:11 done sampling a new configuration.
15:48:11 HBMASTER: schedule new run for iteration 9
15:48:11 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
15:48:11 HBMASTER: submitting job (9, 0, 7) to dispatcher
15:48:11 DISPATCHER: trying to submit job (9, 0, 7)
15:48:11 DISPATCHER: trying to notify the job_runner thread.
15:48:11 HBMASTER: job (9, 0, 7) submitted to dispatcher
15:48:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:48:11 DISPATCHER: Trying to submit another job.
15:48:11 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952
15:48:11 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
15:48:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:48:11 WORKER: start processing job (9, 0, 7)
15:48:11 WORKER: args: ()
15:48:11 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 85, 'last_n_outputs': 37, 'lr': 0.006526747986597804, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.015672708204499414}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:48:45 DISPATCHER: Starting worker discovery
15:48:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:48:45 DISPATCHER: Finished worker discovery
Exception in thread Thread-583:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:49:45 DISPATCHER: Starting worker discovery
15:49:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:49:45 DISPATCHER: Finished worker discovery
15:50:45 DISPATCHER: Starting worker discovery
15:50:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:50:45 DISPATCHER: Finished worker discovery
15:51:20 WORKER: done with job (9, 0, 7), trying to register it.
15:51:20 WORKER: registered result for job (9, 0, 7) with dispatcher
15:51:20 DISPATCHER: job (9, 0, 7) finished
15:51:20 DISPATCHER: register_result: lock acquired
15:51:20 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
15:51:20 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 85, 'last_n_outputs': 37, 'lr': 0.006526747986597804, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.015672708204499414}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.10001328205383227, 'info': {'music_genre': 0.10001328205383227, 'config': "{'batch_size': 64, 'hidden_dim': 85, 'last_n_outputs': 37, 'lr': 0.006526747986597804, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.015672708204499414}"}}
exception: None

15:51:20 job_callback for (9, 0, 7) started
15:51:20 DISPATCHER: Trying to submit another job.
15:51:20 job_callback for (9, 0, 7) got condition
15:51:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:51:20 HBMASTER: Trying to run another job!
15:51:20 job_callback for (9, 0, 7) finished
15:51:20 start sampling a new configuration.
15:51:20 done sampling a new configuration.
15:51:20 HBMASTER: schedule new run for iteration 9
15:51:20 HBMASTER: trying submitting job (9, 0, 8) to dispatcher
15:51:20 HBMASTER: submitting job (9, 0, 8) to dispatcher
15:51:20 DISPATCHER: trying to submit job (9, 0, 8)
15:51:20 DISPATCHER: trying to notify the job_runner thread.
15:51:20 HBMASTER: job (9, 0, 8) submitted to dispatcher
15:51:20 DISPATCHER: Trying to submit another job.
15:51:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:51:20 DISPATCHER: starting job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952
15:51:20 DISPATCHER: job (9, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
15:51:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:51:20 WORKER: start processing job (9, 0, 8)
15:51:20 WORKER: args: ()
15:51:20 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 65, 'last_n_outputs': 1, 'lr': 0.009924633317504022, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.010277507850064463}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:51:45 DISPATCHER: Starting worker discovery
15:51:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:51:45 DISPATCHER: Finished worker discovery
Exception in thread Thread-584:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:52:45 DISPATCHER: Starting worker discovery
15:52:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:52:45 DISPATCHER: Finished worker discovery
15:53:45 DISPATCHER: Starting worker discovery
15:53:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:53:45 DISPATCHER: Finished worker discovery
15:54:28 WORKER: done with job (9, 0, 8), trying to register it.
15:54:28 WORKER: registered result for job (9, 0, 8) with dispatcher
15:54:28 DISPATCHER: job (9, 0, 8) finished
15:54:28 DISPATCHER: register_result: lock acquired
15:54:28 DISPATCHER: job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
15:54:28 job_id: (9, 0, 8)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 65, 'last_n_outputs': 1, 'lr': 0.009924633317504022, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.010277507850064463}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 65, 'last_n_outputs': 1, 'lr': 0.009924633317504022, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.010277507850064463}"}}
exception: None

15:54:28 job_callback for (9, 0, 8) started
15:54:28 DISPATCHER: Trying to submit another job.
15:54:28 job_callback for (9, 0, 8) got condition
15:54:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:54:28 HBMASTER: Trying to run another job!
15:54:28 job_callback for (9, 0, 8) finished
15:54:28 ITERATION: Advancing config (9, 0, 0) to next budget 400.000000
15:54:28 ITERATION: Advancing config (9, 0, 4) to next budget 400.000000
15:54:28 ITERATION: Advancing config (9, 0, 5) to next budget 400.000000
15:54:28 HBMASTER: schedule new run for iteration 9
15:54:28 HBMASTER: trying submitting job (9, 0, 0) to dispatcher
15:54:28 HBMASTER: submitting job (9, 0, 0) to dispatcher
15:54:28 DISPATCHER: trying to submit job (9, 0, 0)
15:54:28 DISPATCHER: trying to notify the job_runner thread.
15:54:28 HBMASTER: job (9, 0, 0) submitted to dispatcher
15:54:28 DISPATCHER: Trying to submit another job.
15:54:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:54:28 DISPATCHER: starting job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
15:54:28 DISPATCHER: job (9, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
15:54:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:54:28 WORKER: start processing job (9, 0, 0)
15:54:28 WORKER: args: ()
15:54:28 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 86, 'last_n_outputs': 17, 'lr': 0.0011152815133874186, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.012588677123230111}, 'budget': 400.0, 'working_directory': '.'}
15:54:45 DISPATCHER: Starting worker discovery
15:54:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:54:45 DISPATCHER: Finished worker discovery
Exception in thread Thread-585:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:55:45 DISPATCHER: Starting worker discovery
15:55:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:55:45 DISPATCHER: Finished worker discovery
15:56:45 DISPATCHER: Starting worker discovery
15:56:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:56:45 DISPATCHER: Finished worker discovery
15:57:45 DISPATCHER: Starting worker discovery
15:57:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:57:45 DISPATCHER: Finished worker discovery
15:58:45 DISPATCHER: Starting worker discovery
15:58:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:58:45 DISPATCHER: Finished worker discovery
15:59:45 DISPATCHER: Starting worker discovery
15:59:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:59:45 DISPATCHER: Finished worker discovery
16:00:45 DISPATCHER: Starting worker discovery
16:00:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:00:45 DISPATCHER: Finished worker discovery
16:01:45 DISPATCHER: Starting worker discovery
16:01:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:01:45 DISPATCHER: Finished worker discovery
16:02:02 WORKER: done with job (9, 0, 0), trying to register it.
16:02:02 WORKER: registered result for job (9, 0, 0) with dispatcher
16:02:02 DISPATCHER: job (9, 0, 0) finished
16:02:02 DISPATCHER: register_result: lock acquired
16:02:02 DISPATCHER: job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
16:02:02 job_id: (9, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 86, 'last_n_outputs': 17, 'lr': 0.0011152815133874186, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.012588677123230111}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.36253127136736973, 'info': {'music_genre': 0.36253127136736973, 'config': "{'batch_size': 32, 'hidden_dim': 86, 'last_n_outputs': 17, 'lr': 0.0011152815133874186, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.012588677123230111}"}}
exception: None

16:02:02 job_callback for (9, 0, 0) started
16:02:02 DISPATCHER: Trying to submit another job.
16:02:02 job_callback for (9, 0, 0) got condition
16:02:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:02:02 done building a new model for budget 400.000000 based on 9/23 split
Best loss for this budget:-0.402368





16:02:02 HBMASTER: Trying to run another job!
16:02:02 job_callback for (9, 0, 0) finished
16:02:02 HBMASTER: schedule new run for iteration 9
16:02:02 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
16:02:02 HBMASTER: submitting job (9, 0, 4) to dispatcher
16:02:02 DISPATCHER: trying to submit job (9, 0, 4)
16:02:02 DISPATCHER: trying to notify the job_runner thread.
16:02:02 HBMASTER: job (9, 0, 4) submitted to dispatcher
16:02:02 DISPATCHER: Trying to submit another job.
16:02:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:02:02 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:02:02 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:02:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:02:02 WORKER: start processing job (9, 0, 4)
16:02:02 WORKER: args: ()
16:02:02 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 97, 'last_n_outputs': 16, 'lr': 0.0032251449159080166, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.021172460855188105}, 'budget': 400.0, 'working_directory': '.'}
16:02:45 DISPATCHER: Starting worker discovery
16:02:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:02:45 DISPATCHER: Finished worker discovery
Exception in thread Thread-586:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

16:03:45 DISPATCHER: Starting worker discovery
16:03:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:03:45 DISPATCHER: Finished worker discovery
16:04:45 DISPATCHER: Starting worker discovery
16:04:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:04:45 DISPATCHER: Finished worker discovery
16:05:45 DISPATCHER: Starting worker discovery
16:05:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:05:45 DISPATCHER: Finished worker discovery
16:06:45 DISPATCHER: Starting worker discovery
16:06:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:06:45 DISPATCHER: Finished worker discovery
16:07:45 DISPATCHER: Starting worker discovery
16:07:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:07:45 DISPATCHER: Finished worker discovery
16:08:45 DISPATCHER: Starting worker discovery
16:08:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:08:45 DISPATCHER: Finished worker discovery
16:09:36 WORKER: done with job (9, 0, 4), trying to register it.
16:09:36 WORKER: registered result for job (9, 0, 4) with dispatcher
16:09:36 DISPATCHER: job (9, 0, 4) finished
16:09:36 DISPATCHER: register_result: lock acquired
16:09:36 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
16:09:36 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 97, 'last_n_outputs': 16, 'lr': 0.0032251449159080166, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.021172460855188105}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.40950908395006136, 'info': {'music_genre': 0.40950908395006136, 'config': "{'batch_size': 128, 'hidden_dim': 97, 'last_n_outputs': 16, 'lr': 0.0032251449159080166, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.021172460855188105}"}}
exception: None

16:09:36 job_callback for (9, 0, 4) started
16:09:36 DISPATCHER: Trying to submit another job.
16:09:36 job_callback for (9, 0, 4) got condition
16:09:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:09:36 done building a new model for budget 400.000000 based on 9/24 split
Best loss for this budget:-0.409509





16:09:36 HBMASTER: Trying to run another job!
16:09:36 job_callback for (9, 0, 4) finished
16:09:36 HBMASTER: schedule new run for iteration 9
16:09:36 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
16:09:36 HBMASTER: submitting job (9, 0, 5) to dispatcher
16:09:36 DISPATCHER: trying to submit job (9, 0, 5)
16:09:36 DISPATCHER: trying to notify the job_runner thread.
16:09:36 HBMASTER: job (9, 0, 5) submitted to dispatcher
16:09:36 DISPATCHER: Trying to submit another job.
16:09:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:09:36 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:09:36 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:09:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:09:37 WORKER: start processing job (9, 0, 5)
16:09:37 WORKER: args: ()
16:09:37 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 70, 'last_n_outputs': 17, 'lr': 0.0019840708348004216, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.017904755535795437}, 'budget': 400.0, 'working_directory': '.'}
16:09:45 DISPATCHER: Starting worker discovery
16:09:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:09:45 DISPATCHER: Finished worker discovery
Exception in thread Thread-587:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

16:10:45 DISPATCHER: Starting worker discovery
16:10:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:10:45 DISPATCHER: Finished worker discovery
16:11:45 DISPATCHER: Starting worker discovery
16:11:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:11:45 DISPATCHER: Finished worker discovery
16:12:45 DISPATCHER: Starting worker discovery
16:12:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:12:45 DISPATCHER: Finished worker discovery
16:13:45 DISPATCHER: Starting worker discovery
16:13:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:13:45 DISPATCHER: Finished worker discovery
16:14:45 DISPATCHER: Starting worker discovery
16:14:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:14:45 DISPATCHER: Finished worker discovery
16:15:45 DISPATCHER: Starting worker discovery
16:15:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:15:45 DISPATCHER: Finished worker discovery
16:16:45 DISPATCHER: Starting worker discovery
16:16:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:16:45 DISPATCHER: Finished worker discovery
16:17:14 WORKER: done with job (9, 0, 5), trying to register it.
16:17:14 WORKER: registered result for job (9, 0, 5) with dispatcher
16:17:14 DISPATCHER: job (9, 0, 5) finished
16:17:14 DISPATCHER: register_result: lock acquired
16:17:14 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
16:17:14 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 70, 'last_n_outputs': 17, 'lr': 0.0019840708348004216, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.017904755535795437}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.303421617895897, 'info': {'music_genre': 0.303421617895897, 'config': "{'batch_size': 32, 'hidden_dim': 70, 'last_n_outputs': 17, 'lr': 0.0019840708348004216, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.017904755535795437}"}}
exception: None

16:17:14 job_callback for (9, 0, 5) started
16:17:14 DISPATCHER: Trying to submit another job.
16:17:14 job_callback for (9, 0, 5) got condition
16:17:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:17:14 done building a new model for budget 400.000000 based on 9/25 split
Best loss for this budget:-0.409509





16:17:14 HBMASTER: Trying to run another job!
16:17:14 job_callback for (9, 0, 5) finished
16:17:14 ITERATION: Advancing config (9, 0, 4) to next budget 1200.000000
16:17:14 HBMASTER: schedule new run for iteration 9
16:17:14 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
16:17:14 HBMASTER: submitting job (9, 0, 4) to dispatcher
16:17:14 DISPATCHER: trying to submit job (9, 0, 4)
16:17:14 DISPATCHER: trying to notify the job_runner thread.
16:17:14 HBMASTER: job (9, 0, 4) submitted to dispatcher
16:17:14 DISPATCHER: Trying to submit another job.
16:17:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:17:14 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:17:14 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:17:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:17:14 WORKER: start processing job (9, 0, 4)
16:17:14 WORKER: args: ()
16:17:14 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 97, 'last_n_outputs': 16, 'lr': 0.0032251449159080166, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.021172460855188105}, 'budget': 1200.0, 'working_directory': '.'}
16:17:45 DISPATCHER: Starting worker discovery
16:17:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:17:45 DISPATCHER: Finished worker discovery
Exception in thread Thread-588:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

16:18:45 DISPATCHER: Starting worker discovery
16:18:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:18:45 DISPATCHER: Finished worker discovery
16:19:45 DISPATCHER: Starting worker discovery
16:19:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:19:45 DISPATCHER: Finished worker discovery
16:20:45 DISPATCHER: Starting worker discovery
16:20:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:20:45 DISPATCHER: Finished worker discovery
16:21:45 DISPATCHER: Starting worker discovery
16:21:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:21:45 DISPATCHER: Finished worker discovery
16:22:45 DISPATCHER: Starting worker discovery
16:22:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:22:45 DISPATCHER: Finished worker discovery
16:23:45 DISPATCHER: Starting worker discovery
16:23:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:23:45 DISPATCHER: Finished worker discovery
16:24:45 DISPATCHER: Starting worker discovery
16:24:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:24:45 DISPATCHER: Finished worker discovery
16:25:45 DISPATCHER: Starting worker discovery
16:25:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:25:45 DISPATCHER: Finished worker discovery
16:26:45 DISPATCHER: Starting worker discovery
16:26:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:26:45 DISPATCHER: Finished worker discovery
16:27:45 DISPATCHER: Starting worker discovery
16:27:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:27:45 DISPATCHER: Finished worker discovery
16:28:45 DISPATCHER: Starting worker discovery
16:28:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:28:45 DISPATCHER: Finished worker discovery
16:29:45 DISPATCHER: Starting worker discovery
16:29:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:29:45 DISPATCHER: Finished worker discovery
16:30:45 DISPATCHER: Starting worker discovery
16:30:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:30:45 DISPATCHER: Finished worker discovery
16:31:45 DISPATCHER: Starting worker discovery
16:31:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:31:45 DISPATCHER: Finished worker discovery
16:32:45 DISPATCHER: Starting worker discovery
16:32:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:32:45 DISPATCHER: Finished worker discovery
16:33:45 DISPATCHER: Starting worker discovery
16:33:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:33:45 DISPATCHER: Finished worker discovery
16:34:45 DISPATCHER: Starting worker discovery
16:34:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:34:45 DISPATCHER: Finished worker discovery
16:35:45 DISPATCHER: Starting worker discovery
16:35:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:35:45 DISPATCHER: Finished worker discovery
16:36:45 DISPATCHER: Starting worker discovery
16:36:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:36:45 DISPATCHER: Finished worker discovery
16:37:45 DISPATCHER: Starting worker discovery
16:37:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:37:45 DISPATCHER: Finished worker discovery
16:38:11 WORKER: done with job (9, 0, 4), trying to register it.
16:38:11 WORKER: registered result for job (9, 0, 4) with dispatcher
16:38:11 DISPATCHER: job (9, 0, 4) finished
16:38:11 DISPATCHER: register_result: lock acquired
16:38:11 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
16:38:11 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 97, 'last_n_outputs': 16, 'lr': 0.0032251449159080166, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.021172460855188105}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.42399965475264767, 'info': {'music_genre': 0.42399965475264767, 'config': "{'batch_size': 128, 'hidden_dim': 97, 'last_n_outputs': 16, 'lr': 0.0032251449159080166, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.021172460855188105}"}}
exception: None

16:38:11 job_callback for (9, 0, 4) started
16:38:11 DISPATCHER: Trying to submit another job.
16:38:11 job_callback for (9, 0, 4) got condition
16:38:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:38:11 done building a new model for budget 1200.000000 based on 9/15 split
Best loss for this budget:-0.424000





16:38:11 HBMASTER: Trying to run another job!
16:38:11 job_callback for (9, 0, 4) finished
16:38:11 HBMASTER: shutdown initiated, shutdown_workers = True
16:38:11 WORKER: shutting down now!
16:38:11 DISPATCHER: Dispatcher shutting down
16:38:11 DISPATCHER: discover_workers shutting down
16:38:11 DISPATCHER: Trying to submit another job.
16:38:11 DISPATCHER: 'discover_worker' thread exited
16:38:11 DISPATCHER: job_runner shutting down
16:38:11 DISPATCHER: 'job_runner' thread exited
16:38:11 DISPATCHER: shut down complete
16:38:11 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7fac6c05b780; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:37293>
16:38:11 WORKER: No dispatcher found. Waiting for one to initiate contact.
16:38:11 WORKER: start listening for jobs
16:38:11 wait_for_workers trying to get the condition
16:38:11 DISPATCHER: started the 'discover_worker' thread
16:38:11 DISPATCHER: started the 'job_runner' thread
16:38:11 DISPATCHER: Pyro daemon running on localhost:36589
16:38:11 HBMASTER: only 0 worker(s) available, waiting for at least 1.
16:38:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:38:11 DISPATCHER: Starting worker discovery
16:38:11 DISPATCHER: Found 1 potential workers, 0 currently in the pool.
16:38:11 DISPATCHER: discovered new worker, hpbandster.run_0.worker.metagpuj.30597140382006277952
16:38:11 HBMASTER: number of workers changed to 1
16:38:11 adjust_queue_size: lock accquired
16:38:11 HBMASTER: adjusted queue size to (0, 1)
16:38:11 DISPATCHER: Finished worker discovery
16:38:11 DISPATCHER: A new worker triggered discover_worker
16:38:11 DISPATCHER: Trying to submit another job.
16:38:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:38:11 Enough workers to start this run!
16:38:11 DISPATCHER: Starting worker discovery
16:38:11 HBMASTER: starting run at 1583941091.688732
16:38:11 start sampling a new configuration.
16:38:11 done sampling a new configuration.
16:38:11 HBMASTER: schedule new run for iteration 0
16:38:11 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
16:38:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:38:11 HBMASTER: submitting job (0, 0, 0) to dispatcher
16:38:11 DISPATCHER: trying to submit job (0, 0, 0)
16:38:11 DISPATCHER: Finished worker discovery
16:38:11 DISPATCHER: trying to notify the job_runner thread.
16:38:11 HBMASTER: job (0, 0, 0) submitted to dispatcher
16:38:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:38:11 DISPATCHER: Trying to submit another job.
16:38:11 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:38:11 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:38:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:38:11 WORKER: start processing job (0, 0, 0)
16:38:11 WORKER: args: ()
16:38:11 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0010910752200006524, 'num_filters_1': 44, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.010542450616706531, 'kernel_size_2': 5, 'num_filters_2': 44}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:39:11 DISPATCHER: Starting worker discovery
16:39:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:39:11 DISPATCHER: Finished worker discovery
16:39:55 WORKER: done with job (0, 0, 0), trying to register it.
16:39:55 WORKER: registered result for job (0, 0, 0) with dispatcher
16:39:55 DISPATCHER: job (0, 0, 0) finished
16:39:55 DISPATCHER: register_result: lock acquired
16:39:55 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
16:39:55 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0010910752200006524, 'num_filters_1': 44, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.010542450616706531, 'kernel_size_2': 5, 'num_filters_2': 44}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.42987352811535284, 'info': {'music_genre': 0.42987352811535284, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0010910752200006524, 'num_filters_1': 44, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.010542450616706531, 'kernel_size_2': 5, 'num_filters_2': 44}"}}
exception: None

16:39:55 job_callback for (0, 0, 0) started
16:39:55 job_callback for (0, 0, 0) got condition
16:39:55 DISPATCHER: Trying to submit another job.
16:39:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:39:55 Only 1 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
16:39:55 HBMASTER: Trying to run another job!
16:39:55 job_callback for (0, 0, 0) finished
16:39:55 start sampling a new configuration.
16:39:55 done sampling a new configuration.
16:39:55 HBMASTER: schedule new run for iteration 0
16:39:55 HBMASTER: trying submitting job (0, 0, 1) to dispatcher
16:39:55 HBMASTER: submitting job (0, 0, 1) to dispatcher
16:39:55 DISPATCHER: trying to submit job (0, 0, 1)
16:39:55 DISPATCHER: trying to notify the job_runner thread.
16:39:55 HBMASTER: job (0, 0, 1) submitted to dispatcher
16:39:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:39:55 DISPATCHER: Trying to submit another job.
16:39:55 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:39:55 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:39:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:39:55 WORKER: start processing job (0, 0, 1)
16:39:55 WORKER: args: ()
16:39:55 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.08914600208258484, 'num_filters_1': 114, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.0626392289165906, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 101, 'num_filters_3': 62, 'num_filters_4': 48, 'num_filters_5': 52}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:40:11 DISPATCHER: Starting worker discovery
16:40:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:40:11 DISPATCHER: Finished worker discovery
16:41:11 DISPATCHER: Starting worker discovery
16:41:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:41:11 DISPATCHER: Finished worker discovery
16:41:41 WORKER: done with job (0, 0, 1), trying to register it.
16:41:41 WORKER: registered result for job (0, 0, 1) with dispatcher
16:41:41 DISPATCHER: job (0, 0, 1) finished
16:41:41 DISPATCHER: register_result: lock acquired
16:41:41 DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
16:41:41 job_id: (0, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.08914600208258484, 'num_filters_1': 114, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.0626392289165906, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 101, 'num_filters_3': 62, 'num_filters_4': 48, 'num_filters_5': 52}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.08914600208258484, 'num_filters_1': 114, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.0626392289165906, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 101, 'num_filters_3': 62, 'num_filters_4': 48, 'num_filters_5': 52}"}}
exception: None

16:41:41 job_callback for (0, 0, 1) started
16:41:41 job_callback for (0, 0, 1) got condition
16:41:41 DISPATCHER: Trying to submit another job.
16:41:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:41:41 Only 2 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
16:41:41 HBMASTER: Trying to run another job!
16:41:41 job_callback for (0, 0, 1) finished
16:41:41 start sampling a new configuration.
16:41:41 done sampling a new configuration.
16:41:41 HBMASTER: schedule new run for iteration 0
16:41:41 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
16:41:41 HBMASTER: submitting job (0, 0, 2) to dispatcher
16:41:41 DISPATCHER: trying to submit job (0, 0, 2)
16:41:41 DISPATCHER: trying to notify the job_runner thread.
16:41:41 HBMASTER: job (0, 0, 2) submitted to dispatcher
16:41:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:41:41 DISPATCHER: Trying to submit another job.
16:41:41 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:41:41 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:41:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:41:41 WORKER: start processing job (0, 0, 2)
16:41:41 WORKER: args: ()
16:41:41 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.02849666132415544, 'num_filters_1': 34, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.11863919902616944}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:42:11 DISPATCHER: Starting worker discovery
16:42:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:42:11 DISPATCHER: Finished worker discovery
16:43:11 DISPATCHER: Starting worker discovery
16:43:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:43:11 DISPATCHER: Finished worker discovery
16:43:24 WORKER: done with job (0, 0, 2), trying to register it.
16:43:24 WORKER: registered result for job (0, 0, 2) with dispatcher
16:43:24 DISPATCHER: job (0, 0, 2) finished
16:43:24 DISPATCHER: register_result: lock acquired
16:43:24 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
16:43:24 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.02849666132415544, 'num_filters_1': 34, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.11863919902616944}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.03239353441113719, 'info': {'music_genre': 0.03239353441113719, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.02849666132415544, 'num_filters_1': 34, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.11863919902616944}"}}
exception: None

16:43:24 job_callback for (0, 0, 2) started
16:43:24 DISPATCHER: Trying to submit another job.
16:43:24 job_callback for (0, 0, 2) got condition
16:43:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:43:24 Only 3 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
16:43:24 HBMASTER: Trying to run another job!
16:43:24 job_callback for (0, 0, 2) finished
16:43:24 start sampling a new configuration.
16:43:24 done sampling a new configuration.
16:43:24 HBMASTER: schedule new run for iteration 0
16:43:24 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
16:43:24 HBMASTER: submitting job (0, 0, 3) to dispatcher
16:43:24 DISPATCHER: trying to submit job (0, 0, 3)
16:43:24 DISPATCHER: trying to notify the job_runner thread.
16:43:24 HBMASTER: job (0, 0, 3) submitted to dispatcher
16:43:24 DISPATCHER: Trying to submit another job.
16:43:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:43:24 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:43:24 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:43:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:43:24 WORKER: start processing job (0, 0, 3)
16:43:24 WORKER: args: ()
16:43:24 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.004182283607576557, 'num_filters_1': 92, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.0642265623614919, 'kernel_size_2': 7, 'num_filters_2': 79}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:44:11 DISPATCHER: Starting worker discovery
16:44:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:44:11 DISPATCHER: Finished worker discovery
16:45:06 WORKER: done with job (0, 0, 3), trying to register it.
16:45:06 WORKER: registered result for job (0, 0, 3) with dispatcher
16:45:06 DISPATCHER: job (0, 0, 3) finished
16:45:06 DISPATCHER: register_result: lock acquired
16:45:06 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
16:45:06 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.004182283607576557, 'num_filters_1': 92, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.0642265623614919, 'kernel_size_2': 7, 'num_filters_2': 79}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4491501841631419, 'info': {'music_genre': 0.4491501841631419, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.004182283607576557, 'num_filters_1': 92, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.0642265623614919, 'kernel_size_2': 7, 'num_filters_2': 79}"}}
exception: None

16:45:06 job_callback for (0, 0, 3) started
16:45:06 DISPATCHER: Trying to submit another job.
16:45:06 job_callback for (0, 0, 3) got condition
16:45:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:45:06 Only 4 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
16:45:06 HBMASTER: Trying to run another job!
16:45:06 job_callback for (0, 0, 3) finished
16:45:06 start sampling a new configuration.
16:45:06 done sampling a new configuration.
16:45:06 HBMASTER: schedule new run for iteration 0
16:45:06 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
16:45:06 HBMASTER: submitting job (0, 0, 4) to dispatcher
16:45:06 DISPATCHER: trying to submit job (0, 0, 4)
16:45:06 DISPATCHER: trying to notify the job_runner thread.
16:45:06 HBMASTER: job (0, 0, 4) submitted to dispatcher
16:45:06 DISPATCHER: Trying to submit another job.
16:45:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:45:06 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:45:06 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:45:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:45:06 WORKER: start processing job (0, 0, 4)
16:45:06 WORKER: args: ()
16:45:06 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0017507205525982984, 'num_filters_1': 117, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.18051131079473626, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 30, 'num_filters_3': 33, 'num_filters_4': 72}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:45:11 DISPATCHER: Starting worker discovery
16:45:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:45:11 DISPATCHER: Finished worker discovery
16:46:11 DISPATCHER: Starting worker discovery
16:46:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:46:11 DISPATCHER: Finished worker discovery
16:46:48 WORKER: done with job (0, 0, 4), trying to register it.
16:46:48 WORKER: registered result for job (0, 0, 4) with dispatcher
16:46:48 DISPATCHER: job (0, 0, 4) finished
16:46:48 DISPATCHER: register_result: lock acquired
16:46:48 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
16:46:48 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0017507205525982984, 'num_filters_1': 117, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.18051131079473626, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 30, 'num_filters_3': 33, 'num_filters_4': 72}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4641827690912662, 'info': {'music_genre': 0.4641827690912662, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0017507205525982984, 'num_filters_1': 117, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.18051131079473626, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 30, 'num_filters_3': 33, 'num_filters_4': 72}"}}
exception: None

16:46:48 job_callback for (0, 0, 4) started
16:46:48 DISPATCHER: Trying to submit another job.
16:46:48 job_callback for (0, 0, 4) got condition
16:46:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:46:48 Only 5 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
16:46:48 HBMASTER: Trying to run another job!
16:46:48 job_callback for (0, 0, 4) finished
16:46:48 start sampling a new configuration.
16:46:48 done sampling a new configuration.
16:46:48 HBMASTER: schedule new run for iteration 0
16:46:48 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
16:46:48 HBMASTER: submitting job (0, 0, 5) to dispatcher
16:46:48 DISPATCHER: trying to submit job (0, 0, 5)
16:46:48 DISPATCHER: trying to notify the job_runner thread.
16:46:48 HBMASTER: job (0, 0, 5) submitted to dispatcher
16:46:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:46:48 DISPATCHER: Trying to submit another job.
16:46:48 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:46:48 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:46:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:46:48 WORKER: start processing job (0, 0, 5)
16:46:48 WORKER: args: ()
16:46:48 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0026102197930619737, 'num_filters_1': 122, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.01279519909696689, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 62, 'num_filters_3': 109, 'num_filters_4': 21}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:47:11 DISPATCHER: Starting worker discovery
16:47:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:47:11 DISPATCHER: Finished worker discovery
16:48:11 DISPATCHER: Starting worker discovery
16:48:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:48:11 DISPATCHER: Finished worker discovery
16:48:31 WORKER: done with job (0, 0, 5), trying to register it.
16:48:31 WORKER: registered result for job (0, 0, 5) with dispatcher
16:48:31 DISPATCHER: job (0, 0, 5) finished
16:48:31 DISPATCHER: register_result: lock acquired
16:48:31 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
16:48:31 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0026102197930619737, 'num_filters_1': 122, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.01279519909696689, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 62, 'num_filters_3': 109, 'num_filters_4': 21}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4615891963465563, 'info': {'music_genre': 0.4615891963465563, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0026102197930619737, 'num_filters_1': 122, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.01279519909696689, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 62, 'num_filters_3': 109, 'num_filters_4': 21}"}}
exception: None

16:48:31 job_callback for (0, 0, 5) started
16:48:31 DISPATCHER: Trying to submit another job.
16:48:31 job_callback for (0, 0, 5) got condition
16:48:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:48:31 Only 6 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
16:48:31 HBMASTER: Trying to run another job!
16:48:31 job_callback for (0, 0, 5) finished
16:48:31 start sampling a new configuration.
16:48:31 done sampling a new configuration.
16:48:31 HBMASTER: schedule new run for iteration 0
16:48:31 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
16:48:31 HBMASTER: submitting job (0, 0, 6) to dispatcher
16:48:31 DISPATCHER: trying to submit job (0, 0, 6)
16:48:31 DISPATCHER: trying to notify the job_runner thread.
16:48:31 HBMASTER: job (0, 0, 6) submitted to dispatcher
16:48:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:48:31 DISPATCHER: Trying to submit another job.
16:48:31 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:48:31 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:48:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:48:31 WORKER: start processing job (0, 0, 6)
16:48:31 WORKER: args: ()
16:48:31 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0062369704011065955, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.06591110964351679, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 30, 'num_filters_3': 32, 'num_filters_4': 34, 'num_filters_5': 64}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:49:11 DISPATCHER: Starting worker discovery
16:49:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:49:11 DISPATCHER: Finished worker discovery
16:50:11 DISPATCHER: Starting worker discovery
16:50:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:50:11 DISPATCHER: Finished worker discovery
16:50:12 WORKER: done with job (0, 0, 6), trying to register it.
16:50:12 WORKER: registered result for job (0, 0, 6) with dispatcher
16:50:12 DISPATCHER: job (0, 0, 6) finished
16:50:12 DISPATCHER: register_result: lock acquired
16:50:12 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
16:50:12 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0062369704011065955, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.06591110964351679, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 30, 'num_filters_3': 32, 'num_filters_4': 34, 'num_filters_5': 64}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.19560364048505632, 'info': {'music_genre': 0.19560364048505632, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0062369704011065955, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.06591110964351679, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 30, 'num_filters_3': 32, 'num_filters_4': 34, 'num_filters_5': 64}"}}
exception: None

16:50:12 job_callback for (0, 0, 6) started
16:50:12 DISPATCHER: Trying to submit another job.
16:50:12 job_callback for (0, 0, 6) got condition
16:50:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:50:12 Only 7 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
16:50:12 HBMASTER: Trying to run another job!
16:50:12 job_callback for (0, 0, 6) finished
16:50:12 start sampling a new configuration.
16:50:12 done sampling a new configuration.
16:50:12 HBMASTER: schedule new run for iteration 0
16:50:12 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
16:50:12 HBMASTER: submitting job (0, 0, 7) to dispatcher
16:50:12 DISPATCHER: trying to submit job (0, 0, 7)
16:50:12 DISPATCHER: trying to notify the job_runner thread.
16:50:12 HBMASTER: job (0, 0, 7) submitted to dispatcher
16:50:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:50:12 DISPATCHER: Trying to submit another job.
16:50:12 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:50:12 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:50:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:50:12 WORKER: start processing job (0, 0, 7)
16:50:12 WORKER: args: ()
16:50:12 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.001976271345108419, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.030339581217738054, 'kernel_size_2': 7, 'num_filters_2': 37}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:51:11 DISPATCHER: Starting worker discovery
16:51:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:51:11 DISPATCHER: Finished worker discovery
16:51:55 WORKER: done with job (0, 0, 7), trying to register it.
16:51:55 WORKER: registered result for job (0, 0, 7) with dispatcher
16:51:55 DISPATCHER: job (0, 0, 7) finished
16:51:55 DISPATCHER: register_result: lock acquired
16:51:55 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
16:51:55 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.001976271345108419, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.030339581217738054, 'kernel_size_2': 7, 'num_filters_2': 37}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4571206788697602, 'info': {'music_genre': 0.4571206788697602, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.001976271345108419, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.030339581217738054, 'kernel_size_2': 7, 'num_filters_2': 37}"}}
exception: None

16:51:55 job_callback for (0, 0, 7) started
16:51:55 DISPATCHER: Trying to submit another job.
16:51:55 job_callback for (0, 0, 7) got condition
16:51:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:51:55 Only 8 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
16:51:55 HBMASTER: Trying to run another job!
16:51:55 job_callback for (0, 0, 7) finished
16:51:55 start sampling a new configuration.
16:51:55 done sampling a new configuration.
16:51:55 HBMASTER: schedule new run for iteration 0
16:51:55 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
16:51:55 HBMASTER: submitting job (0, 0, 8) to dispatcher
16:51:55 DISPATCHER: trying to submit job (0, 0, 8)
16:51:55 DISPATCHER: trying to notify the job_runner thread.
16:51:55 HBMASTER: job (0, 0, 8) submitted to dispatcher
16:51:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:51:55 DISPATCHER: Trying to submit another job.
16:51:55 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:51:55 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:51:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:51:55 WORKER: start processing job (0, 0, 8)
16:51:55 WORKER: args: ()
16:51:55 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.005644335055894565, 'num_filters_1': 82, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.014262716689586001, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 68, 'num_filters_3': 62, 'num_filters_4': 29, 'num_filters_5': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:52:11 DISPATCHER: Starting worker discovery
16:52:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:52:11 DISPATCHER: Finished worker discovery
16:53:11 DISPATCHER: Starting worker discovery
16:53:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:53:11 DISPATCHER: Finished worker discovery
16:53:39 WORKER: done with job (0, 0, 8), trying to register it.
16:53:39 WORKER: registered result for job (0, 0, 8) with dispatcher
16:53:39 DISPATCHER: job (0, 0, 8) finished
16:53:39 DISPATCHER: register_result: lock acquired
16:53:39 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
16:53:39 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.005644335055894565, 'num_filters_1': 82, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.014262716689586001, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 68, 'num_filters_3': 62, 'num_filters_4': 29, 'num_filters_5': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.43928647420134603, 'info': {'music_genre': 0.43928647420134603, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.005644335055894565, 'num_filters_1': 82, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.014262716689586001, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 68, 'num_filters_3': 62, 'num_filters_4': 29, 'num_filters_5': 17}"}}
exception: None

16:53:39 job_callback for (0, 0, 8) started
16:53:39 job_callback for (0, 0, 8) got condition
16:53:39 DISPATCHER: Trying to submit another job.
16:53:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:53:39 Only 9 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
16:53:39 HBMASTER: Trying to run another job!
16:53:39 job_callback for (0, 0, 8) finished
16:53:39 start sampling a new configuration.
16:53:39 done sampling a new configuration.
16:53:39 HBMASTER: schedule new run for iteration 0
16:53:39 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
16:53:39 HBMASTER: submitting job (0, 0, 9) to dispatcher
16:53:39 DISPATCHER: trying to submit job (0, 0, 9)
16:53:39 DISPATCHER: trying to notify the job_runner thread.
16:53:39 HBMASTER: job (0, 0, 9) submitted to dispatcher
16:53:39 DISPATCHER: Trying to submit another job.
16:53:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:53:39 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:53:39 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:53:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:53:39 WORKER: start processing job (0, 0, 9)
16:53:39 WORKER: args: ()
16:53:39 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.02294123577973584, 'num_filters_1': 47, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.016410659730350587, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 75, 'num_filters_3': 43}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:54:11 DISPATCHER: Starting worker discovery
16:54:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:54:11 DISPATCHER: Finished worker discovery
16:55:11 DISPATCHER: Starting worker discovery
16:55:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:55:11 DISPATCHER: Finished worker discovery
16:55:22 WORKER: done with job (0, 0, 9), trying to register it.
16:55:22 WORKER: registered result for job (0, 0, 9) with dispatcher
16:55:22 DISPATCHER: job (0, 0, 9) finished
16:55:22 DISPATCHER: register_result: lock acquired
16:55:22 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
16:55:22 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.02294123577973584, 'num_filters_1': 47, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.016410659730350587, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 75, 'num_filters_3': 43}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.34715805947853146, 'info': {'music_genre': 0.34715805947853146, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.02294123577973584, 'num_filters_1': 47, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.016410659730350587, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 75, 'num_filters_3': 43}"}}
exception: None

16:55:22 job_callback for (0, 0, 9) started
16:55:22 job_callback for (0, 0, 9) got condition
16:55:22 DISPATCHER: Trying to submit another job.
16:55:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:55:22 Only 10 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
16:55:22 HBMASTER: Trying to run another job!
16:55:22 job_callback for (0, 0, 9) finished
16:55:22 start sampling a new configuration.
16:55:22 done sampling a new configuration.
16:55:22 HBMASTER: schedule new run for iteration 0
16:55:22 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
16:55:22 HBMASTER: submitting job (0, 0, 10) to dispatcher
16:55:22 DISPATCHER: trying to submit job (0, 0, 10)
16:55:22 DISPATCHER: trying to notify the job_runner thread.
16:55:22 HBMASTER: job (0, 0, 10) submitted to dispatcher
16:55:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:55:22 DISPATCHER: Trying to submit another job.
16:55:22 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:55:22 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:55:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:55:22 WORKER: start processing job (0, 0, 10)
16:55:22 WORKER: args: ()
16:55:22 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.025435240659368755, 'num_filters_1': 102, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.05565894675380406, 'kernel_size_2': 3, 'num_filters_2': 102}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:56:11 DISPATCHER: Starting worker discovery
16:56:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:56:11 DISPATCHER: Finished worker discovery
16:57:04 WORKER: done with job (0, 0, 10), trying to register it.
16:57:04 WORKER: registered result for job (0, 0, 10) with dispatcher
16:57:04 DISPATCHER: job (0, 0, 10) finished
16:57:04 DISPATCHER: register_result: lock acquired
16:57:04 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
16:57:04 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.025435240659368755, 'num_filters_1': 102, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.05565894675380406, 'kernel_size_2': 3, 'num_filters_2': 102}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1361242316523166, 'info': {'music_genre': 0.1361242316523166, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.025435240659368755, 'num_filters_1': 102, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.05565894675380406, 'kernel_size_2': 3, 'num_filters_2': 102}"}}
exception: None

16:57:04 job_callback for (0, 0, 10) started
16:57:04 job_callback for (0, 0, 10) got condition
16:57:04 DISPATCHER: Trying to submit another job.
16:57:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:57:04 Only 11 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
16:57:04 HBMASTER: Trying to run another job!
16:57:04 job_callback for (0, 0, 10) finished
16:57:04 start sampling a new configuration.
16:57:04 done sampling a new configuration.
16:57:04 HBMASTER: schedule new run for iteration 0
16:57:04 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
16:57:04 HBMASTER: submitting job (0, 0, 11) to dispatcher
16:57:04 DISPATCHER: trying to submit job (0, 0, 11)
16:57:04 DISPATCHER: trying to notify the job_runner thread.
16:57:04 HBMASTER: job (0, 0, 11) submitted to dispatcher
16:57:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:57:04 DISPATCHER: Trying to submit another job.
16:57:04 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:57:04 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:57:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:57:04 WORKER: start processing job (0, 0, 11)
16:57:04 WORKER: args: ()
16:57:04 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.007902216804721801, 'num_filters_1': 60, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.1062714730039958, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 41, 'num_filters_3': 30}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:57:11 DISPATCHER: Starting worker discovery
16:57:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:57:11 DISPATCHER: Finished worker discovery
16:58:11 DISPATCHER: Starting worker discovery
16:58:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:58:11 DISPATCHER: Finished worker discovery
16:58:46 WORKER: done with job (0, 0, 11), trying to register it.
16:58:46 WORKER: registered result for job (0, 0, 11) with dispatcher
16:58:46 DISPATCHER: job (0, 0, 11) finished
16:58:46 DISPATCHER: register_result: lock acquired
16:58:46 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
16:58:46 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.007902216804721801, 'num_filters_1': 60, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.1062714730039958, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 41, 'num_filters_3': 30}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.007902216804721801, 'num_filters_1': 60, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.1062714730039958, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 41, 'num_filters_3': 30}"}}
exception: None

16:58:46 job_callback for (0, 0, 11) started
16:58:46 job_callback for (0, 0, 11) got condition
16:58:46 DISPATCHER: Trying to submit another job.
16:58:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:58:46 Only 12 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
16:58:46 HBMASTER: Trying to run another job!
16:58:46 job_callback for (0, 0, 11) finished
16:58:46 start sampling a new configuration.
16:58:46 done sampling a new configuration.
16:58:46 HBMASTER: schedule new run for iteration 0
16:58:46 HBMASTER: trying submitting job (0, 0, 12) to dispatcher
16:58:46 HBMASTER: submitting job (0, 0, 12) to dispatcher
16:58:46 DISPATCHER: trying to submit job (0, 0, 12)
16:58:46 DISPATCHER: trying to notify the job_runner thread.
16:58:46 HBMASTER: job (0, 0, 12) submitted to dispatcher
16:58:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:58:46 DISPATCHER: Trying to submit another job.
16:58:46 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:58:46 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
16:58:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:58:46 WORKER: start processing job (0, 0, 12)
16:58:46 WORKER: args: ()
16:58:46 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.017019129927908945, 'num_filters_1': 69, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.019836231385581386}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:59:11 DISPATCHER: Starting worker discovery
16:59:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:59:11 DISPATCHER: Finished worker discovery
17:00:11 DISPATCHER: Starting worker discovery
17:00:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:00:11 DISPATCHER: Finished worker discovery
17:00:28 WORKER: done with job (0, 0, 12), trying to register it.
17:00:28 WORKER: registered result for job (0, 0, 12) with dispatcher
17:00:28 DISPATCHER: job (0, 0, 12) finished
17:00:28 DISPATCHER: register_result: lock acquired
17:00:28 DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
17:00:28 job_id: (0, 0, 12)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.017019129927908945, 'num_filters_1': 69, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.019836231385581386}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.14187181311379016, 'info': {'music_genre': 0.14187181311379016, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.017019129927908945, 'num_filters_1': 69, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.019836231385581386}"}}
exception: None

17:00:28 job_callback for (0, 0, 12) started
17:00:28 DISPATCHER: Trying to submit another job.
17:00:28 job_callback for (0, 0, 12) got condition
17:00:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:00:28 Only 13 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
17:00:28 HBMASTER: Trying to run another job!
17:00:28 job_callback for (0, 0, 12) finished
17:00:28 start sampling a new configuration.
17:00:28 done sampling a new configuration.
17:00:28 HBMASTER: schedule new run for iteration 0
17:00:28 HBMASTER: trying submitting job (0, 0, 13) to dispatcher
17:00:28 HBMASTER: submitting job (0, 0, 13) to dispatcher
17:00:28 DISPATCHER: trying to submit job (0, 0, 13)
17:00:28 DISPATCHER: trying to notify the job_runner thread.
17:00:28 HBMASTER: job (0, 0, 13) submitted to dispatcher
17:00:28 DISPATCHER: Trying to submit another job.
17:00:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:00:28 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:00:28 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:00:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:00:28 WORKER: start processing job (0, 0, 13)
17:00:28 WORKER: args: ()
17:00:28 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.014233952682922676, 'num_filters_1': 23, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.07582218148971752, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 71, 'num_filters_3': 26, 'num_filters_4': 38}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:01:11 DISPATCHER: Starting worker discovery
17:01:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:01:11 DISPATCHER: Finished worker discovery
17:02:11 WORKER: done with job (0, 0, 13), trying to register it.
17:02:11 WORKER: registered result for job (0, 0, 13) with dispatcher
17:02:11 DISPATCHER: job (0, 0, 13) finished
17:02:11 DISPATCHER: register_result: lock acquired
17:02:11 DISPATCHER: job (0, 0, 13) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
17:02:11 job_id: (0, 0, 13)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.014233952682922676, 'num_filters_1': 23, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.07582218148971752, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 71, 'num_filters_3': 26, 'num_filters_4': 38}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2555113083364025, 'info': {'music_genre': 0.2555113083364025, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.014233952682922676, 'num_filters_1': 23, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.07582218148971752, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 71, 'num_filters_3': 26, 'num_filters_4': 38}"}}
exception: None

17:02:11 job_callback for (0, 0, 13) started
17:02:11 job_callback for (0, 0, 13) got condition
17:02:11 DISPATCHER: Trying to submit another job.
17:02:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:02:11 Only 14 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
17:02:11 HBMASTER: Trying to run another job!
17:02:11 job_callback for (0, 0, 13) finished
17:02:11 start sampling a new configuration.
17:02:11 done sampling a new configuration.
17:02:11 HBMASTER: schedule new run for iteration 0
17:02:11 HBMASTER: trying submitting job (0, 0, 14) to dispatcher
17:02:11 HBMASTER: submitting job (0, 0, 14) to dispatcher
17:02:11 DISPATCHER: trying to submit job (0, 0, 14)
17:02:11 DISPATCHER: trying to notify the job_runner thread.
17:02:11 HBMASTER: job (0, 0, 14) submitted to dispatcher
17:02:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:02:11 DISPATCHER: Trying to submit another job.
17:02:11 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:02:11 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:02:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:02:11 WORKER: start processing job (0, 0, 14)
17:02:11 WORKER: args: ()
17:02:11 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0011541702154325329, 'num_filters_1': 26, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.021857304788995138, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 109, 'num_filters_3': 27}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:02:11 DISPATCHER: Starting worker discovery
17:02:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:02:11 DISPATCHER: Finished worker discovery
17:03:11 DISPATCHER: Starting worker discovery
17:03:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:03:11 DISPATCHER: Finished worker discovery
17:03:51 WORKER: done with job (0, 0, 14), trying to register it.
17:03:51 WORKER: registered result for job (0, 0, 14) with dispatcher
17:03:51 DISPATCHER: job (0, 0, 14) finished
17:03:51 DISPATCHER: register_result: lock acquired
17:03:51 DISPATCHER: job (0, 0, 14) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
17:03:51 job_id: (0, 0, 14)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0011541702154325329, 'num_filters_1': 26, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.021857304788995138, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 109, 'num_filters_3': 27}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1842335866930104, 'info': {'music_genre': 0.1842335866930104, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0011541702154325329, 'num_filters_1': 26, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.021857304788995138, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 109, 'num_filters_3': 27}"}}
exception: None

17:03:51 job_callback for (0, 0, 14) started
17:03:51 job_callback for (0, 0, 14) got condition
17:03:51 DISPATCHER: Trying to submit another job.
17:03:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:03:51 Only 15 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
17:03:51 HBMASTER: Trying to run another job!
17:03:51 job_callback for (0, 0, 14) finished
17:03:51 start sampling a new configuration.
17:03:51 done sampling a new configuration.
17:03:51 HBMASTER: schedule new run for iteration 0
17:03:51 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
17:03:51 HBMASTER: submitting job (0, 0, 15) to dispatcher
17:03:51 DISPATCHER: trying to submit job (0, 0, 15)
17:03:51 DISPATCHER: trying to notify the job_runner thread.
17:03:51 HBMASTER: job (0, 0, 15) submitted to dispatcher
17:03:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:03:51 DISPATCHER: Trying to submit another job.
17:03:51 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:03:51 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:03:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:03:51 WORKER: start processing job (0, 0, 15)
17:03:51 WORKER: args: ()
17:03:51 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.011805319430344227, 'num_filters_1': 76, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.04941608431749635, 'kernel_size_2': 5, 'num_filters_2': 98}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:04:11 DISPATCHER: Starting worker discovery
17:04:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:04:11 DISPATCHER: Finished worker discovery
17:05:11 DISPATCHER: Starting worker discovery
17:05:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:05:11 DISPATCHER: Finished worker discovery
17:05:33 WORKER: done with job (0, 0, 15), trying to register it.
17:05:33 WORKER: registered result for job (0, 0, 15) with dispatcher
17:05:33 DISPATCHER: job (0, 0, 15) finished
17:05:33 DISPATCHER: register_result: lock acquired
17:05:33 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
17:05:33 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.011805319430344227, 'num_filters_1': 76, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.04941608431749635, 'kernel_size_2': 5, 'num_filters_2': 98}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.00047756622138464305, 'info': {'music_genre': 0.00047756622138464305, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.011805319430344227, 'num_filters_1': 76, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.04941608431749635, 'kernel_size_2': 5, 'num_filters_2': 98}"}}
exception: None

17:05:33 job_callback for (0, 0, 15) started
17:05:33 DISPATCHER: Trying to submit another job.
17:05:33 job_callback for (0, 0, 15) got condition
17:05:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:05:33 Only 16 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
17:05:33 HBMASTER: Trying to run another job!
17:05:33 job_callback for (0, 0, 15) finished
17:05:33 start sampling a new configuration.
17:05:33 done sampling a new configuration.
17:05:33 HBMASTER: schedule new run for iteration 0
17:05:33 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
17:05:33 HBMASTER: submitting job (0, 0, 16) to dispatcher
17:05:33 DISPATCHER: trying to submit job (0, 0, 16)
17:05:33 DISPATCHER: trying to notify the job_runner thread.
17:05:33 HBMASTER: job (0, 0, 16) submitted to dispatcher
17:05:33 DISPATCHER: Trying to submit another job.
17:05:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:05:33 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:05:33 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:05:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:05:33 WORKER: start processing job (0, 0, 16)
17:05:33 WORKER: args: ()
17:05:33 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0019457452863771635, 'num_filters_1': 32, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.023147553472707572}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:06:11 DISPATCHER: Starting worker discovery
17:06:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:06:11 DISPATCHER: Finished worker discovery
17:07:11 DISPATCHER: Starting worker discovery
17:07:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:07:11 DISPATCHER: Finished worker discovery
17:07:14 WORKER: done with job (0, 0, 16), trying to register it.
17:07:14 WORKER: registered result for job (0, 0, 16) with dispatcher
17:07:14 DISPATCHER: job (0, 0, 16) finished
17:07:14 DISPATCHER: register_result: lock acquired
17:07:14 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
17:07:14 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0019457452863771635, 'num_filters_1': 32, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.023147553472707572}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2110810541539015, 'info': {'music_genre': 0.2110810541539015, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0019457452863771635, 'num_filters_1': 32, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.023147553472707572}"}}
exception: None

17:07:14 job_callback for (0, 0, 16) started
17:07:14 DISPATCHER: Trying to submit another job.
17:07:14 job_callback for (0, 0, 16) got condition
17:07:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:07:14 HBMASTER: Trying to run another job!
17:07:14 job_callback for (0, 0, 16) finished
17:07:14 start sampling a new configuration.
17:07:14 done sampling a new configuration.
17:07:14 HBMASTER: schedule new run for iteration 0
17:07:14 HBMASTER: trying submitting job (0, 0, 17) to dispatcher
17:07:14 HBMASTER: submitting job (0, 0, 17) to dispatcher
17:07:14 DISPATCHER: trying to submit job (0, 0, 17)
17:07:14 DISPATCHER: trying to notify the job_runner thread.
17:07:14 HBMASTER: job (0, 0, 17) submitted to dispatcher
17:07:14 DISPATCHER: Trying to submit another job.
17:07:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:07:14 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:07:14 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:07:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:07:14 WORKER: start processing job (0, 0, 17)
17:07:14 WORKER: args: ()
17:07:14 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.07606945988546933, 'num_filters_1': 16, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.017914626303188057, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 45, 'num_filters_3': 24}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-619:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 4607182418800017408 is out of bounds for axis 0 with size 10

17:08:11 DISPATCHER: Starting worker discovery
17:08:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:08:11 DISPATCHER: Finished worker discovery
17:08:54 WORKER: done with job (0, 0, 17), trying to register it.
17:08:54 WORKER: registered result for job (0, 0, 17) with dispatcher
17:08:54 DISPATCHER: job (0, 0, 17) finished
17:08:54 DISPATCHER: register_result: lock acquired
17:08:54 DISPATCHER: job (0, 0, 17) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
17:08:54 job_id: (0, 0, 17)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.07606945988546933, 'num_filters_1': 16, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.017914626303188057, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 45, 'num_filters_3': 24}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3206232514095119, 'info': {'music_genre': 0.3206232514095119, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.07606945988546933, 'num_filters_1': 16, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.017914626303188057, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 45, 'num_filters_3': 24}"}}
exception: None

17:08:54 job_callback for (0, 0, 17) started
17:08:54 job_callback for (0, 0, 17) got condition
17:08:54 DISPATCHER: Trying to submit another job.
17:08:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:08:54 HBMASTER: Trying to run another job!
17:08:54 job_callback for (0, 0, 17) finished
17:08:54 start sampling a new configuration.
17:08:54 done sampling a new configuration.
17:08:54 HBMASTER: schedule new run for iteration 0
17:08:54 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
17:08:54 HBMASTER: submitting job (0, 0, 18) to dispatcher
17:08:54 DISPATCHER: trying to submit job (0, 0, 18)
17:08:54 DISPATCHER: trying to notify the job_runner thread.
17:08:54 HBMASTER: job (0, 0, 18) submitted to dispatcher
17:08:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:08:54 DISPATCHER: Trying to submit another job.
17:08:54 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:08:54 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:08:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:08:54 WORKER: start processing job (0, 0, 18)
17:08:54 WORKER: args: ()
17:08:54 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.011130613387139613, 'num_filters_1': 103, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.10365286405378438, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 39, 'num_filters_3': 22}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:09:11 DISPATCHER: Starting worker discovery
17:09:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:09:12 DISPATCHER: Finished worker discovery
17:10:12 DISPATCHER: Starting worker discovery
17:10:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:10:12 DISPATCHER: Finished worker discovery
17:10:35 WORKER: done with job (0, 0, 18), trying to register it.
17:10:36 WORKER: registered result for job (0, 0, 18) with dispatcher
17:10:36 DISPATCHER: job (0, 0, 18) finished
17:10:36 DISPATCHER: register_result: lock acquired
17:10:36 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
17:10:36 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.011130613387139613, 'num_filters_1': 103, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.10365286405378438, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 39, 'num_filters_3': 22}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.14627255298535163, 'info': {'music_genre': 0.14627255298535163, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.011130613387139613, 'num_filters_1': 103, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.10365286405378438, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 39, 'num_filters_3': 22}"}}
exception: None

17:10:36 job_callback for (0, 0, 18) started
17:10:36 job_callback for (0, 0, 18) got condition
17:10:36 DISPATCHER: Trying to submit another job.
17:10:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:10:36 HBMASTER: Trying to run another job!
17:10:36 job_callback for (0, 0, 18) finished
17:10:36 start sampling a new configuration.
17:10:36 done sampling a new configuration.
17:10:36 HBMASTER: schedule new run for iteration 0
17:10:36 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
17:10:36 HBMASTER: submitting job (0, 0, 19) to dispatcher
17:10:36 DISPATCHER: trying to submit job (0, 0, 19)
17:10:36 DISPATCHER: trying to notify the job_runner thread.
17:10:36 HBMASTER: job (0, 0, 19) submitted to dispatcher
17:10:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:10:36 DISPATCHER: Trying to submit another job.
17:10:36 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:10:36 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:10:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:10:36 WORKER: start processing job (0, 0, 19)
17:10:36 WORKER: args: ()
17:10:36 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0018016970705864075, 'num_filters_1': 110, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.14165090431484575, 'kernel_size_2': 5, 'num_filters_2': 91}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:11:12 DISPATCHER: Starting worker discovery
17:11:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:11:12 DISPATCHER: Finished worker discovery
17:12:12 DISPATCHER: Starting worker discovery
17:12:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:12:12 DISPATCHER: Finished worker discovery
17:12:17 WORKER: done with job (0, 0, 19), trying to register it.
17:12:17 WORKER: registered result for job (0, 0, 19) with dispatcher
17:12:17 DISPATCHER: job (0, 0, 19) finished
17:12:17 DISPATCHER: register_result: lock acquired
17:12:17 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
17:12:17 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0018016970705864075, 'num_filters_1': 110, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.14165090431484575, 'kernel_size_2': 5, 'num_filters_2': 91}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4254127734738106, 'info': {'music_genre': 0.4254127734738106, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0018016970705864075, 'num_filters_1': 110, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.14165090431484575, 'kernel_size_2': 5, 'num_filters_2': 91}"}}
exception: None

17:12:17 job_callback for (0, 0, 19) started
17:12:17 job_callback for (0, 0, 19) got condition
17:12:17 DISPATCHER: Trying to submit another job.
17:12:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:12:17 HBMASTER: Trying to run another job!
17:12:17 job_callback for (0, 0, 19) finished
17:12:17 start sampling a new configuration.
17:12:17 done sampling a new configuration.
17:12:17 HBMASTER: schedule new run for iteration 0
17:12:17 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
17:12:17 HBMASTER: submitting job (0, 0, 20) to dispatcher
17:12:17 DISPATCHER: trying to submit job (0, 0, 20)
17:12:17 DISPATCHER: trying to notify the job_runner thread.
17:12:17 HBMASTER: job (0, 0, 20) submitted to dispatcher
17:12:17 DISPATCHER: Trying to submit another job.
17:12:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:12:17 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:12:17 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:12:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:12:17 WORKER: start processing job (0, 0, 20)
17:12:17 WORKER: args: ()
17:12:17 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001141811053703833, 'num_filters_1': 83, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.03447065014488159, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 78, 'num_filters_3': 50, 'num_filters_4': 94, 'num_filters_5': 56}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:13:12 DISPATCHER: Starting worker discovery
17:13:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:13:12 DISPATCHER: Finished worker discovery
17:14:01 WORKER: done with job (0, 0, 20), trying to register it.
17:14:01 WORKER: registered result for job (0, 0, 20) with dispatcher
17:14:01 DISPATCHER: job (0, 0, 20) finished
17:14:01 DISPATCHER: register_result: lock acquired
17:14:01 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
17:14:01 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001141811053703833, 'num_filters_1': 83, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.03447065014488159, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 78, 'num_filters_3': 50, 'num_filters_4': 94, 'num_filters_5': 56}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4201908275435946, 'info': {'music_genre': 0.4201908275435946, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001141811053703833, 'num_filters_1': 83, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.03447065014488159, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 78, 'num_filters_3': 50, 'num_filters_4': 94, 'num_filters_5': 56}"}}
exception: None

17:14:01 job_callback for (0, 0, 20) started
17:14:01 job_callback for (0, 0, 20) got condition
17:14:01 DISPATCHER: Trying to submit another job.
17:14:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:14:01 HBMASTER: Trying to run another job!
17:14:01 job_callback for (0, 0, 20) finished
17:14:01 start sampling a new configuration.
17:14:01 done sampling a new configuration.
17:14:01 HBMASTER: schedule new run for iteration 0
17:14:01 HBMASTER: trying submitting job (0, 0, 21) to dispatcher
17:14:01 HBMASTER: submitting job (0, 0, 21) to dispatcher
17:14:01 DISPATCHER: trying to submit job (0, 0, 21)
17:14:01 DISPATCHER: trying to notify the job_runner thread.
17:14:01 HBMASTER: job (0, 0, 21) submitted to dispatcher
17:14:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:14:01 DISPATCHER: Trying to submit another job.
17:14:01 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:14:01 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:14:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:14:01 WORKER: start processing job (0, 0, 21)
17:14:01 WORKER: args: ()
17:14:01 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0014055814790224377, 'num_filters_1': 67, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.05804416826463579, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 57, 'num_filters_3': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:14:12 DISPATCHER: Starting worker discovery
17:14:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:14:12 DISPATCHER: Finished worker discovery
17:15:12 DISPATCHER: Starting worker discovery
17:15:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:15:12 DISPATCHER: Finished worker discovery
17:15:44 WORKER: done with job (0, 0, 21), trying to register it.
17:15:44 WORKER: registered result for job (0, 0, 21) with dispatcher
17:15:44 DISPATCHER: job (0, 0, 21) finished
17:15:44 DISPATCHER: register_result: lock acquired
17:15:44 DISPATCHER: job (0, 0, 21) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
17:15:44 job_id: (0, 0, 21)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0014055814790224377, 'num_filters_1': 67, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.05804416826463579, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 57, 'num_filters_3': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.17737602166335428, 'info': {'music_genre': 0.17737602166335428, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0014055814790224377, 'num_filters_1': 67, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.05804416826463579, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 57, 'num_filters_3': 16}"}}
exception: None

17:15:44 job_callback for (0, 0, 21) started
17:15:44 job_callback for (0, 0, 21) got condition
17:15:44 DISPATCHER: Trying to submit another job.
17:15:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:15:44 HBMASTER: Trying to run another job!
17:15:44 job_callback for (0, 0, 21) finished
17:15:44 start sampling a new configuration.
17:15:44 done sampling a new configuration.
17:15:44 HBMASTER: schedule new run for iteration 0
17:15:44 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
17:15:44 HBMASTER: submitting job (0, 0, 22) to dispatcher
17:15:44 DISPATCHER: trying to submit job (0, 0, 22)
17:15:44 DISPATCHER: trying to notify the job_runner thread.
17:15:44 HBMASTER: job (0, 0, 22) submitted to dispatcher
17:15:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:15:44 DISPATCHER: Trying to submit another job.
17:15:44 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:15:44 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:15:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:15:44 WORKER: start processing job (0, 0, 22)
17:15:44 WORKER: args: ()
17:15:44 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.007318804668134622, 'num_filters_1': 21, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.1328650499859262}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:16:12 DISPATCHER: Starting worker discovery
17:16:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:16:12 DISPATCHER: Finished worker discovery
17:17:12 DISPATCHER: Starting worker discovery
17:17:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:17:12 DISPATCHER: Finished worker discovery
17:17:27 WORKER: done with job (0, 0, 22), trying to register it.
17:17:27 WORKER: registered result for job (0, 0, 22) with dispatcher
17:17:27 DISPATCHER: job (0, 0, 22) finished
17:17:27 DISPATCHER: register_result: lock acquired
17:17:27 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
17:17:27 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.007318804668134622, 'num_filters_1': 21, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.1328650499859262}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.32867710729920374, 'info': {'music_genre': 0.32867710729920374, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.007318804668134622, 'num_filters_1': 21, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.1328650499859262}"}}
exception: None

17:17:27 job_callback for (0, 0, 22) started
17:17:27 job_callback for (0, 0, 22) got condition
17:17:27 DISPATCHER: Trying to submit another job.
17:17:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:17:27 HBMASTER: Trying to run another job!
17:17:27 job_callback for (0, 0, 22) finished
17:17:27 start sampling a new configuration.
17:17:27 done sampling a new configuration.
17:17:27 HBMASTER: schedule new run for iteration 0
17:17:27 HBMASTER: trying submitting job (0, 0, 23) to dispatcher
17:17:27 HBMASTER: submitting job (0, 0, 23) to dispatcher
17:17:27 DISPATCHER: trying to submit job (0, 0, 23)
17:17:27 DISPATCHER: trying to notify the job_runner thread.
17:17:27 HBMASTER: job (0, 0, 23) submitted to dispatcher
17:17:27 DISPATCHER: Trying to submit another job.
17:17:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:17:27 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:17:27 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:17:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:17:27 WORKER: start processing job (0, 0, 23)
17:17:27 WORKER: args: ()
17:17:27 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.004826809257563524, 'num_filters_1': 25, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.19065173907721839}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:18:12 DISPATCHER: Starting worker discovery
17:18:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:18:12 DISPATCHER: Finished worker discovery
17:19:09 WORKER: done with job (0, 0, 23), trying to register it.
17:19:09 WORKER: registered result for job (0, 0, 23) with dispatcher
17:19:09 DISPATCHER: job (0, 0, 23) finished
17:19:09 DISPATCHER: register_result: lock acquired
17:19:09 DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
17:19:09 job_id: (0, 0, 23)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.004826809257563524, 'num_filters_1': 25, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.19065173907721839}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.10553311815555182, 'info': {'music_genre': 0.10553311815555182, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.004826809257563524, 'num_filters_1': 25, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.19065173907721839}"}}
exception: None

17:19:09 job_callback for (0, 0, 23) started
17:19:09 job_callback for (0, 0, 23) got condition
17:19:09 DISPATCHER: Trying to submit another job.
17:19:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:19:09 HBMASTER: Trying to run another job!
17:19:09 job_callback for (0, 0, 23) finished
17:19:09 start sampling a new configuration.
17:19:09 done sampling a new configuration.
17:19:09 HBMASTER: schedule new run for iteration 0
17:19:09 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
17:19:09 HBMASTER: submitting job (0, 0, 24) to dispatcher
17:19:09 DISPATCHER: trying to submit job (0, 0, 24)
17:19:09 DISPATCHER: trying to notify the job_runner thread.
17:19:09 HBMASTER: job (0, 0, 24) submitted to dispatcher
17:19:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:19:09 DISPATCHER: Trying to submit another job.
17:19:09 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:19:09 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:19:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:19:09 WORKER: start processing job (0, 0, 24)
17:19:09 WORKER: args: ()
17:19:09 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.036356411252759804, 'num_filters_1': 51, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.11936064681397991, 'kernel_size_2': 5, 'num_filters_2': 80}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:19:12 DISPATCHER: Starting worker discovery
17:19:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:19:12 DISPATCHER: Finished worker discovery
17:20:12 DISPATCHER: Starting worker discovery
17:20:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:20:12 DISPATCHER: Finished worker discovery
17:20:53 WORKER: done with job (0, 0, 24), trying to register it.
17:20:53 WORKER: registered result for job (0, 0, 24) with dispatcher
17:20:53 DISPATCHER: job (0, 0, 24) finished
17:20:53 DISPATCHER: register_result: lock acquired
17:20:53 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
17:20:53 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.036356411252759804, 'num_filters_1': 51, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.11936064681397991, 'kernel_size_2': 5, 'num_filters_2': 80}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.24430159036699822, 'info': {'music_genre': 0.24430159036699822, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.036356411252759804, 'num_filters_1': 51, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.11936064681397991, 'kernel_size_2': 5, 'num_filters_2': 80}"}}
exception: None

17:20:53 job_callback for (0, 0, 24) started
17:20:53 job_callback for (0, 0, 24) got condition
17:20:53 DISPATCHER: Trying to submit another job.
17:20:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:20:53 HBMASTER: Trying to run another job!
17:20:53 job_callback for (0, 0, 24) finished
17:20:53 start sampling a new configuration.
17:20:53 done sampling a new configuration.
17:20:53 HBMASTER: schedule new run for iteration 0
17:20:53 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
17:20:53 HBMASTER: submitting job (0, 0, 25) to dispatcher
17:20:53 DISPATCHER: trying to submit job (0, 0, 25)
17:20:53 DISPATCHER: trying to notify the job_runner thread.
17:20:53 HBMASTER: job (0, 0, 25) submitted to dispatcher
17:20:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:20:53 DISPATCHER: Trying to submit another job.
17:20:53 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:20:53 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:20:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:20:53 WORKER: start processing job (0, 0, 25)
17:20:53 WORKER: args: ()
17:20:53 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.07304222333747587, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.05720632622261565}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:21:12 DISPATCHER: Starting worker discovery
17:21:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:21:12 DISPATCHER: Finished worker discovery
17:22:12 DISPATCHER: Starting worker discovery
17:22:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:22:12 DISPATCHER: Finished worker discovery
17:22:35 WORKER: done with job (0, 0, 25), trying to register it.
17:22:35 WORKER: registered result for job (0, 0, 25) with dispatcher
17:22:35 DISPATCHER: job (0, 0, 25) finished
17:22:35 DISPATCHER: register_result: lock acquired
17:22:35 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
17:22:35 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.07304222333747587, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.05720632622261565}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.03450722293102876, 'info': {'music_genre': 0.03450722293102876, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.07304222333747587, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.05720632622261565}"}}
exception: None

17:22:35 job_callback for (0, 0, 25) started
17:22:35 job_callback for (0, 0, 25) got condition
17:22:35 DISPATCHER: Trying to submit another job.
17:22:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:22:35 HBMASTER: Trying to run another job!
17:22:35 job_callback for (0, 0, 25) finished
17:22:35 start sampling a new configuration.
17:22:35 done sampling a new configuration.
17:22:35 HBMASTER: schedule new run for iteration 0
17:22:35 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
17:22:35 HBMASTER: submitting job (0, 0, 26) to dispatcher
17:22:35 DISPATCHER: trying to submit job (0, 0, 26)
17:22:35 DISPATCHER: trying to notify the job_runner thread.
17:22:35 HBMASTER: job (0, 0, 26) submitted to dispatcher
17:22:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:22:35 DISPATCHER: Trying to submit another job.
17:22:35 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:22:35 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:22:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:22:35 WORKER: start processing job (0, 0, 26)
17:22:35 WORKER: args: ()
17:22:35 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.03442229559490088, 'num_filters_1': 83, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.19087296217413577}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:23:12 DISPATCHER: Starting worker discovery
17:23:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:23:12 DISPATCHER: Finished worker discovery
17:24:12 DISPATCHER: Starting worker discovery
17:24:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:24:12 DISPATCHER: Finished worker discovery
17:24:18 WORKER: done with job (0, 0, 26), trying to register it.
17:24:18 WORKER: registered result for job (0, 0, 26) with dispatcher
17:24:18 DISPATCHER: job (0, 0, 26) finished
17:24:18 DISPATCHER: register_result: lock acquired
17:24:18 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
17:24:18 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.03442229559490088, 'num_filters_1': 83, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.19087296217413577}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.27643808215609866, 'info': {'music_genre': 0.27643808215609866, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.03442229559490088, 'num_filters_1': 83, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.19087296217413577}"}}
exception: None

17:24:18 job_callback for (0, 0, 26) started
17:24:18 DISPATCHER: Trying to submit another job.
17:24:18 job_callback for (0, 0, 26) got condition
17:24:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:24:18 HBMASTER: Trying to run another job!
17:24:18 job_callback for (0, 0, 26) finished
17:24:18 ITERATION: Advancing config (0, 0, 0) to next budget 133.333333
17:24:18 ITERATION: Advancing config (0, 0, 3) to next budget 133.333333
17:24:18 ITERATION: Advancing config (0, 0, 4) to next budget 133.333333
17:24:18 ITERATION: Advancing config (0, 0, 5) to next budget 133.333333
17:24:18 ITERATION: Advancing config (0, 0, 7) to next budget 133.333333
17:24:18 ITERATION: Advancing config (0, 0, 8) to next budget 133.333333
17:24:18 ITERATION: Advancing config (0, 0, 9) to next budget 133.333333
17:24:18 ITERATION: Advancing config (0, 0, 19) to next budget 133.333333
17:24:18 ITERATION: Advancing config (0, 0, 20) to next budget 133.333333
17:24:18 HBMASTER: schedule new run for iteration 0
17:24:18 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
17:24:18 HBMASTER: submitting job (0, 0, 0) to dispatcher
17:24:18 DISPATCHER: trying to submit job (0, 0, 0)
17:24:18 DISPATCHER: trying to notify the job_runner thread.
17:24:18 HBMASTER: job (0, 0, 0) submitted to dispatcher
17:24:18 DISPATCHER: Trying to submit another job.
17:24:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:24:18 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:24:18 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:24:18 WORKER: start processing job (0, 0, 0)
17:24:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:24:18 WORKER: args: ()
17:24:18 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0010910752200006524, 'num_filters_1': 44, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.010542450616706531, 'kernel_size_2': 5, 'num_filters_2': 44}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:25:12 DISPATCHER: Starting worker discovery
17:25:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:25:12 DISPATCHER: Finished worker discovery
17:26:12 DISPATCHER: Starting worker discovery
17:26:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:26:12 DISPATCHER: Finished worker discovery
17:27:12 DISPATCHER: Starting worker discovery
17:27:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:27:12 DISPATCHER: Finished worker discovery
17:27:34 WORKER: done with job (0, 0, 0), trying to register it.
17:27:34 WORKER: registered result for job (0, 0, 0) with dispatcher
17:27:34 DISPATCHER: job (0, 0, 0) finished
17:27:34 DISPATCHER: register_result: lock acquired
17:27:34 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
17:27:34 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0010910752200006524, 'num_filters_1': 44, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.010542450616706531, 'kernel_size_2': 5, 'num_filters_2': 44}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.43383912056113644, 'info': {'music_genre': 0.43383912056113644, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0010910752200006524, 'num_filters_1': 44, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.010542450616706531, 'kernel_size_2': 5, 'num_filters_2': 44}"}}
exception: None

17:27:34 job_callback for (0, 0, 0) started
17:27:34 job_callback for (0, 0, 0) got condition
17:27:34 DISPATCHER: Trying to submit another job.
17:27:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:27:34 Only 1 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
17:27:34 HBMASTER: Trying to run another job!
17:27:34 job_callback for (0, 0, 0) finished
17:27:34 HBMASTER: schedule new run for iteration 0
17:27:34 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
17:27:34 HBMASTER: submitting job (0, 0, 3) to dispatcher
17:27:34 DISPATCHER: trying to submit job (0, 0, 3)
17:27:34 DISPATCHER: trying to notify the job_runner thread.
17:27:34 HBMASTER: job (0, 0, 3) submitted to dispatcher
17:27:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:27:34 DISPATCHER: Trying to submit another job.
17:27:34 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:27:34 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:27:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:27:34 WORKER: start processing job (0, 0, 3)
17:27:34 WORKER: args: ()
17:27:34 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.004182283607576557, 'num_filters_1': 92, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.0642265623614919, 'kernel_size_2': 7, 'num_filters_2': 79}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:28:12 DISPATCHER: Starting worker discovery
17:28:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:28:12 DISPATCHER: Finished worker discovery
17:29:12 DISPATCHER: Starting worker discovery
17:29:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:29:12 DISPATCHER: Finished worker discovery
17:30:12 DISPATCHER: Starting worker discovery
17:30:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:30:12 DISPATCHER: Finished worker discovery
17:30:46 WORKER: done with job (0, 0, 3), trying to register it.
17:30:46 WORKER: registered result for job (0, 0, 3) with dispatcher
17:30:46 DISPATCHER: job (0, 0, 3) finished
17:30:46 DISPATCHER: register_result: lock acquired
17:30:46 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
17:30:46 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.004182283607576557, 'num_filters_1': 92, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.0642265623614919, 'kernel_size_2': 7, 'num_filters_2': 79}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3516596954251515, 'info': {'music_genre': 0.3516596954251515, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.004182283607576557, 'num_filters_1': 92, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.0642265623614919, 'kernel_size_2': 7, 'num_filters_2': 79}"}}
exception: None

17:30:46 job_callback for (0, 0, 3) started
17:30:46 job_callback for (0, 0, 3) got condition
17:30:46 DISPATCHER: Trying to submit another job.
17:30:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:30:46 Only 2 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
17:30:46 HBMASTER: Trying to run another job!
17:30:46 job_callback for (0, 0, 3) finished
17:30:46 HBMASTER: schedule new run for iteration 0
17:30:46 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
17:30:46 HBMASTER: submitting job (0, 0, 4) to dispatcher
17:30:46 DISPATCHER: trying to submit job (0, 0, 4)
17:30:46 DISPATCHER: trying to notify the job_runner thread.
17:30:46 HBMASTER: job (0, 0, 4) submitted to dispatcher
17:30:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:30:46 DISPATCHER: Trying to submit another job.
17:30:46 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:30:46 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:30:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:30:46 WORKER: start processing job (0, 0, 4)
17:30:46 WORKER: args: ()
17:30:46 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0017507205525982984, 'num_filters_1': 117, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.18051131079473626, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 30, 'num_filters_3': 33, 'num_filters_4': 72}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:31:12 DISPATCHER: Starting worker discovery
17:31:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:31:12 DISPATCHER: Finished worker discovery
17:32:12 DISPATCHER: Starting worker discovery
17:32:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:32:12 DISPATCHER: Finished worker discovery
17:33:12 DISPATCHER: Starting worker discovery
17:33:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:33:12 DISPATCHER: Finished worker discovery
17:33:57 WORKER: done with job (0, 0, 4), trying to register it.
17:33:57 WORKER: registered result for job (0, 0, 4) with dispatcher
17:33:57 DISPATCHER: job (0, 0, 4) finished
17:33:57 DISPATCHER: register_result: lock acquired
17:33:57 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
17:33:57 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0017507205525982984, 'num_filters_1': 117, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.18051131079473626, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 30, 'num_filters_3': 33, 'num_filters_4': 72}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3140581714393868, 'info': {'music_genre': 0.3140581714393868, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0017507205525982984, 'num_filters_1': 117, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.18051131079473626, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 30, 'num_filters_3': 33, 'num_filters_4': 72}"}}
exception: None

17:33:57 job_callback for (0, 0, 4) started
17:33:57 job_callback for (0, 0, 4) got condition
17:33:57 DISPATCHER: Trying to submit another job.
17:33:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:33:57 Only 3 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
17:33:57 HBMASTER: Trying to run another job!
17:33:57 job_callback for (0, 0, 4) finished
17:33:57 HBMASTER: schedule new run for iteration 0
17:33:57 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
17:33:57 HBMASTER: submitting job (0, 0, 5) to dispatcher
17:33:57 DISPATCHER: trying to submit job (0, 0, 5)
17:33:57 DISPATCHER: trying to notify the job_runner thread.
17:33:57 HBMASTER: job (0, 0, 5) submitted to dispatcher
17:33:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:33:57 DISPATCHER: Trying to submit another job.
17:33:57 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:33:57 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:33:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:33:57 WORKER: start processing job (0, 0, 5)
17:33:57 WORKER: args: ()
17:33:57 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0026102197930619737, 'num_filters_1': 122, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.01279519909696689, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 62, 'num_filters_3': 109, 'num_filters_4': 21}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:34:12 DISPATCHER: Starting worker discovery
17:34:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:34:12 DISPATCHER: Finished worker discovery
17:35:12 DISPATCHER: Starting worker discovery
17:35:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:35:12 DISPATCHER: Finished worker discovery
17:36:12 DISPATCHER: Starting worker discovery
17:36:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:36:12 DISPATCHER: Finished worker discovery
17:37:09 WORKER: done with job (0, 0, 5), trying to register it.
17:37:09 WORKER: registered result for job (0, 0, 5) with dispatcher
17:37:09 DISPATCHER: job (0, 0, 5) finished
17:37:09 DISPATCHER: register_result: lock acquired
17:37:09 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
17:37:09 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0026102197930619737, 'num_filters_1': 122, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.01279519909696689, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 62, 'num_filters_3': 109, 'num_filters_4': 21}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.43623904144394343, 'info': {'music_genre': 0.43623904144394343, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0026102197930619737, 'num_filters_1': 122, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.01279519909696689, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 62, 'num_filters_3': 109, 'num_filters_4': 21}"}}
exception: None

17:37:09 job_callback for (0, 0, 5) started
17:37:09 job_callback for (0, 0, 5) got condition
17:37:09 DISPATCHER: Trying to submit another job.
17:37:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:37:09 Only 4 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
17:37:09 HBMASTER: Trying to run another job!
17:37:09 job_callback for (0, 0, 5) finished
17:37:09 HBMASTER: schedule new run for iteration 0
17:37:09 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
17:37:09 HBMASTER: submitting job (0, 0, 7) to dispatcher
17:37:09 DISPATCHER: trying to submit job (0, 0, 7)
17:37:09 DISPATCHER: trying to notify the job_runner thread.
17:37:09 HBMASTER: job (0, 0, 7) submitted to dispatcher
17:37:09 DISPATCHER: Trying to submit another job.
17:37:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:37:09 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:37:09 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:37:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:37:09 WORKER: start processing job (0, 0, 7)
17:37:09 WORKER: args: ()
17:37:09 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.001976271345108419, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.030339581217738054, 'kernel_size_2': 7, 'num_filters_2': 37}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:37:12 DISPATCHER: Starting worker discovery
17:37:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:37:12 DISPATCHER: Finished worker discovery
17:38:12 DISPATCHER: Starting worker discovery
17:38:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:38:12 DISPATCHER: Finished worker discovery
17:39:12 DISPATCHER: Starting worker discovery
17:39:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:39:12 DISPATCHER: Finished worker discovery
17:40:12 DISPATCHER: Starting worker discovery
17:40:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:40:12 DISPATCHER: Finished worker discovery
17:40:24 WORKER: done with job (0, 0, 7), trying to register it.
17:40:24 WORKER: registered result for job (0, 0, 7) with dispatcher
17:40:24 DISPATCHER: job (0, 0, 7) finished
17:40:24 DISPATCHER: register_result: lock acquired
17:40:24 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
17:40:24 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.001976271345108419, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.030339581217738054, 'kernel_size_2': 7, 'num_filters_2': 37}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.35965703552473294, 'info': {'music_genre': 0.35965703552473294, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.001976271345108419, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.030339581217738054, 'kernel_size_2': 7, 'num_filters_2': 37}"}}
exception: None

17:40:24 job_callback for (0, 0, 7) started
17:40:24 job_callback for (0, 0, 7) got condition
17:40:24 DISPATCHER: Trying to submit another job.
17:40:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:40:24 Only 5 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
17:40:24 HBMASTER: Trying to run another job!
17:40:24 job_callback for (0, 0, 7) finished
17:40:24 HBMASTER: schedule new run for iteration 0
17:40:24 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
17:40:24 HBMASTER: submitting job (0, 0, 8) to dispatcher
17:40:24 DISPATCHER: trying to submit job (0, 0, 8)
17:40:24 DISPATCHER: trying to notify the job_runner thread.
17:40:24 HBMASTER: job (0, 0, 8) submitted to dispatcher
17:40:24 DISPATCHER: Trying to submit another job.
17:40:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:40:24 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:40:24 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:40:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:40:24 WORKER: start processing job (0, 0, 8)
17:40:24 WORKER: args: ()
17:40:24 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.005644335055894565, 'num_filters_1': 82, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.014262716689586001, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 68, 'num_filters_3': 62, 'num_filters_4': 29, 'num_filters_5': 17}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:41:12 DISPATCHER: Starting worker discovery
17:41:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:41:12 DISPATCHER: Finished worker discovery
17:42:12 DISPATCHER: Starting worker discovery
17:42:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:42:12 DISPATCHER: Finished worker discovery
17:43:12 DISPATCHER: Starting worker discovery
17:43:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:43:12 DISPATCHER: Finished worker discovery
17:43:36 WORKER: done with job (0, 0, 8), trying to register it.
17:43:37 WORKER: registered result for job (0, 0, 8) with dispatcher
17:43:37 DISPATCHER: job (0, 0, 8) finished
17:43:37 DISPATCHER: register_result: lock acquired
17:43:37 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
17:43:37 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.005644335055894565, 'num_filters_1': 82, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.014262716689586001, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 68, 'num_filters_3': 62, 'num_filters_4': 29, 'num_filters_5': 17}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3841149437546678, 'info': {'music_genre': 0.3841149437546678, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.005644335055894565, 'num_filters_1': 82, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.014262716689586001, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 68, 'num_filters_3': 62, 'num_filters_4': 29, 'num_filters_5': 17}"}}
exception: None

17:43:37 job_callback for (0, 0, 8) started
17:43:37 DISPATCHER: Trying to submit another job.
17:43:37 job_callback for (0, 0, 8) got condition
17:43:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:43:37 Only 6 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
17:43:37 HBMASTER: Trying to run another job!
17:43:37 job_callback for (0, 0, 8) finished
17:43:37 HBMASTER: schedule new run for iteration 0
17:43:37 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
17:43:37 HBMASTER: submitting job (0, 0, 9) to dispatcher
17:43:37 DISPATCHER: trying to submit job (0, 0, 9)
17:43:37 DISPATCHER: trying to notify the job_runner thread.
17:43:37 HBMASTER: job (0, 0, 9) submitted to dispatcher
17:43:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:43:37 DISPATCHER: Trying to submit another job.
17:43:37 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:43:37 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:43:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:43:37 WORKER: start processing job (0, 0, 9)
17:43:37 WORKER: args: ()
17:43:37 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.02294123577973584, 'num_filters_1': 47, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.016410659730350587, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 75, 'num_filters_3': 43}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:44:12 DISPATCHER: Starting worker discovery
17:44:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:44:12 DISPATCHER: Finished worker discovery
17:45:12 DISPATCHER: Starting worker discovery
17:45:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:45:12 DISPATCHER: Finished worker discovery
17:46:12 DISPATCHER: Starting worker discovery
17:46:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:46:12 DISPATCHER: Finished worker discovery
17:46:48 WORKER: done with job (0, 0, 9), trying to register it.
17:46:48 WORKER: registered result for job (0, 0, 9) with dispatcher
17:46:48 DISPATCHER: job (0, 0, 9) finished
17:46:48 DISPATCHER: register_result: lock acquired
17:46:48 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
17:46:48 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.02294123577973584, 'num_filters_1': 47, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.016410659730350587, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 75, 'num_filters_3': 43}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.21353338785296805, 'info': {'music_genre': 0.21353338785296805, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.02294123577973584, 'num_filters_1': 47, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.016410659730350587, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 75, 'num_filters_3': 43}"}}
exception: None

17:46:48 job_callback for (0, 0, 9) started
17:46:48 job_callback for (0, 0, 9) got condition
17:46:48 DISPATCHER: Trying to submit another job.
17:46:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:46:48 Only 7 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
17:46:48 HBMASTER: Trying to run another job!
17:46:48 job_callback for (0, 0, 9) finished
17:46:48 HBMASTER: schedule new run for iteration 0
17:46:48 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
17:46:48 HBMASTER: submitting job (0, 0, 19) to dispatcher
17:46:48 DISPATCHER: trying to submit job (0, 0, 19)
17:46:48 DISPATCHER: trying to notify the job_runner thread.
17:46:48 HBMASTER: job (0, 0, 19) submitted to dispatcher
17:46:48 DISPATCHER: Trying to submit another job.
17:46:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:46:48 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:46:48 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:46:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:46:48 WORKER: start processing job (0, 0, 19)
17:46:48 WORKER: args: ()
17:46:48 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0018016970705864075, 'num_filters_1': 110, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.14165090431484575, 'kernel_size_2': 5, 'num_filters_2': 91}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:47:12 DISPATCHER: Starting worker discovery
17:47:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:47:12 DISPATCHER: Finished worker discovery
17:48:12 DISPATCHER: Starting worker discovery
17:48:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:48:12 DISPATCHER: Finished worker discovery
17:49:12 DISPATCHER: Starting worker discovery
17:49:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:49:12 DISPATCHER: Finished worker discovery
17:50:01 WORKER: done with job (0, 0, 19), trying to register it.
17:50:01 WORKER: registered result for job (0, 0, 19) with dispatcher
17:50:01 DISPATCHER: job (0, 0, 19) finished
17:50:01 DISPATCHER: register_result: lock acquired
17:50:01 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
17:50:01 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0018016970705864075, 'num_filters_1': 110, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.14165090431484575, 'kernel_size_2': 5, 'num_filters_2': 91}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.26224180550925313, 'info': {'music_genre': 0.26224180550925313, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0018016970705864075, 'num_filters_1': 110, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.14165090431484575, 'kernel_size_2': 5, 'num_filters_2': 91}"}}
exception: None

17:50:01 job_callback for (0, 0, 19) started
17:50:01 DISPATCHER: Trying to submit another job.
17:50:01 job_callback for (0, 0, 19) got condition
17:50:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:50:01 Only 8 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
17:50:01 HBMASTER: Trying to run another job!
17:50:01 job_callback for (0, 0, 19) finished
17:50:01 HBMASTER: schedule new run for iteration 0
17:50:01 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
17:50:01 HBMASTER: submitting job (0, 0, 20) to dispatcher
17:50:01 DISPATCHER: trying to submit job (0, 0, 20)
17:50:01 DISPATCHER: trying to notify the job_runner thread.
17:50:01 HBMASTER: job (0, 0, 20) submitted to dispatcher
17:50:01 DISPATCHER: Trying to submit another job.
17:50:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:50:01 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:50:01 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:50:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:50:01 WORKER: start processing job (0, 0, 20)
17:50:01 WORKER: args: ()
17:50:01 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001141811053703833, 'num_filters_1': 83, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.03447065014488159, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 78, 'num_filters_3': 50, 'num_filters_4': 94, 'num_filters_5': 56}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:50:12 DISPATCHER: Starting worker discovery
17:50:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:50:12 DISPATCHER: Finished worker discovery
17:51:12 DISPATCHER: Starting worker discovery
17:51:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:51:12 DISPATCHER: Finished worker discovery
17:52:12 DISPATCHER: Starting worker discovery
17:52:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:52:12 DISPATCHER: Finished worker discovery
17:53:12 WORKER: done with job (0, 0, 20), trying to register it.
17:53:12 WORKER: registered result for job (0, 0, 20) with dispatcher
17:53:12 DISPATCHER: job (0, 0, 20) finished
17:53:12 DISPATCHER: register_result: lock acquired
17:53:12 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
17:53:12 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001141811053703833, 'num_filters_1': 83, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.03447065014488159, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 78, 'num_filters_3': 50, 'num_filters_4': 94, 'num_filters_5': 56}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5106245657918542, 'info': {'music_genre': 0.5106245657918542, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001141811053703833, 'num_filters_1': 83, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.03447065014488159, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 78, 'num_filters_3': 50, 'num_filters_4': 94, 'num_filters_5': 56}"}}
exception: None

17:53:12 job_callback for (0, 0, 20) started
17:53:12 job_callback for (0, 0, 20) got condition
17:53:12 DISPATCHER: Trying to submit another job.
17:53:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:53:12 Only 9 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
17:53:12 HBMASTER: Trying to run another job!
17:53:12 job_callback for (0, 0, 20) finished
17:53:12 ITERATION: Advancing config (0, 0, 0) to next budget 400.000000
17:53:12 ITERATION: Advancing config (0, 0, 5) to next budget 400.000000
17:53:12 ITERATION: Advancing config (0, 0, 20) to next budget 400.000000
17:53:12 HBMASTER: schedule new run for iteration 0
17:53:12 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
17:53:12 HBMASTER: submitting job (0, 0, 0) to dispatcher
17:53:12 DISPATCHER: trying to submit job (0, 0, 0)
17:53:12 DISPATCHER: trying to notify the job_runner thread.
17:53:12 HBMASTER: job (0, 0, 0) submitted to dispatcher
17:53:12 DISPATCHER: Trying to submit another job.
17:53:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:53:12 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:53:12 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
17:53:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:53:12 WORKER: start processing job (0, 0, 0)
17:53:12 WORKER: args: ()
17:53:12 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0010910752200006524, 'num_filters_1': 44, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.010542450616706531, 'kernel_size_2': 5, 'num_filters_2': 44}, 'budget': 400.0, 'working_directory': '.'}
17:53:12 DISPATCHER: Starting worker discovery
17:53:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:53:12 DISPATCHER: Finished worker discovery
17:54:12 DISPATCHER: Starting worker discovery
17:54:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:54:12 DISPATCHER: Finished worker discovery
17:55:12 DISPATCHER: Starting worker discovery
17:55:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:55:12 DISPATCHER: Finished worker discovery
17:56:12 DISPATCHER: Starting worker discovery
17:56:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:56:12 DISPATCHER: Finished worker discovery
17:57:12 DISPATCHER: Starting worker discovery
17:57:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:57:12 DISPATCHER: Finished worker discovery
17:58:12 DISPATCHER: Starting worker discovery
17:58:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:58:12 DISPATCHER: Finished worker discovery
17:59:12 DISPATCHER: Starting worker discovery
17:59:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:59:12 DISPATCHER: Finished worker discovery
18:00:12 DISPATCHER: Starting worker discovery
18:00:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:00:12 DISPATCHER: Finished worker discovery
18:01:05 WORKER: done with job (0, 0, 0), trying to register it.
18:01:05 WORKER: registered result for job (0, 0, 0) with dispatcher
18:01:05 DISPATCHER: job (0, 0, 0) finished
18:01:05 DISPATCHER: register_result: lock acquired
18:01:05 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
18:01:05 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0010910752200006524, 'num_filters_1': 44, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.010542450616706531, 'kernel_size_2': 5, 'num_filters_2': 44}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.4086832724112327, 'info': {'music_genre': 0.4086832724112327, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0010910752200006524, 'num_filters_1': 44, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.010542450616706531, 'kernel_size_2': 5, 'num_filters_2': 44}"}}
exception: None

18:01:05 job_callback for (0, 0, 0) started
18:01:05 job_callback for (0, 0, 0) got condition
18:01:05 DISPATCHER: Trying to submit another job.
18:01:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:01:05 Only 1 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
18:01:05 HBMASTER: Trying to run another job!
18:01:05 job_callback for (0, 0, 0) finished
18:01:05 HBMASTER: schedule new run for iteration 0
18:01:05 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
18:01:05 HBMASTER: submitting job (0, 0, 5) to dispatcher
18:01:05 DISPATCHER: trying to submit job (0, 0, 5)
18:01:05 DISPATCHER: trying to notify the job_runner thread.
18:01:05 HBMASTER: job (0, 0, 5) submitted to dispatcher
18:01:05 DISPATCHER: Trying to submit another job.
18:01:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:01:05 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:01:05 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:01:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:01:05 WORKER: start processing job (0, 0, 5)
18:01:05 WORKER: args: ()
18:01:05 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0026102197930619737, 'num_filters_1': 122, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.01279519909696689, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 62, 'num_filters_3': 109, 'num_filters_4': 21}, 'budget': 400.0, 'working_directory': '.'}
18:01:12 DISPATCHER: Starting worker discovery
18:01:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:01:12 DISPATCHER: Finished worker discovery
18:02:12 DISPATCHER: Starting worker discovery
18:02:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:02:12 DISPATCHER: Finished worker discovery
18:03:12 DISPATCHER: Starting worker discovery
18:03:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:03:12 DISPATCHER: Finished worker discovery
18:04:12 DISPATCHER: Starting worker discovery
18:04:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:04:12 DISPATCHER: Finished worker discovery
18:05:12 DISPATCHER: Starting worker discovery
18:05:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:05:12 DISPATCHER: Finished worker discovery
18:06:12 DISPATCHER: Starting worker discovery
18:06:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:06:12 DISPATCHER: Finished worker discovery
18:07:12 DISPATCHER: Starting worker discovery
18:07:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:07:12 DISPATCHER: Finished worker discovery
18:08:12 DISPATCHER: Starting worker discovery
18:08:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:08:12 DISPATCHER: Finished worker discovery
18:08:44 WORKER: done with job (0, 0, 5), trying to register it.
18:08:44 DISPATCHER: job (0, 0, 5) finished
18:08:44 DISPATCHER: register_result: lock acquired
18:08:44 WORKER: registered result for job (0, 0, 5) with dispatcher
18:08:44 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
18:08:44 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0026102197930619737, 'num_filters_1': 122, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.01279519909696689, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 62, 'num_filters_3': 109, 'num_filters_4': 21}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3364771319355998, 'info': {'music_genre': 0.3364771319355998, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0026102197930619737, 'num_filters_1': 122, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.01279519909696689, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 62, 'num_filters_3': 109, 'num_filters_4': 21}"}}
exception: None

18:08:44 job_callback for (0, 0, 5) started
18:08:44 job_callback for (0, 0, 5) got condition
18:08:44 DISPATCHER: Trying to submit another job.
18:08:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:08:44 Only 2 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
18:08:44 HBMASTER: Trying to run another job!
18:08:44 job_callback for (0, 0, 5) finished
18:08:44 HBMASTER: schedule new run for iteration 0
18:08:44 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
18:08:44 HBMASTER: submitting job (0, 0, 20) to dispatcher
18:08:44 DISPATCHER: trying to submit job (0, 0, 20)
18:08:44 DISPATCHER: trying to notify the job_runner thread.
18:08:44 HBMASTER: job (0, 0, 20) submitted to dispatcher
18:08:44 DISPATCHER: Trying to submit another job.
18:08:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:08:44 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:08:44 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:08:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:08:44 WORKER: start processing job (0, 0, 20)
18:08:44 WORKER: args: ()
18:08:44 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001141811053703833, 'num_filters_1': 83, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.03447065014488159, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 78, 'num_filters_3': 50, 'num_filters_4': 94, 'num_filters_5': 56}, 'budget': 400.0, 'working_directory': '.'}
18:09:12 DISPATCHER: Starting worker discovery
18:09:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:09:12 DISPATCHER: Finished worker discovery
18:10:12 DISPATCHER: Starting worker discovery
18:10:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:10:12 DISPATCHER: Finished worker discovery
18:11:12 DISPATCHER: Starting worker discovery
18:11:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:11:12 DISPATCHER: Finished worker discovery
18:12:12 DISPATCHER: Starting worker discovery
18:12:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:12:12 DISPATCHER: Finished worker discovery
18:13:12 DISPATCHER: Starting worker discovery
18:13:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:13:12 DISPATCHER: Finished worker discovery
18:14:12 DISPATCHER: Starting worker discovery
18:14:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:14:12 DISPATCHER: Finished worker discovery
18:15:12 DISPATCHER: Starting worker discovery
18:15:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:15:12 DISPATCHER: Finished worker discovery
18:16:12 DISPATCHER: Starting worker discovery
18:16:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:16:12 DISPATCHER: Finished worker discovery
18:16:24 WORKER: done with job (0, 0, 20), trying to register it.
18:16:24 WORKER: registered result for job (0, 0, 20) with dispatcher
18:16:24 DISPATCHER: job (0, 0, 20) finished
18:16:24 DISPATCHER: register_result: lock acquired
18:16:24 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
18:16:24 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001141811053703833, 'num_filters_1': 83, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.03447065014488159, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 78, 'num_filters_3': 50, 'num_filters_4': 94, 'num_filters_5': 56}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.43797468973318493, 'info': {'music_genre': 0.43797468973318493, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001141811053703833, 'num_filters_1': 83, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.03447065014488159, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 78, 'num_filters_3': 50, 'num_filters_4': 94, 'num_filters_5': 56}"}}
exception: None

18:16:24 job_callback for (0, 0, 20) started
18:16:24 DISPATCHER: Trying to submit another job.
18:16:24 job_callback for (0, 0, 20) got condition
18:16:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:16:24 Only 3 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
18:16:24 HBMASTER: Trying to run another job!
18:16:24 job_callback for (0, 0, 20) finished
18:16:24 ITERATION: Advancing config (0, 0, 20) to next budget 1200.000000
18:16:24 HBMASTER: schedule new run for iteration 0
18:16:24 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
18:16:24 HBMASTER: submitting job (0, 0, 20) to dispatcher
18:16:24 DISPATCHER: trying to submit job (0, 0, 20)
18:16:24 DISPATCHER: trying to notify the job_runner thread.
18:16:24 HBMASTER: job (0, 0, 20) submitted to dispatcher
18:16:24 DISPATCHER: Trying to submit another job.
18:16:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:16:24 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:16:24 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:16:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:16:24 WORKER: start processing job (0, 0, 20)
18:16:24 WORKER: args: ()
18:16:24 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001141811053703833, 'num_filters_1': 83, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.03447065014488159, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 78, 'num_filters_3': 50, 'num_filters_4': 94, 'num_filters_5': 56}, 'budget': 1200.0, 'working_directory': '.'}
18:17:12 DISPATCHER: Starting worker discovery
18:17:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:17:12 DISPATCHER: Finished worker discovery
18:18:12 DISPATCHER: Starting worker discovery
18:18:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:18:12 DISPATCHER: Finished worker discovery
18:19:12 DISPATCHER: Starting worker discovery
18:19:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:19:12 DISPATCHER: Finished worker discovery
18:20:12 DISPATCHER: Starting worker discovery
18:20:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:20:12 DISPATCHER: Finished worker discovery
18:21:12 DISPATCHER: Starting worker discovery
18:21:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:21:12 DISPATCHER: Finished worker discovery
18:22:12 DISPATCHER: Starting worker discovery
18:22:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:22:12 DISPATCHER: Finished worker discovery
18:23:12 DISPATCHER: Starting worker discovery
18:23:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:23:12 DISPATCHER: Finished worker discovery
18:24:12 DISPATCHER: Starting worker discovery
18:24:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:24:12 DISPATCHER: Finished worker discovery
18:25:12 DISPATCHER: Starting worker discovery
18:25:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:25:12 DISPATCHER: Finished worker discovery
18:26:12 DISPATCHER: Starting worker discovery
18:26:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:26:12 DISPATCHER: Finished worker discovery
18:27:12 DISPATCHER: Starting worker discovery
18:27:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:27:12 DISPATCHER: Finished worker discovery
18:28:12 DISPATCHER: Starting worker discovery
18:28:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:28:12 DISPATCHER: Finished worker discovery
18:29:12 DISPATCHER: Starting worker discovery
18:29:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:29:12 DISPATCHER: Finished worker discovery
18:30:12 DISPATCHER: Starting worker discovery
18:30:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:30:12 DISPATCHER: Finished worker discovery
18:31:12 DISPATCHER: Starting worker discovery
18:31:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:31:12 DISPATCHER: Finished worker discovery
18:32:12 DISPATCHER: Starting worker discovery
18:32:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:32:12 DISPATCHER: Finished worker discovery
18:33:12 DISPATCHER: Starting worker discovery
18:33:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:33:12 DISPATCHER: Finished worker discovery
18:34:12 DISPATCHER: Starting worker discovery
18:34:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:34:12 DISPATCHER: Finished worker discovery
18:35:12 DISPATCHER: Starting worker discovery
18:35:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:35:12 DISPATCHER: Finished worker discovery
18:36:12 DISPATCHER: Starting worker discovery
18:36:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:36:12 DISPATCHER: Finished worker discovery
18:37:12 DISPATCHER: Starting worker discovery
18:37:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:37:12 DISPATCHER: Finished worker discovery
18:37:26 WORKER: done with job (0, 0, 20), trying to register it.
18:37:26 WORKER: registered result for job (0, 0, 20) with dispatcher
18:37:26 DISPATCHER: job (0, 0, 20) finished
18:37:26 DISPATCHER: register_result: lock acquired
18:37:26 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
18:37:26 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001141811053703833, 'num_filters_1': 83, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.03447065014488159, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 78, 'num_filters_3': 50, 'num_filters_4': 94, 'num_filters_5': 56}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.4014031732467378, 'info': {'music_genre': 0.4014031732467378, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001141811053703833, 'num_filters_1': 83, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.03447065014488159, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 78, 'num_filters_3': 50, 'num_filters_4': 94, 'num_filters_5': 56}"}}
exception: None

18:37:26 job_callback for (0, 0, 20) started
18:37:26 DISPATCHER: Trying to submit another job.
18:37:26 job_callback for (0, 0, 20) got condition
18:37:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:37:26 Only 1 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
18:37:26 HBMASTER: Trying to run another job!
18:37:26 job_callback for (0, 0, 20) finished
18:37:26 start sampling a new configuration.
18:37:26 done sampling a new configuration.
18:37:26 HBMASTER: schedule new run for iteration 1
18:37:26 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
18:37:26 HBMASTER: submitting job (1, 0, 0) to dispatcher
18:37:26 DISPATCHER: trying to submit job (1, 0, 0)
18:37:26 DISPATCHER: trying to notify the job_runner thread.
18:37:26 HBMASTER: job (1, 0, 0) submitted to dispatcher
18:37:26 DISPATCHER: Trying to submit another job.
18:37:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:37:26 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:37:26 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:37:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:37:26 WORKER: start processing job (1, 0, 0)
18:37:26 WORKER: args: ()
18:37:26 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.034211181446872255, 'num_filters_1': 22, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.021724872666393724, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 89, 'num_filters_3': 125}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:38:12 DISPATCHER: Starting worker discovery
18:38:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:38:12 DISPATCHER: Finished worker discovery
18:39:12 DISPATCHER: Starting worker discovery
18:39:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:39:12 DISPATCHER: Finished worker discovery
18:40:12 DISPATCHER: Starting worker discovery
18:40:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:40:12 DISPATCHER: Finished worker discovery
18:40:38 WORKER: done with job (1, 0, 0), trying to register it.
18:40:38 WORKER: registered result for job (1, 0, 0) with dispatcher
18:40:38 DISPATCHER: job (1, 0, 0) finished
18:40:38 DISPATCHER: register_result: lock acquired
18:40:38 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
18:40:38 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.034211181446872255, 'num_filters_1': 22, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.021724872666393724, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 89, 'num_filters_3': 125}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.18104715333328913, 'info': {'music_genre': 0.18104715333328913, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.034211181446872255, 'num_filters_1': 22, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.021724872666393724, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 89, 'num_filters_3': 125}"}}
exception: None

18:40:38 job_callback for (1, 0, 0) started
18:40:38 DISPATCHER: Trying to submit another job.
18:40:38 job_callback for (1, 0, 0) got condition
18:40:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:40:38 Only 10 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
18:40:38 HBMASTER: Trying to run another job!
18:40:38 job_callback for (1, 0, 0) finished
18:40:38 start sampling a new configuration.
18:40:38 done sampling a new configuration.
18:40:38 HBMASTER: schedule new run for iteration 1
18:40:38 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
18:40:38 HBMASTER: submitting job (1, 0, 1) to dispatcher
18:40:38 DISPATCHER: trying to submit job (1, 0, 1)
18:40:38 DISPATCHER: trying to notify the job_runner thread.
18:40:38 HBMASTER: job (1, 0, 1) submitted to dispatcher
18:40:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:40:38 DISPATCHER: Trying to submit another job.
18:40:38 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:40:38 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:40:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:40:38 WORKER: start processing job (1, 0, 1)
18:40:38 WORKER: args: ()
18:40:38 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0011449277751459143, 'num_filters_1': 71, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.1477583754070114, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 106, 'num_filters_3': 59}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:41:12 DISPATCHER: Starting worker discovery
18:41:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:41:12 DISPATCHER: Finished worker discovery
18:42:12 DISPATCHER: Starting worker discovery
18:42:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:42:12 DISPATCHER: Finished worker discovery
18:43:12 DISPATCHER: Starting worker discovery
18:43:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:43:12 DISPATCHER: Finished worker discovery
18:43:47 WORKER: done with job (1, 0, 1), trying to register it.
18:43:47 WORKER: registered result for job (1, 0, 1) with dispatcher
18:43:47 DISPATCHER: job (1, 0, 1) finished
18:43:47 DISPATCHER: register_result: lock acquired
18:43:47 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
18:43:47 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0011449277751459143, 'num_filters_1': 71, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.1477583754070114, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 106, 'num_filters_3': 59}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1646773994071443, 'info': {'music_genre': 0.1646773994071443, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0011449277751459143, 'num_filters_1': 71, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.1477583754070114, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 106, 'num_filters_3': 59}"}}
exception: None

18:43:47 job_callback for (1, 0, 1) started
18:43:47 DISPATCHER: Trying to submit another job.
18:43:47 job_callback for (1, 0, 1) got condition
18:43:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:43:47 Only 11 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
18:43:47 HBMASTER: Trying to run another job!
18:43:47 job_callback for (1, 0, 1) finished
18:43:47 start sampling a new configuration.
18:43:47 done sampling a new configuration.
18:43:47 HBMASTER: schedule new run for iteration 1
18:43:47 HBMASTER: trying submitting job (1, 0, 2) to dispatcher
18:43:47 HBMASTER: submitting job (1, 0, 2) to dispatcher
18:43:47 DISPATCHER: trying to submit job (1, 0, 2)
18:43:47 DISPATCHER: trying to notify the job_runner thread.
18:43:47 HBMASTER: job (1, 0, 2) submitted to dispatcher
18:43:47 DISPATCHER: Trying to submit another job.
18:43:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:43:47 DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:43:47 DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:43:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:43:47 WORKER: start processing job (1, 0, 2)
18:43:47 WORKER: args: ()
18:43:47 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.08861093841986793, 'num_filters_1': 54, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.01887479350358095, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 37, 'num_filters_3': 69}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:44:12 DISPATCHER: Starting worker discovery
18:44:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:44:12 DISPATCHER: Finished worker discovery
Exception in thread Thread-644:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index -4878299114473888156 is out of bounds for axis 0 with size 10

18:45:12 DISPATCHER: Starting worker discovery
18:45:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:45:12 DISPATCHER: Finished worker discovery
18:46:12 DISPATCHER: Starting worker discovery
18:46:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:46:12 DISPATCHER: Finished worker discovery
18:46:55 WORKER: done with job (1, 0, 2), trying to register it.
18:46:55 WORKER: registered result for job (1, 0, 2) with dispatcher
18:46:55 DISPATCHER: job (1, 0, 2) finished
18:46:55 DISPATCHER: register_result: lock acquired
18:46:55 DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
18:46:55 job_id: (1, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.08861093841986793, 'num_filters_1': 54, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.01887479350358095, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 37, 'num_filters_3': 69}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.41464760113101284, 'info': {'music_genre': 0.41464760113101284, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.08861093841986793, 'num_filters_1': 54, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.01887479350358095, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 37, 'num_filters_3': 69}"}}
exception: None

18:46:55 job_callback for (1, 0, 2) started
18:46:55 DISPATCHER: Trying to submit another job.
18:46:55 job_callback for (1, 0, 2) got condition
18:46:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:46:56 Only 12 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
18:46:56 HBMASTER: Trying to run another job!
18:46:56 job_callback for (1, 0, 2) finished
18:46:56 start sampling a new configuration.
18:46:56 done sampling a new configuration.
18:46:56 HBMASTER: schedule new run for iteration 1
18:46:56 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
18:46:56 HBMASTER: submitting job (1, 0, 3) to dispatcher
18:46:56 DISPATCHER: trying to submit job (1, 0, 3)
18:46:56 DISPATCHER: trying to notify the job_runner thread.
18:46:56 HBMASTER: job (1, 0, 3) submitted to dispatcher
18:46:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:46:56 DISPATCHER: Trying to submit another job.
18:46:56 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:46:56 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:46:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:46:56 WORKER: start processing job (1, 0, 3)
18:46:56 WORKER: args: ()
18:46:56 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.005652151648150772, 'num_filters_1': 30, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.18137824317293083, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 45, 'num_filters_3': 34, 'num_filters_4': 60}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:47:12 DISPATCHER: Starting worker discovery
18:47:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:47:12 DISPATCHER: Finished worker discovery
18:48:12 DISPATCHER: Starting worker discovery
18:48:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:48:12 DISPATCHER: Finished worker discovery
18:49:12 DISPATCHER: Starting worker discovery
18:49:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:49:12 DISPATCHER: Finished worker discovery
18:50:05 WORKER: done with job (1, 0, 3), trying to register it.
18:50:05 WORKER: registered result for job (1, 0, 3) with dispatcher
18:50:05 DISPATCHER: job (1, 0, 3) finished
18:50:05 DISPATCHER: register_result: lock acquired
18:50:05 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
18:50:05 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.005652151648150772, 'num_filters_1': 30, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.18137824317293083, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 45, 'num_filters_3': 34, 'num_filters_4': 60}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0004064402584690398, 'info': {'music_genre': 0.0004064402584690398, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.005652151648150772, 'num_filters_1': 30, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.18137824317293083, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 45, 'num_filters_3': 34, 'num_filters_4': 60}"}}
exception: None

18:50:05 job_callback for (1, 0, 3) started
18:50:05 DISPATCHER: Trying to submit another job.
18:50:05 job_callback for (1, 0, 3) got condition
18:50:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:50:05 Only 13 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
18:50:05 HBMASTER: Trying to run another job!
18:50:05 job_callback for (1, 0, 3) finished
18:50:05 start sampling a new configuration.
18:50:05 done sampling a new configuration.
18:50:05 HBMASTER: schedule new run for iteration 1
18:50:05 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
18:50:05 HBMASTER: submitting job (1, 0, 4) to dispatcher
18:50:05 DISPATCHER: trying to submit job (1, 0, 4)
18:50:05 DISPATCHER: trying to notify the job_runner thread.
18:50:05 HBMASTER: job (1, 0, 4) submitted to dispatcher
18:50:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:50:05 DISPATCHER: Trying to submit another job.
18:50:05 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:50:05 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:50:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:50:05 WORKER: start processing job (1, 0, 4)
18:50:05 WORKER: args: ()
18:50:05 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002744678741730013, 'num_filters_1': 62, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.024789088916613536, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 86, 'num_filters_3': 50}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:50:12 DISPATCHER: Starting worker discovery
18:50:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:50:12 DISPATCHER: Finished worker discovery
18:51:12 DISPATCHER: Starting worker discovery
18:51:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:51:12 DISPATCHER: Finished worker discovery
18:52:12 DISPATCHER: Starting worker discovery
18:52:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:52:12 DISPATCHER: Finished worker discovery
18:53:12 DISPATCHER: Starting worker discovery
18:53:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:53:12 DISPATCHER: Finished worker discovery
18:53:16 WORKER: done with job (1, 0, 4), trying to register it.
18:53:16 WORKER: registered result for job (1, 0, 4) with dispatcher
18:53:16 DISPATCHER: job (1, 0, 4) finished
18:53:16 DISPATCHER: register_result: lock acquired
18:53:16 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
18:53:16 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002744678741730013, 'num_filters_1': 62, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.024789088916613536, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 86, 'num_filters_3': 50}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.42524426953344596, 'info': {'music_genre': 0.42524426953344596, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002744678741730013, 'num_filters_1': 62, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.024789088916613536, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 86, 'num_filters_3': 50}"}}
exception: None

18:53:16 job_callback for (1, 0, 4) started
18:53:16 job_callback for (1, 0, 4) got condition
18:53:16 DISPATCHER: Trying to submit another job.
18:53:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:53:16 Only 14 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
18:53:16 HBMASTER: Trying to run another job!
18:53:16 job_callback for (1, 0, 4) finished
18:53:16 start sampling a new configuration.
18:53:16 done sampling a new configuration.
18:53:16 HBMASTER: schedule new run for iteration 1
18:53:16 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
18:53:16 HBMASTER: submitting job (1, 0, 5) to dispatcher
18:53:16 DISPATCHER: trying to submit job (1, 0, 5)
18:53:16 DISPATCHER: trying to notify the job_runner thread.
18:53:16 HBMASTER: job (1, 0, 5) submitted to dispatcher
18:53:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:53:16 DISPATCHER: Trying to submit another job.
18:53:16 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:53:16 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:53:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:53:16 WORKER: start processing job (1, 0, 5)
18:53:16 WORKER: args: ()
18:53:16 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0068265412287961845, 'num_filters_1': 49, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.025304617827588728, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 16, 'num_filters_3': 39}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:54:12 DISPATCHER: Starting worker discovery
18:54:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:54:12 DISPATCHER: Finished worker discovery
18:55:12 DISPATCHER: Starting worker discovery
18:55:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:55:12 DISPATCHER: Finished worker discovery
18:56:12 DISPATCHER: Starting worker discovery
18:56:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:56:12 DISPATCHER: Finished worker discovery
18:56:26 WORKER: done with job (1, 0, 5), trying to register it.
18:56:26 WORKER: registered result for job (1, 0, 5) with dispatcher
18:56:26 DISPATCHER: job (1, 0, 5) finished
18:56:26 DISPATCHER: register_result: lock acquired
18:56:26 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
18:56:26 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0068265412287961845, 'num_filters_1': 49, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.025304617827588728, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 16, 'num_filters_3': 39}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3575538161819509, 'info': {'music_genre': 0.3575538161819509, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0068265412287961845, 'num_filters_1': 49, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.025304617827588728, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 16, 'num_filters_3': 39}"}}
exception: None

18:56:26 job_callback for (1, 0, 5) started
18:56:26 job_callback for (1, 0, 5) got condition
18:56:26 DISPATCHER: Trying to submit another job.
18:56:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:56:26 Only 15 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
18:56:26 HBMASTER: Trying to run another job!
18:56:26 job_callback for (1, 0, 5) finished
18:56:26 start sampling a new configuration.
18:56:26 done sampling a new configuration.
18:56:26 HBMASTER: schedule new run for iteration 1
18:56:26 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
18:56:26 HBMASTER: submitting job (1, 0, 6) to dispatcher
18:56:26 DISPATCHER: trying to submit job (1, 0, 6)
18:56:26 DISPATCHER: trying to notify the job_runner thread.
18:56:26 HBMASTER: job (1, 0, 6) submitted to dispatcher
18:56:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:56:26 DISPATCHER: Trying to submit another job.
18:56:26 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:56:26 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:56:26 WORKER: start processing job (1, 0, 6)
18:56:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:56:26 WORKER: args: ()
18:56:26 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0010304679424947252, 'num_filters_1': 28, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.05027208802886619, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 69, 'num_filters_3': 61}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:57:12 DISPATCHER: Starting worker discovery
18:57:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:57:12 DISPATCHER: Finished worker discovery
18:58:12 DISPATCHER: Starting worker discovery
18:58:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:58:13 DISPATCHER: Finished worker discovery
18:59:13 DISPATCHER: Starting worker discovery
18:59:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:59:13 DISPATCHER: Finished worker discovery
18:59:36 WORKER: done with job (1, 0, 6), trying to register it.
18:59:36 WORKER: registered result for job (1, 0, 6) with dispatcher
18:59:36 DISPATCHER: job (1, 0, 6) finished
18:59:36 DISPATCHER: register_result: lock acquired
18:59:36 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
18:59:36 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0010304679424947252, 'num_filters_1': 28, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.05027208802886619, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 69, 'num_filters_3': 61}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.17264301411720895, 'info': {'music_genre': 0.17264301411720895, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0010304679424947252, 'num_filters_1': 28, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.05027208802886619, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 69, 'num_filters_3': 61}"}}
exception: None

18:59:36 job_callback for (1, 0, 6) started
18:59:36 DISPATCHER: Trying to submit another job.
18:59:36 job_callback for (1, 0, 6) got condition
18:59:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:59:36 Only 16 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
18:59:36 HBMASTER: Trying to run another job!
18:59:36 job_callback for (1, 0, 6) finished
18:59:36 start sampling a new configuration.
18:59:36 done sampling a new configuration.
18:59:36 HBMASTER: schedule new run for iteration 1
18:59:36 HBMASTER: trying submitting job (1, 0, 7) to dispatcher
18:59:36 HBMASTER: submitting job (1, 0, 7) to dispatcher
18:59:36 DISPATCHER: trying to submit job (1, 0, 7)
18:59:36 DISPATCHER: trying to notify the job_runner thread.
18:59:36 HBMASTER: job (1, 0, 7) submitted to dispatcher
18:59:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:59:36 DISPATCHER: Trying to submit another job.
18:59:36 DISPATCHER: starting job (1, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:59:36 DISPATCHER: job (1, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
18:59:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:59:36 WORKER: start processing job (1, 0, 7)
18:59:36 WORKER: args: ()
18:59:36 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.007553315018196966, 'num_filters_1': 72, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.07497275883930882, 'kernel_size_2': 5, 'num_filters_2': 117}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:00:13 DISPATCHER: Starting worker discovery
19:00:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:00:13 DISPATCHER: Finished worker discovery
19:01:13 DISPATCHER: Starting worker discovery
19:01:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:01:13 DISPATCHER: Finished worker discovery
19:02:13 DISPATCHER: Starting worker discovery
19:02:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:02:13 DISPATCHER: Finished worker discovery
19:02:45 WORKER: done with job (1, 0, 7), trying to register it.
19:02:45 WORKER: registered result for job (1, 0, 7) with dispatcher
19:02:45 DISPATCHER: job (1, 0, 7) finished
19:02:45 DISPATCHER: register_result: lock acquired
19:02:45 DISPATCHER: job (1, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
19:02:45 job_id: (1, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.007553315018196966, 'num_filters_1': 72, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.07497275883930882, 'kernel_size_2': 5, 'num_filters_2': 117}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.29911097627728106, 'info': {'music_genre': 0.29911097627728106, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.007553315018196966, 'num_filters_1': 72, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.07497275883930882, 'kernel_size_2': 5, 'num_filters_2': 117}"}}
exception: None

19:02:45 job_callback for (1, 0, 7) started
19:02:45 DISPATCHER: Trying to submit another job.
19:02:45 job_callback for (1, 0, 7) got condition
19:02:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:02:45 HBMASTER: Trying to run another job!
19:02:45 job_callback for (1, 0, 7) finished
19:02:45 start sampling a new configuration.
19:02:45 done sampling a new configuration.
19:02:45 HBMASTER: schedule new run for iteration 1
19:02:45 HBMASTER: trying submitting job (1, 0, 8) to dispatcher
19:02:45 HBMASTER: submitting job (1, 0, 8) to dispatcher
19:02:45 DISPATCHER: trying to submit job (1, 0, 8)
19:02:45 DISPATCHER: trying to notify the job_runner thread.
19:02:45 HBMASTER: job (1, 0, 8) submitted to dispatcher
19:02:45 DISPATCHER: Trying to submit another job.
19:02:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:02:45 DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:02:45 DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:02:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:02:45 WORKER: start processing job (1, 0, 8)
19:02:45 WORKER: args: ()
19:02:45 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.00265653083223437, 'num_filters_1': 34, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.016587985162291596, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 61, 'num_filters_3': 50, 'num_filters_4': 58, 'num_filters_5': 25}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:03:13 DISPATCHER: Starting worker discovery
19:03:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:03:13 DISPATCHER: Finished worker discovery
19:04:13 DISPATCHER: Starting worker discovery
19:04:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:04:13 DISPATCHER: Finished worker discovery
19:05:13 DISPATCHER: Starting worker discovery
19:05:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:05:13 DISPATCHER: Finished worker discovery
19:05:57 WORKER: done with job (1, 0, 8), trying to register it.
19:05:57 WORKER: registered result for job (1, 0, 8) with dispatcher
19:05:57 DISPATCHER: job (1, 0, 8) finished
19:05:57 DISPATCHER: register_result: lock acquired
19:05:57 DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
19:05:57 job_id: (1, 0, 8)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.00265653083223437, 'num_filters_1': 34, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.016587985162291596, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 61, 'num_filters_3': 50, 'num_filters_4': 58, 'num_filters_5': 25}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3078567111786615, 'info': {'music_genre': 0.3078567111786615, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.00265653083223437, 'num_filters_1': 34, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.016587985162291596, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 61, 'num_filters_3': 50, 'num_filters_4': 58, 'num_filters_5': 25}"}}
exception: None

19:05:57 job_callback for (1, 0, 8) started
19:05:57 job_callback for (1, 0, 8) got condition
19:05:57 DISPATCHER: Trying to submit another job.
19:05:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:05:57 HBMASTER: Trying to run another job!
19:05:57 job_callback for (1, 0, 8) finished
19:05:57 ITERATION: Advancing config (1, 0, 2) to next budget 400.000000
19:05:57 ITERATION: Advancing config (1, 0, 4) to next budget 400.000000
19:05:57 ITERATION: Advancing config (1, 0, 5) to next budget 400.000000
19:05:57 HBMASTER: schedule new run for iteration 1
19:05:57 HBMASTER: trying submitting job (1, 0, 2) to dispatcher
19:05:57 HBMASTER: submitting job (1, 0, 2) to dispatcher
19:05:57 DISPATCHER: trying to submit job (1, 0, 2)
19:05:57 DISPATCHER: trying to notify the job_runner thread.
19:05:57 HBMASTER: job (1, 0, 2) submitted to dispatcher
19:05:57 DISPATCHER: Trying to submit another job.
19:05:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:05:57 DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:05:57 DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:05:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:05:57 WORKER: start processing job (1, 0, 2)
19:05:57 WORKER: args: ()
19:05:57 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.08861093841986793, 'num_filters_1': 54, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.01887479350358095, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 37, 'num_filters_3': 69}, 'budget': 400.0, 'working_directory': '.'}
19:06:13 DISPATCHER: Starting worker discovery
19:06:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:06:13 DISPATCHER: Finished worker discovery
Exception in thread Thread-651:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 4445953545852053094 is out of bounds for axis 0 with size 10

19:07:13 DISPATCHER: Starting worker discovery
19:07:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:07:13 DISPATCHER: Finished worker discovery
19:08:13 DISPATCHER: Starting worker discovery
19:08:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:08:13 DISPATCHER: Finished worker discovery
19:09:13 DISPATCHER: Starting worker discovery
19:09:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:09:13 DISPATCHER: Finished worker discovery
19:10:13 DISPATCHER: Starting worker discovery
19:10:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:10:13 DISPATCHER: Finished worker discovery
19:11:13 DISPATCHER: Starting worker discovery
19:11:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:11:13 DISPATCHER: Finished worker discovery
19:12:13 DISPATCHER: Starting worker discovery
19:12:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:12:13 DISPATCHER: Finished worker discovery
19:13:13 DISPATCHER: Starting worker discovery
19:13:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:13:13 DISPATCHER: Finished worker discovery
19:13:32 WORKER: done with job (1, 0, 2), trying to register it.
19:13:32 WORKER: registered result for job (1, 0, 2) with dispatcher
19:13:32 DISPATCHER: job (1, 0, 2) finished
19:13:32 DISPATCHER: register_result: lock acquired
19:13:32 DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
19:13:32 job_id: (1, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.08861093841986793, 'num_filters_1': 54, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.01887479350358095, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 37, 'num_filters_3': 69}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5177119195425317, 'info': {'music_genre': 0.5177119195425317, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.08861093841986793, 'num_filters_1': 54, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.01887479350358095, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 37, 'num_filters_3': 69}"}}
exception: None

19:13:32 DISPATCHER: Trying to submit another job.
19:13:32 job_callback for (1, 0, 2) started
19:13:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:13:32 job_callback for (1, 0, 2) got condition
19:13:32 Only 4 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
19:13:32 HBMASTER: Trying to run another job!
19:13:32 job_callback for (1, 0, 2) finished
19:13:32 HBMASTER: schedule new run for iteration 1
19:13:32 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
19:13:32 HBMASTER: submitting job (1, 0, 4) to dispatcher
19:13:32 DISPATCHER: trying to submit job (1, 0, 4)
19:13:32 DISPATCHER: trying to notify the job_runner thread.
19:13:32 HBMASTER: job (1, 0, 4) submitted to dispatcher
19:13:32 DISPATCHER: Trying to submit another job.
19:13:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:13:32 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:13:32 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:13:32 WORKER: start processing job (1, 0, 4)
19:13:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:13:32 WORKER: args: ()
19:13:32 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002744678741730013, 'num_filters_1': 62, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.024789088916613536, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 86, 'num_filters_3': 50}, 'budget': 400.0, 'working_directory': '.'}
19:14:13 DISPATCHER: Starting worker discovery
19:14:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:14:13 DISPATCHER: Finished worker discovery
19:15:13 DISPATCHER: Starting worker discovery
19:15:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:15:13 DISPATCHER: Finished worker discovery
19:16:13 DISPATCHER: Starting worker discovery
19:16:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:16:13 DISPATCHER: Finished worker discovery
19:17:13 DISPATCHER: Starting worker discovery
19:17:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:17:13 DISPATCHER: Finished worker discovery
19:18:13 DISPATCHER: Starting worker discovery
19:18:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:18:13 DISPATCHER: Finished worker discovery
19:19:13 DISPATCHER: Starting worker discovery
19:19:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:19:13 DISPATCHER: Finished worker discovery
19:20:13 DISPATCHER: Starting worker discovery
19:20:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:20:13 DISPATCHER: Finished worker discovery
19:21:08 WORKER: done with job (1, 0, 4), trying to register it.
19:21:08 WORKER: registered result for job (1, 0, 4) with dispatcher
19:21:08 DISPATCHER: job (1, 0, 4) finished
19:21:08 DISPATCHER: register_result: lock acquired
19:21:08 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
19:21:08 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002744678741730013, 'num_filters_1': 62, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.024789088916613536, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 86, 'num_filters_3': 50}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3549801922312572, 'info': {'music_genre': 0.3549801922312572, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002744678741730013, 'num_filters_1': 62, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.024789088916613536, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 86, 'num_filters_3': 50}"}}
exception: None

19:21:08 job_callback for (1, 0, 4) started
19:21:08 job_callback for (1, 0, 4) got condition
19:21:08 DISPATCHER: Trying to submit another job.
19:21:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:21:08 Only 5 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
19:21:08 HBMASTER: Trying to run another job!
19:21:08 job_callback for (1, 0, 4) finished
19:21:08 HBMASTER: schedule new run for iteration 1
19:21:08 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
19:21:08 HBMASTER: submitting job (1, 0, 5) to dispatcher
19:21:08 DISPATCHER: trying to submit job (1, 0, 5)
19:21:08 DISPATCHER: trying to notify the job_runner thread.
19:21:08 HBMASTER: job (1, 0, 5) submitted to dispatcher
19:21:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:21:08 DISPATCHER: Trying to submit another job.
19:21:08 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:21:08 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:21:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:21:08 WORKER: start processing job (1, 0, 5)
19:21:08 WORKER: args: ()
19:21:08 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0068265412287961845, 'num_filters_1': 49, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.025304617827588728, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 16, 'num_filters_3': 39}, 'budget': 400.0, 'working_directory': '.'}
19:21:13 DISPATCHER: Starting worker discovery
19:21:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:21:13 DISPATCHER: Finished worker discovery
19:22:13 DISPATCHER: Starting worker discovery
19:22:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:22:13 DISPATCHER: Finished worker discovery
19:23:13 DISPATCHER: Starting worker discovery
19:23:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:23:13 DISPATCHER: Finished worker discovery
19:24:13 DISPATCHER: Starting worker discovery
19:24:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:24:13 DISPATCHER: Finished worker discovery
19:25:13 DISPATCHER: Starting worker discovery
19:25:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:25:13 DISPATCHER: Finished worker discovery
19:26:13 DISPATCHER: Starting worker discovery
19:26:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:26:13 DISPATCHER: Finished worker discovery
19:27:13 DISPATCHER: Starting worker discovery
19:27:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:27:13 DISPATCHER: Finished worker discovery
19:28:13 DISPATCHER: Starting worker discovery
19:28:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:28:13 DISPATCHER: Finished worker discovery
19:28:47 WORKER: done with job (1, 0, 5), trying to register it.
19:28:47 WORKER: registered result for job (1, 0, 5) with dispatcher
19:28:47 DISPATCHER: job (1, 0, 5) finished
19:28:47 DISPATCHER: register_result: lock acquired
19:28:47 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
19:28:47 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0068265412287961845, 'num_filters_1': 49, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.025304617827588728, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 16, 'num_filters_3': 39}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.2384831779763416, 'info': {'music_genre': 0.2384831779763416, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0068265412287961845, 'num_filters_1': 49, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.025304617827588728, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 16, 'num_filters_3': 39}"}}
exception: None

19:28:47 job_callback for (1, 0, 5) started
19:28:47 job_callback for (1, 0, 5) got condition
19:28:47 DISPATCHER: Trying to submit another job.
19:28:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:28:47 Only 6 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
19:28:47 HBMASTER: Trying to run another job!
19:28:47 job_callback for (1, 0, 5) finished
19:28:47 ITERATION: Advancing config (1, 0, 2) to next budget 1200.000000
19:28:47 HBMASTER: schedule new run for iteration 1
19:28:47 HBMASTER: trying submitting job (1, 0, 2) to dispatcher
19:28:47 HBMASTER: submitting job (1, 0, 2) to dispatcher
19:28:47 DISPATCHER: trying to submit job (1, 0, 2)
19:28:47 DISPATCHER: trying to notify the job_runner thread.
19:28:47 HBMASTER: job (1, 0, 2) submitted to dispatcher
19:28:47 DISPATCHER: Trying to submit another job.
19:28:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:28:47 DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:28:47 DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:28:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:28:47 WORKER: start processing job (1, 0, 2)
19:28:47 WORKER: args: ()
19:28:47 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.08861093841986793, 'num_filters_1': 54, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.01887479350358095, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 37, 'num_filters_3': 69}, 'budget': 1200.0, 'working_directory': '.'}
19:29:13 DISPATCHER: Starting worker discovery
19:29:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:29:13 DISPATCHER: Finished worker discovery
Exception in thread Thread-654:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 4607182418800017408 is out of bounds for axis 0 with size 10

19:30:13 DISPATCHER: Starting worker discovery
19:30:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:30:13 DISPATCHER: Finished worker discovery
19:31:13 DISPATCHER: Starting worker discovery
19:31:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:31:13 DISPATCHER: Finished worker discovery
19:32:13 DISPATCHER: Starting worker discovery
19:32:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:32:13 DISPATCHER: Finished worker discovery
19:33:13 DISPATCHER: Starting worker discovery
19:33:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:33:13 DISPATCHER: Finished worker discovery
19:34:13 DISPATCHER: Starting worker discovery
19:34:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:34:13 DISPATCHER: Finished worker discovery
19:35:13 DISPATCHER: Starting worker discovery
19:35:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:35:13 DISPATCHER: Finished worker discovery
19:36:13 DISPATCHER: Starting worker discovery
19:36:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:36:13 DISPATCHER: Finished worker discovery
19:37:13 DISPATCHER: Starting worker discovery
19:37:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:37:13 DISPATCHER: Finished worker discovery
19:38:13 DISPATCHER: Starting worker discovery
19:38:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:38:13 DISPATCHER: Finished worker discovery
19:39:13 DISPATCHER: Starting worker discovery
19:39:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:39:13 DISPATCHER: Finished worker discovery
19:40:13 DISPATCHER: Starting worker discovery
19:40:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:40:13 DISPATCHER: Finished worker discovery
19:41:13 DISPATCHER: Starting worker discovery
19:41:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:41:13 DISPATCHER: Finished worker discovery
19:42:13 DISPATCHER: Starting worker discovery
19:42:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:42:13 DISPATCHER: Finished worker discovery
19:43:13 DISPATCHER: Starting worker discovery
19:43:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:43:13 DISPATCHER: Finished worker discovery
19:44:13 DISPATCHER: Starting worker discovery
19:44:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:44:13 DISPATCHER: Finished worker discovery
19:45:13 DISPATCHER: Starting worker discovery
19:45:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:45:13 DISPATCHER: Finished worker discovery
19:46:13 DISPATCHER: Starting worker discovery
19:46:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:46:13 DISPATCHER: Finished worker discovery
19:47:13 DISPATCHER: Starting worker discovery
19:47:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:47:13 DISPATCHER: Finished worker discovery
19:48:13 DISPATCHER: Starting worker discovery
19:48:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:48:13 DISPATCHER: Finished worker discovery
19:49:13 DISPATCHER: Starting worker discovery
19:49:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:49:13 DISPATCHER: Finished worker discovery
19:49:41 WORKER: done with job (1, 0, 2), trying to register it.
19:49:41 WORKER: registered result for job (1, 0, 2) with dispatcher
19:49:41 DISPATCHER: job (1, 0, 2) finished
19:49:41 DISPATCHER: register_result: lock acquired
19:49:41 DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
19:49:41 job_id: (1, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.08861093841986793, 'num_filters_1': 54, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.01887479350358095, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 37, 'num_filters_3': 69}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.4243767627723891, 'info': {'music_genre': 0.4243767627723891, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.08861093841986793, 'num_filters_1': 54, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.01887479350358095, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 37, 'num_filters_3': 69}"}}
exception: None

19:49:41 job_callback for (1, 0, 2) started
19:49:41 DISPATCHER: Trying to submit another job.
19:49:41 job_callback for (1, 0, 2) got condition
19:49:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:49:41 Only 2 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
19:49:41 HBMASTER: Trying to run another job!
19:49:41 job_callback for (1, 0, 2) finished
19:49:41 start sampling a new configuration.
19:49:41 done sampling a new configuration.
19:49:41 HBMASTER: schedule new run for iteration 2
19:49:41 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
19:49:41 HBMASTER: submitting job (2, 0, 0) to dispatcher
19:49:41 DISPATCHER: trying to submit job (2, 0, 0)
19:49:41 DISPATCHER: trying to notify the job_runner thread.
19:49:41 HBMASTER: job (2, 0, 0) submitted to dispatcher
19:49:41 DISPATCHER: Trying to submit another job.
19:49:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:49:41 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:49:41 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:49:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:49:41 WORKER: start processing job (2, 0, 0)
19:49:41 WORKER: args: ()
19:49:41 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.005221224262178675, 'num_filters_1': 52, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.04988637289275871, 'kernel_size_2': 7, 'num_filters_2': 89}, 'budget': 400.0, 'working_directory': '.'}
19:50:13 DISPATCHER: Starting worker discovery
19:50:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:50:13 DISPATCHER: Finished worker discovery
19:51:13 DISPATCHER: Starting worker discovery
19:51:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:51:13 DISPATCHER: Finished worker discovery
19:52:13 DISPATCHER: Starting worker discovery
19:52:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:52:13 DISPATCHER: Finished worker discovery
19:53:13 DISPATCHER: Starting worker discovery
19:53:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:53:13 DISPATCHER: Finished worker discovery
19:54:13 DISPATCHER: Starting worker discovery
19:54:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:54:13 DISPATCHER: Finished worker discovery
19:55:13 DISPATCHER: Starting worker discovery
19:55:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:55:13 DISPATCHER: Finished worker discovery
19:56:13 DISPATCHER: Starting worker discovery
19:56:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:56:13 DISPATCHER: Finished worker discovery
19:57:13 DISPATCHER: Starting worker discovery
19:57:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:57:13 DISPATCHER: Finished worker discovery
19:57:21 WORKER: done with job (2, 0, 0), trying to register it.
19:57:21 WORKER: registered result for job (2, 0, 0) with dispatcher
19:57:21 DISPATCHER: job (2, 0, 0) finished
19:57:21 DISPATCHER: register_result: lock acquired
19:57:21 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
19:57:21 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.005221224262178675, 'num_filters_1': 52, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.04988637289275871, 'kernel_size_2': 7, 'num_filters_2': 89}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.24853052375254364, 'info': {'music_genre': 0.24853052375254364, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.005221224262178675, 'num_filters_1': 52, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.04988637289275871, 'kernel_size_2': 7, 'num_filters_2': 89}"}}
exception: None

19:57:21 job_callback for (2, 0, 0) started
19:57:21 DISPATCHER: Trying to submit another job.
19:57:21 job_callback for (2, 0, 0) got condition
19:57:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:57:21 Only 7 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
19:57:21 HBMASTER: Trying to run another job!
19:57:21 job_callback for (2, 0, 0) finished
19:57:21 start sampling a new configuration.
19:57:21 done sampling a new configuration.
19:57:21 HBMASTER: schedule new run for iteration 2
19:57:21 HBMASTER: trying submitting job (2, 0, 1) to dispatcher
19:57:21 HBMASTER: submitting job (2, 0, 1) to dispatcher
19:57:21 DISPATCHER: trying to submit job (2, 0, 1)
19:57:21 DISPATCHER: trying to notify the job_runner thread.
19:57:21 HBMASTER: job (2, 0, 1) submitted to dispatcher
19:57:21 DISPATCHER: Trying to submit another job.
19:57:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:57:21 DISPATCHER: starting job (2, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:57:21 DISPATCHER: job (2, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
19:57:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:57:21 WORKER: start processing job (2, 0, 1)
19:57:21 WORKER: args: ()
19:57:21 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.010370536817516504, 'num_filters_1': 37, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.0672284717669635, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 24, 'num_filters_3': 87, 'num_filters_4': 50}, 'budget': 400.0, 'working_directory': '.'}
19:58:13 DISPATCHER: Starting worker discovery
19:58:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:58:13 DISPATCHER: Finished worker discovery
19:59:13 DISPATCHER: Starting worker discovery
19:59:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:59:13 DISPATCHER: Finished worker discovery
20:00:13 DISPATCHER: Starting worker discovery
20:00:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:00:13 DISPATCHER: Finished worker discovery
20:01:13 DISPATCHER: Starting worker discovery
20:01:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:01:13 DISPATCHER: Finished worker discovery
20:02:13 DISPATCHER: Starting worker discovery
20:02:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:02:13 DISPATCHER: Finished worker discovery
20:03:13 DISPATCHER: Starting worker discovery
20:03:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:03:13 DISPATCHER: Finished worker discovery
20:04:13 DISPATCHER: Starting worker discovery
20:04:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:04:13 DISPATCHER: Finished worker discovery
20:05:11 WORKER: done with job (2, 0, 1), trying to register it.
20:05:11 WORKER: registered result for job (2, 0, 1) with dispatcher
20:05:11 DISPATCHER: job (2, 0, 1) finished
20:05:11 DISPATCHER: register_result: lock acquired
20:05:11 DISPATCHER: job (2, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
20:05:11 job_id: (2, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.010370536817516504, 'num_filters_1': 37, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.0672284717669635, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 24, 'num_filters_3': 87, 'num_filters_4': 50}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.20440769323531083, 'info': {'music_genre': 0.20440769323531083, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.010370536817516504, 'num_filters_1': 37, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.0672284717669635, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 24, 'num_filters_3': 87, 'num_filters_4': 50}"}}
exception: None

20:05:11 job_callback for (2, 0, 1) started
20:05:11 job_callback for (2, 0, 1) got condition
20:05:11 DISPATCHER: Trying to submit another job.
20:05:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:05:11 Only 8 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
20:05:11 HBMASTER: Trying to run another job!
20:05:11 job_callback for (2, 0, 1) finished
20:05:11 start sampling a new configuration.
20:05:11 done sampling a new configuration.
20:05:12 HBMASTER: schedule new run for iteration 2
20:05:12 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
20:05:12 HBMASTER: submitting job (2, 0, 2) to dispatcher
20:05:12 DISPATCHER: trying to submit job (2, 0, 2)
20:05:12 DISPATCHER: trying to notify the job_runner thread.
20:05:12 HBMASTER: job (2, 0, 2) submitted to dispatcher
20:05:12 DISPATCHER: Trying to submit another job.
20:05:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:05:12 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
20:05:12 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
20:05:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:05:12 WORKER: start processing job (2, 0, 2)
20:05:12 WORKER: args: ()
20:05:12 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0024555705223741823, 'num_filters_1': 48, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.1423284627576706, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 65, 'num_filters_3': 25, 'num_filters_4': 57}, 'budget': 400.0, 'working_directory': '.'}
20:05:13 DISPATCHER: Starting worker discovery
20:05:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:05:13 DISPATCHER: Finished worker discovery
20:06:13 DISPATCHER: Starting worker discovery
20:06:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:06:13 DISPATCHER: Finished worker discovery
20:07:13 DISPATCHER: Starting worker discovery
20:07:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:07:13 DISPATCHER: Finished worker discovery
20:08:13 DISPATCHER: Starting worker discovery
20:08:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:08:13 DISPATCHER: Finished worker discovery
20:09:13 DISPATCHER: Starting worker discovery
20:09:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:09:13 DISPATCHER: Finished worker discovery
20:10:13 DISPATCHER: Starting worker discovery
20:10:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:10:13 DISPATCHER: Finished worker discovery
20:11:13 DISPATCHER: Starting worker discovery
20:11:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:11:13 DISPATCHER: Finished worker discovery
20:12:13 DISPATCHER: Starting worker discovery
20:12:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:12:13 DISPATCHER: Finished worker discovery
20:12:51 WORKER: done with job (2, 0, 2), trying to register it.
20:12:51 WORKER: registered result for job (2, 0, 2) with dispatcher
20:12:51 DISPATCHER: job (2, 0, 2) finished
20:12:51 DISPATCHER: register_result: lock acquired
20:12:51 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
20:12:51 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0024555705223741823, 'num_filters_1': 48, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.1423284627576706, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 65, 'num_filters_3': 25, 'num_filters_4': 57}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0014981741219452567, 'info': {'music_genre': 0.0014981741219452567, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0024555705223741823, 'num_filters_1': 48, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.1423284627576706, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 65, 'num_filters_3': 25, 'num_filters_4': 57}"}}
exception: None

20:12:51 job_callback for (2, 0, 2) started
20:12:51 job_callback for (2, 0, 2) got condition
20:12:51 DISPATCHER: Trying to submit another job.
20:12:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:12:51 Only 9 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
20:12:51 HBMASTER: Trying to run another job!
20:12:51 job_callback for (2, 0, 2) finished
20:12:51 start sampling a new configuration.
20:12:51 done sampling a new configuration.
20:12:51 HBMASTER: schedule new run for iteration 2
20:12:51 HBMASTER: trying submitting job (2, 0, 3) to dispatcher
20:12:51 HBMASTER: submitting job (2, 0, 3) to dispatcher
20:12:51 DISPATCHER: trying to submit job (2, 0, 3)
20:12:51 DISPATCHER: trying to notify the job_runner thread.
20:12:51 HBMASTER: job (2, 0, 3) submitted to dispatcher
20:12:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:12:51 DISPATCHER: Trying to submit another job.
20:12:51 DISPATCHER: starting job (2, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
20:12:51 DISPATCHER: job (2, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
20:12:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:12:51 WORKER: start processing job (2, 0, 3)
20:12:51 WORKER: args: ()
20:12:51 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.01254376223292494, 'num_filters_1': 25, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.04842222487721841, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 25, 'num_filters_3': 20, 'num_filters_4': 26}, 'budget': 400.0, 'working_directory': '.'}
20:13:13 DISPATCHER: Starting worker discovery
20:13:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:13:14 DISPATCHER: Finished worker discovery
20:14:14 DISPATCHER: Starting worker discovery
20:14:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:14:14 DISPATCHER: Finished worker discovery
20:15:14 DISPATCHER: Starting worker discovery
20:15:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:15:14 DISPATCHER: Finished worker discovery
20:16:14 DISPATCHER: Starting worker discovery
20:16:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:16:14 DISPATCHER: Finished worker discovery
20:17:14 DISPATCHER: Starting worker discovery
20:17:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:17:14 DISPATCHER: Finished worker discovery
20:18:14 DISPATCHER: Starting worker discovery
20:18:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:18:14 DISPATCHER: Finished worker discovery
20:19:14 DISPATCHER: Starting worker discovery
20:19:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:19:14 DISPATCHER: Finished worker discovery
20:20:14 DISPATCHER: Starting worker discovery
20:20:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:20:14 DISPATCHER: Finished worker discovery
20:20:31 WORKER: done with job (2, 0, 3), trying to register it.
20:20:31 WORKER: registered result for job (2, 0, 3) with dispatcher
20:20:31 DISPATCHER: job (2, 0, 3) finished
20:20:31 DISPATCHER: register_result: lock acquired
20:20:31 DISPATCHER: job (2, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
20:20:31 job_id: (2, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.01254376223292494, 'num_filters_1': 25, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.04842222487721841, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 25, 'num_filters_3': 20, 'num_filters_4': 26}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.2044640195816324, 'info': {'music_genre': 0.2044640195816324, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.01254376223292494, 'num_filters_1': 25, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.04842222487721841, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 25, 'num_filters_3': 20, 'num_filters_4': 26}"}}
exception: None

20:20:31 job_callback for (2, 0, 3) started
20:20:31 job_callback for (2, 0, 3) got condition
20:20:31 DISPATCHER: Trying to submit another job.
20:20:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:20:31 Only 10 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
20:20:31 HBMASTER: Trying to run another job!
20:20:31 job_callback for (2, 0, 3) finished
20:20:31 start sampling a new configuration.
20:20:31 done sampling a new configuration.
20:20:31 HBMASTER: schedule new run for iteration 2
20:20:31 HBMASTER: trying submitting job (2, 0, 4) to dispatcher
20:20:31 HBMASTER: submitting job (2, 0, 4) to dispatcher
20:20:31 DISPATCHER: trying to submit job (2, 0, 4)
20:20:31 DISPATCHER: trying to notify the job_runner thread.
20:20:31 HBMASTER: job (2, 0, 4) submitted to dispatcher
20:20:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:20:31 DISPATCHER: Trying to submit another job.
20:20:31 DISPATCHER: starting job (2, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
20:20:31 DISPATCHER: job (2, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
20:20:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:20:31 WORKER: start processing job (2, 0, 4)
20:20:31 WORKER: args: ()
20:20:31 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.021630754223777925, 'num_filters_1': 59, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.010525390731268978, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 20, 'num_filters_3': 57, 'num_filters_4': 124}, 'budget': 400.0, 'working_directory': '.'}
20:21:14 DISPATCHER: Starting worker discovery
20:21:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:21:14 DISPATCHER: Finished worker discovery
20:22:14 DISPATCHER: Starting worker discovery
20:22:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:22:14 DISPATCHER: Finished worker discovery
20:23:14 DISPATCHER: Starting worker discovery
20:23:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:23:14 DISPATCHER: Finished worker discovery
20:24:14 DISPATCHER: Starting worker discovery
20:24:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:24:14 DISPATCHER: Finished worker discovery
20:25:14 DISPATCHER: Starting worker discovery
20:25:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:25:14 DISPATCHER: Finished worker discovery
20:26:14 DISPATCHER: Starting worker discovery
20:26:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:26:14 DISPATCHER: Finished worker discovery
20:27:14 DISPATCHER: Starting worker discovery
20:27:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:27:14 DISPATCHER: Finished worker discovery
20:28:10 WORKER: done with job (2, 0, 4), trying to register it.
20:28:10 WORKER: registered result for job (2, 0, 4) with dispatcher
20:28:10 DISPATCHER: job (2, 0, 4) finished
20:28:10 DISPATCHER: register_result: lock acquired
20:28:10 DISPATCHER: job (2, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
20:28:10 job_id: (2, 0, 4)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.021630754223777925, 'num_filters_1': 59, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.010525390731268978, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 20, 'num_filters_3': 57, 'num_filters_4': 124}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.021630754223777925, 'num_filters_1': 59, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.010525390731268978, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 20, 'num_filters_3': 57, 'num_filters_4': 124}"}}
exception: None

20:28:10 job_callback for (2, 0, 4) started
20:28:10 job_callback for (2, 0, 4) got condition
20:28:10 DISPATCHER: Trying to submit another job.
20:28:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:28:10 Only 11 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
20:28:10 HBMASTER: Trying to run another job!
20:28:10 job_callback for (2, 0, 4) finished
20:28:10 start sampling a new configuration.
20:28:10 done sampling a new configuration.
20:28:10 HBMASTER: schedule new run for iteration 2
20:28:10 HBMASTER: trying submitting job (2, 0, 5) to dispatcher
20:28:10 HBMASTER: submitting job (2, 0, 5) to dispatcher
20:28:10 DISPATCHER: trying to submit job (2, 0, 5)
20:28:10 DISPATCHER: trying to notify the job_runner thread.
20:28:10 HBMASTER: job (2, 0, 5) submitted to dispatcher
20:28:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:28:10 DISPATCHER: Trying to submit another job.
20:28:10 DISPATCHER: starting job (2, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952
20:28:10 DISPATCHER: job (2, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
20:28:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:28:10 WORKER: start processing job (2, 0, 5)
20:28:10 WORKER: args: ()
20:28:10 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0050901992381641135, 'num_filters_1': 26, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.023897763791760836, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 23, 'num_filters_3': 46, 'num_filters_4': 114}, 'budget': 400.0, 'working_directory': '.'}
20:28:14 DISPATCHER: Starting worker discovery
20:28:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:28:14 DISPATCHER: Finished worker discovery
20:29:14 DISPATCHER: Starting worker discovery
20:29:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:29:14 DISPATCHER: Finished worker discovery
20:30:14 DISPATCHER: Starting worker discovery
20:30:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:30:14 DISPATCHER: Finished worker discovery
20:31:14 DISPATCHER: Starting worker discovery
20:31:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:31:14 DISPATCHER: Finished worker discovery
20:32:14 DISPATCHER: Starting worker discovery
20:32:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:32:14 DISPATCHER: Finished worker discovery
20:33:14 DISPATCHER: Starting worker discovery
20:33:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:33:14 DISPATCHER: Finished worker discovery
20:34:14 DISPATCHER: Starting worker discovery
20:34:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:34:14 DISPATCHER: Finished worker discovery
20:35:14 DISPATCHER: Starting worker discovery
20:35:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:35:14 DISPATCHER: Finished worker discovery
20:35:49 WORKER: done with job (2, 0, 5), trying to register it.
20:35:49 WORKER: registered result for job (2, 0, 5) with dispatcher
20:35:49 DISPATCHER: job (2, 0, 5) finished
20:35:49 DISPATCHER: register_result: lock acquired
20:35:49 DISPATCHER: job (2, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
20:35:49 job_id: (2, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0050901992381641135, 'num_filters_1': 26, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.023897763791760836, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 23, 'num_filters_3': 46, 'num_filters_4': 114}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.11519179844566618, 'info': {'music_genre': 0.11519179844566618, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0050901992381641135, 'num_filters_1': 26, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.023897763791760836, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 23, 'num_filters_3': 46, 'num_filters_4': 114}"}}
exception: None

20:35:49 job_callback for (2, 0, 5) started
20:35:49 DISPATCHER: Trying to submit another job.
20:35:49 job_callback for (2, 0, 5) got condition
20:35:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:35:49 Only 12 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
20:35:49 HBMASTER: Trying to run another job!
20:35:49 job_callback for (2, 0, 5) finished
20:35:49 ITERATION: Advancing config (2, 0, 0) to next budget 1200.000000
20:35:49 ITERATION: Advancing config (2, 0, 3) to next budget 1200.000000
20:35:49 HBMASTER: schedule new run for iteration 2
20:35:49 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
20:35:49 HBMASTER: submitting job (2, 0, 0) to dispatcher
20:35:49 DISPATCHER: trying to submit job (2, 0, 0)
20:35:49 DISPATCHER: trying to notify the job_runner thread.
20:35:49 HBMASTER: job (2, 0, 0) submitted to dispatcher
20:35:49 DISPATCHER: Trying to submit another job.
20:35:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:35:49 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
20:35:49 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
20:35:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:35:49 WORKER: start processing job (2, 0, 0)
20:35:49 WORKER: args: ()
20:35:49 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.005221224262178675, 'num_filters_1': 52, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.04988637289275871, 'kernel_size_2': 7, 'num_filters_2': 89}, 'budget': 1200.0, 'working_directory': '.'}
20:36:14 DISPATCHER: Starting worker discovery
20:36:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:36:14 DISPATCHER: Finished worker discovery
20:37:14 DISPATCHER: Starting worker discovery
20:37:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:37:14 DISPATCHER: Finished worker discovery
20:38:14 DISPATCHER: Starting worker discovery
20:38:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:38:14 DISPATCHER: Finished worker discovery
20:39:14 DISPATCHER: Starting worker discovery
20:39:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:39:14 DISPATCHER: Finished worker discovery
20:40:14 DISPATCHER: Starting worker discovery
20:40:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:40:14 DISPATCHER: Finished worker discovery
20:41:14 DISPATCHER: Starting worker discovery
20:41:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:41:14 DISPATCHER: Finished worker discovery
20:42:14 DISPATCHER: Starting worker discovery
20:42:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:42:14 DISPATCHER: Finished worker discovery
20:43:14 DISPATCHER: Starting worker discovery
20:43:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:43:14 DISPATCHER: Finished worker discovery
20:44:14 DISPATCHER: Starting worker discovery
20:44:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:44:14 DISPATCHER: Finished worker discovery
20:45:14 DISPATCHER: Starting worker discovery
20:45:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:45:14 DISPATCHER: Finished worker discovery
20:46:14 DISPATCHER: Starting worker discovery
20:46:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:46:14 DISPATCHER: Finished worker discovery
20:47:14 DISPATCHER: Starting worker discovery
20:47:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:47:14 DISPATCHER: Finished worker discovery
20:48:14 DISPATCHER: Starting worker discovery
20:48:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:48:14 DISPATCHER: Finished worker discovery
20:49:14 DISPATCHER: Starting worker discovery
20:49:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:49:14 DISPATCHER: Finished worker discovery
20:50:14 DISPATCHER: Starting worker discovery
20:50:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:50:14 DISPATCHER: Finished worker discovery
20:51:14 DISPATCHER: Starting worker discovery
20:51:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:51:14 DISPATCHER: Finished worker discovery
20:52:14 DISPATCHER: Starting worker discovery
20:52:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:52:14 DISPATCHER: Finished worker discovery
20:53:14 DISPATCHER: Starting worker discovery
20:53:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:53:14 DISPATCHER: Finished worker discovery
20:54:14 DISPATCHER: Starting worker discovery
20:54:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:54:14 DISPATCHER: Finished worker discovery
20:55:14 DISPATCHER: Starting worker discovery
20:55:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:55:14 DISPATCHER: Finished worker discovery
20:56:14 DISPATCHER: Starting worker discovery
20:56:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:56:14 DISPATCHER: Finished worker discovery
20:56:55 WORKER: done with job (2, 0, 0), trying to register it.
20:56:55 WORKER: registered result for job (2, 0, 0) with dispatcher
20:56:55 DISPATCHER: job (2, 0, 0) finished
20:56:55 DISPATCHER: register_result: lock acquired
20:56:55 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
20:56:55 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.005221224262178675, 'num_filters_1': 52, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.04988637289275871, 'kernel_size_2': 7, 'num_filters_2': 89}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.19724775536369643, 'info': {'music_genre': 0.19724775536369643, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.005221224262178675, 'num_filters_1': 52, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.04988637289275871, 'kernel_size_2': 7, 'num_filters_2': 89}"}}
exception: None

20:56:55 job_callback for (2, 0, 0) started
20:56:55 job_callback for (2, 0, 0) got condition
20:56:55 DISPATCHER: Trying to submit another job.
20:56:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:56:55 Only 3 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
20:56:55 HBMASTER: Trying to run another job!
20:56:55 job_callback for (2, 0, 0) finished
20:56:55 HBMASTER: schedule new run for iteration 2
20:56:55 HBMASTER: trying submitting job (2, 0, 3) to dispatcher
20:56:55 HBMASTER: submitting job (2, 0, 3) to dispatcher
20:56:55 DISPATCHER: trying to submit job (2, 0, 3)
20:56:55 DISPATCHER: trying to notify the job_runner thread.
20:56:55 HBMASTER: job (2, 0, 3) submitted to dispatcher
20:56:55 DISPATCHER: Trying to submit another job.
20:56:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:56:55 DISPATCHER: starting job (2, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
20:56:55 DISPATCHER: job (2, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
20:56:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:56:55 WORKER: start processing job (2, 0, 3)
20:56:55 WORKER: args: ()
20:56:55 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.01254376223292494, 'num_filters_1': 25, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.04842222487721841, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 25, 'num_filters_3': 20, 'num_filters_4': 26}, 'budget': 1200.0, 'working_directory': '.'}
20:57:14 DISPATCHER: Starting worker discovery
20:57:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:57:14 DISPATCHER: Finished worker discovery
20:58:14 DISPATCHER: Starting worker discovery
20:58:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:58:14 DISPATCHER: Finished worker discovery
20:59:14 DISPATCHER: Starting worker discovery
20:59:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:59:14 DISPATCHER: Finished worker discovery
21:00:14 DISPATCHER: Starting worker discovery
21:00:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:00:14 DISPATCHER: Finished worker discovery
21:01:14 DISPATCHER: Starting worker discovery
21:01:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:01:14 DISPATCHER: Finished worker discovery
21:02:14 DISPATCHER: Starting worker discovery
21:02:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:02:14 DISPATCHER: Finished worker discovery
21:03:14 DISPATCHER: Starting worker discovery
21:03:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:03:14 DISPATCHER: Finished worker discovery
21:04:14 DISPATCHER: Starting worker discovery
21:04:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:04:14 DISPATCHER: Finished worker discovery
21:05:14 DISPATCHER: Starting worker discovery
21:05:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:05:14 DISPATCHER: Finished worker discovery
21:06:14 DISPATCHER: Starting worker discovery
21:06:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:06:14 DISPATCHER: Finished worker discovery
21:07:14 DISPATCHER: Starting worker discovery
21:07:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:07:14 DISPATCHER: Finished worker discovery
21:08:14 DISPATCHER: Starting worker discovery
21:08:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:08:14 DISPATCHER: Finished worker discovery
21:09:14 DISPATCHER: Starting worker discovery
21:09:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:09:14 DISPATCHER: Finished worker discovery
21:10:14 DISPATCHER: Starting worker discovery
21:10:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:10:14 DISPATCHER: Finished worker discovery
21:11:14 DISPATCHER: Starting worker discovery
21:11:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:11:14 DISPATCHER: Finished worker discovery
21:12:14 DISPATCHER: Starting worker discovery
21:12:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:12:14 DISPATCHER: Finished worker discovery
21:13:14 DISPATCHER: Starting worker discovery
21:13:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:13:14 DISPATCHER: Finished worker discovery
21:14:14 DISPATCHER: Starting worker discovery
21:14:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:14:14 DISPATCHER: Finished worker discovery
21:15:14 DISPATCHER: Starting worker discovery
21:15:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:15:14 DISPATCHER: Finished worker discovery
21:16:14 DISPATCHER: Starting worker discovery
21:16:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:16:14 DISPATCHER: Finished worker discovery
21:17:14 DISPATCHER: Starting worker discovery
21:17:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:17:14 DISPATCHER: Finished worker discovery
21:18:05 WORKER: done with job (2, 0, 3), trying to register it.
21:18:05 WORKER: registered result for job (2, 0, 3) with dispatcher
21:18:05 DISPATCHER: job (2, 0, 3) finished
21:18:05 DISPATCHER: register_result: lock acquired
21:18:05 DISPATCHER: job (2, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
21:18:05 job_id: (2, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.01254376223292494, 'num_filters_1': 25, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.04842222487721841, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 25, 'num_filters_3': 20, 'num_filters_4': 26}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.1823332418636905, 'info': {'music_genre': 0.1823332418636905, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.01254376223292494, 'num_filters_1': 25, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.04842222487721841, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 25, 'num_filters_3': 20, 'num_filters_4': 26}"}}
exception: None

21:18:05 job_callback for (2, 0, 3) started
21:18:05 job_callback for (2, 0, 3) got condition
21:18:05 DISPATCHER: Trying to submit another job.
21:18:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:18:05 Only 4 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
21:18:05 HBMASTER: Trying to run another job!
21:18:05 job_callback for (2, 0, 3) finished
21:18:05 start sampling a new configuration.
21:18:05 done sampling a new configuration.
21:18:05 HBMASTER: schedule new run for iteration 3
21:18:05 HBMASTER: trying submitting job (3, 0, 0) to dispatcher
21:18:05 HBMASTER: submitting job (3, 0, 0) to dispatcher
21:18:05 DISPATCHER: trying to submit job (3, 0, 0)
21:18:05 DISPATCHER: trying to notify the job_runner thread.
21:18:05 HBMASTER: job (3, 0, 0) submitted to dispatcher
21:18:05 DISPATCHER: Trying to submit another job.
21:18:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:18:05 DISPATCHER: starting job (3, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
21:18:05 DISPATCHER: job (3, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
21:18:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:18:05 WORKER: start processing job (3, 0, 0)
21:18:05 WORKER: args: ()
21:18:05 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0013080680293371214, 'num_filters_1': 50, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.05427624811896504, 'kernel_size_2': 3, 'num_filters_2': 20}, 'budget': 1200.0, 'working_directory': '.'}
21:18:14 DISPATCHER: Starting worker discovery
21:18:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:18:15 DISPATCHER: Finished worker discovery
21:19:15 DISPATCHER: Starting worker discovery
21:19:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:19:15 DISPATCHER: Finished worker discovery
21:20:15 DISPATCHER: Starting worker discovery
21:20:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:20:15 DISPATCHER: Finished worker discovery
21:21:15 DISPATCHER: Starting worker discovery
21:21:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:21:15 DISPATCHER: Finished worker discovery
21:22:15 DISPATCHER: Starting worker discovery
21:22:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:22:15 DISPATCHER: Finished worker discovery
21:23:15 DISPATCHER: Starting worker discovery
21:23:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:23:15 DISPATCHER: Finished worker discovery
21:24:15 DISPATCHER: Starting worker discovery
21:24:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:24:15 DISPATCHER: Finished worker discovery
21:25:15 DISPATCHER: Starting worker discovery
21:25:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:25:15 DISPATCHER: Finished worker discovery
21:26:15 DISPATCHER: Starting worker discovery
21:26:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:26:15 DISPATCHER: Finished worker discovery
21:27:15 DISPATCHER: Starting worker discovery
21:27:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:27:15 DISPATCHER: Finished worker discovery
21:28:15 DISPATCHER: Starting worker discovery
21:28:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:28:15 DISPATCHER: Finished worker discovery
21:29:15 DISPATCHER: Starting worker discovery
21:29:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:29:15 DISPATCHER: Finished worker discovery
21:30:15 DISPATCHER: Starting worker discovery
21:30:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:30:15 DISPATCHER: Finished worker discovery
21:31:15 DISPATCHER: Starting worker discovery
21:31:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:31:15 DISPATCHER: Finished worker discovery
21:32:15 DISPATCHER: Starting worker discovery
21:32:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:32:15 DISPATCHER: Finished worker discovery
21:33:15 DISPATCHER: Starting worker discovery
21:33:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:33:15 DISPATCHER: Finished worker discovery
21:34:15 DISPATCHER: Starting worker discovery
21:34:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:34:15 DISPATCHER: Finished worker discovery
21:35:15 DISPATCHER: Starting worker discovery
21:35:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:35:15 DISPATCHER: Finished worker discovery
21:36:15 DISPATCHER: Starting worker discovery
21:36:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:36:15 DISPATCHER: Finished worker discovery
21:37:15 DISPATCHER: Starting worker discovery
21:37:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:37:15 DISPATCHER: Finished worker discovery
21:38:15 DISPATCHER: Starting worker discovery
21:38:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:38:15 DISPATCHER: Finished worker discovery
21:39:12 WORKER: done with job (3, 0, 0), trying to register it.
21:39:12 WORKER: registered result for job (3, 0, 0) with dispatcher
21:39:12 DISPATCHER: job (3, 0, 0) finished
21:39:12 DISPATCHER: register_result: lock acquired
21:39:12 DISPATCHER: job (3, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
21:39:12 job_id: (3, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0013080680293371214, 'num_filters_1': 50, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.05427624811896504, 'kernel_size_2': 3, 'num_filters_2': 20}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.27877680875374644, 'info': {'music_genre': 0.27877680875374644, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0013080680293371214, 'num_filters_1': 50, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.05427624811896504, 'kernel_size_2': 3, 'num_filters_2': 20}"}}
exception: None

21:39:12 job_callback for (3, 0, 0) started
21:39:12 DISPATCHER: Trying to submit another job.
21:39:12 job_callback for (3, 0, 0) got condition
21:39:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:39:12 Only 5 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
21:39:12 HBMASTER: Trying to run another job!
21:39:12 job_callback for (3, 0, 0) finished
21:39:12 start sampling a new configuration.
21:39:12 done sampling a new configuration.
21:39:12 HBMASTER: schedule new run for iteration 3
21:39:12 HBMASTER: trying submitting job (3, 0, 1) to dispatcher
21:39:12 HBMASTER: submitting job (3, 0, 1) to dispatcher
21:39:12 DISPATCHER: trying to submit job (3, 0, 1)
21:39:12 DISPATCHER: trying to notify the job_runner thread.
21:39:12 HBMASTER: job (3, 0, 1) submitted to dispatcher
21:39:12 DISPATCHER: Trying to submit another job.
21:39:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:39:12 DISPATCHER: starting job (3, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
21:39:12 DISPATCHER: job (3, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
21:39:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:39:12 WORKER: start processing job (3, 0, 1)
21:39:12 WORKER: args: ()
21:39:12 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.004147261058521504, 'num_filters_1': 128, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.07799117120914205, 'kernel_size_2': 7, 'num_filters_2': 82}, 'budget': 1200.0, 'working_directory': '.'}
21:39:15 DISPATCHER: Starting worker discovery
21:39:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:39:15 DISPATCHER: Finished worker discovery
21:40:15 DISPATCHER: Starting worker discovery
21:40:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:40:15 DISPATCHER: Finished worker discovery
21:41:15 DISPATCHER: Starting worker discovery
21:41:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:41:15 DISPATCHER: Finished worker discovery
21:42:15 DISPATCHER: Starting worker discovery
21:42:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:42:15 DISPATCHER: Finished worker discovery
21:43:15 DISPATCHER: Starting worker discovery
21:43:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:43:15 DISPATCHER: Finished worker discovery
21:44:15 DISPATCHER: Starting worker discovery
21:44:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:44:15 DISPATCHER: Finished worker discovery
21:45:15 DISPATCHER: Starting worker discovery
21:45:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:45:15 DISPATCHER: Finished worker discovery
21:46:15 DISPATCHER: Starting worker discovery
21:46:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:46:15 DISPATCHER: Finished worker discovery
21:47:15 DISPATCHER: Starting worker discovery
21:47:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:47:15 DISPATCHER: Finished worker discovery
21:48:15 DISPATCHER: Starting worker discovery
21:48:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:48:15 DISPATCHER: Finished worker discovery
21:49:15 DISPATCHER: Starting worker discovery
21:49:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:49:15 DISPATCHER: Finished worker discovery
21:50:15 DISPATCHER: Starting worker discovery
21:50:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:50:15 DISPATCHER: Finished worker discovery
21:51:15 DISPATCHER: Starting worker discovery
21:51:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:51:15 DISPATCHER: Finished worker discovery
21:52:15 DISPATCHER: Starting worker discovery
21:52:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:52:15 DISPATCHER: Finished worker discovery
21:53:15 DISPATCHER: Starting worker discovery
21:53:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:53:15 DISPATCHER: Finished worker discovery
21:54:15 DISPATCHER: Starting worker discovery
21:54:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:54:15 DISPATCHER: Finished worker discovery
21:55:15 DISPATCHER: Starting worker discovery
21:55:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:55:15 DISPATCHER: Finished worker discovery
21:56:15 DISPATCHER: Starting worker discovery
21:56:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:56:15 DISPATCHER: Finished worker discovery
21:57:15 DISPATCHER: Starting worker discovery
21:57:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:57:15 DISPATCHER: Finished worker discovery
21:58:15 DISPATCHER: Starting worker discovery
21:58:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:58:15 DISPATCHER: Finished worker discovery
21:59:15 DISPATCHER: Starting worker discovery
21:59:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:59:15 DISPATCHER: Finished worker discovery
22:00:15 DISPATCHER: Starting worker discovery
22:00:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:00:15 DISPATCHER: Finished worker discovery
22:00:17 WORKER: done with job (3, 0, 1), trying to register it.
22:00:17 WORKER: registered result for job (3, 0, 1) with dispatcher
22:00:17 DISPATCHER: job (3, 0, 1) finished
22:00:17 DISPATCHER: register_result: lock acquired
22:00:17 DISPATCHER: job (3, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
22:00:17 job_id: (3, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.004147261058521504, 'num_filters_1': 128, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.07799117120914205, 'kernel_size_2': 7, 'num_filters_2': 82}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.0026429596270599286, 'info': {'music_genre': 0.0026429596270599286, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.004147261058521504, 'num_filters_1': 128, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.07799117120914205, 'kernel_size_2': 7, 'num_filters_2': 82}"}}
exception: None

22:00:17 job_callback for (3, 0, 1) started
22:00:17 DISPATCHER: Trying to submit another job.
22:00:17 job_callback for (3, 0, 1) got condition
22:00:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:00:17 Only 6 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
22:00:17 HBMASTER: Trying to run another job!
22:00:17 job_callback for (3, 0, 1) finished
22:00:17 start sampling a new configuration.
22:00:17 done sampling a new configuration.
22:00:17 HBMASTER: schedule new run for iteration 3
22:00:17 HBMASTER: trying submitting job (3, 0, 2) to dispatcher
22:00:17 HBMASTER: submitting job (3, 0, 2) to dispatcher
22:00:17 DISPATCHER: trying to submit job (3, 0, 2)
22:00:17 DISPATCHER: trying to notify the job_runner thread.
22:00:17 HBMASTER: job (3, 0, 2) submitted to dispatcher
22:00:17 DISPATCHER: Trying to submit another job.
22:00:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:00:17 DISPATCHER: starting job (3, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:00:17 DISPATCHER: job (3, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:00:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:00:17 WORKER: start processing job (3, 0, 2)
22:00:17 WORKER: args: ()
22:00:17 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.039140154531697426, 'num_filters_1': 58, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.06599203723546831, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 50, 'num_filters_3': 40}, 'budget': 1200.0, 'working_directory': '.'}
22:01:15 DISPATCHER: Starting worker discovery
22:01:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:01:15 DISPATCHER: Finished worker discovery
22:02:15 DISPATCHER: Starting worker discovery
22:02:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:02:15 DISPATCHER: Finished worker discovery
22:03:15 DISPATCHER: Starting worker discovery
22:03:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:03:15 DISPATCHER: Finished worker discovery
22:04:15 DISPATCHER: Starting worker discovery
22:04:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:04:15 DISPATCHER: Finished worker discovery
22:05:15 DISPATCHER: Starting worker discovery
22:05:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:05:15 DISPATCHER: Finished worker discovery
22:06:15 DISPATCHER: Starting worker discovery
22:06:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:06:15 DISPATCHER: Finished worker discovery
22:07:15 DISPATCHER: Starting worker discovery
22:07:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:07:15 DISPATCHER: Finished worker discovery
22:08:15 DISPATCHER: Starting worker discovery
22:08:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:08:15 DISPATCHER: Finished worker discovery
22:09:15 DISPATCHER: Starting worker discovery
22:09:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:09:15 DISPATCHER: Finished worker discovery
22:10:15 DISPATCHER: Starting worker discovery
22:10:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:10:15 DISPATCHER: Finished worker discovery
22:11:15 DISPATCHER: Starting worker discovery
22:11:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:11:15 DISPATCHER: Finished worker discovery
22:12:15 DISPATCHER: Starting worker discovery
22:12:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:12:15 DISPATCHER: Finished worker discovery
22:13:15 DISPATCHER: Starting worker discovery
22:13:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:13:15 DISPATCHER: Finished worker discovery
22:14:15 DISPATCHER: Starting worker discovery
22:14:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:14:16 DISPATCHER: Finished worker discovery
22:15:16 DISPATCHER: Starting worker discovery
22:15:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:15:16 DISPATCHER: Finished worker discovery
22:16:16 DISPATCHER: Starting worker discovery
22:16:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:16:16 DISPATCHER: Finished worker discovery
22:17:16 DISPATCHER: Starting worker discovery
22:17:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:17:16 DISPATCHER: Finished worker discovery
22:18:16 DISPATCHER: Starting worker discovery
22:18:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:18:16 DISPATCHER: Finished worker discovery
22:19:16 DISPATCHER: Starting worker discovery
22:19:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:19:16 DISPATCHER: Finished worker discovery
22:20:16 DISPATCHER: Starting worker discovery
22:20:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:20:16 DISPATCHER: Finished worker discovery
22:21:16 DISPATCHER: Starting worker discovery
22:21:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:21:16 DISPATCHER: Finished worker discovery
22:21:21 WORKER: done with job (3, 0, 2), trying to register it.
22:21:21 WORKER: registered result for job (3, 0, 2) with dispatcher
22:21:21 DISPATCHER: job (3, 0, 2) finished
22:21:21 DISPATCHER: register_result: lock acquired
22:21:21 DISPATCHER: job (3, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
22:21:21 job_id: (3, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.039140154531697426, 'num_filters_1': 58, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.06599203723546831, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 50, 'num_filters_3': 40}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.19991247189105343, 'info': {'music_genre': 0.19991247189105343, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.039140154531697426, 'num_filters_1': 58, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.06599203723546831, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 50, 'num_filters_3': 40}"}}
exception: None

22:21:21 job_callback for (3, 0, 2) started
22:21:21 DISPATCHER: Trying to submit another job.
22:21:21 job_callback for (3, 0, 2) got condition
22:21:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:21:21 Only 7 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
22:21:21 HBMASTER: Trying to run another job!
22:21:21 job_callback for (3, 0, 2) finished
22:21:21 start sampling a new configuration.
22:21:21 done sampling a new configuration.
22:21:21 HBMASTER: schedule new run for iteration 3
22:21:21 HBMASTER: trying submitting job (3, 0, 3) to dispatcher
22:21:21 HBMASTER: submitting job (3, 0, 3) to dispatcher
22:21:21 DISPATCHER: trying to submit job (3, 0, 3)
22:21:21 DISPATCHER: trying to notify the job_runner thread.
22:21:21 HBMASTER: job (3, 0, 3) submitted to dispatcher
22:21:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:21:21 DISPATCHER: Trying to submit another job.
22:21:21 DISPATCHER: starting job (3, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:21:21 DISPATCHER: job (3, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:21:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:21:21 WORKER: start processing job (3, 0, 3)
22:21:21 WORKER: args: ()
22:21:21 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.01485014096096295, 'num_filters_1': 63, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.015096521673890268, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 113, 'num_filters_3': 37}, 'budget': 1200.0, 'working_directory': '.'}
22:22:16 DISPATCHER: Starting worker discovery
22:22:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:22:16 DISPATCHER: Finished worker discovery
22:23:16 DISPATCHER: Starting worker discovery
22:23:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:23:16 DISPATCHER: Finished worker discovery
22:24:16 DISPATCHER: Starting worker discovery
22:24:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:24:16 DISPATCHER: Finished worker discovery
22:25:16 DISPATCHER: Starting worker discovery
22:25:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:25:16 DISPATCHER: Finished worker discovery
22:26:16 DISPATCHER: Starting worker discovery
22:26:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:26:16 DISPATCHER: Finished worker discovery
22:27:16 DISPATCHER: Starting worker discovery
22:27:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:27:16 DISPATCHER: Finished worker discovery
22:28:16 DISPATCHER: Starting worker discovery
22:28:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:28:16 DISPATCHER: Finished worker discovery
22:29:16 DISPATCHER: Starting worker discovery
22:29:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:29:16 DISPATCHER: Finished worker discovery
22:30:16 DISPATCHER: Starting worker discovery
22:30:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:30:16 DISPATCHER: Finished worker discovery
22:31:16 DISPATCHER: Starting worker discovery
22:31:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:31:16 DISPATCHER: Finished worker discovery
22:32:16 DISPATCHER: Starting worker discovery
22:32:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:32:16 DISPATCHER: Finished worker discovery
22:33:16 DISPATCHER: Starting worker discovery
22:33:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:33:16 DISPATCHER: Finished worker discovery
22:34:16 DISPATCHER: Starting worker discovery
22:34:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:34:16 DISPATCHER: Finished worker discovery
22:35:16 DISPATCHER: Starting worker discovery
22:35:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:35:16 DISPATCHER: Finished worker discovery
22:36:16 DISPATCHER: Starting worker discovery
22:36:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:36:16 DISPATCHER: Finished worker discovery
22:37:16 DISPATCHER: Starting worker discovery
22:37:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:37:16 DISPATCHER: Finished worker discovery
22:38:16 DISPATCHER: Starting worker discovery
22:38:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:38:16 DISPATCHER: Finished worker discovery
22:39:16 DISPATCHER: Starting worker discovery
22:39:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:39:16 DISPATCHER: Finished worker discovery
22:40:16 DISPATCHER: Starting worker discovery
22:40:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:40:16 DISPATCHER: Finished worker discovery
22:41:16 DISPATCHER: Starting worker discovery
22:41:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:41:16 DISPATCHER: Finished worker discovery
22:42:16 DISPATCHER: Starting worker discovery
22:42:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:42:16 DISPATCHER: Finished worker discovery
22:42:22 WORKER: done with job (3, 0, 3), trying to register it.
22:42:22 WORKER: registered result for job (3, 0, 3) with dispatcher
22:42:22 DISPATCHER: job (3, 0, 3) finished
22:42:22 DISPATCHER: register_result: lock acquired
22:42:22 DISPATCHER: job (3, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
22:42:22 job_id: (3, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.01485014096096295, 'num_filters_1': 63, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.015096521673890268, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 113, 'num_filters_3': 37}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.21357671342908946, 'info': {'music_genre': 0.21357671342908946, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.01485014096096295, 'num_filters_1': 63, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.015096521673890268, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 113, 'num_filters_3': 37}"}}
exception: None

22:42:22 job_callback for (3, 0, 3) started
22:42:22 DISPATCHER: Trying to submit another job.
22:42:22 job_callback for (3, 0, 3) got condition
22:42:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:42:22 Only 8 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
22:42:22 HBMASTER: Trying to run another job!
22:42:22 job_callback for (3, 0, 3) finished
22:42:22 start sampling a new configuration.
22:42:22 done sampling a new configuration.
22:42:22 HBMASTER: schedule new run for iteration 4
22:42:22 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
22:42:22 HBMASTER: submitting job (4, 0, 0) to dispatcher
22:42:22 DISPATCHER: trying to submit job (4, 0, 0)
22:42:22 DISPATCHER: trying to notify the job_runner thread.
22:42:22 HBMASTER: job (4, 0, 0) submitted to dispatcher
22:42:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:42:22 DISPATCHER: Trying to submit another job.
22:42:22 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:42:22 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:42:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:42:22 WORKER: start processing job (4, 0, 0)
22:42:22 WORKER: args: ()
22:42:22 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0038631211964140263, 'num_filters_1': 17, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.018207570189185833, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 77, 'num_filters_3': 40, 'num_filters_4': 126}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:43:16 DISPATCHER: Starting worker discovery
22:43:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:43:16 DISPATCHER: Finished worker discovery
22:44:04 WORKER: done with job (4, 0, 0), trying to register it.
22:44:04 WORKER: registered result for job (4, 0, 0) with dispatcher
22:44:04 DISPATCHER: job (4, 0, 0) finished
22:44:04 DISPATCHER: register_result: lock acquired
22:44:04 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
22:44:04 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0038631211964140263, 'num_filters_1': 17, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.018207570189185833, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 77, 'num_filters_3': 40, 'num_filters_4': 126}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.44253950438086986, 'info': {'music_genre': 0.44253950438086986, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0038631211964140263, 'num_filters_1': 17, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.018207570189185833, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 77, 'num_filters_3': 40, 'num_filters_4': 126}"}}
exception: None

22:44:04 job_callback for (4, 0, 0) started
22:44:04 job_callback for (4, 0, 0) got condition
22:44:04 DISPATCHER: Trying to submit another job.
22:44:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:44:04 HBMASTER: Trying to run another job!
22:44:04 job_callback for (4, 0, 0) finished
22:44:04 start sampling a new configuration.
22:44:04 done sampling a new configuration.
22:44:04 HBMASTER: schedule new run for iteration 4
22:44:04 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
22:44:04 HBMASTER: submitting job (4, 0, 1) to dispatcher
22:44:04 DISPATCHER: trying to submit job (4, 0, 1)
22:44:04 DISPATCHER: trying to notify the job_runner thread.
22:44:04 HBMASTER: job (4, 0, 1) submitted to dispatcher
22:44:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:44:04 DISPATCHER: Trying to submit another job.
22:44:04 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:44:04 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:44:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:44:04 WORKER: start processing job (4, 0, 1)
22:44:04 WORKER: args: ()
22:44:04 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004304783069984872, 'num_filters_1': 73, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.029544803860486878, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 36, 'num_filters_3': 45, 'num_filters_4': 38, 'num_filters_5': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:44:16 DISPATCHER: Starting worker discovery
22:44:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:44:16 DISPATCHER: Finished worker discovery
22:45:16 DISPATCHER: Starting worker discovery
22:45:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:45:16 DISPATCHER: Finished worker discovery
22:45:46 WORKER: done with job (4, 0, 1), trying to register it.
22:45:46 WORKER: registered result for job (4, 0, 1) with dispatcher
22:45:46 DISPATCHER: job (4, 0, 1) finished
22:45:46 DISPATCHER: register_result: lock acquired
22:45:46 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
22:45:46 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004304783069984872, 'num_filters_1': 73, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.029544803860486878, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 36, 'num_filters_3': 45, 'num_filters_4': 38, 'num_filters_5': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4160908527796846, 'info': {'music_genre': 0.4160908527796846, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004304783069984872, 'num_filters_1': 73, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.029544803860486878, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 36, 'num_filters_3': 45, 'num_filters_4': 38, 'num_filters_5': 18}"}}
exception: None

22:45:46 job_callback for (4, 0, 1) started
22:45:46 DISPATCHER: Trying to submit another job.
22:45:46 job_callback for (4, 0, 1) got condition
22:45:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:45:46 HBMASTER: Trying to run another job!
22:45:46 job_callback for (4, 0, 1) finished
22:45:46 start sampling a new configuration.
22:45:46 done sampling a new configuration.
22:45:46 HBMASTER: schedule new run for iteration 4
22:45:46 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
22:45:46 HBMASTER: submitting job (4, 0, 2) to dispatcher
22:45:46 DISPATCHER: trying to submit job (4, 0, 2)
22:45:46 DISPATCHER: trying to notify the job_runner thread.
22:45:46 HBMASTER: job (4, 0, 2) submitted to dispatcher
22:45:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:45:46 DISPATCHER: Trying to submit another job.
22:45:46 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:45:46 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:45:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:45:46 WORKER: start processing job (4, 0, 2)
22:45:46 WORKER: args: ()
22:45:46 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0014162377383362989, 'num_filters_1': 66, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.012569834719951378}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:46:16 DISPATCHER: Starting worker discovery
22:46:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:46:16 DISPATCHER: Finished worker discovery
22:47:16 DISPATCHER: Starting worker discovery
22:47:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:47:16 DISPATCHER: Finished worker discovery
22:47:26 WORKER: done with job (4, 0, 2), trying to register it.
22:47:26 WORKER: registered result for job (4, 0, 2) with dispatcher
22:47:26 DISPATCHER: job (4, 0, 2) finished
22:47:26 DISPATCHER: register_result: lock acquired
22:47:26 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
22:47:26 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0014162377383362989, 'num_filters_1': 66, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.012569834719951378}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3000422360269963, 'info': {'music_genre': 0.3000422360269963, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0014162377383362989, 'num_filters_1': 66, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.012569834719951378}"}}
exception: None

22:47:26 job_callback for (4, 0, 2) started
22:47:26 DISPATCHER: Trying to submit another job.
22:47:26 job_callback for (4, 0, 2) got condition
22:47:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:47:26 HBMASTER: Trying to run another job!
22:47:26 job_callback for (4, 0, 2) finished
22:47:26 start sampling a new configuration.
22:47:26 done sampling a new configuration.
22:47:26 HBMASTER: schedule new run for iteration 4
22:47:26 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
22:47:26 HBMASTER: submitting job (4, 0, 3) to dispatcher
22:47:26 DISPATCHER: trying to submit job (4, 0, 3)
22:47:26 DISPATCHER: trying to notify the job_runner thread.
22:47:26 HBMASTER: job (4, 0, 3) submitted to dispatcher
22:47:26 DISPATCHER: Trying to submit another job.
22:47:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:47:26 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:47:26 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:47:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:47:26 WORKER: start processing job (4, 0, 3)
22:47:26 WORKER: args: ()
22:47:26 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.03299812435576623, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.01572126900139441, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 21, 'num_filters_3': 39, 'num_filters_4': 38, 'num_filters_5': 44}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:48:16 DISPATCHER: Starting worker discovery
22:48:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:48:16 DISPATCHER: Finished worker discovery
22:49:07 WORKER: done with job (4, 0, 3), trying to register it.
22:49:07 WORKER: registered result for job (4, 0, 3) with dispatcher
22:49:07 DISPATCHER: job (4, 0, 3) finished
22:49:07 DISPATCHER: register_result: lock acquired
22:49:07 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
22:49:07 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.03299812435576623, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.01572126900139441, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 21, 'num_filters_3': 39, 'num_filters_4': 38, 'num_filters_5': 44}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1973044439000283, 'info': {'music_genre': 0.1973044439000283, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.03299812435576623, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.01572126900139441, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 21, 'num_filters_3': 39, 'num_filters_4': 38, 'num_filters_5': 44}"}}
exception: None

22:49:07 job_callback for (4, 0, 3) started
22:49:07 DISPATCHER: Trying to submit another job.
22:49:07 job_callback for (4, 0, 3) got condition
22:49:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:49:07 HBMASTER: Trying to run another job!
22:49:07 job_callback for (4, 0, 3) finished
22:49:07 start sampling a new configuration.
22:49:07 done sampling a new configuration.
22:49:07 HBMASTER: schedule new run for iteration 4
22:49:07 HBMASTER: trying submitting job (4, 0, 4) to dispatcher
22:49:07 HBMASTER: submitting job (4, 0, 4) to dispatcher
22:49:07 DISPATCHER: trying to submit job (4, 0, 4)
22:49:07 DISPATCHER: trying to notify the job_runner thread.
22:49:07 HBMASTER: job (4, 0, 4) submitted to dispatcher
22:49:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:49:07 DISPATCHER: Trying to submit another job.
22:49:07 DISPATCHER: starting job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:49:07 DISPATCHER: job (4, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:49:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:49:07 WORKER: start processing job (4, 0, 4)
22:49:07 WORKER: args: ()
22:49:07 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0018822824147314808, 'num_filters_1': 127, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.10723792543746426}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:49:16 DISPATCHER: Starting worker discovery
22:49:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:49:16 DISPATCHER: Finished worker discovery
22:50:16 DISPATCHER: Starting worker discovery
22:50:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:50:16 DISPATCHER: Finished worker discovery
22:50:47 WORKER: done with job (4, 0, 4), trying to register it.
22:50:47 WORKER: registered result for job (4, 0, 4) with dispatcher
22:50:47 DISPATCHER: job (4, 0, 4) finished
22:50:47 DISPATCHER: register_result: lock acquired
22:50:47 DISPATCHER: job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
22:50:47 job_id: (4, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0018822824147314808, 'num_filters_1': 127, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.10723792543746426}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4837698995430772, 'info': {'music_genre': 0.4837698995430772, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0018822824147314808, 'num_filters_1': 127, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.10723792543746426}"}}
exception: None

22:50:47 job_callback for (4, 0, 4) started
22:50:47 job_callback for (4, 0, 4) got condition
22:50:47 DISPATCHER: Trying to submit another job.
22:50:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:50:47 HBMASTER: Trying to run another job!
22:50:47 job_callback for (4, 0, 4) finished
22:50:47 start sampling a new configuration.
22:50:47 done sampling a new configuration.
22:50:48 HBMASTER: schedule new run for iteration 4
22:50:48 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
22:50:48 HBMASTER: submitting job (4, 0, 5) to dispatcher
22:50:48 DISPATCHER: trying to submit job (4, 0, 5)
22:50:48 DISPATCHER: trying to notify the job_runner thread.
22:50:48 HBMASTER: job (4, 0, 5) submitted to dispatcher
22:50:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:50:48 DISPATCHER: Trying to submit another job.
22:50:48 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:50:48 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:50:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:50:48 WORKER: start processing job (4, 0, 5)
22:50:48 WORKER: args: ()
22:50:48 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.00975715908855558, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.09280605171065515}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:51:16 DISPATCHER: Starting worker discovery
22:51:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:51:16 DISPATCHER: Finished worker discovery
22:52:16 DISPATCHER: Starting worker discovery
22:52:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:52:16 DISPATCHER: Finished worker discovery
22:52:28 WORKER: done with job (4, 0, 5), trying to register it.
22:52:28 WORKER: registered result for job (4, 0, 5) with dispatcher
22:52:28 DISPATCHER: job (4, 0, 5) finished
22:52:28 DISPATCHER: register_result: lock acquired
22:52:28 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
22:52:28 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.00975715908855558, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.09280605171065515}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.11444883897349563, 'info': {'music_genre': 0.11444883897349563, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.00975715908855558, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.09280605171065515}"}}
exception: None

22:52:28 job_callback for (4, 0, 5) started
22:52:28 job_callback for (4, 0, 5) got condition
22:52:28 DISPATCHER: Trying to submit another job.
22:52:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:52:28 HBMASTER: Trying to run another job!
22:52:28 job_callback for (4, 0, 5) finished
22:52:28 start sampling a new configuration.
22:52:28 done sampling a new configuration.
22:52:28 HBMASTER: schedule new run for iteration 4
22:52:28 HBMASTER: trying submitting job (4, 0, 6) to dispatcher
22:52:28 HBMASTER: submitting job (4, 0, 6) to dispatcher
22:52:28 DISPATCHER: trying to submit job (4, 0, 6)
22:52:28 DISPATCHER: trying to notify the job_runner thread.
22:52:28 HBMASTER: job (4, 0, 6) submitted to dispatcher
22:52:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:52:28 DISPATCHER: Trying to submit another job.
22:52:28 DISPATCHER: starting job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:52:28 DISPATCHER: job (4, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:52:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:52:28 WORKER: start processing job (4, 0, 6)
22:52:28 WORKER: args: ()
22:52:28 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.019886175781580206, 'num_filters_1': 110, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.015644716209705097, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 38, 'num_filters_3': 96}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:53:16 DISPATCHER: Starting worker discovery
22:53:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:53:16 DISPATCHER: Finished worker discovery
22:54:07 WORKER: done with job (4, 0, 6), trying to register it.
22:54:07 WORKER: registered result for job (4, 0, 6) with dispatcher
22:54:07 DISPATCHER: job (4, 0, 6) finished
22:54:07 DISPATCHER: register_result: lock acquired
22:54:07 DISPATCHER: job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
22:54:07 job_id: (4, 0, 6)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.019886175781580206, 'num_filters_1': 110, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.015644716209705097, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 38, 'num_filters_3': 96}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.42466737773460367, 'info': {'music_genre': 0.42466737773460367, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.019886175781580206, 'num_filters_1': 110, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.015644716209705097, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 38, 'num_filters_3': 96}"}}
exception: None

22:54:07 job_callback for (4, 0, 6) started
22:54:07 job_callback for (4, 0, 6) got condition
22:54:07 DISPATCHER: Trying to submit another job.
22:54:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:54:07 done building a new model for budget 44.444444 based on 17/28 split
Best loss for this budget:-0.483770





22:54:07 HBMASTER: Trying to run another job!
22:54:07 job_callback for (4, 0, 6) finished
22:54:07 start sampling a new configuration.
22:54:07 done sampling a new configuration.
22:54:07 HBMASTER: schedule new run for iteration 4
22:54:07 HBMASTER: trying submitting job (4, 0, 7) to dispatcher
22:54:07 HBMASTER: submitting job (4, 0, 7) to dispatcher
22:54:07 DISPATCHER: trying to submit job (4, 0, 7)
22:54:07 DISPATCHER: trying to notify the job_runner thread.
22:54:07 HBMASTER: job (4, 0, 7) submitted to dispatcher
22:54:07 DISPATCHER: Trying to submit another job.
22:54:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:54:07 DISPATCHER: starting job (4, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:54:07 DISPATCHER: job (4, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:54:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:54:07 WORKER: start processing job (4, 0, 7)
22:54:07 WORKER: args: ()
22:54:07 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.008451116123301563, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.032511293971584705, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 118, 'num_filters_3': 96, 'num_filters_4': 36}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:54:16 DISPATCHER: Starting worker discovery
22:54:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:54:16 DISPATCHER: Finished worker discovery
22:55:16 DISPATCHER: Starting worker discovery
22:55:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:55:16 DISPATCHER: Finished worker discovery
22:55:47 WORKER: done with job (4, 0, 7), trying to register it.
22:55:47 WORKER: registered result for job (4, 0, 7) with dispatcher
22:55:47 DISPATCHER: job (4, 0, 7) finished
22:55:47 DISPATCHER: register_result: lock acquired
22:55:47 DISPATCHER: job (4, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
22:55:47 job_id: (4, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.008451116123301563, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.032511293971584705, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 118, 'num_filters_3': 96, 'num_filters_4': 36}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 8.536555545790627e-05, 'info': {'music_genre': -8.536555545790627e-05, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.008451116123301563, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.032511293971584705, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 118, 'num_filters_3': 96, 'num_filters_4': 36}"}}
exception: None

22:55:47 job_callback for (4, 0, 7) started
22:55:47 DISPATCHER: Trying to submit another job.
22:55:47 job_callback for (4, 0, 7) got condition
22:55:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:55:47 done building a new model for budget 44.444444 based on 17/29 split
Best loss for this budget:-0.483770





22:55:47 HBMASTER: Trying to run another job!
22:55:47 job_callback for (4, 0, 7) finished
22:55:47 start sampling a new configuration.
22:55:47 best_vector: [2, 0, 0.2160931071940397, 0.9665298822688706, 0.3344931298065684, 1, 0.6623329839930066, 0.8377517412243327, 2, 0, 1, 2, 0.3387644894159587, 0.6239342334076093, 0.7070253818888341, 0.550210236460648], 3.243280441958728e-29, 0.00030832979691267954, -1.5931919541794335e-08
22:55:47 done sampling a new configuration.
22:55:47 HBMASTER: schedule new run for iteration 4
22:55:47 HBMASTER: trying submitting job (4, 0, 8) to dispatcher
22:55:47 HBMASTER: submitting job (4, 0, 8) to dispatcher
22:55:47 DISPATCHER: trying to submit job (4, 0, 8)
22:55:47 DISPATCHER: trying to notify the job_runner thread.
22:55:47 HBMASTER: job (4, 0, 8) submitted to dispatcher
22:55:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:55:47 DISPATCHER: Trying to submit another job.
22:55:47 DISPATCHER: starting job (4, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:55:47 DISPATCHER: job (4, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:55:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:55:47 WORKER: start processing job (4, 0, 8)
22:55:47 WORKER: args: ()
22:55:47 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0027051180010279736, 'num_filters_1': 120, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.12300992232230164, 'kernel_size_2': 7, 'num_filters_2': 32}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:56:16 DISPATCHER: Starting worker discovery
22:56:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:56:16 DISPATCHER: Finished worker discovery
22:57:16 DISPATCHER: Starting worker discovery
22:57:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:57:16 DISPATCHER: Finished worker discovery
22:57:27 WORKER: done with job (4, 0, 8), trying to register it.
22:57:27 WORKER: registered result for job (4, 0, 8) with dispatcher
22:57:27 DISPATCHER: job (4, 0, 8) finished
22:57:27 DISPATCHER: register_result: lock acquired
22:57:27 DISPATCHER: job (4, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
22:57:27 job_id: (4, 0, 8)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0027051180010279736, 'num_filters_1': 120, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.12300992232230164, 'kernel_size_2': 7, 'num_filters_2': 32}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3940743654706581, 'info': {'music_genre': 0.3940743654706581, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0027051180010279736, 'num_filters_1': 120, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.12300992232230164, 'kernel_size_2': 7, 'num_filters_2': 32}"}}
exception: None

22:57:27 job_callback for (4, 0, 8) started
22:57:27 job_callback for (4, 0, 8) got condition
22:57:27 DISPATCHER: Trying to submit another job.
22:57:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:57:27 done building a new model for budget 44.444444 based on 17/30 split
Best loss for this budget:-0.483770





22:57:27 HBMASTER: Trying to run another job!
22:57:27 job_callback for (4, 0, 8) finished
22:57:27 start sampling a new configuration.
22:57:27 done sampling a new configuration.
22:57:27 HBMASTER: schedule new run for iteration 4
22:57:27 HBMASTER: trying submitting job (4, 0, 9) to dispatcher
22:57:27 HBMASTER: submitting job (4, 0, 9) to dispatcher
22:57:27 DISPATCHER: trying to submit job (4, 0, 9)
22:57:27 DISPATCHER: trying to notify the job_runner thread.
22:57:27 HBMASTER: job (4, 0, 9) submitted to dispatcher
22:57:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:57:27 DISPATCHER: Trying to submit another job.
22:57:27 DISPATCHER: starting job (4, 0, 9) on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:57:27 DISPATCHER: job (4, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:57:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:57:27 WORKER: start processing job (4, 0, 9)
22:57:27 WORKER: args: ()
22:57:27 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.02248480038165544, 'num_filters_1': 121, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.04514578043269313, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 19, 'num_filters_3': 31}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:58:16 DISPATCHER: Starting worker discovery
22:58:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:58:16 DISPATCHER: Finished worker discovery
22:59:07 WORKER: done with job (4, 0, 9), trying to register it.
22:59:07 WORKER: registered result for job (4, 0, 9) with dispatcher
22:59:07 DISPATCHER: job (4, 0, 9) finished
22:59:07 DISPATCHER: register_result: lock acquired
22:59:07 DISPATCHER: job (4, 0, 9) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
22:59:07 job_id: (4, 0, 9)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.02248480038165544, 'num_filters_1': 121, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.04514578043269313, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 19, 'num_filters_3': 31}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.02248480038165544, 'num_filters_1': 121, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.04514578043269313, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 19, 'num_filters_3': 31}"}}
exception: None

22:59:07 job_callback for (4, 0, 9) started
22:59:08 DISPATCHER: Trying to submit another job.
22:59:08 job_callback for (4, 0, 9) got condition
22:59:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:59:08 done building a new model for budget 44.444444 based on 17/31 split
Best loss for this budget:-0.483770





22:59:08 HBMASTER: Trying to run another job!
22:59:08 job_callback for (4, 0, 9) finished
22:59:08 start sampling a new configuration.
22:59:08 best_vector: [1, 2, 0.14514092739809484, 0.771690198270435, 0.0053613693793446715, 1, 0.41886714224824173, 0.30922284521375465, 0, 1, 1, 1, 0.7469401463744055, 0.6837627074430301, 0.08194719699419079, 0.34639521888954994], 2.1173238934853664e-29, 0.0004722942970968326, -9.570736691063931e-26
22:59:08 done sampling a new configuration.
22:59:08 HBMASTER: schedule new run for iteration 4
22:59:08 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
22:59:08 HBMASTER: submitting job (4, 0, 10) to dispatcher
22:59:08 DISPATCHER: trying to submit job (4, 0, 10)
22:59:08 DISPATCHER: trying to notify the job_runner thread.
22:59:08 HBMASTER: job (4, 0, 10) submitted to dispatcher
22:59:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:59:08 DISPATCHER: Trying to submit another job.
22:59:08 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:59:08 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
22:59:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:59:08 WORKER: start processing job (4, 0, 10)
22:59:08 WORKER: args: ()
22:59:08 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0019511104491960318, 'num_filters_1': 79, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.02525272195529587}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:59:16 DISPATCHER: Starting worker discovery
22:59:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:59:16 DISPATCHER: Finished worker discovery
23:00:16 DISPATCHER: Starting worker discovery
23:00:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:00:16 DISPATCHER: Finished worker discovery
23:00:48 WORKER: done with job (4, 0, 10), trying to register it.
23:00:48 WORKER: registered result for job (4, 0, 10) with dispatcher
23:00:48 DISPATCHER: job (4, 0, 10) finished
23:00:48 DISPATCHER: register_result: lock acquired
23:00:48 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:00:48 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0019511104491960318, 'num_filters_1': 79, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.02525272195529587}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.43451912577574525, 'info': {'music_genre': 0.43451912577574525, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0019511104491960318, 'num_filters_1': 79, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.02525272195529587}"}}
exception: None

23:00:48 job_callback for (4, 0, 10) started
23:00:48 job_callback for (4, 0, 10) got condition
23:00:48 DISPATCHER: Trying to submit another job.
23:00:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:00:48 done building a new model for budget 44.444444 based on 17/32 split
Best loss for this budget:-0.483770





23:00:48 HBMASTER: Trying to run another job!
23:00:48 job_callback for (4, 0, 10) finished
23:00:48 start sampling a new configuration.
23:00:48 best_vector: [0, 1, 0.5796391141142884, 0.7914958552623887, 0.6771828554500179, 1, 0.02628196177838047, 0.4418184472535804, 2, 0, 2, 1, 0.47018263782945163, 0.7879496770996, 0.9933051732491036, 0.49515296918007257], 8.548009824408099e-30, 0.0011698629511919688, 3.617734183857958e-33
23:00:48 done sampling a new configuration.
23:00:48 HBMASTER: schedule new run for iteration 4
23:00:48 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
23:00:48 HBMASTER: submitting job (4, 0, 11) to dispatcher
23:00:48 DISPATCHER: trying to submit job (4, 0, 11)
23:00:48 DISPATCHER: trying to notify the job_runner thread.
23:00:48 HBMASTER: job (4, 0, 11) submitted to dispatcher
23:00:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:00:48 DISPATCHER: Trying to submit another job.
23:00:48 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:00:48 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:00:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:00:48 WORKER: start processing job (4, 0, 11)
23:00:48 WORKER: args: ()
23:00:48 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.014430395303228274, 'num_filters_1': 83, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.03756808453851936, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 42, 'num_filters_3': 82, 'num_filters_4': 127}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:01:16 DISPATCHER: Starting worker discovery
23:01:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:01:16 DISPATCHER: Finished worker discovery
23:02:16 DISPATCHER: Starting worker discovery
23:02:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:02:16 DISPATCHER: Finished worker discovery
23:02:31 WORKER: done with job (4, 0, 11), trying to register it.
23:02:31 WORKER: registered result for job (4, 0, 11) with dispatcher
23:02:31 DISPATCHER: job (4, 0, 11) finished
23:02:31 DISPATCHER: register_result: lock acquired
23:02:31 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:02:31 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.014430395303228274, 'num_filters_1': 83, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.03756808453851936, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 42, 'num_filters_3': 82, 'num_filters_4': 127}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3618617337342584, 'info': {'music_genre': 0.3618617337342584, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.014430395303228274, 'num_filters_1': 83, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.03756808453851936, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 42, 'num_filters_3': 82, 'num_filters_4': 127}"}}
exception: None

23:02:31 job_callback for (4, 0, 11) started
23:02:31 DISPATCHER: Trying to submit another job.
23:02:31 job_callback for (4, 0, 11) got condition
23:02:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:02:31 done building a new model for budget 44.444444 based on 17/33 split
Best loss for this budget:-0.483770





23:02:31 HBMASTER: Trying to run another job!
23:02:31 job_callback for (4, 0, 11) finished
23:02:31 start sampling a new configuration.
23:02:31 done sampling a new configuration.
23:02:31 HBMASTER: schedule new run for iteration 4
23:02:31 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
23:02:31 HBMASTER: submitting job (4, 0, 12) to dispatcher
23:02:31 DISPATCHER: trying to submit job (4, 0, 12)
23:02:31 DISPATCHER: trying to notify the job_runner thread.
23:02:31 HBMASTER: job (4, 0, 12) submitted to dispatcher
23:02:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:02:31 DISPATCHER: Trying to submit another job.
23:02:31 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:02:31 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:02:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:02:31 WORKER: start processing job (4, 0, 12)
23:02:31 WORKER: args: ()
23:02:31 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.06855016810390284, 'num_filters_1': 59, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.01979061989378043, 'kernel_size_2': 3, 'num_filters_2': 119}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:03:16 DISPATCHER: Starting worker discovery
23:03:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:03:16 DISPATCHER: Finished worker discovery
Exception in thread Thread-679:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    preds = np.concatenate(preds)
IndexError: index 4607182418800017408 is out of bounds for axis 0 with size 10

23:04:10 WORKER: done with job (4, 0, 12), trying to register it.
23:04:10 WORKER: registered result for job (4, 0, 12) with dispatcher
23:04:10 DISPATCHER: job (4, 0, 12) finished
23:04:10 DISPATCHER: register_result: lock acquired
23:04:10 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:04:10 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.06855016810390284, 'num_filters_1': 59, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.01979061989378043, 'kernel_size_2': 3, 'num_filters_2': 119}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4064082006702618, 'info': {'music_genre': 0.4064082006702618, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.06855016810390284, 'num_filters_1': 59, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.01979061989378043, 'kernel_size_2': 3, 'num_filters_2': 119}"}}
exception: None

23:04:10 job_callback for (4, 0, 12) started
23:04:10 DISPATCHER: Trying to submit another job.
23:04:10 job_callback for (4, 0, 12) got condition
23:04:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:04:10 done building a new model for budget 44.444444 based on 17/34 split
Best loss for this budget:-0.483770





23:04:10 HBMASTER: Trying to run another job!
23:04:10 job_callback for (4, 0, 12) finished
23:04:10 start sampling a new configuration.
23:04:10 best_vector: [3, 1, 0.32802508429205396, 0.5460421950879997, 0.8332464608913348, 1, 0.7107924848287686, 0.5795008874965057, 0, 2, 2, 1, 0.49889927383025917, 0.7890082081639664, 0.8327208539574341, 0.6493172886189919], 3.29971802132111e-29, 0.0003030561986019731, -8.967081314697965e-15
23:04:10 done sampling a new configuration.
23:04:10 HBMASTER: schedule new run for iteration 4
23:04:10 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
23:04:10 HBMASTER: submitting job (4, 0, 13) to dispatcher
23:04:10 DISPATCHER: trying to submit job (4, 0, 13)
23:04:10 DISPATCHER: trying to notify the job_runner thread.
23:04:10 HBMASTER: job (4, 0, 13) submitted to dispatcher
23:04:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:04:10 DISPATCHER: Trying to submit another job.
23:04:10 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:04:10 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:04:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:04:10 WORKER: start processing job (4, 0, 13)
23:04:10 WORKER: args: ()
23:04:10 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.004529499004917843, 'num_filters_1': 49, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.05674767033881716, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 45, 'num_filters_3': 82, 'num_filters_4': 90, 'num_filters_5': 61}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:04:16 DISPATCHER: Starting worker discovery
23:04:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:04:16 DISPATCHER: Finished worker discovery
23:05:16 DISPATCHER: Starting worker discovery
23:05:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:05:16 DISPATCHER: Finished worker discovery
23:05:51 WORKER: done with job (4, 0, 13), trying to register it.
23:05:51 WORKER: registered result for job (4, 0, 13) with dispatcher
23:05:51 DISPATCHER: job (4, 0, 13) finished
23:05:51 DISPATCHER: register_result: lock acquired
23:05:51 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:05:51 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.004529499004917843, 'num_filters_1': 49, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.05674767033881716, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 45, 'num_filters_3': 82, 'num_filters_4': 90, 'num_filters_5': 61}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.44914164468366996, 'info': {'music_genre': 0.44914164468366996, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.004529499004917843, 'num_filters_1': 49, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.05674767033881716, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 45, 'num_filters_3': 82, 'num_filters_4': 90, 'num_filters_5': 61}"}}
exception: None

23:05:51 job_callback for (4, 0, 13) started
23:05:51 job_callback for (4, 0, 13) got condition
23:05:51 DISPATCHER: Trying to submit another job.
23:05:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:05:51 done building a new model for budget 44.444444 based on 17/34 split
Best loss for this budget:-0.483770





23:05:51 HBMASTER: Trying to run another job!
23:05:51 job_callback for (4, 0, 13) finished
23:05:51 start sampling a new configuration.
23:05:51 done sampling a new configuration.
23:05:51 HBMASTER: schedule new run for iteration 4
23:05:51 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
23:05:51 HBMASTER: submitting job (4, 0, 14) to dispatcher
23:05:51 DISPATCHER: trying to submit job (4, 0, 14)
23:05:51 DISPATCHER: trying to notify the job_runner thread.
23:05:51 HBMASTER: job (4, 0, 14) submitted to dispatcher
23:05:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:05:51 DISPATCHER: Trying to submit another job.
23:05:51 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:05:51 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:05:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:05:51 WORKER: start processing job (4, 0, 14)
23:05:51 WORKER: args: ()
23:05:51 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0018959391412729037, 'num_filters_1': 27, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.11276572732739437, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 112, 'num_filters_3': 65}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:06:16 DISPATCHER: Starting worker discovery
23:06:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:06:16 DISPATCHER: Finished worker discovery
23:07:16 DISPATCHER: Starting worker discovery
23:07:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:07:16 DISPATCHER: Finished worker discovery
23:07:30 WORKER: done with job (4, 0, 14), trying to register it.
23:07:30 WORKER: registered result for job (4, 0, 14) with dispatcher
23:07:30 DISPATCHER: job (4, 0, 14) finished
23:07:30 DISPATCHER: register_result: lock acquired
23:07:30 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:07:30 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0018959391412729037, 'num_filters_1': 27, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.11276572732739437, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 112, 'num_filters_3': 65}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.49965592213093285, 'info': {'music_genre': 0.49965592213093285, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0018959391412729037, 'num_filters_1': 27, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.11276572732739437, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 112, 'num_filters_3': 65}"}}
exception: None

23:07:30 job_callback for (4, 0, 14) started
23:07:30 job_callback for (4, 0, 14) got condition
23:07:30 DISPATCHER: Trying to submit another job.
23:07:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:07:30 done building a new model for budget 44.444444 based on 17/35 split
Best loss for this budget:-0.499656





23:07:30 HBMASTER: Trying to run another job!
23:07:30 job_callback for (4, 0, 14) finished
23:07:30 start sampling a new configuration.
23:07:30 done sampling a new configuration.
23:07:30 HBMASTER: schedule new run for iteration 4
23:07:30 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
23:07:30 HBMASTER: submitting job (4, 0, 15) to dispatcher
23:07:30 DISPATCHER: trying to submit job (4, 0, 15)
23:07:30 DISPATCHER: trying to notify the job_runner thread.
23:07:30 HBMASTER: job (4, 0, 15) submitted to dispatcher
23:07:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:07:30 DISPATCHER: Trying to submit another job.
23:07:30 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:07:30 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:07:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:07:30 WORKER: start processing job (4, 0, 15)
23:07:30 WORKER: args: ()
23:07:30 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0012072433041419048, 'num_filters_1': 99, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.07741634407836703, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 57, 'num_filters_3': 22, 'num_filters_4': 21}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:08:16 DISPATCHER: Starting worker discovery
23:08:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:08:16 DISPATCHER: Finished worker discovery
23:09:11 WORKER: done with job (4, 0, 15), trying to register it.
23:09:11 WORKER: registered result for job (4, 0, 15) with dispatcher
23:09:11 DISPATCHER: job (4, 0, 15) finished
23:09:11 DISPATCHER: register_result: lock acquired
23:09:11 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:09:11 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0012072433041419048, 'num_filters_1': 99, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.07741634407836703, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 57, 'num_filters_3': 22, 'num_filters_4': 21}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2510689618949895, 'info': {'music_genre': 0.2510689618949895, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0012072433041419048, 'num_filters_1': 99, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.07741634407836703, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 57, 'num_filters_3': 22, 'num_filters_4': 21}"}}
exception: None

23:09:11 job_callback for (4, 0, 15) started
23:09:11 job_callback for (4, 0, 15) got condition
23:09:11 DISPATCHER: Trying to submit another job.
23:09:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:09:11 done building a new model for budget 44.444444 based on 17/36 split
Best loss for this budget:-0.499656





23:09:11 HBMASTER: Trying to run another job!
23:09:11 job_callback for (4, 0, 15) finished
23:09:11 start sampling a new configuration.
23:09:11 done sampling a new configuration.
23:09:11 HBMASTER: schedule new run for iteration 4
23:09:11 HBMASTER: trying submitting job (4, 0, 16) to dispatcher
23:09:11 HBMASTER: submitting job (4, 0, 16) to dispatcher
23:09:11 DISPATCHER: trying to submit job (4, 0, 16)
23:09:11 DISPATCHER: trying to notify the job_runner thread.
23:09:11 HBMASTER: job (4, 0, 16) submitted to dispatcher
23:09:11 DISPATCHER: Trying to submit another job.
23:09:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:09:11 DISPATCHER: starting job (4, 0, 16) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:09:11 DISPATCHER: job (4, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:09:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:09:11 WORKER: start processing job (4, 0, 16)
23:09:11 WORKER: args: ()
23:09:11 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.020038447896682198, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.17947468120941495, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 16, 'num_filters_3': 33, 'num_filters_4': 29}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:09:16 DISPATCHER: Starting worker discovery
23:09:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:09:16 DISPATCHER: Finished worker discovery
23:10:16 DISPATCHER: Starting worker discovery
23:10:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:10:16 DISPATCHER: Finished worker discovery
23:10:50 WORKER: done with job (4, 0, 16), trying to register it.
23:10:50 WORKER: registered result for job (4, 0, 16) with dispatcher
23:10:50 DISPATCHER: job (4, 0, 16) finished
23:10:50 DISPATCHER: register_result: lock acquired
23:10:50 DISPATCHER: job (4, 0, 16) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:10:50 job_id: (4, 0, 16)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.020038447896682198, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.17947468120941495, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 16, 'num_filters_3': 33, 'num_filters_4': 29}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.020038447896682198, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.17947468120941495, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 16, 'num_filters_3': 33, 'num_filters_4': 29}"}}
exception: None

23:10:50 job_callback for (4, 0, 16) started
23:10:50 job_callback for (4, 0, 16) got condition
23:10:50 DISPATCHER: Trying to submit another job.
23:10:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:10:50 done building a new model for budget 44.444444 based on 17/37 split
Best loss for this budget:-0.499656





23:10:50 HBMASTER: Trying to run another job!
23:10:50 job_callback for (4, 0, 16) finished
23:10:50 start sampling a new configuration.
23:10:50 best_vector: [0, 1, 0.8731110879340858, 0.8413802695263118, 0.2736304520420783, 1, 0.8356564940213357, 0.6908349090365913, 0, 1, 2, 0, 0.8276133653758956, 0.9096081170570038, 0.5077473911970074, 0.0684776174105469], 1.9528302499639494e-10, 0.00037227128060820125, 7.269826179645132e-14
23:10:50 done sampling a new configuration.
23:10:50 HBMASTER: schedule new run for iteration 4
23:10:50 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
23:10:50 HBMASTER: submitting job (4, 0, 17) to dispatcher
23:10:50 DISPATCHER: trying to submit job (4, 0, 17)
23:10:50 DISPATCHER: trying to notify the job_runner thread.
23:10:50 HBMASTER: job (4, 0, 17) submitted to dispatcher
23:10:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:10:50 DISPATCHER: Trying to submit another job.
23:10:50 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:10:50 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:10:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:10:50 WORKER: start processing job (4, 0, 17)
23:10:50 WORKER: args: ()
23:10:50 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.05574708662959766, 'num_filters_1': 92, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.07921308704942392, 'kernel_size_2': 3, 'num_filters_2': 89}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:11:16 DISPATCHER: Starting worker discovery
23:11:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:11:16 DISPATCHER: Finished worker discovery
23:12:16 DISPATCHER: Starting worker discovery
23:12:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:12:16 DISPATCHER: Finished worker discovery
23:12:30 WORKER: done with job (4, 0, 17), trying to register it.
23:12:30 WORKER: registered result for job (4, 0, 17) with dispatcher
23:12:30 DISPATCHER: job (4, 0, 17) finished
23:12:30 DISPATCHER: register_result: lock acquired
23:12:30 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:12:30 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.05574708662959766, 'num_filters_1': 92, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.07921308704942392, 'kernel_size_2': 3, 'num_filters_2': 89}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2235211681628601, 'info': {'music_genre': 0.2235211681628601, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.05574708662959766, 'num_filters_1': 92, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.07921308704942392, 'kernel_size_2': 3, 'num_filters_2': 89}"}}
exception: None

23:12:30 job_callback for (4, 0, 17) started
23:12:30 DISPATCHER: Trying to submit another job.
23:12:30 job_callback for (4, 0, 17) got condition
23:12:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:12:30 done building a new model for budget 44.444444 based on 17/38 split
Best loss for this budget:-0.499656





23:12:30 HBMASTER: Trying to run another job!
23:12:30 job_callback for (4, 0, 17) finished
23:12:30 start sampling a new configuration.
23:12:30 done sampling a new configuration.
23:12:30 HBMASTER: schedule new run for iteration 4
23:12:30 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
23:12:30 HBMASTER: submitting job (4, 0, 18) to dispatcher
23:12:30 DISPATCHER: trying to submit job (4, 0, 18)
23:12:30 DISPATCHER: trying to notify the job_runner thread.
23:12:30 HBMASTER: job (4, 0, 18) submitted to dispatcher
23:12:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:12:30 DISPATCHER: Trying to submit another job.
23:12:30 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:12:30 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:12:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:12:30 WORKER: start processing job (4, 0, 18)
23:12:30 WORKER: args: ()
23:12:30 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.09452634828898622, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.011896556680106878, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 27, 'num_filters_3': 90, 'num_filters_4': 56, 'num_filters_5': 120}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:13:16 DISPATCHER: Starting worker discovery
23:13:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:13:16 DISPATCHER: Finished worker discovery
23:14:11 WORKER: done with job (4, 0, 18), trying to register it.
23:14:11 WORKER: registered result for job (4, 0, 18) with dispatcher
23:14:11 DISPATCHER: job (4, 0, 18) finished
23:14:11 DISPATCHER: register_result: lock acquired
23:14:11 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:14:11 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.09452634828898622, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.011896556680106878, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 27, 'num_filters_3': 90, 'num_filters_4': 56, 'num_filters_5': 120}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.09452634828898622, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.011896556680106878, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 27, 'num_filters_3': 90, 'num_filters_4': 56, 'num_filters_5': 120}"}}
exception: None

23:14:11 job_callback for (4, 0, 18) started
23:14:11 job_callback for (4, 0, 18) got condition
23:14:11 DISPATCHER: Trying to submit another job.
23:14:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:14:11 done building a new model for budget 44.444444 based on 17/39 split
Best loss for this budget:-0.499656





23:14:11 HBMASTER: Trying to run another job!
23:14:11 job_callback for (4, 0, 18) finished
23:14:11 start sampling a new configuration.
23:14:11 done sampling a new configuration.
23:14:11 HBMASTER: schedule new run for iteration 4
23:14:11 HBMASTER: trying submitting job (4, 0, 19) to dispatcher
23:14:11 HBMASTER: submitting job (4, 0, 19) to dispatcher
23:14:11 DISPATCHER: trying to submit job (4, 0, 19)
23:14:11 DISPATCHER: trying to notify the job_runner thread.
23:14:11 HBMASTER: job (4, 0, 19) submitted to dispatcher
23:14:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:14:11 DISPATCHER: Trying to submit another job.
23:14:11 DISPATCHER: starting job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:14:11 DISPATCHER: job (4, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:14:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:14:11 WORKER: start processing job (4, 0, 19)
23:14:11 WORKER: args: ()
23:14:11 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.010555168814250004, 'num_filters_1': 35, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.012354595834232941, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 125, 'num_filters_3': 119, 'num_filters_4': 47}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:14:16 DISPATCHER: Starting worker discovery
23:14:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:14:16 DISPATCHER: Finished worker discovery
23:15:16 DISPATCHER: Starting worker discovery
23:15:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:15:16 DISPATCHER: Finished worker discovery
23:15:52 WORKER: done with job (4, 0, 19), trying to register it.
23:15:52 WORKER: registered result for job (4, 0, 19) with dispatcher
23:15:52 DISPATCHER: job (4, 0, 19) finished
23:15:52 DISPATCHER: register_result: lock acquired
23:15:52 DISPATCHER: job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:15:52 job_id: (4, 0, 19)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.010555168814250004, 'num_filters_1': 35, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.012354595834232941, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 125, 'num_filters_3': 119, 'num_filters_4': 47}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.48888197441613634, 'info': {'music_genre': 0.48888197441613634, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.010555168814250004, 'num_filters_1': 35, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.012354595834232941, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 125, 'num_filters_3': 119, 'num_filters_4': 47}"}}
exception: None

23:15:52 job_callback for (4, 0, 19) started
23:15:52 DISPATCHER: Trying to submit another job.
23:15:52 job_callback for (4, 0, 19) got condition
23:15:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:15:52 done building a new model for budget 44.444444 based on 17/39 split
Best loss for this budget:-0.499656





23:15:52 HBMASTER: Trying to run another job!
23:15:52 job_callback for (4, 0, 19) finished
23:15:52 start sampling a new configuration.
23:15:52 best_vector: [0, 0, 0.24613233715269567, 0.6192372886309485, 0.8683727504520388, 1, 0.2984195214494433, 0.04272961824664823, 1, 1, 1, 0, 0.09730520246990981, 0.6957439512069973, 0.9250246393699357, 0.5012830881756324], 2.210508920311289e-28, 4.5238451236793824e-05, -6.410317187539545e-07
23:15:52 done sampling a new configuration.
23:15:52 HBMASTER: schedule new run for iteration 4
23:15:52 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
23:15:52 HBMASTER: submitting job (4, 0, 20) to dispatcher
23:15:52 DISPATCHER: trying to submit job (4, 0, 20)
23:15:52 DISPATCHER: trying to notify the job_runner thread.
23:15:52 HBMASTER: job (4, 0, 20) submitted to dispatcher
23:15:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:15:52 DISPATCHER: Trying to submit another job.
23:15:52 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:15:52 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:15:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:15:52 WORKER: start processing job (4, 0, 20)
23:15:52 WORKER: args: ()
23:15:52 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.003106452192393904, 'num_filters_1': 57, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.011365603862445712, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 19, 'num_filters_3': 68, 'num_filters_4': 110, 'num_filters_5': 45}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:16:16 DISPATCHER: Starting worker discovery
23:16:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:16:16 DISPATCHER: Finished worker discovery
23:17:16 DISPATCHER: Starting worker discovery
23:17:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:17:16 DISPATCHER: Finished worker discovery
23:17:33 WORKER: done with job (4, 0, 20), trying to register it.
23:17:33 WORKER: registered result for job (4, 0, 20) with dispatcher
23:17:33 DISPATCHER: job (4, 0, 20) finished
23:17:33 DISPATCHER: register_result: lock acquired
23:17:33 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:17:33 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.003106452192393904, 'num_filters_1': 57, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.011365603862445712, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 19, 'num_filters_3': 68, 'num_filters_4': 110, 'num_filters_5': 45}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.46822935034178753, 'info': {'music_genre': 0.46822935034178753, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.003106452192393904, 'num_filters_1': 57, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.011365603862445712, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 19, 'num_filters_3': 68, 'num_filters_4': 110, 'num_filters_5': 45}"}}
exception: None

23:17:33 job_callback for (4, 0, 20) started
23:17:33 DISPATCHER: Trying to submit another job.
23:17:33 job_callback for (4, 0, 20) got condition
23:17:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:17:33 done building a new model for budget 44.444444 based on 17/40 split
Best loss for this budget:-0.499656





23:17:33 HBMASTER: Trying to run another job!
23:17:33 job_callback for (4, 0, 20) finished
23:17:33 start sampling a new configuration.
23:17:33 best_vector: [0, 1, 0.5393560134966116, 0.30543305991136327, 0.8086345459032692, 1, 0.25288715076309154, 0.3967939972296954, 0, 2, 2, 0, 0.43593327323898046, 0.6961996371696416, 0.782801726633961, 0.0503204026201501], 0.00016323325005131813, 0.00010146300091433056, 1.656213539920604e-08
23:17:33 done sampling a new configuration.
23:17:33 HBMASTER: schedule new run for iteration 4
23:17:33 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
23:17:33 HBMASTER: submitting job (4, 0, 21) to dispatcher
23:17:33 DISPATCHER: trying to submit job (4, 0, 21)
23:17:33 DISPATCHER: trying to notify the job_runner thread.
23:17:33 HBMASTER: job (4, 0, 21) submitted to dispatcher
23:17:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:17:33 DISPATCHER: Trying to submit another job.
23:17:33 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:17:33 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:17:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:17:33 WORKER: start processing job (4, 0, 21)
23:17:33 WORKER: args: ()
23:17:33 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.01198704199968095, 'num_filters_1': 30, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.03282773300045919, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 39, 'num_filters_3': 68, 'num_filters_4': 81, 'num_filters_5': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:18:16 DISPATCHER: Starting worker discovery
23:18:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:18:16 DISPATCHER: Finished worker discovery
23:19:14 WORKER: done with job (4, 0, 21), trying to register it.
23:19:14 WORKER: registered result for job (4, 0, 21) with dispatcher
23:19:14 DISPATCHER: job (4, 0, 21) finished
23:19:14 DISPATCHER: register_result: lock acquired
23:19:14 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:19:14 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.01198704199968095, 'num_filters_1': 30, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.03282773300045919, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 39, 'num_filters_3': 68, 'num_filters_4': 81, 'num_filters_5': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.29123697269813137, 'info': {'music_genre': 0.29123697269813137, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.01198704199968095, 'num_filters_1': 30, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.03282773300045919, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 39, 'num_filters_3': 68, 'num_filters_4': 81, 'num_filters_5': 17}"}}
exception: None

23:19:14 job_callback for (4, 0, 21) started
23:19:14 job_callback for (4, 0, 21) got condition
23:19:14 DISPATCHER: Trying to submit another job.
23:19:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:19:14 done building a new model for budget 44.444444 based on 17/41 split
Best loss for this budget:-0.499656





23:19:14 HBMASTER: Trying to run another job!
23:19:14 job_callback for (4, 0, 21) finished
23:19:14 start sampling a new configuration.
23:19:14 done sampling a new configuration.
23:19:14 HBMASTER: schedule new run for iteration 4
23:19:14 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
23:19:14 HBMASTER: submitting job (4, 0, 22) to dispatcher
23:19:14 DISPATCHER: trying to submit job (4, 0, 22)
23:19:14 DISPATCHER: trying to notify the job_runner thread.
23:19:14 HBMASTER: job (4, 0, 22) submitted to dispatcher
23:19:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:19:14 DISPATCHER: Trying to submit another job.
23:19:14 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:19:14 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:19:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:19:14 WORKER: start processing job (4, 0, 22)
23:19:14 WORKER: args: ()
23:19:14 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0012750457481152748, 'num_filters_1': 68, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.06644397135636479, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 107, 'num_filters_3': 115}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:19:16 DISPATCHER: Starting worker discovery
23:19:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:19:16 DISPATCHER: Finished worker discovery
23:20:16 DISPATCHER: Starting worker discovery
23:20:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:20:16 DISPATCHER: Finished worker discovery
23:20:55 WORKER: done with job (4, 0, 22), trying to register it.
23:20:55 WORKER: registered result for job (4, 0, 22) with dispatcher
23:20:55 DISPATCHER: job (4, 0, 22) finished
23:20:55 DISPATCHER: register_result: lock acquired
23:20:55 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:20:55 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0012750457481152748, 'num_filters_1': 68, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.06644397135636479, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 107, 'num_filters_3': 115}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.11882397955411127, 'info': {'music_genre': 0.11882397955411127, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0012750457481152748, 'num_filters_1': 68, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.06644397135636479, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 107, 'num_filters_3': 115}"}}
exception: None

23:20:55 job_callback for (4, 0, 22) started
23:20:55 job_callback for (4, 0, 22) got condition
23:20:55 DISPATCHER: Trying to submit another job.
23:20:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:20:55 done building a new model for budget 44.444444 based on 17/42 split
Best loss for this budget:-0.499656





23:20:55 HBMASTER: Trying to run another job!
23:20:55 job_callback for (4, 0, 22) finished
23:20:55 start sampling a new configuration.
23:20:55 done sampling a new configuration.
23:20:55 HBMASTER: schedule new run for iteration 4
23:20:55 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
23:20:55 HBMASTER: submitting job (4, 0, 23) to dispatcher
23:20:55 DISPATCHER: trying to submit job (4, 0, 23)
23:20:55 DISPATCHER: trying to notify the job_runner thread.
23:20:55 HBMASTER: job (4, 0, 23) submitted to dispatcher
23:20:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:20:55 DISPATCHER: Trying to submit another job.
23:20:55 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:20:55 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:20:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:20:55 WORKER: start processing job (4, 0, 23)
23:20:55 WORKER: args: ()
23:20:55 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.019564180522536626, 'num_filters_1': 83, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.07302937381399932, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 126, 'num_filters_3': 20, 'num_filters_4': 43, 'num_filters_5': 42}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:21:16 DISPATCHER: Starting worker discovery
23:21:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:21:16 DISPATCHER: Finished worker discovery
23:22:16 DISPATCHER: Starting worker discovery
23:22:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:22:16 DISPATCHER: Finished worker discovery
23:22:34 WORKER: done with job (4, 0, 23), trying to register it.
23:22:34 WORKER: registered result for job (4, 0, 23) with dispatcher
23:22:34 DISPATCHER: job (4, 0, 23) finished
23:22:34 DISPATCHER: register_result: lock acquired
23:22:34 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:22:34 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.019564180522536626, 'num_filters_1': 83, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.07302937381399932, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 126, 'num_filters_3': 20, 'num_filters_4': 43, 'num_filters_5': 42}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.19668582469034263, 'info': {'music_genre': 0.19668582469034263, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.019564180522536626, 'num_filters_1': 83, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.07302937381399932, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 126, 'num_filters_3': 20, 'num_filters_4': 43, 'num_filters_5': 42}"}}
exception: None

23:22:34 job_callback for (4, 0, 23) started
23:22:34 job_callback for (4, 0, 23) got condition
23:22:34 DISPATCHER: Trying to submit another job.
23:22:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:22:34 done building a new model for budget 44.444444 based on 17/43 split
Best loss for this budget:-0.499656





23:22:34 HBMASTER: Trying to run another job!
23:22:34 job_callback for (4, 0, 23) finished
23:22:34 start sampling a new configuration.
23:22:34 done sampling a new configuration.
23:22:34 HBMASTER: schedule new run for iteration 4
23:22:34 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
23:22:34 HBMASTER: submitting job (4, 0, 24) to dispatcher
23:22:34 DISPATCHER: trying to submit job (4, 0, 24)
23:22:34 DISPATCHER: trying to notify the job_runner thread.
23:22:34 HBMASTER: job (4, 0, 24) submitted to dispatcher
23:22:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:22:34 DISPATCHER: Trying to submit another job.
23:22:34 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:22:34 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:22:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:22:34 WORKER: start processing job (4, 0, 24)
23:22:34 WORKER: args: ()
23:22:34 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.010908005641836707, 'num_filters_1': 29, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.030487964951858477, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 23, 'num_filters_3': 81, 'num_filters_4': 87}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:23:16 DISPATCHER: Starting worker discovery
23:23:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:23:16 DISPATCHER: Finished worker discovery
23:24:15 WORKER: done with job (4, 0, 24), trying to register it.
23:24:15 WORKER: registered result for job (4, 0, 24) with dispatcher
23:24:15 DISPATCHER: job (4, 0, 24) finished
23:24:15 DISPATCHER: register_result: lock acquired
23:24:15 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:24:15 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.010908005641836707, 'num_filters_1': 29, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.030487964951858477, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 23, 'num_filters_3': 81, 'num_filters_4': 87}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.00015948777950304549, 'info': {'music_genre': 0.00015948777950304549, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.010908005641836707, 'num_filters_1': 29, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.030487964951858477, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 23, 'num_filters_3': 81, 'num_filters_4': 87}"}}
exception: None

23:24:15 job_callback for (4, 0, 24) started
23:24:15 job_callback for (4, 0, 24) got condition
23:24:15 DISPATCHER: Trying to submit another job.
23:24:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:24:15 done building a new model for budget 44.444444 based on 17/44 split
Best loss for this budget:-0.499656





23:24:15 HBMASTER: Trying to run another job!
23:24:15 job_callback for (4, 0, 24) finished
23:24:15 start sampling a new configuration.
23:24:15 best_vector: [3, 0, 0.0974485708220886, 0.890670708560059, 0.18386159680110828, 1, 0.10389232076060989, 0.40793721886254025, 1, 2, 2, 1, 0.4496816254647918, 0.7407799546192565, 0.1478792853537533, 0.49258958916023654], 0.00396520152807393, 0.0031038249729075556, 1.2307291525447064e-05
23:24:15 done sampling a new configuration.
23:24:15 HBMASTER: schedule new run for iteration 4
23:24:15 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
23:24:15 HBMASTER: submitting job (4, 0, 25) to dispatcher
23:24:15 DISPATCHER: trying to submit job (4, 0, 25)
23:24:15 DISPATCHER: trying to notify the job_runner thread.
23:24:15 HBMASTER: job (4, 0, 25) submitted to dispatcher
23:24:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:24:15 DISPATCHER: Trying to submit another job.
23:24:15 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:24:15 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:24:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:24:15 WORKER: start processing job (4, 0, 25)
23:24:15 WORKER: args: ()
23:24:15 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0015663800445403007, 'num_filters_1': 102, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.033942088233543256}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:24:16 DISPATCHER: Starting worker discovery
23:24:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:24:16 DISPATCHER: Finished worker discovery
23:25:16 DISPATCHER: Starting worker discovery
23:25:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:25:16 DISPATCHER: Finished worker discovery
23:25:56 WORKER: done with job (4, 0, 25), trying to register it.
23:25:56 WORKER: registered result for job (4, 0, 25) with dispatcher
23:25:56 DISPATCHER: job (4, 0, 25) finished
23:25:56 DISPATCHER: register_result: lock acquired
23:25:56 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:25:56 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0015663800445403007, 'num_filters_1': 102, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.033942088233543256}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.44960440991927625, 'info': {'music_genre': 0.44960440991927625, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0015663800445403007, 'num_filters_1': 102, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.033942088233543256}"}}
exception: None

23:25:56 job_callback for (4, 0, 25) started
23:25:56 DISPATCHER: Trying to submit another job.
23:25:56 job_callback for (4, 0, 25) got condition
23:25:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:25:56 done building a new model for budget 44.444444 based on 17/45 split
Best loss for this budget:-0.499656





23:25:56 HBMASTER: Trying to run another job!
23:25:56 job_callback for (4, 0, 25) finished
23:25:56 start sampling a new configuration.
23:25:56 best_vector: [0, 1, 0.005729916229637144, 0.9775781019243923, 0.4546039706830585, 1, 0.6112631140649782, 0.18749438270857877, 0, 2, 1, 1, 0.989657337194473, 0.7289248745862026, 0.9332277227218507, 0.5058992568340315], 0.0009283969917455054, 0.0010178387810846324, 9.449584624408847e-07
23:25:56 done sampling a new configuration.
23:25:56 HBMASTER: schedule new run for iteration 4
23:25:56 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
23:25:56 HBMASTER: submitting job (4, 0, 26) to dispatcher
23:25:56 DISPATCHER: trying to submit job (4, 0, 26)
23:25:56 DISPATCHER: trying to notify the job_runner thread.
23:25:56 HBMASTER: job (4, 0, 26) submitted to dispatcher
23:25:56 DISPATCHER: Trying to submit another job.
23:25:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:25:56 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:25:56 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:25:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:25:56 WORKER: start processing job (4, 0, 26)
23:25:56 WORKER: args: ()
23:25:56 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0010267384650772433, 'num_filters_1': 123, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.01753621316222356, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 126, 'num_filters_3': 72}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:26:16 DISPATCHER: Starting worker discovery
23:26:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:26:16 DISPATCHER: Finished worker discovery
23:27:16 DISPATCHER: Starting worker discovery
23:27:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:27:16 DISPATCHER: Finished worker discovery
23:27:38 WORKER: done with job (4, 0, 26), trying to register it.
23:27:38 WORKER: registered result for job (4, 0, 26) with dispatcher
23:27:38 DISPATCHER: job (4, 0, 26) finished
23:27:38 DISPATCHER: register_result: lock acquired
23:27:38 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:27:38 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0010267384650772433, 'num_filters_1': 123, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.01753621316222356, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 126, 'num_filters_3': 72}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.48360527642274853, 'info': {'music_genre': 0.48360527642274853, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0010267384650772433, 'num_filters_1': 123, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.01753621316222356, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 126, 'num_filters_3': 72}"}}
exception: None

23:27:38 job_callback for (4, 0, 26) started
23:27:38 DISPATCHER: Trying to submit another job.
23:27:38 job_callback for (4, 0, 26) got condition
23:27:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:27:38 done building a new model for budget 44.444444 based on 17/45 split
Best loss for this budget:-0.499656





23:27:38 HBMASTER: Trying to run another job!
23:27:38 job_callback for (4, 0, 26) finished
23:27:38 ITERATION: Advancing config (4, 0, 0) to next budget 133.333333
23:27:38 ITERATION: Advancing config (4, 0, 4) to next budget 133.333333
23:27:38 ITERATION: Advancing config (4, 0, 10) to next budget 133.333333
23:27:38 ITERATION: Advancing config (4, 0, 13) to next budget 133.333333
23:27:38 ITERATION: Advancing config (4, 0, 14) to next budget 133.333333
23:27:38 ITERATION: Advancing config (4, 0, 19) to next budget 133.333333
23:27:38 ITERATION: Advancing config (4, 0, 20) to next budget 133.333333
23:27:38 ITERATION: Advancing config (4, 0, 25) to next budget 133.333333
23:27:38 ITERATION: Advancing config (4, 0, 26) to next budget 133.333333
23:27:38 HBMASTER: schedule new run for iteration 4
23:27:38 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
23:27:38 HBMASTER: submitting job (4, 0, 0) to dispatcher
23:27:38 DISPATCHER: trying to submit job (4, 0, 0)
23:27:38 DISPATCHER: trying to notify the job_runner thread.
23:27:38 HBMASTER: job (4, 0, 0) submitted to dispatcher
23:27:38 DISPATCHER: Trying to submit another job.
23:27:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:27:38 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:27:38 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:27:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:27:38 WORKER: start processing job (4, 0, 0)
23:27:38 WORKER: args: ()
23:27:38 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0038631211964140263, 'num_filters_1': 17, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.018207570189185833, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 77, 'num_filters_3': 40, 'num_filters_4': 126}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:28:16 DISPATCHER: Starting worker discovery
23:28:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:28:16 DISPATCHER: Finished worker discovery
23:29:16 DISPATCHER: Starting worker discovery
23:29:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:29:16 DISPATCHER: Finished worker discovery
23:30:16 DISPATCHER: Starting worker discovery
23:30:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:30:16 DISPATCHER: Finished worker discovery
23:30:47 WORKER: done with job (4, 0, 0), trying to register it.
23:30:47 WORKER: registered result for job (4, 0, 0) with dispatcher
23:30:47 DISPATCHER: job (4, 0, 0) finished
23:30:47 DISPATCHER: register_result: lock acquired
23:30:47 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:30:47 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0038631211964140263, 'num_filters_1': 17, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.018207570189185833, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 77, 'num_filters_3': 40, 'num_filters_4': 126}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.269766658935354, 'info': {'music_genre': 0.269766658935354, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0038631211964140263, 'num_filters_1': 17, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.018207570189185833, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 77, 'num_filters_3': 40, 'num_filters_4': 126}"}}
exception: None

23:30:47 job_callback for (4, 0, 0) started
23:30:47 DISPATCHER: Trying to submit another job.
23:30:47 job_callback for (4, 0, 0) got condition
23:30:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:30:47 HBMASTER: Trying to run another job!
23:30:47 job_callback for (4, 0, 0) finished
23:30:47 HBMASTER: schedule new run for iteration 4
23:30:47 HBMASTER: trying submitting job (4, 0, 4) to dispatcher
23:30:47 HBMASTER: submitting job (4, 0, 4) to dispatcher
23:30:47 DISPATCHER: trying to submit job (4, 0, 4)
23:30:47 DISPATCHER: trying to notify the job_runner thread.
23:30:47 HBMASTER: job (4, 0, 4) submitted to dispatcher
23:30:47 DISPATCHER: Trying to submit another job.
23:30:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:30:47 DISPATCHER: starting job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:30:47 DISPATCHER: job (4, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:30:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:30:47 WORKER: start processing job (4, 0, 4)
23:30:47 WORKER: args: ()
23:30:47 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0018822824147314808, 'num_filters_1': 127, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.10723792543746426}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:31:16 DISPATCHER: Starting worker discovery
23:31:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:31:16 DISPATCHER: Finished worker discovery
23:32:16 DISPATCHER: Starting worker discovery
23:32:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:32:16 DISPATCHER: Finished worker discovery
23:33:16 DISPATCHER: Starting worker discovery
23:33:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:33:16 DISPATCHER: Finished worker discovery
23:33:58 WORKER: done with job (4, 0, 4), trying to register it.
23:33:58 WORKER: registered result for job (4, 0, 4) with dispatcher
23:33:58 DISPATCHER: job (4, 0, 4) finished
23:33:58 DISPATCHER: register_result: lock acquired
23:33:58 DISPATCHER: job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:33:58 job_id: (4, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0018822824147314808, 'num_filters_1': 127, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.10723792543746426}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.35316093393192605, 'info': {'music_genre': 0.35316093393192605, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0018822824147314808, 'num_filters_1': 127, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.10723792543746426}"}}
exception: None

23:33:58 job_callback for (4, 0, 4) started
23:33:58 job_callback for (4, 0, 4) got condition
23:33:58 DISPATCHER: Trying to submit another job.
23:33:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:33:59 HBMASTER: Trying to run another job!
23:33:59 job_callback for (4, 0, 4) finished
23:33:59 HBMASTER: schedule new run for iteration 4
23:33:59 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
23:33:59 HBMASTER: submitting job (4, 0, 10) to dispatcher
23:33:59 DISPATCHER: trying to submit job (4, 0, 10)
23:33:59 DISPATCHER: trying to notify the job_runner thread.
23:33:59 HBMASTER: job (4, 0, 10) submitted to dispatcher
23:33:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:33:59 DISPATCHER: Trying to submit another job.
23:33:59 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:33:59 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:33:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:33:59 WORKER: start processing job (4, 0, 10)
23:33:59 WORKER: args: ()
23:33:59 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0019511104491960318, 'num_filters_1': 79, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.02525272195529587}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:34:16 DISPATCHER: Starting worker discovery
23:34:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:34:16 DISPATCHER: Finished worker discovery
23:35:16 DISPATCHER: Starting worker discovery
23:35:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:35:16 DISPATCHER: Finished worker discovery
23:36:16 DISPATCHER: Starting worker discovery
23:36:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:36:16 DISPATCHER: Finished worker discovery
23:37:11 WORKER: done with job (4, 0, 10), trying to register it.
23:37:11 WORKER: registered result for job (4, 0, 10) with dispatcher
23:37:11 DISPATCHER: job (4, 0, 10) finished
23:37:11 DISPATCHER: register_result: lock acquired
23:37:11 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:37:11 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0019511104491960318, 'num_filters_1': 79, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.02525272195529587}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.45500562314483717, 'info': {'music_genre': 0.45500562314483717, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0019511104491960318, 'num_filters_1': 79, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.02525272195529587}"}}
exception: None

23:37:11 job_callback for (4, 0, 10) started
23:37:11 DISPATCHER: Trying to submit another job.
23:37:11 job_callback for (4, 0, 10) got condition
23:37:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:37:11 HBMASTER: Trying to run another job!
23:37:11 job_callback for (4, 0, 10) finished
23:37:11 HBMASTER: schedule new run for iteration 4
23:37:11 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
23:37:11 HBMASTER: submitting job (4, 0, 13) to dispatcher
23:37:11 DISPATCHER: trying to submit job (4, 0, 13)
23:37:11 DISPATCHER: trying to notify the job_runner thread.
23:37:11 HBMASTER: job (4, 0, 13) submitted to dispatcher
23:37:11 DISPATCHER: Trying to submit another job.
23:37:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:37:11 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:37:11 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:37:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:37:11 WORKER: start processing job (4, 0, 13)
23:37:11 WORKER: args: ()
23:37:11 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.004529499004917843, 'num_filters_1': 49, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.05674767033881716, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 45, 'num_filters_3': 82, 'num_filters_4': 90, 'num_filters_5': 61}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:37:16 DISPATCHER: Starting worker discovery
23:37:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:37:16 DISPATCHER: Finished worker discovery
23:38:16 DISPATCHER: Starting worker discovery
23:38:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:38:17 DISPATCHER: Finished worker discovery
23:39:17 DISPATCHER: Starting worker discovery
23:39:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:39:17 DISPATCHER: Finished worker discovery
23:40:17 DISPATCHER: Starting worker discovery
23:40:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:40:17 DISPATCHER: Finished worker discovery
23:40:23 WORKER: done with job (4, 0, 13), trying to register it.
23:40:23 WORKER: registered result for job (4, 0, 13) with dispatcher
23:40:23 DISPATCHER: job (4, 0, 13) finished
23:40:23 DISPATCHER: register_result: lock acquired
23:40:23 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:40:23 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.004529499004917843, 'num_filters_1': 49, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.05674767033881716, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 45, 'num_filters_3': 82, 'num_filters_4': 90, 'num_filters_5': 61}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3614723289325514, 'info': {'music_genre': 0.3614723289325514, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.004529499004917843, 'num_filters_1': 49, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.05674767033881716, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 45, 'num_filters_3': 82, 'num_filters_4': 90, 'num_filters_5': 61}"}}
exception: None

23:40:23 job_callback for (4, 0, 13) started
23:40:23 DISPATCHER: Trying to submit another job.
23:40:23 job_callback for (4, 0, 13) got condition
23:40:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:40:23 HBMASTER: Trying to run another job!
23:40:23 job_callback for (4, 0, 13) finished
23:40:23 HBMASTER: schedule new run for iteration 4
23:40:23 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
23:40:23 HBMASTER: submitting job (4, 0, 14) to dispatcher
23:40:23 DISPATCHER: trying to submit job (4, 0, 14)
23:40:23 DISPATCHER: trying to notify the job_runner thread.
23:40:23 HBMASTER: job (4, 0, 14) submitted to dispatcher
23:40:23 DISPATCHER: Trying to submit another job.
23:40:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:40:23 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:40:23 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:40:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:40:23 WORKER: start processing job (4, 0, 14)
23:40:23 WORKER: args: ()
23:40:23 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0018959391412729037, 'num_filters_1': 27, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.11276572732739437, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 112, 'num_filters_3': 65}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:41:17 DISPATCHER: Starting worker discovery
23:41:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:41:17 DISPATCHER: Finished worker discovery
23:42:17 DISPATCHER: Starting worker discovery
23:42:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:42:17 DISPATCHER: Finished worker discovery
23:43:17 DISPATCHER: Starting worker discovery
23:43:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:43:17 DISPATCHER: Finished worker discovery
23:43:34 WORKER: done with job (4, 0, 14), trying to register it.
23:43:34 WORKER: registered result for job (4, 0, 14) with dispatcher
23:43:34 DISPATCHER: job (4, 0, 14) finished
23:43:34 DISPATCHER: register_result: lock acquired
23:43:34 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:43:34 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0018959391412729037, 'num_filters_1': 27, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.11276572732739437, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 112, 'num_filters_3': 65}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.39979692980306814, 'info': {'music_genre': 0.39979692980306814, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0018959391412729037, 'num_filters_1': 27, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.11276572732739437, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 112, 'num_filters_3': 65}"}}
exception: None

23:43:34 job_callback for (4, 0, 14) started
23:43:34 DISPATCHER: Trying to submit another job.
23:43:34 job_callback for (4, 0, 14) got condition
23:43:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:43:34 HBMASTER: Trying to run another job!
23:43:34 job_callback for (4, 0, 14) finished
23:43:34 HBMASTER: schedule new run for iteration 4
23:43:34 HBMASTER: trying submitting job (4, 0, 19) to dispatcher
23:43:34 HBMASTER: submitting job (4, 0, 19) to dispatcher
23:43:34 DISPATCHER: trying to submit job (4, 0, 19)
23:43:34 DISPATCHER: trying to notify the job_runner thread.
23:43:34 HBMASTER: job (4, 0, 19) submitted to dispatcher
23:43:34 DISPATCHER: Trying to submit another job.
23:43:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:43:34 DISPATCHER: starting job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:43:34 DISPATCHER: job (4, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:43:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:43:34 WORKER: start processing job (4, 0, 19)
23:43:34 WORKER: args: ()
23:43:34 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.010555168814250004, 'num_filters_1': 35, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.012354595834232941, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 125, 'num_filters_3': 119, 'num_filters_4': 47}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:44:17 DISPATCHER: Starting worker discovery
23:44:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:44:17 DISPATCHER: Finished worker discovery
23:45:17 DISPATCHER: Starting worker discovery
23:45:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:45:17 DISPATCHER: Finished worker discovery
23:46:17 DISPATCHER: Starting worker discovery
23:46:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:46:17 DISPATCHER: Finished worker discovery
23:46:44 WORKER: done with job (4, 0, 19), trying to register it.
23:46:44 WORKER: registered result for job (4, 0, 19) with dispatcher
23:46:44 DISPATCHER: job (4, 0, 19) finished
23:46:44 DISPATCHER: register_result: lock acquired
23:46:44 DISPATCHER: job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:46:44 job_id: (4, 0, 19)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.010555168814250004, 'num_filters_1': 35, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.012354595834232941, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 125, 'num_filters_3': 119, 'num_filters_4': 47}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.29602716062440865, 'info': {'music_genre': 0.29602716062440865, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.010555168814250004, 'num_filters_1': 35, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.012354595834232941, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 125, 'num_filters_3': 119, 'num_filters_4': 47}"}}
exception: None

23:46:44 job_callback for (4, 0, 19) started
23:46:44 DISPATCHER: Trying to submit another job.
23:46:44 job_callback for (4, 0, 19) got condition
23:46:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:46:44 HBMASTER: Trying to run another job!
23:46:44 job_callback for (4, 0, 19) finished
23:46:44 HBMASTER: schedule new run for iteration 4
23:46:44 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
23:46:44 HBMASTER: submitting job (4, 0, 20) to dispatcher
23:46:44 DISPATCHER: trying to submit job (4, 0, 20)
23:46:44 DISPATCHER: trying to notify the job_runner thread.
23:46:44 HBMASTER: job (4, 0, 20) submitted to dispatcher
23:46:44 DISPATCHER: Trying to submit another job.
23:46:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:46:44 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:46:44 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:46:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:46:44 WORKER: start processing job (4, 0, 20)
23:46:44 WORKER: args: ()
23:46:44 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.003106452192393904, 'num_filters_1': 57, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.011365603862445712, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 19, 'num_filters_3': 68, 'num_filters_4': 110, 'num_filters_5': 45}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:47:17 DISPATCHER: Starting worker discovery
23:47:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:47:17 DISPATCHER: Finished worker discovery
23:48:17 DISPATCHER: Starting worker discovery
23:48:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:48:17 DISPATCHER: Finished worker discovery
23:49:17 DISPATCHER: Starting worker discovery
23:49:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:49:17 DISPATCHER: Finished worker discovery
23:49:54 WORKER: done with job (4, 0, 20), trying to register it.
23:49:54 WORKER: registered result for job (4, 0, 20) with dispatcher
23:49:54 DISPATCHER: job (4, 0, 20) finished
23:49:54 DISPATCHER: register_result: lock acquired
23:49:54 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:49:54 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.003106452192393904, 'num_filters_1': 57, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.011365603862445712, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 19, 'num_filters_3': 68, 'num_filters_4': 110, 'num_filters_5': 45}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.45409763070951, 'info': {'music_genre': 0.45409763070951, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.003106452192393904, 'num_filters_1': 57, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.011365603862445712, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 19, 'num_filters_3': 68, 'num_filters_4': 110, 'num_filters_5': 45}"}}
exception: None

23:49:54 job_callback for (4, 0, 20) started
23:49:54 DISPATCHER: Trying to submit another job.
23:49:54 job_callback for (4, 0, 20) got condition
23:49:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:49:55 HBMASTER: Trying to run another job!
23:49:55 job_callback for (4, 0, 20) finished
23:49:55 HBMASTER: schedule new run for iteration 4
23:49:55 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
23:49:55 HBMASTER: submitting job (4, 0, 25) to dispatcher
23:49:55 DISPATCHER: trying to submit job (4, 0, 25)
23:49:55 DISPATCHER: trying to notify the job_runner thread.
23:49:55 HBMASTER: job (4, 0, 25) submitted to dispatcher
23:49:55 DISPATCHER: Trying to submit another job.
23:49:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:49:55 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:49:55 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:49:55 WORKER: start processing job (4, 0, 25)
23:49:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:49:55 WORKER: args: ()
23:49:55 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0015663800445403007, 'num_filters_1': 102, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.033942088233543256}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:50:17 DISPATCHER: Starting worker discovery
23:50:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:50:17 DISPATCHER: Finished worker discovery
23:51:17 DISPATCHER: Starting worker discovery
23:51:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:51:17 DISPATCHER: Finished worker discovery
23:52:17 DISPATCHER: Starting worker discovery
23:52:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:52:17 DISPATCHER: Finished worker discovery
23:53:08 WORKER: done with job (4, 0, 25), trying to register it.
23:53:08 WORKER: registered result for job (4, 0, 25) with dispatcher
23:53:08 DISPATCHER: job (4, 0, 25) finished
23:53:08 DISPATCHER: register_result: lock acquired
23:53:08 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:53:08 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0015663800445403007, 'num_filters_1': 102, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.033942088233543256}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4394145390364553, 'info': {'music_genre': 0.4394145390364553, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0015663800445403007, 'num_filters_1': 102, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.033942088233543256}"}}
exception: None

23:53:08 job_callback for (4, 0, 25) started
23:53:08 job_callback for (4, 0, 25) got condition
23:53:08 DISPATCHER: Trying to submit another job.
23:53:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:53:08 HBMASTER: Trying to run another job!
23:53:08 job_callback for (4, 0, 25) finished
23:53:08 HBMASTER: schedule new run for iteration 4
23:53:08 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
23:53:08 HBMASTER: submitting job (4, 0, 26) to dispatcher
23:53:08 DISPATCHER: trying to submit job (4, 0, 26)
23:53:08 DISPATCHER: trying to notify the job_runner thread.
23:53:08 HBMASTER: job (4, 0, 26) submitted to dispatcher
23:53:08 DISPATCHER: Trying to submit another job.
23:53:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:53:08 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:53:08 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:53:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:53:08 WORKER: start processing job (4, 0, 26)
23:53:08 WORKER: args: ()
23:53:08 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0010267384650772433, 'num_filters_1': 123, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.01753621316222356, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 126, 'num_filters_3': 72}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:53:17 DISPATCHER: Starting worker discovery
23:53:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:53:17 DISPATCHER: Finished worker discovery
23:54:17 DISPATCHER: Starting worker discovery
23:54:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:54:17 DISPATCHER: Finished worker discovery
23:55:17 DISPATCHER: Starting worker discovery
23:55:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:55:17 DISPATCHER: Finished worker discovery
23:56:17 DISPATCHER: Starting worker discovery
23:56:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:56:17 DISPATCHER: Finished worker discovery
23:56:18 WORKER: done with job (4, 0, 26), trying to register it.
23:56:18 WORKER: registered result for job (4, 0, 26) with dispatcher
23:56:18 DISPATCHER: job (4, 0, 26) finished
23:56:18 DISPATCHER: register_result: lock acquired
23:56:18 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
23:56:18 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0010267384650772433, 'num_filters_1': 123, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.01753621316222356, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 126, 'num_filters_3': 72}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4850322423193672, 'info': {'music_genre': 0.4850322423193672, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0010267384650772433, 'num_filters_1': 123, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.01753621316222356, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 126, 'num_filters_3': 72}"}}
exception: None

23:56:18 job_callback for (4, 0, 26) started
23:56:18 DISPATCHER: Trying to submit another job.
23:56:18 job_callback for (4, 0, 26) got condition
23:56:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:56:18 HBMASTER: Trying to run another job!
23:56:18 job_callback for (4, 0, 26) finished
23:56:18 ITERATION: Advancing config (4, 0, 10) to next budget 400.000000
23:56:18 ITERATION: Advancing config (4, 0, 20) to next budget 400.000000
23:56:18 ITERATION: Advancing config (4, 0, 26) to next budget 400.000000
23:56:18 HBMASTER: schedule new run for iteration 4
23:56:18 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
23:56:18 HBMASTER: submitting job (4, 0, 10) to dispatcher
23:56:18 DISPATCHER: trying to submit job (4, 0, 10)
23:56:18 DISPATCHER: trying to notify the job_runner thread.
23:56:18 HBMASTER: job (4, 0, 10) submitted to dispatcher
23:56:18 DISPATCHER: Trying to submit another job.
23:56:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:56:18 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:56:18 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
23:56:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:56:18 WORKER: start processing job (4, 0, 10)
23:56:18 WORKER: args: ()
23:56:18 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0019511104491960318, 'num_filters_1': 79, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.02525272195529587}, 'budget': 400.0, 'working_directory': '.'}
23:57:17 DISPATCHER: Starting worker discovery
23:57:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:57:17 DISPATCHER: Finished worker discovery
23:58:17 DISPATCHER: Starting worker discovery
23:58:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:58:17 DISPATCHER: Finished worker discovery
23:59:17 DISPATCHER: Starting worker discovery
23:59:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:59:17 DISPATCHER: Finished worker discovery
00:00:17 DISPATCHER: Starting worker discovery
00:00:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:00:17 DISPATCHER: Finished worker discovery
00:01:17 DISPATCHER: Starting worker discovery
00:01:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:01:17 DISPATCHER: Finished worker discovery
00:02:17 DISPATCHER: Starting worker discovery
00:02:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:02:17 DISPATCHER: Finished worker discovery
00:03:17 DISPATCHER: Starting worker discovery
00:03:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:03:17 DISPATCHER: Finished worker discovery
00:04:00 WORKER: done with job (4, 0, 10), trying to register it.
00:04:00 WORKER: registered result for job (4, 0, 10) with dispatcher
00:04:00 DISPATCHER: job (4, 0, 10) finished
00:04:00 DISPATCHER: register_result: lock acquired
00:04:00 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
00:04:00 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0019511104491960318, 'num_filters_1': 79, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.02525272195529587}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.4109434961407844, 'info': {'music_genre': 0.4109434961407844, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0019511104491960318, 'num_filters_1': 79, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.02525272195529587}"}}
exception: None

00:04:00 job_callback for (4, 0, 10) started
00:04:00 DISPATCHER: Trying to submit another job.
00:04:00 job_callback for (4, 0, 10) got condition
00:04:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:04:00 Only 13 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
00:04:00 HBMASTER: Trying to run another job!
00:04:00 job_callback for (4, 0, 10) finished
00:04:00 HBMASTER: schedule new run for iteration 4
00:04:00 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
00:04:00 HBMASTER: submitting job (4, 0, 20) to dispatcher
00:04:00 DISPATCHER: trying to submit job (4, 0, 20)
00:04:00 DISPATCHER: trying to notify the job_runner thread.
00:04:00 HBMASTER: job (4, 0, 20) submitted to dispatcher
00:04:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:04:00 DISPATCHER: Trying to submit another job.
00:04:00 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:04:00 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:04:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:04:00 WORKER: start processing job (4, 0, 20)
00:04:00 WORKER: args: ()
00:04:00 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.003106452192393904, 'num_filters_1': 57, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.011365603862445712, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 19, 'num_filters_3': 68, 'num_filters_4': 110, 'num_filters_5': 45}, 'budget': 400.0, 'working_directory': '.'}
00:04:17 DISPATCHER: Starting worker discovery
00:04:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:04:17 DISPATCHER: Finished worker discovery
00:05:17 DISPATCHER: Starting worker discovery
00:05:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:05:17 DISPATCHER: Finished worker discovery
00:06:17 DISPATCHER: Starting worker discovery
00:06:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:06:17 DISPATCHER: Finished worker discovery
00:07:17 DISPATCHER: Starting worker discovery
00:07:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:07:17 DISPATCHER: Finished worker discovery
00:08:17 DISPATCHER: Starting worker discovery
00:08:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:08:17 DISPATCHER: Finished worker discovery
00:09:17 DISPATCHER: Starting worker discovery
00:09:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:09:17 DISPATCHER: Finished worker discovery
00:10:17 DISPATCHER: Starting worker discovery
00:10:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:10:17 DISPATCHER: Finished worker discovery
00:11:17 DISPATCHER: Starting worker discovery
00:11:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:11:17 DISPATCHER: Finished worker discovery
00:11:41 WORKER: done with job (4, 0, 20), trying to register it.
00:11:41 WORKER: registered result for job (4, 0, 20) with dispatcher
00:11:41 DISPATCHER: job (4, 0, 20) finished
00:11:41 DISPATCHER: register_result: lock acquired
00:11:41 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
00:11:41 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.003106452192393904, 'num_filters_1': 57, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.011365603862445712, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 19, 'num_filters_3': 68, 'num_filters_4': 110, 'num_filters_5': 45}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3192369809009929, 'info': {'music_genre': 0.3192369809009929, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.003106452192393904, 'num_filters_1': 57, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.011365603862445712, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 19, 'num_filters_3': 68, 'num_filters_4': 110, 'num_filters_5': 45}"}}
exception: None

00:11:41 job_callback for (4, 0, 20) started
00:11:41 job_callback for (4, 0, 20) got condition
00:11:41 DISPATCHER: Trying to submit another job.
00:11:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:11:41 Only 14 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
00:11:41 HBMASTER: Trying to run another job!
00:11:41 job_callback for (4, 0, 20) finished
00:11:41 HBMASTER: schedule new run for iteration 4
00:11:41 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
00:11:41 HBMASTER: submitting job (4, 0, 26) to dispatcher
00:11:41 DISPATCHER: trying to submit job (4, 0, 26)
00:11:41 DISPATCHER: trying to notify the job_runner thread.
00:11:41 HBMASTER: job (4, 0, 26) submitted to dispatcher
00:11:41 DISPATCHER: Trying to submit another job.
00:11:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:11:41 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:11:41 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:11:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:11:41 WORKER: start processing job (4, 0, 26)
00:11:41 WORKER: args: ()
00:11:41 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0010267384650772433, 'num_filters_1': 123, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.01753621316222356, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 126, 'num_filters_3': 72}, 'budget': 400.0, 'working_directory': '.'}
00:12:17 DISPATCHER: Starting worker discovery
00:12:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:12:17 DISPATCHER: Finished worker discovery
00:13:17 DISPATCHER: Starting worker discovery
00:13:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:13:17 DISPATCHER: Finished worker discovery
00:14:17 DISPATCHER: Starting worker discovery
00:14:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:14:17 DISPATCHER: Finished worker discovery
00:15:17 DISPATCHER: Starting worker discovery
00:15:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:15:17 DISPATCHER: Finished worker discovery
00:16:17 DISPATCHER: Starting worker discovery
00:16:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:16:17 DISPATCHER: Finished worker discovery
00:17:17 DISPATCHER: Starting worker discovery
00:17:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:17:17 DISPATCHER: Finished worker discovery
00:18:17 DISPATCHER: Starting worker discovery
00:18:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:18:17 DISPATCHER: Finished worker discovery
00:19:17 DISPATCHER: Starting worker discovery
00:19:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:19:17 DISPATCHER: Finished worker discovery
00:19:20 WORKER: done with job (4, 0, 26), trying to register it.
00:19:20 WORKER: registered result for job (4, 0, 26) with dispatcher
00:19:20 DISPATCHER: job (4, 0, 26) finished
00:19:20 DISPATCHER: register_result: lock acquired
00:19:20 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
00:19:20 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0010267384650772433, 'num_filters_1': 123, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.01753621316222356, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 126, 'num_filters_3': 72}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.47632875398772584, 'info': {'music_genre': 0.47632875398772584, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0010267384650772433, 'num_filters_1': 123, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.01753621316222356, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 126, 'num_filters_3': 72}"}}
exception: None

00:19:20 job_callback for (4, 0, 26) started
00:19:20 DISPATCHER: Trying to submit another job.
00:19:20 job_callback for (4, 0, 26) got condition
00:19:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:19:20 Only 15 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
00:19:20 HBMASTER: Trying to run another job!
00:19:20 job_callback for (4, 0, 26) finished
00:19:20 ITERATION: Advancing config (4, 0, 26) to next budget 1200.000000
00:19:20 HBMASTER: schedule new run for iteration 4
00:19:20 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
00:19:20 HBMASTER: submitting job (4, 0, 26) to dispatcher
00:19:20 DISPATCHER: trying to submit job (4, 0, 26)
00:19:20 DISPATCHER: trying to notify the job_runner thread.
00:19:20 HBMASTER: job (4, 0, 26) submitted to dispatcher
00:19:20 DISPATCHER: Trying to submit another job.
00:19:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:19:20 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:19:20 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:19:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:19:20 WORKER: start processing job (4, 0, 26)
00:19:20 WORKER: args: ()
00:19:20 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0010267384650772433, 'num_filters_1': 123, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.01753621316222356, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 126, 'num_filters_3': 72}, 'budget': 1200.0, 'working_directory': '.'}
00:20:17 DISPATCHER: Starting worker discovery
00:20:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:20:17 DISPATCHER: Finished worker discovery
00:21:17 DISPATCHER: Starting worker discovery
00:21:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:21:17 DISPATCHER: Finished worker discovery
00:22:17 DISPATCHER: Starting worker discovery
00:22:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:22:17 DISPATCHER: Finished worker discovery
00:23:17 DISPATCHER: Starting worker discovery
00:23:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:23:17 DISPATCHER: Finished worker discovery
00:24:17 DISPATCHER: Starting worker discovery
00:24:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:24:17 DISPATCHER: Finished worker discovery
00:25:17 DISPATCHER: Starting worker discovery
00:25:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:25:17 DISPATCHER: Finished worker discovery
00:26:17 DISPATCHER: Starting worker discovery
00:26:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:26:17 DISPATCHER: Finished worker discovery
00:27:17 DISPATCHER: Starting worker discovery
00:27:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:27:17 DISPATCHER: Finished worker discovery
00:28:17 DISPATCHER: Starting worker discovery
00:28:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:28:17 DISPATCHER: Finished worker discovery
00:29:17 DISPATCHER: Starting worker discovery
00:29:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:29:17 DISPATCHER: Finished worker discovery
00:30:17 DISPATCHER: Starting worker discovery
00:30:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:30:17 DISPATCHER: Finished worker discovery
00:31:17 DISPATCHER: Starting worker discovery
00:31:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:31:17 DISPATCHER: Finished worker discovery
00:32:17 DISPATCHER: Starting worker discovery
00:32:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:32:17 DISPATCHER: Finished worker discovery
00:33:17 DISPATCHER: Starting worker discovery
00:33:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:33:17 DISPATCHER: Finished worker discovery
00:34:17 DISPATCHER: Starting worker discovery
00:34:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:34:17 DISPATCHER: Finished worker discovery
00:35:17 DISPATCHER: Starting worker discovery
00:35:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:35:17 DISPATCHER: Finished worker discovery
00:36:17 DISPATCHER: Starting worker discovery
00:36:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:36:17 DISPATCHER: Finished worker discovery
00:37:17 DISPATCHER: Starting worker discovery
00:37:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:37:17 DISPATCHER: Finished worker discovery
00:38:17 DISPATCHER: Starting worker discovery
00:38:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:38:17 DISPATCHER: Finished worker discovery
00:39:17 DISPATCHER: Starting worker discovery
00:39:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:39:17 DISPATCHER: Finished worker discovery
00:40:17 DISPATCHER: Starting worker discovery
00:40:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:40:17 DISPATCHER: Finished worker discovery
00:40:25 WORKER: done with job (4, 0, 26), trying to register it.
00:40:25 WORKER: registered result for job (4, 0, 26) with dispatcher
00:40:25 DISPATCHER: job (4, 0, 26) finished
00:40:25 DISPATCHER: register_result: lock acquired
00:40:25 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
00:40:25 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0010267384650772433, 'num_filters_1': 123, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.01753621316222356, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 126, 'num_filters_3': 72}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.4055508499138272, 'info': {'music_genre': 0.4055508499138272, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0010267384650772433, 'num_filters_1': 123, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.01753621316222356, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 126, 'num_filters_3': 72}"}}
exception: None

00:40:25 job_callback for (4, 0, 26) started
00:40:25 job_callback for (4, 0, 26) got condition
00:40:25 DISPATCHER: Trying to submit another job.
00:40:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:40:25 Only 9 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
00:40:25 HBMASTER: Trying to run another job!
00:40:25 job_callback for (4, 0, 26) finished
00:40:25 start sampling a new configuration.
00:40:25 best_vector: [1, 1, 0.13282676716504965, 0.10365732009795812, 0.4400430298357665, 1, 0.7071915410966454, 0.5745997069643556, 2, 1, 1, 2, 0.6323371952825451, 0.8130382187436749, 0.8949748183662217, 0.7256562191941988], 0.00873844657312379, 0.0009156995587956813, 8.001791671569089e-06
00:40:25 done sampling a new configuration.
00:40:26 HBMASTER: schedule new run for iteration 5
00:40:26 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
00:40:26 HBMASTER: submitting job (5, 0, 0) to dispatcher
00:40:26 DISPATCHER: trying to submit job (5, 0, 0)
00:40:26 DISPATCHER: trying to notify the job_runner thread.
00:40:26 HBMASTER: job (5, 0, 0) submitted to dispatcher
00:40:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:40:26 DISPATCHER: Trying to submit another job.
00:40:26 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:40:26 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:40:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:40:26 WORKER: start processing job (5, 0, 0)
00:40:26 WORKER: args: ()
00:40:26 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0018435441142985595, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.055920552581594014, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 59, 'num_filters_3': 87}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:41:17 DISPATCHER: Starting worker discovery
00:41:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:41:17 DISPATCHER: Finished worker discovery
00:42:17 DISPATCHER: Starting worker discovery
00:42:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:42:17 DISPATCHER: Finished worker discovery
00:43:17 DISPATCHER: Starting worker discovery
00:43:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:43:17 DISPATCHER: Finished worker discovery
00:43:35 WORKER: done with job (5, 0, 0), trying to register it.
00:43:35 WORKER: registered result for job (5, 0, 0) with dispatcher
00:43:35 DISPATCHER: job (5, 0, 0) finished
00:43:35 DISPATCHER: register_result: lock acquired
00:43:35 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
00:43:35 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0018435441142985595, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.055920552581594014, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 59, 'num_filters_3': 87}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3718034697853513, 'info': {'music_genre': 0.3718034697853513, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0018435441142985595, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.055920552581594014, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 59, 'num_filters_3': 87}"}}
exception: None

00:43:35 job_callback for (5, 0, 0) started
00:43:35 job_callback for (5, 0, 0) got condition
00:43:35 DISPATCHER: Trying to submit another job.
00:43:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:43:35 HBMASTER: Trying to run another job!
00:43:35 job_callback for (5, 0, 0) finished
00:43:35 start sampling a new configuration.
00:43:35 done sampling a new configuration.
00:43:35 HBMASTER: schedule new run for iteration 5
00:43:35 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
00:43:35 HBMASTER: submitting job (5, 0, 1) to dispatcher
00:43:35 DISPATCHER: trying to submit job (5, 0, 1)
00:43:35 DISPATCHER: trying to notify the job_runner thread.
00:43:35 HBMASTER: job (5, 0, 1) submitted to dispatcher
00:43:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:43:35 DISPATCHER: Trying to submit another job.
00:43:35 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:43:35 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:43:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:43:35 WORKER: start processing job (5, 0, 1)
00:43:35 WORKER: args: ()
00:43:35 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.007009232230797139, 'num_filters_1': 105, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.011355529853639296, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 125, 'num_filters_3': 113}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:44:17 DISPATCHER: Starting worker discovery
00:44:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:44:17 DISPATCHER: Finished worker discovery
00:45:17 DISPATCHER: Starting worker discovery
00:45:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:45:17 DISPATCHER: Finished worker discovery
00:46:17 DISPATCHER: Starting worker discovery
00:46:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:46:17 DISPATCHER: Finished worker discovery
00:46:45 WORKER: done with job (5, 0, 1), trying to register it.
00:46:45 WORKER: registered result for job (5, 0, 1) with dispatcher
00:46:45 DISPATCHER: job (5, 0, 1) finished
00:46:45 DISPATCHER: register_result: lock acquired
00:46:45 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
00:46:45 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.007009232230797139, 'num_filters_1': 105, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.011355529853639296, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 125, 'num_filters_3': 113}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4496720768045248, 'info': {'music_genre': 0.4496720768045248, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.007009232230797139, 'num_filters_1': 105, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.011355529853639296, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 125, 'num_filters_3': 113}"}}
exception: None

00:46:45 job_callback for (5, 0, 1) started
00:46:45 job_callback for (5, 0, 1) got condition
00:46:45 DISPATCHER: Trying to submit another job.
00:46:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:46:45 HBMASTER: Trying to run another job!
00:46:45 job_callback for (5, 0, 1) finished
00:46:45 start sampling a new configuration.
00:46:45 done sampling a new configuration.
00:46:45 HBMASTER: schedule new run for iteration 5
00:46:45 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
00:46:45 HBMASTER: submitting job (5, 0, 2) to dispatcher
00:46:45 DISPATCHER: trying to submit job (5, 0, 2)
00:46:45 DISPATCHER: trying to notify the job_runner thread.
00:46:45 HBMASTER: job (5, 0, 2) submitted to dispatcher
00:46:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:46:45 DISPATCHER: Trying to submit another job.
00:46:45 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:46:45 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:46:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:46:45 WORKER: start processing job (5, 0, 2)
00:46:45 WORKER: args: ()
00:46:45 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.012201278836433566, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.08731182031800641, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 21, 'num_filters_3': 57}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:47:17 DISPATCHER: Starting worker discovery
00:47:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:47:17 DISPATCHER: Finished worker discovery
00:48:17 DISPATCHER: Starting worker discovery
00:48:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:48:17 DISPATCHER: Finished worker discovery
00:49:17 DISPATCHER: Starting worker discovery
00:49:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:49:17 DISPATCHER: Finished worker discovery
00:49:57 WORKER: done with job (5, 0, 2), trying to register it.
00:49:57 WORKER: registered result for job (5, 0, 2) with dispatcher
00:49:57 DISPATCHER: job (5, 0, 2) finished
00:49:57 DISPATCHER: register_result: lock acquired
00:49:57 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
00:49:57 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.012201278836433566, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.08731182031800641, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 21, 'num_filters_3': 57}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0005471234681214364, 'info': {'music_genre': 0.0005471234681214364, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.012201278836433566, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.08731182031800641, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 21, 'num_filters_3': 57}"}}
exception: None

00:49:57 job_callback for (5, 0, 2) started
00:49:57 DISPATCHER: Trying to submit another job.
00:49:57 job_callback for (5, 0, 2) got condition
00:49:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:49:57 HBMASTER: Trying to run another job!
00:49:57 job_callback for (5, 0, 2) finished
00:49:57 start sampling a new configuration.
00:49:57 best_vector: [3, 1, 0.007487004087609245, 0.39883901380909786, 0.07861079394659881, 1, 0.1490703534777313, 0.17317236925880405, 2, 2, 2, 1, 0.07155475851832027, 0.7358725682761252, 0.7824656891763341, 0.06815752423817611], 0.004081259411728615, 0.00010110394746439185, 4.126314371519647e-07
00:49:57 done sampling a new configuration.
00:49:57 HBMASTER: schedule new run for iteration 5
00:49:57 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
00:49:57 HBMASTER: submitting job (5, 0, 3) to dispatcher
00:49:57 DISPATCHER: trying to submit job (5, 0, 3)
00:49:57 DISPATCHER: trying to notify the job_runner thread.
00:49:57 HBMASTER: job (5, 0, 3) submitted to dispatcher
00:49:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:49:57 DISPATCHER: Trying to submit another job.
00:49:57 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:49:57 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:49:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:49:57 WORKER: start processing job (5, 0, 3)
00:49:57 WORKER: args: ()
00:49:57 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0010350802169428403, 'num_filters_1': 36, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.01679973560470938}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:50:17 DISPATCHER: Starting worker discovery
00:50:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:50:17 DISPATCHER: Finished worker discovery
00:51:17 DISPATCHER: Starting worker discovery
00:51:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:51:17 DISPATCHER: Finished worker discovery
00:52:17 DISPATCHER: Starting worker discovery
00:52:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:52:17 DISPATCHER: Finished worker discovery
00:53:10 WORKER: done with job (5, 0, 3), trying to register it.
00:53:10 WORKER: registered result for job (5, 0, 3) with dispatcher
00:53:10 DISPATCHER: job (5, 0, 3) finished
00:53:10 DISPATCHER: register_result: lock acquired
00:53:10 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
00:53:10 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0010350802169428403, 'num_filters_1': 36, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.01679973560470938}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.40961893509544745, 'info': {'music_genre': 0.40961893509544745, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0010350802169428403, 'num_filters_1': 36, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.01679973560470938}"}}
exception: None

00:53:10 job_callback for (5, 0, 3) started
00:53:10 job_callback for (5, 0, 3) got condition
00:53:10 DISPATCHER: Trying to submit another job.
00:53:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:53:10 HBMASTER: Trying to run another job!
00:53:10 job_callback for (5, 0, 3) finished
00:53:10 start sampling a new configuration.
00:53:10 best_vector: [2, 1, 0.23147805605911506, 0.5310033179134167, 0.5981872602118349, 1, 0.04125717902759035, 0.5452335882514068, 0, 2, 2, 1, 0.9460709144506279, 0.8384247082135182, 0.7315466843060564, 0.7784855831604945], 0.010009825820704126, 0.002576382082976096, 2.5789135898173608e-05
00:53:10 done sampling a new configuration.
00:53:10 HBMASTER: schedule new run for iteration 5
00:53:10 HBMASTER: trying submitting job (5, 0, 4) to dispatcher
00:53:10 HBMASTER: submitting job (5, 0, 4) to dispatcher
00:53:10 DISPATCHER: trying to submit job (5, 0, 4)
00:53:10 DISPATCHER: trying to notify the job_runner thread.
00:53:10 HBMASTER: job (5, 0, 4) submitted to dispatcher
00:53:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:53:10 DISPATCHER: Trying to submit another job.
00:53:10 DISPATCHER: starting job (5, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:53:10 DISPATCHER: job (5, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:53:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:53:10 WORKER: start processing job (5, 0, 4)
00:53:10 WORKER: args: ()
00:53:10 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.002903729201591792, 'num_filters_1': 48, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.05121123542900934, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 115, 'num_filters_3': 91}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:53:17 DISPATCHER: Starting worker discovery
00:53:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:53:17 DISPATCHER: Finished worker discovery
00:54:17 DISPATCHER: Starting worker discovery
00:54:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:54:17 DISPATCHER: Finished worker discovery
00:55:17 DISPATCHER: Starting worker discovery
00:55:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:55:18 DISPATCHER: Finished worker discovery
00:56:18 DISPATCHER: Starting worker discovery
00:56:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:56:18 DISPATCHER: Finished worker discovery
00:56:22 WORKER: done with job (5, 0, 4), trying to register it.
00:56:22 WORKER: registered result for job (5, 0, 4) with dispatcher
00:56:22 DISPATCHER: job (5, 0, 4) finished
00:56:22 DISPATCHER: register_result: lock acquired
00:56:22 DISPATCHER: job (5, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
00:56:22 job_id: (5, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.002903729201591792, 'num_filters_1': 48, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.05121123542900934, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 115, 'num_filters_3': 91}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3662000259902657, 'info': {'music_genre': 0.3662000259902657, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.002903729201591792, 'num_filters_1': 48, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.05121123542900934, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 115, 'num_filters_3': 91}"}}
exception: None

00:56:22 job_callback for (5, 0, 4) started
00:56:22 job_callback for (5, 0, 4) got condition
00:56:22 DISPATCHER: Trying to submit another job.
00:56:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:56:22 HBMASTER: Trying to run another job!
00:56:22 job_callback for (5, 0, 4) finished
00:56:22 start sampling a new configuration.
00:56:22 done sampling a new configuration.
00:56:22 HBMASTER: schedule new run for iteration 5
00:56:22 HBMASTER: trying submitting job (5, 0, 5) to dispatcher
00:56:22 HBMASTER: submitting job (5, 0, 5) to dispatcher
00:56:22 DISPATCHER: trying to submit job (5, 0, 5)
00:56:22 DISPATCHER: trying to notify the job_runner thread.
00:56:22 HBMASTER: job (5, 0, 5) submitted to dispatcher
00:56:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:56:22 DISPATCHER: Trying to submit another job.
00:56:22 DISPATCHER: starting job (5, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:56:22 DISPATCHER: job (5, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:56:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:56:22 WORKER: start processing job (5, 0, 5)
00:56:22 WORKER: args: ()
00:56:22 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.025885015758944082, 'num_filters_1': 61, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.016644067461998403}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:57:18 DISPATCHER: Starting worker discovery
00:57:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:57:18 DISPATCHER: Finished worker discovery
00:58:18 DISPATCHER: Starting worker discovery
00:58:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:58:18 DISPATCHER: Finished worker discovery
00:59:18 DISPATCHER: Starting worker discovery
00:59:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:59:18 DISPATCHER: Finished worker discovery
00:59:31 WORKER: done with job (5, 0, 5), trying to register it.
00:59:31 WORKER: registered result for job (5, 0, 5) with dispatcher
00:59:31 DISPATCHER: job (5, 0, 5) finished
00:59:31 DISPATCHER: register_result: lock acquired
00:59:31 DISPATCHER: job (5, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
00:59:31 job_id: (5, 0, 5)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.025885015758944082, 'num_filters_1': 61, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.016644067461998403}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.05677840426079128, 'info': {'music_genre': 0.05677840426079128, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.025885015758944082, 'num_filters_1': 61, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.016644067461998403}"}}
exception: None

00:59:31 job_callback for (5, 0, 5) started
00:59:31 DISPATCHER: Trying to submit another job.
00:59:31 job_callback for (5, 0, 5) got condition
00:59:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:59:31 HBMASTER: Trying to run another job!
00:59:31 job_callback for (5, 0, 5) finished
00:59:31 start sampling a new configuration.
00:59:31 done sampling a new configuration.
00:59:31 HBMASTER: schedule new run for iteration 5
00:59:31 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
00:59:31 HBMASTER: submitting job (5, 0, 6) to dispatcher
00:59:31 DISPATCHER: trying to submit job (5, 0, 6)
00:59:31 DISPATCHER: trying to notify the job_runner thread.
00:59:31 HBMASTER: job (5, 0, 6) submitted to dispatcher
00:59:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:59:31 DISPATCHER: Trying to submit another job.
00:59:31 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:59:31 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
00:59:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:59:31 WORKER: start processing job (5, 0, 6)
00:59:31 WORKER: args: ()
00:59:31 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0075472944939786795, 'num_filters_1': 30, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.018718745641847515, 'kernel_size_2': 5, 'num_filters_2': 26}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:00:18 DISPATCHER: Starting worker discovery
01:00:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:00:18 DISPATCHER: Finished worker discovery
01:01:18 DISPATCHER: Starting worker discovery
01:01:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:01:18 DISPATCHER: Finished worker discovery
01:02:18 DISPATCHER: Starting worker discovery
01:02:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:02:18 DISPATCHER: Finished worker discovery
01:02:41 WORKER: done with job (5, 0, 6), trying to register it.
01:02:41 WORKER: registered result for job (5, 0, 6) with dispatcher
01:02:41 DISPATCHER: job (5, 0, 6) finished
01:02:41 DISPATCHER: register_result: lock acquired
01:02:41 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:02:41 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0075472944939786795, 'num_filters_1': 30, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.018718745641847515, 'kernel_size_2': 5, 'num_filters_2': 26}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.23094198796592666, 'info': {'music_genre': 0.23094198796592666, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0075472944939786795, 'num_filters_1': 30, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.018718745641847515, 'kernel_size_2': 5, 'num_filters_2': 26}"}}
exception: None

01:02:41 job_callback for (5, 0, 6) started
01:02:41 job_callback for (5, 0, 6) got condition
01:02:41 DISPATCHER: Trying to submit another job.
01:02:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:02:41 done building a new model for budget 133.333333 based on 17/28 split
Best loss for this budget:-0.510625





01:02:41 HBMASTER: Trying to run another job!
01:02:41 job_callback for (5, 0, 6) finished
01:02:41 start sampling a new configuration.
01:02:41 done sampling a new configuration.
01:02:41 HBMASTER: schedule new run for iteration 5
01:02:41 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
01:02:41 HBMASTER: submitting job (5, 0, 7) to dispatcher
01:02:41 DISPATCHER: trying to submit job (5, 0, 7)
01:02:41 DISPATCHER: trying to notify the job_runner thread.
01:02:41 HBMASTER: job (5, 0, 7) submitted to dispatcher
01:02:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:02:41 DISPATCHER: Trying to submit another job.
01:02:41 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:02:41 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:02:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:02:41 WORKER: start processing job (5, 0, 7)
01:02:41 WORKER: args: ()
01:02:41 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.018778867238893777, 'num_filters_1': 33, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.03083210945097143, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 20, 'num_filters_3': 50, 'num_filters_4': 46, 'num_filters_5': 65}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:03:18 DISPATCHER: Starting worker discovery
01:03:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:03:18 DISPATCHER: Finished worker discovery
01:04:18 DISPATCHER: Starting worker discovery
01:04:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:04:18 DISPATCHER: Finished worker discovery
01:05:18 DISPATCHER: Starting worker discovery
01:05:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:05:18 DISPATCHER: Finished worker discovery
01:05:49 WORKER: done with job (5, 0, 7), trying to register it.
01:05:49 WORKER: registered result for job (5, 0, 7) with dispatcher
01:05:49 DISPATCHER: job (5, 0, 7) finished
01:05:49 DISPATCHER: register_result: lock acquired
01:05:49 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:05:49 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.018778867238893777, 'num_filters_1': 33, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.03083210945097143, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 20, 'num_filters_3': 50, 'num_filters_4': 46, 'num_filters_5': 65}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.018778867238893777, 'num_filters_1': 33, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.03083210945097143, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 20, 'num_filters_3': 50, 'num_filters_4': 46, 'num_filters_5': 65}"}}
exception: None

01:05:49 job_callback for (5, 0, 7) started
01:05:49 job_callback for (5, 0, 7) got condition
01:05:49 DISPATCHER: Trying to submit another job.
01:05:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:05:49 done building a new model for budget 133.333333 based on 17/29 split
Best loss for this budget:-0.510625





01:05:49 HBMASTER: Trying to run another job!
01:05:49 job_callback for (5, 0, 7) finished
01:05:49 start sampling a new configuration.
01:05:49 best_vector: [1, 0, 0.03539011265612259, 0.5483516693334609, 0.07281518537723142, 1, 0.7579960399486129, 0.0006009336605879989, 1, 2, 2, 2, 0.5830186538746251, 0.7550248308673, 0.131716010215877, 0.17200359065816073], 0.000667131687717374, 0.0001594288918386129, 1.063600656832045e-07
01:05:49 done sampling a new configuration.
01:05:49 HBMASTER: schedule new run for iteration 5
01:05:49 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
01:05:49 HBMASTER: submitting job (5, 0, 8) to dispatcher
01:05:49 DISPATCHER: trying to submit job (5, 0, 8)
01:05:49 DISPATCHER: trying to notify the job_runner thread.
01:05:49 HBMASTER: job (5, 0, 8) submitted to dispatcher
01:05:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:05:49 DISPATCHER: Trying to submit another job.
01:05:49 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:05:49 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:05:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:05:49 WORKER: start processing job (5, 0, 8)
01:05:49 WORKER: args: ()
01:05:49 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.00117701019687138, 'num_filters_1': 49, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.010018018577595876}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:06:18 DISPATCHER: Starting worker discovery
01:06:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:06:18 DISPATCHER: Finished worker discovery
01:07:18 DISPATCHER: Starting worker discovery
01:07:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:07:18 DISPATCHER: Finished worker discovery
01:08:18 DISPATCHER: Starting worker discovery
01:08:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:08:18 DISPATCHER: Finished worker discovery
01:09:00 WORKER: done with job (5, 0, 8), trying to register it.
01:09:00 WORKER: registered result for job (5, 0, 8) with dispatcher
01:09:00 DISPATCHER: job (5, 0, 8) finished
01:09:00 DISPATCHER: register_result: lock acquired
01:09:00 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:09:00 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.00117701019687138, 'num_filters_1': 49, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.010018018577595876}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4529968335488162, 'info': {'music_genre': 0.4529968335488162, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.00117701019687138, 'num_filters_1': 49, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.010018018577595876}"}}
exception: None

01:09:00 job_callback for (5, 0, 8) started
01:09:00 DISPATCHER: Trying to submit another job.
01:09:00 job_callback for (5, 0, 8) got condition
01:09:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:09:00 done building a new model for budget 133.333333 based on 17/30 split
Best loss for this budget:-0.510625





01:09:00 HBMASTER: Trying to run another job!
01:09:00 job_callback for (5, 0, 8) finished
01:09:00 ITERATION: Advancing config (5, 0, 1) to next budget 400.000000
01:09:00 ITERATION: Advancing config (5, 0, 3) to next budget 400.000000
01:09:00 ITERATION: Advancing config (5, 0, 8) to next budget 400.000000
01:09:00 HBMASTER: schedule new run for iteration 5
01:09:00 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
01:09:00 HBMASTER: submitting job (5, 0, 1) to dispatcher
01:09:00 DISPATCHER: trying to submit job (5, 0, 1)
01:09:00 DISPATCHER: trying to notify the job_runner thread.
01:09:00 HBMASTER: job (5, 0, 1) submitted to dispatcher
01:09:00 DISPATCHER: Trying to submit another job.
01:09:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:09:00 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:09:00 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:09:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:09:00 WORKER: start processing job (5, 0, 1)
01:09:00 WORKER: args: ()
01:09:00 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.007009232230797139, 'num_filters_1': 105, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.011355529853639296, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 125, 'num_filters_3': 113}, 'budget': 400.0, 'working_directory': '.'}
01:09:18 DISPATCHER: Starting worker discovery
01:09:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:09:18 DISPATCHER: Finished worker discovery
01:10:18 DISPATCHER: Starting worker discovery
01:10:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:10:18 DISPATCHER: Finished worker discovery
01:11:18 DISPATCHER: Starting worker discovery
01:11:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:11:18 DISPATCHER: Finished worker discovery
01:12:18 DISPATCHER: Starting worker discovery
01:12:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:12:18 DISPATCHER: Finished worker discovery
01:13:18 DISPATCHER: Starting worker discovery
01:13:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:13:18 DISPATCHER: Finished worker discovery
01:14:18 DISPATCHER: Starting worker discovery
01:14:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:14:18 DISPATCHER: Finished worker discovery
01:15:18 DISPATCHER: Starting worker discovery
01:15:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:15:18 DISPATCHER: Finished worker discovery
01:16:18 DISPATCHER: Starting worker discovery
01:16:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:16:18 DISPATCHER: Finished worker discovery
01:16:39 WORKER: done with job (5, 0, 1), trying to register it.
01:16:39 WORKER: registered result for job (5, 0, 1) with dispatcher
01:16:39 DISPATCHER: job (5, 0, 1) finished
01:16:39 DISPATCHER: register_result: lock acquired
01:16:39 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:16:39 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.007009232230797139, 'num_filters_1': 105, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.011355529853639296, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 125, 'num_filters_3': 113}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.36833878742296194, 'info': {'music_genre': 0.36833878742296194, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.007009232230797139, 'num_filters_1': 105, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.011355529853639296, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 125, 'num_filters_3': 113}"}}
exception: None

01:16:39 job_callback for (5, 0, 1) started
01:16:39 DISPATCHER: Trying to submit another job.
01:16:39 job_callback for (5, 0, 1) got condition
01:16:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:16:39 Only 16 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
01:16:39 HBMASTER: Trying to run another job!
01:16:39 job_callback for (5, 0, 1) finished
01:16:39 HBMASTER: schedule new run for iteration 5
01:16:39 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
01:16:39 HBMASTER: submitting job (5, 0, 3) to dispatcher
01:16:39 DISPATCHER: trying to submit job (5, 0, 3)
01:16:39 DISPATCHER: trying to notify the job_runner thread.
01:16:39 HBMASTER: job (5, 0, 3) submitted to dispatcher
01:16:39 DISPATCHER: Trying to submit another job.
01:16:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:16:39 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:16:39 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:16:39 WORKER: start processing job (5, 0, 3)
01:16:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:16:39 WORKER: args: ()
01:16:39 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0010350802169428403, 'num_filters_1': 36, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.01679973560470938}, 'budget': 400.0, 'working_directory': '.'}
01:17:18 DISPATCHER: Starting worker discovery
01:17:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:17:18 DISPATCHER: Finished worker discovery
01:18:18 DISPATCHER: Starting worker discovery
01:18:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:18:18 DISPATCHER: Finished worker discovery
01:19:18 DISPATCHER: Starting worker discovery
01:19:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:19:18 DISPATCHER: Finished worker discovery
01:20:18 DISPATCHER: Starting worker discovery
01:20:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:20:18 DISPATCHER: Finished worker discovery
01:21:18 DISPATCHER: Starting worker discovery
01:21:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:21:18 DISPATCHER: Finished worker discovery
01:22:18 DISPATCHER: Starting worker discovery
01:22:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:22:18 DISPATCHER: Finished worker discovery
01:23:18 DISPATCHER: Starting worker discovery
01:23:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:23:18 DISPATCHER: Finished worker discovery
01:24:18 DISPATCHER: Starting worker discovery
01:24:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:24:18 DISPATCHER: Finished worker discovery
01:24:28 WORKER: done with job (5, 0, 3), trying to register it.
01:24:28 WORKER: registered result for job (5, 0, 3) with dispatcher
01:24:28 DISPATCHER: job (5, 0, 3) finished
01:24:28 DISPATCHER: register_result: lock acquired
01:24:28 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:24:29 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0010350802169428403, 'num_filters_1': 36, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.01679973560470938}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3946178386989742, 'info': {'music_genre': 0.3946178386989742, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0010350802169428403, 'num_filters_1': 36, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.01679973560470938}"}}
exception: None

01:24:29 job_callback for (5, 0, 3) started
01:24:29 DISPATCHER: Trying to submit another job.
01:24:29 job_callback for (5, 0, 3) got condition
01:24:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:24:29 HBMASTER: Trying to run another job!
01:24:29 job_callback for (5, 0, 3) finished
01:24:29 HBMASTER: schedule new run for iteration 5
01:24:29 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
01:24:29 HBMASTER: submitting job (5, 0, 8) to dispatcher
01:24:29 DISPATCHER: trying to submit job (5, 0, 8)
01:24:29 DISPATCHER: trying to notify the job_runner thread.
01:24:29 HBMASTER: job (5, 0, 8) submitted to dispatcher
01:24:29 DISPATCHER: Trying to submit another job.
01:24:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:24:29 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:24:29 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:24:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:24:29 WORKER: start processing job (5, 0, 8)
01:24:29 WORKER: args: ()
01:24:29 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.00117701019687138, 'num_filters_1': 49, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.010018018577595876}, 'budget': 400.0, 'working_directory': '.'}
01:25:18 DISPATCHER: Starting worker discovery
01:25:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:25:18 DISPATCHER: Finished worker discovery
01:26:18 DISPATCHER: Starting worker discovery
01:26:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:26:18 DISPATCHER: Finished worker discovery
01:27:18 DISPATCHER: Starting worker discovery
01:27:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:27:18 DISPATCHER: Finished worker discovery
01:28:18 DISPATCHER: Starting worker discovery
01:28:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:28:18 DISPATCHER: Finished worker discovery
01:29:18 DISPATCHER: Starting worker discovery
01:29:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:29:18 DISPATCHER: Finished worker discovery
01:30:18 DISPATCHER: Starting worker discovery
01:30:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:30:18 DISPATCHER: Finished worker discovery
01:31:18 DISPATCHER: Starting worker discovery
01:31:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:31:18 DISPATCHER: Finished worker discovery
01:32:08 WORKER: done with job (5, 0, 8), trying to register it.
01:32:08 WORKER: registered result for job (5, 0, 8) with dispatcher
01:32:08 DISPATCHER: job (5, 0, 8) finished
01:32:08 DISPATCHER: register_result: lock acquired
01:32:08 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:32:08 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.00117701019687138, 'num_filters_1': 49, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.010018018577595876}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3881125859364297, 'info': {'music_genre': 0.3881125859364297, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.00117701019687138, 'num_filters_1': 49, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.010018018577595876}"}}
exception: None

01:32:08 job_callback for (5, 0, 8) started
01:32:08 job_callback for (5, 0, 8) got condition
01:32:08 DISPATCHER: Trying to submit another job.
01:32:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:32:08 HBMASTER: Trying to run another job!
01:32:08 job_callback for (5, 0, 8) finished
01:32:08 ITERATION: Advancing config (5, 0, 3) to next budget 1200.000000
01:32:08 HBMASTER: schedule new run for iteration 5
01:32:08 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
01:32:08 HBMASTER: submitting job (5, 0, 3) to dispatcher
01:32:08 DISPATCHER: trying to submit job (5, 0, 3)
01:32:08 DISPATCHER: trying to notify the job_runner thread.
01:32:08 HBMASTER: job (5, 0, 3) submitted to dispatcher
01:32:08 DISPATCHER: Trying to submit another job.
01:32:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:32:08 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:32:08 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:32:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:32:08 WORKER: start processing job (5, 0, 3)
01:32:08 WORKER: args: ()
01:32:08 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0010350802169428403, 'num_filters_1': 36, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.01679973560470938}, 'budget': 1200.0, 'working_directory': '.'}
01:32:18 DISPATCHER: Starting worker discovery
01:32:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:32:18 DISPATCHER: Finished worker discovery
01:33:18 DISPATCHER: Starting worker discovery
01:33:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:33:18 DISPATCHER: Finished worker discovery
01:34:18 DISPATCHER: Starting worker discovery
01:34:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:34:18 DISPATCHER: Finished worker discovery
01:35:18 DISPATCHER: Starting worker discovery
01:35:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:35:18 DISPATCHER: Finished worker discovery
01:36:18 DISPATCHER: Starting worker discovery
01:36:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:36:18 DISPATCHER: Finished worker discovery
01:37:18 DISPATCHER: Starting worker discovery
01:37:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:37:18 DISPATCHER: Finished worker discovery
01:38:18 DISPATCHER: Starting worker discovery
01:38:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:38:18 DISPATCHER: Finished worker discovery
01:39:18 DISPATCHER: Starting worker discovery
01:39:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:39:18 DISPATCHER: Finished worker discovery
01:40:18 DISPATCHER: Starting worker discovery
01:40:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:40:18 DISPATCHER: Finished worker discovery
01:41:18 DISPATCHER: Starting worker discovery
01:41:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:41:18 DISPATCHER: Finished worker discovery
01:42:18 DISPATCHER: Starting worker discovery
01:42:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:42:18 DISPATCHER: Finished worker discovery
01:43:18 DISPATCHER: Starting worker discovery
01:43:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:43:18 DISPATCHER: Finished worker discovery
01:44:18 DISPATCHER: Starting worker discovery
01:44:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:44:18 DISPATCHER: Finished worker discovery
01:45:18 DISPATCHER: Starting worker discovery
01:45:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:45:18 DISPATCHER: Finished worker discovery
01:46:18 DISPATCHER: Starting worker discovery
01:46:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:46:18 DISPATCHER: Finished worker discovery
01:47:18 DISPATCHER: Starting worker discovery
01:47:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:47:18 DISPATCHER: Finished worker discovery
01:48:18 DISPATCHER: Starting worker discovery
01:48:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:48:18 DISPATCHER: Finished worker discovery
01:49:18 DISPATCHER: Starting worker discovery
01:49:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:49:18 DISPATCHER: Finished worker discovery
01:50:18 DISPATCHER: Starting worker discovery
01:50:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:50:18 DISPATCHER: Finished worker discovery
01:51:18 DISPATCHER: Starting worker discovery
01:51:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:51:18 DISPATCHER: Finished worker discovery
01:52:18 DISPATCHER: Starting worker discovery
01:52:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:52:18 DISPATCHER: Finished worker discovery
01:53:18 DISPATCHER: Starting worker discovery
01:53:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:53:19 DISPATCHER: Finished worker discovery
01:53:37 WORKER: done with job (5, 0, 3), trying to register it.
01:53:37 WORKER: registered result for job (5, 0, 3) with dispatcher
01:53:37 DISPATCHER: job (5, 0, 3) finished
01:53:37 DISPATCHER: register_result: lock acquired
01:53:37 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
01:53:37 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0010350802169428403, 'num_filters_1': 36, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.01679973560470938}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.3816393224942868, 'info': {'music_genre': 0.3816393224942868, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0010350802169428403, 'num_filters_1': 36, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.01679973560470938}"}}
exception: None

01:53:37 job_callback for (5, 0, 3) started
01:53:37 DISPATCHER: Trying to submit another job.
01:53:37 job_callback for (5, 0, 3) got condition
01:53:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:53:37 Only 10 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
01:53:37 HBMASTER: Trying to run another job!
01:53:37 job_callback for (5, 0, 3) finished
01:53:37 start sampling a new configuration.
01:53:37 done sampling a new configuration.
01:53:37 HBMASTER: schedule new run for iteration 6
01:53:37 HBMASTER: trying submitting job (6, 0, 0) to dispatcher
01:53:37 HBMASTER: submitting job (6, 0, 0) to dispatcher
01:53:37 DISPATCHER: trying to submit job (6, 0, 0)
01:53:37 DISPATCHER: trying to notify the job_runner thread.
01:53:37 HBMASTER: job (6, 0, 0) submitted to dispatcher
01:53:37 DISPATCHER: Trying to submit another job.
01:53:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:53:37 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:53:37 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
01:53:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:53:37 WORKER: start processing job (6, 0, 0)
01:53:37 WORKER: args: ()
01:53:37 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.018412934328709333, 'num_filters_1': 121, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.0260873299423045, 'kernel_size_2': 5, 'num_filters_2': 97}, 'budget': 400.0, 'working_directory': '.'}
01:54:19 DISPATCHER: Starting worker discovery
01:54:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:54:19 DISPATCHER: Finished worker discovery
01:55:19 DISPATCHER: Starting worker discovery
01:55:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:55:19 DISPATCHER: Finished worker discovery
01:56:19 DISPATCHER: Starting worker discovery
01:56:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:56:19 DISPATCHER: Finished worker discovery
01:57:19 DISPATCHER: Starting worker discovery
01:57:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:57:19 DISPATCHER: Finished worker discovery
01:58:19 DISPATCHER: Starting worker discovery
01:58:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:58:19 DISPATCHER: Finished worker discovery
01:59:19 DISPATCHER: Starting worker discovery
01:59:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:59:19 DISPATCHER: Finished worker discovery
02:00:19 DISPATCHER: Starting worker discovery
02:00:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:00:19 DISPATCHER: Finished worker discovery
02:01:14 WORKER: done with job (6, 0, 0), trying to register it.
02:01:14 WORKER: registered result for job (6, 0, 0) with dispatcher
02:01:14 DISPATCHER: job (6, 0, 0) finished
02:01:14 DISPATCHER: register_result: lock acquired
02:01:14 DISPATCHER: job (6, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
02:01:14 job_id: (6, 0, 0)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.018412934328709333, 'num_filters_1': 121, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.0260873299423045, 'kernel_size_2': 5, 'num_filters_2': 97}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.23633751118207558, 'info': {'music_genre': 0.23633751118207558, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.018412934328709333, 'num_filters_1': 121, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.0260873299423045, 'kernel_size_2': 5, 'num_filters_2': 97}"}}
exception: None

02:01:14 job_callback for (6, 0, 0) started
02:01:14 DISPATCHER: Trying to submit another job.
02:01:14 job_callback for (6, 0, 0) got condition
02:01:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:01:14 HBMASTER: Trying to run another job!
02:01:14 job_callback for (6, 0, 0) finished
02:01:14 start sampling a new configuration.
02:01:14 best_vector: [0, 0, 0.34012494273126986, 0.48950878472617837, 0.3598953351308129, 1, 0.9669310390301427, 0.410115916575231, 2, 2, 0, 0, 0.5924409951321468, 0.7319611429799865, 0.08928935951741741, 9.480499449587843e-05], 0.0011797621901360547, 0.00014817089088979316, 1.7480641475055277e-07
02:01:14 done sampling a new configuration.
02:01:14 HBMASTER: schedule new run for iteration 6
02:01:14 HBMASTER: trying submitting job (6, 0, 1) to dispatcher
02:01:14 HBMASTER: submitting job (6, 0, 1) to dispatcher
02:01:14 DISPATCHER: trying to submit job (6, 0, 1)
02:01:14 DISPATCHER: trying to notify the job_runner thread.
02:01:14 HBMASTER: job (6, 0, 1) submitted to dispatcher
02:01:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:01:14 DISPATCHER: Trying to submit another job.
02:01:14 DISPATCHER: starting job (6, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:01:14 DISPATCHER: job (6, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:01:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:01:14 WORKER: start processing job (6, 0, 1)
02:01:14 WORKER: args: ()
02:01:14 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.004789055669654081, 'num_filters_1': 44, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.034164345812926565, 'kernel_size_2': 7, 'num_filters_2': 54}, 'budget': 400.0, 'working_directory': '.'}
02:01:19 DISPATCHER: Starting worker discovery
02:01:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:01:19 DISPATCHER: Finished worker discovery
02:02:19 DISPATCHER: Starting worker discovery
02:02:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:02:19 DISPATCHER: Finished worker discovery
02:03:19 DISPATCHER: Starting worker discovery
02:03:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:03:19 DISPATCHER: Finished worker discovery
02:04:19 DISPATCHER: Starting worker discovery
02:04:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:04:19 DISPATCHER: Finished worker discovery
02:05:19 DISPATCHER: Starting worker discovery
02:05:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:05:19 DISPATCHER: Finished worker discovery
02:06:19 DISPATCHER: Starting worker discovery
02:06:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:06:19 DISPATCHER: Finished worker discovery
02:07:19 DISPATCHER: Starting worker discovery
02:07:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:07:19 DISPATCHER: Finished worker discovery
02:08:19 DISPATCHER: Starting worker discovery
02:08:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:08:19 DISPATCHER: Finished worker discovery
02:08:53 WORKER: done with job (6, 0, 1), trying to register it.
02:08:53 WORKER: registered result for job (6, 0, 1) with dispatcher
02:08:53 DISPATCHER: job (6, 0, 1) finished
02:08:53 DISPATCHER: register_result: lock acquired
02:08:53 DISPATCHER: job (6, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
02:08:53 job_id: (6, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.004789055669654081, 'num_filters_1': 44, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.034164345812926565, 'kernel_size_2': 7, 'num_filters_2': 54}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.2183807126278193, 'info': {'music_genre': 0.2183807126278193, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.004789055669654081, 'num_filters_1': 44, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.034164345812926565, 'kernel_size_2': 7, 'num_filters_2': 54}"}}
exception: None

02:08:53 job_callback for (6, 0, 1) started
02:08:53 DISPATCHER: Trying to submit another job.
02:08:53 job_callback for (6, 0, 1) got condition
02:08:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:08:53 HBMASTER: Trying to run another job!
02:08:53 job_callback for (6, 0, 1) finished
02:08:53 start sampling a new configuration.
02:08:53 best_vector: [2, 0, 0.5950419082244653, 0.9092702990853669, 0.38563029208477495, 1, 0.9695790198863837, 0.6218604049006939, 2, 1, 2, 0, 0.8191106298994651, 0.5983781854738597, 0.11843883418743062, 0.9431107958937325], 0.0024404658518876483, 1.0655639937804708e-05, 2.6004725398222613e-08
02:08:53 done sampling a new configuration.
02:08:53 HBMASTER: schedule new run for iteration 6
02:08:53 HBMASTER: trying submitting job (6, 0, 2) to dispatcher
02:08:53 HBMASTER: submitting job (6, 0, 2) to dispatcher
02:08:53 DISPATCHER: trying to submit job (6, 0, 2)
02:08:53 DISPATCHER: trying to notify the job_runner thread.
02:08:53 HBMASTER: job (6, 0, 2) submitted to dispatcher
02:08:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:08:53 DISPATCHER: Trying to submit another job.
02:08:53 DISPATCHER: starting job (6, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:08:53 DISPATCHER: job (6, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:08:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:08:53 WORKER: start processing job (6, 0, 2)
02:08:53 WORKER: args: ()
02:08:53 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.015491155608566586, 'num_filters_1': 106, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.06442568426555174, 'kernel_size_2': 7, 'num_filters_2': 88}, 'budget': 400.0, 'working_directory': '.'}
02:09:19 DISPATCHER: Starting worker discovery
02:09:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:09:19 DISPATCHER: Finished worker discovery
02:10:19 DISPATCHER: Starting worker discovery
02:10:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:10:19 DISPATCHER: Finished worker discovery
02:11:19 DISPATCHER: Starting worker discovery
02:11:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:11:19 DISPATCHER: Finished worker discovery
02:12:19 DISPATCHER: Starting worker discovery
02:12:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:12:19 DISPATCHER: Finished worker discovery
02:13:19 DISPATCHER: Starting worker discovery
02:13:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:13:19 DISPATCHER: Finished worker discovery
02:14:19 DISPATCHER: Starting worker discovery
02:14:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:14:19 DISPATCHER: Finished worker discovery
02:15:19 DISPATCHER: Starting worker discovery
02:15:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:15:19 DISPATCHER: Finished worker discovery
02:16:19 DISPATCHER: Starting worker discovery
02:16:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:16:19 DISPATCHER: Finished worker discovery
02:16:33 WORKER: done with job (6, 0, 2), trying to register it.
02:16:33 WORKER: registered result for job (6, 0, 2) with dispatcher
02:16:33 DISPATCHER: job (6, 0, 2) finished
02:16:33 DISPATCHER: register_result: lock acquired
02:16:33 DISPATCHER: job (6, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
02:16:33 job_id: (6, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.015491155608566586, 'num_filters_1': 106, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.06442568426555174, 'kernel_size_2': 7, 'num_filters_2': 88}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.18944245125459608, 'info': {'music_genre': 0.18944245125459608, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.015491155608566586, 'num_filters_1': 106, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.06442568426555174, 'kernel_size_2': 7, 'num_filters_2': 88}"}}
exception: None

02:16:33 job_callback for (6, 0, 2) started
02:16:33 job_callback for (6, 0, 2) got condition
02:16:33 DISPATCHER: Trying to submit another job.
02:16:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:16:33 HBMASTER: Trying to run another job!
02:16:33 job_callback for (6, 0, 2) finished
02:16:33 start sampling a new configuration.
02:16:33 done sampling a new configuration.
02:16:33 HBMASTER: schedule new run for iteration 6
02:16:33 HBMASTER: trying submitting job (6, 0, 3) to dispatcher
02:16:33 HBMASTER: submitting job (6, 0, 3) to dispatcher
02:16:33 DISPATCHER: trying to submit job (6, 0, 3)
02:16:33 DISPATCHER: trying to notify the job_runner thread.
02:16:33 HBMASTER: job (6, 0, 3) submitted to dispatcher
02:16:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:16:33 DISPATCHER: Trying to submit another job.
02:16:33 DISPATCHER: starting job (6, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:16:33 DISPATCHER: job (6, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:16:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:16:33 WORKER: start processing job (6, 0, 3)
02:16:33 WORKER: args: ()
02:16:33 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.06050429043885228, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.056198569941081515}, 'budget': 400.0, 'working_directory': '.'}
02:17:19 DISPATCHER: Starting worker discovery
02:17:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:17:19 DISPATCHER: Finished worker discovery
02:18:19 DISPATCHER: Starting worker discovery
02:18:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:18:19 DISPATCHER: Finished worker discovery
02:19:19 DISPATCHER: Starting worker discovery
02:19:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:19:19 DISPATCHER: Finished worker discovery
02:20:19 DISPATCHER: Starting worker discovery
02:20:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:20:19 DISPATCHER: Finished worker discovery
02:21:19 DISPATCHER: Starting worker discovery
02:21:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:21:19 DISPATCHER: Finished worker discovery
02:22:19 DISPATCHER: Starting worker discovery
02:22:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:22:19 DISPATCHER: Finished worker discovery
02:23:19 DISPATCHER: Starting worker discovery
02:23:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:23:19 DISPATCHER: Finished worker discovery
02:24:11 WORKER: done with job (6, 0, 3), trying to register it.
02:24:11 WORKER: registered result for job (6, 0, 3) with dispatcher
02:24:11 DISPATCHER: job (6, 0, 3) finished
02:24:11 DISPATCHER: register_result: lock acquired
02:24:11 DISPATCHER: job (6, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
02:24:11 job_id: (6, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.06050429043885228, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.056198569941081515}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.2749642538921042, 'info': {'music_genre': 0.2749642538921042, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.06050429043885228, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.056198569941081515}"}}
exception: None

02:24:11 job_callback for (6, 0, 3) started
02:24:11 DISPATCHER: Trying to submit another job.
02:24:11 job_callback for (6, 0, 3) got condition
02:24:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:24:11 HBMASTER: Trying to run another job!
02:24:11 job_callback for (6, 0, 3) finished
02:24:11 start sampling a new configuration.
02:24:11 best_vector: [2, 0, 0.09168219312146597, 0.6109994042592283, 0.8076968649784213, 1, 0.8679945918929167, 0.7919407518670075, 0, 0, 2, 1, 0.030622322967817583, 0.7076304336087312, 0.05331062477234638, 0.3319034023248954], 0.007939054875539166, 1.1389627610819408e-05, 9.042287861425132e-08
02:24:11 done sampling a new configuration.
02:24:11 HBMASTER: schedule new run for iteration 6
02:24:11 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
02:24:11 HBMASTER: submitting job (6, 0, 4) to dispatcher
02:24:11 DISPATCHER: trying to submit job (6, 0, 4)
02:24:11 DISPATCHER: trying to notify the job_runner thread.
02:24:11 HBMASTER: job (6, 0, 4) submitted to dispatcher
02:24:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:24:11 DISPATCHER: Trying to submit another job.
02:24:11 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:24:11 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:24:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:24:11 WORKER: start processing job (6, 0, 4)
02:24:11 WORKER: args: ()
02:24:11 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.00152533201687909, 'num_filters_1': 56, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.10723552268801197, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 17, 'num_filters_3': 69, 'num_filters_4': 17, 'num_filters_5': 31}, 'budget': 400.0, 'working_directory': '.'}
02:24:19 DISPATCHER: Starting worker discovery
02:24:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:24:19 DISPATCHER: Finished worker discovery
02:25:19 DISPATCHER: Starting worker discovery
02:25:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:25:19 DISPATCHER: Finished worker discovery
02:26:19 DISPATCHER: Starting worker discovery
02:26:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:26:19 DISPATCHER: Finished worker discovery
02:27:19 DISPATCHER: Starting worker discovery
02:27:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:27:19 DISPATCHER: Finished worker discovery
02:28:19 DISPATCHER: Starting worker discovery
02:28:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:28:19 DISPATCHER: Finished worker discovery
02:29:19 DISPATCHER: Starting worker discovery
02:29:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:29:19 DISPATCHER: Finished worker discovery
02:30:19 DISPATCHER: Starting worker discovery
02:30:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:30:19 DISPATCHER: Finished worker discovery
02:31:19 DISPATCHER: Starting worker discovery
02:31:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:31:19 DISPATCHER: Finished worker discovery
02:31:48 WORKER: done with job (6, 0, 4), trying to register it.
02:31:48 WORKER: registered result for job (6, 0, 4) with dispatcher
02:31:48 DISPATCHER: job (6, 0, 4) finished
02:31:48 DISPATCHER: register_result: lock acquired
02:31:48 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
02:31:48 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.00152533201687909, 'num_filters_1': 56, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.10723552268801197, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 17, 'num_filters_3': 69, 'num_filters_4': 17, 'num_filters_5': 31}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.26831998807977275, 'info': {'music_genre': 0.26831998807977275, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.00152533201687909, 'num_filters_1': 56, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.10723552268801197, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 17, 'num_filters_3': 69, 'num_filters_4': 17, 'num_filters_5': 31}"}}
exception: None

02:31:48 job_callback for (6, 0, 4) started
02:31:48 DISPATCHER: Trying to submit another job.
02:31:48 job_callback for (6, 0, 4) got condition
02:31:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:31:48 HBMASTER: Trying to run another job!
02:31:48 job_callback for (6, 0, 4) finished
02:31:48 start sampling a new configuration.
02:31:48 best_vector: [2, 1, 0.5178444664254717, 0.8905819236334499, 0.5777746019154215, 1, 0.8732751316480325, 0.3607619137317615, 0, 1, 2, 0, 0.5919914559408119, 0.8631013615948913, 0.08632135076999514, 0.6404886936154677], 0.00039005988150463936, 0.0015659033816721936, 6.107960875027699e-07
02:31:48 done sampling a new configuration.
02:31:48 HBMASTER: schedule new run for iteration 6
02:31:48 HBMASTER: trying submitting job (6, 0, 5) to dispatcher
02:31:48 HBMASTER: submitting job (6, 0, 5) to dispatcher
02:31:48 DISPATCHER: trying to submit job (6, 0, 5)
02:31:48 DISPATCHER: trying to notify the job_runner thread.
02:31:48 HBMASTER: job (6, 0, 5) submitted to dispatcher
02:31:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:31:48 DISPATCHER: Trying to submit another job.
02:31:48 DISPATCHER: starting job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:31:48 DISPATCHER: job (6, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:31:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:31:48 WORKER: start processing job (6, 0, 5)
02:31:48 WORKER: args: ()
02:31:48 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.010856477405582144, 'num_filters_1': 102, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.029468774199619355, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 54, 'num_filters_3': 96}, 'budget': 400.0, 'working_directory': '.'}
02:32:19 DISPATCHER: Starting worker discovery
02:32:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:32:19 DISPATCHER: Finished worker discovery
02:33:19 DISPATCHER: Starting worker discovery
02:33:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:33:19 DISPATCHER: Finished worker discovery
02:34:19 DISPATCHER: Starting worker discovery
02:34:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:34:19 DISPATCHER: Finished worker discovery
02:35:19 DISPATCHER: Starting worker discovery
02:35:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:35:19 DISPATCHER: Finished worker discovery
02:36:19 DISPATCHER: Starting worker discovery
02:36:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:36:19 DISPATCHER: Finished worker discovery
02:37:19 DISPATCHER: Starting worker discovery
02:37:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:37:19 DISPATCHER: Finished worker discovery
02:38:19 DISPATCHER: Starting worker discovery
02:38:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:38:19 DISPATCHER: Finished worker discovery
02:39:19 DISPATCHER: Starting worker discovery
02:39:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:39:19 DISPATCHER: Finished worker discovery
02:39:24 WORKER: done with job (6, 0, 5), trying to register it.
02:39:24 WORKER: registered result for job (6, 0, 5) with dispatcher
02:39:24 DISPATCHER: job (6, 0, 5) finished
02:39:24 DISPATCHER: register_result: lock acquired
02:39:24 DISPATCHER: job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
02:39:24 job_id: (6, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.010856477405582144, 'num_filters_1': 102, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.029468774199619355, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 54, 'num_filters_3': 96}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.21782929781171123, 'info': {'music_genre': 0.21782929781171123, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.010856477405582144, 'num_filters_1': 102, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.029468774199619355, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 54, 'num_filters_3': 96}"}}
exception: None

02:39:24 job_callback for (6, 0, 5) started
02:39:24 job_callback for (6, 0, 5) got condition
02:39:24 DISPATCHER: Trying to submit another job.
02:39:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:39:24 HBMASTER: Trying to run another job!
02:39:24 job_callback for (6, 0, 5) finished
02:39:24 ITERATION: Advancing config (6, 0, 3) to next budget 1200.000000
02:39:24 ITERATION: Advancing config (6, 0, 4) to next budget 1200.000000
02:39:24 HBMASTER: schedule new run for iteration 6
02:39:24 HBMASTER: trying submitting job (6, 0, 3) to dispatcher
02:39:24 HBMASTER: submitting job (6, 0, 3) to dispatcher
02:39:24 DISPATCHER: trying to submit job (6, 0, 3)
02:39:24 DISPATCHER: trying to notify the job_runner thread.
02:39:24 HBMASTER: job (6, 0, 3) submitted to dispatcher
02:39:24 DISPATCHER: Trying to submit another job.
02:39:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:39:24 DISPATCHER: starting job (6, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:39:24 DISPATCHER: job (6, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
02:39:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:39:24 WORKER: start processing job (6, 0, 3)
02:39:24 WORKER: args: ()
02:39:24 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.06050429043885228, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.056198569941081515}, 'budget': 1200.0, 'working_directory': '.'}
02:40:19 DISPATCHER: Starting worker discovery
02:40:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:40:19 DISPATCHER: Finished worker discovery
02:41:19 DISPATCHER: Starting worker discovery
02:41:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:41:19 DISPATCHER: Finished worker discovery
02:42:19 DISPATCHER: Starting worker discovery
02:42:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:42:19 DISPATCHER: Finished worker discovery
02:43:19 DISPATCHER: Starting worker discovery
02:43:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:43:19 DISPATCHER: Finished worker discovery
02:44:19 DISPATCHER: Starting worker discovery
02:44:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:44:19 DISPATCHER: Finished worker discovery
02:45:19 DISPATCHER: Starting worker discovery
02:45:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:45:19 DISPATCHER: Finished worker discovery
02:46:19 DISPATCHER: Starting worker discovery
02:46:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:46:19 DISPATCHER: Finished worker discovery
02:47:19 DISPATCHER: Starting worker discovery
02:47:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:47:19 DISPATCHER: Finished worker discovery
02:48:19 DISPATCHER: Starting worker discovery
02:48:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:48:19 DISPATCHER: Finished worker discovery
02:49:19 DISPATCHER: Starting worker discovery
02:49:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:49:19 DISPATCHER: Finished worker discovery
02:50:19 DISPATCHER: Starting worker discovery
02:50:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:50:19 DISPATCHER: Finished worker discovery
02:51:19 DISPATCHER: Starting worker discovery
02:51:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:51:19 DISPATCHER: Finished worker discovery
02:52:19 DISPATCHER: Starting worker discovery
02:52:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:52:19 DISPATCHER: Finished worker discovery
02:53:19 DISPATCHER: Starting worker discovery
02:53:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:53:19 DISPATCHER: Finished worker discovery
02:54:19 DISPATCHER: Starting worker discovery
02:54:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:54:19 DISPATCHER: Finished worker discovery
02:55:19 DISPATCHER: Starting worker discovery
02:55:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:55:19 DISPATCHER: Finished worker discovery
02:56:19 DISPATCHER: Starting worker discovery
02:56:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:56:19 DISPATCHER: Finished worker discovery
02:57:19 DISPATCHER: Starting worker discovery
02:57:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:57:19 DISPATCHER: Finished worker discovery
02:58:19 DISPATCHER: Starting worker discovery
02:58:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:58:19 DISPATCHER: Finished worker discovery
02:59:19 DISPATCHER: Starting worker discovery
02:59:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:59:19 DISPATCHER: Finished worker discovery
03:00:19 DISPATCHER: Starting worker discovery
03:00:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:00:19 DISPATCHER: Finished worker discovery
03:00:35 WORKER: done with job (6, 0, 3), trying to register it.
03:00:35 WORKER: registered result for job (6, 0, 3) with dispatcher
03:00:35 DISPATCHER: job (6, 0, 3) finished
03:00:35 DISPATCHER: register_result: lock acquired
03:00:35 DISPATCHER: job (6, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
03:00:35 job_id: (6, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.06050429043885228, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.056198569941081515}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.2513144449882647, 'info': {'music_genre': 0.2513144449882647, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.06050429043885228, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.056198569941081515}"}}
exception: None

03:00:35 job_callback for (6, 0, 3) started
03:00:35 job_callback for (6, 0, 3) got condition
03:00:35 DISPATCHER: Trying to submit another job.
03:00:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:00:35 Only 11 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
03:00:35 HBMASTER: Trying to run another job!
03:00:35 job_callback for (6, 0, 3) finished
03:00:35 HBMASTER: schedule new run for iteration 6
03:00:35 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
03:00:35 HBMASTER: submitting job (6, 0, 4) to dispatcher
03:00:35 DISPATCHER: trying to submit job (6, 0, 4)
03:00:35 DISPATCHER: trying to notify the job_runner thread.
03:00:35 HBMASTER: job (6, 0, 4) submitted to dispatcher
03:00:35 DISPATCHER: Trying to submit another job.
03:00:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:00:35 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:00:35 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:00:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:00:35 WORKER: start processing job (6, 0, 4)
03:00:35 WORKER: args: ()
03:00:35 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.00152533201687909, 'num_filters_1': 56, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.10723552268801197, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 17, 'num_filters_3': 69, 'num_filters_4': 17, 'num_filters_5': 31}, 'budget': 1200.0, 'working_directory': '.'}
03:01:19 DISPATCHER: Starting worker discovery
03:01:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:01:19 DISPATCHER: Finished worker discovery
03:02:19 DISPATCHER: Starting worker discovery
03:02:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:02:19 DISPATCHER: Finished worker discovery
03:03:19 DISPATCHER: Starting worker discovery
03:03:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:03:19 DISPATCHER: Finished worker discovery
03:04:19 DISPATCHER: Starting worker discovery
03:04:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:04:19 DISPATCHER: Finished worker discovery
03:05:19 DISPATCHER: Starting worker discovery
03:05:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:05:19 DISPATCHER: Finished worker discovery
03:06:19 DISPATCHER: Starting worker discovery
03:06:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:06:19 DISPATCHER: Finished worker discovery
03:07:19 DISPATCHER: Starting worker discovery
03:07:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:07:19 DISPATCHER: Finished worker discovery
03:08:19 DISPATCHER: Starting worker discovery
03:08:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:08:20 DISPATCHER: Finished worker discovery
03:09:20 DISPATCHER: Starting worker discovery
03:09:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:09:20 DISPATCHER: Finished worker discovery
03:10:20 DISPATCHER: Starting worker discovery
03:10:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:10:20 DISPATCHER: Finished worker discovery
03:11:20 DISPATCHER: Starting worker discovery
03:11:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:11:20 DISPATCHER: Finished worker discovery
03:12:20 DISPATCHER: Starting worker discovery
03:12:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:12:20 DISPATCHER: Finished worker discovery
03:13:20 DISPATCHER: Starting worker discovery
03:13:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:13:20 DISPATCHER: Finished worker discovery
03:14:20 DISPATCHER: Starting worker discovery
03:14:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:14:20 DISPATCHER: Finished worker discovery
03:15:20 DISPATCHER: Starting worker discovery
03:15:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:15:20 DISPATCHER: Finished worker discovery
03:16:20 DISPATCHER: Starting worker discovery
03:16:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:16:20 DISPATCHER: Finished worker discovery
03:17:20 DISPATCHER: Starting worker discovery
03:17:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:17:20 DISPATCHER: Finished worker discovery
03:18:20 DISPATCHER: Starting worker discovery
03:18:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:18:20 DISPATCHER: Finished worker discovery
03:19:20 DISPATCHER: Starting worker discovery
03:19:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:19:20 DISPATCHER: Finished worker discovery
03:20:20 DISPATCHER: Starting worker discovery
03:20:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:20:20 DISPATCHER: Finished worker discovery
03:21:20 DISPATCHER: Starting worker discovery
03:21:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:21:20 DISPATCHER: Finished worker discovery
03:21:37 WORKER: done with job (6, 0, 4), trying to register it.
03:21:37 WORKER: registered result for job (6, 0, 4) with dispatcher
03:21:37 DISPATCHER: job (6, 0, 4) finished
03:21:37 DISPATCHER: register_result: lock acquired
03:21:37 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
03:21:37 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.00152533201687909, 'num_filters_1': 56, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.10723552268801197, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 17, 'num_filters_3': 69, 'num_filters_4': 17, 'num_filters_5': 31}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.24834716432091358, 'info': {'music_genre': 0.24834716432091358, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.00152533201687909, 'num_filters_1': 56, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.10723552268801197, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 17, 'num_filters_3': 69, 'num_filters_4': 17, 'num_filters_5': 31}"}}
exception: None

03:21:37 job_callback for (6, 0, 4) started
03:21:37 DISPATCHER: Trying to submit another job.
03:21:37 job_callback for (6, 0, 4) got condition
03:21:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:21:37 Only 12 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
03:21:37 HBMASTER: Trying to run another job!
03:21:37 job_callback for (6, 0, 4) finished
03:21:37 start sampling a new configuration.
03:21:37 best_vector: [2, 1, 0.44752779583731295, 0.7850313974438763, 0.4181996480473416, 1, 0.09051960987433941, 0.024908909482789985, 0, 0, 1, 2, 0.8466468879839695, 0.5939172924930858, 0.019629522438373903, 0.037702500109559056], 0.00014263240837560705, 9.424184661379259e-05, 1.3441941552289786e-08
03:21:37 done sampling a new configuration.
03:21:37 HBMASTER: schedule new run for iteration 7
03:21:37 HBMASTER: trying submitting job (7, 0, 0) to dispatcher
03:21:37 HBMASTER: submitting job (7, 0, 0) to dispatcher
03:21:37 DISPATCHER: trying to submit job (7, 0, 0)
03:21:37 DISPATCHER: trying to notify the job_runner thread.
03:21:37 HBMASTER: job (7, 0, 0) submitted to dispatcher
03:21:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:21:37 DISPATCHER: Trying to submit another job.
03:21:37 DISPATCHER: starting job (7, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:21:37 DISPATCHER: job (7, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:21:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:21:37 WORKER: start processing job (7, 0, 0)
03:21:37 WORKER: args: ()
03:21:37 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.007853361547863718, 'num_filters_1': 82, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.010774750896094832, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 93, 'num_filters_3': 54}, 'budget': 1200.0, 'working_directory': '.'}
03:22:20 DISPATCHER: Starting worker discovery
03:22:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:22:20 DISPATCHER: Finished worker discovery
03:23:20 DISPATCHER: Starting worker discovery
03:23:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:23:20 DISPATCHER: Finished worker discovery
03:24:20 DISPATCHER: Starting worker discovery
03:24:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:24:20 DISPATCHER: Finished worker discovery
03:25:20 DISPATCHER: Starting worker discovery
03:25:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:25:20 DISPATCHER: Finished worker discovery
03:26:20 DISPATCHER: Starting worker discovery
03:26:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:26:20 DISPATCHER: Finished worker discovery
03:27:20 DISPATCHER: Starting worker discovery
03:27:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:27:20 DISPATCHER: Finished worker discovery
03:28:20 DISPATCHER: Starting worker discovery
03:28:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:28:20 DISPATCHER: Finished worker discovery
03:29:20 DISPATCHER: Starting worker discovery
03:29:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:29:20 DISPATCHER: Finished worker discovery
03:30:20 DISPATCHER: Starting worker discovery
03:30:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:30:20 DISPATCHER: Finished worker discovery
03:31:20 DISPATCHER: Starting worker discovery
03:31:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:31:20 DISPATCHER: Finished worker discovery
03:32:20 DISPATCHER: Starting worker discovery
03:32:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:32:20 DISPATCHER: Finished worker discovery
03:33:20 DISPATCHER: Starting worker discovery
03:33:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:33:20 DISPATCHER: Finished worker discovery
03:34:20 DISPATCHER: Starting worker discovery
03:34:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:34:20 DISPATCHER: Finished worker discovery
03:35:20 DISPATCHER: Starting worker discovery
03:35:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:35:20 DISPATCHER: Finished worker discovery
03:36:20 DISPATCHER: Starting worker discovery
03:36:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:36:20 DISPATCHER: Finished worker discovery
03:37:20 DISPATCHER: Starting worker discovery
03:37:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:37:20 DISPATCHER: Finished worker discovery
03:38:20 DISPATCHER: Starting worker discovery
03:38:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:38:20 DISPATCHER: Finished worker discovery
03:39:20 DISPATCHER: Starting worker discovery
03:39:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:39:20 DISPATCHER: Finished worker discovery
03:40:20 DISPATCHER: Starting worker discovery
03:40:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:40:20 DISPATCHER: Finished worker discovery
03:41:20 DISPATCHER: Starting worker discovery
03:41:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:41:20 DISPATCHER: Finished worker discovery
03:42:20 DISPATCHER: Starting worker discovery
03:42:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:42:20 DISPATCHER: Finished worker discovery
03:42:52 WORKER: done with job (7, 0, 0), trying to register it.
03:42:52 WORKER: registered result for job (7, 0, 0) with dispatcher
03:42:52 DISPATCHER: job (7, 0, 0) finished
03:42:52 DISPATCHER: register_result: lock acquired
03:42:52 DISPATCHER: job (7, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
03:42:52 job_id: (7, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.007853361547863718, 'num_filters_1': 82, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.010774750896094832, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 93, 'num_filters_3': 54}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.2983403559061092, 'info': {'music_genre': 0.2983403559061092, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.007853361547863718, 'num_filters_1': 82, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.010774750896094832, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 93, 'num_filters_3': 54}"}}
exception: None

03:42:52 job_callback for (7, 0, 0) started
03:42:52 DISPATCHER: Trying to submit another job.
03:42:52 job_callback for (7, 0, 0) got condition
03:42:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:42:52 Only 13 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
03:42:52 HBMASTER: Trying to run another job!
03:42:52 job_callback for (7, 0, 0) finished
03:42:52 start sampling a new configuration.
03:42:52 best_vector: [0, 0, 0.08922580315111159, 0.9502164276876695, 0.7566018033109938, 1, 0.8903754952728312, 0.17408490316743608, 0, 2, 2, 0, 0.7093656125850649, 0.756394215051942, 0.024587862162253463, 0.21055492305757734], 1.1231598326705133e-05, 0.0008341165518253291, 9.368462067758422e-09
03:42:52 done sampling a new configuration.
03:42:52 HBMASTER: schedule new run for iteration 7
03:42:52 HBMASTER: trying submitting job (7, 0, 1) to dispatcher
03:42:52 HBMASTER: submitting job (7, 0, 1) to dispatcher
03:42:52 DISPATCHER: trying to submit job (7, 0, 1)
03:42:52 DISPATCHER: trying to notify the job_runner thread.
03:42:52 HBMASTER: job (7, 0, 1) submitted to dispatcher
03:42:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:42:52 DISPATCHER: Trying to submit another job.
03:42:52 DISPATCHER: starting job (7, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:42:52 DISPATCHER: job (7, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
03:42:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:42:52 WORKER: start processing job (7, 0, 1)
03:42:52 WORKER: args: ()
03:42:52 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0015081745443717117, 'num_filters_1': 116, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.016845723995006338, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 69, 'num_filters_3': 77, 'num_filters_4': 16}, 'budget': 1200.0, 'working_directory': '.'}
03:43:20 DISPATCHER: Starting worker discovery
03:43:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:43:20 DISPATCHER: Finished worker discovery
03:44:20 DISPATCHER: Starting worker discovery
03:44:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:44:20 DISPATCHER: Finished worker discovery
03:45:20 DISPATCHER: Starting worker discovery
03:45:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:45:20 DISPATCHER: Finished worker discovery
03:46:20 DISPATCHER: Starting worker discovery
03:46:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:46:20 DISPATCHER: Finished worker discovery
03:47:20 DISPATCHER: Starting worker discovery
03:47:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:47:20 DISPATCHER: Finished worker discovery
03:48:20 DISPATCHER: Starting worker discovery
03:48:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:48:20 DISPATCHER: Finished worker discovery
03:49:20 DISPATCHER: Starting worker discovery
03:49:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:49:20 DISPATCHER: Finished worker discovery
03:50:20 DISPATCHER: Starting worker discovery
03:50:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:50:20 DISPATCHER: Finished worker discovery
03:51:20 DISPATCHER: Starting worker discovery
03:51:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:51:20 DISPATCHER: Finished worker discovery
03:52:20 DISPATCHER: Starting worker discovery
03:52:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:52:20 DISPATCHER: Finished worker discovery
03:53:20 DISPATCHER: Starting worker discovery
03:53:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:53:20 DISPATCHER: Finished worker discovery
03:54:20 DISPATCHER: Starting worker discovery
03:54:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:54:20 DISPATCHER: Finished worker discovery
03:55:20 DISPATCHER: Starting worker discovery
03:55:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:55:20 DISPATCHER: Finished worker discovery
03:56:20 DISPATCHER: Starting worker discovery
03:56:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:56:20 DISPATCHER: Finished worker discovery
03:57:20 DISPATCHER: Starting worker discovery
03:57:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:57:20 DISPATCHER: Finished worker discovery
03:58:20 DISPATCHER: Starting worker discovery
03:58:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:58:20 DISPATCHER: Finished worker discovery
03:59:20 DISPATCHER: Starting worker discovery
03:59:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:59:20 DISPATCHER: Finished worker discovery
04:00:20 DISPATCHER: Starting worker discovery
04:00:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:00:20 DISPATCHER: Finished worker discovery
04:01:20 DISPATCHER: Starting worker discovery
04:01:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:01:20 DISPATCHER: Finished worker discovery
04:02:20 DISPATCHER: Starting worker discovery
04:02:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:02:20 DISPATCHER: Finished worker discovery
04:03:20 DISPATCHER: Starting worker discovery
04:03:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:03:20 DISPATCHER: Finished worker discovery
04:03:55 WORKER: done with job (7, 0, 1), trying to register it.
04:03:55 WORKER: registered result for job (7, 0, 1) with dispatcher
04:03:55 DISPATCHER: job (7, 0, 1) finished
04:03:55 DISPATCHER: register_result: lock acquired
04:03:55 DISPATCHER: job (7, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
04:03:55 job_id: (7, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0015081745443717117, 'num_filters_1': 116, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.016845723995006338, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 69, 'num_filters_3': 77, 'num_filters_4': 16}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.32940261332848036, 'info': {'music_genre': 0.32940261332848036, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0015081745443717117, 'num_filters_1': 116, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.016845723995006338, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 69, 'num_filters_3': 77, 'num_filters_4': 16}"}}
exception: None

04:03:55 job_callback for (7, 0, 1) started
04:03:55 DISPATCHER: Trying to submit another job.
04:03:55 job_callback for (7, 0, 1) got condition
04:03:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:03:55 Only 14 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
04:03:55 HBMASTER: Trying to run another job!
04:03:55 job_callback for (7, 0, 1) finished
04:03:55 start sampling a new configuration.
04:03:55 best_vector: [0, 0, 0.1853233850964172, 0.947224192175128, 0.25589926334083457, 1, 0.3835718935989908, 0.33275150124261926, 1, 2, 1, 1, 0.4210228866522975, 0.8983312996501709, 0.015552259323625806, 0.43451437218176975], 4.6643171365386407e-05, 0.0017110432476070915, 7.980848341172485e-08
04:03:55 done sampling a new configuration.
04:03:55 HBMASTER: schedule new run for iteration 7
04:03:55 HBMASTER: trying submitting job (7, 0, 2) to dispatcher
04:03:55 HBMASTER: submitting job (7, 0, 2) to dispatcher
04:03:55 DISPATCHER: trying to submit job (7, 0, 2)
04:03:55 DISPATCHER: trying to notify the job_runner thread.
04:03:55 HBMASTER: job (7, 0, 2) submitted to dispatcher
04:03:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:03:55 DISPATCHER: Trying to submit another job.
04:03:55 DISPATCHER: starting job (7, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:03:55 DISPATCHER: job (7, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:03:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:03:55 WORKER: start processing job (7, 0, 2)
04:03:55 WORKER: args: ()
04:03:55 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0023477225434821412, 'num_filters_1': 115, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.027096904718695858, 'kernel_size_2': 5, 'num_filters_2': 38}, 'budget': 1200.0, 'working_directory': '.'}
04:04:20 DISPATCHER: Starting worker discovery
04:04:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:04:20 DISPATCHER: Finished worker discovery
04:05:20 DISPATCHER: Starting worker discovery
04:05:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:05:20 DISPATCHER: Finished worker discovery
04:06:20 DISPATCHER: Starting worker discovery
04:06:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:06:20 DISPATCHER: Finished worker discovery
04:07:20 DISPATCHER: Starting worker discovery
04:07:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:07:20 DISPATCHER: Finished worker discovery
04:08:20 DISPATCHER: Starting worker discovery
04:08:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:08:20 DISPATCHER: Finished worker discovery
04:09:20 DISPATCHER: Starting worker discovery
04:09:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:09:20 DISPATCHER: Finished worker discovery
04:10:20 DISPATCHER: Starting worker discovery
04:10:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:10:20 DISPATCHER: Finished worker discovery
04:11:20 DISPATCHER: Starting worker discovery
04:11:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:11:20 DISPATCHER: Finished worker discovery
04:12:20 DISPATCHER: Starting worker discovery
04:12:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:12:20 DISPATCHER: Finished worker discovery
04:13:20 DISPATCHER: Starting worker discovery
04:13:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:13:20 DISPATCHER: Finished worker discovery
04:14:20 DISPATCHER: Starting worker discovery
04:14:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:14:20 DISPATCHER: Finished worker discovery
04:15:20 DISPATCHER: Starting worker discovery
04:15:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:15:20 DISPATCHER: Finished worker discovery
04:16:20 DISPATCHER: Starting worker discovery
04:16:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:16:20 DISPATCHER: Finished worker discovery
04:17:20 DISPATCHER: Starting worker discovery
04:17:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:17:20 DISPATCHER: Finished worker discovery
04:18:20 DISPATCHER: Starting worker discovery
04:18:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:18:21 DISPATCHER: Finished worker discovery
04:19:21 DISPATCHER: Starting worker discovery
04:19:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:19:21 DISPATCHER: Finished worker discovery
04:20:21 DISPATCHER: Starting worker discovery
04:20:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:20:21 DISPATCHER: Finished worker discovery
04:21:21 DISPATCHER: Starting worker discovery
04:21:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:21:21 DISPATCHER: Finished worker discovery
04:22:21 DISPATCHER: Starting worker discovery
04:22:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:22:21 DISPATCHER: Finished worker discovery
04:23:21 DISPATCHER: Starting worker discovery
04:23:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:23:21 DISPATCHER: Finished worker discovery
04:24:21 DISPATCHER: Starting worker discovery
04:24:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:24:21 DISPATCHER: Finished worker discovery
04:25:07 WORKER: done with job (7, 0, 2), trying to register it.
04:25:07 WORKER: registered result for job (7, 0, 2) with dispatcher
04:25:07 DISPATCHER: job (7, 0, 2) finished
04:25:07 DISPATCHER: register_result: lock acquired
04:25:07 DISPATCHER: job (7, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
04:25:07 job_id: (7, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0023477225434821412, 'num_filters_1': 115, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.027096904718695858, 'kernel_size_2': 5, 'num_filters_2': 38}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.2712846314500008, 'info': {'music_genre': 0.2712846314500008, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0023477225434821412, 'num_filters_1': 115, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.027096904718695858, 'kernel_size_2': 5, 'num_filters_2': 38}"}}
exception: None

04:25:07 job_callback for (7, 0, 2) started
04:25:07 job_callback for (7, 0, 2) got condition
04:25:07 DISPATCHER: Trying to submit another job.
04:25:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:25:07 Only 15 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
04:25:07 HBMASTER: Trying to run another job!
04:25:07 job_callback for (7, 0, 2) finished
04:25:07 start sampling a new configuration.
04:25:07 best_vector: [2, 2, 0.2546289310228523, 0.2835250935786377, 0.8798579307583938, 1, 0.0740438033806402, 0.7621243630290478, 1, 1, 0, 0, 0.981947541208784, 0.8544275401294391, 0.024801630359709323, 0.5763277394088746], 0.0001189561616932943, 6.304269064107079e-05, 7.499316501479548e-09
04:25:07 done sampling a new configuration.
04:25:07 HBMASTER: schedule new run for iteration 7
04:25:07 HBMASTER: trying submitting job (7, 0, 3) to dispatcher
04:25:07 HBMASTER: submitting job (7, 0, 3) to dispatcher
04:25:07 DISPATCHER: trying to submit job (7, 0, 3)
04:25:07 DISPATCHER: trying to notify the job_runner thread.
04:25:07 HBMASTER: job (7, 0, 3) submitted to dispatcher
04:25:07 DISPATCHER: Trying to submit another job.
04:25:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:25:07 DISPATCHER: starting job (7, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:25:07 DISPATCHER: job (7, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:25:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:25:07 WORKER: start processing job (7, 0, 3)
04:25:07 WORKER: args: ()
04:25:07 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0032304116070419474, 'num_filters_1': 28, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.09807236688698394, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 124, 'num_filters_3': 94, 'num_filters_4': 16, 'num_filters_5': 52}, 'budget': 1200.0, 'working_directory': '.'}
04:25:21 DISPATCHER: Starting worker discovery
04:25:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:25:21 DISPATCHER: Finished worker discovery
04:26:21 DISPATCHER: Starting worker discovery
04:26:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:26:21 DISPATCHER: Finished worker discovery
04:27:21 DISPATCHER: Starting worker discovery
04:27:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:27:21 DISPATCHER: Finished worker discovery
04:28:21 DISPATCHER: Starting worker discovery
04:28:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:28:21 DISPATCHER: Finished worker discovery
04:29:21 DISPATCHER: Starting worker discovery
04:29:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:29:21 DISPATCHER: Finished worker discovery
04:30:21 DISPATCHER: Starting worker discovery
04:30:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:30:21 DISPATCHER: Finished worker discovery
04:31:21 DISPATCHER: Starting worker discovery
04:31:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:31:21 DISPATCHER: Finished worker discovery
04:32:21 DISPATCHER: Starting worker discovery
04:32:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:32:21 DISPATCHER: Finished worker discovery
04:33:21 DISPATCHER: Starting worker discovery
04:33:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:33:21 DISPATCHER: Finished worker discovery
04:34:21 DISPATCHER: Starting worker discovery
04:34:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:34:21 DISPATCHER: Finished worker discovery
04:35:21 DISPATCHER: Starting worker discovery
04:35:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:35:21 DISPATCHER: Finished worker discovery
04:36:21 DISPATCHER: Starting worker discovery
04:36:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:36:21 DISPATCHER: Finished worker discovery
04:37:21 DISPATCHER: Starting worker discovery
04:37:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:37:21 DISPATCHER: Finished worker discovery
04:38:21 DISPATCHER: Starting worker discovery
04:38:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:38:21 DISPATCHER: Finished worker discovery
04:39:21 DISPATCHER: Starting worker discovery
04:39:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:39:21 DISPATCHER: Finished worker discovery
04:40:21 DISPATCHER: Starting worker discovery
04:40:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:40:21 DISPATCHER: Finished worker discovery
04:41:21 DISPATCHER: Starting worker discovery
04:41:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:41:21 DISPATCHER: Finished worker discovery
04:42:21 DISPATCHER: Starting worker discovery
04:42:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:42:21 DISPATCHER: Finished worker discovery
04:43:21 DISPATCHER: Starting worker discovery
04:43:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:43:21 DISPATCHER: Finished worker discovery
04:44:21 DISPATCHER: Starting worker discovery
04:44:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:44:21 DISPATCHER: Finished worker discovery
04:45:21 DISPATCHER: Starting worker discovery
04:45:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:45:21 DISPATCHER: Finished worker discovery
04:46:16 WORKER: done with job (7, 0, 3), trying to register it.
04:46:16 WORKER: registered result for job (7, 0, 3) with dispatcher
04:46:16 DISPATCHER: job (7, 0, 3) finished
04:46:16 DISPATCHER: register_result: lock acquired
04:46:16 DISPATCHER: job (7, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
04:46:16 job_id: (7, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0032304116070419474, 'num_filters_1': 28, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.09807236688698394, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 124, 'num_filters_3': 94, 'num_filters_4': 16, 'num_filters_5': 52}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.0973308145073174, 'info': {'music_genre': 0.0973308145073174, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0032304116070419474, 'num_filters_1': 28, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.09807236688698394, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 124, 'num_filters_3': 94, 'num_filters_4': 16, 'num_filters_5': 52}"}}
exception: None

04:46:16 job_callback for (7, 0, 3) started
04:46:16 job_callback for (7, 0, 3) got condition
04:46:16 DISPATCHER: Trying to submit another job.
04:46:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:46:16 Only 16 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
04:46:16 HBMASTER: Trying to run another job!
04:46:16 job_callback for (7, 0, 3) finished
04:46:16 start sampling a new configuration.
04:46:16 best_vector: [0, 0, 0.07407050837815135, 0.8673305086419361, 0.7610423273252177, 1, 0.5330197252862245, 0.17044062563173468, 1, 2, 0, 2, 0.7173590903814759, 0.5532522018984241, 0.05239622288118795, 0.1158780775036542], 0.0001445271299495901, 0.0005782924665421955, 8.357895046081288e-08
04:46:16 done sampling a new configuration.
04:46:16 HBMASTER: schedule new run for iteration 8
04:46:16 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
04:46:16 HBMASTER: submitting job (8, 0, 0) to dispatcher
04:46:16 DISPATCHER: trying to submit job (8, 0, 0)
04:46:16 DISPATCHER: trying to notify the job_runner thread.
04:46:16 HBMASTER: job (8, 0, 0) submitted to dispatcher
04:46:16 DISPATCHER: Trying to submit another job.
04:46:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:46:16 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:46:16 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:46:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:46:16 WORKER: start processing job (8, 0, 0)
04:46:16 WORKER: args: ()
04:46:16 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0014065041462222143, 'num_filters_1': 97, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.016662814764578603, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 71, 'num_filters_3': 50, 'num_filters_4': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:46:21 DISPATCHER: Starting worker discovery
04:46:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:46:21 DISPATCHER: Finished worker discovery
04:47:21 DISPATCHER: Starting worker discovery
04:47:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:47:21 DISPATCHER: Finished worker discovery
04:47:54 WORKER: done with job (8, 0, 0), trying to register it.
04:47:54 WORKER: registered result for job (8, 0, 0) with dispatcher
04:47:54 DISPATCHER: job (8, 0, 0) finished
04:47:54 DISPATCHER: register_result: lock acquired
04:47:54 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
04:47:54 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0014065041462222143, 'num_filters_1': 97, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.016662814764578603, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 71, 'num_filters_3': 50, 'num_filters_4': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4556183062493564, 'info': {'music_genre': 0.4556183062493564, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0014065041462222143, 'num_filters_1': 97, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.016662814764578603, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 71, 'num_filters_3': 50, 'num_filters_4': 17}"}}
exception: None

04:47:54 job_callback for (8, 0, 0) started
04:47:54 job_callback for (8, 0, 0) got condition
04:47:54 DISPATCHER: Trying to submit another job.
04:47:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:47:54 HBMASTER: Trying to run another job!
04:47:54 job_callback for (8, 0, 0) finished
04:47:54 start sampling a new configuration.
04:47:54 done sampling a new configuration.
04:47:54 HBMASTER: schedule new run for iteration 8
04:47:54 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
04:47:54 HBMASTER: submitting job (8, 0, 1) to dispatcher
04:47:54 DISPATCHER: trying to submit job (8, 0, 1)
04:47:54 DISPATCHER: trying to notify the job_runner thread.
04:47:54 HBMASTER: job (8, 0, 1) submitted to dispatcher
04:47:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:47:54 DISPATCHER: Trying to submit another job.
04:47:54 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:47:54 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:47:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:47:54 WORKER: start processing job (8, 0, 1)
04:47:54 WORKER: args: ()
04:47:54 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0018631442655392232, 'num_filters_1': 115, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.010367178689878544, 'kernel_size_2': 5, 'num_filters_2': 96}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:48:21 DISPATCHER: Starting worker discovery
04:48:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:48:21 DISPATCHER: Finished worker discovery
04:49:21 DISPATCHER: Starting worker discovery
04:49:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:49:21 DISPATCHER: Finished worker discovery
04:49:32 WORKER: done with job (8, 0, 1), trying to register it.
04:49:32 WORKER: registered result for job (8, 0, 1) with dispatcher
04:49:32 DISPATCHER: job (8, 0, 1) finished
04:49:32 DISPATCHER: register_result: lock acquired
04:49:32 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
04:49:32 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0018631442655392232, 'num_filters_1': 115, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.010367178689878544, 'kernel_size_2': 5, 'num_filters_2': 96}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2563498656109854, 'info': {'music_genre': 0.2563498656109854, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0018631442655392232, 'num_filters_1': 115, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.010367178689878544, 'kernel_size_2': 5, 'num_filters_2': 96}"}}
exception: None

04:49:32 job_callback for (8, 0, 1) started
04:49:32 DISPATCHER: Trying to submit another job.
04:49:32 job_callback for (8, 0, 1) got condition
04:49:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:49:32 HBMASTER: Trying to run another job!
04:49:32 job_callback for (8, 0, 1) finished
04:49:32 start sampling a new configuration.
04:49:33 best_vector: [2, 1, 0.8257640029072564, 0.7666162447613534, 0.13587830134079826, 1, 0.28471079386601605, 0.46653035178146707, 1, 2, 1, 0, 0.5444899493399935, 0.7777731401878789, 0.05773428120113344, 0.6445477899600724], 0.0021346872868541872, 3.800529791680105e-05, 8.112942629610113e-08
04:49:33 done sampling a new configuration.
04:49:33 HBMASTER: schedule new run for iteration 8
04:49:33 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
04:49:33 HBMASTER: submitting job (8, 0, 2) to dispatcher
04:49:33 DISPATCHER: trying to submit job (8, 0, 2)
04:49:33 DISPATCHER: trying to notify the job_runner thread.
04:49:33 HBMASTER: job (8, 0, 2) submitted to dispatcher
04:49:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:49:33 DISPATCHER: Trying to submit another job.
04:49:33 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:49:33 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:49:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:49:33 WORKER: start processing job (8, 0, 2)
04:49:33 WORKER: args: ()
04:49:33 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.04482579553244818, 'num_filters_1': 78, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.040454792836886744}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:50:21 DISPATCHER: Starting worker discovery
04:50:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:50:21 DISPATCHER: Finished worker discovery
04:51:11 WORKER: done with job (8, 0, 2), trying to register it.
04:51:11 WORKER: registered result for job (8, 0, 2) with dispatcher
04:51:11 DISPATCHER: job (8, 0, 2) finished
04:51:11 DISPATCHER: register_result: lock acquired
04:51:11 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
04:51:11 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.04482579553244818, 'num_filters_1': 78, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.040454792836886744}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.25712062227135024, 'info': {'music_genre': 0.25712062227135024, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.04482579553244818, 'num_filters_1': 78, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.040454792836886744}"}}
exception: None

04:51:11 job_callback for (8, 0, 2) started
04:51:11 job_callback for (8, 0, 2) got condition
04:51:11 DISPATCHER: Trying to submit another job.
04:51:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:51:11 HBMASTER: Trying to run another job!
04:51:11 job_callback for (8, 0, 2) finished
04:51:11 start sampling a new configuration.
04:51:11 best_vector: [0, 1, 0.5621472430667213, 0.6250957269969384, 0.8137915900416545, 1, 0.41707941781462693, 0.9531290077532962, 0, 2, 0, 0, 0.8716584710394669, 0.7688574403128325, 0.0456333573330398, 0.7383542590242845], 0.0006509823487344125, 3.2003454810537774e-05, 2.083368418017951e-08
04:51:11 done sampling a new configuration.
04:51:11 HBMASTER: schedule new run for iteration 8
04:51:11 HBMASTER: trying submitting job (8, 0, 3) to dispatcher
04:51:11 HBMASTER: submitting job (8, 0, 3) to dispatcher
04:51:11 DISPATCHER: trying to submit job (8, 0, 3)
04:51:11 DISPATCHER: trying to notify the job_runner thread.
04:51:11 HBMASTER: job (8, 0, 3) submitted to dispatcher
04:51:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:51:11 DISPATCHER: Trying to submit another job.
04:51:11 DISPATCHER: starting job (8, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:51:11 DISPATCHER: job (8, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:51:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:51:11 WORKER: start processing job (8, 0, 3)
04:51:11 WORKER: args: ()
04:51:11 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.01331356877621287, 'num_filters_1': 58, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.17379986261980873, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 98, 'num_filters_3': 79, 'num_filters_4': 17, 'num_filters_5': 74}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:51:21 DISPATCHER: Starting worker discovery
04:51:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:51:21 DISPATCHER: Finished worker discovery
04:52:21 DISPATCHER: Starting worker discovery
04:52:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:52:21 DISPATCHER: Finished worker discovery
04:52:51 WORKER: done with job (8, 0, 3), trying to register it.
04:52:51 WORKER: registered result for job (8, 0, 3) with dispatcher
04:52:51 DISPATCHER: job (8, 0, 3) finished
04:52:51 DISPATCHER: register_result: lock acquired
04:52:51 DISPATCHER: job (8, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
04:52:51 job_id: (8, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.01331356877621287, 'num_filters_1': 58, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.17379986261980873, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 98, 'num_filters_3': 79, 'num_filters_4': 17, 'num_filters_5': 74}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.007333331973509679, 'info': {'music_genre': 0.007333331973509679, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.01331356877621287, 'num_filters_1': 58, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.17379986261980873, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 98, 'num_filters_3': 79, 'num_filters_4': 17, 'num_filters_5': 74}"}}
exception: None

04:52:51 job_callback for (8, 0, 3) started
04:52:51 DISPATCHER: Trying to submit another job.
04:52:51 job_callback for (8, 0, 3) got condition
04:52:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:52:51 HBMASTER: Trying to run another job!
04:52:51 job_callback for (8, 0, 3) finished
04:52:51 start sampling a new configuration.
04:52:51 best_vector: [3, 2, 0.2781669412471857, 0.5197017913773967, 0.12991279323883553, 1, 0.3575663340632962, 0.016030708576267372, 0, 0, 1, 0, 0.460760293217335, 0.5627249827543582, 0.011850851769828807, 0.903847731557574], 0.00033269751946933307, 9.707056332934932e-05, 3.2295135633165326e-08
04:52:51 done sampling a new configuration.
04:52:51 HBMASTER: schedule new run for iteration 8
04:52:51 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
04:52:51 HBMASTER: submitting job (8, 0, 4) to dispatcher
04:52:51 DISPATCHER: trying to submit job (8, 0, 4)
04:52:51 DISPATCHER: trying to notify the job_runner thread.
04:52:51 HBMASTER: job (8, 0, 4) submitted to dispatcher
04:52:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:52:51 DISPATCHER: Trying to submit another job.
04:52:51 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:52:51 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:52:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:52:51 WORKER: start processing job (8, 0, 4)
04:52:51 WORKER: args: ()
04:52:51 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0036002601421478223, 'num_filters_1': 47, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.010491955325571258}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:53:21 DISPATCHER: Starting worker discovery
04:53:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:53:21 DISPATCHER: Finished worker discovery
04:54:21 DISPATCHER: Starting worker discovery
04:54:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:54:21 DISPATCHER: Finished worker discovery
04:54:30 WORKER: done with job (8, 0, 4), trying to register it.
04:54:30 WORKER: registered result for job (8, 0, 4) with dispatcher
04:54:30 DISPATCHER: job (8, 0, 4) finished
04:54:30 DISPATCHER: register_result: lock acquired
04:54:30 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
04:54:30 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0036002601421478223, 'num_filters_1': 47, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.010491955325571258}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4347898299740796, 'info': {'music_genre': 0.4347898299740796, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0036002601421478223, 'num_filters_1': 47, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.010491955325571258}"}}
exception: None

04:54:30 job_callback for (8, 0, 4) started
04:54:30 job_callback for (8, 0, 4) got condition
04:54:30 DISPATCHER: Trying to submit another job.
04:54:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:54:30 HBMASTER: Trying to run another job!
04:54:30 job_callback for (8, 0, 4) finished
04:54:30 start sampling a new configuration.
04:54:30 best_vector: [2, 1, 0.18373989370915336, 0.9423739703874184, 0.9990720672267736, 1, 0.9704177335998174, 0.8807574711404946, 2, 2, 1, 0, 0.21937295752920838, 0.790203115391289, 0.04120923903948126, 0.7238745265163482], 1.9118621766999573e-05, 2.569142525739605e-05, 4.911846421512948e-10
04:54:30 done sampling a new configuration.
04:54:30 HBMASTER: schedule new run for iteration 8
04:54:30 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
04:54:30 HBMASTER: submitting job (8, 0, 5) to dispatcher
04:54:30 DISPATCHER: trying to submit job (8, 0, 5)
04:54:30 DISPATCHER: trying to notify the job_runner thread.
04:54:30 HBMASTER: job (8, 0, 5) submitted to dispatcher
04:54:30 DISPATCHER: Trying to submit another job.
04:54:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:54:30 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:54:30 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:54:30 WORKER: start processing job (8, 0, 5)
04:54:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:54:30 WORKER: args: ()
04:54:30 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0023306646408541533, 'num_filters_1': 114, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.1399238959521692, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 25, 'num_filters_3': 82, 'num_filters_4': 17, 'num_filters_5': 72}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:55:21 DISPATCHER: Starting worker discovery
04:55:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:55:21 DISPATCHER: Finished worker discovery
04:56:08 WORKER: done with job (8, 0, 5), trying to register it.
04:56:08 WORKER: registered result for job (8, 0, 5) with dispatcher
04:56:08 DISPATCHER: job (8, 0, 5) finished
04:56:08 DISPATCHER: register_result: lock acquired
04:56:08 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
04:56:08 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0023306646408541533, 'num_filters_1': 114, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.1399238959521692, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 25, 'num_filters_3': 82, 'num_filters_4': 17, 'num_filters_5': 72}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4463743579289909, 'info': {'music_genre': 0.4463743579289909, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0023306646408541533, 'num_filters_1': 114, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.1399238959521692, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 25, 'num_filters_3': 82, 'num_filters_4': 17, 'num_filters_5': 72}"}}
exception: None

04:56:08 job_callback for (8, 0, 5) started
04:56:08 job_callback for (8, 0, 5) got condition
04:56:08 DISPATCHER: Trying to submit another job.
04:56:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:56:08 HBMASTER: Trying to run another job!
04:56:08 job_callback for (8, 0, 5) finished
04:56:08 start sampling a new configuration.
04:56:08 best_vector: [2, 0, 0.10849583831849838, 0.4467551842457902, 0.6509703943551935, 1, 0.48778976421834525, 0.5880713616886128, 1, 2, 2, 1, 0.7256016517134315, 0.8249370528515352, 0.06843011757610487, 0.6203194020856426], 0.001665977835456108, 0.002346640171417838, 3.90945051337304e-06
04:56:08 done sampling a new configuration.
04:56:08 HBMASTER: schedule new run for iteration 8
04:56:08 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
04:56:08 HBMASTER: submitting job (8, 0, 6) to dispatcher
04:56:08 DISPATCHER: trying to submit job (8, 0, 6)
04:56:08 DISPATCHER: trying to notify the job_runner thread.
04:56:08 HBMASTER: job (8, 0, 6) submitted to dispatcher
04:56:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:56:08 DISPATCHER: Trying to submit another job.
04:56:08 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:56:08 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:56:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:56:08 WORKER: start processing job (8, 0, 6)
04:56:08 WORKER: args: ()
04:56:08 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0016481308043813276, 'num_filters_1': 40, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.058223523117562556, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 72, 'num_filters_3': 89, 'num_filters_4': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:56:21 DISPATCHER: Starting worker discovery
04:56:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:56:21 DISPATCHER: Finished worker discovery
04:57:21 DISPATCHER: Starting worker discovery
04:57:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:57:21 DISPATCHER: Finished worker discovery
04:57:46 WORKER: done with job (8, 0, 6), trying to register it.
04:57:46 WORKER: registered result for job (8, 0, 6) with dispatcher
04:57:46 DISPATCHER: job (8, 0, 6) finished
04:57:46 DISPATCHER: register_result: lock acquired
04:57:46 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
04:57:46 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0016481308043813276, 'num_filters_1': 40, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.058223523117562556, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 72, 'num_filters_3': 89, 'num_filters_4': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4849467404470017, 'info': {'music_genre': 0.4849467404470017, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0016481308043813276, 'num_filters_1': 40, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.058223523117562556, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 72, 'num_filters_3': 89, 'num_filters_4': 18}"}}
exception: None

04:57:46 job_callback for (8, 0, 6) started
04:57:46 job_callback for (8, 0, 6) got condition
04:57:46 DISPATCHER: Trying to submit another job.
04:57:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:57:46 HBMASTER: Trying to run another job!
04:57:46 job_callback for (8, 0, 6) finished
04:57:46 start sampling a new configuration.
04:57:47 best_vector: [0, 0, 0.08112692277378428, 0.6808055785786866, 0.10846419914929982, 1, 0.482973577170091, 0.3600252511348202, 0, 0, 1, 0, 0.12128303199277948, 0.706688300870586, 0.10371113674550458, 0.36283065652464963], 7.036598339869244e-05, 0.004463746857396007, 3.1409593726349296e-07
04:57:47 done sampling a new configuration.
04:57:47 HBMASTER: schedule new run for iteration 8
04:57:47 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
04:57:47 HBMASTER: submitting job (8, 0, 7) to dispatcher
04:57:47 DISPATCHER: trying to submit job (8, 0, 7)
04:57:47 DISPATCHER: trying to notify the job_runner thread.
04:57:47 HBMASTER: job (8, 0, 7) submitted to dispatcher
04:57:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:57:47 DISPATCHER: Trying to submit another job.
04:57:47 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:57:47 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:57:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:57:47 WORKER: start processing job (8, 0, 7)
04:57:47 WORKER: args: ()
04:57:47 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0014529606263412734, 'num_filters_1': 65, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.029403812920619835}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:58:21 DISPATCHER: Starting worker discovery
04:58:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:58:21 DISPATCHER: Finished worker discovery
04:59:21 DISPATCHER: Starting worker discovery
04:59:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:59:21 DISPATCHER: Finished worker discovery
04:59:26 WORKER: done with job (8, 0, 7), trying to register it.
04:59:26 WORKER: registered result for job (8, 0, 7) with dispatcher
04:59:26 DISPATCHER: job (8, 0, 7) finished
04:59:26 DISPATCHER: register_result: lock acquired
04:59:26 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
04:59:26 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0014529606263412734, 'num_filters_1': 65, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.029403812920619835}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4496543732557861, 'info': {'music_genre': 0.4496543732557861, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0014529606263412734, 'num_filters_1': 65, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.029403812920619835}"}}
exception: None

04:59:26 job_callback for (8, 0, 7) started
04:59:26 DISPATCHER: Trying to submit another job.
04:59:26 job_callback for (8, 0, 7) got condition
04:59:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:59:26 HBMASTER: Trying to run another job!
04:59:26 job_callback for (8, 0, 7) finished
04:59:26 start sampling a new configuration.
04:59:26 done sampling a new configuration.
04:59:26 HBMASTER: schedule new run for iteration 8
04:59:26 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
04:59:26 HBMASTER: submitting job (8, 0, 8) to dispatcher
04:59:26 DISPATCHER: trying to submit job (8, 0, 8)
04:59:26 DISPATCHER: trying to notify the job_runner thread.
04:59:26 HBMASTER: job (8, 0, 8) submitted to dispatcher
04:59:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:59:26 DISPATCHER: Trying to submit another job.
04:59:26 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:59:26 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
04:59:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:59:26 WORKER: start processing job (8, 0, 8)
04:59:26 WORKER: args: ()
04:59:26 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.004493615701370262, 'num_filters_1': 29, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.1390345260439466, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 108, 'num_filters_3': 32}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:00:21 DISPATCHER: Starting worker discovery
05:00:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:00:21 DISPATCHER: Finished worker discovery
05:01:05 WORKER: done with job (8, 0, 8), trying to register it.
05:01:05 WORKER: registered result for job (8, 0, 8) with dispatcher
05:01:05 DISPATCHER: job (8, 0, 8) finished
05:01:05 DISPATCHER: register_result: lock acquired
05:01:05 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
05:01:05 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.004493615701370262, 'num_filters_1': 29, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.1390345260439466, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 108, 'num_filters_3': 32}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.004493615701370262, 'num_filters_1': 29, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.1390345260439466, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 108, 'num_filters_3': 32}"}}
exception: None

05:01:05 job_callback for (8, 0, 8) started
05:01:05 job_callback for (8, 0, 8) got condition
05:01:05 DISPATCHER: Trying to submit another job.
05:01:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:01:05 HBMASTER: Trying to run another job!
05:01:05 job_callback for (8, 0, 8) finished
05:01:05 start sampling a new configuration.
05:01:05 done sampling a new configuration.
05:01:05 HBMASTER: schedule new run for iteration 8
05:01:05 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
05:01:05 HBMASTER: submitting job (8, 0, 9) to dispatcher
05:01:05 DISPATCHER: trying to submit job (8, 0, 9)
05:01:05 DISPATCHER: trying to notify the job_runner thread.
05:01:05 HBMASTER: job (8, 0, 9) submitted to dispatcher
05:01:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:01:05 DISPATCHER: Trying to submit another job.
05:01:05 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:01:05 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:01:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:01:05 WORKER: start processing job (8, 0, 9)
05:01:05 WORKER: args: ()
05:01:05 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.036820145343971974, 'num_filters_1': 53, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.13467505151397827, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 54, 'num_filters_3': 96, 'num_filters_4': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:01:21 DISPATCHER: Starting worker discovery
05:01:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:01:21 DISPATCHER: Finished worker discovery
05:02:21 DISPATCHER: Starting worker discovery
05:02:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:02:21 DISPATCHER: Finished worker discovery
05:02:44 WORKER: done with job (8, 0, 9), trying to register it.
05:02:44 WORKER: registered result for job (8, 0, 9) with dispatcher
05:02:44 DISPATCHER: job (8, 0, 9) finished
05:02:44 DISPATCHER: register_result: lock acquired
05:02:44 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
05:02:44 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.036820145343971974, 'num_filters_1': 53, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.13467505151397827, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 54, 'num_filters_3': 96, 'num_filters_4': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.036820145343971974, 'num_filters_1': 53, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.13467505151397827, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 54, 'num_filters_3': 96, 'num_filters_4': 17}"}}
exception: None

05:02:44 job_callback for (8, 0, 9) started
05:02:44 DISPATCHER: Trying to submit another job.
05:02:44 job_callback for (8, 0, 9) got condition
05:02:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:02:44 HBMASTER: Trying to run another job!
05:02:44 job_callback for (8, 0, 9) finished
05:02:44 start sampling a new configuration.
05:02:44 best_vector: [0, 0, 0.6940976407268534, 0.8690364236682041, 0.9617394015833454, 1, 0.5952330400993666, 0.7037980011758015, 0, 2, 0, 0, 0.4195709084981682, 0.9568730155199408, 0.8643811591660328, 0.6540921945779339], 0.0012196902200714201, 0.00027481914541165097, 3.3519422394697616e-07
05:02:44 done sampling a new configuration.
05:02:44 HBMASTER: schedule new run for iteration 8
05:02:44 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
05:02:44 HBMASTER: submitting job (8, 0, 10) to dispatcher
05:02:44 DISPATCHER: trying to submit job (8, 0, 10)
05:02:44 DISPATCHER: trying to notify the job_runner thread.
05:02:44 HBMASTER: job (8, 0, 10) submitted to dispatcher
05:02:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:02:44 DISPATCHER: Trying to submit another job.
05:02:44 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:02:44 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:02:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:02:44 WORKER: start processing job (8, 0, 10)
05:02:44 WORKER: args: ()
05:02:44 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.024445294935822297, 'num_filters_1': 97, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.08234975480781329, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 38, 'num_filters_3': 117, 'num_filters_4': 96, 'num_filters_5': 62}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:03:21 DISPATCHER: Starting worker discovery
05:03:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:03:21 DISPATCHER: Finished worker discovery
05:04:21 DISPATCHER: Starting worker discovery
05:04:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:04:21 DISPATCHER: Finished worker discovery
05:04:23 WORKER: done with job (8, 0, 10), trying to register it.
05:04:23 WORKER: registered result for job (8, 0, 10) with dispatcher
05:04:23 DISPATCHER: job (8, 0, 10) finished
05:04:23 DISPATCHER: register_result: lock acquired
05:04:23 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
05:04:23 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.024445294935822297, 'num_filters_1': 97, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.08234975480781329, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 38, 'num_filters_3': 117, 'num_filters_4': 96, 'num_filters_5': 62}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1787290216703687, 'info': {'music_genre': 0.1787290216703687, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.024445294935822297, 'num_filters_1': 97, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.08234975480781329, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 38, 'num_filters_3': 117, 'num_filters_4': 96, 'num_filters_5': 62}"}}
exception: None

05:04:23 job_callback for (8, 0, 10) started
05:04:23 job_callback for (8, 0, 10) got condition
05:04:23 DISPATCHER: Trying to submit another job.
05:04:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:04:23 HBMASTER: Trying to run another job!
05:04:23 job_callback for (8, 0, 10) finished
05:04:23 start sampling a new configuration.
05:04:23 best_vector: [0, 2, 0.31595838722702535, 0.4849434314255746, 0.35034539884299265, 1, 0.4796037575732789, 0.49484842088265624, 0, 2, 0, 0, 0.764977211586596, 0.7929414351523787, 0.021348876610614784, 0.7620036437758065], 0.00037080376739397834, 0.0010409421571189895, 3.8598527349893585e-07
05:04:23 done sampling a new configuration.
05:04:23 HBMASTER: schedule new run for iteration 8
05:04:23 HBMASTER: trying submitting job (8, 0, 11) to dispatcher
05:04:23 HBMASTER: submitting job (8, 0, 11) to dispatcher
05:04:23 DISPATCHER: trying to submit job (8, 0, 11)
05:04:23 DISPATCHER: trying to notify the job_runner thread.
05:04:23 HBMASTER: job (8, 0, 11) submitted to dispatcher
05:04:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:04:23 DISPATCHER: Trying to submit another job.
05:04:23 DISPATCHER: starting job (8, 0, 11) on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:04:23 DISPATCHER: job (8, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:04:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:04:23 WORKER: start processing job (8, 0, 11)
05:04:23 WORKER: args: ()
05:04:23 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.004284664038409205, 'num_filters_1': 43, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.0440364842551621, 'kernel_size_2': 3, 'num_filters_2': 78}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:05:21 DISPATCHER: Starting worker discovery
05:05:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:05:21 DISPATCHER: Finished worker discovery
05:06:00 WORKER: done with job (8, 0, 11), trying to register it.
05:06:00 WORKER: registered result for job (8, 0, 11) with dispatcher
05:06:00 DISPATCHER: job (8, 0, 11) finished
05:06:00 DISPATCHER: register_result: lock acquired
05:06:00 DISPATCHER: job (8, 0, 11) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
05:06:00 job_id: (8, 0, 11)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.004284664038409205, 'num_filters_1': 43, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.0440364842551621, 'kernel_size_2': 3, 'num_filters_2': 78}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4245051809574336, 'info': {'music_genre': 0.4245051809574336, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.004284664038409205, 'num_filters_1': 43, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.0440364842551621, 'kernel_size_2': 3, 'num_filters_2': 78}"}}
exception: None

05:06:00 job_callback for (8, 0, 11) started
05:06:00 DISPATCHER: Trying to submit another job.
05:06:00 job_callback for (8, 0, 11) got condition
05:06:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:06:00 HBMASTER: Trying to run another job!
05:06:00 job_callback for (8, 0, 11) finished
05:06:00 start sampling a new configuration.
05:06:00 best_vector: [3, 2, 0.39364195735576635, 0.45195675409430813, 0.884581661404389, 1, 0.9600532669594151, 0.24326358957260272, 2, 2, 0, 0, 0.69495532039796, 0.6282770306905268, 0.09508678968785877, 0.03411618121881976], 2.355178593317199e-05, 0.0026623690083574895, 6.270354495994698e-08
05:06:00 done sampling a new configuration.
05:06:00 HBMASTER: schedule new run for iteration 8
05:06:00 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
05:06:00 HBMASTER: submitting job (8, 0, 12) to dispatcher
05:06:00 DISPATCHER: trying to submit job (8, 0, 12)
05:06:00 DISPATCHER: trying to notify the job_runner thread.
05:06:00 HBMASTER: job (8, 0, 12) submitted to dispatcher
05:06:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:06:00 DISPATCHER: Trying to submit another job.
05:06:00 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:06:00 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:06:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:06:00 WORKER: start processing job (8, 0, 12)
05:06:00 WORKER: args: ()
05:06:00 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.006127508391915043, 'num_filters_1': 40, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.020724937374034177, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 67, 'num_filters_3': 59, 'num_filters_4': 19, 'num_filters_5': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:06:21 DISPATCHER: Starting worker discovery
05:06:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:06:21 DISPATCHER: Finished worker discovery
05:07:21 DISPATCHER: Starting worker discovery
05:07:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:07:21 DISPATCHER: Finished worker discovery
05:07:42 WORKER: done with job (8, 0, 12), trying to register it.
05:07:42 WORKER: registered result for job (8, 0, 12) with dispatcher
05:07:42 DISPATCHER: job (8, 0, 12) finished
05:07:42 DISPATCHER: register_result: lock acquired
05:07:42 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
05:07:42 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.006127508391915043, 'num_filters_1': 40, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.020724937374034177, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 67, 'num_filters_3': 59, 'num_filters_4': 19, 'num_filters_5': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4273575388589274, 'info': {'music_genre': 0.4273575388589274, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.006127508391915043, 'num_filters_1': 40, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.020724937374034177, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 67, 'num_filters_3': 59, 'num_filters_4': 19, 'num_filters_5': 17}"}}
exception: None

05:07:42 job_callback for (8, 0, 12) started
05:07:42 DISPATCHER: Trying to submit another job.
05:07:42 job_callback for (8, 0, 12) got condition
05:07:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:07:42 HBMASTER: Trying to run another job!
05:07:42 job_callback for (8, 0, 12) finished
05:07:42 start sampling a new configuration.
05:07:42 done sampling a new configuration.
05:07:42 HBMASTER: schedule new run for iteration 8
05:07:42 HBMASTER: trying submitting job (8, 0, 13) to dispatcher
05:07:42 HBMASTER: submitting job (8, 0, 13) to dispatcher
05:07:42 DISPATCHER: trying to submit job (8, 0, 13)
05:07:42 DISPATCHER: trying to notify the job_runner thread.
05:07:42 HBMASTER: job (8, 0, 13) submitted to dispatcher
05:07:42 DISPATCHER: Trying to submit another job.
05:07:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:07:42 DISPATCHER: starting job (8, 0, 13) on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:07:42 DISPATCHER: job (8, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:07:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:07:42 WORKER: start processing job (8, 0, 13)
05:07:42 WORKER: args: ()
05:07:42 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.009298097797484745, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.019500617022098075, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 93, 'num_filters_3': 32, 'num_filters_4': 23}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:08:21 DISPATCHER: Starting worker discovery
05:08:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:08:21 DISPATCHER: Finished worker discovery
05:09:20 WORKER: done with job (8, 0, 13), trying to register it.
05:09:20 WORKER: registered result for job (8, 0, 13) with dispatcher
05:09:20 DISPATCHER: job (8, 0, 13) finished
05:09:20 DISPATCHER: register_result: lock acquired
05:09:20 DISPATCHER: job (8, 0, 13) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
05:09:20 job_id: (8, 0, 13)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.009298097797484745, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.019500617022098075, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 93, 'num_filters_3': 32, 'num_filters_4': 23}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.009298097797484745, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.019500617022098075, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 93, 'num_filters_3': 32, 'num_filters_4': 23}"}}
exception: None

05:09:20 job_callback for (8, 0, 13) started
05:09:20 DISPATCHER: Trying to submit another job.
05:09:20 job_callback for (8, 0, 13) got condition
05:09:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:09:20 HBMASTER: Trying to run another job!
05:09:20 job_callback for (8, 0, 13) finished
05:09:20 start sampling a new configuration.
05:09:21 best_vector: [0, 1, 0.18346011495882322, 0.4132124253828011, 0.47986462509086236, 1, 0.5218977796523268, 0.9105260093588219, 0, 2, 2, 0, 0.3385925906460825, 0.9682715931228466, 0.008588383593649662, 0.4155519384650586], 0.0002708648120880009, 0.00019009422546407918, 5.148983665934188e-08
05:09:21 done sampling a new configuration.
05:09:21 HBMASTER: schedule new run for iteration 8
05:09:21 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
05:09:21 HBMASTER: submitting job (8, 0, 14) to dispatcher
05:09:21 DISPATCHER: trying to submit job (8, 0, 14)
05:09:21 DISPATCHER: trying to notify the job_runner thread.
05:09:21 HBMASTER: job (8, 0, 14) submitted to dispatcher
05:09:21 DISPATCHER: Trying to submit another job.
05:09:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:09:21 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:09:21 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:09:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:09:21 WORKER: start processing job (8, 0, 14)
05:09:21 WORKER: args: ()
05:09:21 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002327663679179486, 'num_filters_1': 37, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.15297541850835172, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 32, 'num_filters_3': 120}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:09:21 DISPATCHER: Starting worker discovery
05:09:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:09:21 DISPATCHER: Finished worker discovery
05:10:21 DISPATCHER: Starting worker discovery
05:10:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:10:21 DISPATCHER: Finished worker discovery
05:10:59 WORKER: done with job (8, 0, 14), trying to register it.
05:10:59 WORKER: registered result for job (8, 0, 14) with dispatcher
05:10:59 DISPATCHER: job (8, 0, 14) finished
05:10:59 DISPATCHER: register_result: lock acquired
05:10:59 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
05:10:59 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002327663679179486, 'num_filters_1': 37, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.15297541850835172, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 32, 'num_filters_3': 120}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.33133871624320876, 'info': {'music_genre': 0.33133871624320876, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002327663679179486, 'num_filters_1': 37, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.15297541850835172, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 32, 'num_filters_3': 120}"}}
exception: None

05:10:59 job_callback for (8, 0, 14) started
05:10:59 DISPATCHER: Trying to submit another job.
05:10:59 job_callback for (8, 0, 14) got condition
05:10:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:10:59 HBMASTER: Trying to run another job!
05:10:59 job_callback for (8, 0, 14) finished
05:10:59 start sampling a new configuration.
05:10:59 best_vector: [0, 2, 0.6443154752533611, 0.6627102484668084, 0.16838621617965133, 1, 0.903579272793597, 0.9775637218497967, 0, 1, 1, 2, 0.19311584350091726, 0.8229614937843882, 0.0015591135763139974, 0.5240955052179407], 0.007046831530511696, 1.2243962938327989e-06, 8.62811440922263e-09
05:10:59 done sampling a new configuration.
05:10:59 HBMASTER: schedule new run for iteration 8
05:10:59 HBMASTER: trying submitting job (8, 0, 15) to dispatcher
05:10:59 HBMASTER: submitting job (8, 0, 15) to dispatcher
05:10:59 DISPATCHER: trying to submit job (8, 0, 15)
05:10:59 DISPATCHER: trying to notify the job_runner thread.
05:10:59 HBMASTER: job (8, 0, 15) submitted to dispatcher
05:10:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:10:59 DISPATCHER: Trying to submit another job.
05:10:59 DISPATCHER: starting job (8, 0, 15) on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:10:59 DISPATCHER: job (8, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:10:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:10:59 WORKER: start processing job (8, 0, 15)
05:10:59 WORKER: args: ()
05:10:59 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.019437076793242927, 'num_filters_1': 63, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.18699918975701976}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:11:21 DISPATCHER: Starting worker discovery
05:11:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:11:21 DISPATCHER: Finished worker discovery
05:12:21 DISPATCHER: Starting worker discovery
05:12:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:12:21 DISPATCHER: Finished worker discovery
05:12:38 WORKER: done with job (8, 0, 15), trying to register it.
05:12:38 WORKER: registered result for job (8, 0, 15) with dispatcher
05:12:38 DISPATCHER: job (8, 0, 15) finished
05:12:38 DISPATCHER: register_result: lock acquired
05:12:38 DISPATCHER: job (8, 0, 15) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
05:12:38 job_id: (8, 0, 15)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.019437076793242927, 'num_filters_1': 63, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.18699918975701976}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2707988819008974, 'info': {'music_genre': 0.2707988819008974, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.019437076793242927, 'num_filters_1': 63, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.18699918975701976}"}}
exception: None

05:12:38 job_callback for (8, 0, 15) started
05:12:38 DISPATCHER: Trying to submit another job.
05:12:38 job_callback for (8, 0, 15) got condition
05:12:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:12:38 HBMASTER: Trying to run another job!
05:12:38 job_callback for (8, 0, 15) finished
05:12:38 start sampling a new configuration.
05:12:39 best_vector: [1, 1, 0.13736850401134185, 0.5203334747917389, 0.9346127036747696, 1, 0.22193627944857375, 0.5079590981596562, 2, 1, 1, 2, 0.6009245267707474, 0.8959772524769034, 0.027416726761698096, 0.05229375044525309], 2.403784225588263e-05, 0.0010478001694236559, 2.5186855188292932e-08
05:12:39 done sampling a new configuration.
05:12:39 HBMASTER: schedule new run for iteration 8
05:12:39 HBMASTER: trying submitting job (8, 0, 16) to dispatcher
05:12:39 HBMASTER: submitting job (8, 0, 16) to dispatcher
05:12:39 DISPATCHER: trying to submit job (8, 0, 16)
05:12:39 DISPATCHER: trying to notify the job_runner thread.
05:12:39 HBMASTER: job (8, 0, 16) submitted to dispatcher
05:12:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:12:39 DISPATCHER: Trying to submit another job.
05:12:39 DISPATCHER: starting job (8, 0, 16) on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:12:39 DISPATCHER: job (8, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:12:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:12:39 WORKER: start processing job (8, 0, 16)
05:12:39 WORKER: args: ()
05:12:39 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0018825087695994367, 'num_filters_1': 47, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.04580047933963686, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 55, 'num_filters_3': 103, 'num_filters_4': 16, 'num_filters_5': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:13:21 DISPATCHER: Starting worker discovery
05:13:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:13:21 DISPATCHER: Finished worker discovery
05:14:17 WORKER: done with job (8, 0, 16), trying to register it.
05:14:17 WORKER: registered result for job (8, 0, 16) with dispatcher
05:14:17 DISPATCHER: job (8, 0, 16) finished
05:14:17 DISPATCHER: register_result: lock acquired
05:14:17 DISPATCHER: job (8, 0, 16) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
05:14:17 job_id: (8, 0, 16)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0018825087695994367, 'num_filters_1': 47, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.04580047933963686, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 55, 'num_filters_3': 103, 'num_filters_4': 16, 'num_filters_5': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3734731434798565, 'info': {'music_genre': 0.3734731434798565, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0018825087695994367, 'num_filters_1': 47, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.04580047933963686, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 55, 'num_filters_3': 103, 'num_filters_4': 16, 'num_filters_5': 17}"}}
exception: None

05:14:17 job_callback for (8, 0, 16) started
05:14:17 job_callback for (8, 0, 16) got condition
05:14:17 DISPATCHER: Trying to submit another job.
05:14:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:14:17 HBMASTER: Trying to run another job!
05:14:17 job_callback for (8, 0, 16) finished
05:14:17 start sampling a new configuration.
05:14:17 best_vector: [1, 2, 0.08046295403280719, 0.7767140991539229, 0.9425138298895321, 1, 0.305621469754252, 0.4363019494310688, 2, 2, 2, 2, 0.6866127813967058, 0.9941711988187165, 0.027883207861211762, 0.1122899780234447], 2.829836462235533e-05, 0.00013958851600336943, 3.95012672295683e-09
05:14:17 done sampling a new configuration.
05:14:17 HBMASTER: schedule new run for iteration 8
05:14:17 HBMASTER: trying submitting job (8, 0, 17) to dispatcher
05:14:17 HBMASTER: submitting job (8, 0, 17) to dispatcher
05:14:17 DISPATCHER: trying to submit job (8, 0, 17)
05:14:17 DISPATCHER: trying to notify the job_runner thread.
05:14:17 HBMASTER: job (8, 0, 17) submitted to dispatcher
05:14:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:14:17 DISPATCHER: Trying to submit another job.
05:14:17 DISPATCHER: starting job (8, 0, 17) on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:14:17 DISPATCHER: job (8, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:14:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:14:17 WORKER: start processing job (8, 0, 17)
05:14:17 WORKER: args: ()
05:14:17 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0014485247098262794, 'num_filters_1': 80, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.03695233814157306, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 66, 'num_filters_3': 127, 'num_filters_4': 16, 'num_filters_5': 20}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:14:21 DISPATCHER: Starting worker discovery
05:14:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:14:21 DISPATCHER: Finished worker discovery
05:15:21 DISPATCHER: Starting worker discovery
05:15:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:15:21 DISPATCHER: Finished worker discovery
05:15:55 WORKER: done with job (8, 0, 17), trying to register it.
05:15:55 WORKER: registered result for job (8, 0, 17) with dispatcher
05:15:55 DISPATCHER: job (8, 0, 17) finished
05:15:55 DISPATCHER: register_result: lock acquired
05:15:55 DISPATCHER: job (8, 0, 17) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
05:15:55 job_id: (8, 0, 17)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0014485247098262794, 'num_filters_1': 80, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.03695233814157306, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 66, 'num_filters_3': 127, 'num_filters_4': 16, 'num_filters_5': 20}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4758084069464097, 'info': {'music_genre': 0.4758084069464097, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0014485247098262794, 'num_filters_1': 80, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.03695233814157306, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 66, 'num_filters_3': 127, 'num_filters_4': 16, 'num_filters_5': 20}"}}
exception: None

05:15:55 job_callback for (8, 0, 17) started
05:15:55 DISPATCHER: Trying to submit another job.
05:15:55 job_callback for (8, 0, 17) got condition
05:15:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:15:55 HBMASTER: Trying to run another job!
05:15:55 job_callback for (8, 0, 17) finished
05:15:55 start sampling a new configuration.
05:15:56 best_vector: [1, 1, 0.030423573623463068, 0.06441740481489477, 0.06759128592684399, 1, 0.16657303514139488, 0.18525614238975752, 1, 2, 2, 1, 0.9344167305049824, 0.5901425287420874, 0.0025045620945283176, 0.9614260235835985], 0.0003937370165642578, 0.0013198638780473465, 5.196792656132936e-07
05:15:56 done sampling a new configuration.
05:15:56 HBMASTER: schedule new run for iteration 8
05:15:56 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
05:15:56 HBMASTER: submitting job (8, 0, 18) to dispatcher
05:15:56 DISPATCHER: trying to submit job (8, 0, 18)
05:15:56 DISPATCHER: trying to notify the job_runner thread.
05:15:56 HBMASTER: job (8, 0, 18) submitted to dispatcher
05:15:56 DISPATCHER: Trying to submit another job.
05:15:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:15:56 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:15:56 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:15:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:15:56 WORKER: start processing job (8, 0, 18)
05:15:56 WORKER: args: ()
05:15:56 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0011503954285695115, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.01741902322180402}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:16:21 DISPATCHER: Starting worker discovery
05:16:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:16:21 DISPATCHER: Finished worker discovery
05:17:21 DISPATCHER: Starting worker discovery
05:17:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:17:21 DISPATCHER: Finished worker discovery
05:17:36 WORKER: done with job (8, 0, 18), trying to register it.
05:17:36 WORKER: registered result for job (8, 0, 18) with dispatcher
05:17:36 DISPATCHER: job (8, 0, 18) finished
05:17:36 DISPATCHER: register_result: lock acquired
05:17:36 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
05:17:36 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0011503954285695115, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.01741902322180402}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.40649745150521244, 'info': {'music_genre': 0.40649745150521244, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0011503954285695115, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.01741902322180402}"}}
exception: None

05:17:36 job_callback for (8, 0, 18) started
05:17:36 DISPATCHER: Trying to submit another job.
05:17:36 job_callback for (8, 0, 18) got condition
05:17:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:17:36 HBMASTER: Trying to run another job!
05:17:36 job_callback for (8, 0, 18) finished
05:17:36 start sampling a new configuration.
05:17:36 done sampling a new configuration.
05:17:36 HBMASTER: schedule new run for iteration 8
05:17:36 HBMASTER: trying submitting job (8, 0, 19) to dispatcher
05:17:36 HBMASTER: submitting job (8, 0, 19) to dispatcher
05:17:36 DISPATCHER: trying to submit job (8, 0, 19)
05:17:36 DISPATCHER: trying to notify the job_runner thread.
05:17:36 HBMASTER: job (8, 0, 19) submitted to dispatcher
05:17:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:17:36 DISPATCHER: Trying to submit another job.
05:17:36 DISPATCHER: starting job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:17:36 DISPATCHER: job (8, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:17:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:17:36 WORKER: start processing job (8, 0, 19)
05:17:36 WORKER: args: ()
05:17:36 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.040730818622022116, 'num_filters_1': 105, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.01635060538128047, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 36, 'num_filters_3': 38}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:18:21 DISPATCHER: Starting worker discovery
05:18:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:18:21 DISPATCHER: Finished worker discovery
05:19:13 WORKER: done with job (8, 0, 19), trying to register it.
05:19:13 WORKER: registered result for job (8, 0, 19) with dispatcher
05:19:13 DISPATCHER: job (8, 0, 19) finished
05:19:13 DISPATCHER: register_result: lock acquired
05:19:13 DISPATCHER: job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
05:19:13 job_id: (8, 0, 19)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.040730818622022116, 'num_filters_1': 105, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.01635060538128047, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 36, 'num_filters_3': 38}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.040730818622022116, 'num_filters_1': 105, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.01635060538128047, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 36, 'num_filters_3': 38}"}}
exception: None

05:19:13 job_callback for (8, 0, 19) started
05:19:13 DISPATCHER: Trying to submit another job.
05:19:13 job_callback for (8, 0, 19) got condition
05:19:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:19:13 HBMASTER: Trying to run another job!
05:19:13 job_callback for (8, 0, 19) finished
05:19:13 start sampling a new configuration.
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/numpy/core/_methods.py:38: RuntimeWarning: invalid value encountered in reduce
  return umr_sum(a, axis, dtype, out, keepdims, initial, where)
05:19:14 sampled vector: [0, 1, 0.5290426013464251, 0.7245108084143083, 0.2803406244749469, 0, 0.21624775574195465, 0.3785312148918629, 1, 2, 1, 1, 0.08333722131758603, 0.5429688274862532, 0.9218708509174608, 0.5305874624708826] has EI value nan
05:19:14 data in the KDEs:
[[2.00000000e+00 1.00000000e+00 2.87971215e-02 7.93347517e-01
  9.00001600e-01 1.00000000e+00 7.19780268e-01 4.13095376e-01
  0.00000000e+00 1.00000000e+00 0.00000000e+00 2.00000000e+00
  7.63972013e-01 5.53727433e-01 8.52188646e-01 6.07308503e-01]
 [0.00000000e+00 1.00000000e+00 5.72991623e-03 9.79317897e-01
  5.00000000e-01 1.00000000e+00 6.09890134e-01 1.87494383e-01
  0.00000000e+00 2.00000000e+00 0.00000000e+00 2.00000000e+00
  9.90711064e-01 7.26128339e-01 8.52188646e-01 6.07308503e-01]
 [1.00000000e+00 2.00000000e+00 1.45140927e-01 7.69994942e-01
  9.99984000e-02 1.00000000e+00 4.23076906e-01 3.09222845e-01
  2.00000000e+00 2.00000000e+00 0.00000000e+00 0.00000000e+00
  4.11366893e-01 7.06006428e-01 1.43578776e-01 5.03913663e-01]
 [0.00000000e+00 0.00000000e+00 2.46132337e-01 6.15676748e-01
  9.00001600e-01 1.00000000e+00 3.02197759e-01 4.27296182e-02
  1.00000000e+00 1.00000000e+00 1.00000000e+00 0.00000000e+00
  9.62599641e-02 6.99104210e-01 9.26504973e-01 5.03913663e-01]
 [1.00000000e+00 0.00000000e+00 3.53901127e-02 5.44175724e-01
  9.99984000e-02 1.00000000e+00 7.52747308e-01 6.00933661e-04
  0.00000000e+00 2.00000000e+00 2.00000000e+00 1.00000000e+00
  5.03913663e-01 7.87616617e-01 8.31629166e-01 6.47742833e-01]
 [1.00000000e+00 1.00000000e+00 4.22835225e-01 9.04510611e-01
  5.00000000e-01 1.00000000e+00 4.78021973e-01 4.24336130e-02
  1.00000000e+00 2.00000000e+00 1.00000000e+00 0.00000000e+00
  9.86943764e-01 9.39226643e-01 9.26504973e-01 5.03913663e-01]
 [3.00000000e+00 0.00000000e+00 9.74485708e-02 8.90805491e-01
  9.99984000e-02 1.00000000e+00 1.04395517e-01 4.07937219e-01
  1.00000000e+00 1.00000000e+00 1.00000000e+00 0.00000000e+00
  9.62599641e-02 6.99104210e-01 9.26504973e-01 5.03913663e-01]
 [0.00000000e+00 0.00000000e+00 2.08338539e-01 9.75458337e-01
  7.00000800e-01 1.00000000e+00 8.40659416e-01 8.22786933e-02
  1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00
  6.55430702e-01 9.22187194e-01 1.43578776e-01 6.47742833e-01]
 [0.00000000e+00 0.00000000e+00 1.89273462e-02 4.93288642e-01
  2.99999200e-01 1.00000000e+00 2.14285651e-01 1.76333946e-02
  1.00000000e+00 2.00000000e+00 1.00000000e+00 0.00000000e+00
  4.93288642e-01 7.06006428e-01 2.96183948e-01 4.36732032e-02]
 [1.00000000e+00 2.00000000e+00 2.19245759e-01 6.55430702e-01
  5.00000000e-01 1.00000000e+00 9.17582509e-01 3.03037260e-01
  1.00000000e+00 2.00000000e+00 2.00000000e+00 1.00000000e+00
  8.10134850e-01 5.53727433e-01 8.31629166e-01 6.47742833e-01]
 [3.00000000e+00 1.00000000e+00 9.73743668e-01 5.90114116e-01
  5.00000000e-01 1.00000000e+00 9.17582509e-01 2.12049076e-01
  2.00000000e+00 2.00000000e+00 1.00000000e+00 0.00000000e+00
  4.11366893e-01 7.06006428e-01 9.26504973e-01 5.03913663e-01]
 [3.00000000e+00 1.00000000e+00 7.48700409e-03 3.98412835e-01
  9.99984000e-02 1.00000000e+00 1.48351571e-01 1.73172369e-01
  0.00000000e+00 2.00000000e+00 0.00000000e+00 2.00000000e+00
  9.35024006e-01 6.77771560e-01 1.43578776e-01 6.07308503e-01]
 [3.00000000e+00 1.00000000e+00 1.38912196e-01 2.62398612e-01
  5.00000000e-01 1.00000000e+00 4.45054933e-01 8.08726262e-01
  0.00000000e+00 2.00000000e+00 1.00000000e+00 0.00000000e+00
  9.35024006e-01 6.77771560e-01 9.26504973e-01 5.03913663e-01]
 [2.00000000e+00 1.00000000e+00 3.75806393e-01 7.87616617e-01
  9.00001600e-01 1.00000000e+00 9.28571523e-01 1.18523213e-01
  1.00000000e+00 1.00000000e+00 1.00000000e+00 0.00000000e+00
  6.99104210e-01 6.55430702e-01 2.96183948e-01 4.36732032e-02]
 [1.00000000e+00 1.00000000e+00 1.32826767e-01 9.62599641e-02
  5.00000000e-01 1.00000000e+00 7.08791255e-01 5.74599707e-01
  2.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00
  6.31981589e-01 8.15600732e-01 1.43578776e-01 5.03913663e-01]
 [2.00000000e+00 1.00000000e+00 2.31478056e-01 5.34427058e-01
  5.00000000e-01 1.00000000e+00 3.84614370e-02 5.45233588e-01
  0.00000000e+00 2.00000000e+00 1.00000000e+00 0.00000000e+00
  9.47521479e-01 8.36853457e-01 2.96183948e-01 4.36732032e-02]
 [3.00000000e+00 1.00000000e+00 3.28025084e-01 5.44175724e-01
  9.00001600e-01 1.00000000e+00 7.08791255e-01 5.79500887e-01
  0.00000000e+00 2.00000000e+00 2.00000000e+00 1.00000000e+00
  5.03913663e-01 7.87616617e-01 8.31629166e-01 6.47742833e-01]]
[[3.         1.         0.14792329 0.18658964 0.2999992  1.
  0.06043946 0.37048307 2.         1.         0.         0.
  0.41136689 0.55372743 0.51430515 0.67777156]
 [3.         0.         0.41710036 0.54417572 0.5        1.
  0.56593408 0.30990814 1.         2.         2.         0.
  0.01501027 0.43625651 0.52447314 0.67777156]
 [0.         0.         0.13734239 0.99444858 0.0999984  1.
  0.70879125 0.79194823 0.         2.         1.         2.
  0.74542871 0.48241935 0.99071106 0.22601193]
 [1.         0.         0.31070674 0.84202065 0.2999992  1.
  0.37912085 0.6208271  2.         2.         2.         2.
  0.76999494 0.35727442 0.72612834 0.22601193]
 [2.         1.         0.12160842 0.95567329 0.7000008  1.
  0.44505493 0.96577667 1.         2.         2.         0.
  0.31221238 0.35727442 0.72612834 0.67777156]
 [3.         2.         0.21215743 0.37138871 0.9000016  0.
  0.26923072 0.16893818 2.         2.         1.         2.
  0.64774283 0.55372743 0.62389945 0.22601193]
 [1.         2.         0.4390688  0.72612834 0.2999992  1.
  0.42307691 0.67246989 1.         2.         1.         2.
  0.95567329 0.43625651 0.62389945 0.22601193]
 [0.         1.         0.51173259 0.38509383 0.7000008  1.
  0.81868139 0.07058142 0.         2.         2.         0.
  0.98694376 0.96368694 0.52447314 0.67777156]
 [2.         0.         0.29346917 0.0436732  0.7000008  1.
  0.54395605 0.20003535 0.         0.         1.         2.
  0.75787137 0.44822661 0.99071106 0.22601193]
 [1.         0.         0.12784089 0.92650497 0.2999992  1.
  0.19230762 0.88485227 1.         2.         1.         2.
  0.83685346 0.55372743 0.62389945 0.22601193]
 [0.         0.         0.43889565 0.31221238 0.2999992  0.
  0.57692309 0.20927784 1.         1.         2.         2.
  0.24455523 0.98694376 0.52447314 0.22601193]
 [2.         2.         0.6803084  0.52447314 0.5        1.
  0.14835157 0.16535056 0.         2.         0.         0.
  0.74542871 0.48241935 0.51430515 0.67777156]
 [2.         1.         0.76708404 0.16557314 0.5        1.
  0.79670336 0.25899268 1.         1.         1.         0.
  0.8263465  0.98694376 0.63992789 0.67777156]
 [2.         2.         0.00651724 0.279593   0.5        0.
  0.73076928 0.53905515 1.         1.         2.         0.
  0.70600643 0.64774283 0.52447314 0.67777156]
 [3.         2.         0.02938905 0.71951573 0.5        0.
  0.41208789 0.89894323 2.         0.         1.         0.
  0.9089921  0.63198159 0.99071106 0.67777156]
 [0.         2.         0.70652422 0.64774283 0.0999984  0.
  0.93956054 0.17006485 1.         1.         1.         2.
  0.70600643 0.64774283 0.62389945 0.22601193]
 [3.         0.         0.54320268 0.3277152  0.5        0.
  0.08241749 0.72332924 1.         1.         1.         2.
  0.14357878 0.61567675 0.62389945 0.22601193]
 [2.         0.         0.3761069  0.31221238 0.7000008  0.
  0.20329664 0.967376   2.         2.         1.         2.
  0.50391366 0.37138871 0.63992789 0.22601193]
 [2.         1.         0.6368347  0.35727442 0.9000016  0.
  0.93956054 0.37585854 0.         1.         0.         0.
  0.1205111  0.55372743 0.51430515 0.67777156]]
05:19:14 bandwidth of the KDEs:
[1.05215663e+00 5.67584910e-01 2.09577336e-01 2.20163138e-01
 2.60213695e-01 1.00000000e-03 2.68634323e-01 2.12975435e-01
 6.71575522e-01 5.51888275e-01 6.49405173e-01 7.09739083e-01
 2.55826593e-01 9.54033680e-02 3.10050967e-01 1.91406000e-01]
[0.98682292 0.77940867 0.21048171 0.25629983 0.20966961 0.45170606
 0.25185775 0.27673763 0.6637299  0.61664684 0.61287526 0.9136205
 0.26831197 0.17743871 0.1455717  0.20636843]
05:19:14 l(x) = nan
05:19:14 g(x) = 0.00016733451826667602
05:19:14 best_vector: [2, 2, 0.9323775249550057, 0.7682621710174385, 0.7898725063556552, 1, 0.47955249074623596, 0.36277014765423865, 1, 2, 2, 1, 0.3758965511595227, 0.7536555047699496, 0.9624087157159669, 0.26911532342549427], 0.0022271722242117667, 0.0008485296664718294, 1.8898217045857329e-06
05:19:14 done sampling a new configuration.
05:19:14 HBMASTER: schedule new run for iteration 8
05:19:14 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
05:19:14 HBMASTER: submitting job (8, 0, 20) to dispatcher
05:19:14 DISPATCHER: trying to submit job (8, 0, 20)
05:19:14 DISPATCHER: trying to notify the job_runner thread.
05:19:14 HBMASTER: job (8, 0, 20) submitted to dispatcher
05:19:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:19:14 DISPATCHER: Trying to submit another job.
05:19:14 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:19:14 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:19:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:19:14 WORKER: start processing job (8, 0, 20)
05:19:14 WORKER: args: ()
05:19:14 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.07324113231393645, 'num_filters_1': 79, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.029646596575784587, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 34, 'num_filters_3': 76, 'num_filters_4': 119}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:19:21 DISPATCHER: Starting worker discovery
05:19:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:19:21 DISPATCHER: Finished worker discovery
05:20:21 DISPATCHER: Starting worker discovery
05:20:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:20:21 DISPATCHER: Finished worker discovery
05:20:52 WORKER: done with job (8, 0, 20), trying to register it.
05:20:52 WORKER: registered result for job (8, 0, 20) with dispatcher
05:20:52 DISPATCHER: job (8, 0, 20) finished
05:20:52 DISPATCHER: register_result: lock acquired
05:20:52 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
05:20:52 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.07324113231393645, 'num_filters_1': 79, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.029646596575784587, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 34, 'num_filters_3': 76, 'num_filters_4': 119}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2622436072511165, 'info': {'music_genre': 0.2622436072511165, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.07324113231393645, 'num_filters_1': 79, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.029646596575784587, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 34, 'num_filters_3': 76, 'num_filters_4': 119}"}}
exception: None

05:20:52 job_callback for (8, 0, 20) started
05:20:52 job_callback for (8, 0, 20) got condition
05:20:52 DISPATCHER: Trying to submit another job.
05:20:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:20:52 HBMASTER: Trying to run another job!
05:20:52 job_callback for (8, 0, 20) finished
05:20:52 start sampling a new configuration.
05:20:52 best_vector: [3, 1, 0.1932330017607858, 0.8168802298278668, 0.22190719423471283, 1, 0.7428634784254216, 0.036964189632358924, 2, 0, 0, 2, 0.7958628986997696, 0.6787266159766113, 0.058958677848947746, 0.5462072735147142], 0.0005891052513706337, 0.0012180407551013069, 7.175542052136318e-07
05:20:52 done sampling a new configuration.
05:20:52 HBMASTER: schedule new run for iteration 8
05:20:52 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
05:20:52 HBMASTER: submitting job (8, 0, 21) to dispatcher
05:20:52 DISPATCHER: trying to submit job (8, 0, 21)
05:20:52 DISPATCHER: trying to notify the job_runner thread.
05:20:52 HBMASTER: job (8, 0, 21) submitted to dispatcher
05:20:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:20:52 DISPATCHER: Trying to submit another job.
05:20:52 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:20:52 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:20:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:20:52 WORKER: start processing job (8, 0, 21)
05:20:52 WORKER: args: ()
05:20:52 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002434815195683213, 'num_filters_1': 87, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.011170986307186003, 'kernel_size_2': 7, 'num_filters_2': 83}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:21:21 DISPATCHER: Starting worker discovery
05:21:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:21:21 DISPATCHER: Finished worker discovery
05:22:21 DISPATCHER: Starting worker discovery
05:22:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:22:21 DISPATCHER: Finished worker discovery
05:22:31 WORKER: done with job (8, 0, 21), trying to register it.
05:22:31 WORKER: registered result for job (8, 0, 21) with dispatcher
05:22:31 DISPATCHER: job (8, 0, 21) finished
05:22:31 DISPATCHER: register_result: lock acquired
05:22:31 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
05:22:31 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002434815195683213, 'num_filters_1': 87, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.011170986307186003, 'kernel_size_2': 7, 'num_filters_2': 83}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.48139837863864976, 'info': {'music_genre': 0.48139837863864976, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002434815195683213, 'num_filters_1': 87, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.011170986307186003, 'kernel_size_2': 7, 'num_filters_2': 83}"}}
exception: None

05:22:31 job_callback for (8, 0, 21) started
05:22:31 DISPATCHER: Trying to submit another job.
05:22:31 job_callback for (8, 0, 21) got condition
05:22:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:22:31 HBMASTER: Trying to run another job!
05:22:31 job_callback for (8, 0, 21) finished
05:22:31 start sampling a new configuration.
05:22:31 done sampling a new configuration.
05:22:31 HBMASTER: schedule new run for iteration 8
05:22:31 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
05:22:31 HBMASTER: submitting job (8, 0, 22) to dispatcher
05:22:31 DISPATCHER: trying to submit job (8, 0, 22)
05:22:31 DISPATCHER: trying to notify the job_runner thread.
05:22:31 HBMASTER: job (8, 0, 22) submitted to dispatcher
05:22:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:22:31 DISPATCHER: Trying to submit another job.
05:22:31 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:22:31 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:22:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:22:31 WORKER: start processing job (8, 0, 22)
05:22:31 WORKER: args: ()
05:22:31 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.008051738530869669, 'num_filters_1': 93, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.04647507033389811, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 38, 'num_filters_3': 127}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:23:21 DISPATCHER: Starting worker discovery
05:23:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:23:21 DISPATCHER: Finished worker discovery
05:24:10 WORKER: done with job (8, 0, 22), trying to register it.
05:24:10 WORKER: registered result for job (8, 0, 22) with dispatcher
05:24:10 DISPATCHER: job (8, 0, 22) finished
05:24:10 DISPATCHER: register_result: lock acquired
05:24:10 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
05:24:10 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.008051738530869669, 'num_filters_1': 93, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.04647507033389811, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 38, 'num_filters_3': 127}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.41725322755992167, 'info': {'music_genre': 0.41725322755992167, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.008051738530869669, 'num_filters_1': 93, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.04647507033389811, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 38, 'num_filters_3': 127}"}}
exception: None

05:24:10 job_callback for (8, 0, 22) started
05:24:10 job_callback for (8, 0, 22) got condition
05:24:10 DISPATCHER: Trying to submit another job.
05:24:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:24:10 HBMASTER: Trying to run another job!
05:24:10 job_callback for (8, 0, 22) finished
05:24:10 start sampling a new configuration.
05:24:10 done sampling a new configuration.
05:24:10 HBMASTER: schedule new run for iteration 8
05:24:10 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
05:24:10 HBMASTER: submitting job (8, 0, 23) to dispatcher
05:24:10 DISPATCHER: trying to submit job (8, 0, 23)
05:24:10 DISPATCHER: trying to notify the job_runner thread.
05:24:10 HBMASTER: job (8, 0, 23) submitted to dispatcher
05:24:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:24:10 DISPATCHER: Trying to submit another job.
05:24:10 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:24:10 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:24:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:24:10 WORKER: start processing job (8, 0, 23)
05:24:10 WORKER: args: ()
05:24:10 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.011920484363275672, 'num_filters_1': 59, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.020642642719908014, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 41, 'num_filters_3': 19, 'num_filters_4': 32, 'num_filters_5': 50}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:24:21 DISPATCHER: Starting worker discovery
05:24:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:24:21 DISPATCHER: Finished worker discovery
05:25:21 DISPATCHER: Starting worker discovery
05:25:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:25:21 DISPATCHER: Finished worker discovery
05:25:47 WORKER: done with job (8, 0, 23), trying to register it.
05:25:47 WORKER: registered result for job (8, 0, 23) with dispatcher
05:25:47 DISPATCHER: job (8, 0, 23) finished
05:25:47 DISPATCHER: register_result: lock acquired
05:25:47 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
05:25:47 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.011920484363275672, 'num_filters_1': 59, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.020642642719908014, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 41, 'num_filters_3': 19, 'num_filters_4': 32, 'num_filters_5': 50}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.30226494481584404, 'info': {'music_genre': 0.30226494481584404, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.011920484363275672, 'num_filters_1': 59, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.020642642719908014, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 41, 'num_filters_3': 19, 'num_filters_4': 32, 'num_filters_5': 50}"}}
exception: None

05:25:47 job_callback for (8, 0, 23) started
05:25:47 job_callback for (8, 0, 23) got condition
05:25:47 DISPATCHER: Trying to submit another job.
05:25:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:25:47 HBMASTER: Trying to run another job!
05:25:47 job_callback for (8, 0, 23) finished
05:25:47 start sampling a new configuration.
05:25:47 done sampling a new configuration.
05:25:47 HBMASTER: schedule new run for iteration 8
05:25:47 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
05:25:47 HBMASTER: submitting job (8, 0, 24) to dispatcher
05:25:47 DISPATCHER: trying to submit job (8, 0, 24)
05:25:47 DISPATCHER: trying to notify the job_runner thread.
05:25:47 HBMASTER: job (8, 0, 24) submitted to dispatcher
05:25:47 DISPATCHER: Trying to submit another job.
05:25:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:25:47 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:25:47 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:25:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:25:47 WORKER: start processing job (8, 0, 24)
05:25:47 WORKER: args: ()
05:25:47 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.03915324611889184, 'num_filters_1': 40, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.05107823368928771, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 16, 'num_filters_3': 37, 'num_filters_4': 45, 'num_filters_5': 85}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:26:21 DISPATCHER: Starting worker discovery
05:26:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:26:21 DISPATCHER: Finished worker discovery
05:27:21 DISPATCHER: Starting worker discovery
05:27:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:27:21 DISPATCHER: Finished worker discovery
05:27:26 WORKER: done with job (8, 0, 24), trying to register it.
05:27:26 WORKER: registered result for job (8, 0, 24) with dispatcher
05:27:26 DISPATCHER: job (8, 0, 24) finished
05:27:26 DISPATCHER: register_result: lock acquired
05:27:26 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
05:27:26 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.03915324611889184, 'num_filters_1': 40, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.05107823368928771, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 16, 'num_filters_3': 37, 'num_filters_4': 45, 'num_filters_5': 85}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music_genre': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.03915324611889184, 'num_filters_1': 40, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.05107823368928771, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 16, 'num_filters_3': 37, 'num_filters_4': 45, 'num_filters_5': 85}"}}
exception: None

05:27:26 job_callback for (8, 0, 24) started
05:27:26 DISPATCHER: Trying to submit another job.
05:27:26 job_callback for (8, 0, 24) got condition
05:27:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:27:26 HBMASTER: Trying to run another job!
05:27:26 job_callback for (8, 0, 24) finished
05:27:26 start sampling a new configuration.
05:27:27 best_vector: [0, 1, 0.26614270502416454, 0.46884778378007225, 0.6848697361357593, 1, 0.015700589036663215, 0.6203579373489322, 0, 2, 0, 2, 0.5351556017440697, 0.7321616094985837, 0.012882663223193203, 0.07788973606046723], 2.5131611470847565e-05, 0.00259364857151886, 6.518256819133078e-08
05:27:27 done sampling a new configuration.
05:27:27 HBMASTER: schedule new run for iteration 8
05:27:27 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
05:27:27 HBMASTER: submitting job (8, 0, 25) to dispatcher
05:27:27 DISPATCHER: trying to submit job (8, 0, 25)
05:27:27 DISPATCHER: trying to notify the job_runner thread.
05:27:27 HBMASTER: job (8, 0, 25) submitted to dispatcher
05:27:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:27:27 DISPATCHER: Trying to submit another job.
05:27:27 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:27:27 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:27:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:27:27 WORKER: start processing job (8, 0, 25)
05:27:27 WORKER: args: ()
05:27:27 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0034063197299419577, 'num_filters_1': 42, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.06413635648972142, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 48, 'num_filters_3': 73, 'num_filters_4': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:28:21 DISPATCHER: Starting worker discovery
05:28:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:28:21 DISPATCHER: Finished worker discovery
05:29:06 WORKER: done with job (8, 0, 25), trying to register it.
05:29:06 WORKER: registered result for job (8, 0, 25) with dispatcher
05:29:06 DISPATCHER: job (8, 0, 25) finished
05:29:06 DISPATCHER: register_result: lock acquired
05:29:06 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
05:29:06 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0034063197299419577, 'num_filters_1': 42, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.06413635648972142, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 48, 'num_filters_3': 73, 'num_filters_4': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3018752560155518, 'info': {'music_genre': 0.3018752560155518, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0034063197299419577, 'num_filters_1': 42, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.06413635648972142, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 48, 'num_filters_3': 73, 'num_filters_4': 16}"}}
exception: None

05:29:06 job_callback for (8, 0, 25) started
05:29:06 job_callback for (8, 0, 25) got condition
05:29:06 DISPATCHER: Trying to submit another job.
05:29:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:29:06 HBMASTER: Trying to run another job!
05:29:06 job_callback for (8, 0, 25) finished
05:29:06 start sampling a new configuration.
05:29:06 done sampling a new configuration.
05:29:06 HBMASTER: schedule new run for iteration 8
05:29:06 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
05:29:06 HBMASTER: submitting job (8, 0, 26) to dispatcher
05:29:06 DISPATCHER: trying to submit job (8, 0, 26)
05:29:06 DISPATCHER: trying to notify the job_runner thread.
05:29:06 HBMASTER: job (8, 0, 26) submitted to dispatcher
05:29:06 DISPATCHER: Trying to submit another job.
05:29:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:29:06 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:29:06 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:29:06 WORKER: start processing job (8, 0, 26)
05:29:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:29:06 WORKER: args: ()
05:29:06 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.005502044176052163, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.013173214986036543}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:29:21 DISPATCHER: Starting worker discovery
05:29:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:29:21 DISPATCHER: Finished worker discovery
05:30:21 DISPATCHER: Starting worker discovery
05:30:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:30:21 DISPATCHER: Finished worker discovery
05:30:45 WORKER: done with job (8, 0, 26), trying to register it.
05:30:45 WORKER: registered result for job (8, 0, 26) with dispatcher
05:30:45 DISPATCHER: job (8, 0, 26) finished
05:30:45 DISPATCHER: register_result: lock acquired
05:30:45 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
05:30:45 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.005502044176052163, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.013173214986036543}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4353955811393572, 'info': {'music_genre': 0.4353955811393572, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.005502044176052163, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.013173214986036543}"}}
exception: None

05:30:45 job_callback for (8, 0, 26) started
05:30:45 job_callback for (8, 0, 26) got condition
05:30:45 DISPATCHER: Trying to submit another job.
05:30:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:30:45 HBMASTER: Trying to run another job!
05:30:45 job_callback for (8, 0, 26) finished
05:30:45 ITERATION: Advancing config (8, 0, 0) to next budget 133.333333
05:30:45 ITERATION: Advancing config (8, 0, 4) to next budget 133.333333
05:30:45 ITERATION: Advancing config (8, 0, 5) to next budget 133.333333
05:30:45 ITERATION: Advancing config (8, 0, 6) to next budget 133.333333
05:30:45 ITERATION: Advancing config (8, 0, 7) to next budget 133.333333
05:30:45 ITERATION: Advancing config (8, 0, 12) to next budget 133.333333
05:30:45 ITERATION: Advancing config (8, 0, 17) to next budget 133.333333
05:30:45 ITERATION: Advancing config (8, 0, 21) to next budget 133.333333
05:30:45 ITERATION: Advancing config (8, 0, 26) to next budget 133.333333
05:30:45 HBMASTER: schedule new run for iteration 8
05:30:45 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
05:30:45 HBMASTER: submitting job (8, 0, 0) to dispatcher
05:30:45 DISPATCHER: trying to submit job (8, 0, 0)
05:30:45 DISPATCHER: trying to notify the job_runner thread.
05:30:45 HBMASTER: job (8, 0, 0) submitted to dispatcher
05:30:45 DISPATCHER: Trying to submit another job.
05:30:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:30:45 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:30:45 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:30:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:30:45 WORKER: start processing job (8, 0, 0)
05:30:45 WORKER: args: ()
05:30:45 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0014065041462222143, 'num_filters_1': 97, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.016662814764578603, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 71, 'num_filters_3': 50, 'num_filters_4': 17}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:31:21 DISPATCHER: Starting worker discovery
05:31:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:31:21 DISPATCHER: Finished worker discovery
05:32:21 DISPATCHER: Starting worker discovery
05:32:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:32:21 DISPATCHER: Finished worker discovery
05:33:21 DISPATCHER: Starting worker discovery
05:33:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:33:21 DISPATCHER: Finished worker discovery
05:33:55 WORKER: done with job (8, 0, 0), trying to register it.
05:33:55 WORKER: registered result for job (8, 0, 0) with dispatcher
05:33:55 DISPATCHER: job (8, 0, 0) finished
05:33:55 DISPATCHER: register_result: lock acquired
05:33:55 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
05:33:55 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0014065041462222143, 'num_filters_1': 97, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.016662814764578603, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 71, 'num_filters_3': 50, 'num_filters_4': 17}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.484492426420982, 'info': {'music_genre': 0.484492426420982, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0014065041462222143, 'num_filters_1': 97, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.016662814764578603, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 71, 'num_filters_3': 50, 'num_filters_4': 17}"}}
exception: None

05:33:55 job_callback for (8, 0, 0) started
05:33:55 job_callback for (8, 0, 0) got condition
05:33:55 DISPATCHER: Trying to submit another job.
05:33:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:33:55 done building a new model for budget 133.333333 based on 17/31 split
Best loss for this budget:-0.510625





05:33:55 HBMASTER: Trying to run another job!
05:33:55 job_callback for (8, 0, 0) finished
05:33:55 HBMASTER: schedule new run for iteration 8
05:33:55 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
05:33:55 HBMASTER: submitting job (8, 0, 4) to dispatcher
05:33:55 DISPATCHER: trying to submit job (8, 0, 4)
05:33:55 DISPATCHER: trying to notify the job_runner thread.
05:33:55 HBMASTER: job (8, 0, 4) submitted to dispatcher
05:33:55 DISPATCHER: Trying to submit another job.
05:33:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:33:55 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:33:55 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:33:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:33:55 WORKER: start processing job (8, 0, 4)
05:33:55 WORKER: args: ()
05:33:55 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0036002601421478223, 'num_filters_1': 47, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.010491955325571258}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:34:21 DISPATCHER: Starting worker discovery
05:34:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:34:21 DISPATCHER: Finished worker discovery
05:35:21 DISPATCHER: Starting worker discovery
05:35:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:35:21 DISPATCHER: Finished worker discovery
05:36:21 DISPATCHER: Starting worker discovery
05:36:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:36:21 DISPATCHER: Finished worker discovery
05:37:03 WORKER: done with job (8, 0, 4), trying to register it.
05:37:03 WORKER: registered result for job (8, 0, 4) with dispatcher
05:37:03 DISPATCHER: job (8, 0, 4) finished
05:37:03 DISPATCHER: register_result: lock acquired
05:37:03 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
05:37:03 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0036002601421478223, 'num_filters_1': 47, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.010491955325571258}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.46616984020592755, 'info': {'music_genre': 0.46616984020592755, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0036002601421478223, 'num_filters_1': 47, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.010491955325571258}"}}
exception: None

05:37:03 job_callback for (8, 0, 4) started
05:37:03 DISPATCHER: Trying to submit another job.
05:37:03 job_callback for (8, 0, 4) got condition
05:37:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:37:03 done building a new model for budget 133.333333 based on 17/32 split
Best loss for this budget:-0.510625





05:37:03 HBMASTER: Trying to run another job!
05:37:03 job_callback for (8, 0, 4) finished
05:37:03 HBMASTER: schedule new run for iteration 8
05:37:03 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
05:37:03 HBMASTER: submitting job (8, 0, 5) to dispatcher
05:37:03 DISPATCHER: trying to submit job (8, 0, 5)
05:37:03 DISPATCHER: trying to notify the job_runner thread.
05:37:03 HBMASTER: job (8, 0, 5) submitted to dispatcher
05:37:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:37:03 DISPATCHER: Trying to submit another job.
05:37:03 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:37:03 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:37:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:37:03 WORKER: start processing job (8, 0, 5)
05:37:03 WORKER: args: ()
05:37:03 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0023306646408541533, 'num_filters_1': 114, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.1399238959521692, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 25, 'num_filters_3': 82, 'num_filters_4': 17, 'num_filters_5': 72}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:37:21 DISPATCHER: Starting worker discovery
05:37:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:37:21 DISPATCHER: Finished worker discovery
05:38:21 DISPATCHER: Starting worker discovery
05:38:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:38:21 DISPATCHER: Finished worker discovery
05:39:21 DISPATCHER: Starting worker discovery
05:39:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:39:21 DISPATCHER: Finished worker discovery
05:40:12 WORKER: done with job (8, 0, 5), trying to register it.
05:40:12 WORKER: registered result for job (8, 0, 5) with dispatcher
05:40:12 DISPATCHER: job (8, 0, 5) finished
05:40:12 DISPATCHER: register_result: lock acquired
05:40:12 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
05:40:12 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0023306646408541533, 'num_filters_1': 114, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.1399238959521692, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 25, 'num_filters_3': 82, 'num_filters_4': 17, 'num_filters_5': 72}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.38893102503450927, 'info': {'music_genre': 0.38893102503450927, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0023306646408541533, 'num_filters_1': 114, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.1399238959521692, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 25, 'num_filters_3': 82, 'num_filters_4': 17, 'num_filters_5': 72}"}}
exception: None

05:40:12 job_callback for (8, 0, 5) started
05:40:12 job_callback for (8, 0, 5) got condition
05:40:12 DISPATCHER: Trying to submit another job.
05:40:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:40:12 done building a new model for budget 133.333333 based on 17/33 split
Best loss for this budget:-0.510625





05:40:12 HBMASTER: Trying to run another job!
05:40:12 job_callback for (8, 0, 5) finished
05:40:12 HBMASTER: schedule new run for iteration 8
05:40:12 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
05:40:12 HBMASTER: submitting job (8, 0, 6) to dispatcher
05:40:12 DISPATCHER: trying to submit job (8, 0, 6)
05:40:12 DISPATCHER: trying to notify the job_runner thread.
05:40:12 HBMASTER: job (8, 0, 6) submitted to dispatcher
05:40:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:40:12 DISPATCHER: Trying to submit another job.
05:40:12 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:40:12 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:40:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:40:12 WORKER: start processing job (8, 0, 6)
05:40:12 WORKER: args: ()
05:40:12 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0016481308043813276, 'num_filters_1': 40, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.058223523117562556, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 72, 'num_filters_3': 89, 'num_filters_4': 18}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:40:21 DISPATCHER: Starting worker discovery
05:40:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:40:21 DISPATCHER: Finished worker discovery
05:41:21 DISPATCHER: Starting worker discovery
05:41:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:41:21 DISPATCHER: Finished worker discovery
05:42:21 DISPATCHER: Starting worker discovery
05:42:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:42:21 DISPATCHER: Finished worker discovery
05:43:20 WORKER: done with job (8, 0, 6), trying to register it.
05:43:20 WORKER: registered result for job (8, 0, 6) with dispatcher
05:43:20 DISPATCHER: job (8, 0, 6) finished
05:43:20 DISPATCHER: register_result: lock acquired
05:43:20 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
05:43:20 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0016481308043813276, 'num_filters_1': 40, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.058223523117562556, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 72, 'num_filters_3': 89, 'num_filters_4': 18}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.43684267451645403, 'info': {'music_genre': 0.43684267451645403, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0016481308043813276, 'num_filters_1': 40, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.058223523117562556, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 72, 'num_filters_3': 89, 'num_filters_4': 18}"}}
exception: None

05:43:20 job_callback for (8, 0, 6) started
05:43:20 DISPATCHER: Trying to submit another job.
05:43:20 job_callback for (8, 0, 6) got condition
05:43:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:43:20 done building a new model for budget 133.333333 based on 17/34 split
Best loss for this budget:-0.510625





05:43:20 HBMASTER: Trying to run another job!
05:43:20 job_callback for (8, 0, 6) finished
05:43:20 HBMASTER: schedule new run for iteration 8
05:43:20 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
05:43:20 HBMASTER: submitting job (8, 0, 7) to dispatcher
05:43:20 DISPATCHER: trying to submit job (8, 0, 7)
05:43:20 DISPATCHER: trying to notify the job_runner thread.
05:43:20 HBMASTER: job (8, 0, 7) submitted to dispatcher
05:43:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:43:20 DISPATCHER: Trying to submit another job.
05:43:20 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:43:20 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:43:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:43:20 WORKER: start processing job (8, 0, 7)
05:43:20 WORKER: args: ()
05:43:20 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0014529606263412734, 'num_filters_1': 65, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.029403812920619835}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:43:21 DISPATCHER: Starting worker discovery
05:43:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:43:21 DISPATCHER: Finished worker discovery
05:44:21 DISPATCHER: Starting worker discovery
05:44:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:44:21 DISPATCHER: Finished worker discovery
05:45:21 DISPATCHER: Starting worker discovery
05:45:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:45:21 DISPATCHER: Finished worker discovery
05:46:21 DISPATCHER: Starting worker discovery
05:46:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:46:21 DISPATCHER: Finished worker discovery
05:46:30 WORKER: done with job (8, 0, 7), trying to register it.
05:46:30 WORKER: registered result for job (8, 0, 7) with dispatcher
05:46:30 DISPATCHER: job (8, 0, 7) finished
05:46:30 DISPATCHER: register_result: lock acquired
05:46:30 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
05:46:30 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0014529606263412734, 'num_filters_1': 65, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.029403812920619835}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4583318875910603, 'info': {'music_genre': 0.4583318875910603, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0014529606263412734, 'num_filters_1': 65, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.029403812920619835}"}}
exception: None

05:46:30 job_callback for (8, 0, 7) started
05:46:30 DISPATCHER: Trying to submit another job.
05:46:30 job_callback for (8, 0, 7) got condition
05:46:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:46:30 done building a new model for budget 133.333333 based on 17/34 split
Best loss for this budget:-0.510625





05:46:30 HBMASTER: Trying to run another job!
05:46:30 job_callback for (8, 0, 7) finished
05:46:30 HBMASTER: schedule new run for iteration 8
05:46:30 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
05:46:30 HBMASTER: submitting job (8, 0, 12) to dispatcher
05:46:30 DISPATCHER: trying to submit job (8, 0, 12)
05:46:30 DISPATCHER: trying to notify the job_runner thread.
05:46:30 HBMASTER: job (8, 0, 12) submitted to dispatcher
05:46:30 DISPATCHER: Trying to submit another job.
05:46:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:46:30 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:46:30 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:46:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:46:30 WORKER: start processing job (8, 0, 12)
05:46:30 WORKER: args: ()
05:46:30 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.006127508391915043, 'num_filters_1': 40, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.020724937374034177, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 67, 'num_filters_3': 59, 'num_filters_4': 19, 'num_filters_5': 17}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:47:21 DISPATCHER: Starting worker discovery
05:47:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:47:21 DISPATCHER: Finished worker discovery
05:48:21 DISPATCHER: Starting worker discovery
05:48:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:48:21 DISPATCHER: Finished worker discovery
05:49:21 DISPATCHER: Starting worker discovery
05:49:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:49:21 DISPATCHER: Finished worker discovery
05:49:38 WORKER: done with job (8, 0, 12), trying to register it.
05:49:38 WORKER: registered result for job (8, 0, 12) with dispatcher
05:49:38 DISPATCHER: job (8, 0, 12) finished
05:49:38 DISPATCHER: register_result: lock acquired
05:49:38 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
05:49:38 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.006127508391915043, 'num_filters_1': 40, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.020724937374034177, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 67, 'num_filters_3': 59, 'num_filters_4': 19, 'num_filters_5': 17}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.37121192599116126, 'info': {'music_genre': 0.37121192599116126, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.006127508391915043, 'num_filters_1': 40, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.020724937374034177, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 67, 'num_filters_3': 59, 'num_filters_4': 19, 'num_filters_5': 17}"}}
exception: None

05:49:38 job_callback for (8, 0, 12) started
05:49:38 DISPATCHER: Trying to submit another job.
05:49:38 job_callback for (8, 0, 12) got condition
05:49:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:49:38 done building a new model for budget 133.333333 based on 17/35 split
Best loss for this budget:-0.510625





05:49:38 HBMASTER: Trying to run another job!
05:49:38 job_callback for (8, 0, 12) finished
05:49:38 HBMASTER: schedule new run for iteration 8
05:49:38 HBMASTER: trying submitting job (8, 0, 17) to dispatcher
05:49:38 HBMASTER: submitting job (8, 0, 17) to dispatcher
05:49:38 DISPATCHER: trying to submit job (8, 0, 17)
05:49:38 DISPATCHER: trying to notify the job_runner thread.
05:49:38 HBMASTER: job (8, 0, 17) submitted to dispatcher
05:49:38 DISPATCHER: Trying to submit another job.
05:49:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:49:38 DISPATCHER: starting job (8, 0, 17) on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:49:38 DISPATCHER: job (8, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:49:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:49:38 WORKER: start processing job (8, 0, 17)
05:49:38 WORKER: args: ()
05:49:38 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0014485247098262794, 'num_filters_1': 80, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.03695233814157306, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 66, 'num_filters_3': 127, 'num_filters_4': 16, 'num_filters_5': 20}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:50:21 DISPATCHER: Starting worker discovery
05:50:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:50:21 DISPATCHER: Finished worker discovery
05:51:21 DISPATCHER: Starting worker discovery
05:51:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:51:21 DISPATCHER: Finished worker discovery
05:52:21 DISPATCHER: Starting worker discovery
05:52:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:52:21 DISPATCHER: Finished worker discovery
05:52:47 WORKER: done with job (8, 0, 17), trying to register it.
05:52:47 WORKER: registered result for job (8, 0, 17) with dispatcher
05:52:47 DISPATCHER: job (8, 0, 17) finished
05:52:47 DISPATCHER: register_result: lock acquired
05:52:47 DISPATCHER: job (8, 0, 17) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
05:52:47 job_id: (8, 0, 17)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0014485247098262794, 'num_filters_1': 80, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.03695233814157306, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 66, 'num_filters_3': 127, 'num_filters_4': 16, 'num_filters_5': 20}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4207524079217361, 'info': {'music_genre': 0.4207524079217361, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0014485247098262794, 'num_filters_1': 80, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.03695233814157306, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 66, 'num_filters_3': 127, 'num_filters_4': 16, 'num_filters_5': 20}"}}
exception: None

05:52:47 job_callback for (8, 0, 17) started
05:52:47 job_callback for (8, 0, 17) got condition
05:52:47 DISPATCHER: Trying to submit another job.
05:52:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:52:47 done building a new model for budget 133.333333 based on 17/36 split
Best loss for this budget:-0.510625





05:52:47 HBMASTER: Trying to run another job!
05:52:47 job_callback for (8, 0, 17) finished
05:52:47 HBMASTER: schedule new run for iteration 8
05:52:47 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
05:52:47 HBMASTER: submitting job (8, 0, 21) to dispatcher
05:52:47 DISPATCHER: trying to submit job (8, 0, 21)
05:52:47 DISPATCHER: trying to notify the job_runner thread.
05:52:47 HBMASTER: job (8, 0, 21) submitted to dispatcher
05:52:47 DISPATCHER: Trying to submit another job.
05:52:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:52:47 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:52:47 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:52:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:52:47 WORKER: start processing job (8, 0, 21)
05:52:47 WORKER: args: ()
05:52:47 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002434815195683213, 'num_filters_1': 87, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.011170986307186003, 'kernel_size_2': 7, 'num_filters_2': 83}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:53:21 DISPATCHER: Starting worker discovery
05:53:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:53:21 DISPATCHER: Finished worker discovery
05:54:21 DISPATCHER: Starting worker discovery
05:54:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:54:21 DISPATCHER: Finished worker discovery
05:55:21 DISPATCHER: Starting worker discovery
05:55:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:55:21 DISPATCHER: Finished worker discovery
05:55:58 WORKER: done with job (8, 0, 21), trying to register it.
05:55:58 WORKER: registered result for job (8, 0, 21) with dispatcher
05:55:58 DISPATCHER: job (8, 0, 21) finished
05:55:58 DISPATCHER: register_result: lock acquired
05:55:58 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
05:55:58 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002434815195683213, 'num_filters_1': 87, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.011170986307186003, 'kernel_size_2': 7, 'num_filters_2': 83}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.45237026124169244, 'info': {'music_genre': 0.45237026124169244, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002434815195683213, 'num_filters_1': 87, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.011170986307186003, 'kernel_size_2': 7, 'num_filters_2': 83}"}}
exception: None

05:55:58 job_callback for (8, 0, 21) started
05:55:58 DISPATCHER: Trying to submit another job.
05:55:58 job_callback for (8, 0, 21) got condition
05:55:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:55:58 done building a new model for budget 133.333333 based on 17/37 split
Best loss for this budget:-0.510625





05:55:58 HBMASTER: Trying to run another job!
05:55:58 job_callback for (8, 0, 21) finished
05:55:58 HBMASTER: schedule new run for iteration 8
05:55:58 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
05:55:58 HBMASTER: submitting job (8, 0, 26) to dispatcher
05:55:58 DISPATCHER: trying to submit job (8, 0, 26)
05:55:58 DISPATCHER: trying to notify the job_runner thread.
05:55:58 HBMASTER: job (8, 0, 26) submitted to dispatcher
05:55:58 DISPATCHER: Trying to submit another job.
05:55:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:55:58 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:55:58 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:55:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:55:58 WORKER: start processing job (8, 0, 26)
05:55:58 WORKER: args: ()
05:55:58 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.005502044176052163, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.013173214986036543}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:56:21 DISPATCHER: Starting worker discovery
05:56:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:56:21 DISPATCHER: Finished worker discovery
05:57:21 DISPATCHER: Starting worker discovery
05:57:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:57:22 DISPATCHER: Finished worker discovery
05:58:22 DISPATCHER: Starting worker discovery
05:58:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:58:22 DISPATCHER: Finished worker discovery
05:59:10 WORKER: done with job (8, 0, 26), trying to register it.
05:59:10 WORKER: registered result for job (8, 0, 26) with dispatcher
05:59:10 DISPATCHER: job (8, 0, 26) finished
05:59:10 DISPATCHER: register_result: lock acquired
05:59:10 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
05:59:10 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.005502044176052163, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.013173214986036543}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3768775087344362, 'info': {'music_genre': 0.3768775087344362, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.005502044176052163, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.013173214986036543}"}}
exception: None

05:59:10 job_callback for (8, 0, 26) started
05:59:10 DISPATCHER: Trying to submit another job.
05:59:10 job_callback for (8, 0, 26) got condition
05:59:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:59:10 done building a new model for budget 133.333333 based on 17/38 split
Best loss for this budget:-0.510625





05:59:10 HBMASTER: Trying to run another job!
05:59:10 job_callback for (8, 0, 26) finished
05:59:10 ITERATION: Advancing config (8, 0, 0) to next budget 400.000000
05:59:10 ITERATION: Advancing config (8, 0, 4) to next budget 400.000000
05:59:10 ITERATION: Advancing config (8, 0, 7) to next budget 400.000000
05:59:10 HBMASTER: schedule new run for iteration 8
05:59:10 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
05:59:10 HBMASTER: submitting job (8, 0, 0) to dispatcher
05:59:10 DISPATCHER: trying to submit job (8, 0, 0)
05:59:10 DISPATCHER: trying to notify the job_runner thread.
05:59:10 HBMASTER: job (8, 0, 0) submitted to dispatcher
05:59:10 DISPATCHER: Trying to submit another job.
05:59:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:59:10 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:59:10 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
05:59:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:59:10 WORKER: start processing job (8, 0, 0)
05:59:10 WORKER: args: ()
05:59:10 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0014065041462222143, 'num_filters_1': 97, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.016662814764578603, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 71, 'num_filters_3': 50, 'num_filters_4': 17}, 'budget': 400.0, 'working_directory': '.'}
05:59:22 DISPATCHER: Starting worker discovery
05:59:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:59:22 DISPATCHER: Finished worker discovery
06:00:22 DISPATCHER: Starting worker discovery
06:00:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:00:22 DISPATCHER: Finished worker discovery
06:01:22 DISPATCHER: Starting worker discovery
06:01:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:01:22 DISPATCHER: Finished worker discovery
06:02:22 DISPATCHER: Starting worker discovery
06:02:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:02:22 DISPATCHER: Finished worker discovery
06:03:22 DISPATCHER: Starting worker discovery
06:03:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:03:22 DISPATCHER: Finished worker discovery
06:04:22 DISPATCHER: Starting worker discovery
06:04:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:04:22 DISPATCHER: Finished worker discovery
06:05:22 DISPATCHER: Starting worker discovery
06:05:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:05:22 DISPATCHER: Finished worker discovery
06:06:22 DISPATCHER: Starting worker discovery
06:06:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:06:22 DISPATCHER: Finished worker discovery
06:06:47 WORKER: done with job (8, 0, 0), trying to register it.
06:06:47 WORKER: registered result for job (8, 0, 0) with dispatcher
06:06:47 DISPATCHER: job (8, 0, 0) finished
06:06:47 DISPATCHER: register_result: lock acquired
06:06:47 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
06:06:47 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0014065041462222143, 'num_filters_1': 97, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.016662814764578603, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 71, 'num_filters_3': 50, 'num_filters_4': 17}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.38974257786141564, 'info': {'music_genre': 0.38974257786141564, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0014065041462222143, 'num_filters_1': 97, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.016662814764578603, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 71, 'num_filters_3': 50, 'num_filters_4': 17}"}}
exception: None

06:06:47 job_callback for (8, 0, 0) started
06:06:47 DISPATCHER: Trying to submit another job.
06:06:47 job_callback for (8, 0, 0) got condition
06:06:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:06:47 HBMASTER: Trying to run another job!
06:06:47 job_callback for (8, 0, 0) finished
06:06:47 HBMASTER: schedule new run for iteration 8
06:06:47 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
06:06:47 HBMASTER: submitting job (8, 0, 4) to dispatcher
06:06:47 DISPATCHER: trying to submit job (8, 0, 4)
06:06:47 DISPATCHER: trying to notify the job_runner thread.
06:06:47 HBMASTER: job (8, 0, 4) submitted to dispatcher
06:06:47 DISPATCHER: Trying to submit another job.
06:06:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:06:47 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
06:06:47 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
06:06:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:06:47 WORKER: start processing job (8, 0, 4)
06:06:47 WORKER: args: ()
06:06:47 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0036002601421478223, 'num_filters_1': 47, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.010491955325571258}, 'budget': 400.0, 'working_directory': '.'}
06:07:22 DISPATCHER: Starting worker discovery
06:07:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:07:22 DISPATCHER: Finished worker discovery
06:08:22 DISPATCHER: Starting worker discovery
06:08:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:08:22 DISPATCHER: Finished worker discovery
06:09:22 DISPATCHER: Starting worker discovery
06:09:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:09:22 DISPATCHER: Finished worker discovery
06:10:22 DISPATCHER: Starting worker discovery
06:10:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:10:22 DISPATCHER: Finished worker discovery
06:11:22 DISPATCHER: Starting worker discovery
06:11:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:11:22 DISPATCHER: Finished worker discovery
06:12:22 DISPATCHER: Starting worker discovery
06:12:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:12:22 DISPATCHER: Finished worker discovery
06:13:22 DISPATCHER: Starting worker discovery
06:13:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:13:22 DISPATCHER: Finished worker discovery
06:14:22 DISPATCHER: Starting worker discovery
06:14:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:14:22 DISPATCHER: Finished worker discovery
06:14:24 WORKER: done with job (8, 0, 4), trying to register it.
06:14:24 WORKER: registered result for job (8, 0, 4) with dispatcher
06:14:24 DISPATCHER: job (8, 0, 4) finished
06:14:24 DISPATCHER: register_result: lock acquired
06:14:24 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
06:14:24 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0036002601421478223, 'num_filters_1': 47, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.010491955325571258}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.38494620065891727, 'info': {'music_genre': 0.38494620065891727, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0036002601421478223, 'num_filters_1': 47, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.010491955325571258}"}}
exception: None

06:14:24 job_callback for (8, 0, 4) started
06:14:24 job_callback for (8, 0, 4) got condition
06:14:24 DISPATCHER: Trying to submit another job.
06:14:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:14:24 HBMASTER: Trying to run another job!
06:14:24 job_callback for (8, 0, 4) finished
06:14:24 HBMASTER: schedule new run for iteration 8
06:14:24 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
06:14:24 HBMASTER: submitting job (8, 0, 7) to dispatcher
06:14:24 DISPATCHER: trying to submit job (8, 0, 7)
06:14:24 DISPATCHER: trying to notify the job_runner thread.
06:14:24 HBMASTER: job (8, 0, 7) submitted to dispatcher
06:14:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:14:24 DISPATCHER: Trying to submit another job.
06:14:24 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952
06:14:24 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
06:14:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:14:24 WORKER: start processing job (8, 0, 7)
06:14:24 WORKER: args: ()
06:14:24 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0014529606263412734, 'num_filters_1': 65, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.029403812920619835}, 'budget': 400.0, 'working_directory': '.'}
06:15:22 DISPATCHER: Starting worker discovery
06:15:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:15:22 DISPATCHER: Finished worker discovery
06:16:22 DISPATCHER: Starting worker discovery
06:16:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:16:22 DISPATCHER: Finished worker discovery
06:17:22 DISPATCHER: Starting worker discovery
06:17:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:17:22 DISPATCHER: Finished worker discovery
06:18:22 DISPATCHER: Starting worker discovery
06:18:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:18:22 DISPATCHER: Finished worker discovery
06:19:22 DISPATCHER: Starting worker discovery
06:19:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:19:22 DISPATCHER: Finished worker discovery
06:20:22 DISPATCHER: Starting worker discovery
06:20:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:20:22 DISPATCHER: Finished worker discovery
06:21:22 DISPATCHER: Starting worker discovery
06:21:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:21:22 DISPATCHER: Finished worker discovery
06:22:02 WORKER: done with job (8, 0, 7), trying to register it.
06:22:02 WORKER: registered result for job (8, 0, 7) with dispatcher
06:22:02 DISPATCHER: job (8, 0, 7) finished
06:22:02 DISPATCHER: register_result: lock acquired
06:22:02 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
06:22:02 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0014529606263412734, 'num_filters_1': 65, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.029403812920619835}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.37547863134884696, 'info': {'music_genre': 0.37547863134884696, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0014529606263412734, 'num_filters_1': 65, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.029403812920619835}"}}
exception: None

06:22:02 job_callback for (8, 0, 7) started
06:22:02 job_callback for (8, 0, 7) got condition
06:22:02 DISPATCHER: Trying to submit another job.
06:22:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:22:02 HBMASTER: Trying to run another job!
06:22:02 job_callback for (8, 0, 7) finished
06:22:02 ITERATION: Advancing config (8, 0, 0) to next budget 1200.000000
06:22:02 HBMASTER: schedule new run for iteration 8
06:22:02 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
06:22:02 HBMASTER: submitting job (8, 0, 0) to dispatcher
06:22:02 DISPATCHER: trying to submit job (8, 0, 0)
06:22:02 DISPATCHER: trying to notify the job_runner thread.
06:22:02 HBMASTER: job (8, 0, 0) submitted to dispatcher
06:22:02 DISPATCHER: Trying to submit another job.
06:22:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:22:02 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
06:22:02 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
06:22:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:22:02 WORKER: start processing job (8, 0, 0)
06:22:02 WORKER: args: ()
06:22:02 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0014065041462222143, 'num_filters_1': 97, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.016662814764578603, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 71, 'num_filters_3': 50, 'num_filters_4': 17}, 'budget': 1200.0, 'working_directory': '.'}
06:22:22 DISPATCHER: Starting worker discovery
06:22:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:22:22 DISPATCHER: Finished worker discovery
06:23:22 DISPATCHER: Starting worker discovery
06:23:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:23:22 DISPATCHER: Finished worker discovery
06:24:22 DISPATCHER: Starting worker discovery
06:24:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:24:22 DISPATCHER: Finished worker discovery
06:25:22 DISPATCHER: Starting worker discovery
06:25:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:25:22 DISPATCHER: Finished worker discovery
06:26:22 DISPATCHER: Starting worker discovery
06:26:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:26:22 DISPATCHER: Finished worker discovery
06:27:22 DISPATCHER: Starting worker discovery
06:27:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:27:22 DISPATCHER: Finished worker discovery
06:28:22 DISPATCHER: Starting worker discovery
06:28:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:28:22 DISPATCHER: Finished worker discovery
06:29:22 DISPATCHER: Starting worker discovery
06:29:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:29:22 DISPATCHER: Finished worker discovery
06:30:22 DISPATCHER: Starting worker discovery
06:30:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:30:22 DISPATCHER: Finished worker discovery
06:31:22 DISPATCHER: Starting worker discovery
06:31:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:31:22 DISPATCHER: Finished worker discovery
06:32:22 DISPATCHER: Starting worker discovery
06:32:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:32:22 DISPATCHER: Finished worker discovery
06:33:22 DISPATCHER: Starting worker discovery
06:33:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:33:22 DISPATCHER: Finished worker discovery
06:34:22 DISPATCHER: Starting worker discovery
06:34:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:34:22 DISPATCHER: Finished worker discovery
06:35:22 DISPATCHER: Starting worker discovery
06:35:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:35:22 DISPATCHER: Finished worker discovery
06:36:22 DISPATCHER: Starting worker discovery
06:36:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:36:22 DISPATCHER: Finished worker discovery
06:37:22 DISPATCHER: Starting worker discovery
06:37:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:37:22 DISPATCHER: Finished worker discovery
06:38:22 DISPATCHER: Starting worker discovery
06:38:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:38:22 DISPATCHER: Finished worker discovery
06:39:22 DISPATCHER: Starting worker discovery
06:39:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:39:22 DISPATCHER: Finished worker discovery
06:40:22 DISPATCHER: Starting worker discovery
06:40:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:40:22 DISPATCHER: Finished worker discovery
06:41:22 DISPATCHER: Starting worker discovery
06:41:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:41:22 DISPATCHER: Finished worker discovery
06:42:22 DISPATCHER: Starting worker discovery
06:42:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:42:22 DISPATCHER: Finished worker discovery
06:43:05 WORKER: done with job (8, 0, 0), trying to register it.
06:43:05 WORKER: registered result for job (8, 0, 0) with dispatcher
06:43:05 DISPATCHER: job (8, 0, 0) finished
06:43:05 DISPATCHER: register_result: lock acquired
06:43:05 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
06:43:05 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0014065041462222143, 'num_filters_1': 97, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.016662814764578603, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 71, 'num_filters_3': 50, 'num_filters_4': 17}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.31308748585146307, 'info': {'music_genre': 0.31308748585146307, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0014065041462222143, 'num_filters_1': 97, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.016662814764578603, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 71, 'num_filters_3': 50, 'num_filters_4': 17}"}}
exception: None

06:43:05 job_callback for (8, 0, 0) started
06:43:05 job_callback for (8, 0, 0) got condition
06:43:05 DISPATCHER: Trying to submit another job.
06:43:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:43:05 HBMASTER: Trying to run another job!
06:43:05 job_callback for (8, 0, 0) finished
06:43:05 start sampling a new configuration.
06:43:05 best_vector: [3, 1, 0.20851762410651137, 0.8106635065092007, 0.9201002600947354, 1, 0.3101206069954186, 0.38518598483093053, 1, 1, 0, 0, 0.9076982490361113, 0.7925309464241033, 0.26973941230570336, 0.49924496869143614], 0.010236620821658372, 0.00349356863887269, 3.5762337470576875e-05
06:43:05 done sampling a new configuration.
06:43:05 HBMASTER: schedule new run for iteration 9
06:43:05 HBMASTER: trying submitting job (9, 0, 0) to dispatcher
06:43:05 HBMASTER: submitting job (9, 0, 0) to dispatcher
06:43:05 DISPATCHER: trying to submit job (9, 0, 0)
06:43:05 DISPATCHER: trying to notify the job_runner thread.
06:43:05 HBMASTER: job (9, 0, 0) submitted to dispatcher
06:43:05 DISPATCHER: Trying to submit another job.
06:43:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:43:05 DISPATCHER: starting job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952
06:43:05 DISPATCHER: job (9, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
06:43:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:43:05 WORKER: start processing job (9, 0, 0)
06:43:05 WORKER: args: ()
06:43:05 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0026123733712685514, 'num_filters_1': 86, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.0317057857205331, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 106, 'num_filters_3': 83, 'num_filters_4': 27, 'num_filters_5': 45}, 'budget': 133.33333333333331, 'working_directory': '.'}
06:43:22 DISPATCHER: Starting worker discovery
06:43:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:43:22 DISPATCHER: Finished worker discovery
06:44:22 DISPATCHER: Starting worker discovery
06:44:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:44:22 DISPATCHER: Finished worker discovery
06:45:22 DISPATCHER: Starting worker discovery
06:45:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:45:22 DISPATCHER: Finished worker discovery
06:46:10 WORKER: done with job (9, 0, 0), trying to register it.
06:46:10 WORKER: registered result for job (9, 0, 0) with dispatcher
06:46:10 DISPATCHER: job (9, 0, 0) finished
06:46:10 DISPATCHER: register_result: lock acquired
06:46:10 DISPATCHER: job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
06:46:10 job_id: (9, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0026123733712685514, 'num_filters_1': 86, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.0317057857205331, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 106, 'num_filters_3': 83, 'num_filters_4': 27, 'num_filters_5': 45}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4330881921971179, 'info': {'music_genre': 0.4330881921971179, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0026123733712685514, 'num_filters_1': 86, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.0317057857205331, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 106, 'num_filters_3': 83, 'num_filters_4': 27, 'num_filters_5': 45}"}}
exception: None

06:46:10 job_callback for (9, 0, 0) started
06:46:10 job_callback for (9, 0, 0) got condition
06:46:10 DISPATCHER: Trying to submit another job.
06:46:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:46:10 done building a new model for budget 133.333333 based on 17/39 split
Best loss for this budget:-0.510625





06:46:10 HBMASTER: Trying to run another job!
06:46:10 job_callback for (9, 0, 0) finished
06:46:10 start sampling a new configuration.
06:46:11 best_vector: [2, 0, 0.08111010423475552, 0.7157703862016124, 0.09640655499292607, 1, 0.2738475278647775, 0.5374227842533222, 1, 0, 0, 2, 0.07374866384049439, 0.4574147144532951, 0.12193217857094135, 0.57639393504026], 0.0013920723408284517, 0.007380600396537357, 1.0274329670727158e-05
06:46:11 done sampling a new configuration.
06:46:11 HBMASTER: schedule new run for iteration 9
06:46:11 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
06:46:11 HBMASTER: submitting job (9, 0, 1) to dispatcher
06:46:11 DISPATCHER: trying to submit job (9, 0, 1)
06:46:11 DISPATCHER: trying to notify the job_runner thread.
06:46:11 HBMASTER: job (9, 0, 1) submitted to dispatcher
06:46:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:46:11 DISPATCHER: Trying to submit another job.
06:46:11 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952
06:46:11 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
06:46:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:46:11 WORKER: start processing job (9, 0, 1)
06:46:11 WORKER: args: ()
06:46:11 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0014528480956520445, 'num_filters_1': 70, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.05002685055178234}, 'budget': 133.33333333333331, 'working_directory': '.'}
06:46:22 DISPATCHER: Starting worker discovery
06:46:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:46:22 DISPATCHER: Finished worker discovery
06:47:22 DISPATCHER: Starting worker discovery
06:47:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:47:22 DISPATCHER: Finished worker discovery
06:48:22 DISPATCHER: Starting worker discovery
06:48:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:48:22 DISPATCHER: Finished worker discovery
06:49:16 WORKER: done with job (9, 0, 1), trying to register it.
06:49:16 WORKER: registered result for job (9, 0, 1) with dispatcher
06:49:16 DISPATCHER: job (9, 0, 1) finished
06:49:16 DISPATCHER: register_result: lock acquired
06:49:16 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
06:49:16 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0014528480956520445, 'num_filters_1': 70, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.05002685055178234}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.43663049079565375, 'info': {'music_genre': 0.43663049079565375, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0014528480956520445, 'num_filters_1': 70, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.05002685055178234}"}}
exception: None

06:49:16 job_callback for (9, 0, 1) started
06:49:16 DISPATCHER: Trying to submit another job.
06:49:16 job_callback for (9, 0, 1) got condition
06:49:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:49:16 done building a new model for budget 133.333333 based on 17/39 split
Best loss for this budget:-0.510625





06:49:16 HBMASTER: Trying to run another job!
06:49:16 job_callback for (9, 0, 1) finished
06:49:16 start sampling a new configuration.
06:49:16 done sampling a new configuration.
06:49:16 HBMASTER: schedule new run for iteration 9
06:49:16 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
06:49:16 HBMASTER: submitting job (9, 0, 2) to dispatcher
06:49:16 DISPATCHER: trying to submit job (9, 0, 2)
06:49:16 DISPATCHER: trying to notify the job_runner thread.
06:49:16 HBMASTER: job (9, 0, 2) submitted to dispatcher
06:49:16 DISPATCHER: Trying to submit another job.
06:49:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:49:16 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952
06:49:16 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
06:49:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:49:16 WORKER: start processing job (9, 0, 2)
06:49:16 WORKER: args: ()
06:49:16 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.009146134740727854, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.020959468888547585, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 16, 'num_filters_3': 38, 'num_filters_4': 16, 'num_filters_5': 92}, 'budget': 133.33333333333331, 'working_directory': '.'}
06:49:22 DISPATCHER: Starting worker discovery
06:49:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:49:22 DISPATCHER: Finished worker discovery
06:50:22 DISPATCHER: Starting worker discovery
06:50:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:50:22 DISPATCHER: Finished worker discovery
06:51:22 DISPATCHER: Starting worker discovery
06:51:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:51:22 DISPATCHER: Finished worker discovery
06:52:22 DISPATCHER: Starting worker discovery
06:52:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:52:22 DISPATCHER: Finished worker discovery
06:52:23 WORKER: done with job (9, 0, 2), trying to register it.
06:52:23 WORKER: registered result for job (9, 0, 2) with dispatcher
06:52:23 DISPATCHER: job (9, 0, 2) finished
06:52:23 DISPATCHER: register_result: lock acquired
06:52:23 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
06:52:23 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.009146134740727854, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.020959468888547585, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 16, 'num_filters_3': 38, 'num_filters_4': 16, 'num_filters_5': 92}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.31807919953746244, 'info': {'music_genre': 0.31807919953746244, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.009146134740727854, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.020959468888547585, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 16, 'num_filters_3': 38, 'num_filters_4': 16, 'num_filters_5': 92}"}}
exception: None

06:52:23 job_callback for (9, 0, 2) started
06:52:23 job_callback for (9, 0, 2) got condition
06:52:23 DISPATCHER: Trying to submit another job.
06:52:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:52:23 done building a new model for budget 133.333333 based on 17/40 split
Best loss for this budget:-0.510625





06:52:23 HBMASTER: Trying to run another job!
06:52:23 job_callback for (9, 0, 2) finished
06:52:23 start sampling a new configuration.
06:52:23 sampled vector: [2, 2, 0.2230500763484625, 0.8977794382487436, 0.4219678347622908, 0, 0.9641072938195407, 0.31144784385137636, 1, 2, 2, 0, 0.8789491873244342, 0.4922788876831786, 0.35660866246559897, 0.3781087306984158] has EI value nan
06:52:23 data in the KDEs:
[[2.00000000e+00 1.00000000e+00 2.87971215e-02 7.93347517e-01
  9.00001600e-01 1.00000000e+00 7.19780268e-01 4.13095376e-01
  0.00000000e+00 1.00000000e+00 0.00000000e+00 2.00000000e+00
  7.63972013e-01 5.53727433e-01 8.52188646e-01 6.07308503e-01]
 [0.00000000e+00 1.00000000e+00 5.72991623e-03 9.79317897e-01
  5.00000000e-01 1.00000000e+00 6.09890134e-01 1.87494383e-01
  0.00000000e+00 2.00000000e+00 0.00000000e+00 2.00000000e+00
  9.90711064e-01 7.26128339e-01 4.36732032e-02 6.07308503e-01]
 [0.00000000e+00 0.00000000e+00 7.40705084e-02 8.67042020e-01
  7.00000800e-01 1.00000000e+00 5.32967040e-01 1.70440626e-01
  1.00000000e+00 2.00000000e+00 0.00000000e+00 0.00000000e+00
  7.19515734e-01 5.53727433e-01 4.36732032e-02 5.03913663e-01]
 [3.00000000e+00 2.00000000e+00 2.78166941e-01 5.24473143e-01
  9.99984000e-02 1.00000000e+00 3.57142826e-01 1.60307086e-02
  1.00000000e+00 2.00000000e+00 0.00000000e+00 2.00000000e+00
  8.10134850e-01 5.53727433e-01 8.52188646e-01 6.07308503e-01]
 [0.00000000e+00 0.00000000e+00 8.11269228e-02 6.77771560e-01
  9.99984000e-02 1.00000000e+00 4.78021973e-01 3.60025251e-01
  1.00000000e+00 2.00000000e+00 0.00000000e+00 0.00000000e+00
  7.19515734e-01 5.53727433e-01 4.36732032e-02 5.03913663e-01]
 [1.00000000e+00 2.00000000e+00 1.45140927e-01 7.69994942e-01
  9.99984000e-02 1.00000000e+00 4.23076906e-01 3.09222845e-01
  1.00000000e+00 2.00000000e+00 0.00000000e+00 0.00000000e+00
  8.10134850e-01 5.53727433e-01 2.62398612e-01 5.03913663e-01]
 [0.00000000e+00 0.00000000e+00 2.46132337e-01 6.15676748e-01
  9.00001600e-01 1.00000000e+00 3.02197759e-01 4.27296182e-02
  1.00000000e+00 1.00000000e+00 1.00000000e+00 0.00000000e+00
  9.62599641e-02 6.99104210e-01 9.26504973e-01 5.03913663e-01]
 [1.00000000e+00 0.00000000e+00 3.53901127e-02 5.44175724e-01
  9.99984000e-02 1.00000000e+00 7.52747308e-01 6.00933661e-04
  1.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00
  4.93288642e-01 7.93347517e-01 2.62398612e-01 5.03913663e-01]
 [3.00000000e+00 1.00000000e+00 1.93233002e-01 8.15600732e-01
  2.99999200e-01 1.00000000e+00 7.41758295e-01 3.69641896e-02
  2.00000000e+00 1.00000000e+00 1.00000000e+00 0.00000000e+00
  7.93347517e-01 6.99104210e-01 9.26504973e-01 5.03913663e-01]
 [1.00000000e+00 1.00000000e+00 4.22835225e-01 9.04510611e-01
  5.00000000e-01 1.00000000e+00 4.78021973e-01 4.24336130e-02
  1.00000000e+00 2.00000000e+00 0.00000000e+00 0.00000000e+00
  9.86943764e-01 9.39226643e-01 2.62398612e-01 5.03913663e-01]
 [3.00000000e+00 0.00000000e+00 9.74485708e-02 8.90805491e-01
  9.99984000e-02 1.00000000e+00 1.04395517e-01 4.07937219e-01
  2.00000000e+00 0.00000000e+00 0.00000000e+00 2.00000000e+00
  7.93347517e-01 9.22187194e-01 1.43578776e-01 6.07308503e-01]
 [2.00000000e+00 0.00000000e+00 1.08495838e-01 4.48226605e-01
  7.00000800e-01 1.00000000e+00 4.89010987e-01 5.88071362e-01
  1.00000000e+00 2.00000000e+00 2.00000000e+00 0.00000000e+00
  7.26128339e-01 8.26346502e-01 7.06973316e-02 5.03913663e-01]
 [2.00000000e+00 0.00000000e+00 8.11101042e-02 7.12809330e-01
  9.99984000e-02 1.00000000e+00 2.69230719e-01 5.37422784e-01
  1.00000000e+00 2.00000000e+00 0.00000000e+00 2.00000000e+00
  7.19515734e-01 5.53727433e-01 4.36732032e-02 6.07308503e-01]
 [0.00000000e+00 0.00000000e+00 2.08338539e-01 9.75458337e-01
  7.00000800e-01 1.00000000e+00 8.40659416e-01 8.22786933e-02
  1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  6.55430702e-01 9.22187194e-01 1.43578776e-01 5.03913663e-01]
 [0.00000000e+00 0.00000000e+00 1.89273462e-02 4.93288642e-01
  2.99999200e-01 1.00000000e+00 2.14285651e-01 1.76333946e-02
  1.00000000e+00 2.00000000e+00 0.00000000e+00 0.00000000e+00
  4.93288642e-01 5.53727433e-01 1.43578776e-01 5.03913663e-01]
 [3.00000000e+00 1.00000000e+00 2.08517624e-01 8.10134850e-01
  9.00001600e-01 1.00000000e+00 3.13186772e-01 3.85185985e-01
  1.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00
  9.08992100e-01 7.93347517e-01 2.62398612e-01 5.03913663e-01]
 [1.00000000e+00 2.00000000e+00 2.19245759e-01 6.55430702e-01
  5.00000000e-01 1.00000000e+00 9.17582509e-01 3.03037260e-01
  1.00000000e+00 2.00000000e+00 0.00000000e+00 0.00000000e+00
  8.10134850e-01 5.53727433e-01 2.62398612e-01 5.03913663e-01]]
[[1.         2.         0.08046295 0.77594211 0.9000016  1.
  0.30219776 0.43630195 2.         2.         2.         2.
  0.68498992 0.99444858 0.01501027 0.1205111 ]
 [3.         1.         0.97374367 0.59011412 0.5        1.
  0.91758251 0.21204908 2.         2.         2.         0.
  0.41136689 0.70600643 0.72612834 0.0436732 ]
 [3.         1.         0.007487   0.39841284 0.0999984  1.
  0.14835157 0.17317237 1.         1.         1.         2.
  0.70600643 0.64774283 0.62389945 0.22601193]
 [3.         1.         0.1389122  0.26239861 0.5        1.
  0.44505493 0.80872626 0.         2.         1.         2.
  0.93502401 0.67777156 0.01501027 0.84202065]
 [2.         1.         0.18373989 0.94339225 0.9000016  1.
  0.97252758 0.88075747 2.         2.         1.         0.
  0.22601193 0.78761662 0.0436732  0.72612834]
 [2.         1.         0.37580639 0.78761662 0.9000016  1.
  0.92857152 0.11852321 1.         1.         1.         0.
  0.69910421 0.6554307  0.29618395 0.0436732 ]
 [3.         1.         0.37026204 0.16557314 0.0999984  1.
  0.12637354 0.09199771 1.         1.         2.         1.
  0.70600643 0.64774283 0.83162917 0.64774283]
 [1.         1.         0.13282677 0.09625996 0.5        1.
  0.70879125 0.57459971 2.         1.         1.         0.
  0.63198159 0.81560073 0.0436732  0.72612834]
 [3.         2.         0.39364196 0.44822661 0.9000016  1.
  0.96153856 0.24326359 2.         2.         0.         0.
  0.69209973 0.63198159 0.09625996 0.0436732 ]
 [2.         1.         0.23147806 0.53442706 0.5        1.
  0.03846144 0.54523359 0.         2.         2.         0.
  0.94752148 0.83685346 0.52447314 0.67777156]
 [3.         1.         0.32802508 0.54417572 0.9000016  1.
  0.70879125 0.57950089 0.         2.         2.         1.
  0.50391366 0.78761662 0.83162917 0.64774283]
 [3.         1.         0.14792329 0.18658964 0.2999992  1.
  0.06043946 0.37048307 2.         2.         1.         2.
  0.41136689 0.42397547 0.01501027 0.84202065]
 [3.         0.         0.41710036 0.54417572 0.5        1.
  0.56593408 0.30990814 1.         2.         2.         1.
  0.01501027 0.43625651 0.83162917 0.64774283]
 [0.         0.         0.13734239 0.99444858 0.0999984  1.
  0.70879125 0.79194823 2.         2.         1.         2.
  0.64774283 0.55372743 0.62389945 0.22601193]
 [1.         0.         0.31070674 0.84202065 0.2999992  1.
  0.37912085 0.6208271  2.         1.         2.         1.
  0.76999494 0.81560073 0.83162917 0.64774283]
 [3.         0.         0.4806188  0.07069733 0.9000016  1.
  0.75274731 0.24701988 1.         2.         1.         2.
  0.01501027 0.42397547 0.01501027 0.84202065]
 [2.         1.         0.12160842 0.95567329 0.7000008  1.
  0.44505493 0.96577667 1.         2.         2.         0.
  0.31221238 0.35727442 0.72612834 0.72612834]
 [3.         2.         0.21215743 0.37138871 0.9000016  0.
  0.26923072 0.16893818 2.         2.         1.         2.
  0.64774283 0.55372743 0.62389945 0.22601193]
 [1.         2.         0.4390688  0.72612834 0.2999992  1.
  0.42307691 0.67246989 1.         2.         2.         1.
  0.95567329 0.48241935 0.83162917 0.64774283]
 [0.         1.         0.51173259 0.38509383 0.7000008  1.
  0.81868139 0.07058142 0.         2.         2.         0.
  0.98694376 0.96368694 0.52447314 0.72612834]
 [2.         0.         0.29346917 0.0436732  0.7000008  1.
  0.54395605 0.20003535 0.         0.         1.         2.
  0.75787137 0.44822661 0.99071106 0.1205111 ]
 [1.         0.         0.12784089 0.92650497 0.2999992  1.
  0.19230762 0.88485227 1.         0.         1.         2.
  0.83685346 0.63198159 0.01501027 0.84202065]
 [0.         0.         0.43889565 0.31221238 0.2999992  0.
  0.57692309 0.20927784 1.         2.         2.         2.
  0.24455523 0.99444858 0.01501027 0.1205111 ]
 [2.         2.         0.6803084  0.52447314 0.5        1.
  0.14835157 0.16535056 0.         2.         1.         0.
  0.74542871 0.48241935 0.29618395 0.0436732 ]
 [2.         1.         0.76708404 0.16557314 0.5        1.
  0.79670336 0.25899268 1.         1.         1.         1.
  0.8263465  0.98694376 0.63992789 0.64774283]
 [2.         2.         0.00651724 0.279593   0.5        0.
  0.73076928 0.53905515 1.         1.         0.         0.
  0.70600643 0.64774283 0.51430515 0.67777156]
 [3.         2.         0.02938905 0.71951573 0.5        0.
  0.41208789 0.89894323 2.         0.         1.         0.
  0.9089921  0.63198159 0.29618395 0.0436732 ]
 [0.         2.         0.70652422 0.64774283 0.0999984  0.
  0.93956054 0.17006485 1.         2.         2.         2.
  0.31221238 0.35727442 0.72612834 0.22601193]
 [3.         0.         0.54320268 0.3277152  0.5        0.
  0.08241749 0.72332924 1.         1.         2.         2.
  0.14357878 0.61567675 0.01501027 0.1205111 ]
 [2.         0.         0.3761069  0.31221238 0.7000008  0.
  0.20329664 0.967376   2.         2.         1.         2.
  0.50391366 0.37138871 0.63992789 0.1205111 ]
 [2.         1.         0.6368347  0.35727442 0.9000016  0.
  0.93956054 0.37585854 0.         1.         0.         0.
  0.1205111  0.55372743 0.51430515 0.67777156]]
06:52:23 bandwidth of the KDEs:
[1.08234196e+00 7.01437756e-01 9.94431683e-02 1.49754541e-01
 2.80576225e-01 1.00000000e-03 2.07754968e-01 1.75508900e-01
 4.46261020e-01 6.40322136e-01 5.01861319e-01 8.38378473e-01
 1.88440524e-01 1.33858739e-01 2.97612277e-01 4.33420039e-02]
[0.92066479 0.66049412 0.21150999 0.2476308  0.23873682 0.39064745
 0.2725576  0.25759853 0.67046441 0.59440285 0.57309112 0.80121038
 0.25275801 0.16838734 0.29043617 0.27206495]
06:52:23 l(x) = nan
06:52:23 g(x) = 4.380115043086011e-05
06:52:23 best_vector: [0, 1, 0.08248129410231869, 0.9681580129951538, 0.03254376034788353, 1, 0.15871799496684436, 0.00853588760590232, 0, 1, 0, 2, 0.7595700629808726, 0.5926339440162876, 0.04089841765514587, 0.5020267595211476], 0.00028808056640185675, 0.024174656547304857, 6.9642487507179385e-06
06:52:23 done sampling a new configuration.
06:52:23 HBMASTER: schedule new run for iteration 9
06:52:23 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
06:52:23 HBMASTER: submitting job (9, 0, 3) to dispatcher
06:52:23 DISPATCHER: trying to submit job (9, 0, 3)
06:52:23 DISPATCHER: trying to notify the job_runner thread.
06:52:23 HBMASTER: job (9, 0, 3) submitted to dispatcher
06:52:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:52:23 DISPATCHER: Trying to submit another job.
06:52:23 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
06:52:23 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
06:52:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:52:23 WORKER: start processing job (9, 0, 3)
06:52:23 WORKER: args: ()
06:52:23 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0014620512223218604, 'num_filters_1': 120, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.010259009826822804}, 'budget': 133.33333333333331, 'working_directory': '.'}
06:53:22 DISPATCHER: Starting worker discovery
06:53:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:53:22 DISPATCHER: Finished worker discovery
06:54:22 DISPATCHER: Starting worker discovery
06:54:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:54:22 DISPATCHER: Finished worker discovery
06:55:22 DISPATCHER: Starting worker discovery
06:55:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:55:22 DISPATCHER: Finished worker discovery
06:55:31 WORKER: done with job (9, 0, 3), trying to register it.
06:55:31 WORKER: registered result for job (9, 0, 3) with dispatcher
06:55:31 DISPATCHER: job (9, 0, 3) finished
06:55:31 DISPATCHER: register_result: lock acquired
06:55:31 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
06:55:31 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0014620512223218604, 'num_filters_1': 120, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.010259009826822804}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4457875416583578, 'info': {'music_genre': 0.4457875416583578, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0014620512223218604, 'num_filters_1': 120, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.010259009826822804}"}}
exception: None

06:55:31 job_callback for (9, 0, 3) started
06:55:31 job_callback for (9, 0, 3) got condition
06:55:31 DISPATCHER: Trying to submit another job.
06:55:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:55:31 done building a new model for budget 133.333333 based on 17/41 split
Best loss for this budget:-0.510625





06:55:31 HBMASTER: Trying to run another job!
06:55:31 job_callback for (9, 0, 3) finished
06:55:31 start sampling a new configuration.
06:55:31 best_vector: [0, 1, 0.08223245935767992, 0.6269546262765459, 0.05951386995369323, 1, 0.3119278951116381, 0.3498324190571196, 1, 2, 0, 0, 0.6995091158869776, 0.6898674591016634, 0.17445737979540257, 0.6204341075430442], 0.00019399828268712685, 0.7382545214625785, 0.00014322010934974687
06:55:31 done sampling a new configuration.
06:55:31 HBMASTER: schedule new run for iteration 9
06:55:31 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
06:55:31 HBMASTER: submitting job (9, 0, 4) to dispatcher
06:55:31 DISPATCHER: trying to submit job (9, 0, 4)
06:55:31 DISPATCHER: trying to notify the job_runner thread.
06:55:31 HBMASTER: job (9, 0, 4) submitted to dispatcher
06:55:31 DISPATCHER: Trying to submit another job.
06:55:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:55:31 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952
06:55:31 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
06:55:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:55:31 WORKER: start processing job (9, 0, 4)
06:55:31 WORKER: args: ()
06:55:31 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0014603767788828339, 'num_filters_1': 58, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.028519536997324964}, 'budget': 133.33333333333331, 'working_directory': '.'}
06:56:22 DISPATCHER: Starting worker discovery
06:56:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:56:22 DISPATCHER: Finished worker discovery
06:57:22 DISPATCHER: Starting worker discovery
06:57:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:57:22 DISPATCHER: Finished worker discovery
06:58:22 DISPATCHER: Starting worker discovery
06:58:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:58:22 DISPATCHER: Finished worker discovery
06:58:38 WORKER: done with job (9, 0, 4), trying to register it.
06:58:38 WORKER: registered result for job (9, 0, 4) with dispatcher
06:58:38 DISPATCHER: job (9, 0, 4) finished
06:58:38 DISPATCHER: register_result: lock acquired
06:58:38 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
06:58:38 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0014603767788828339, 'num_filters_1': 58, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.028519536997324964}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.41158440489068887, 'info': {'music_genre': 0.41158440489068887, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0014603767788828339, 'num_filters_1': 58, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.028519536997324964}"}}
exception: None

06:58:38 job_callback for (9, 0, 4) started
06:58:38 job_callback for (9, 0, 4) got condition
06:58:38 DISPATCHER: Trying to submit another job.
06:58:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:58:38 done building a new model for budget 133.333333 based on 17/42 split
Best loss for this budget:-0.510625





06:58:38 HBMASTER: Trying to run another job!
06:58:38 job_callback for (9, 0, 4) finished
06:58:38 start sampling a new configuration.
06:58:38 done sampling a new configuration.
06:58:38 HBMASTER: schedule new run for iteration 9
06:58:38 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
06:58:38 HBMASTER: submitting job (9, 0, 5) to dispatcher
06:58:38 DISPATCHER: trying to submit job (9, 0, 5)
06:58:38 DISPATCHER: trying to notify the job_runner thread.
06:58:38 HBMASTER: job (9, 0, 5) submitted to dispatcher
06:58:38 DISPATCHER: Trying to submit another job.
06:58:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:58:38 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952
06:58:38 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
06:58:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:58:38 WORKER: start processing job (9, 0, 5)
06:58:38 WORKER: args: ()
06:58:38 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.00185627074106216, 'num_filters_1': 24, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.03176924504613348, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 112, 'num_filters_3': 58, 'num_filters_4': 31}, 'budget': 133.33333333333331, 'working_directory': '.'}
06:59:22 DISPATCHER: Starting worker discovery
06:59:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:59:22 DISPATCHER: Finished worker discovery
07:00:22 DISPATCHER: Starting worker discovery
07:00:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:00:22 DISPATCHER: Finished worker discovery
07:01:22 DISPATCHER: Starting worker discovery
07:01:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:01:22 DISPATCHER: Finished worker discovery
07:01:43 WORKER: done with job (9, 0, 5), trying to register it.
07:01:43 WORKER: registered result for job (9, 0, 5) with dispatcher
07:01:43 DISPATCHER: job (9, 0, 5) finished
07:01:43 DISPATCHER: register_result: lock acquired
07:01:43 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:01:43 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.00185627074106216, 'num_filters_1': 24, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.03176924504613348, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 112, 'num_filters_3': 58, 'num_filters_4': 31}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.20542134213830757, 'info': {'music_genre': 0.20542134213830757, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.00185627074106216, 'num_filters_1': 24, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.03176924504613348, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 112, 'num_filters_3': 58, 'num_filters_4': 31}"}}
exception: None

07:01:43 job_callback for (9, 0, 5) started
07:01:43 DISPATCHER: Trying to submit another job.
07:01:43 job_callback for (9, 0, 5) got condition
07:01:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:01:43 done building a new model for budget 133.333333 based on 17/43 split
Best loss for this budget:-0.510625





07:01:43 HBMASTER: Trying to run another job!
07:01:43 job_callback for (9, 0, 5) finished
07:01:43 start sampling a new configuration.
07:01:43 best_vector: [1, 1, 0.08395086335320281, 0.9185529890897339, 0.46305675350046616, 1, 0.5730672058665132, 0.21717662399120133, 1, 2, 0, 2, 0.8236741966572709, 0.7053250889969903, 0.576137456653939, 0.5161853988242541], 0.00041788025286802695, 0.4516077399816292, 0.00018871795658068137
07:01:43 done sampling a new configuration.
07:01:43 HBMASTER: schedule new run for iteration 9
07:01:43 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
07:01:43 HBMASTER: submitting job (9, 0, 6) to dispatcher
07:01:43 DISPATCHER: trying to submit job (9, 0, 6)
07:01:43 DISPATCHER: trying to notify the job_runner thread.
07:01:43 HBMASTER: job (9, 0, 6) submitted to dispatcher
07:01:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:01:43 DISPATCHER: Trying to submit another job.
07:01:43 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:01:43 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:01:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:01:43 WORKER: start processing job (9, 0, 6)
07:01:43 WORKER: args: ()
07:01:43 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.001471979381392102, 'num_filters_1': 108, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.01916696289766271, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 88, 'num_filters_3': 69}, 'budget': 133.33333333333331, 'working_directory': '.'}
07:02:22 DISPATCHER: Starting worker discovery
07:02:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:02:22 DISPATCHER: Finished worker discovery
07:03:22 DISPATCHER: Starting worker discovery
07:03:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:03:22 DISPATCHER: Finished worker discovery
07:04:22 DISPATCHER: Starting worker discovery
07:04:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:04:22 DISPATCHER: Finished worker discovery
07:04:50 WORKER: done with job (9, 0, 6), trying to register it.
07:04:50 WORKER: registered result for job (9, 0, 6) with dispatcher
07:04:50 DISPATCHER: job (9, 0, 6) finished
07:04:50 DISPATCHER: register_result: lock acquired
07:04:50 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:04:50 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.001471979381392102, 'num_filters_1': 108, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.01916696289766271, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 88, 'num_filters_3': 69}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.49007005740823883, 'info': {'music_genre': 0.49007005740823883, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.001471979381392102, 'num_filters_1': 108, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.01916696289766271, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 88, 'num_filters_3': 69}"}}
exception: None

07:04:50 job_callback for (9, 0, 6) started
07:04:50 DISPATCHER: Trying to submit another job.
07:04:50 job_callback for (9, 0, 6) got condition
07:04:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:04:50 done building a new model for budget 133.333333 based on 17/44 split
Best loss for this budget:-0.510625





07:04:50 HBMASTER: Trying to run another job!
07:04:50 job_callback for (9, 0, 6) finished
07:04:50 start sampling a new configuration.
07:04:50 best_vector: [1, 1, 0.07831390068527144, 0.9188803240680156, 0.0428034360651704, 1, 0.6562175858158386, 0.43191391728662565, 2, 0, 1, 1, 0.9480281508375553, 0.6218416805990091, 0.21668606386045314, 0.45025911260181206], 0.009004649309395802, 0.014280199520635115, 0.00012858818875152126
07:04:50 done sampling a new configuration.
07:04:50 HBMASTER: schedule new run for iteration 9
07:04:50 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
07:04:50 HBMASTER: submitting job (9, 0, 7) to dispatcher
07:04:50 DISPATCHER: trying to submit job (9, 0, 7)
07:04:50 DISPATCHER: trying to notify the job_runner thread.
07:04:50 HBMASTER: job (9, 0, 7) submitted to dispatcher
07:04:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:04:50 DISPATCHER: Trying to submit another job.
07:04:50 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:04:50 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:04:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:04:50 WORKER: start processing job (9, 0, 7)
07:04:50 WORKER: args: ()
07:04:50 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0014342597186319795, 'num_filters_1': 108, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.036469764754164885}, 'budget': 133.33333333333331, 'working_directory': '.'}
07:05:22 DISPATCHER: Starting worker discovery
07:05:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:05:22 DISPATCHER: Finished worker discovery
07:06:22 DISPATCHER: Starting worker discovery
07:06:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:06:22 DISPATCHER: Finished worker discovery
07:07:22 DISPATCHER: Starting worker discovery
07:07:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:07:22 DISPATCHER: Finished worker discovery
07:07:56 WORKER: done with job (9, 0, 7), trying to register it.
07:07:56 WORKER: registered result for job (9, 0, 7) with dispatcher
07:07:56 DISPATCHER: job (9, 0, 7) finished
07:07:56 DISPATCHER: register_result: lock acquired
07:07:56 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:07:56 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0014342597186319795, 'num_filters_1': 108, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.036469764754164885}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4441536428952017, 'info': {'music_genre': 0.4441536428952017, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0014342597186319795, 'num_filters_1': 108, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.036469764754164885}"}}
exception: None

07:07:56 job_callback for (9, 0, 7) started
07:07:56 DISPATCHER: Trying to submit another job.
07:07:56 job_callback for (9, 0, 7) got condition
07:07:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:07:56 done building a new model for budget 133.333333 based on 17/45 split
Best loss for this budget:-0.510625





07:07:56 HBMASTER: Trying to run another job!
07:07:56 job_callback for (9, 0, 7) finished
07:07:56 start sampling a new configuration.
07:07:56 best_vector: [3, 1, 0.14238342336852014, 0.8489230013810352, 0.41443317192182794, 1, 0.6555238954220021, 0.06327444505520864, 2, 1, 0, 1, 0.9151328718617403, 0.85463830330281, 0.9110487111091986, 0.5410404309643502], 0.00021666140184608046, 0.15864147692116037, 3.437148478067123e-05
07:07:56 done sampling a new configuration.
07:07:56 HBMASTER: schedule new run for iteration 9
07:07:56 HBMASTER: trying submitting job (9, 0, 8) to dispatcher
07:07:56 HBMASTER: submitting job (9, 0, 8) to dispatcher
07:07:56 DISPATCHER: trying to submit job (9, 0, 8)
07:07:56 DISPATCHER: trying to notify the job_runner thread.
07:07:56 HBMASTER: job (9, 0, 8) submitted to dispatcher
07:07:56 DISPATCHER: Trying to submit another job.
07:07:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:07:56 DISPATCHER: starting job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:07:56 DISPATCHER: job (9, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:07:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:07:56 WORKER: start processing job (9, 0, 8)
07:07:56 WORKER: args: ()
07:07:56 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0019264903890845026, 'num_filters_1': 93, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.012087095430382335, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 107, 'num_filters_3': 94}, 'budget': 133.33333333333331, 'working_directory': '.'}
07:08:22 DISPATCHER: Starting worker discovery
07:08:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:08:22 DISPATCHER: Finished worker discovery
07:09:22 DISPATCHER: Starting worker discovery
07:09:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:09:22 DISPATCHER: Finished worker discovery
07:10:22 DISPATCHER: Starting worker discovery
07:10:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:10:22 DISPATCHER: Finished worker discovery
07:11:03 WORKER: done with job (9, 0, 8), trying to register it.
07:11:03 WORKER: registered result for job (9, 0, 8) with dispatcher
07:11:03 DISPATCHER: job (9, 0, 8) finished
07:11:03 DISPATCHER: register_result: lock acquired
07:11:03 DISPATCHER: job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:11:03 job_id: (9, 0, 8)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0019264903890845026, 'num_filters_1': 93, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.012087095430382335, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 107, 'num_filters_3': 94}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5032843312340828, 'info': {'music_genre': 0.5032843312340828, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0019264903890845026, 'num_filters_1': 93, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.012087095430382335, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 107, 'num_filters_3': 94}"}}
exception: None

07:11:03 job_callback for (9, 0, 8) started
07:11:03 DISPATCHER: Trying to submit another job.
07:11:03 job_callback for (9, 0, 8) got condition
07:11:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:11:03 done building a new model for budget 133.333333 based on 17/45 split
Best loss for this budget:-0.510625





07:11:03 HBMASTER: Trying to run another job!
07:11:03 job_callback for (9, 0, 8) finished
07:11:03 ITERATION: Advancing config (9, 0, 3) to next budget 400.000000
07:11:03 ITERATION: Advancing config (9, 0, 6) to next budget 400.000000
07:11:03 ITERATION: Advancing config (9, 0, 8) to next budget 400.000000
07:11:03 HBMASTER: schedule new run for iteration 9
07:11:03 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
07:11:03 HBMASTER: submitting job (9, 0, 3) to dispatcher
07:11:03 DISPATCHER: trying to submit job (9, 0, 3)
07:11:03 DISPATCHER: trying to notify the job_runner thread.
07:11:03 HBMASTER: job (9, 0, 3) submitted to dispatcher
07:11:03 DISPATCHER: Trying to submit another job.
07:11:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:11:03 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:11:03 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:11:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:11:03 WORKER: start processing job (9, 0, 3)
07:11:03 WORKER: args: ()
07:11:03 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0014620512223218604, 'num_filters_1': 120, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.010259009826822804}, 'budget': 400.0, 'working_directory': '.'}
07:11:22 DISPATCHER: Starting worker discovery
07:11:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:11:22 DISPATCHER: Finished worker discovery
07:12:22 DISPATCHER: Starting worker discovery
07:12:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:12:22 DISPATCHER: Finished worker discovery
07:13:22 DISPATCHER: Starting worker discovery
07:13:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:13:22 DISPATCHER: Finished worker discovery
07:14:22 DISPATCHER: Starting worker discovery
07:14:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:14:22 DISPATCHER: Finished worker discovery
07:15:22 DISPATCHER: Starting worker discovery
07:15:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:15:22 DISPATCHER: Finished worker discovery
07:16:22 DISPATCHER: Starting worker discovery
07:16:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:16:22 DISPATCHER: Finished worker discovery
07:17:22 DISPATCHER: Starting worker discovery
07:17:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:17:22 DISPATCHER: Finished worker discovery
07:18:22 DISPATCHER: Starting worker discovery
07:18:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:18:22 DISPATCHER: Finished worker discovery
07:18:50 WORKER: done with job (9, 0, 3), trying to register it.
07:18:50 WORKER: registered result for job (9, 0, 3) with dispatcher
07:18:50 DISPATCHER: job (9, 0, 3) finished
07:18:50 DISPATCHER: register_result: lock acquired
07:18:50 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:18:50 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0014620512223218604, 'num_filters_1': 120, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.010259009826822804}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.4429268444342234, 'info': {'music_genre': 0.4429268444342234, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0014620512223218604, 'num_filters_1': 120, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.010259009826822804}"}}
exception: None

07:18:50 job_callback for (9, 0, 3) started
07:18:50 job_callback for (9, 0, 3) got condition
07:18:50 DISPATCHER: Trying to submit another job.
07:18:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:18:50 HBMASTER: Trying to run another job!
07:18:50 job_callback for (9, 0, 3) finished
07:18:50 HBMASTER: schedule new run for iteration 9
07:18:50 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
07:18:50 HBMASTER: submitting job (9, 0, 6) to dispatcher
07:18:50 DISPATCHER: trying to submit job (9, 0, 6)
07:18:50 DISPATCHER: trying to notify the job_runner thread.
07:18:50 HBMASTER: job (9, 0, 6) submitted to dispatcher
07:18:50 DISPATCHER: Trying to submit another job.
07:18:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:18:50 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:18:50 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:18:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:18:50 WORKER: start processing job (9, 0, 6)
07:18:50 WORKER: args: ()
07:18:50 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.001471979381392102, 'num_filters_1': 108, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.01916696289766271, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 88, 'num_filters_3': 69}, 'budget': 400.0, 'working_directory': '.'}
07:19:22 DISPATCHER: Starting worker discovery
07:19:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:19:22 DISPATCHER: Finished worker discovery
07:20:22 DISPATCHER: Starting worker discovery
07:20:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:20:22 DISPATCHER: Finished worker discovery
07:21:22 DISPATCHER: Starting worker discovery
07:21:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:21:22 DISPATCHER: Finished worker discovery
07:22:22 DISPATCHER: Starting worker discovery
07:22:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:22:22 DISPATCHER: Finished worker discovery
07:23:22 DISPATCHER: Starting worker discovery
07:23:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:23:22 DISPATCHER: Finished worker discovery
07:24:22 DISPATCHER: Starting worker discovery
07:24:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:24:22 DISPATCHER: Finished worker discovery
07:25:22 DISPATCHER: Starting worker discovery
07:25:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:25:22 DISPATCHER: Finished worker discovery
07:26:22 DISPATCHER: Starting worker discovery
07:26:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:26:23 DISPATCHER: Finished worker discovery
07:26:23 WORKER: done with job (9, 0, 6), trying to register it.
07:26:23 WORKER: registered result for job (9, 0, 6) with dispatcher
07:26:23 DISPATCHER: job (9, 0, 6) finished
07:26:23 DISPATCHER: register_result: lock acquired
07:26:23 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:26:23 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.001471979381392102, 'num_filters_1': 108, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.01916696289766271, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 88, 'num_filters_3': 69}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.42969195940145544, 'info': {'music_genre': 0.42969195940145544, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.001471979381392102, 'num_filters_1': 108, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.01916696289766271, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 88, 'num_filters_3': 69}"}}
exception: None

07:26:23 job_callback for (9, 0, 6) started
07:26:23 DISPATCHER: Trying to submit another job.
07:26:23 job_callback for (9, 0, 6) got condition
07:26:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:26:23 HBMASTER: Trying to run another job!
07:26:23 job_callback for (9, 0, 6) finished
07:26:23 HBMASTER: schedule new run for iteration 9
07:26:23 HBMASTER: trying submitting job (9, 0, 8) to dispatcher
07:26:23 HBMASTER: submitting job (9, 0, 8) to dispatcher
07:26:23 DISPATCHER: trying to submit job (9, 0, 8)
07:26:23 DISPATCHER: trying to notify the job_runner thread.
07:26:23 HBMASTER: job (9, 0, 8) submitted to dispatcher
07:26:23 DISPATCHER: Trying to submit another job.
07:26:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:26:23 DISPATCHER: starting job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:26:23 DISPATCHER: job (9, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:26:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:26:23 WORKER: start processing job (9, 0, 8)
07:26:23 WORKER: args: ()
07:26:23 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0019264903890845026, 'num_filters_1': 93, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.012087095430382335, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 107, 'num_filters_3': 94}, 'budget': 400.0, 'working_directory': '.'}
07:27:23 DISPATCHER: Starting worker discovery
07:27:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:27:23 DISPATCHER: Finished worker discovery
07:28:23 DISPATCHER: Starting worker discovery
07:28:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:28:23 DISPATCHER: Finished worker discovery
07:29:23 DISPATCHER: Starting worker discovery
07:29:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:29:23 DISPATCHER: Finished worker discovery
07:30:23 DISPATCHER: Starting worker discovery
07:30:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:30:23 DISPATCHER: Finished worker discovery
07:31:23 DISPATCHER: Starting worker discovery
07:31:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:31:23 DISPATCHER: Finished worker discovery
07:32:23 DISPATCHER: Starting worker discovery
07:32:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:32:23 DISPATCHER: Finished worker discovery
07:33:23 DISPATCHER: Starting worker discovery
07:33:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:33:23 DISPATCHER: Finished worker discovery
07:33:57 WORKER: done with job (9, 0, 8), trying to register it.
07:33:57 WORKER: registered result for job (9, 0, 8) with dispatcher
07:33:57 DISPATCHER: job (9, 0, 8) finished
07:33:57 DISPATCHER: register_result: lock acquired
07:33:57 DISPATCHER: job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:33:57 job_id: (9, 0, 8)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0019264903890845026, 'num_filters_1': 93, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.012087095430382335, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 107, 'num_filters_3': 94}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.4732530274799741, 'info': {'music_genre': 0.4732530274799741, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0019264903890845026, 'num_filters_1': 93, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.012087095430382335, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 107, 'num_filters_3': 94}"}}
exception: None

07:33:57 job_callback for (9, 0, 8) started
07:33:57 DISPATCHER: Trying to submit another job.
07:33:57 job_callback for (9, 0, 8) got condition
07:33:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:33:57 HBMASTER: Trying to run another job!
07:33:57 job_callback for (9, 0, 8) finished
07:33:57 ITERATION: Advancing config (9, 0, 8) to next budget 1200.000000
07:33:57 HBMASTER: schedule new run for iteration 9
07:33:57 HBMASTER: trying submitting job (9, 0, 8) to dispatcher
07:33:57 HBMASTER: submitting job (9, 0, 8) to dispatcher
07:33:57 DISPATCHER: trying to submit job (9, 0, 8)
07:33:57 DISPATCHER: trying to notify the job_runner thread.
07:33:57 HBMASTER: job (9, 0, 8) submitted to dispatcher
07:33:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:33:57 DISPATCHER: Trying to submit another job.
07:33:57 DISPATCHER: starting job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:33:57 DISPATCHER: job (9, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30597140382006277952
07:33:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:33:57 WORKER: start processing job (9, 0, 8)
07:33:57 WORKER: args: ()
07:33:57 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0019264903890845026, 'num_filters_1': 93, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.012087095430382335, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 107, 'num_filters_3': 94}, 'budget': 1200.0, 'working_directory': '.'}
07:34:23 DISPATCHER: Starting worker discovery
07:34:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:34:23 DISPATCHER: Finished worker discovery
07:35:23 DISPATCHER: Starting worker discovery
07:35:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:35:23 DISPATCHER: Finished worker discovery
07:36:23 DISPATCHER: Starting worker discovery
07:36:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:36:23 DISPATCHER: Finished worker discovery
07:37:23 DISPATCHER: Starting worker discovery
07:37:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:37:23 DISPATCHER: Finished worker discovery
07:38:23 DISPATCHER: Starting worker discovery
07:38:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:38:23 DISPATCHER: Finished worker discovery
07:39:23 DISPATCHER: Starting worker discovery
07:39:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:39:23 DISPATCHER: Finished worker discovery
07:40:23 DISPATCHER: Starting worker discovery
07:40:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:40:23 DISPATCHER: Finished worker discovery
07:41:23 DISPATCHER: Starting worker discovery
07:41:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:41:23 DISPATCHER: Finished worker discovery
07:42:23 DISPATCHER: Starting worker discovery
07:42:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:42:23 DISPATCHER: Finished worker discovery
07:43:23 DISPATCHER: Starting worker discovery
07:43:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:43:23 DISPATCHER: Finished worker discovery
07:44:23 DISPATCHER: Starting worker discovery
07:44:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:44:23 DISPATCHER: Finished worker discovery
07:45:23 DISPATCHER: Starting worker discovery
07:45:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:45:23 DISPATCHER: Finished worker discovery
07:46:23 DISPATCHER: Starting worker discovery
07:46:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:46:23 DISPATCHER: Finished worker discovery
07:47:23 DISPATCHER: Starting worker discovery
07:47:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:47:23 DISPATCHER: Finished worker discovery
07:48:23 DISPATCHER: Starting worker discovery
07:48:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:48:23 DISPATCHER: Finished worker discovery
07:49:23 DISPATCHER: Starting worker discovery
07:49:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:49:23 DISPATCHER: Finished worker discovery
07:50:23 DISPATCHER: Starting worker discovery
07:50:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:50:23 DISPATCHER: Finished worker discovery
07:51:23 DISPATCHER: Starting worker discovery
07:51:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:51:23 DISPATCHER: Finished worker discovery
07:52:23 DISPATCHER: Starting worker discovery
07:52:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:52:23 DISPATCHER: Finished worker discovery
07:53:23 DISPATCHER: Starting worker discovery
07:53:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:53:23 DISPATCHER: Finished worker discovery
07:54:23 DISPATCHER: Starting worker discovery
07:54:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:54:23 DISPATCHER: Finished worker discovery
07:54:54 WORKER: done with job (9, 0, 8), trying to register it.
07:54:54 WORKER: registered result for job (9, 0, 8) with dispatcher
07:54:54 DISPATCHER: job (9, 0, 8) finished
07:54:54 DISPATCHER: register_result: lock acquired
07:54:54 DISPATCHER: job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.30597140382006277952 finished
07:54:54 job_id: (9, 0, 8)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0019264903890845026, 'num_filters_1': 93, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.012087095430382335, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 107, 'num_filters_3': 94}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.4710943485228595, 'info': {'music_genre': 0.4710943485228595, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0019264903890845026, 'num_filters_1': 93, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.012087095430382335, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 107, 'num_filters_3': 94}"}}
exception: None

07:54:54 job_callback for (9, 0, 8) started
07:54:54 job_callback for (9, 0, 8) got condition
07:54:54 DISPATCHER: Trying to submit another job.
07:54:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:54:54 HBMASTER: Trying to run another job!
07:54:54 job_callback for (9, 0, 8) finished
07:54:54 HBMASTER: shutdown initiated, shutdown_workers = True
07:54:54 WORKER: shutting down now!
07:54:54 DISPATCHER: Dispatcher shutting down
07:54:54 DISPATCHER: discover_workers shutting down
07:54:54 DISPATCHER: Trying to submit another job.
07:54:54 DISPATCHER: 'discover_worker' thread exited
07:54:54 DISPATCHER: job_runner shutting down
07:54:54 DISPATCHER: 'job_runner' thread exited
07:54:54 DISPATCHER: shut down complete
