/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Using TensorFlow backend.
WARNING:tensorflow:From /home/ahnj/repo/autodl/AutoDL/model.py:27: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /home/ahnj/repo/autodl/AutoDL/model.py:31: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2020-03-09 18:39:34.519289: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-03-09 18:39:34.523247: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299960000 Hz
2020-03-09 18:39:34.523532: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a75a697840 executing computations on platform Host. Devices:
2020-03-09 18:39:34.523554: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-03-09 18:39:34.524411: I tensorflow/core/common_runtime/direct_session.cc:296] Device mapping:
/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device

18:39:34 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7fb47c6ce6d8; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:34722>
18:39:34 WORKER: No dispatcher found. Waiting for one to initiate contact.
18:39:34 WORKER: start listening for jobs
18:39:34 wait_for_workers trying to get the condition
18:39:34 DISPATCHER: started the 'discover_worker' thread
18:39:34 DISPATCHER: started the 'job_runner' thread
18:39:34 DISPATCHER: Pyro daemon running on localhost:41137
18:39:34 DISPATCHER: Starting worker discovery
18:39:34 DISPATCHER: Found 1 potential workers, 0 currently in the pool.
18:39:34 DISPATCHER: discovered new worker, hpbandster.run_0.worker.metagpuj.30598140416580691776
18:39:34 HBMASTER: number of workers changed to 1
18:39:34 Enough workers to start this run!
18:39:34 adjust_queue_size: lock accquired
18:39:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:39:34 HBMASTER: starting run at 1583775574.6195405
18:39:34 HBMASTER: adjusted queue size to (0, 1)
18:39:34 DISPATCHER: Finished worker discovery
18:39:34 start sampling a new configuration.
18:39:34 DISPATCHER: Trying to submit another job.
18:39:34 done sampling a new configuration.
18:39:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:39:34 HBMASTER: schedule new run for iteration 0
18:39:34 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
18:39:34 HBMASTER: submitting job (0, 0, 0) to dispatcher
18:39:34 DISPATCHER: trying to submit job (0, 0, 0)
18:39:34 DISPATCHER: trying to notify the job_runner thread.
18:39:34 HBMASTER: job (0, 0, 0) submitted to dispatcher
18:39:34 DISPATCHER: Trying to submit another job.
18:39:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:39:34 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:39:34 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:39:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:39:34 WORKER: start processing job (0, 0, 0)
18:39:34 WORKER: args: ()
18:39:34 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 723, 'last_n_outputs': 48, 'leak_rate': 0.785837400561296, 'lr': 0.006981039731265697, 'optimizer': 'Adam', 'sparsity': 0.904034224096982, 'steps_to_train': 67, 'weight_decay': 0.011289392231699794}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:40:34 DISPATCHER: Starting worker discovery
18:40:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:40:34 DISPATCHER: Finished worker discovery
18:41:29 WORKER: done with job (0, 0, 0), trying to register it.
18:41:29 WORKER: registered result for job (0, 0, 0) with dispatcher
18:41:29 DISPATCHER: job (0, 0, 0) finished
18:41:29 DISPATCHER: register_result: lock acquired
18:41:29 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
18:41:29 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 723, 'last_n_outputs': 48, 'leak_rate': 0.785837400561296, 'lr': 0.006981039731265697, 'optimizer': 'Adam', 'sparsity': 0.904034224096982, 'steps_to_train': 67, 'weight_decay': 0.011289392231699794}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.089128126240621, 'info': {'sick_no_sick': 0.089128126240621, 'config': "{'batch_size': 64, 'hidden_dim': 723, 'last_n_outputs': 48, 'leak_rate': 0.785837400561296, 'lr': 0.006981039731265697, 'optimizer': 'Adam', 'sparsity': 0.904034224096982, 'steps_to_train': 67, 'weight_decay': 0.011289392231699794}"}}
exception: None

18:41:29 job_callback for (0, 0, 0) started
18:41:29 job_callback for (0, 0, 0) got condition
18:41:29 DISPATCHER: Trying to submit another job.
18:41:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:41:29 Only 1 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
18:41:29 HBMASTER: Trying to run another job!
18:41:29 job_callback for (0, 0, 0) finished
18:41:29 start sampling a new configuration.
18:41:29 done sampling a new configuration.
18:41:29 HBMASTER: schedule new run for iteration 0
18:41:29 HBMASTER: trying submitting job (0, 0, 1) to dispatcher
18:41:29 HBMASTER: submitting job (0, 0, 1) to dispatcher
18:41:29 DISPATCHER: trying to submit job (0, 0, 1)
18:41:29 DISPATCHER: trying to notify the job_runner thread.
18:41:29 HBMASTER: job (0, 0, 1) submitted to dispatcher
18:41:29 DISPATCHER: Trying to submit another job.
18:41:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:41:29 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:41:29 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:41:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:41:29 WORKER: start processing job (0, 0, 1)
18:41:29 WORKER: args: ()
18:41:29 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 970, 'last_n_outputs': 20, 'leak_rate': 0.9362550402648038, 'lr': 0.007000936231426626, 'optimizer': 'Adam', 'sparsity': 0.781410098381483, 'steps_to_train': 63, 'weight_decay': 0.014434167239536336}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:41:34 DISPATCHER: Starting worker discovery
18:41:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:41:34 DISPATCHER: Finished worker discovery
18:42:34 DISPATCHER: Starting worker discovery
18:42:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:42:34 DISPATCHER: Finished worker discovery
18:43:18 WORKER: done with job (0, 0, 1), trying to register it.
18:43:18 WORKER: registered result for job (0, 0, 1) with dispatcher
18:43:18 DISPATCHER: job (0, 0, 1) finished
18:43:18 DISPATCHER: register_result: lock acquired
18:43:18 DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
18:43:18 job_id: (0, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 970, 'last_n_outputs': 20, 'leak_rate': 0.9362550402648038, 'lr': 0.007000936231426626, 'optimizer': 'Adam', 'sparsity': 0.781410098381483, 'steps_to_train': 63, 'weight_decay': 0.014434167239536336}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.16036361778855346, 'info': {'sick_no_sick': 0.16036361778855346, 'config': "{'batch_size': 16, 'hidden_dim': 970, 'last_n_outputs': 20, 'leak_rate': 0.9362550402648038, 'lr': 0.007000936231426626, 'optimizer': 'Adam', 'sparsity': 0.781410098381483, 'steps_to_train': 63, 'weight_decay': 0.014434167239536336}"}}
exception: None

18:43:18 job_callback for (0, 0, 1) started
18:43:18 DISPATCHER: Trying to submit another job.
18:43:18 job_callback for (0, 0, 1) got condition
18:43:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:43:18 Only 2 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
18:43:18 HBMASTER: Trying to run another job!
18:43:18 job_callback for (0, 0, 1) finished
18:43:18 start sampling a new configuration.
18:43:18 done sampling a new configuration.
18:43:18 HBMASTER: schedule new run for iteration 0
18:43:18 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
18:43:18 HBMASTER: submitting job (0, 0, 2) to dispatcher
18:43:18 DISPATCHER: trying to submit job (0, 0, 2)
18:43:18 DISPATCHER: trying to notify the job_runner thread.
18:43:18 HBMASTER: job (0, 0, 2) submitted to dispatcher
18:43:18 DISPATCHER: Trying to submit another job.
18:43:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:43:18 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:43:18 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:43:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:43:18 WORKER: start processing job (0, 0, 2)
18:43:18 WORKER: args: ()
18:43:18 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 348, 'last_n_outputs': 21, 'leak_rate': 0.8563905239047704, 'lr': 0.024713903305973988, 'optimizer': 'SGD', 'sparsity': 0.7879380525106308, 'steps_to_train': 49, 'weight_decay': 0.011928889473808947}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:43:34 DISPATCHER: Starting worker discovery
18:43:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:43:34 DISPATCHER: Finished worker discovery
18:44:34 DISPATCHER: Starting worker discovery
18:44:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:44:34 DISPATCHER: Finished worker discovery
18:45:06 WORKER: done with job (0, 0, 2), trying to register it.
18:45:06 WORKER: registered result for job (0, 0, 2) with dispatcher
18:45:06 DISPATCHER: job (0, 0, 2) finished
18:45:06 DISPATCHER: register_result: lock acquired
18:45:06 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
18:45:06 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 348, 'last_n_outputs': 21, 'leak_rate': 0.8563905239047704, 'lr': 0.024713903305973988, 'optimizer': 'SGD', 'sparsity': 0.7879380525106308, 'steps_to_train': 49, 'weight_decay': 0.011928889473808947}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.11777530326306224, 'info': {'sick_no_sick': 0.11777530326306224, 'config': "{'batch_size': 64, 'hidden_dim': 348, 'last_n_outputs': 21, 'leak_rate': 0.8563905239047704, 'lr': 0.024713903305973988, 'optimizer': 'SGD', 'sparsity': 0.7879380525106308, 'steps_to_train': 49, 'weight_decay': 0.011928889473808947}"}}
exception: None

18:45:06 job_callback for (0, 0, 2) started
18:45:06 job_callback for (0, 0, 2) got condition
18:45:06 DISPATCHER: Trying to submit another job.
18:45:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:45:06 Only 3 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
18:45:06 HBMASTER: Trying to run another job!
18:45:06 job_callback for (0, 0, 2) finished
18:45:06 start sampling a new configuration.
18:45:06 done sampling a new configuration.
18:45:06 HBMASTER: schedule new run for iteration 0
18:45:06 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
18:45:06 HBMASTER: submitting job (0, 0, 3) to dispatcher
18:45:06 DISPATCHER: trying to submit job (0, 0, 3)
18:45:06 DISPATCHER: trying to notify the job_runner thread.
18:45:06 HBMASTER: job (0, 0, 3) submitted to dispatcher
18:45:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:45:06 DISPATCHER: Trying to submit another job.
18:45:06 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:45:06 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:45:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:45:06 WORKER: start processing job (0, 0, 3)
18:45:06 WORKER: args: ()
18:45:06 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 402, 'last_n_outputs': 35, 'leak_rate': 0.795539644473837, 'lr': 0.05623569620988763, 'optimizer': 'Adam', 'sparsity': 0.8452493304892197, 'steps_to_train': 50, 'weight_decay': 0.016880599912543988}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:45:34 DISPATCHER: Starting worker discovery
18:45:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:45:34 DISPATCHER: Finished worker discovery
18:46:34 DISPATCHER: Starting worker discovery
18:46:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:46:34 DISPATCHER: Finished worker discovery
18:46:53 WORKER: done with job (0, 0, 3), trying to register it.
18:46:53 WORKER: registered result for job (0, 0, 3) with dispatcher
18:46:53 DISPATCHER: job (0, 0, 3) finished
18:46:53 DISPATCHER: register_result: lock acquired
18:46:53 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
18:46:53 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 402, 'last_n_outputs': 35, 'leak_rate': 0.795539644473837, 'lr': 0.05623569620988763, 'optimizer': 'Adam', 'sparsity': 0.8452493304892197, 'steps_to_train': 50, 'weight_decay': 0.016880599912543988}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.15369661284384992, 'info': {'sick_no_sick': 0.15369661284384992, 'config': "{'batch_size': 16, 'hidden_dim': 402, 'last_n_outputs': 35, 'leak_rate': 0.795539644473837, 'lr': 0.05623569620988763, 'optimizer': 'Adam', 'sparsity': 0.8452493304892197, 'steps_to_train': 50, 'weight_decay': 0.016880599912543988}"}}
exception: None

18:46:53 job_callback for (0, 0, 3) started
18:46:53 DISPATCHER: Trying to submit another job.
18:46:53 job_callback for (0, 0, 3) got condition
18:46:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:46:53 Only 4 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
18:46:53 HBMASTER: Trying to run another job!
18:46:53 job_callback for (0, 0, 3) finished
18:46:53 start sampling a new configuration.
18:46:53 done sampling a new configuration.
18:46:53 HBMASTER: schedule new run for iteration 0
18:46:53 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
18:46:53 HBMASTER: submitting job (0, 0, 4) to dispatcher
18:46:53 DISPATCHER: trying to submit job (0, 0, 4)
18:46:53 DISPATCHER: trying to notify the job_runner thread.
18:46:53 HBMASTER: job (0, 0, 4) submitted to dispatcher
18:46:53 DISPATCHER: Trying to submit another job.
18:46:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:46:53 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:46:53 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:46:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:46:53 WORKER: start processing job (0, 0, 4)
18:46:53 WORKER: args: ()
18:46:53 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 388, 'last_n_outputs': 38, 'leak_rate': 0.7793947641569635, 'lr': 0.00869219619059654, 'optimizer': 'SGD', 'sparsity': 0.9357278561460562, 'steps_to_train': 52, 'weight_decay': 0.08254578925802113}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:47:34 DISPATCHER: Starting worker discovery
18:47:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:47:34 DISPATCHER: Finished worker discovery
18:48:34 DISPATCHER: Starting worker discovery
18:48:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:48:34 DISPATCHER: Finished worker discovery
18:48:41 WORKER: done with job (0, 0, 4), trying to register it.
18:48:41 WORKER: registered result for job (0, 0, 4) with dispatcher
18:48:41 DISPATCHER: job (0, 0, 4) finished
18:48:41 DISPATCHER: register_result: lock acquired
18:48:41 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
18:48:41 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 388, 'last_n_outputs': 38, 'leak_rate': 0.7793947641569635, 'lr': 0.00869219619059654, 'optimizer': 'SGD', 'sparsity': 0.9357278561460562, 'steps_to_train': 52, 'weight_decay': 0.08254578925802113}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.011286680805338834, 'info': {'sick_no_sick': 0.011286680805338834, 'config': "{'batch_size': 16, 'hidden_dim': 388, 'last_n_outputs': 38, 'leak_rate': 0.7793947641569635, 'lr': 0.00869219619059654, 'optimizer': 'SGD', 'sparsity': 0.9357278561460562, 'steps_to_train': 52, 'weight_decay': 0.08254578925802113}"}}
exception: None

18:48:41 job_callback for (0, 0, 4) started
18:48:41 DISPATCHER: Trying to submit another job.
18:48:41 job_callback for (0, 0, 4) got condition
18:48:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:48:41 Only 5 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
18:48:41 HBMASTER: Trying to run another job!
18:48:41 job_callback for (0, 0, 4) finished
18:48:41 start sampling a new configuration.
18:48:41 done sampling a new configuration.
18:48:41 HBMASTER: schedule new run for iteration 0
18:48:41 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
18:48:41 HBMASTER: submitting job (0, 0, 5) to dispatcher
18:48:41 DISPATCHER: trying to submit job (0, 0, 5)
18:48:41 DISPATCHER: trying to notify the job_runner thread.
18:48:41 HBMASTER: job (0, 0, 5) submitted to dispatcher
18:48:41 DISPATCHER: Trying to submit another job.
18:48:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:48:41 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:48:41 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:48:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:48:41 WORKER: start processing job (0, 0, 5)
18:48:41 WORKER: args: ()
18:48:41 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 304, 'last_n_outputs': 19, 'leak_rate': 0.973117057714689, 'lr': 0.042253962945824, 'optimizer': 'SGD', 'sparsity': 0.9228931269882179, 'steps_to_train': 12, 'weight_decay': 0.10185120482858469}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:49:34 DISPATCHER: Starting worker discovery
18:49:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:49:34 DISPATCHER: Finished worker discovery
18:50:27 WORKER: done with job (0, 0, 5), trying to register it.
18:50:27 WORKER: registered result for job (0, 0, 5) with dispatcher
18:50:27 DISPATCHER: job (0, 0, 5) finished
18:50:27 DISPATCHER: register_result: lock acquired
18:50:27 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
18:50:27 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 304, 'last_n_outputs': 19, 'leak_rate': 0.973117057714689, 'lr': 0.042253962945824, 'optimizer': 'SGD', 'sparsity': 0.9228931269882179, 'steps_to_train': 12, 'weight_decay': 0.10185120482858469}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.010780129582731649, 'info': {'sick_no_sick': 0.010780129582731649, 'config': "{'batch_size': 128, 'hidden_dim': 304, 'last_n_outputs': 19, 'leak_rate': 0.973117057714689, 'lr': 0.042253962945824, 'optimizer': 'SGD', 'sparsity': 0.9228931269882179, 'steps_to_train': 12, 'weight_decay': 0.10185120482858469}"}}
exception: None

18:50:27 job_callback for (0, 0, 5) started
18:50:27 job_callback for (0, 0, 5) got condition
18:50:27 DISPATCHER: Trying to submit another job.
18:50:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:50:28 Only 6 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
18:50:28 HBMASTER: Trying to run another job!
18:50:28 job_callback for (0, 0, 5) finished
18:50:28 start sampling a new configuration.
18:50:28 done sampling a new configuration.
18:50:28 HBMASTER: schedule new run for iteration 0
18:50:28 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
18:50:28 HBMASTER: submitting job (0, 0, 6) to dispatcher
18:50:28 DISPATCHER: trying to submit job (0, 0, 6)
18:50:28 DISPATCHER: trying to notify the job_runner thread.
18:50:28 HBMASTER: job (0, 0, 6) submitted to dispatcher
18:50:28 DISPATCHER: Trying to submit another job.
18:50:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:50:28 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:50:28 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:50:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:50:28 WORKER: start processing job (0, 0, 6)
18:50:28 WORKER: args: ()
18:50:28 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 342, 'last_n_outputs': 37, 'leak_rate': 0.8978851895994716, 'lr': 0.07342915856420486, 'optimizer': 'Adam', 'sparsity': 0.8808665998325257, 'steps_to_train': 21, 'weight_decay': 0.1381817464147845}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:50:34 DISPATCHER: Starting worker discovery
18:50:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:50:34 DISPATCHER: Finished worker discovery
18:51:34 DISPATCHER: Starting worker discovery
18:51:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:51:34 DISPATCHER: Finished worker discovery
18:52:15 WORKER: done with job (0, 0, 6), trying to register it.
18:52:15 WORKER: registered result for job (0, 0, 6) with dispatcher
18:52:15 DISPATCHER: job (0, 0, 6) finished
18:52:15 DISPATCHER: register_result: lock acquired
18:52:15 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
18:52:15 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 342, 'last_n_outputs': 37, 'leak_rate': 0.8978851895994716, 'lr': 0.07342915856420486, 'optimizer': 'Adam', 'sparsity': 0.8808665998325257, 'steps_to_train': 21, 'weight_decay': 0.1381817464147845}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.015244982473793519, 'info': {'sick_no_sick': 0.015244982473793519, 'config': "{'batch_size': 32, 'hidden_dim': 342, 'last_n_outputs': 37, 'leak_rate': 0.8978851895994716, 'lr': 0.07342915856420486, 'optimizer': 'Adam', 'sparsity': 0.8808665998325257, 'steps_to_train': 21, 'weight_decay': 0.1381817464147845}"}}
exception: None

18:52:15 job_callback for (0, 0, 6) started
18:52:15 DISPATCHER: Trying to submit another job.
18:52:15 job_callback for (0, 0, 6) got condition
18:52:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:52:15 Only 7 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
18:52:15 HBMASTER: Trying to run another job!
18:52:15 job_callback for (0, 0, 6) finished
18:52:15 start sampling a new configuration.
18:52:15 done sampling a new configuration.
18:52:15 HBMASTER: schedule new run for iteration 0
18:52:15 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
18:52:15 HBMASTER: submitting job (0, 0, 7) to dispatcher
18:52:15 DISPATCHER: trying to submit job (0, 0, 7)
18:52:15 DISPATCHER: trying to notify the job_runner thread.
18:52:15 HBMASTER: job (0, 0, 7) submitted to dispatcher
18:52:15 DISPATCHER: Trying to submit another job.
18:52:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:52:15 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:52:15 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:52:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:52:15 WORKER: start processing job (0, 0, 7)
18:52:15 WORKER: args: ()
18:52:15 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 207, 'last_n_outputs': 16, 'leak_rate': 0.9842981516787215, 'lr': 0.010854475475523723, 'optimizer': 'Adam', 'sparsity': 0.8527205152492151, 'steps_to_train': 15, 'weight_decay': 0.17434403150690397}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:52:34 DISPATCHER: Starting worker discovery
18:52:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:52:34 DISPATCHER: Finished worker discovery
18:53:34 DISPATCHER: Starting worker discovery
18:53:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:53:34 DISPATCHER: Finished worker discovery
18:54:03 WORKER: done with job (0, 0, 7), trying to register it.
18:54:03 WORKER: registered result for job (0, 0, 7) with dispatcher
18:54:03 DISPATCHER: job (0, 0, 7) finished
18:54:03 DISPATCHER: register_result: lock acquired
18:54:03 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
18:54:03 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 207, 'last_n_outputs': 16, 'leak_rate': 0.9842981516787215, 'lr': 0.010854475475523723, 'optimizer': 'Adam', 'sparsity': 0.8527205152492151, 'steps_to_train': 15, 'weight_decay': 0.17434403150690397}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1526577637909638, 'info': {'sick_no_sick': 0.1526577637909638, 'config': "{'batch_size': 64, 'hidden_dim': 207, 'last_n_outputs': 16, 'leak_rate': 0.9842981516787215, 'lr': 0.010854475475523723, 'optimizer': 'Adam', 'sparsity': 0.8527205152492151, 'steps_to_train': 15, 'weight_decay': 0.17434403150690397}"}}
exception: None

18:54:03 job_callback for (0, 0, 7) started
18:54:03 job_callback for (0, 0, 7) got condition
18:54:03 DISPATCHER: Trying to submit another job.
18:54:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:54:03 Only 8 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
18:54:03 HBMASTER: Trying to run another job!
18:54:03 job_callback for (0, 0, 7) finished
18:54:03 start sampling a new configuration.
18:54:03 done sampling a new configuration.
18:54:03 HBMASTER: schedule new run for iteration 0
18:54:03 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
18:54:03 HBMASTER: submitting job (0, 0, 8) to dispatcher
18:54:03 DISPATCHER: trying to submit job (0, 0, 8)
18:54:03 DISPATCHER: trying to notify the job_runner thread.
18:54:03 HBMASTER: job (0, 0, 8) submitted to dispatcher
18:54:03 DISPATCHER: Trying to submit another job.
18:54:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:54:03 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:54:03 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:54:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:54:03 WORKER: start processing job (0, 0, 8)
18:54:03 WORKER: args: ()
18:54:03 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 626, 'last_n_outputs': 29, 'leak_rate': 0.7829255712488108, 'lr': 0.014810038346758226, 'optimizer': 'Adam', 'sparsity': 0.9225209684665923, 'steps_to_train': 31, 'weight_decay': 0.01571872599753148}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:54:34 DISPATCHER: Starting worker discovery
18:54:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:54:34 DISPATCHER: Finished worker discovery
18:55:34 DISPATCHER: Starting worker discovery
18:55:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:55:34 DISPATCHER: Finished worker discovery
18:55:51 WORKER: done with job (0, 0, 8), trying to register it.
18:55:51 WORKER: registered result for job (0, 0, 8) with dispatcher
18:55:51 DISPATCHER: job (0, 0, 8) finished
18:55:51 DISPATCHER: register_result: lock acquired
18:55:51 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
18:55:51 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 626, 'last_n_outputs': 29, 'leak_rate': 0.7829255712488108, 'lr': 0.014810038346758226, 'optimizer': 'Adam', 'sparsity': 0.9225209684665923, 'steps_to_train': 31, 'weight_decay': 0.01571872599753148}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.23471396088947788, 'info': {'sick_no_sick': 0.23471396088947788, 'config': "{'batch_size': 32, 'hidden_dim': 626, 'last_n_outputs': 29, 'leak_rate': 0.7829255712488108, 'lr': 0.014810038346758226, 'optimizer': 'Adam', 'sparsity': 0.9225209684665923, 'steps_to_train': 31, 'weight_decay': 0.01571872599753148}"}}
exception: None

18:55:51 job_callback for (0, 0, 8) started
18:55:51 DISPATCHER: Trying to submit another job.
18:55:51 job_callback for (0, 0, 8) got condition
18:55:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:55:51 Only 9 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
18:55:51 HBMASTER: Trying to run another job!
18:55:51 job_callback for (0, 0, 8) finished
18:55:51 start sampling a new configuration.
18:55:51 done sampling a new configuration.
18:55:51 HBMASTER: schedule new run for iteration 0
18:55:51 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
18:55:51 HBMASTER: submitting job (0, 0, 9) to dispatcher
18:55:51 DISPATCHER: trying to submit job (0, 0, 9)
18:55:51 DISPATCHER: trying to notify the job_runner thread.
18:55:51 HBMASTER: job (0, 0, 9) submitted to dispatcher
18:55:51 DISPATCHER: Trying to submit another job.
18:55:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:55:51 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:55:51 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:55:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:55:51 WORKER: start processing job (0, 0, 9)
18:55:51 WORKER: args: ()
18:55:51 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 570, 'last_n_outputs': 41, 'leak_rate': 0.8458892140749139, 'lr': 0.0010640503296790557, 'optimizer': 'SGD', 'sparsity': 0.8550615557337402, 'steps_to_train': 19, 'weight_decay': 0.025195718626074722}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:56:34 DISPATCHER: Starting worker discovery
18:56:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:56:34 DISPATCHER: Finished worker discovery
18:57:34 DISPATCHER: Starting worker discovery
18:57:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:57:34 DISPATCHER: Finished worker discovery
18:57:40 WORKER: done with job (0, 0, 9), trying to register it.
18:57:40 WORKER: registered result for job (0, 0, 9) with dispatcher
18:57:40 DISPATCHER: job (0, 0, 9) finished
18:57:40 DISPATCHER: register_result: lock acquired
18:57:40 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
18:57:40 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 570, 'last_n_outputs': 41, 'leak_rate': 0.8458892140749139, 'lr': 0.0010640503296790557, 'optimizer': 'SGD', 'sparsity': 0.8550615557337402, 'steps_to_train': 19, 'weight_decay': 0.025195718626074722}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.17105433240107407, 'info': {'sick_no_sick': 0.17105433240107407, 'config': "{'batch_size': 128, 'hidden_dim': 570, 'last_n_outputs': 41, 'leak_rate': 0.8458892140749139, 'lr': 0.0010640503296790557, 'optimizer': 'SGD', 'sparsity': 0.8550615557337402, 'steps_to_train': 19, 'weight_decay': 0.025195718626074722}"}}
exception: None

18:57:40 DISPATCHER: Trying to submit another job.
18:57:40 job_callback for (0, 0, 9) started
18:57:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:57:40 job_callback for (0, 0, 9) got condition
18:57:40 HBMASTER: Trying to run another job!
18:57:40 job_callback for (0, 0, 9) finished
18:57:40 start sampling a new configuration.
18:57:40 done sampling a new configuration.
18:57:40 HBMASTER: schedule new run for iteration 0
18:57:40 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
18:57:40 HBMASTER: submitting job (0, 0, 10) to dispatcher
18:57:40 DISPATCHER: trying to submit job (0, 0, 10)
18:57:40 DISPATCHER: trying to notify the job_runner thread.
18:57:40 HBMASTER: job (0, 0, 10) submitted to dispatcher
18:57:40 DISPATCHER: Trying to submit another job.
18:57:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:57:40 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:57:40 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:57:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:57:40 WORKER: start processing job (0, 0, 10)
18:57:40 WORKER: args: ()
18:57:40 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 810, 'last_n_outputs': 13, 'leak_rate': 0.8160260751598141, 'lr': 0.05067368983128376, 'optimizer': 'Adam', 'sparsity': 0.8680539810681247, 'steps_to_train': 47, 'weight_decay': 0.024663244582559966}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:58:34 DISPATCHER: Starting worker discovery
18:58:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:58:34 DISPATCHER: Finished worker discovery
18:59:26 WORKER: done with job (0, 0, 10), trying to register it.
18:59:26 WORKER: registered result for job (0, 0, 10) with dispatcher
18:59:26 DISPATCHER: job (0, 0, 10) finished
18:59:26 DISPATCHER: register_result: lock acquired
18:59:26 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
18:59:26 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 810, 'last_n_outputs': 13, 'leak_rate': 0.8160260751598141, 'lr': 0.05067368983128376, 'optimizer': 'Adam', 'sparsity': 0.8680539810681247, 'steps_to_train': 47, 'weight_decay': 0.024663244582559966}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.05510769449709199, 'info': {'sick_no_sick': 0.05510769449709199, 'config': "{'batch_size': 32, 'hidden_dim': 810, 'last_n_outputs': 13, 'leak_rate': 0.8160260751598141, 'lr': 0.05067368983128376, 'optimizer': 'Adam', 'sparsity': 0.8680539810681247, 'steps_to_train': 47, 'weight_decay': 0.024663244582559966}"}}
exception: None

18:59:26 job_callback for (0, 0, 10) started
18:59:26 job_callback for (0, 0, 10) got condition
18:59:26 DISPATCHER: Trying to submit another job.
18:59:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:59:26 HBMASTER: Trying to run another job!
18:59:26 job_callback for (0, 0, 10) finished
18:59:26 start sampling a new configuration.
18:59:26 done sampling a new configuration.
18:59:26 HBMASTER: schedule new run for iteration 0
18:59:26 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
18:59:26 HBMASTER: submitting job (0, 0, 11) to dispatcher
18:59:26 DISPATCHER: trying to submit job (0, 0, 11)
18:59:26 DISPATCHER: trying to notify the job_runner thread.
18:59:26 HBMASTER: job (0, 0, 11) submitted to dispatcher
18:59:26 DISPATCHER: Trying to submit another job.
18:59:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:59:26 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:59:26 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:59:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:59:26 WORKER: start processing job (0, 0, 11)
18:59:26 WORKER: args: ()
18:59:26 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 747, 'last_n_outputs': 22, 'leak_rate': 0.8241569774659603, 'lr': 0.07475685988893112, 'optimizer': 'SGD', 'sparsity': 0.8824901623815671, 'steps_to_train': 59, 'weight_decay': 0.024700825493802377}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:59:34 DISPATCHER: Starting worker discovery
18:59:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:59:34 DISPATCHER: Finished worker discovery
19:00:34 DISPATCHER: Starting worker discovery
19:00:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:00:34 DISPATCHER: Finished worker discovery
19:01:15 WORKER: done with job (0, 0, 11), trying to register it.
19:01:15 WORKER: registered result for job (0, 0, 11) with dispatcher
19:01:15 DISPATCHER: job (0, 0, 11) finished
19:01:15 DISPATCHER: register_result: lock acquired
19:01:15 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
19:01:15 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 747, 'last_n_outputs': 22, 'leak_rate': 0.8241569774659603, 'lr': 0.07475685988893112, 'optimizer': 'SGD', 'sparsity': 0.8824901623815671, 'steps_to_train': 59, 'weight_decay': 0.024700825493802377}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.13553144656710514, 'info': {'sick_no_sick': 0.13553144656710514, 'config': "{'batch_size': 32, 'hidden_dim': 747, 'last_n_outputs': 22, 'leak_rate': 0.8241569774659603, 'lr': 0.07475685988893112, 'optimizer': 'SGD', 'sparsity': 0.8824901623815671, 'steps_to_train': 59, 'weight_decay': 0.024700825493802377}"}}
exception: None

19:01:15 DISPATCHER: Trying to submit another job.
19:01:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:01:15 job_callback for (0, 0, 11) started
19:01:15 job_callback for (0, 0, 11) got condition
19:01:15 HBMASTER: Trying to run another job!
19:01:15 job_callback for (0, 0, 11) finished
19:01:15 start sampling a new configuration.
19:01:15 done sampling a new configuration.
19:01:15 HBMASTER: schedule new run for iteration 0
19:01:15 HBMASTER: trying submitting job (0, 0, 12) to dispatcher
19:01:15 HBMASTER: submitting job (0, 0, 12) to dispatcher
19:01:15 DISPATCHER: trying to submit job (0, 0, 12)
19:01:15 DISPATCHER: trying to notify the job_runner thread.
19:01:15 HBMASTER: job (0, 0, 12) submitted to dispatcher
19:01:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:01:15 DISPATCHER: Trying to submit another job.
19:01:15 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:01:15 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:01:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:01:15 WORKER: start processing job (0, 0, 12)
19:01:15 WORKER: args: ()
19:01:15 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 420, 'last_n_outputs': 44, 'leak_rate': 0.7550687813183201, 'lr': 0.04583926049865948, 'optimizer': 'SGD', 'sparsity': 0.9632852973229635, 'steps_to_train': 70, 'weight_decay': 0.15332317536749232}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:01:34 DISPATCHER: Starting worker discovery
19:01:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:01:34 DISPATCHER: Finished worker discovery
19:02:34 DISPATCHER: Starting worker discovery
19:02:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:02:34 DISPATCHER: Finished worker discovery
19:03:03 WORKER: done with job (0, 0, 12), trying to register it.
19:03:03 WORKER: registered result for job (0, 0, 12) with dispatcher
19:03:03 DISPATCHER: job (0, 0, 12) finished
19:03:03 DISPATCHER: register_result: lock acquired
19:03:03 DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
19:03:03 job_id: (0, 0, 12)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 420, 'last_n_outputs': 44, 'leak_rate': 0.7550687813183201, 'lr': 0.04583926049865948, 'optimizer': 'SGD', 'sparsity': 0.9632852973229635, 'steps_to_train': 70, 'weight_decay': 0.15332317536749232}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.0007659377229109361, 'info': {'sick_no_sick': -0.0007659377229109361, 'config': "{'batch_size': 64, 'hidden_dim': 420, 'last_n_outputs': 44, 'leak_rate': 0.7550687813183201, 'lr': 0.04583926049865948, 'optimizer': 'SGD', 'sparsity': 0.9632852973229635, 'steps_to_train': 70, 'weight_decay': 0.15332317536749232}"}}
exception: None

19:03:03 job_callback for (0, 0, 12) started
19:03:03 job_callback for (0, 0, 12) got condition
19:03:03 DISPATCHER: Trying to submit another job.
19:03:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:03:03 HBMASTER: Trying to run another job!
19:03:03 job_callback for (0, 0, 12) finished
19:03:03 start sampling a new configuration.
19:03:03 done sampling a new configuration.
19:03:03 HBMASTER: schedule new run for iteration 0
19:03:03 HBMASTER: trying submitting job (0, 0, 13) to dispatcher
19:03:03 HBMASTER: submitting job (0, 0, 13) to dispatcher
19:03:03 DISPATCHER: trying to submit job (0, 0, 13)
19:03:03 DISPATCHER: trying to notify the job_runner thread.
19:03:03 HBMASTER: job (0, 0, 13) submitted to dispatcher
19:03:03 DISPATCHER: Trying to submit another job.
19:03:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:03:03 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:03:03 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:03:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:03:03 WORKER: start processing job (0, 0, 13)
19:03:03 WORKER: args: ()
19:03:03 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 362, 'last_n_outputs': 50, 'leak_rate': 0.8026074631000555, 'lr': 0.03147455969561027, 'optimizer': 'SGD', 'sparsity': 0.9668760535007216, 'steps_to_train': 38, 'weight_decay': 0.06552085909079464}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:03:34 DISPATCHER: Starting worker discovery
19:03:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:03:34 DISPATCHER: Finished worker discovery
19:04:34 DISPATCHER: Starting worker discovery
19:04:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:04:34 DISPATCHER: Finished worker discovery
19:04:51 WORKER: done with job (0, 0, 13), trying to register it.
19:04:51 WORKER: registered result for job (0, 0, 13) with dispatcher
19:04:51 DISPATCHER: job (0, 0, 13) finished
19:04:51 DISPATCHER: register_result: lock acquired
19:04:51 DISPATCHER: job (0, 0, 13) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
19:04:51 job_id: (0, 0, 13)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 362, 'last_n_outputs': 50, 'leak_rate': 0.8026074631000555, 'lr': 0.03147455969561027, 'optimizer': 'SGD', 'sparsity': 0.9668760535007216, 'steps_to_train': 38, 'weight_decay': 0.06552085909079464}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.004209099865379666, 'info': {'sick_no_sick': 0.004209099865379666, 'config': "{'batch_size': 64, 'hidden_dim': 362, 'last_n_outputs': 50, 'leak_rate': 0.8026074631000555, 'lr': 0.03147455969561027, 'optimizer': 'SGD', 'sparsity': 0.9668760535007216, 'steps_to_train': 38, 'weight_decay': 0.06552085909079464}"}}
exception: None

19:04:51 job_callback for (0, 0, 13) started
19:04:51 job_callback for (0, 0, 13) got condition
19:04:51 DISPATCHER: Trying to submit another job.
19:04:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:04:51 HBMASTER: Trying to run another job!
19:04:51 job_callback for (0, 0, 13) finished
19:04:51 start sampling a new configuration.
19:04:51 done sampling a new configuration.
19:04:51 HBMASTER: schedule new run for iteration 0
19:04:51 HBMASTER: trying submitting job (0, 0, 14) to dispatcher
19:04:51 HBMASTER: submitting job (0, 0, 14) to dispatcher
19:04:51 DISPATCHER: trying to submit job (0, 0, 14)
19:04:51 DISPATCHER: trying to notify the job_runner thread.
19:04:51 HBMASTER: job (0, 0, 14) submitted to dispatcher
19:04:51 DISPATCHER: Trying to submit another job.
19:04:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:04:51 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:04:51 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:04:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:04:51 WORKER: start processing job (0, 0, 14)
19:04:51 WORKER: args: ()
19:04:51 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 255, 'last_n_outputs': 18, 'leak_rate': 0.8474278159412721, 'lr': 0.008718759588618726, 'optimizer': 'Adam', 'sparsity': 0.8192347393670106, 'steps_to_train': 78, 'weight_decay': 0.14933399400559808}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:05:34 DISPATCHER: Starting worker discovery
19:05:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:05:34 DISPATCHER: Finished worker discovery
19:06:34 DISPATCHER: Starting worker discovery
19:06:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:06:34 DISPATCHER: Finished worker discovery
19:06:39 WORKER: done with job (0, 0, 14), trying to register it.
19:06:39 WORKER: registered result for job (0, 0, 14) with dispatcher
19:06:39 DISPATCHER: job (0, 0, 14) finished
19:06:39 DISPATCHER: register_result: lock acquired
19:06:39 DISPATCHER: job (0, 0, 14) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
19:06:39 job_id: (0, 0, 14)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 255, 'last_n_outputs': 18, 'leak_rate': 0.8474278159412721, 'lr': 0.008718759588618726, 'optimizer': 'Adam', 'sparsity': 0.8192347393670106, 'steps_to_train': 78, 'weight_decay': 0.14933399400559808}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.037305113039959786, 'info': {'sick_no_sick': 0.037305113039959786, 'config': "{'batch_size': 16, 'hidden_dim': 255, 'last_n_outputs': 18, 'leak_rate': 0.8474278159412721, 'lr': 0.008718759588618726, 'optimizer': 'Adam', 'sparsity': 0.8192347393670106, 'steps_to_train': 78, 'weight_decay': 0.14933399400559808}"}}
exception: None

19:06:39 job_callback for (0, 0, 14) started
19:06:39 job_callback for (0, 0, 14) got condition
19:06:39 DISPATCHER: Trying to submit another job.
19:06:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:06:39 HBMASTER: Trying to run another job!
19:06:39 job_callback for (0, 0, 14) finished
19:06:39 start sampling a new configuration.
19:06:39 done sampling a new configuration.
19:06:39 HBMASTER: schedule new run for iteration 0
19:06:39 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
19:06:39 HBMASTER: submitting job (0, 0, 15) to dispatcher
19:06:39 DISPATCHER: trying to submit job (0, 0, 15)
19:06:39 DISPATCHER: trying to notify the job_runner thread.
19:06:39 HBMASTER: job (0, 0, 15) submitted to dispatcher
19:06:39 DISPATCHER: Trying to submit another job.
19:06:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:06:39 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:06:39 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:06:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:06:39 WORKER: start processing job (0, 0, 15)
19:06:39 WORKER: args: ()
19:06:39 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 504, 'last_n_outputs': 11, 'leak_rate': 0.8394416979472488, 'lr': 0.05260168348727783, 'optimizer': 'SGD', 'sparsity': 0.9367222298941769, 'steps_to_train': 21, 'weight_decay': 0.011672783818815518}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:07:34 DISPATCHER: Starting worker discovery
19:07:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:07:34 DISPATCHER: Finished worker discovery
19:08:27 WORKER: done with job (0, 0, 15), trying to register it.
19:08:27 WORKER: registered result for job (0, 0, 15) with dispatcher
19:08:27 DISPATCHER: job (0, 0, 15) finished
19:08:27 DISPATCHER: register_result: lock acquired
19:08:27 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
19:08:27 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 504, 'last_n_outputs': 11, 'leak_rate': 0.8394416979472488, 'lr': 0.05260168348727783, 'optimizer': 'SGD', 'sparsity': 0.9367222298941769, 'steps_to_train': 21, 'weight_decay': 0.011672783818815518}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0882446344548825, 'info': {'sick_no_sick': 0.0882446344548825, 'config': "{'batch_size': 32, 'hidden_dim': 504, 'last_n_outputs': 11, 'leak_rate': 0.8394416979472488, 'lr': 0.05260168348727783, 'optimizer': 'SGD', 'sparsity': 0.9367222298941769, 'steps_to_train': 21, 'weight_decay': 0.011672783818815518}"}}
exception: None

19:08:27 job_callback for (0, 0, 15) started
19:08:27 DISPATCHER: Trying to submit another job.
19:08:27 job_callback for (0, 0, 15) got condition
19:08:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:08:27 HBMASTER: Trying to run another job!
19:08:27 job_callback for (0, 0, 15) finished
19:08:27 start sampling a new configuration.
19:08:27 done sampling a new configuration.
19:08:27 HBMASTER: schedule new run for iteration 0
19:08:27 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
19:08:27 HBMASTER: submitting job (0, 0, 16) to dispatcher
19:08:27 DISPATCHER: trying to submit job (0, 0, 16)
19:08:27 DISPATCHER: trying to notify the job_runner thread.
19:08:27 HBMASTER: job (0, 0, 16) submitted to dispatcher
19:08:27 DISPATCHER: Trying to submit another job.
19:08:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:08:27 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:08:27 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:08:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:08:27 WORKER: start processing job (0, 0, 16)
19:08:27 WORKER: args: ()
19:08:27 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 808, 'last_n_outputs': 49, 'leak_rate': 0.818179525743189, 'lr': 0.002353728719720085, 'optimizer': 'Adam', 'sparsity': 0.8300530454747739, 'steps_to_train': 98, 'weight_decay': 0.19053369737739712}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:08:34 DISPATCHER: Starting worker discovery
19:08:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:08:34 DISPATCHER: Finished worker discovery
19:09:34 DISPATCHER: Starting worker discovery
19:09:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:09:34 DISPATCHER: Finished worker discovery
19:10:17 WORKER: done with job (0, 0, 16), trying to register it.
19:10:17 WORKER: registered result for job (0, 0, 16) with dispatcher
19:10:17 DISPATCHER: job (0, 0, 16) finished
19:10:17 DISPATCHER: register_result: lock acquired
19:10:17 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
19:10:17 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 808, 'last_n_outputs': 49, 'leak_rate': 0.818179525743189, 'lr': 0.002353728719720085, 'optimizer': 'Adam', 'sparsity': 0.8300530454747739, 'steps_to_train': 98, 'weight_decay': 0.19053369737739712}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.08473151262124048, 'info': {'sick_no_sick': 0.08473151262124048, 'config': "{'batch_size': 16, 'hidden_dim': 808, 'last_n_outputs': 49, 'leak_rate': 0.818179525743189, 'lr': 0.002353728719720085, 'optimizer': 'Adam', 'sparsity': 0.8300530454747739, 'steps_to_train': 98, 'weight_decay': 0.19053369737739712}"}}
exception: None

19:10:17 job_callback for (0, 0, 16) started
19:10:17 DISPATCHER: Trying to submit another job.
19:10:17 job_callback for (0, 0, 16) got condition
19:10:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:10:17 HBMASTER: Trying to run another job!
19:10:17 job_callback for (0, 0, 16) finished
19:10:17 start sampling a new configuration.
19:10:17 done sampling a new configuration.
19:10:17 HBMASTER: schedule new run for iteration 0
19:10:17 HBMASTER: trying submitting job (0, 0, 17) to dispatcher
19:10:17 HBMASTER: submitting job (0, 0, 17) to dispatcher
19:10:17 DISPATCHER: trying to submit job (0, 0, 17)
19:10:17 DISPATCHER: trying to notify the job_runner thread.
19:10:17 HBMASTER: job (0, 0, 17) submitted to dispatcher
19:10:17 DISPATCHER: Trying to submit another job.
19:10:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:10:17 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:10:17 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:10:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:10:17 WORKER: start processing job (0, 0, 17)
19:10:17 WORKER: args: ()
19:10:17 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 435, 'last_n_outputs': 45, 'leak_rate': 0.8908044564996284, 'lr': 0.0012049127332055924, 'optimizer': 'SGD', 'sparsity': 0.8849090495040177, 'steps_to_train': 37, 'weight_decay': 0.039660375714767764}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:10:34 DISPATCHER: Starting worker discovery
19:10:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:10:34 DISPATCHER: Finished worker discovery
19:11:34 DISPATCHER: Starting worker discovery
19:11:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:11:34 DISPATCHER: Finished worker discovery
19:12:03 WORKER: done with job (0, 0, 17), trying to register it.
19:12:03 WORKER: registered result for job (0, 0, 17) with dispatcher
19:12:03 DISPATCHER: job (0, 0, 17) finished
19:12:03 DISPATCHER: register_result: lock acquired
19:12:03 DISPATCHER: job (0, 0, 17) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
19:12:03 job_id: (0, 0, 17)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 435, 'last_n_outputs': 45, 'leak_rate': 0.8908044564996284, 'lr': 0.0012049127332055924, 'optimizer': 'SGD', 'sparsity': 0.8849090495040177, 'steps_to_train': 37, 'weight_decay': 0.039660375714767764}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.20786815263395972, 'info': {'sick_no_sick': 0.20786815263395972, 'config': "{'batch_size': 16, 'hidden_dim': 435, 'last_n_outputs': 45, 'leak_rate': 0.8908044564996284, 'lr': 0.0012049127332055924, 'optimizer': 'SGD', 'sparsity': 0.8849090495040177, 'steps_to_train': 37, 'weight_decay': 0.039660375714767764}"}}
exception: None

19:12:03 job_callback for (0, 0, 17) started
19:12:03 DISPATCHER: Trying to submit another job.
19:12:03 job_callback for (0, 0, 17) got condition
19:12:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:12:03 HBMASTER: Trying to run another job!
19:12:03 job_callback for (0, 0, 17) finished
19:12:03 start sampling a new configuration.
19:12:03 done sampling a new configuration.
19:12:03 HBMASTER: schedule new run for iteration 0
19:12:03 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
19:12:03 HBMASTER: submitting job (0, 0, 18) to dispatcher
19:12:03 DISPATCHER: trying to submit job (0, 0, 18)
19:12:03 DISPATCHER: trying to notify the job_runner thread.
19:12:03 HBMASTER: job (0, 0, 18) submitted to dispatcher
19:12:03 DISPATCHER: Trying to submit another job.
19:12:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:12:03 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:12:03 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:12:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:12:03 WORKER: start processing job (0, 0, 18)
19:12:03 WORKER: args: ()
19:12:03 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 968, 'last_n_outputs': 20, 'leak_rate': 0.984748749461624, 'lr': 0.008590395100442696, 'optimizer': 'Adam', 'sparsity': 0.8216004201332118, 'steps_to_train': 76, 'weight_decay': 0.028893016753584758}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:12:34 DISPATCHER: Starting worker discovery
19:12:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:12:34 DISPATCHER: Finished worker discovery
19:13:34 DISPATCHER: Starting worker discovery
19:13:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:13:34 DISPATCHER: Finished worker discovery
19:13:53 WORKER: done with job (0, 0, 18), trying to register it.
19:13:53 WORKER: registered result for job (0, 0, 18) with dispatcher
19:13:53 DISPATCHER: job (0, 0, 18) finished
19:13:53 DISPATCHER: register_result: lock acquired
19:13:53 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
19:13:53 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 968, 'last_n_outputs': 20, 'leak_rate': 0.984748749461624, 'lr': 0.008590395100442696, 'optimizer': 'Adam', 'sparsity': 0.8216004201332118, 'steps_to_train': 76, 'weight_decay': 0.028893016753584758}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.17413015288776834, 'info': {'sick_no_sick': 0.17413015288776834, 'config': "{'batch_size': 32, 'hidden_dim': 968, 'last_n_outputs': 20, 'leak_rate': 0.984748749461624, 'lr': 0.008590395100442696, 'optimizer': 'Adam', 'sparsity': 0.8216004201332118, 'steps_to_train': 76, 'weight_decay': 0.028893016753584758}"}}
exception: None

19:13:53 job_callback for (0, 0, 18) started
19:13:53 job_callback for (0, 0, 18) got condition
19:13:53 DISPATCHER: Trying to submit another job.
19:13:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:13:53 HBMASTER: Trying to run another job!
19:13:53 job_callback for (0, 0, 18) finished
19:13:53 start sampling a new configuration.
19:13:53 done sampling a new configuration.
19:13:53 HBMASTER: schedule new run for iteration 0
19:13:53 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
19:13:53 HBMASTER: submitting job (0, 0, 19) to dispatcher
19:13:53 DISPATCHER: trying to submit job (0, 0, 19)
19:13:53 DISPATCHER: trying to notify the job_runner thread.
19:13:53 HBMASTER: job (0, 0, 19) submitted to dispatcher
19:13:53 DISPATCHER: Trying to submit another job.
19:13:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:13:53 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:13:53 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:13:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:13:53 WORKER: start processing job (0, 0, 19)
19:13:53 WORKER: args: ()
19:13:53 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 518, 'last_n_outputs': 43, 'leak_rate': 0.8777704161494415, 'lr': 0.0291718955644775, 'optimizer': 'Adam', 'sparsity': 0.8476572133175637, 'steps_to_train': 21, 'weight_decay': 0.04461841092657966}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:14:34 DISPATCHER: Starting worker discovery
19:14:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:14:34 DISPATCHER: Finished worker discovery
19:15:34 DISPATCHER: Starting worker discovery
19:15:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:15:34 DISPATCHER: Finished worker discovery
19:15:39 WORKER: done with job (0, 0, 19), trying to register it.
19:15:39 WORKER: registered result for job (0, 0, 19) with dispatcher
19:15:39 DISPATCHER: job (0, 0, 19) finished
19:15:39 DISPATCHER: register_result: lock acquired
19:15:39 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
19:15:39 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 518, 'last_n_outputs': 43, 'leak_rate': 0.8777704161494415, 'lr': 0.0291718955644775, 'optimizer': 'Adam', 'sparsity': 0.8476572133175637, 'steps_to_train': 21, 'weight_decay': 0.04461841092657966}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1294987639713525, 'info': {'sick_no_sick': 0.1294987639713525, 'config': "{'batch_size': 64, 'hidden_dim': 518, 'last_n_outputs': 43, 'leak_rate': 0.8777704161494415, 'lr': 0.0291718955644775, 'optimizer': 'Adam', 'sparsity': 0.8476572133175637, 'steps_to_train': 21, 'weight_decay': 0.04461841092657966}"}}
exception: None

19:15:39 job_callback for (0, 0, 19) started
19:15:39 DISPATCHER: Trying to submit another job.
19:15:39 job_callback for (0, 0, 19) got condition
19:15:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:15:39 done building a new model for budget 44.444444 based on 10/17 split
Best loss for this budget:-0.234714





19:15:39 HBMASTER: Trying to run another job!
19:15:39 job_callback for (0, 0, 19) finished
19:15:39 start sampling a new configuration.
19:15:40 best_vector: [0, 0.9218587811556259, 0.4054358824776919, 0.9868004182592819, 0.2283448084819003, 0, 0.20543559705675096, 0.898079527679104, 0.0706765760358915], 1.4014355520938032e-05, 0.1775996771037771, 2.4889450153361306e-06
19:15:40 done sampling a new configuration.
19:15:40 HBMASTER: schedule new run for iteration 0
19:15:40 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
19:15:40 HBMASTER: submitting job (0, 0, 20) to dispatcher
19:15:40 DISPATCHER: trying to submit job (0, 0, 20)
19:15:40 DISPATCHER: trying to notify the job_runner thread.
19:15:40 HBMASTER: job (0, 0, 20) submitted to dispatcher
19:15:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:15:40 DISPATCHER: Trying to submit another job.
19:15:40 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:15:40 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:15:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:15:40 WORKER: start processing job (0, 0, 20)
19:15:40 WORKER: args: ()
19:15:40 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 938, 'last_n_outputs': 26, 'leak_rate': 0.9967001045648205, 'lr': 0.0028621317208907, 'optimizer': 'Adam', 'sparsity': 0.7993045432936202, 'steps_to_train': 91, 'weight_decay': 0.012358118219297666}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:16:34 DISPATCHER: Starting worker discovery
19:16:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:16:34 DISPATCHER: Finished worker discovery
19:17:27 WORKER: done with job (0, 0, 20), trying to register it.
19:17:27 WORKER: registered result for job (0, 0, 20) with dispatcher
19:17:27 DISPATCHER: job (0, 0, 20) finished
19:17:27 DISPATCHER: register_result: lock acquired
19:17:27 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
19:17:27 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 938, 'last_n_outputs': 26, 'leak_rate': 0.9967001045648205, 'lr': 0.0028621317208907, 'optimizer': 'Adam', 'sparsity': 0.7993045432936202, 'steps_to_train': 91, 'weight_decay': 0.012358118219297666}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1156303940246467, 'info': {'sick_no_sick': 0.1156303940246467, 'config': "{'batch_size': 16, 'hidden_dim': 938, 'last_n_outputs': 26, 'leak_rate': 0.9967001045648205, 'lr': 0.0028621317208907, 'optimizer': 'Adam', 'sparsity': 0.7993045432936202, 'steps_to_train': 91, 'weight_decay': 0.012358118219297666}"}}
exception: None

19:17:27 job_callback for (0, 0, 20) started
19:17:27 DISPATCHER: Trying to submit another job.
19:17:27 job_callback for (0, 0, 20) got condition
19:17:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:17:27 done building a new model for budget 44.444444 based on 10/17 split
Best loss for this budget:-0.234714





19:17:27 HBMASTER: Trying to run another job!
19:17:27 job_callback for (0, 0, 20) finished
19:17:27 start sampling a new configuration.
19:17:27 best_vector: [3, 0.40200871835962637, 0.5821195753806786, 0.4809052296498267, 0.50145171346286, 1, 0.156289575440981, 0.24517246514220398, 0.12435393595259177], 0.013128043172554888, 0.18265143162227881, 0.002397855879866233
19:17:27 done sampling a new configuration.
19:17:27 HBMASTER: schedule new run for iteration 0
19:17:27 HBMASTER: trying submitting job (0, 0, 21) to dispatcher
19:17:27 HBMASTER: submitting job (0, 0, 21) to dispatcher
19:17:27 DISPATCHER: trying to submit job (0, 0, 21)
19:17:27 DISPATCHER: trying to notify the job_runner thread.
19:17:27 HBMASTER: job (0, 0, 21) submitted to dispatcher
19:17:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:17:27 DISPATCHER: Trying to submit another job.
19:17:27 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:17:27 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:17:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:17:27 WORKER: start processing job (0, 0, 21)
19:17:27 WORKER: args: ()
19:17:27 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 522, 'last_n_outputs': 33, 'leak_rate': 0.8702263074124567, 'lr': 0.010067077846444089, 'optimizer': 'SGD', 'sparsity': 0.7875094981058355, 'steps_to_train': 32, 'weight_decay': 0.014514036160438669}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:17:34 DISPATCHER: Starting worker discovery
19:17:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:17:34 DISPATCHER: Finished worker discovery
19:18:34 DISPATCHER: Starting worker discovery
19:18:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:18:34 DISPATCHER: Finished worker discovery
19:19:14 WORKER: done with job (0, 0, 21), trying to register it.
19:19:14 WORKER: registered result for job (0, 0, 21) with dispatcher
19:19:14 DISPATCHER: job (0, 0, 21) finished
19:19:14 DISPATCHER: register_result: lock acquired
19:19:14 DISPATCHER: job (0, 0, 21) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
19:19:14 job_id: (0, 0, 21)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 522, 'last_n_outputs': 33, 'leak_rate': 0.8702263074124567, 'lr': 0.010067077846444089, 'optimizer': 'SGD', 'sparsity': 0.7875094981058355, 'steps_to_train': 32, 'weight_decay': 0.014514036160438669}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.009058034014534956, 'info': {'sick_no_sick': 0.009058034014534956, 'config': "{'batch_size': 128, 'hidden_dim': 522, 'last_n_outputs': 33, 'leak_rate': 0.8702263074124567, 'lr': 0.010067077846444089, 'optimizer': 'SGD', 'sparsity': 0.7875094981058355, 'steps_to_train': 32, 'weight_decay': 0.014514036160438669}"}}
exception: None

19:19:14 job_callback for (0, 0, 21) started
19:19:14 DISPATCHER: Trying to submit another job.
19:19:14 job_callback for (0, 0, 21) got condition
19:19:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:19:14 done building a new model for budget 44.444444 based on 10/18 split
Best loss for this budget:-0.234714





19:19:14 HBMASTER: Trying to run another job!
19:19:14 job_callback for (0, 0, 21) finished
19:19:14 start sampling a new configuration.
19:19:14 best_vector: [3, 0.6769123481036903, 0.9454619450466766, 0.5914459807744382, 0.05463068424487511, 1, 0.5922652172506588, 0.060531425625988046, 0.8463051146847926], 0.010532283875084305, 0.04046477321563759, 0.00042618647844800306
19:19:14 done sampling a new configuration.
19:19:14 HBMASTER: schedule new run for iteration 0
19:19:14 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
19:19:14 HBMASTER: submitting job (0, 0, 22) to dispatcher
19:19:14 DISPATCHER: trying to submit job (0, 0, 22)
19:19:14 DISPATCHER: trying to notify the job_runner thread.
19:19:14 HBMASTER: job (0, 0, 22) submitted to dispatcher
19:19:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:19:14 DISPATCHER: Trying to submit another job.
19:19:14 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:19:14 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:19:14 WORKER: start processing job (0, 0, 22)
19:19:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:19:14 WORKER: args: ()
19:19:14 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 742, 'last_n_outputs': 48, 'leak_rate': 0.8978614951936096, 'lr': 0.0012860604080655804, 'optimizer': 'SGD', 'sparsity': 0.8921436521401581, 'steps_to_train': 15, 'weight_decay': 0.12620261088062076}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:19:34 DISPATCHER: Starting worker discovery
19:19:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:19:34 DISPATCHER: Finished worker discovery
19:20:34 DISPATCHER: Starting worker discovery
19:20:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:20:34 DISPATCHER: Finished worker discovery
19:21:00 WORKER: done with job (0, 0, 22), trying to register it.
19:21:00 WORKER: registered result for job (0, 0, 22) with dispatcher
19:21:00 DISPATCHER: job (0, 0, 22) finished
19:21:00 DISPATCHER: register_result: lock acquired
19:21:00 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
19:21:00 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 742, 'last_n_outputs': 48, 'leak_rate': 0.8978614951936096, 'lr': 0.0012860604080655804, 'optimizer': 'SGD', 'sparsity': 0.8921436521401581, 'steps_to_train': 15, 'weight_decay': 0.12620261088062076}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.20335886007081128, 'info': {'sick_no_sick': 0.20335886007081128, 'config': "{'batch_size': 128, 'hidden_dim': 742, 'last_n_outputs': 48, 'leak_rate': 0.8978614951936096, 'lr': 0.0012860604080655804, 'optimizer': 'SGD', 'sparsity': 0.8921436521401581, 'steps_to_train': 15, 'weight_decay': 0.12620261088062076}"}}
exception: None

19:21:00 job_callback for (0, 0, 22) started
19:21:00 job_callback for (0, 0, 22) got condition
19:21:00 DISPATCHER: Trying to submit another job.
19:21:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:21:00 done building a new model for budget 44.444444 based on 10/19 split
Best loss for this budget:-0.234714





19:21:00 HBMASTER: Trying to run another job!
19:21:00 job_callback for (0, 0, 22) finished
19:21:00 start sampling a new configuration.
19:21:00 done sampling a new configuration.
19:21:00 HBMASTER: schedule new run for iteration 0
19:21:00 HBMASTER: trying submitting job (0, 0, 23) to dispatcher
19:21:00 HBMASTER: submitting job (0, 0, 23) to dispatcher
19:21:00 DISPATCHER: trying to submit job (0, 0, 23)
19:21:00 DISPATCHER: trying to notify the job_runner thread.
19:21:00 HBMASTER: job (0, 0, 23) submitted to dispatcher
19:21:00 DISPATCHER: Trying to submit another job.
19:21:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:21:00 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:21:00 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:21:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:21:00 WORKER: start processing job (0, 0, 23)
19:21:00 WORKER: args: ()
19:21:00 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 244, 'last_n_outputs': 37, 'leak_rate': 0.9303056471220993, 'lr': 0.027937808266377158, 'optimizer': 'SGD', 'sparsity': 0.8119231633327444, 'steps_to_train': 15, 'weight_decay': 0.024165234576837027}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:21:34 DISPATCHER: Starting worker discovery
19:21:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:21:34 DISPATCHER: Finished worker discovery
19:22:34 DISPATCHER: Starting worker discovery
19:22:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:22:34 DISPATCHER: Finished worker discovery
19:22:46 WORKER: done with job (0, 0, 23), trying to register it.
19:22:46 WORKER: registered result for job (0, 0, 23) with dispatcher
19:22:46 DISPATCHER: job (0, 0, 23) finished
19:22:46 DISPATCHER: register_result: lock acquired
19:22:46 DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
19:22:46 job_id: (0, 0, 23)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 244, 'last_n_outputs': 37, 'leak_rate': 0.9303056471220993, 'lr': 0.027937808266377158, 'optimizer': 'SGD', 'sparsity': 0.8119231633327444, 'steps_to_train': 15, 'weight_decay': 0.024165234576837027}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.13494604039954006, 'info': {'sick_no_sick': 0.13494604039954006, 'config': "{'batch_size': 32, 'hidden_dim': 244, 'last_n_outputs': 37, 'leak_rate': 0.9303056471220993, 'lr': 0.027937808266377158, 'optimizer': 'SGD', 'sparsity': 0.8119231633327444, 'steps_to_train': 15, 'weight_decay': 0.024165234576837027}"}}
exception: None

19:22:46 job_callback for (0, 0, 23) started
19:22:46 job_callback for (0, 0, 23) got condition
19:22:46 DISPATCHER: Trying to submit another job.
19:22:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:22:46 done building a new model for budget 44.444444 based on 10/20 split
Best loss for this budget:-0.234714





19:22:46 HBMASTER: Trying to run another job!
19:22:46 job_callback for (0, 0, 23) finished
19:22:46 start sampling a new configuration.
19:22:46 best_vector: [2, 0.5071559514381805, 0.740200419221096, 0.8629760835566237, 0.025813578384926483, 1, 0.6719632127548469, 0.31760996277667675, 0.24191541028412664], 0.0029744064330680105, 0.15134417339432832, 0.0004501590829514506
19:22:46 done sampling a new configuration.
19:22:46 HBMASTER: schedule new run for iteration 0
19:22:46 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
19:22:46 HBMASTER: submitting job (0, 0, 24) to dispatcher
19:22:46 DISPATCHER: trying to submit job (0, 0, 24)
19:22:46 DISPATCHER: trying to notify the job_runner thread.
19:22:46 HBMASTER: job (0, 0, 24) submitted to dispatcher
19:22:46 DISPATCHER: Trying to submit another job.
19:22:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:22:46 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:22:46 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:22:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:22:46 WORKER: start processing job (0, 0, 24)
19:22:46 WORKER: args: ()
19:22:46 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 606, 'last_n_outputs': 40, 'leak_rate': 0.9657440208891559, 'lr': 0.0011262301687495974, 'optimizer': 'SGD', 'sparsity': 0.9112711710611633, 'steps_to_train': 38, 'weight_decay': 0.020641402627275676}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:23:34 DISPATCHER: Starting worker discovery
19:23:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:23:34 DISPATCHER: Finished worker discovery
19:24:34 WORKER: done with job (0, 0, 24), trying to register it.
19:24:34 WORKER: registered result for job (0, 0, 24) with dispatcher
19:24:34 DISPATCHER: job (0, 0, 24) finished
19:24:34 DISPATCHER: register_result: lock acquired
19:24:34 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
19:24:34 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 606, 'last_n_outputs': 40, 'leak_rate': 0.9657440208891559, 'lr': 0.0011262301687495974, 'optimizer': 'SGD', 'sparsity': 0.9112711710611633, 'steps_to_train': 38, 'weight_decay': 0.020641402627275676}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2148939418314285, 'info': {'sick_no_sick': 0.2148939418314285, 'config': "{'batch_size': 64, 'hidden_dim': 606, 'last_n_outputs': 40, 'leak_rate': 0.9657440208891559, 'lr': 0.0011262301687495974, 'optimizer': 'SGD', 'sparsity': 0.9112711710611633, 'steps_to_train': 38, 'weight_decay': 0.020641402627275676}"}}
exception: None

19:24:34 job_callback for (0, 0, 24) started
19:24:34 job_callback for (0, 0, 24) got condition
19:24:34 DISPATCHER: Trying to submit another job.
19:24:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:24:34 done building a new model for budget 44.444444 based on 10/21 split
Best loss for this budget:-0.234714





19:24:34 HBMASTER: Trying to run another job!
19:24:34 job_callback for (0, 0, 24) finished
19:24:34 start sampling a new configuration.
19:24:34 done sampling a new configuration.
19:24:34 HBMASTER: schedule new run for iteration 0
19:24:34 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
19:24:34 HBMASTER: submitting job (0, 0, 25) to dispatcher
19:24:34 DISPATCHER: trying to submit job (0, 0, 25)
19:24:34 DISPATCHER: trying to notify the job_runner thread.
19:24:34 HBMASTER: job (0, 0, 25) submitted to dispatcher
19:24:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:24:34 DISPATCHER: Trying to submit another job.
19:24:34 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:24:34 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:24:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:24:34 WORKER: start processing job (0, 0, 25)
19:24:34 WORKER: args: ()
19:24:34 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 826, 'last_n_outputs': 36, 'leak_rate': 0.9091130864534696, 'lr': 0.0018310412124696218, 'optimizer': 'Adam', 'sparsity': 0.956512481131527, 'steps_to_train': 96, 'weight_decay': 0.03730501179132334}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:24:34 DISPATCHER: Starting worker discovery
19:24:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:24:34 DISPATCHER: Finished worker discovery
19:25:34 DISPATCHER: Starting worker discovery
19:25:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:25:34 DISPATCHER: Finished worker discovery
19:26:26 WORKER: done with job (0, 0, 25), trying to register it.
19:26:26 WORKER: registered result for job (0, 0, 25) with dispatcher
19:26:26 DISPATCHER: job (0, 0, 25) finished
19:26:26 DISPATCHER: register_result: lock acquired
19:26:26 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
19:26:26 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 826, 'last_n_outputs': 36, 'leak_rate': 0.9091130864534696, 'lr': 0.0018310412124696218, 'optimizer': 'Adam', 'sparsity': 0.956512481131527, 'steps_to_train': 96, 'weight_decay': 0.03730501179132334}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.13776215303844808, 'info': {'sick_no_sick': 0.13776215303844808, 'config': "{'batch_size': 128, 'hidden_dim': 826, 'last_n_outputs': 36, 'leak_rate': 0.9091130864534696, 'lr': 0.0018310412124696218, 'optimizer': 'Adam', 'sparsity': 0.956512481131527, 'steps_to_train': 96, 'weight_decay': 0.03730501179132334}"}}
exception: None

19:26:26 job_callback for (0, 0, 25) started
19:26:26 job_callback for (0, 0, 25) got condition
19:26:26 DISPATCHER: Trying to submit another job.
19:26:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:26:26 done building a new model for budget 44.444444 based on 10/22 split
Best loss for this budget:-0.234714





19:26:26 HBMASTER: Trying to run another job!
19:26:26 job_callback for (0, 0, 25) finished
19:26:26 start sampling a new configuration.
19:26:26 best_vector: [0, 0.8649937076316677, 0.45008964608959656, 0.5643904057890785, 0.06848219079476969, 0, 0.6105785341092076, 0.10710051739696014, 0.842560102747872], 0.0012160965097247468, 0.052679159226958726, 6.40629416711387e-05
19:26:26 done sampling a new configuration.
19:26:26 HBMASTER: schedule new run for iteration 0
19:26:26 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
19:26:26 HBMASTER: submitting job (0, 0, 26) to dispatcher
19:26:26 DISPATCHER: trying to submit job (0, 0, 26)
19:26:26 DISPATCHER: trying to notify the job_runner thread.
19:26:26 HBMASTER: job (0, 0, 26) submitted to dispatcher
19:26:26 DISPATCHER: Trying to submit another job.
19:26:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:26:26 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:26:26 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:26:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:26:26 WORKER: start processing job (0, 0, 26)
19:26:26 WORKER: args: ()
19:26:26 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 892, 'last_n_outputs': 28, 'leak_rate': 0.8910976014472696, 'lr': 0.001370769338700993, 'optimizer': 'Adam', 'sparsity': 0.8965388481862098, 'steps_to_train': 19, 'weight_decay': 0.12479464984751502}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:26:34 DISPATCHER: Starting worker discovery
19:26:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:26:34 DISPATCHER: Finished worker discovery
19:27:34 DISPATCHER: Starting worker discovery
19:27:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:27:34 DISPATCHER: Finished worker discovery
19:28:12 WORKER: done with job (0, 0, 26), trying to register it.
19:28:12 WORKER: registered result for job (0, 0, 26) with dispatcher
19:28:12 DISPATCHER: job (0, 0, 26) finished
19:28:12 DISPATCHER: register_result: lock acquired
19:28:12 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
19:28:12 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 892, 'last_n_outputs': 28, 'leak_rate': 0.8910976014472696, 'lr': 0.001370769338700993, 'optimizer': 'Adam', 'sparsity': 0.8965388481862098, 'steps_to_train': 19, 'weight_decay': 0.12479464984751502}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.13446314784304855, 'info': {'sick_no_sick': 0.13446314784304855, 'config': "{'batch_size': 16, 'hidden_dim': 892, 'last_n_outputs': 28, 'leak_rate': 0.8910976014472696, 'lr': 0.001370769338700993, 'optimizer': 'Adam', 'sparsity': 0.8965388481862098, 'steps_to_train': 19, 'weight_decay': 0.12479464984751502}"}}
exception: None

19:28:12 job_callback for (0, 0, 26) started
19:28:12 job_callback for (0, 0, 26) got condition
19:28:12 DISPATCHER: Trying to submit another job.
19:28:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:28:12 done building a new model for budget 44.444444 based on 10/22 split
Best loss for this budget:-0.234714





19:28:12 HBMASTER: Trying to run another job!
19:28:12 job_callback for (0, 0, 26) finished
19:28:12 ITERATION: Advancing config (0, 0, 1) to next budget 133.333333
19:28:12 ITERATION: Advancing config (0, 0, 3) to next budget 133.333333
19:28:12 ITERATION: Advancing config (0, 0, 7) to next budget 133.333333
19:28:12 ITERATION: Advancing config (0, 0, 8) to next budget 133.333333
19:28:12 ITERATION: Advancing config (0, 0, 9) to next budget 133.333333
19:28:12 ITERATION: Advancing config (0, 0, 17) to next budget 133.333333
19:28:12 ITERATION: Advancing config (0, 0, 18) to next budget 133.333333
19:28:12 ITERATION: Advancing config (0, 0, 22) to next budget 133.333333
19:28:12 ITERATION: Advancing config (0, 0, 24) to next budget 133.333333
19:28:12 HBMASTER: schedule new run for iteration 0
19:28:12 HBMASTER: trying submitting job (0, 0, 1) to dispatcher
19:28:12 HBMASTER: submitting job (0, 0, 1) to dispatcher
19:28:12 DISPATCHER: trying to submit job (0, 0, 1)
19:28:12 DISPATCHER: trying to notify the job_runner thread.
19:28:12 HBMASTER: job (0, 0, 1) submitted to dispatcher
19:28:12 DISPATCHER: Trying to submit another job.
19:28:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:28:12 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:28:12 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:28:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:28:12 WORKER: start processing job (0, 0, 1)
19:28:12 WORKER: args: ()
19:28:12 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 970, 'last_n_outputs': 20, 'leak_rate': 0.9362550402648038, 'lr': 0.007000936231426626, 'optimizer': 'Adam', 'sparsity': 0.781410098381483, 'steps_to_train': 63, 'weight_decay': 0.014434167239536336}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:28:34 DISPATCHER: Starting worker discovery
19:28:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:28:34 DISPATCHER: Finished worker discovery
19:29:34 DISPATCHER: Starting worker discovery
19:29:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:29:34 DISPATCHER: Finished worker discovery
19:30:34 DISPATCHER: Starting worker discovery
19:30:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:30:34 DISPATCHER: Finished worker discovery
19:31:28 WORKER: done with job (0, 0, 1), trying to register it.
19:31:28 WORKER: registered result for job (0, 0, 1) with dispatcher
19:31:28 DISPATCHER: job (0, 0, 1) finished
19:31:28 DISPATCHER: register_result: lock acquired
19:31:28 DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
19:31:28 job_id: (0, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 970, 'last_n_outputs': 20, 'leak_rate': 0.9362550402648038, 'lr': 0.007000936231426626, 'optimizer': 'Adam', 'sparsity': 0.781410098381483, 'steps_to_train': 63, 'weight_decay': 0.014434167239536336}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.09047593767178268, 'info': {'sick_no_sick': 0.09047593767178268, 'config': "{'batch_size': 16, 'hidden_dim': 970, 'last_n_outputs': 20, 'leak_rate': 0.9362550402648038, 'lr': 0.007000936231426626, 'optimizer': 'Adam', 'sparsity': 0.781410098381483, 'steps_to_train': 63, 'weight_decay': 0.014434167239536336}"}}
exception: None

19:31:28 job_callback for (0, 0, 1) started
19:31:28 DISPATCHER: Trying to submit another job.
19:31:28 job_callback for (0, 0, 1) got condition
19:31:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:31:28 Only 1 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
19:31:28 HBMASTER: Trying to run another job!
19:31:28 job_callback for (0, 0, 1) finished
19:31:28 HBMASTER: schedule new run for iteration 0
19:31:28 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
19:31:28 HBMASTER: submitting job (0, 0, 3) to dispatcher
19:31:28 DISPATCHER: trying to submit job (0, 0, 3)
19:31:28 DISPATCHER: trying to notify the job_runner thread.
19:31:28 HBMASTER: job (0, 0, 3) submitted to dispatcher
19:31:28 DISPATCHER: Trying to submit another job.
19:31:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:31:28 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:31:28 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:31:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:31:28 WORKER: start processing job (0, 0, 3)
19:31:28 WORKER: args: ()
19:31:28 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 402, 'last_n_outputs': 35, 'leak_rate': 0.795539644473837, 'lr': 0.05623569620988763, 'optimizer': 'Adam', 'sparsity': 0.8452493304892197, 'steps_to_train': 50, 'weight_decay': 0.016880599912543988}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:31:34 DISPATCHER: Starting worker discovery
19:31:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:31:34 DISPATCHER: Finished worker discovery
19:32:34 DISPATCHER: Starting worker discovery
19:32:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:32:34 DISPATCHER: Finished worker discovery
19:33:34 DISPATCHER: Starting worker discovery
19:33:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:33:34 DISPATCHER: Finished worker discovery
19:34:34 DISPATCHER: Starting worker discovery
19:34:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:34:34 DISPATCHER: Finished worker discovery
19:34:44 WORKER: done with job (0, 0, 3), trying to register it.
19:34:44 WORKER: registered result for job (0, 0, 3) with dispatcher
19:34:44 DISPATCHER: job (0, 0, 3) finished
19:34:44 DISPATCHER: register_result: lock acquired
19:34:44 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
19:34:44 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 402, 'last_n_outputs': 35, 'leak_rate': 0.795539644473837, 'lr': 0.05623569620988763, 'optimizer': 'Adam', 'sparsity': 0.8452493304892197, 'steps_to_train': 50, 'weight_decay': 0.016880599912543988}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.16383849704972495, 'info': {'sick_no_sick': 0.16383849704972495, 'config': "{'batch_size': 16, 'hidden_dim': 402, 'last_n_outputs': 35, 'leak_rate': 0.795539644473837, 'lr': 0.05623569620988763, 'optimizer': 'Adam', 'sparsity': 0.8452493304892197, 'steps_to_train': 50, 'weight_decay': 0.016880599912543988}"}}
exception: None

19:34:44 job_callback for (0, 0, 3) started
19:34:44 job_callback for (0, 0, 3) got condition
19:34:44 DISPATCHER: Trying to submit another job.
19:34:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:34:44 Only 2 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
19:34:44 HBMASTER: Trying to run another job!
19:34:44 job_callback for (0, 0, 3) finished
19:34:44 HBMASTER: schedule new run for iteration 0
19:34:44 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
19:34:44 HBMASTER: submitting job (0, 0, 7) to dispatcher
19:34:44 DISPATCHER: trying to submit job (0, 0, 7)
19:34:44 DISPATCHER: trying to notify the job_runner thread.
19:34:44 HBMASTER: job (0, 0, 7) submitted to dispatcher
19:34:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:34:44 DISPATCHER: Trying to submit another job.
19:34:44 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:34:44 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:34:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:34:44 WORKER: start processing job (0, 0, 7)
19:34:44 WORKER: args: ()
19:34:44 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 207, 'last_n_outputs': 16, 'leak_rate': 0.9842981516787215, 'lr': 0.010854475475523723, 'optimizer': 'Adam', 'sparsity': 0.8527205152492151, 'steps_to_train': 15, 'weight_decay': 0.17434403150690397}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:35:34 DISPATCHER: Starting worker discovery
19:35:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:35:34 DISPATCHER: Finished worker discovery
19:36:34 DISPATCHER: Starting worker discovery
19:36:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:36:34 DISPATCHER: Finished worker discovery
19:37:34 DISPATCHER: Starting worker discovery
19:37:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:37:34 DISPATCHER: Finished worker discovery
19:38:00 WORKER: done with job (0, 0, 7), trying to register it.
19:38:00 WORKER: registered result for job (0, 0, 7) with dispatcher
19:38:00 DISPATCHER: job (0, 0, 7) finished
19:38:00 DISPATCHER: register_result: lock acquired
19:38:00 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
19:38:00 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 207, 'last_n_outputs': 16, 'leak_rate': 0.9842981516787215, 'lr': 0.010854475475523723, 'optimizer': 'Adam', 'sparsity': 0.8527205152492151, 'steps_to_train': 15, 'weight_decay': 0.17434403150690397}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.14389109787435259, 'info': {'sick_no_sick': 0.14389109787435259, 'config': "{'batch_size': 64, 'hidden_dim': 207, 'last_n_outputs': 16, 'leak_rate': 0.9842981516787215, 'lr': 0.010854475475523723, 'optimizer': 'Adam', 'sparsity': 0.8527205152492151, 'steps_to_train': 15, 'weight_decay': 0.17434403150690397}"}}
exception: None

19:38:00 job_callback for (0, 0, 7) started
19:38:00 DISPATCHER: Trying to submit another job.
19:38:00 job_callback for (0, 0, 7) got condition
19:38:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:38:00 Only 3 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
19:38:00 HBMASTER: Trying to run another job!
19:38:00 job_callback for (0, 0, 7) finished
19:38:00 HBMASTER: schedule new run for iteration 0
19:38:00 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
19:38:00 HBMASTER: submitting job (0, 0, 8) to dispatcher
19:38:00 DISPATCHER: trying to submit job (0, 0, 8)
19:38:00 DISPATCHER: trying to notify the job_runner thread.
19:38:00 HBMASTER: job (0, 0, 8) submitted to dispatcher
19:38:00 DISPATCHER: Trying to submit another job.
19:38:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:38:00 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:38:00 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:38:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:38:00 WORKER: start processing job (0, 0, 8)
19:38:00 WORKER: args: ()
19:38:00 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 626, 'last_n_outputs': 29, 'leak_rate': 0.7829255712488108, 'lr': 0.014810038346758226, 'optimizer': 'Adam', 'sparsity': 0.9225209684665923, 'steps_to_train': 31, 'weight_decay': 0.01571872599753148}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:38:34 DISPATCHER: Starting worker discovery
19:38:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:38:34 DISPATCHER: Finished worker discovery
19:39:34 DISPATCHER: Starting worker discovery
19:39:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:39:34 DISPATCHER: Finished worker discovery
19:40:34 DISPATCHER: Starting worker discovery
19:40:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:40:34 DISPATCHER: Finished worker discovery
19:41:17 WORKER: done with job (0, 0, 8), trying to register it.
19:41:17 WORKER: registered result for job (0, 0, 8) with dispatcher
19:41:17 DISPATCHER: job (0, 0, 8) finished
19:41:17 DISPATCHER: register_result: lock acquired
19:41:17 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
19:41:17 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 626, 'last_n_outputs': 29, 'leak_rate': 0.7829255712488108, 'lr': 0.014810038346758226, 'optimizer': 'Adam', 'sparsity': 0.9225209684665923, 'steps_to_train': 31, 'weight_decay': 0.01571872599753148}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.19443033143599703, 'info': {'sick_no_sick': 0.19443033143599703, 'config': "{'batch_size': 32, 'hidden_dim': 626, 'last_n_outputs': 29, 'leak_rate': 0.7829255712488108, 'lr': 0.014810038346758226, 'optimizer': 'Adam', 'sparsity': 0.9225209684665923, 'steps_to_train': 31, 'weight_decay': 0.01571872599753148}"}}
exception: None

19:41:17 job_callback for (0, 0, 8) started
19:41:17 DISPATCHER: Trying to submit another job.
19:41:17 job_callback for (0, 0, 8) got condition
19:41:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:41:17 Only 4 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
19:41:17 HBMASTER: Trying to run another job!
19:41:17 job_callback for (0, 0, 8) finished
19:41:17 HBMASTER: schedule new run for iteration 0
19:41:17 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
19:41:17 HBMASTER: submitting job (0, 0, 9) to dispatcher
19:41:17 DISPATCHER: trying to submit job (0, 0, 9)
19:41:17 DISPATCHER: trying to notify the job_runner thread.
19:41:17 HBMASTER: job (0, 0, 9) submitted to dispatcher
19:41:17 DISPATCHER: Trying to submit another job.
19:41:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:41:17 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:41:17 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:41:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:41:17 WORKER: start processing job (0, 0, 9)
19:41:17 WORKER: args: ()
19:41:17 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 570, 'last_n_outputs': 41, 'leak_rate': 0.8458892140749139, 'lr': 0.0010640503296790557, 'optimizer': 'SGD', 'sparsity': 0.8550615557337402, 'steps_to_train': 19, 'weight_decay': 0.025195718626074722}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:41:34 DISPATCHER: Starting worker discovery
19:41:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:41:34 DISPATCHER: Finished worker discovery
19:42:34 DISPATCHER: Starting worker discovery
19:42:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:42:34 DISPATCHER: Finished worker discovery
19:43:34 DISPATCHER: Starting worker discovery
19:43:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:43:34 DISPATCHER: Finished worker discovery
19:44:33 WORKER: done with job (0, 0, 9), trying to register it.
19:44:33 WORKER: registered result for job (0, 0, 9) with dispatcher
19:44:33 DISPATCHER: job (0, 0, 9) finished
19:44:33 DISPATCHER: register_result: lock acquired
19:44:33 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
19:44:33 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 570, 'last_n_outputs': 41, 'leak_rate': 0.8458892140749139, 'lr': 0.0010640503296790557, 'optimizer': 'SGD', 'sparsity': 0.8550615557337402, 'steps_to_train': 19, 'weight_decay': 0.025195718626074722}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.13711444062293637, 'info': {'sick_no_sick': 0.13711444062293637, 'config': "{'batch_size': 128, 'hidden_dim': 570, 'last_n_outputs': 41, 'leak_rate': 0.8458892140749139, 'lr': 0.0010640503296790557, 'optimizer': 'SGD', 'sparsity': 0.8550615557337402, 'steps_to_train': 19, 'weight_decay': 0.025195718626074722}"}}
exception: None

19:44:33 job_callback for (0, 0, 9) started
19:44:33 job_callback for (0, 0, 9) got condition
19:44:33 DISPATCHER: Trying to submit another job.
19:44:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:44:33 Only 5 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
19:44:33 HBMASTER: Trying to run another job!
19:44:33 job_callback for (0, 0, 9) finished
19:44:33 HBMASTER: schedule new run for iteration 0
19:44:33 HBMASTER: trying submitting job (0, 0, 17) to dispatcher
19:44:33 HBMASTER: submitting job (0, 0, 17) to dispatcher
19:44:33 DISPATCHER: trying to submit job (0, 0, 17)
19:44:33 DISPATCHER: trying to notify the job_runner thread.
19:44:33 HBMASTER: job (0, 0, 17) submitted to dispatcher
19:44:33 DISPATCHER: Trying to submit another job.
19:44:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:44:33 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:44:33 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:44:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:44:33 WORKER: start processing job (0, 0, 17)
19:44:33 WORKER: args: ()
19:44:33 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 435, 'last_n_outputs': 45, 'leak_rate': 0.8908044564996284, 'lr': 0.0012049127332055924, 'optimizer': 'SGD', 'sparsity': 0.8849090495040177, 'steps_to_train': 37, 'weight_decay': 0.039660375714767764}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:44:35 DISPATCHER: Starting worker discovery
19:44:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:44:35 DISPATCHER: Finished worker discovery
19:45:35 DISPATCHER: Starting worker discovery
19:45:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:45:35 DISPATCHER: Finished worker discovery
19:46:35 DISPATCHER: Starting worker discovery
19:46:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:46:35 DISPATCHER: Finished worker discovery
19:47:35 DISPATCHER: Starting worker discovery
19:47:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:47:35 DISPATCHER: Finished worker discovery
19:47:51 WORKER: done with job (0, 0, 17), trying to register it.
19:47:51 WORKER: registered result for job (0, 0, 17) with dispatcher
19:47:51 DISPATCHER: job (0, 0, 17) finished
19:47:51 DISPATCHER: register_result: lock acquired
19:47:51 DISPATCHER: job (0, 0, 17) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
19:47:51 job_id: (0, 0, 17)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 435, 'last_n_outputs': 45, 'leak_rate': 0.8908044564996284, 'lr': 0.0012049127332055924, 'optimizer': 'SGD', 'sparsity': 0.8849090495040177, 'steps_to_train': 37, 'weight_decay': 0.039660375714767764}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1777344192144265, 'info': {'sick_no_sick': 0.1777344192144265, 'config': "{'batch_size': 16, 'hidden_dim': 435, 'last_n_outputs': 45, 'leak_rate': 0.8908044564996284, 'lr': 0.0012049127332055924, 'optimizer': 'SGD', 'sparsity': 0.8849090495040177, 'steps_to_train': 37, 'weight_decay': 0.039660375714767764}"}}
exception: None

19:47:51 job_callback for (0, 0, 17) started
19:47:51 job_callback for (0, 0, 17) got condition
19:47:51 DISPATCHER: Trying to submit another job.
19:47:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:47:51 Only 6 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
19:47:51 HBMASTER: Trying to run another job!
19:47:51 job_callback for (0, 0, 17) finished
19:47:51 HBMASTER: schedule new run for iteration 0
19:47:51 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
19:47:51 HBMASTER: submitting job (0, 0, 18) to dispatcher
19:47:51 DISPATCHER: trying to submit job (0, 0, 18)
19:47:51 DISPATCHER: trying to notify the job_runner thread.
19:47:51 HBMASTER: job (0, 0, 18) submitted to dispatcher
19:47:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:47:51 DISPATCHER: Trying to submit another job.
19:47:51 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:47:51 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:47:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:47:51 WORKER: start processing job (0, 0, 18)
19:47:51 WORKER: args: ()
19:47:51 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 968, 'last_n_outputs': 20, 'leak_rate': 0.984748749461624, 'lr': 0.008590395100442696, 'optimizer': 'Adam', 'sparsity': 0.8216004201332118, 'steps_to_train': 76, 'weight_decay': 0.028893016753584758}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:48:35 DISPATCHER: Starting worker discovery
19:48:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:48:35 DISPATCHER: Finished worker discovery
19:49:35 DISPATCHER: Starting worker discovery
19:49:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:49:35 DISPATCHER: Finished worker discovery
19:50:35 DISPATCHER: Starting worker discovery
19:50:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:50:35 DISPATCHER: Finished worker discovery
19:51:10 WORKER: done with job (0, 0, 18), trying to register it.
19:51:10 WORKER: registered result for job (0, 0, 18) with dispatcher
19:51:10 DISPATCHER: job (0, 0, 18) finished
19:51:10 DISPATCHER: register_result: lock acquired
19:51:10 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
19:51:10 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 968, 'last_n_outputs': 20, 'leak_rate': 0.984748749461624, 'lr': 0.008590395100442696, 'optimizer': 'Adam', 'sparsity': 0.8216004201332118, 'steps_to_train': 76, 'weight_decay': 0.028893016753584758}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.09163679186892112, 'info': {'sick_no_sick': 0.09163679186892112, 'config': "{'batch_size': 32, 'hidden_dim': 968, 'last_n_outputs': 20, 'leak_rate': 0.984748749461624, 'lr': 0.008590395100442696, 'optimizer': 'Adam', 'sparsity': 0.8216004201332118, 'steps_to_train': 76, 'weight_decay': 0.028893016753584758}"}}
exception: None

19:51:10 job_callback for (0, 0, 18) started
19:51:10 job_callback for (0, 0, 18) got condition
19:51:10 DISPATCHER: Trying to submit another job.
19:51:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:51:10 Only 7 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
19:51:10 HBMASTER: Trying to run another job!
19:51:10 job_callback for (0, 0, 18) finished
19:51:10 HBMASTER: schedule new run for iteration 0
19:51:10 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
19:51:10 HBMASTER: submitting job (0, 0, 22) to dispatcher
19:51:10 DISPATCHER: trying to submit job (0, 0, 22)
19:51:10 DISPATCHER: trying to notify the job_runner thread.
19:51:10 HBMASTER: job (0, 0, 22) submitted to dispatcher
19:51:10 DISPATCHER: Trying to submit another job.
19:51:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:51:10 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:51:10 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:51:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:51:10 WORKER: start processing job (0, 0, 22)
19:51:10 WORKER: args: ()
19:51:10 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 742, 'last_n_outputs': 48, 'leak_rate': 0.8978614951936096, 'lr': 0.0012860604080655804, 'optimizer': 'SGD', 'sparsity': 0.8921436521401581, 'steps_to_train': 15, 'weight_decay': 0.12620261088062076}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:51:35 DISPATCHER: Starting worker discovery
19:51:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:51:35 DISPATCHER: Finished worker discovery
19:52:35 DISPATCHER: Starting worker discovery
19:52:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:52:35 DISPATCHER: Finished worker discovery
19:53:35 DISPATCHER: Starting worker discovery
19:53:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:53:35 DISPATCHER: Finished worker discovery
19:54:28 WORKER: done with job (0, 0, 22), trying to register it.
19:54:28 WORKER: registered result for job (0, 0, 22) with dispatcher
19:54:28 DISPATCHER: job (0, 0, 22) finished
19:54:28 DISPATCHER: register_result: lock acquired
19:54:28 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
19:54:28 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 742, 'last_n_outputs': 48, 'leak_rate': 0.8978614951936096, 'lr': 0.0012860604080655804, 'optimizer': 'SGD', 'sparsity': 0.8921436521401581, 'steps_to_train': 15, 'weight_decay': 0.12620261088062076}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.22168995205149916, 'info': {'sick_no_sick': 0.22168995205149916, 'config': "{'batch_size': 128, 'hidden_dim': 742, 'last_n_outputs': 48, 'leak_rate': 0.8978614951936096, 'lr': 0.0012860604080655804, 'optimizer': 'SGD', 'sparsity': 0.8921436521401581, 'steps_to_train': 15, 'weight_decay': 0.12620261088062076}"}}
exception: None

19:54:28 job_callback for (0, 0, 22) started
19:54:28 DISPATCHER: Trying to submit another job.
19:54:28 job_callback for (0, 0, 22) got condition
19:54:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:54:28 Only 8 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
19:54:28 HBMASTER: Trying to run another job!
19:54:28 job_callback for (0, 0, 22) finished
19:54:28 HBMASTER: schedule new run for iteration 0
19:54:28 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
19:54:28 HBMASTER: submitting job (0, 0, 24) to dispatcher
19:54:28 DISPATCHER: trying to submit job (0, 0, 24)
19:54:28 DISPATCHER: trying to notify the job_runner thread.
19:54:28 HBMASTER: job (0, 0, 24) submitted to dispatcher
19:54:28 DISPATCHER: Trying to submit another job.
19:54:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:54:28 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:54:28 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:54:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:54:28 WORKER: start processing job (0, 0, 24)
19:54:28 WORKER: args: ()
19:54:28 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 606, 'last_n_outputs': 40, 'leak_rate': 0.9657440208891559, 'lr': 0.0011262301687495974, 'optimizer': 'SGD', 'sparsity': 0.9112711710611633, 'steps_to_train': 38, 'weight_decay': 0.020641402627275676}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:54:35 DISPATCHER: Starting worker discovery
19:54:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:54:35 DISPATCHER: Finished worker discovery
19:55:35 DISPATCHER: Starting worker discovery
19:55:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:55:35 DISPATCHER: Finished worker discovery
19:56:35 DISPATCHER: Starting worker discovery
19:56:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:56:35 DISPATCHER: Finished worker discovery
19:57:35 DISPATCHER: Starting worker discovery
19:57:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:57:35 DISPATCHER: Finished worker discovery
19:57:45 WORKER: done with job (0, 0, 24), trying to register it.
19:57:45 WORKER: registered result for job (0, 0, 24) with dispatcher
19:57:45 DISPATCHER: job (0, 0, 24) finished
19:57:45 DISPATCHER: register_result: lock acquired
19:57:45 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
19:57:45 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 606, 'last_n_outputs': 40, 'leak_rate': 0.9657440208891559, 'lr': 0.0011262301687495974, 'optimizer': 'SGD', 'sparsity': 0.9112711710611633, 'steps_to_train': 38, 'weight_decay': 0.020641402627275676}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.19124443914148684, 'info': {'sick_no_sick': 0.19124443914148684, 'config': "{'batch_size': 64, 'hidden_dim': 606, 'last_n_outputs': 40, 'leak_rate': 0.9657440208891559, 'lr': 0.0011262301687495974, 'optimizer': 'SGD', 'sparsity': 0.9112711710611633, 'steps_to_train': 38, 'weight_decay': 0.020641402627275676}"}}
exception: None

19:57:45 job_callback for (0, 0, 24) started
19:57:45 job_callback for (0, 0, 24) got condition
19:57:45 DISPATCHER: Trying to submit another job.
19:57:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:57:45 Only 9 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
19:57:45 HBMASTER: Trying to run another job!
19:57:45 job_callback for (0, 0, 24) finished
19:57:45 ITERATION: Advancing config (0, 0, 8) to next budget 400.000000
19:57:45 ITERATION: Advancing config (0, 0, 22) to next budget 400.000000
19:57:45 ITERATION: Advancing config (0, 0, 24) to next budget 400.000000
19:57:45 HBMASTER: schedule new run for iteration 0
19:57:45 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
19:57:45 HBMASTER: submitting job (0, 0, 8) to dispatcher
19:57:45 DISPATCHER: trying to submit job (0, 0, 8)
19:57:45 DISPATCHER: trying to notify the job_runner thread.
19:57:45 HBMASTER: job (0, 0, 8) submitted to dispatcher
19:57:45 DISPATCHER: Trying to submit another job.
19:57:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:57:45 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:57:45 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:57:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:57:45 WORKER: start processing job (0, 0, 8)
19:57:45 WORKER: args: ()
19:57:45 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 626, 'last_n_outputs': 29, 'leak_rate': 0.7829255712488108, 'lr': 0.014810038346758226, 'optimizer': 'Adam', 'sparsity': 0.9225209684665923, 'steps_to_train': 31, 'weight_decay': 0.01571872599753148}, 'budget': 400.0, 'working_directory': '.'}
19:58:35 DISPATCHER: Starting worker discovery
19:58:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:58:35 DISPATCHER: Finished worker discovery
19:59:35 DISPATCHER: Starting worker discovery
19:59:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:59:35 DISPATCHER: Finished worker discovery
20:00:35 DISPATCHER: Starting worker discovery
20:00:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:00:35 DISPATCHER: Finished worker discovery
20:01:35 DISPATCHER: Starting worker discovery
20:01:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:01:35 DISPATCHER: Finished worker discovery
20:02:35 DISPATCHER: Starting worker discovery
20:02:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:02:35 DISPATCHER: Finished worker discovery
20:03:35 DISPATCHER: Starting worker discovery
20:03:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:03:35 DISPATCHER: Finished worker discovery
20:04:35 DISPATCHER: Starting worker discovery
20:04:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:04:35 DISPATCHER: Finished worker discovery
20:05:33 WORKER: done with job (0, 0, 8), trying to register it.
20:05:33 WORKER: registered result for job (0, 0, 8) with dispatcher
20:05:33 DISPATCHER: job (0, 0, 8) finished
20:05:33 DISPATCHER: register_result: lock acquired
20:05:33 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
20:05:33 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 626, 'last_n_outputs': 29, 'leak_rate': 0.7829255712488108, 'lr': 0.014810038346758226, 'optimizer': 'Adam', 'sparsity': 0.9225209684665923, 'steps_to_train': 31, 'weight_decay': 0.01571872599753148}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.07873533543952657, 'info': {'sick_no_sick': 0.07873533543952657, 'config': "{'batch_size': 32, 'hidden_dim': 626, 'last_n_outputs': 29, 'leak_rate': 0.7829255712488108, 'lr': 0.014810038346758226, 'optimizer': 'Adam', 'sparsity': 0.9225209684665923, 'steps_to_train': 31, 'weight_decay': 0.01571872599753148}"}}
exception: None

20:05:33 job_callback for (0, 0, 8) started
20:05:33 DISPATCHER: Trying to submit another job.
20:05:33 job_callback for (0, 0, 8) got condition
20:05:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:05:33 Only 1 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
20:05:33 HBMASTER: Trying to run another job!
20:05:33 job_callback for (0, 0, 8) finished
20:05:33 HBMASTER: schedule new run for iteration 0
20:05:33 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
20:05:33 HBMASTER: submitting job (0, 0, 22) to dispatcher
20:05:33 DISPATCHER: trying to submit job (0, 0, 22)
20:05:33 DISPATCHER: trying to notify the job_runner thread.
20:05:33 HBMASTER: job (0, 0, 22) submitted to dispatcher
20:05:33 DISPATCHER: Trying to submit another job.
20:05:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:05:33 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.30598140416580691776
20:05:33 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
20:05:33 WORKER: start processing job (0, 0, 22)
20:05:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:05:33 WORKER: args: ()
20:05:33 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 742, 'last_n_outputs': 48, 'leak_rate': 0.8978614951936096, 'lr': 0.0012860604080655804, 'optimizer': 'SGD', 'sparsity': 0.8921436521401581, 'steps_to_train': 15, 'weight_decay': 0.12620261088062076}, 'budget': 400.0, 'working_directory': '.'}
20:05:35 DISPATCHER: Starting worker discovery
20:05:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:05:35 DISPATCHER: Finished worker discovery
20:06:35 DISPATCHER: Starting worker discovery
20:06:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:06:35 DISPATCHER: Finished worker discovery
20:07:35 DISPATCHER: Starting worker discovery
20:07:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:07:35 DISPATCHER: Finished worker discovery
20:08:35 DISPATCHER: Starting worker discovery
20:08:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:08:35 DISPATCHER: Finished worker discovery
20:09:35 DISPATCHER: Starting worker discovery
20:09:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:09:35 DISPATCHER: Finished worker discovery
20:10:35 DISPATCHER: Starting worker discovery
20:10:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:10:35 DISPATCHER: Finished worker discovery
20:11:35 DISPATCHER: Starting worker discovery
20:11:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:11:35 DISPATCHER: Finished worker discovery
20:12:35 DISPATCHER: Starting worker discovery
20:12:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:12:35 DISPATCHER: Finished worker discovery
20:13:19 WORKER: done with job (0, 0, 22), trying to register it.
20:13:19 WORKER: registered result for job (0, 0, 22) with dispatcher
20:13:19 DISPATCHER: job (0, 0, 22) finished
20:13:19 DISPATCHER: register_result: lock acquired
20:13:19 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
20:13:19 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 742, 'last_n_outputs': 48, 'leak_rate': 0.8978614951936096, 'lr': 0.0012860604080655804, 'optimizer': 'SGD', 'sparsity': 0.8921436521401581, 'steps_to_train': 15, 'weight_decay': 0.12620261088062076}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.15124696177118083, 'info': {'sick_no_sick': 0.15124696177118083, 'config': "{'batch_size': 128, 'hidden_dim': 742, 'last_n_outputs': 48, 'leak_rate': 0.8978614951936096, 'lr': 0.0012860604080655804, 'optimizer': 'SGD', 'sparsity': 0.8921436521401581, 'steps_to_train': 15, 'weight_decay': 0.12620261088062076}"}}
exception: None

20:13:19 job_callback for (0, 0, 22) started
20:13:19 job_callback for (0, 0, 22) got condition
20:13:19 DISPATCHER: Trying to submit another job.
20:13:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:13:19 Only 2 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
20:13:19 HBMASTER: Trying to run another job!
20:13:19 job_callback for (0, 0, 22) finished
20:13:19 HBMASTER: schedule new run for iteration 0
20:13:19 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
20:13:19 HBMASTER: submitting job (0, 0, 24) to dispatcher
20:13:19 DISPATCHER: trying to submit job (0, 0, 24)
20:13:19 DISPATCHER: trying to notify the job_runner thread.
20:13:19 HBMASTER: job (0, 0, 24) submitted to dispatcher
20:13:19 DISPATCHER: Trying to submit another job.
20:13:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:13:19 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpuj.30598140416580691776
20:13:19 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
20:13:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:13:19 WORKER: start processing job (0, 0, 24)
20:13:19 WORKER: args: ()
20:13:19 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 606, 'last_n_outputs': 40, 'leak_rate': 0.9657440208891559, 'lr': 0.0011262301687495974, 'optimizer': 'SGD', 'sparsity': 0.9112711710611633, 'steps_to_train': 38, 'weight_decay': 0.020641402627275676}, 'budget': 400.0, 'working_directory': '.'}
20:13:35 DISPATCHER: Starting worker discovery
20:13:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:13:35 DISPATCHER: Finished worker discovery
20:14:35 DISPATCHER: Starting worker discovery
20:14:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:14:35 DISPATCHER: Finished worker discovery
20:15:35 DISPATCHER: Starting worker discovery
20:15:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:15:35 DISPATCHER: Finished worker discovery
20:16:35 DISPATCHER: Starting worker discovery
20:16:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:16:35 DISPATCHER: Finished worker discovery
20:17:35 DISPATCHER: Starting worker discovery
20:17:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:17:35 DISPATCHER: Finished worker discovery
20:18:35 DISPATCHER: Starting worker discovery
20:18:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:18:35 DISPATCHER: Finished worker discovery
20:19:35 DISPATCHER: Starting worker discovery
20:19:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:19:35 DISPATCHER: Finished worker discovery
20:20:35 DISPATCHER: Starting worker discovery
20:20:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:20:35 DISPATCHER: Finished worker discovery
20:21:04 WORKER: done with job (0, 0, 24), trying to register it.
20:21:04 WORKER: registered result for job (0, 0, 24) with dispatcher
20:21:04 DISPATCHER: job (0, 0, 24) finished
20:21:04 DISPATCHER: register_result: lock acquired
20:21:04 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
20:21:04 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 606, 'last_n_outputs': 40, 'leak_rate': 0.9657440208891559, 'lr': 0.0011262301687495974, 'optimizer': 'SGD', 'sparsity': 0.9112711710611633, 'steps_to_train': 38, 'weight_decay': 0.020641402627275676}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.14939575420501994, 'info': {'sick_no_sick': 0.14939575420501994, 'config': "{'batch_size': 64, 'hidden_dim': 606, 'last_n_outputs': 40, 'leak_rate': 0.9657440208891559, 'lr': 0.0011262301687495974, 'optimizer': 'SGD', 'sparsity': 0.9112711710611633, 'steps_to_train': 38, 'weight_decay': 0.020641402627275676}"}}
exception: None

20:21:04 job_callback for (0, 0, 24) started
20:21:04 DISPATCHER: Trying to submit another job.
20:21:04 job_callback for (0, 0, 24) got condition
20:21:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:21:04 Only 3 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
20:21:04 HBMASTER: Trying to run another job!
20:21:04 job_callback for (0, 0, 24) finished
20:21:04 ITERATION: Advancing config (0, 0, 22) to next budget 1200.000000
20:21:04 HBMASTER: schedule new run for iteration 0
20:21:04 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
20:21:04 HBMASTER: submitting job (0, 0, 22) to dispatcher
20:21:04 DISPATCHER: trying to submit job (0, 0, 22)
20:21:04 DISPATCHER: trying to notify the job_runner thread.
20:21:04 HBMASTER: job (0, 0, 22) submitted to dispatcher
20:21:04 DISPATCHER: Trying to submit another job.
20:21:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:21:04 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.30598140416580691776
20:21:04 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
20:21:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:21:04 WORKER: start processing job (0, 0, 22)
20:21:04 WORKER: args: ()
20:21:04 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 742, 'last_n_outputs': 48, 'leak_rate': 0.8978614951936096, 'lr': 0.0012860604080655804, 'optimizer': 'SGD', 'sparsity': 0.8921436521401581, 'steps_to_train': 15, 'weight_decay': 0.12620261088062076}, 'budget': 1200.0, 'working_directory': '.'}
20:21:35 DISPATCHER: Starting worker discovery
20:21:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:21:35 DISPATCHER: Finished worker discovery
20:22:35 DISPATCHER: Starting worker discovery
20:22:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:22:35 DISPATCHER: Finished worker discovery
20:23:35 DISPATCHER: Starting worker discovery
20:23:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:23:35 DISPATCHER: Finished worker discovery
20:24:35 DISPATCHER: Starting worker discovery
20:24:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:24:35 DISPATCHER: Finished worker discovery
20:25:35 DISPATCHER: Starting worker discovery
20:25:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:25:35 DISPATCHER: Finished worker discovery
20:26:35 DISPATCHER: Starting worker discovery
20:26:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:26:35 DISPATCHER: Finished worker discovery
20:27:35 DISPATCHER: Starting worker discovery
20:27:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:27:35 DISPATCHER: Finished worker discovery
20:28:35 DISPATCHER: Starting worker discovery
20:28:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:28:35 DISPATCHER: Finished worker discovery
20:29:35 DISPATCHER: Starting worker discovery
20:29:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:29:35 DISPATCHER: Finished worker discovery
20:30:35 DISPATCHER: Starting worker discovery
20:30:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:30:35 DISPATCHER: Finished worker discovery
20:31:35 DISPATCHER: Starting worker discovery
20:31:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:31:35 DISPATCHER: Finished worker discovery
20:32:35 DISPATCHER: Starting worker discovery
20:32:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:32:35 DISPATCHER: Finished worker discovery
20:33:35 DISPATCHER: Starting worker discovery
20:33:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:33:35 DISPATCHER: Finished worker discovery
20:34:35 DISPATCHER: Starting worker discovery
20:34:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:34:35 DISPATCHER: Finished worker discovery
20:35:35 DISPATCHER: Starting worker discovery
20:35:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:35:35 DISPATCHER: Finished worker discovery
20:36:35 DISPATCHER: Starting worker discovery
20:36:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:36:35 DISPATCHER: Finished worker discovery
20:37:35 DISPATCHER: Starting worker discovery
20:37:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:37:35 DISPATCHER: Finished worker discovery
20:38:35 DISPATCHER: Starting worker discovery
20:38:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:38:35 DISPATCHER: Finished worker discovery
20:39:35 DISPATCHER: Starting worker discovery
20:39:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:39:35 DISPATCHER: Finished worker discovery
20:40:35 DISPATCHER: Starting worker discovery
20:40:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:40:35 DISPATCHER: Finished worker discovery
20:41:35 DISPATCHER: Starting worker discovery
20:41:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:41:35 DISPATCHER: Finished worker discovery
20:42:23 WORKER: done with job (0, 0, 22), trying to register it.
20:42:23 WORKER: registered result for job (0, 0, 22) with dispatcher
20:42:23 DISPATCHER: job (0, 0, 22) finished
20:42:23 DISPATCHER: register_result: lock acquired
20:42:23 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
20:42:23 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 742, 'last_n_outputs': 48, 'leak_rate': 0.8978614951936096, 'lr': 0.0012860604080655804, 'optimizer': 'SGD', 'sparsity': 0.8921436521401581, 'steps_to_train': 15, 'weight_decay': 0.12620261088062076}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.16006689958575634, 'info': {'sick_no_sick': 0.16006689958575634, 'config': "{'batch_size': 128, 'hidden_dim': 742, 'last_n_outputs': 48, 'leak_rate': 0.8978614951936096, 'lr': 0.0012860604080655804, 'optimizer': 'SGD', 'sparsity': 0.8921436521401581, 'steps_to_train': 15, 'weight_decay': 0.12620261088062076}"}}
exception: None

20:42:23 job_callback for (0, 0, 22) started
20:42:23 job_callback for (0, 0, 22) got condition
20:42:23 DISPATCHER: Trying to submit another job.
20:42:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:42:23 Only 1 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
20:42:23 HBMASTER: Trying to run another job!
20:42:23 job_callback for (0, 0, 22) finished
20:42:23 start sampling a new configuration.
20:42:23 best_vector: [2, 0.7900686235308964, 0.7004625566233493, 0.7044957851025428, 0.12820888276345332, 0, 0.973302487698234, 0.8055082431298528, 0.1532844016954744], 0.0016986184599499913, 0.25249608134908763, 0.000428894504844595
20:42:23 done sampling a new configuration.
20:42:23 HBMASTER: schedule new run for iteration 1
20:42:23 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
20:42:23 HBMASTER: submitting job (1, 0, 0) to dispatcher
20:42:23 DISPATCHER: trying to submit job (1, 0, 0)
20:42:23 DISPATCHER: trying to notify the job_runner thread.
20:42:23 HBMASTER: job (1, 0, 0) submitted to dispatcher
20:42:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:42:23 DISPATCHER: Trying to submit another job.
20:42:23 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
20:42:23 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
20:42:23 WORKER: start processing job (1, 0, 0)
20:42:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:42:23 WORKER: args: ()
20:42:23 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 832, 'last_n_outputs': 38, 'leak_rate': 0.9261239462756357, 'lr': 0.0018047529714221913, 'optimizer': 'Adam', 'sparsity': 0.9835925970475762, 'steps_to_train': 83, 'weight_decay': 0.015828056959731197}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:42:35 DISPATCHER: Starting worker discovery
20:42:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:42:35 DISPATCHER: Finished worker discovery
20:43:35 DISPATCHER: Starting worker discovery
20:43:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:43:35 DISPATCHER: Finished worker discovery
20:44:35 DISPATCHER: Starting worker discovery
20:44:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:44:35 DISPATCHER: Finished worker discovery
20:45:35 DISPATCHER: Starting worker discovery
20:45:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:45:35 DISPATCHER: Finished worker discovery
20:45:39 WORKER: done with job (1, 0, 0), trying to register it.
20:45:39 WORKER: registered result for job (1, 0, 0) with dispatcher
20:45:39 DISPATCHER: job (1, 0, 0) finished
20:45:39 DISPATCHER: register_result: lock acquired
20:45:39 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
20:45:39 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 832, 'last_n_outputs': 38, 'leak_rate': 0.9261239462756357, 'lr': 0.0018047529714221913, 'optimizer': 'Adam', 'sparsity': 0.9835925970475762, 'steps_to_train': 83, 'weight_decay': 0.015828056959731197}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.18497288231916365, 'info': {'sick_no_sick': 0.18497288231916365, 'config': "{'batch_size': 64, 'hidden_dim': 832, 'last_n_outputs': 38, 'leak_rate': 0.9261239462756357, 'lr': 0.0018047529714221913, 'optimizer': 'Adam', 'sparsity': 0.9835925970475762, 'steps_to_train': 83, 'weight_decay': 0.015828056959731197}"}}
exception: None

20:45:39 job_callback for (1, 0, 0) started
20:45:39 DISPATCHER: Trying to submit another job.
20:45:39 job_callback for (1, 0, 0) got condition
20:45:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:45:39 HBMASTER: Trying to run another job!
20:45:39 job_callback for (1, 0, 0) finished
20:45:39 start sampling a new configuration.
20:45:39 best_vector: [3, 0.12272959738833666, 0.7599698219706494, 0.6812761012944488, 0.005968083047733892, 1, 0.5936896951153929, 0.32180716363858264, 0.111071743824085], 0.003016318882838259, 0.32041374299577885, 0.0009664700233190527
20:45:39 done sampling a new configuration.
20:45:39 HBMASTER: schedule new run for iteration 1
20:45:39 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
20:45:39 HBMASTER: submitting job (1, 0, 1) to dispatcher
20:45:39 DISPATCHER: trying to submit job (1, 0, 1)
20:45:39 DISPATCHER: trying to notify the job_runner thread.
20:45:39 HBMASTER: job (1, 0, 1) submitted to dispatcher
20:45:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:45:39 DISPATCHER: Trying to submit another job.
20:45:39 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
20:45:39 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
20:45:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:45:39 WORKER: start processing job (1, 0, 1)
20:45:39 WORKER: args: ()
20:45:39 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 298, 'last_n_outputs': 41, 'leak_rate': 0.9203190253236122, 'lr': 0.0010278652083140956, 'optimizer': 'SGD', 'sparsity': 0.8924855268276943, 'steps_to_train': 39, 'weight_decay': 0.013947862917419488}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:46:35 DISPATCHER: Starting worker discovery
20:46:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:46:35 DISPATCHER: Finished worker discovery
20:47:35 DISPATCHER: Starting worker discovery
20:47:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:47:35 DISPATCHER: Finished worker discovery
20:48:35 DISPATCHER: Starting worker discovery
20:48:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:48:35 DISPATCHER: Finished worker discovery
20:48:57 WORKER: done with job (1, 0, 1), trying to register it.
20:48:57 WORKER: registered result for job (1, 0, 1) with dispatcher
20:48:57 DISPATCHER: job (1, 0, 1) finished
20:48:57 DISPATCHER: register_result: lock acquired
20:48:57 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
20:48:57 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 298, 'last_n_outputs': 41, 'leak_rate': 0.9203190253236122, 'lr': 0.0010278652083140956, 'optimizer': 'SGD', 'sparsity': 0.8924855268276943, 'steps_to_train': 39, 'weight_decay': 0.013947862917419488}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.20370536765480907, 'info': {'sick_no_sick': 0.20370536765480907, 'config': "{'batch_size': 128, 'hidden_dim': 298, 'last_n_outputs': 41, 'leak_rate': 0.9203190253236122, 'lr': 0.0010278652083140956, 'optimizer': 'SGD', 'sparsity': 0.8924855268276943, 'steps_to_train': 39, 'weight_decay': 0.013947862917419488}"}}
exception: None

20:48:57 job_callback for (1, 0, 1) started
20:48:57 job_callback for (1, 0, 1) got condition
20:48:57 DISPATCHER: Trying to submit another job.
20:48:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:48:57 HBMASTER: Trying to run another job!
20:48:57 job_callback for (1, 0, 1) finished
20:48:57 start sampling a new configuration.
20:48:57 done sampling a new configuration.
20:48:57 HBMASTER: schedule new run for iteration 1
20:48:57 HBMASTER: trying submitting job (1, 0, 2) to dispatcher
20:48:57 HBMASTER: submitting job (1, 0, 2) to dispatcher
20:48:57 DISPATCHER: trying to submit job (1, 0, 2)
20:48:57 DISPATCHER: trying to notify the job_runner thread.
20:48:57 HBMASTER: job (1, 0, 2) submitted to dispatcher
20:48:57 DISPATCHER: Trying to submit another job.
20:48:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:48:57 DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
20:48:57 DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
20:48:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:48:57 WORKER: start processing job (1, 0, 2)
20:48:57 WORKER: args: ()
20:48:57 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 216, 'last_n_outputs': 16, 'leak_rate': 0.9122645957844943, 'lr': 0.0016012547089281572, 'optimizer': 'SGD', 'sparsity': 0.982150321717715, 'steps_to_train': 13, 'weight_decay': 0.15124766218839997}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:49:35 DISPATCHER: Starting worker discovery
20:49:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:49:35 DISPATCHER: Finished worker discovery
20:50:35 DISPATCHER: Starting worker discovery
20:50:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:50:35 DISPATCHER: Finished worker discovery
20:51:35 DISPATCHER: Starting worker discovery
20:51:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:51:35 DISPATCHER: Finished worker discovery
20:52:14 WORKER: done with job (1, 0, 2), trying to register it.
20:52:14 WORKER: registered result for job (1, 0, 2) with dispatcher
20:52:14 DISPATCHER: job (1, 0, 2) finished
20:52:14 DISPATCHER: register_result: lock acquired
20:52:14 DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
20:52:14 job_id: (1, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 216, 'last_n_outputs': 16, 'leak_rate': 0.9122645957844943, 'lr': 0.0016012547089281572, 'optimizer': 'SGD', 'sparsity': 0.982150321717715, 'steps_to_train': 13, 'weight_decay': 0.15124766218839997}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.13498406645535616, 'info': {'sick_no_sick': 0.13498406645535616, 'config': "{'batch_size': 128, 'hidden_dim': 216, 'last_n_outputs': 16, 'leak_rate': 0.9122645957844943, 'lr': 0.0016012547089281572, 'optimizer': 'SGD', 'sparsity': 0.982150321717715, 'steps_to_train': 13, 'weight_decay': 0.15124766218839997}"}}
exception: None

20:52:14 job_callback for (1, 0, 2) started
20:52:14 DISPATCHER: Trying to submit another job.
20:52:14 job_callback for (1, 0, 2) got condition
20:52:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:52:14 HBMASTER: Trying to run another job!
20:52:14 job_callback for (1, 0, 2) finished
20:52:14 start sampling a new configuration.
20:52:14 done sampling a new configuration.
20:52:14 HBMASTER: schedule new run for iteration 1
20:52:14 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
20:52:14 HBMASTER: submitting job (1, 0, 3) to dispatcher
20:52:14 DISPATCHER: trying to submit job (1, 0, 3)
20:52:14 DISPATCHER: trying to notify the job_runner thread.
20:52:14 HBMASTER: job (1, 0, 3) submitted to dispatcher
20:52:14 DISPATCHER: Trying to submit another job.
20:52:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:52:14 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
20:52:14 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
20:52:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:52:14 WORKER: start processing job (1, 0, 3)
20:52:14 WORKER: args: ()
20:52:14 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 901, 'last_n_outputs': 40, 'leak_rate': 0.8811815856215269, 'lr': 0.0015808914218834267, 'optimizer': 'SGD', 'sparsity': 0.9094270033750156, 'steps_to_train': 24, 'weight_decay': 0.046496911345069544}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:52:35 DISPATCHER: Starting worker discovery
20:52:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:52:35 DISPATCHER: Finished worker discovery
20:53:35 DISPATCHER: Starting worker discovery
20:53:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:53:35 DISPATCHER: Finished worker discovery
20:54:35 DISPATCHER: Starting worker discovery
20:54:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:54:35 DISPATCHER: Finished worker discovery
20:55:31 WORKER: done with job (1, 0, 3), trying to register it.
20:55:31 WORKER: registered result for job (1, 0, 3) with dispatcher
20:55:31 DISPATCHER: job (1, 0, 3) finished
20:55:31 DISPATCHER: register_result: lock acquired
20:55:31 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
20:55:31 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 901, 'last_n_outputs': 40, 'leak_rate': 0.8811815856215269, 'lr': 0.0015808914218834267, 'optimizer': 'SGD', 'sparsity': 0.9094270033750156, 'steps_to_train': 24, 'weight_decay': 0.046496911345069544}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.014199881455837376, 'info': {'sick_no_sick': 0.014199881455837376, 'config': "{'batch_size': 16, 'hidden_dim': 901, 'last_n_outputs': 40, 'leak_rate': 0.8811815856215269, 'lr': 0.0015808914218834267, 'optimizer': 'SGD', 'sparsity': 0.9094270033750156, 'steps_to_train': 24, 'weight_decay': 0.046496911345069544}"}}
exception: None

20:55:31 job_callback for (1, 0, 3) started
20:55:31 job_callback for (1, 0, 3) got condition
20:55:31 DISPATCHER: Trying to submit another job.
20:55:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:55:31 HBMASTER: Trying to run another job!
20:55:31 job_callback for (1, 0, 3) finished
20:55:31 start sampling a new configuration.
20:55:31 best_vector: [1, 0.44114306670351455, 0.5411896863390245, 0.9955834825292574, 0.02121771348639311, 1, 0.6962612115565201, 0.334579854193257, 0.07560882926282342], 0.0008822245303893975, 0.36349441911254565, 0.00032068369320073243
20:55:31 done sampling a new configuration.
20:55:31 HBMASTER: schedule new run for iteration 1
20:55:31 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
20:55:31 HBMASTER: submitting job (1, 0, 4) to dispatcher
20:55:31 DISPATCHER: trying to submit job (1, 0, 4)
20:55:31 DISPATCHER: trying to notify the job_runner thread.
20:55:31 HBMASTER: job (1, 0, 4) submitted to dispatcher
20:55:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:55:31 DISPATCHER: Trying to submit another job.
20:55:31 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776
20:55:31 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
20:55:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:55:31 WORKER: start processing job (1, 0, 4)
20:55:31 WORKER: args: ()
20:55:31 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 553, 'last_n_outputs': 32, 'leak_rate': 0.9988958706323143, 'lr': 0.0011026442751181477, 'optimizer': 'SGD', 'sparsity': 0.9171026907735649, 'steps_to_train': 40, 'weight_decay': 0.012542073883402437}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:55:35 DISPATCHER: Starting worker discovery
20:55:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:55:35 DISPATCHER: Finished worker discovery
20:56:35 DISPATCHER: Starting worker discovery
20:56:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:56:35 DISPATCHER: Finished worker discovery
20:57:35 DISPATCHER: Starting worker discovery
20:57:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:57:35 DISPATCHER: Finished worker discovery
20:58:35 DISPATCHER: Starting worker discovery
20:58:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:58:35 DISPATCHER: Finished worker discovery
20:58:46 WORKER: done with job (1, 0, 4), trying to register it.
20:58:46 WORKER: registered result for job (1, 0, 4) with dispatcher
20:58:46 DISPATCHER: job (1, 0, 4) finished
20:58:46 DISPATCHER: register_result: lock acquired
20:58:46 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
20:58:46 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 553, 'last_n_outputs': 32, 'leak_rate': 0.9988958706323143, 'lr': 0.0011026442751181477, 'optimizer': 'SGD', 'sparsity': 0.9171026907735649, 'steps_to_train': 40, 'weight_decay': 0.012542073883402437}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.14085803482313425, 'info': {'sick_no_sick': 0.14085803482313425, 'config': "{'batch_size': 32, 'hidden_dim': 553, 'last_n_outputs': 32, 'leak_rate': 0.9988958706323143, 'lr': 0.0011026442751181477, 'optimizer': 'SGD', 'sparsity': 0.9171026907735649, 'steps_to_train': 40, 'weight_decay': 0.012542073883402437}"}}
exception: None

20:58:46 job_callback for (1, 0, 4) started
20:58:46 job_callback for (1, 0, 4) got condition
20:58:46 DISPATCHER: Trying to submit another job.
20:58:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:58:46 HBMASTER: Trying to run another job!
20:58:46 job_callback for (1, 0, 4) finished
20:58:46 start sampling a new configuration.
20:58:46 best_vector: [0, 0.5987342279707, 0.27351007999080124, 0.8712455854080248, 0.04831782005792731, 0, 0.9001856675575538, 0.7675507114823328, 0.35667193374347117], 0.0020849129906763716, 0.07677959166443533, 0.0001600787680800085
20:58:46 done sampling a new configuration.
20:58:46 HBMASTER: schedule new run for iteration 1
20:58:46 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
20:58:46 HBMASTER: submitting job (1, 0, 5) to dispatcher
20:58:46 DISPATCHER: trying to submit job (1, 0, 5)
20:58:46 DISPATCHER: trying to notify the job_runner thread.
20:58:46 HBMASTER: job (1, 0, 5) submitted to dispatcher
20:58:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:58:46 DISPATCHER: Trying to submit another job.
20:58:46 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776
20:58:46 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
20:58:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:58:46 WORKER: start processing job (1, 0, 5)
20:58:46 WORKER: args: ()
20:58:46 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 679, 'last_n_outputs': 21, 'leak_rate': 0.9678113963520062, 'lr': 0.001249210540739004, 'optimizer': 'Adam', 'sparsity': 0.9660445602138129, 'steps_to_train': 79, 'weight_decay': 0.029109911453998674}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:59:35 DISPATCHER: Starting worker discovery
20:59:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:59:35 DISPATCHER: Finished worker discovery
21:00:35 DISPATCHER: Starting worker discovery
21:00:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:00:35 DISPATCHER: Finished worker discovery
21:01:35 DISPATCHER: Starting worker discovery
21:01:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:01:35 DISPATCHER: Finished worker discovery
21:02:03 WORKER: done with job (1, 0, 5), trying to register it.
21:02:03 WORKER: registered result for job (1, 0, 5) with dispatcher
21:02:03 DISPATCHER: job (1, 0, 5) finished
21:02:03 DISPATCHER: register_result: lock acquired
21:02:03 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
21:02:03 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 679, 'last_n_outputs': 21, 'leak_rate': 0.9678113963520062, 'lr': 0.001249210540739004, 'optimizer': 'Adam', 'sparsity': 0.9660445602138129, 'steps_to_train': 79, 'weight_decay': 0.029109911453998674}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.11547613786577976, 'info': {'sick_no_sick': 0.11547613786577976, 'config': "{'batch_size': 16, 'hidden_dim': 679, 'last_n_outputs': 21, 'leak_rate': 0.9678113963520062, 'lr': 0.001249210540739004, 'optimizer': 'Adam', 'sparsity': 0.9660445602138129, 'steps_to_train': 79, 'weight_decay': 0.029109911453998674}"}}
exception: None

21:02:03 job_callback for (1, 0, 5) started
21:02:03 job_callback for (1, 0, 5) got condition
21:02:03 DISPATCHER: Trying to submit another job.
21:02:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:02:03 HBMASTER: Trying to run another job!
21:02:03 job_callback for (1, 0, 5) finished
21:02:03 start sampling a new configuration.
21:02:03 best_vector: [2, 0.4427748316345969, 0.773904834570469, 0.7125113341012319, 0.05752424609621537, 0, 0.7180969897049596, 0.44091148078652653, 0.13738135446029837], 0.02732443105758344, 0.06075360076748748, 0.0016600575756711602
21:02:03 done sampling a new configuration.
21:02:03 HBMASTER: schedule new run for iteration 1
21:02:03 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
21:02:03 HBMASTER: submitting job (1, 0, 6) to dispatcher
21:02:03 DISPATCHER: trying to submit job (1, 0, 6)
21:02:03 DISPATCHER: trying to notify the job_runner thread.
21:02:03 HBMASTER: job (1, 0, 6) submitted to dispatcher
21:02:03 DISPATCHER: Trying to submit another job.
21:02:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:02:03 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776
21:02:03 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
21:02:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:02:03 WORKER: start processing job (1, 0, 6)
21:02:03 WORKER: args: ()
21:02:03 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 554, 'last_n_outputs': 41, 'leak_rate': 0.928127833525308, 'lr': 0.0013033122947896261, 'optimizer': 'Adam', 'sparsity': 0.9223432775291903, 'steps_to_train': 50, 'weight_decay': 0.015091668707572573}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:02:35 DISPATCHER: Starting worker discovery
21:02:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:02:35 DISPATCHER: Finished worker discovery
21:03:35 DISPATCHER: Starting worker discovery
21:03:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:03:35 DISPATCHER: Finished worker discovery
21:04:35 DISPATCHER: Starting worker discovery
21:04:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:04:35 DISPATCHER: Finished worker discovery
21:05:20 WORKER: done with job (1, 0, 6), trying to register it.
21:05:20 WORKER: registered result for job (1, 0, 6) with dispatcher
21:05:20 DISPATCHER: job (1, 0, 6) finished
21:05:20 DISPATCHER: register_result: lock acquired
21:05:20 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
21:05:20 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 554, 'last_n_outputs': 41, 'leak_rate': 0.928127833525308, 'lr': 0.0013033122947896261, 'optimizer': 'Adam', 'sparsity': 0.9223432775291903, 'steps_to_train': 50, 'weight_decay': 0.015091668707572573}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.19073548708549765, 'info': {'sick_no_sick': 0.19073548708549765, 'config': "{'batch_size': 64, 'hidden_dim': 554, 'last_n_outputs': 41, 'leak_rate': 0.928127833525308, 'lr': 0.0013033122947896261, 'optimizer': 'Adam', 'sparsity': 0.9223432775291903, 'steps_to_train': 50, 'weight_decay': 0.015091668707572573}"}}
exception: None

21:05:20 job_callback for (1, 0, 6) started
21:05:20 job_callback for (1, 0, 6) got condition
21:05:20 DISPATCHER: Trying to submit another job.
21:05:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:05:20 HBMASTER: Trying to run another job!
21:05:20 job_callback for (1, 0, 6) finished
21:05:20 start sampling a new configuration.
21:05:20 best_vector: [1, 0.6797100996422555, 0.7020413717955413, 0.9415117940627986, 0.5906407124383317, 0, 0.88056718694726, 0.8135173511928544, 0.8852030106380707], 0.008812701962064953, 0.009908860214531336, 8.732383185442766e-05
21:05:20 done sampling a new configuration.
21:05:20 HBMASTER: schedule new run for iteration 1
21:05:20 HBMASTER: trying submitting job (1, 0, 7) to dispatcher
21:05:20 HBMASTER: submitting job (1, 0, 7) to dispatcher
21:05:20 DISPATCHER: trying to submit job (1, 0, 7)
21:05:20 DISPATCHER: trying to notify the job_runner thread.
21:05:20 HBMASTER: job (1, 0, 7) submitted to dispatcher
21:05:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:05:20 DISPATCHER: Trying to submit another job.
21:05:20 DISPATCHER: starting job (1, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776
21:05:20 DISPATCHER: job (1, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
21:05:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:05:20 WORKER: start processing job (1, 0, 7)
21:05:20 WORKER: args: ()
21:05:20 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 744, 'last_n_outputs': 38, 'leak_rate': 0.9853779485156997, 'lr': 0.015180337418479479, 'optimizer': 'Adam', 'sparsity': 0.9613361248673424, 'steps_to_train': 84, 'weight_decay': 0.14179981658346968}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:05:35 DISPATCHER: Starting worker discovery
21:05:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:05:35 DISPATCHER: Finished worker discovery
21:06:35 DISPATCHER: Starting worker discovery
21:06:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:06:35 DISPATCHER: Finished worker discovery
21:07:35 DISPATCHER: Starting worker discovery
21:07:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:07:35 DISPATCHER: Finished worker discovery
21:08:35 DISPATCHER: Starting worker discovery
21:08:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:08:35 DISPATCHER: Finished worker discovery
21:08:37 WORKER: done with job (1, 0, 7), trying to register it.
21:08:37 WORKER: registered result for job (1, 0, 7) with dispatcher
21:08:37 DISPATCHER: job (1, 0, 7) finished
21:08:37 DISPATCHER: register_result: lock acquired
21:08:37 DISPATCHER: job (1, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
21:08:37 job_id: (1, 0, 7)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 744, 'last_n_outputs': 38, 'leak_rate': 0.9853779485156997, 'lr': 0.015180337418479479, 'optimizer': 'Adam', 'sparsity': 0.9613361248673424, 'steps_to_train': 84, 'weight_decay': 0.14179981658346968}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.14527208288691562, 'info': {'sick_no_sick': 0.14527208288691562, 'config': "{'batch_size': 32, 'hidden_dim': 744, 'last_n_outputs': 38, 'leak_rate': 0.9853779485156997, 'lr': 0.015180337418479479, 'optimizer': 'Adam', 'sparsity': 0.9613361248673424, 'steps_to_train': 84, 'weight_decay': 0.14179981658346968}"}}
exception: None

21:08:37 job_callback for (1, 0, 7) started
21:08:37 DISPATCHER: Trying to submit another job.
21:08:37 job_callback for (1, 0, 7) got condition
21:08:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:08:37 HBMASTER: Trying to run another job!
21:08:37 job_callback for (1, 0, 7) finished
21:08:37 start sampling a new configuration.
21:08:37 best_vector: [1, 0.04255026674129614, 0.8713162649164333, 0.9948995300933435, 0.3025429605488694, 1, 0.5886426759169986, 0.9845390394463573, 0.24795482459498297], 0.007245099507764183, 0.003222614871521082, 2.3348165419370924e-05
21:08:37 done sampling a new configuration.
21:08:37 HBMASTER: schedule new run for iteration 1
21:08:37 HBMASTER: trying submitting job (1, 0, 8) to dispatcher
21:08:37 HBMASTER: submitting job (1, 0, 8) to dispatcher
21:08:37 DISPATCHER: trying to submit job (1, 0, 8)
21:08:37 DISPATCHER: trying to notify the job_runner thread.
21:08:37 HBMASTER: job (1, 0, 8) submitted to dispatcher
21:08:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:08:37 DISPATCHER: Trying to submit another job.
21:08:37 DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776
21:08:37 DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
21:08:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:08:37 WORKER: start processing job (1, 0, 8)
21:08:37 WORKER: args: ()
21:08:37 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 234, 'last_n_outputs': 45, 'leak_rate': 0.9987248825233359, 'lr': 0.004027967160026739, 'optimizer': 'SGD', 'sparsity': 0.8912742422200797, 'steps_to_train': 99, 'weight_decay': 0.02101825536968915}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:09:35 DISPATCHER: Starting worker discovery
21:09:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:09:35 DISPATCHER: Finished worker discovery
21:10:35 DISPATCHER: Starting worker discovery
21:10:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:10:35 DISPATCHER: Finished worker discovery
21:11:35 DISPATCHER: Starting worker discovery
21:11:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:11:35 DISPATCHER: Finished worker discovery
21:11:53 WORKER: done with job (1, 0, 8), trying to register it.
21:11:53 WORKER: registered result for job (1, 0, 8) with dispatcher
21:11:53 DISPATCHER: job (1, 0, 8) finished
21:11:53 DISPATCHER: register_result: lock acquired
21:11:53 DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
21:11:53 job_id: (1, 0, 8)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 234, 'last_n_outputs': 45, 'leak_rate': 0.9987248825233359, 'lr': 0.004027967160026739, 'optimizer': 'SGD', 'sparsity': 0.8912742422200797, 'steps_to_train': 99, 'weight_decay': 0.02101825536968915}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2131186319866853, 'info': {'sick_no_sick': 0.2131186319866853, 'config': "{'batch_size': 32, 'hidden_dim': 234, 'last_n_outputs': 45, 'leak_rate': 0.9987248825233359, 'lr': 0.004027967160026739, 'optimizer': 'SGD', 'sparsity': 0.8912742422200797, 'steps_to_train': 99, 'weight_decay': 0.02101825536968915}"}}
exception: None

21:11:53 job_callback for (1, 0, 8) started
21:11:53 job_callback for (1, 0, 8) got condition
21:11:53 DISPATCHER: Trying to submit another job.
21:11:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:11:53 HBMASTER: Trying to run another job!
21:11:53 job_callback for (1, 0, 8) finished
21:11:53 ITERATION: Advancing config (1, 0, 1) to next budget 400.000000
21:11:53 ITERATION: Advancing config (1, 0, 6) to next budget 400.000000
21:11:53 ITERATION: Advancing config (1, 0, 8) to next budget 400.000000
21:11:53 HBMASTER: schedule new run for iteration 1
21:11:53 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
21:11:53 HBMASTER: submitting job (1, 0, 1) to dispatcher
21:11:53 DISPATCHER: trying to submit job (1, 0, 1)
21:11:53 DISPATCHER: trying to notify the job_runner thread.
21:11:53 HBMASTER: job (1, 0, 1) submitted to dispatcher
21:11:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:11:53 DISPATCHER: Trying to submit another job.
21:11:53 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
21:11:53 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
21:11:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:11:53 WORKER: start processing job (1, 0, 1)
21:11:53 WORKER: args: ()
21:11:53 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 298, 'last_n_outputs': 41, 'leak_rate': 0.9203190253236122, 'lr': 0.0010278652083140956, 'optimizer': 'SGD', 'sparsity': 0.8924855268276943, 'steps_to_train': 39, 'weight_decay': 0.013947862917419488}, 'budget': 400.0, 'working_directory': '.'}
21:12:35 DISPATCHER: Starting worker discovery
21:12:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:12:35 DISPATCHER: Finished worker discovery
21:13:35 DISPATCHER: Starting worker discovery
21:13:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:13:35 DISPATCHER: Finished worker discovery
21:14:35 DISPATCHER: Starting worker discovery
21:14:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:14:35 DISPATCHER: Finished worker discovery
21:15:35 DISPATCHER: Starting worker discovery
21:15:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:15:35 DISPATCHER: Finished worker discovery
21:16:35 DISPATCHER: Starting worker discovery
21:16:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:16:35 DISPATCHER: Finished worker discovery
21:17:35 DISPATCHER: Starting worker discovery
21:17:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:17:35 DISPATCHER: Finished worker discovery
21:18:35 DISPATCHER: Starting worker discovery
21:18:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:18:35 DISPATCHER: Finished worker discovery
21:19:35 DISPATCHER: Starting worker discovery
21:19:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:19:35 DISPATCHER: Finished worker discovery
21:19:37 WORKER: done with job (1, 0, 1), trying to register it.
21:19:37 WORKER: registered result for job (1, 0, 1) with dispatcher
21:19:37 DISPATCHER: job (1, 0, 1) finished
21:19:37 DISPATCHER: register_result: lock acquired
21:19:37 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
21:19:37 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 298, 'last_n_outputs': 41, 'leak_rate': 0.9203190253236122, 'lr': 0.0010278652083140956, 'optimizer': 'SGD', 'sparsity': 0.8924855268276943, 'steps_to_train': 39, 'weight_decay': 0.013947862917419488}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.19268176511034668, 'info': {'sick_no_sick': 0.19268176511034668, 'config': "{'batch_size': 128, 'hidden_dim': 298, 'last_n_outputs': 41, 'leak_rate': 0.9203190253236122, 'lr': 0.0010278652083140956, 'optimizer': 'SGD', 'sparsity': 0.8924855268276943, 'steps_to_train': 39, 'weight_decay': 0.013947862917419488}"}}
exception: None

21:19:37 job_callback for (1, 0, 1) started
21:19:37 DISPATCHER: Trying to submit another job.
21:19:37 job_callback for (1, 0, 1) got condition
21:19:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:19:37 Only 4 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
21:19:37 HBMASTER: Trying to run another job!
21:19:37 job_callback for (1, 0, 1) finished
21:19:37 HBMASTER: schedule new run for iteration 1
21:19:37 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
21:19:37 HBMASTER: submitting job (1, 0, 6) to dispatcher
21:19:37 DISPATCHER: trying to submit job (1, 0, 6)
21:19:37 DISPATCHER: trying to notify the job_runner thread.
21:19:37 HBMASTER: job (1, 0, 6) submitted to dispatcher
21:19:37 DISPATCHER: Trying to submit another job.
21:19:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:19:37 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776
21:19:37 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
21:19:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:19:37 WORKER: start processing job (1, 0, 6)
21:19:37 WORKER: args: ()
21:19:37 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 554, 'last_n_outputs': 41, 'leak_rate': 0.928127833525308, 'lr': 0.0013033122947896261, 'optimizer': 'Adam', 'sparsity': 0.9223432775291903, 'steps_to_train': 50, 'weight_decay': 0.015091668707572573}, 'budget': 400.0, 'working_directory': '.'}
21:20:35 DISPATCHER: Starting worker discovery
21:20:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:20:35 DISPATCHER: Finished worker discovery
21:21:35 DISPATCHER: Starting worker discovery
21:21:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:21:35 DISPATCHER: Finished worker discovery
21:22:35 DISPATCHER: Starting worker discovery
21:22:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:22:35 DISPATCHER: Finished worker discovery
21:23:35 DISPATCHER: Starting worker discovery
21:23:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:23:35 DISPATCHER: Finished worker discovery
21:24:35 DISPATCHER: Starting worker discovery
21:24:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:24:35 DISPATCHER: Finished worker discovery
21:25:35 DISPATCHER: Starting worker discovery
21:25:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:25:35 DISPATCHER: Finished worker discovery
21:26:35 DISPATCHER: Starting worker discovery
21:26:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:26:35 DISPATCHER: Finished worker discovery
21:27:22 WORKER: done with job (1, 0, 6), trying to register it.
21:27:22 WORKER: registered result for job (1, 0, 6) with dispatcher
21:27:22 DISPATCHER: job (1, 0, 6) finished
21:27:22 DISPATCHER: register_result: lock acquired
21:27:22 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
21:27:22 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 554, 'last_n_outputs': 41, 'leak_rate': 0.928127833525308, 'lr': 0.0013033122947896261, 'optimizer': 'Adam', 'sparsity': 0.9223432775291903, 'steps_to_train': 50, 'weight_decay': 0.015091668707572573}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.18941802013870984, 'info': {'sick_no_sick': 0.18941802013870984, 'config': "{'batch_size': 64, 'hidden_dim': 554, 'last_n_outputs': 41, 'leak_rate': 0.928127833525308, 'lr': 0.0013033122947896261, 'optimizer': 'Adam', 'sparsity': 0.9223432775291903, 'steps_to_train': 50, 'weight_decay': 0.015091668707572573}"}}
exception: None

21:27:22 job_callback for (1, 0, 6) started
21:27:22 job_callback for (1, 0, 6) got condition
21:27:22 DISPATCHER: Trying to submit another job.
21:27:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:27:22 Only 5 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
21:27:22 HBMASTER: Trying to run another job!
21:27:22 job_callback for (1, 0, 6) finished
21:27:22 HBMASTER: schedule new run for iteration 1
21:27:22 HBMASTER: trying submitting job (1, 0, 8) to dispatcher
21:27:22 HBMASTER: submitting job (1, 0, 8) to dispatcher
21:27:22 DISPATCHER: trying to submit job (1, 0, 8)
21:27:22 DISPATCHER: trying to notify the job_runner thread.
21:27:22 HBMASTER: job (1, 0, 8) submitted to dispatcher
21:27:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:27:22 DISPATCHER: Trying to submit another job.
21:27:22 DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776
21:27:22 DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
21:27:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:27:22 WORKER: start processing job (1, 0, 8)
21:27:22 WORKER: args: ()
21:27:22 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 234, 'last_n_outputs': 45, 'leak_rate': 0.9987248825233359, 'lr': 0.004027967160026739, 'optimizer': 'SGD', 'sparsity': 0.8912742422200797, 'steps_to_train': 99, 'weight_decay': 0.02101825536968915}, 'budget': 400.0, 'working_directory': '.'}
21:27:35 DISPATCHER: Starting worker discovery
21:27:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:27:35 DISPATCHER: Finished worker discovery
21:28:35 DISPATCHER: Starting worker discovery
21:28:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:28:35 DISPATCHER: Finished worker discovery
21:29:35 DISPATCHER: Starting worker discovery
21:29:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:29:35 DISPATCHER: Finished worker discovery
21:30:35 DISPATCHER: Starting worker discovery
21:30:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:30:35 DISPATCHER: Finished worker discovery
21:31:35 DISPATCHER: Starting worker discovery
21:31:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:31:35 DISPATCHER: Finished worker discovery
21:32:35 DISPATCHER: Starting worker discovery
21:32:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:32:35 DISPATCHER: Finished worker discovery
21:33:35 DISPATCHER: Starting worker discovery
21:33:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:33:35 DISPATCHER: Finished worker discovery
21:34:35 DISPATCHER: Starting worker discovery
21:34:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:34:35 DISPATCHER: Finished worker discovery
21:35:08 WORKER: done with job (1, 0, 8), trying to register it.
21:35:08 WORKER: registered result for job (1, 0, 8) with dispatcher
21:35:08 DISPATCHER: job (1, 0, 8) finished
21:35:08 DISPATCHER: register_result: lock acquired
21:35:08 DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
21:35:08 job_id: (1, 0, 8)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 234, 'last_n_outputs': 45, 'leak_rate': 0.9987248825233359, 'lr': 0.004027967160026739, 'optimizer': 'SGD', 'sparsity': 0.8912742422200797, 'steps_to_train': 99, 'weight_decay': 0.02101825536968915}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.06222837909709669, 'info': {'sick_no_sick': 0.06222837909709669, 'config': "{'batch_size': 32, 'hidden_dim': 234, 'last_n_outputs': 45, 'leak_rate': 0.9987248825233359, 'lr': 0.004027967160026739, 'optimizer': 'SGD', 'sparsity': 0.8912742422200797, 'steps_to_train': 99, 'weight_decay': 0.02101825536968915}"}}
exception: None

21:35:08 job_callback for (1, 0, 8) started
21:35:08 DISPATCHER: Trying to submit another job.
21:35:08 job_callback for (1, 0, 8) got condition
21:35:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:35:08 Only 6 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
21:35:08 HBMASTER: Trying to run another job!
21:35:08 job_callback for (1, 0, 8) finished
21:35:08 ITERATION: Advancing config (1, 0, 1) to next budget 1200.000000
21:35:08 HBMASTER: schedule new run for iteration 1
21:35:08 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
21:35:08 HBMASTER: submitting job (1, 0, 1) to dispatcher
21:35:08 DISPATCHER: trying to submit job (1, 0, 1)
21:35:08 DISPATCHER: trying to notify the job_runner thread.
21:35:08 HBMASTER: job (1, 0, 1) submitted to dispatcher
21:35:08 DISPATCHER: Trying to submit another job.
21:35:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:35:08 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
21:35:08 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
21:35:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:35:08 WORKER: start processing job (1, 0, 1)
21:35:08 WORKER: args: ()
21:35:08 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 298, 'last_n_outputs': 41, 'leak_rate': 0.9203190253236122, 'lr': 0.0010278652083140956, 'optimizer': 'SGD', 'sparsity': 0.8924855268276943, 'steps_to_train': 39, 'weight_decay': 0.013947862917419488}, 'budget': 1200.0, 'working_directory': '.'}
21:35:35 DISPATCHER: Starting worker discovery
21:35:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:35:35 DISPATCHER: Finished worker discovery
21:36:35 DISPATCHER: Starting worker discovery
21:36:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:36:35 DISPATCHER: Finished worker discovery
21:37:35 DISPATCHER: Starting worker discovery
21:37:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:37:35 DISPATCHER: Finished worker discovery
21:38:35 DISPATCHER: Starting worker discovery
21:38:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:38:35 DISPATCHER: Finished worker discovery
21:39:35 DISPATCHER: Starting worker discovery
21:39:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:39:35 DISPATCHER: Finished worker discovery
21:40:35 DISPATCHER: Starting worker discovery
21:40:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:40:35 DISPATCHER: Finished worker discovery
21:41:35 DISPATCHER: Starting worker discovery
21:41:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:41:35 DISPATCHER: Finished worker discovery
21:42:35 DISPATCHER: Starting worker discovery
21:42:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:42:35 DISPATCHER: Finished worker discovery
21:43:35 DISPATCHER: Starting worker discovery
21:43:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:43:35 DISPATCHER: Finished worker discovery
21:44:35 DISPATCHER: Starting worker discovery
21:44:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:44:35 DISPATCHER: Finished worker discovery
21:45:35 DISPATCHER: Starting worker discovery
21:45:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:45:35 DISPATCHER: Finished worker discovery
21:46:35 DISPATCHER: Starting worker discovery
21:46:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:46:35 DISPATCHER: Finished worker discovery
21:47:35 DISPATCHER: Starting worker discovery
21:47:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:47:35 DISPATCHER: Finished worker discovery
21:48:35 DISPATCHER: Starting worker discovery
21:48:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:48:35 DISPATCHER: Finished worker discovery
21:49:35 DISPATCHER: Starting worker discovery
21:49:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:49:35 DISPATCHER: Finished worker discovery
21:50:35 DISPATCHER: Starting worker discovery
21:50:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:50:35 DISPATCHER: Finished worker discovery
21:51:35 DISPATCHER: Starting worker discovery
21:51:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:51:35 DISPATCHER: Finished worker discovery
21:52:35 DISPATCHER: Starting worker discovery
21:52:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:52:35 DISPATCHER: Finished worker discovery
21:53:35 DISPATCHER: Starting worker discovery
21:53:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:53:35 DISPATCHER: Finished worker discovery
21:54:35 DISPATCHER: Starting worker discovery
21:54:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:54:35 DISPATCHER: Finished worker discovery
21:55:35 DISPATCHER: Starting worker discovery
21:55:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:55:35 DISPATCHER: Finished worker discovery
21:56:16 WORKER: done with job (1, 0, 1), trying to register it.
21:56:16 WORKER: registered result for job (1, 0, 1) with dispatcher
21:56:16 DISPATCHER: job (1, 0, 1) finished
21:56:16 DISPATCHER: register_result: lock acquired
21:56:16 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
21:56:16 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 298, 'last_n_outputs': 41, 'leak_rate': 0.9203190253236122, 'lr': 0.0010278652083140956, 'optimizer': 'SGD', 'sparsity': 0.8924855268276943, 'steps_to_train': 39, 'weight_decay': 0.013947862917419488}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.16124326152904445, 'info': {'sick_no_sick': 0.16124326152904445, 'config': "{'batch_size': 128, 'hidden_dim': 298, 'last_n_outputs': 41, 'leak_rate': 0.9203190253236122, 'lr': 0.0010278652083140956, 'optimizer': 'SGD', 'sparsity': 0.8924855268276943, 'steps_to_train': 39, 'weight_decay': 0.013947862917419488}"}}
exception: None

21:56:16 job_callback for (1, 0, 1) started
21:56:16 job_callback for (1, 0, 1) got condition
21:56:16 DISPATCHER: Trying to submit another job.
21:56:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:56:16 Only 2 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
21:56:16 HBMASTER: Trying to run another job!
21:56:16 job_callback for (1, 0, 1) finished
21:56:16 start sampling a new configuration.
21:56:16 done sampling a new configuration.
21:56:16 HBMASTER: schedule new run for iteration 2
21:56:16 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
21:56:16 HBMASTER: submitting job (2, 0, 0) to dispatcher
21:56:16 DISPATCHER: trying to submit job (2, 0, 0)
21:56:16 DISPATCHER: trying to notify the job_runner thread.
21:56:16 HBMASTER: job (2, 0, 0) submitted to dispatcher
21:56:16 DISPATCHER: Trying to submit another job.
21:56:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:56:16 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
21:56:16 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
21:56:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:56:16 WORKER: start processing job (2, 0, 0)
21:56:16 WORKER: args: ()
21:56:16 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 527, 'last_n_outputs': 49, 'leak_rate': 0.9018250055559249, 'lr': 0.010328031365598234, 'optimizer': 'Adam', 'sparsity': 0.7841172408113452, 'steps_to_train': 35, 'weight_decay': 0.08903775761812599}, 'budget': 400.0, 'working_directory': '.'}
21:56:35 DISPATCHER: Starting worker discovery
21:56:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:56:35 DISPATCHER: Finished worker discovery
21:57:35 DISPATCHER: Starting worker discovery
21:57:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:57:35 DISPATCHER: Finished worker discovery
21:58:35 DISPATCHER: Starting worker discovery
21:58:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:58:35 DISPATCHER: Finished worker discovery
21:59:35 DISPATCHER: Starting worker discovery
21:59:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:59:35 DISPATCHER: Finished worker discovery
22:00:35 DISPATCHER: Starting worker discovery
22:00:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:00:35 DISPATCHER: Finished worker discovery
22:01:35 DISPATCHER: Starting worker discovery
22:01:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:01:35 DISPATCHER: Finished worker discovery
22:02:35 DISPATCHER: Starting worker discovery
22:02:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:02:35 DISPATCHER: Finished worker discovery
22:03:35 DISPATCHER: Starting worker discovery
22:03:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:03:35 DISPATCHER: Finished worker discovery
22:04:01 WORKER: done with job (2, 0, 0), trying to register it.
22:04:01 WORKER: registered result for job (2, 0, 0) with dispatcher
22:04:01 DISPATCHER: job (2, 0, 0) finished
22:04:01 DISPATCHER: register_result: lock acquired
22:04:01 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
22:04:01 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 527, 'last_n_outputs': 49, 'leak_rate': 0.9018250055559249, 'lr': 0.010328031365598234, 'optimizer': 'Adam', 'sparsity': 0.7841172408113452, 'steps_to_train': 35, 'weight_decay': 0.08903775761812599}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.16171110817543016, 'info': {'sick_no_sick': 0.16171110817543016, 'config': "{'batch_size': 128, 'hidden_dim': 527, 'last_n_outputs': 49, 'leak_rate': 0.9018250055559249, 'lr': 0.010328031365598234, 'optimizer': 'Adam', 'sparsity': 0.7841172408113452, 'steps_to_train': 35, 'weight_decay': 0.08903775761812599}"}}
exception: None

22:04:01 job_callback for (2, 0, 0) started
22:04:01 DISPATCHER: Trying to submit another job.
22:04:01 job_callback for (2, 0, 0) got condition
22:04:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:04:01 Only 7 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
22:04:01 HBMASTER: Trying to run another job!
22:04:01 job_callback for (2, 0, 0) finished
22:04:01 start sampling a new configuration.
22:04:01 best_vector: [2, 0.8585351155243531, 0.6674185088539546, 0.6124956936068503, 0.027505915307383222, 1, 0.9350648776254222, 0.8154315239198999, 0.6091324004584198], 0.0025538010284942288, 0.3289007382798558, 0.0008399470436916068
22:04:01 done sampling a new configuration.
22:04:01 HBMASTER: schedule new run for iteration 2
22:04:01 HBMASTER: trying submitting job (2, 0, 1) to dispatcher
22:04:01 HBMASTER: submitting job (2, 0, 1) to dispatcher
22:04:01 DISPATCHER: trying to submit job (2, 0, 1)
22:04:01 DISPATCHER: trying to notify the job_runner thread.
22:04:01 HBMASTER: job (2, 0, 1) submitted to dispatcher
22:04:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:04:01 DISPATCHER: Trying to submit another job.
22:04:01 DISPATCHER: starting job (2, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
22:04:01 DISPATCHER: job (2, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
22:04:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:04:01 WORKER: start processing job (2, 0, 1)
22:04:01 WORKER: args: ()
22:04:01 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 887, 'last_n_outputs': 37, 'leak_rate': 0.9031239234017125, 'lr': 0.0011350417349199034, 'optimizer': 'SGD', 'sparsity': 0.9744155706301013, 'steps_to_train': 84, 'weight_decay': 0.06201539644129906}, 'budget': 400.0, 'working_directory': '.'}
22:04:35 DISPATCHER: Starting worker discovery
22:04:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:04:35 DISPATCHER: Finished worker discovery
22:05:35 DISPATCHER: Starting worker discovery
22:05:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:05:35 DISPATCHER: Finished worker discovery
22:06:35 DISPATCHER: Starting worker discovery
22:06:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:06:36 DISPATCHER: Finished worker discovery
22:07:36 DISPATCHER: Starting worker discovery
22:07:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:07:36 DISPATCHER: Finished worker discovery
22:08:36 DISPATCHER: Starting worker discovery
22:08:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:08:36 DISPATCHER: Finished worker discovery
22:09:36 DISPATCHER: Starting worker discovery
22:09:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:09:36 DISPATCHER: Finished worker discovery
22:10:36 DISPATCHER: Starting worker discovery
22:10:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:10:36 DISPATCHER: Finished worker discovery
22:11:36 DISPATCHER: Starting worker discovery
22:11:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:11:36 DISPATCHER: Finished worker discovery
22:11:46 WORKER: done with job (2, 0, 1), trying to register it.
22:11:46 WORKER: registered result for job (2, 0, 1) with dispatcher
22:11:46 DISPATCHER: job (2, 0, 1) finished
22:11:46 DISPATCHER: register_result: lock acquired
22:11:46 DISPATCHER: job (2, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
22:11:46 job_id: (2, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 887, 'last_n_outputs': 37, 'leak_rate': 0.9031239234017125, 'lr': 0.0011350417349199034, 'optimizer': 'SGD', 'sparsity': 0.9744155706301013, 'steps_to_train': 84, 'weight_decay': 0.06201539644129906}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.20893487453332207, 'info': {'sick_no_sick': 0.20893487453332207, 'config': "{'batch_size': 64, 'hidden_dim': 887, 'last_n_outputs': 37, 'leak_rate': 0.9031239234017125, 'lr': 0.0011350417349199034, 'optimizer': 'SGD', 'sparsity': 0.9744155706301013, 'steps_to_train': 84, 'weight_decay': 0.06201539644129906}"}}
exception: None

22:11:46 job_callback for (2, 0, 1) started
22:11:46 job_callback for (2, 0, 1) got condition
22:11:46 DISPATCHER: Trying to submit another job.
22:11:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:11:46 Only 8 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
22:11:46 HBMASTER: Trying to run another job!
22:11:46 job_callback for (2, 0, 1) finished
22:11:46 start sampling a new configuration.
22:11:46 best_vector: [1, 0.9454055883323953, 0.06264661854073417, 0.2802658362598336, 0.06835607069772251, 1, 0.07358156918072256, 0.44599763407380955, 0.14294528094207548], 0.019324645951640667, 0.02141989063135552, 0.0004139318027738103
22:11:46 done sampling a new configuration.
22:11:46 HBMASTER: schedule new run for iteration 2
22:11:46 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
22:11:46 HBMASTER: submitting job (2, 0, 2) to dispatcher
22:11:46 DISPATCHER: trying to submit job (2, 0, 2)
22:11:46 DISPATCHER: trying to notify the job_runner thread.
22:11:46 HBMASTER: job (2, 0, 2) submitted to dispatcher
22:11:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:11:46 DISPATCHER: Trying to submit another job.
22:11:46 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
22:11:46 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
22:11:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:11:46 WORKER: start processing job (2, 0, 2)
22:11:46 WORKER: args: ()
22:11:46 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 957, 'last_n_outputs': 12, 'leak_rate': 0.8200664590649585, 'lr': 0.0013699734208445574, 'optimizer': 'SGD', 'sparsity': 0.7676595766033734, 'steps_to_train': 50, 'weight_decay': 0.015345325262094145}, 'budget': 400.0, 'working_directory': '.'}
22:12:36 DISPATCHER: Starting worker discovery
22:12:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:12:36 DISPATCHER: Finished worker discovery
22:13:36 DISPATCHER: Starting worker discovery
22:13:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:13:36 DISPATCHER: Finished worker discovery
22:14:36 DISPATCHER: Starting worker discovery
22:14:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:14:36 DISPATCHER: Finished worker discovery
22:15:36 DISPATCHER: Starting worker discovery
22:15:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:15:36 DISPATCHER: Finished worker discovery
22:16:36 DISPATCHER: Starting worker discovery
22:16:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:16:36 DISPATCHER: Finished worker discovery
22:17:36 DISPATCHER: Starting worker discovery
22:17:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:17:36 DISPATCHER: Finished worker discovery
22:18:36 DISPATCHER: Starting worker discovery
22:18:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:18:36 DISPATCHER: Finished worker discovery
22:19:32 WORKER: done with job (2, 0, 2), trying to register it.
22:19:32 WORKER: registered result for job (2, 0, 2) with dispatcher
22:19:32 DISPATCHER: job (2, 0, 2) finished
22:19:32 DISPATCHER: register_result: lock acquired
22:19:32 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
22:19:32 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 957, 'last_n_outputs': 12, 'leak_rate': 0.8200664590649585, 'lr': 0.0013699734208445574, 'optimizer': 'SGD', 'sparsity': 0.7676595766033734, 'steps_to_train': 50, 'weight_decay': 0.015345325262094145}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.19583424266443564, 'info': {'sick_no_sick': 0.19583424266443564, 'config': "{'batch_size': 32, 'hidden_dim': 957, 'last_n_outputs': 12, 'leak_rate': 0.8200664590649585, 'lr': 0.0013699734208445574, 'optimizer': 'SGD', 'sparsity': 0.7676595766033734, 'steps_to_train': 50, 'weight_decay': 0.015345325262094145}"}}
exception: None

22:19:32 job_callback for (2, 0, 2) started
22:19:32 DISPATCHER: Trying to submit another job.
22:19:32 job_callback for (2, 0, 2) got condition
22:19:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:19:32 Only 9 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
22:19:32 HBMASTER: Trying to run another job!
22:19:32 job_callback for (2, 0, 2) finished
22:19:32 start sampling a new configuration.
22:19:32 best_vector: [1, 0.9120059208237503, 0.9256982026360822, 0.8678414654241565, 0.6520994462171081, 0, 0.9312907453277277, 0.8446700531055762, 0.7628947890701533], 0.0034606483966364994, 0.0089690910586494, 3.103887059140181e-05
22:19:32 done sampling a new configuration.
22:19:32 HBMASTER: schedule new run for iteration 2
22:19:32 HBMASTER: trying submitting job (2, 0, 3) to dispatcher
22:19:32 HBMASTER: submitting job (2, 0, 3) to dispatcher
22:19:32 DISPATCHER: trying to submit job (2, 0, 3)
22:19:32 DISPATCHER: trying to notify the job_runner thread.
22:19:32 HBMASTER: job (2, 0, 3) submitted to dispatcher
22:19:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:19:32 DISPATCHER: Trying to submit another job.
22:19:32 DISPATCHER: starting job (2, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
22:19:32 DISPATCHER: job (2, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
22:19:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:19:32 WORKER: start processing job (2, 0, 3)
22:19:32 WORKER: args: ()
22:19:32 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 930, 'last_n_outputs': 47, 'leak_rate': 0.9669603663560391, 'lr': 0.02014646679825829, 'optimizer': 'Adam', 'sparsity': 0.9735097788786546, 'steps_to_train': 86, 'weight_decay': 0.09829897835223014}, 'budget': 400.0, 'working_directory': '.'}
22:19:36 DISPATCHER: Starting worker discovery
22:19:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:19:36 DISPATCHER: Finished worker discovery
22:20:36 DISPATCHER: Starting worker discovery
22:20:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:20:36 DISPATCHER: Finished worker discovery
22:21:36 DISPATCHER: Starting worker discovery
22:21:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:21:36 DISPATCHER: Finished worker discovery
22:22:36 DISPATCHER: Starting worker discovery
22:22:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:22:36 DISPATCHER: Finished worker discovery
22:23:36 DISPATCHER: Starting worker discovery
22:23:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:23:36 DISPATCHER: Finished worker discovery
22:24:36 DISPATCHER: Starting worker discovery
22:24:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:24:36 DISPATCHER: Finished worker discovery
22:25:36 DISPATCHER: Starting worker discovery
22:25:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:25:36 DISPATCHER: Finished worker discovery
22:26:36 DISPATCHER: Starting worker discovery
22:26:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:26:36 DISPATCHER: Finished worker discovery
22:27:17 WORKER: done with job (2, 0, 3), trying to register it.
22:27:17 WORKER: registered result for job (2, 0, 3) with dispatcher
22:27:17 DISPATCHER: job (2, 0, 3) finished
22:27:17 DISPATCHER: register_result: lock acquired
22:27:17 DISPATCHER: job (2, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
22:27:17 job_id: (2, 0, 3)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 930, 'last_n_outputs': 47, 'leak_rate': 0.9669603663560391, 'lr': 0.02014646679825829, 'optimizer': 'Adam', 'sparsity': 0.9735097788786546, 'steps_to_train': 86, 'weight_decay': 0.09829897835223014}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0331392010053342, 'info': {'sick_no_sick': 0.0331392010053342, 'config': "{'batch_size': 32, 'hidden_dim': 930, 'last_n_outputs': 47, 'leak_rate': 0.9669603663560391, 'lr': 0.02014646679825829, 'optimizer': 'Adam', 'sparsity': 0.9735097788786546, 'steps_to_train': 86, 'weight_decay': 0.09829897835223014}"}}
exception: None

22:27:17 job_callback for (2, 0, 3) started
22:27:17 job_callback for (2, 0, 3) got condition
22:27:17 DISPATCHER: Trying to submit another job.
22:27:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:27:17 HBMASTER: Trying to run another job!
22:27:17 job_callback for (2, 0, 3) finished
22:27:17 start sampling a new configuration.
22:27:17 done sampling a new configuration.
22:27:17 HBMASTER: schedule new run for iteration 2
22:27:17 HBMASTER: trying submitting job (2, 0, 4) to dispatcher
22:27:17 HBMASTER: submitting job (2, 0, 4) to dispatcher
22:27:17 DISPATCHER: trying to submit job (2, 0, 4)
22:27:17 DISPATCHER: trying to notify the job_runner thread.
22:27:17 HBMASTER: job (2, 0, 4) submitted to dispatcher
22:27:17 DISPATCHER: Trying to submit another job.
22:27:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:27:17 DISPATCHER: starting job (2, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776
22:27:17 DISPATCHER: job (2, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
22:27:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:27:17 WORKER: start processing job (2, 0, 4)
22:27:17 WORKER: args: ()
22:27:17 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 713, 'last_n_outputs': 41, 'leak_rate': 0.7725102028292026, 'lr': 0.09502735300873673, 'optimizer': 'Adam', 'sparsity': 0.7553210429071766, 'steps_to_train': 35, 'weight_decay': 0.037315329173592794}, 'budget': 400.0, 'working_directory': '.'}
22:27:36 DISPATCHER: Starting worker discovery
22:27:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:27:36 DISPATCHER: Finished worker discovery
22:28:36 DISPATCHER: Starting worker discovery
22:28:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:28:36 DISPATCHER: Finished worker discovery
22:29:36 DISPATCHER: Starting worker discovery
22:29:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:29:36 DISPATCHER: Finished worker discovery
22:30:36 DISPATCHER: Starting worker discovery
22:30:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:30:36 DISPATCHER: Finished worker discovery
22:31:36 DISPATCHER: Starting worker discovery
22:31:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:31:36 DISPATCHER: Finished worker discovery
22:32:36 DISPATCHER: Starting worker discovery
22:32:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:32:36 DISPATCHER: Finished worker discovery
22:33:36 DISPATCHER: Starting worker discovery
22:33:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:33:36 DISPATCHER: Finished worker discovery
22:34:36 DISPATCHER: Starting worker discovery
22:34:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:34:36 DISPATCHER: Finished worker discovery
22:35:05 WORKER: done with job (2, 0, 4), trying to register it.
22:35:05 WORKER: registered result for job (2, 0, 4) with dispatcher
22:35:05 DISPATCHER: job (2, 0, 4) finished
22:35:05 DISPATCHER: register_result: lock acquired
22:35:05 DISPATCHER: job (2, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
22:35:05 job_id: (2, 0, 4)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 713, 'last_n_outputs': 41, 'leak_rate': 0.7725102028292026, 'lr': 0.09502735300873673, 'optimizer': 'Adam', 'sparsity': 0.7553210429071766, 'steps_to_train': 35, 'weight_decay': 0.037315329173592794}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.08076550314009048, 'info': {'sick_no_sick': 0.08076550314009048, 'config': "{'batch_size': 16, 'hidden_dim': 713, 'last_n_outputs': 41, 'leak_rate': 0.7725102028292026, 'lr': 0.09502735300873673, 'optimizer': 'Adam', 'sparsity': 0.7553210429071766, 'steps_to_train': 35, 'weight_decay': 0.037315329173592794}"}}
exception: None

22:35:05 job_callback for (2, 0, 4) started
22:35:05 DISPATCHER: Trying to submit another job.
22:35:05 job_callback for (2, 0, 4) got condition
22:35:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:35:05 HBMASTER: Trying to run another job!
22:35:05 job_callback for (2, 0, 4) finished
22:35:05 start sampling a new configuration.
22:35:05 best_vector: [2, 0.41455638019371865, 0.7903638900358332, 0.8380431079311927, 0.16483126109381435, 0, 0.909583846536665, 0.633303193902931, 0.4244303281695447], 0.0049291141130140565, 0.07802209780072401, 0.0003845798233965117
22:35:05 done sampling a new configuration.
22:35:05 HBMASTER: schedule new run for iteration 2
22:35:05 HBMASTER: trying submitting job (2, 0, 5) to dispatcher
22:35:05 HBMASTER: submitting job (2, 0, 5) to dispatcher
22:35:05 DISPATCHER: trying to submit job (2, 0, 5)
22:35:05 DISPATCHER: trying to notify the job_runner thread.
22:35:05 HBMASTER: job (2, 0, 5) submitted to dispatcher
22:35:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:35:05 DISPATCHER: Trying to submit another job.
22:35:05 DISPATCHER: starting job (2, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776
22:35:05 DISPATCHER: job (2, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
22:35:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:35:05 WORKER: start processing job (2, 0, 5)
22:35:05 WORKER: args: ()
22:35:05 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 532, 'last_n_outputs': 42, 'leak_rate': 0.9595107769827982, 'lr': 0.0021363013856772655, 'optimizer': 'Adam', 'sparsity': 0.9683001231687995, 'steps_to_train': 67, 'weight_decay': 0.035661252134861966}, 'budget': 400.0, 'working_directory': '.'}
22:35:36 DISPATCHER: Starting worker discovery
22:35:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:35:36 DISPATCHER: Finished worker discovery
22:36:36 DISPATCHER: Starting worker discovery
22:36:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:36:36 DISPATCHER: Finished worker discovery
22:37:36 DISPATCHER: Starting worker discovery
22:37:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:37:36 DISPATCHER: Finished worker discovery
22:38:36 DISPATCHER: Starting worker discovery
22:38:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:38:36 DISPATCHER: Finished worker discovery
22:39:36 DISPATCHER: Starting worker discovery
22:39:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:39:36 DISPATCHER: Finished worker discovery
22:40:36 DISPATCHER: Starting worker discovery
22:40:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:40:36 DISPATCHER: Finished worker discovery
22:41:36 DISPATCHER: Starting worker discovery
22:41:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:41:36 DISPATCHER: Finished worker discovery
22:42:36 DISPATCHER: Starting worker discovery
22:42:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:42:36 DISPATCHER: Finished worker discovery
22:42:51 WORKER: done with job (2, 0, 5), trying to register it.
22:42:51 WORKER: registered result for job (2, 0, 5) with dispatcher
22:42:51 DISPATCHER: job (2, 0, 5) finished
22:42:51 DISPATCHER: register_result: lock acquired
22:42:51 DISPATCHER: job (2, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
22:42:51 job_id: (2, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 532, 'last_n_outputs': 42, 'leak_rate': 0.9595107769827982, 'lr': 0.0021363013856772655, 'optimizer': 'Adam', 'sparsity': 0.9683001231687995, 'steps_to_train': 67, 'weight_decay': 0.035661252134861966}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.10889389112909606, 'info': {'sick_no_sick': 0.10889389112909606, 'config': "{'batch_size': 64, 'hidden_dim': 532, 'last_n_outputs': 42, 'leak_rate': 0.9595107769827982, 'lr': 0.0021363013856772655, 'optimizer': 'Adam', 'sparsity': 0.9683001231687995, 'steps_to_train': 67, 'weight_decay': 0.035661252134861966}"}}
exception: None

22:42:51 job_callback for (2, 0, 5) started
22:42:51 job_callback for (2, 0, 5) got condition
22:42:51 DISPATCHER: Trying to submit another job.
22:42:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:42:51 HBMASTER: Trying to run another job!
22:42:51 job_callback for (2, 0, 5) finished
22:42:51 ITERATION: Advancing config (2, 0, 1) to next budget 1200.000000
22:42:51 ITERATION: Advancing config (2, 0, 2) to next budget 1200.000000
22:42:51 HBMASTER: schedule new run for iteration 2
22:42:51 HBMASTER: trying submitting job (2, 0, 1) to dispatcher
22:42:51 HBMASTER: submitting job (2, 0, 1) to dispatcher
22:42:51 DISPATCHER: trying to submit job (2, 0, 1)
22:42:51 DISPATCHER: trying to notify the job_runner thread.
22:42:51 HBMASTER: job (2, 0, 1) submitted to dispatcher
22:42:51 DISPATCHER: Trying to submit another job.
22:42:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:42:51 DISPATCHER: starting job (2, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
22:42:51 DISPATCHER: job (2, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
22:42:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:42:51 WORKER: start processing job (2, 0, 1)
22:42:51 WORKER: args: ()
22:42:51 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 887, 'last_n_outputs': 37, 'leak_rate': 0.9031239234017125, 'lr': 0.0011350417349199034, 'optimizer': 'SGD', 'sparsity': 0.9744155706301013, 'steps_to_train': 84, 'weight_decay': 0.06201539644129906}, 'budget': 1200.0, 'working_directory': '.'}
22:43:36 DISPATCHER: Starting worker discovery
22:43:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:43:36 DISPATCHER: Finished worker discovery
22:44:36 DISPATCHER: Starting worker discovery
22:44:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:44:36 DISPATCHER: Finished worker discovery
22:45:36 DISPATCHER: Starting worker discovery
22:45:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:45:36 DISPATCHER: Finished worker discovery
22:46:36 DISPATCHER: Starting worker discovery
22:46:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:46:36 DISPATCHER: Finished worker discovery
22:47:36 DISPATCHER: Starting worker discovery
22:47:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:47:36 DISPATCHER: Finished worker discovery
22:48:36 DISPATCHER: Starting worker discovery
22:48:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:48:36 DISPATCHER: Finished worker discovery
22:49:36 DISPATCHER: Starting worker discovery
22:49:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:49:36 DISPATCHER: Finished worker discovery
22:50:36 DISPATCHER: Starting worker discovery
22:50:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:50:36 DISPATCHER: Finished worker discovery
22:51:36 DISPATCHER: Starting worker discovery
22:51:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:51:36 DISPATCHER: Finished worker discovery
22:52:36 DISPATCHER: Starting worker discovery
22:52:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:52:36 DISPATCHER: Finished worker discovery
22:53:36 DISPATCHER: Starting worker discovery
22:53:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:53:36 DISPATCHER: Finished worker discovery
22:54:36 DISPATCHER: Starting worker discovery
22:54:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:54:36 DISPATCHER: Finished worker discovery
22:55:36 DISPATCHER: Starting worker discovery
22:55:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:55:36 DISPATCHER: Finished worker discovery
22:56:36 DISPATCHER: Starting worker discovery
22:56:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:56:36 DISPATCHER: Finished worker discovery
22:57:36 DISPATCHER: Starting worker discovery
22:57:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:57:36 DISPATCHER: Finished worker discovery
22:58:36 DISPATCHER: Starting worker discovery
22:58:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:58:36 DISPATCHER: Finished worker discovery
22:59:36 DISPATCHER: Starting worker discovery
22:59:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:59:36 DISPATCHER: Finished worker discovery
23:00:36 DISPATCHER: Starting worker discovery
23:00:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:00:36 DISPATCHER: Finished worker discovery
23:01:36 DISPATCHER: Starting worker discovery
23:01:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:01:36 DISPATCHER: Finished worker discovery
23:02:36 DISPATCHER: Starting worker discovery
23:02:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:02:36 DISPATCHER: Finished worker discovery
23:03:36 DISPATCHER: Starting worker discovery
23:03:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:03:36 DISPATCHER: Finished worker discovery
23:03:58 WORKER: done with job (2, 0, 1), trying to register it.
23:03:58 WORKER: registered result for job (2, 0, 1) with dispatcher
23:03:58 DISPATCHER: job (2, 0, 1) finished
23:03:58 DISPATCHER: register_result: lock acquired
23:03:58 DISPATCHER: job (2, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
23:03:58 job_id: (2, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 887, 'last_n_outputs': 37, 'leak_rate': 0.9031239234017125, 'lr': 0.0011350417349199034, 'optimizer': 'SGD', 'sparsity': 0.9744155706301013, 'steps_to_train': 84, 'weight_decay': 0.06201539644129906}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.15776208048137835, 'info': {'sick_no_sick': 0.15776208048137835, 'config': "{'batch_size': 64, 'hidden_dim': 887, 'last_n_outputs': 37, 'leak_rate': 0.9031239234017125, 'lr': 0.0011350417349199034, 'optimizer': 'SGD', 'sparsity': 0.9744155706301013, 'steps_to_train': 84, 'weight_decay': 0.06201539644129906}"}}
exception: None

23:03:58 job_callback for (2, 0, 1) started
23:03:58 job_callback for (2, 0, 1) got condition
23:03:58 DISPATCHER: Trying to submit another job.
23:03:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:03:58 Only 3 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
23:03:58 HBMASTER: Trying to run another job!
23:03:58 job_callback for (2, 0, 1) finished
23:03:58 HBMASTER: schedule new run for iteration 2
23:03:58 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
23:03:58 HBMASTER: submitting job (2, 0, 2) to dispatcher
23:03:58 DISPATCHER: trying to submit job (2, 0, 2)
23:03:58 DISPATCHER: trying to notify the job_runner thread.
23:03:58 HBMASTER: job (2, 0, 2) submitted to dispatcher
23:03:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:03:58 DISPATCHER: Trying to submit another job.
23:03:58 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:03:58 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:03:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:03:58 WORKER: start processing job (2, 0, 2)
23:03:58 WORKER: args: ()
23:03:58 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 957, 'last_n_outputs': 12, 'leak_rate': 0.8200664590649585, 'lr': 0.0013699734208445574, 'optimizer': 'SGD', 'sparsity': 0.7676595766033734, 'steps_to_train': 50, 'weight_decay': 0.015345325262094145}, 'budget': 1200.0, 'working_directory': '.'}
23:04:36 DISPATCHER: Starting worker discovery
23:04:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:04:36 DISPATCHER: Finished worker discovery
23:05:36 DISPATCHER: Starting worker discovery
23:05:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:05:36 DISPATCHER: Finished worker discovery
23:06:36 DISPATCHER: Starting worker discovery
23:06:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:06:36 DISPATCHER: Finished worker discovery
23:07:36 DISPATCHER: Starting worker discovery
23:07:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:07:36 DISPATCHER: Finished worker discovery
23:08:36 DISPATCHER: Starting worker discovery
23:08:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:08:36 DISPATCHER: Finished worker discovery
23:09:36 DISPATCHER: Starting worker discovery
23:09:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:09:36 DISPATCHER: Finished worker discovery
23:10:36 DISPATCHER: Starting worker discovery
23:10:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:10:36 DISPATCHER: Finished worker discovery
23:11:36 DISPATCHER: Starting worker discovery
23:11:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:11:36 DISPATCHER: Finished worker discovery
23:12:36 DISPATCHER: Starting worker discovery
23:12:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:12:36 DISPATCHER: Finished worker discovery
23:13:36 DISPATCHER: Starting worker discovery
23:13:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:13:36 DISPATCHER: Finished worker discovery
23:14:36 DISPATCHER: Starting worker discovery
23:14:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:14:36 DISPATCHER: Finished worker discovery
23:15:36 DISPATCHER: Starting worker discovery
23:15:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:15:36 DISPATCHER: Finished worker discovery
23:16:36 DISPATCHER: Starting worker discovery
23:16:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:16:36 DISPATCHER: Finished worker discovery
23:17:36 DISPATCHER: Starting worker discovery
23:17:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:17:36 DISPATCHER: Finished worker discovery
23:18:36 DISPATCHER: Starting worker discovery
23:18:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:18:36 DISPATCHER: Finished worker discovery
23:19:36 DISPATCHER: Starting worker discovery
23:19:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:19:36 DISPATCHER: Finished worker discovery
23:20:36 DISPATCHER: Starting worker discovery
23:20:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:20:36 DISPATCHER: Finished worker discovery
23:21:36 DISPATCHER: Starting worker discovery
23:21:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:21:36 DISPATCHER: Finished worker discovery
23:22:36 DISPATCHER: Starting worker discovery
23:22:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:22:36 DISPATCHER: Finished worker discovery
23:23:36 DISPATCHER: Starting worker discovery
23:23:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:23:36 DISPATCHER: Finished worker discovery
23:24:36 DISPATCHER: Starting worker discovery
23:24:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:24:36 DISPATCHER: Finished worker discovery
23:25:07 WORKER: done with job (2, 0, 2), trying to register it.
23:25:07 WORKER: registered result for job (2, 0, 2) with dispatcher
23:25:07 DISPATCHER: job (2, 0, 2) finished
23:25:07 DISPATCHER: register_result: lock acquired
23:25:07 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
23:25:07 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 957, 'last_n_outputs': 12, 'leak_rate': 0.8200664590649585, 'lr': 0.0013699734208445574, 'optimizer': 'SGD', 'sparsity': 0.7676595766033734, 'steps_to_train': 50, 'weight_decay': 0.015345325262094145}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.14844811164209284, 'info': {'sick_no_sick': 0.14844811164209284, 'config': "{'batch_size': 32, 'hidden_dim': 957, 'last_n_outputs': 12, 'leak_rate': 0.8200664590649585, 'lr': 0.0013699734208445574, 'optimizer': 'SGD', 'sparsity': 0.7676595766033734, 'steps_to_train': 50, 'weight_decay': 0.015345325262094145}"}}
exception: None

23:25:07 job_callback for (2, 0, 2) started
23:25:07 job_callback for (2, 0, 2) got condition
23:25:07 DISPATCHER: Trying to submit another job.
23:25:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:25:07 Only 4 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
23:25:07 HBMASTER: Trying to run another job!
23:25:07 job_callback for (2, 0, 2) finished
23:25:07 start sampling a new configuration.
23:25:07 done sampling a new configuration.
23:25:07 HBMASTER: schedule new run for iteration 3
23:25:07 HBMASTER: trying submitting job (3, 0, 0) to dispatcher
23:25:07 HBMASTER: submitting job (3, 0, 0) to dispatcher
23:25:07 DISPATCHER: trying to submit job (3, 0, 0)
23:25:07 DISPATCHER: trying to notify the job_runner thread.
23:25:07 HBMASTER: job (3, 0, 0) submitted to dispatcher
23:25:07 DISPATCHER: Trying to submit another job.
23:25:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:25:07 DISPATCHER: starting job (3, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:25:07 DISPATCHER: job (3, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:25:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:25:07 WORKER: start processing job (3, 0, 0)
23:25:07 WORKER: args: ()
23:25:07 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 498, 'last_n_outputs': 31, 'leak_rate': 0.8926201892521313, 'lr': 0.07697219929979665, 'optimizer': 'SGD', 'sparsity': 0.8196710826055565, 'steps_to_train': 72, 'weight_decay': 0.10346291487031697}, 'budget': 1200.0, 'working_directory': '.'}
23:25:36 DISPATCHER: Starting worker discovery
23:25:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:25:36 DISPATCHER: Finished worker discovery
23:26:36 DISPATCHER: Starting worker discovery
23:26:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:26:36 DISPATCHER: Finished worker discovery
23:27:36 DISPATCHER: Starting worker discovery
23:27:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:27:36 DISPATCHER: Finished worker discovery
23:28:36 DISPATCHER: Starting worker discovery
23:28:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:28:36 DISPATCHER: Finished worker discovery
23:29:36 DISPATCHER: Starting worker discovery
23:29:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:29:36 DISPATCHER: Finished worker discovery
23:30:36 DISPATCHER: Starting worker discovery
23:30:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:30:36 DISPATCHER: Finished worker discovery
23:31:36 DISPATCHER: Starting worker discovery
23:31:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:31:36 DISPATCHER: Finished worker discovery
23:32:36 DISPATCHER: Starting worker discovery
23:32:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:32:36 DISPATCHER: Finished worker discovery
23:33:36 DISPATCHER: Starting worker discovery
23:33:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:33:36 DISPATCHER: Finished worker discovery
23:34:36 DISPATCHER: Starting worker discovery
23:34:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:34:36 DISPATCHER: Finished worker discovery
23:35:36 DISPATCHER: Starting worker discovery
23:35:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:35:36 DISPATCHER: Finished worker discovery
23:36:36 DISPATCHER: Starting worker discovery
23:36:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:36:36 DISPATCHER: Finished worker discovery
23:37:36 DISPATCHER: Starting worker discovery
23:37:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:37:36 DISPATCHER: Finished worker discovery
23:38:36 DISPATCHER: Starting worker discovery
23:38:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:38:36 DISPATCHER: Finished worker discovery
23:39:36 DISPATCHER: Starting worker discovery
23:39:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:39:36 DISPATCHER: Finished worker discovery
23:40:36 DISPATCHER: Starting worker discovery
23:40:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:40:36 DISPATCHER: Finished worker discovery
23:41:36 DISPATCHER: Starting worker discovery
23:41:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:41:36 DISPATCHER: Finished worker discovery
23:42:36 DISPATCHER: Starting worker discovery
23:42:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:42:36 DISPATCHER: Finished worker discovery
23:43:36 DISPATCHER: Starting worker discovery
23:43:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:43:36 DISPATCHER: Finished worker discovery
23:44:36 DISPATCHER: Starting worker discovery
23:44:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:44:36 DISPATCHER: Finished worker discovery
23:45:36 DISPATCHER: Starting worker discovery
23:45:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:45:36 DISPATCHER: Finished worker discovery
23:46:17 WORKER: done with job (3, 0, 0), trying to register it.
23:46:17 WORKER: registered result for job (3, 0, 0) with dispatcher
23:46:17 DISPATCHER: job (3, 0, 0) finished
23:46:17 DISPATCHER: register_result: lock acquired
23:46:17 DISPATCHER: job (3, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
23:46:17 job_id: (3, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 498, 'last_n_outputs': 31, 'leak_rate': 0.8926201892521313, 'lr': 0.07697219929979665, 'optimizer': 'SGD', 'sparsity': 0.8196710826055565, 'steps_to_train': 72, 'weight_decay': 0.10346291487031697}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.07093386165399741, 'info': {'sick_no_sick': 0.07093386165399741, 'config': "{'batch_size': 32, 'hidden_dim': 498, 'last_n_outputs': 31, 'leak_rate': 0.8926201892521313, 'lr': 0.07697219929979665, 'optimizer': 'SGD', 'sparsity': 0.8196710826055565, 'steps_to_train': 72, 'weight_decay': 0.10346291487031697}"}}
exception: None

23:46:17 job_callback for (3, 0, 0) started
23:46:17 DISPATCHER: Trying to submit another job.
23:46:17 job_callback for (3, 0, 0) got condition
23:46:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:46:17 Only 5 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
23:46:17 HBMASTER: Trying to run another job!
23:46:17 job_callback for (3, 0, 0) finished
23:46:17 start sampling a new configuration.
23:46:17 best_vector: [2, 0.42354338833592853, 0.40136494874086553, 0.8762267314979664, 0.13733796653757382, 0, 0.7424877706080233, 0.9972081344749468, 0.6923206902401824], 0.005538217091545742, 0.049953043158912115, 0.0002766507973974092
23:46:17 done sampling a new configuration.
23:46:17 HBMASTER: schedule new run for iteration 3
23:46:17 HBMASTER: trying submitting job (3, 0, 1) to dispatcher
23:46:17 HBMASTER: submitting job (3, 0, 1) to dispatcher
23:46:17 DISPATCHER: trying to submit job (3, 0, 1)
23:46:17 DISPATCHER: trying to notify the job_runner thread.
23:46:17 HBMASTER: job (3, 0, 1) submitted to dispatcher
23:46:17 DISPATCHER: Trying to submit another job.
23:46:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:46:17 DISPATCHER: starting job (3, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:46:17 DISPATCHER: job (3, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:46:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:46:17 WORKER: start processing job (3, 0, 1)
23:46:17 WORKER: args: ()
23:46:17 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 539, 'last_n_outputs': 26, 'leak_rate': 0.9690566828744915, 'lr': 0.001882244050508846, 'optimizer': 'Adam', 'sparsity': 0.9281970649459256, 'steps_to_train': 100, 'weight_decay': 0.07956645054154016}, 'budget': 1200.0, 'working_directory': '.'}
23:46:36 DISPATCHER: Starting worker discovery
23:46:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:46:36 DISPATCHER: Finished worker discovery
23:47:36 DISPATCHER: Starting worker discovery
23:47:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:47:36 DISPATCHER: Finished worker discovery
23:48:36 DISPATCHER: Starting worker discovery
23:48:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:48:36 DISPATCHER: Finished worker discovery
23:49:36 DISPATCHER: Starting worker discovery
23:49:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:49:36 DISPATCHER: Finished worker discovery
23:50:36 DISPATCHER: Starting worker discovery
23:50:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:50:36 DISPATCHER: Finished worker discovery
23:51:36 DISPATCHER: Starting worker discovery
23:51:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:51:36 DISPATCHER: Finished worker discovery
23:52:36 DISPATCHER: Starting worker discovery
23:52:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:52:36 DISPATCHER: Finished worker discovery
23:53:36 DISPATCHER: Starting worker discovery
23:53:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:53:36 DISPATCHER: Finished worker discovery
23:54:36 DISPATCHER: Starting worker discovery
23:54:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:54:36 DISPATCHER: Finished worker discovery
23:55:36 DISPATCHER: Starting worker discovery
23:55:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:55:36 DISPATCHER: Finished worker discovery
23:56:36 DISPATCHER: Starting worker discovery
23:56:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:56:36 DISPATCHER: Finished worker discovery
23:57:36 DISPATCHER: Starting worker discovery
23:57:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:57:36 DISPATCHER: Finished worker discovery
23:58:36 DISPATCHER: Starting worker discovery
23:58:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:58:36 DISPATCHER: Finished worker discovery
23:59:36 DISPATCHER: Starting worker discovery
23:59:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:59:36 DISPATCHER: Finished worker discovery
00:00:36 DISPATCHER: Starting worker discovery
00:00:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:00:36 DISPATCHER: Finished worker discovery
00:01:36 DISPATCHER: Starting worker discovery
00:01:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:01:36 DISPATCHER: Finished worker discovery
00:02:36 DISPATCHER: Starting worker discovery
00:02:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:02:36 DISPATCHER: Finished worker discovery
00:03:36 DISPATCHER: Starting worker discovery
00:03:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:03:36 DISPATCHER: Finished worker discovery
00:04:36 DISPATCHER: Starting worker discovery
00:04:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:04:36 DISPATCHER: Finished worker discovery
00:05:36 DISPATCHER: Starting worker discovery
00:05:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:05:36 DISPATCHER: Finished worker discovery
00:06:36 DISPATCHER: Starting worker discovery
00:06:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:06:36 DISPATCHER: Finished worker discovery
00:07:23 WORKER: done with job (3, 0, 1), trying to register it.
00:07:23 WORKER: registered result for job (3, 0, 1) with dispatcher
00:07:23 DISPATCHER: job (3, 0, 1) finished
00:07:23 DISPATCHER: register_result: lock acquired
00:07:23 DISPATCHER: job (3, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
00:07:23 job_id: (3, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 539, 'last_n_outputs': 26, 'leak_rate': 0.9690566828744915, 'lr': 0.001882244050508846, 'optimizer': 'Adam', 'sparsity': 0.9281970649459256, 'steps_to_train': 100, 'weight_decay': 0.07956645054154016}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.14296195528169275, 'info': {'sick_no_sick': 0.14296195528169275, 'config': "{'batch_size': 64, 'hidden_dim': 539, 'last_n_outputs': 26, 'leak_rate': 0.9690566828744915, 'lr': 0.001882244050508846, 'optimizer': 'Adam', 'sparsity': 0.9281970649459256, 'steps_to_train': 100, 'weight_decay': 0.07956645054154016}"}}
exception: None

00:07:23 job_callback for (3, 0, 1) started
00:07:23 DISPATCHER: Trying to submit another job.
00:07:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:07:23 job_callback for (3, 0, 1) got condition
00:07:23 Only 6 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
00:07:23 HBMASTER: Trying to run another job!
00:07:23 job_callback for (3, 0, 1) finished
00:07:23 start sampling a new configuration.
00:07:23 best_vector: [3, 0.9161003482538007, 0.1286358801478153, 0.7930063879930336, 0.7019317414624251, 0, 0.05022465299173173, 0.24267292365169413, 0.29144036259420897], 0.019037428236789704, 0.11977376495898087, 0.0022801844550567156
00:07:23 done sampling a new configuration.
00:07:23 HBMASTER: schedule new run for iteration 3
00:07:23 HBMASTER: trying submitting job (3, 0, 2) to dispatcher
00:07:23 HBMASTER: submitting job (3, 0, 2) to dispatcher
00:07:23 DISPATCHER: trying to submit job (3, 0, 2)
00:07:23 DISPATCHER: trying to notify the job_runner thread.
00:07:23 HBMASTER: job (3, 0, 2) submitted to dispatcher
00:07:23 DISPATCHER: Trying to submit another job.
00:07:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:07:23 DISPATCHER: starting job (3, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:07:23 DISPATCHER: job (3, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:07:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:07:23 WORKER: start processing job (3, 0, 2)
00:07:23 WORKER: args: ()
00:07:23 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 933, 'last_n_outputs': 15, 'leak_rate': 0.9482515969982583, 'lr': 0.02534331857868278, 'optimizer': 'Adam', 'sparsity': 0.7620539167180156, 'steps_to_train': 32, 'weight_decay': 0.023942674077455952}, 'budget': 1200.0, 'working_directory': '.'}
00:07:36 DISPATCHER: Starting worker discovery
00:07:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:07:36 DISPATCHER: Finished worker discovery
00:08:36 DISPATCHER: Starting worker discovery
00:08:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:08:36 DISPATCHER: Finished worker discovery
00:09:36 DISPATCHER: Starting worker discovery
00:09:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:09:36 DISPATCHER: Finished worker discovery
00:10:36 DISPATCHER: Starting worker discovery
00:10:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:10:36 DISPATCHER: Finished worker discovery
00:11:36 DISPATCHER: Starting worker discovery
00:11:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:11:36 DISPATCHER: Finished worker discovery
00:12:36 DISPATCHER: Starting worker discovery
00:12:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:12:36 DISPATCHER: Finished worker discovery
00:13:36 DISPATCHER: Starting worker discovery
00:13:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:13:36 DISPATCHER: Finished worker discovery
00:14:36 DISPATCHER: Starting worker discovery
00:14:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:14:36 DISPATCHER: Finished worker discovery
00:15:36 DISPATCHER: Starting worker discovery
00:15:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:15:36 DISPATCHER: Finished worker discovery
00:16:36 DISPATCHER: Starting worker discovery
00:16:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:16:36 DISPATCHER: Finished worker discovery
00:17:36 DISPATCHER: Starting worker discovery
00:17:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:17:36 DISPATCHER: Finished worker discovery
00:18:36 DISPATCHER: Starting worker discovery
00:18:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:18:36 DISPATCHER: Finished worker discovery
00:19:36 DISPATCHER: Starting worker discovery
00:19:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:19:36 DISPATCHER: Finished worker discovery
00:20:36 DISPATCHER: Starting worker discovery
00:20:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:20:36 DISPATCHER: Finished worker discovery
00:21:36 DISPATCHER: Starting worker discovery
00:21:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:21:36 DISPATCHER: Finished worker discovery
00:22:36 DISPATCHER: Starting worker discovery
00:22:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:22:36 DISPATCHER: Finished worker discovery
00:23:36 DISPATCHER: Starting worker discovery
00:23:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:23:36 DISPATCHER: Finished worker discovery
00:24:36 DISPATCHER: Starting worker discovery
00:24:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:24:36 DISPATCHER: Finished worker discovery
00:25:36 DISPATCHER: Starting worker discovery
00:25:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:25:36 DISPATCHER: Finished worker discovery
00:26:36 DISPATCHER: Starting worker discovery
00:26:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:26:36 DISPATCHER: Finished worker discovery
00:27:36 DISPATCHER: Starting worker discovery
00:27:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:27:36 DISPATCHER: Finished worker discovery
00:28:33 WORKER: done with job (3, 0, 2), trying to register it.
00:28:33 WORKER: registered result for job (3, 0, 2) with dispatcher
00:28:33 DISPATCHER: job (3, 0, 2) finished
00:28:33 DISPATCHER: register_result: lock acquired
00:28:33 DISPATCHER: job (3, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
00:28:33 job_id: (3, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 933, 'last_n_outputs': 15, 'leak_rate': 0.9482515969982583, 'lr': 0.02534331857868278, 'optimizer': 'Adam', 'sparsity': 0.7620539167180156, 'steps_to_train': 32, 'weight_decay': 0.023942674077455952}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.1599166724795321, 'info': {'sick_no_sick': 0.1599166724795321, 'config': "{'batch_size': 128, 'hidden_dim': 933, 'last_n_outputs': 15, 'leak_rate': 0.9482515969982583, 'lr': 0.02534331857868278, 'optimizer': 'Adam', 'sparsity': 0.7620539167180156, 'steps_to_train': 32, 'weight_decay': 0.023942674077455952}"}}
exception: None

00:28:33 job_callback for (3, 0, 2) started
00:28:33 job_callback for (3, 0, 2) got condition
00:28:33 DISPATCHER: Trying to submit another job.
00:28:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:28:33 Only 7 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
00:28:33 HBMASTER: Trying to run another job!
00:28:33 job_callback for (3, 0, 2) finished
00:28:33 start sampling a new configuration.
00:28:33 done sampling a new configuration.
00:28:33 HBMASTER: schedule new run for iteration 3
00:28:33 HBMASTER: trying submitting job (3, 0, 3) to dispatcher
00:28:33 HBMASTER: submitting job (3, 0, 3) to dispatcher
00:28:33 DISPATCHER: trying to submit job (3, 0, 3)
00:28:33 DISPATCHER: trying to notify the job_runner thread.
00:28:33 HBMASTER: job (3, 0, 3) submitted to dispatcher
00:28:33 DISPATCHER: Trying to submit another job.
00:28:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:28:33 DISPATCHER: starting job (3, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:28:33 DISPATCHER: job (3, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:28:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:28:33 WORKER: start processing job (3, 0, 3)
00:28:33 WORKER: args: ()
00:28:33 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 813, 'last_n_outputs': 22, 'leak_rate': 0.8415497952593725, 'lr': 0.08998620772048117, 'optimizer': 'SGD', 'sparsity': 0.8858217820421934, 'steps_to_train': 63, 'weight_decay': 0.045391260213876204}, 'budget': 1200.0, 'working_directory': '.'}
00:28:36 DISPATCHER: Starting worker discovery
00:28:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:28:36 DISPATCHER: Finished worker discovery
00:29:36 DISPATCHER: Starting worker discovery
00:29:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:29:36 DISPATCHER: Finished worker discovery
00:30:36 DISPATCHER: Starting worker discovery
00:30:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:30:36 DISPATCHER: Finished worker discovery
00:31:36 DISPATCHER: Starting worker discovery
00:31:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:31:37 DISPATCHER: Finished worker discovery
00:32:37 DISPATCHER: Starting worker discovery
00:32:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:32:37 DISPATCHER: Finished worker discovery
00:33:37 DISPATCHER: Starting worker discovery
00:33:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:33:37 DISPATCHER: Finished worker discovery
00:34:37 DISPATCHER: Starting worker discovery
00:34:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:34:37 DISPATCHER: Finished worker discovery
00:35:37 DISPATCHER: Starting worker discovery
00:35:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:35:37 DISPATCHER: Finished worker discovery
00:36:37 DISPATCHER: Starting worker discovery
00:36:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:36:37 DISPATCHER: Finished worker discovery
00:37:37 DISPATCHER: Starting worker discovery
00:37:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:37:37 DISPATCHER: Finished worker discovery
00:38:37 DISPATCHER: Starting worker discovery
00:38:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:38:37 DISPATCHER: Finished worker discovery
00:39:37 DISPATCHER: Starting worker discovery
00:39:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:39:37 DISPATCHER: Finished worker discovery
00:40:37 DISPATCHER: Starting worker discovery
00:40:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:40:37 DISPATCHER: Finished worker discovery
00:41:37 DISPATCHER: Starting worker discovery
00:41:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:41:37 DISPATCHER: Finished worker discovery
00:42:37 DISPATCHER: Starting worker discovery
00:42:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:42:37 DISPATCHER: Finished worker discovery
00:43:37 DISPATCHER: Starting worker discovery
00:43:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:43:37 DISPATCHER: Finished worker discovery
00:44:37 DISPATCHER: Starting worker discovery
00:44:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:44:37 DISPATCHER: Finished worker discovery
00:45:37 DISPATCHER: Starting worker discovery
00:45:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:45:37 DISPATCHER: Finished worker discovery
00:46:37 DISPATCHER: Starting worker discovery
00:46:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:46:37 DISPATCHER: Finished worker discovery
00:47:37 DISPATCHER: Starting worker discovery
00:47:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:47:37 DISPATCHER: Finished worker discovery
00:48:37 DISPATCHER: Starting worker discovery
00:48:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:48:37 DISPATCHER: Finished worker discovery
00:49:37 DISPATCHER: Starting worker discovery
00:49:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:49:37 DISPATCHER: Finished worker discovery
00:49:42 WORKER: done with job (3, 0, 3), trying to register it.
00:49:42 WORKER: registered result for job (3, 0, 3) with dispatcher
00:49:42 DISPATCHER: job (3, 0, 3) finished
00:49:42 DISPATCHER: register_result: lock acquired
00:49:42 DISPATCHER: job (3, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
00:49:42 job_id: (3, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 813, 'last_n_outputs': 22, 'leak_rate': 0.8415497952593725, 'lr': 0.08998620772048117, 'optimizer': 'SGD', 'sparsity': 0.8858217820421934, 'steps_to_train': 63, 'weight_decay': 0.045391260213876204}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.08197284137021871, 'info': {'sick_no_sick': 0.08197284137021871, 'config': "{'batch_size': 16, 'hidden_dim': 813, 'last_n_outputs': 22, 'leak_rate': 0.8415497952593725, 'lr': 0.08998620772048117, 'optimizer': 'SGD', 'sparsity': 0.8858217820421934, 'steps_to_train': 63, 'weight_decay': 0.045391260213876204}"}}
exception: None

00:49:42 job_callback for (3, 0, 3) started
00:49:42 job_callback for (3, 0, 3) got condition
00:49:42 DISPATCHER: Trying to submit another job.
00:49:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:49:42 Only 8 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
00:49:42 HBMASTER: Trying to run another job!
00:49:42 job_callback for (3, 0, 3) finished
00:49:42 start sampling a new configuration.
00:49:42 done sampling a new configuration.
00:49:42 HBMASTER: schedule new run for iteration 4
00:49:42 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
00:49:42 HBMASTER: submitting job (4, 0, 0) to dispatcher
00:49:42 DISPATCHER: trying to submit job (4, 0, 0)
00:49:42 DISPATCHER: trying to notify the job_runner thread.
00:49:42 HBMASTER: job (4, 0, 0) submitted to dispatcher
00:49:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:49:42 DISPATCHER: Trying to submit another job.
00:49:42 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:49:42 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:49:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:49:42 WORKER: start processing job (4, 0, 0)
00:49:42 WORKER: args: ()
00:49:42 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 743, 'last_n_outputs': 13, 'leak_rate': 0.813806288811964, 'lr': 0.005315157157747162, 'optimizer': 'SGD', 'sparsity': 0.7618154624928459, 'steps_to_train': 100, 'weight_decay': 0.01095261809141746}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:50:37 DISPATCHER: Starting worker discovery
00:50:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:50:37 DISPATCHER: Finished worker discovery
00:51:31 WORKER: done with job (4, 0, 0), trying to register it.
00:51:31 WORKER: registered result for job (4, 0, 0) with dispatcher
00:51:31 DISPATCHER: job (4, 0, 0) finished
00:51:31 DISPATCHER: register_result: lock acquired
00:51:31 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
00:51:31 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 743, 'last_n_outputs': 13, 'leak_rate': 0.813806288811964, 'lr': 0.005315157157747162, 'optimizer': 'SGD', 'sparsity': 0.7618154624928459, 'steps_to_train': 100, 'weight_decay': 0.01095261809141746}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.18702377263322276, 'info': {'sick_no_sick': 0.18702377263322276, 'config': "{'batch_size': 128, 'hidden_dim': 743, 'last_n_outputs': 13, 'leak_rate': 0.813806288811964, 'lr': 0.005315157157747162, 'optimizer': 'SGD', 'sparsity': 0.7618154624928459, 'steps_to_train': 100, 'weight_decay': 0.01095261809141746}"}}
exception: None

00:51:31 job_callback for (4, 0, 0) started
00:51:31 DISPATCHER: Trying to submit another job.
00:51:31 job_callback for (4, 0, 0) got condition
00:51:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:51:31 done building a new model for budget 44.444444 based on 10/23 split
Best loss for this budget:-0.234714





00:51:31 HBMASTER: Trying to run another job!
00:51:31 job_callback for (4, 0, 0) finished
00:51:31 start sampling a new configuration.
00:51:31 best_vector: [1, 0.9653940409852433, 0.07629486643486438, 0.8905053556274006, 0.45202487630335697, 0, 0.06786015049717664, 0.1470898122174576, 0.0500975891421587], 0.017037780986795283, 0.08350372935276194, 0.0014227182522929867
00:51:31 done sampling a new configuration.
00:51:31 HBMASTER: schedule new run for iteration 4
00:51:31 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
00:51:31 HBMASTER: submitting job (4, 0, 1) to dispatcher
00:51:31 DISPATCHER: trying to submit job (4, 0, 1)
00:51:31 DISPATCHER: trying to notify the job_runner thread.
00:51:31 HBMASTER: job (4, 0, 1) submitted to dispatcher
00:51:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:51:31 DISPATCHER: Trying to submit another job.
00:51:31 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:51:31 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:51:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:51:31 WORKER: start processing job (4, 0, 1)
00:51:31 WORKER: args: ()
00:51:31 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 973, 'last_n_outputs': 13, 'leak_rate': 0.9726263389068501, 'lr': 0.008017699085751874, 'optimizer': 'Adam', 'sparsity': 0.7662864361193223, 'steps_to_train': 23, 'weight_decay': 0.011619259901505955}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:51:37 DISPATCHER: Starting worker discovery
00:51:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:51:37 DISPATCHER: Finished worker discovery
00:52:37 DISPATCHER: Starting worker discovery
00:52:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:52:37 DISPATCHER: Finished worker discovery
00:53:20 WORKER: done with job (4, 0, 1), trying to register it.
00:53:20 WORKER: registered result for job (4, 0, 1) with dispatcher
00:53:20 DISPATCHER: job (4, 0, 1) finished
00:53:20 DISPATCHER: register_result: lock acquired
00:53:20 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
00:53:20 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 973, 'last_n_outputs': 13, 'leak_rate': 0.9726263389068501, 'lr': 0.008017699085751874, 'optimizer': 'Adam', 'sparsity': 0.7662864361193223, 'steps_to_train': 23, 'weight_decay': 0.011619259901505955}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.22102495800364302, 'info': {'sick_no_sick': 0.22102495800364302, 'config': "{'batch_size': 32, 'hidden_dim': 973, 'last_n_outputs': 13, 'leak_rate': 0.9726263389068501, 'lr': 0.008017699085751874, 'optimizer': 'Adam', 'sparsity': 0.7662864361193223, 'steps_to_train': 23, 'weight_decay': 0.011619259901505955}"}}
exception: None

00:53:20 job_callback for (4, 0, 1) started
00:53:20 DISPATCHER: Trying to submit another job.
00:53:20 job_callback for (4, 0, 1) got condition
00:53:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:53:20 done building a new model for budget 44.444444 based on 10/24 split
Best loss for this budget:-0.234714





00:53:20 HBMASTER: Trying to run another job!
00:53:20 job_callback for (4, 0, 1) finished
00:53:20 start sampling a new configuration.
00:53:20 done sampling a new configuration.
00:53:20 HBMASTER: schedule new run for iteration 4
00:53:20 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
00:53:20 HBMASTER: submitting job (4, 0, 2) to dispatcher
00:53:20 DISPATCHER: trying to submit job (4, 0, 2)
00:53:20 DISPATCHER: trying to notify the job_runner thread.
00:53:20 HBMASTER: job (4, 0, 2) submitted to dispatcher
00:53:20 DISPATCHER: Trying to submit another job.
00:53:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:53:20 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:53:20 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:53:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:53:20 WORKER: start processing job (4, 0, 2)
00:53:20 WORKER: args: ()
00:53:20 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 972, 'last_n_outputs': 14, 'leak_rate': 0.8751051251895478, 'lr': 0.007935283846549573, 'optimizer': 'Adam', 'sparsity': 0.7942360115390649, 'steps_to_train': 26, 'weight_decay': 0.09151501170267076}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:53:37 DISPATCHER: Starting worker discovery
00:53:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:53:37 DISPATCHER: Finished worker discovery
00:54:37 DISPATCHER: Starting worker discovery
00:54:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:54:37 DISPATCHER: Finished worker discovery
00:55:08 WORKER: done with job (4, 0, 2), trying to register it.
00:55:08 WORKER: registered result for job (4, 0, 2) with dispatcher
00:55:08 DISPATCHER: job (4, 0, 2) finished
00:55:08 DISPATCHER: register_result: lock acquired
00:55:08 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
00:55:08 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 972, 'last_n_outputs': 14, 'leak_rate': 0.8751051251895478, 'lr': 0.007935283846549573, 'optimizer': 'Adam', 'sparsity': 0.7942360115390649, 'steps_to_train': 26, 'weight_decay': 0.09151501170267076}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.12152416247310456, 'info': {'sick_no_sick': 0.12152416247310456, 'config': "{'batch_size': 64, 'hidden_dim': 972, 'last_n_outputs': 14, 'leak_rate': 0.8751051251895478, 'lr': 0.007935283846549573, 'optimizer': 'Adam', 'sparsity': 0.7942360115390649, 'steps_to_train': 26, 'weight_decay': 0.09151501170267076}"}}
exception: None

00:55:08 job_callback for (4, 0, 2) started
00:55:08 DISPATCHER: Trying to submit another job.
00:55:08 job_callback for (4, 0, 2) got condition
00:55:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:55:08 done building a new model for budget 44.444444 based on 10/25 split
Best loss for this budget:-0.234714





00:55:08 HBMASTER: Trying to run another job!
00:55:08 job_callback for (4, 0, 2) finished
00:55:08 start sampling a new configuration.
00:55:08 done sampling a new configuration.
00:55:08 HBMASTER: schedule new run for iteration 4
00:55:08 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
00:55:08 HBMASTER: submitting job (4, 0, 3) to dispatcher
00:55:08 DISPATCHER: trying to submit job (4, 0, 3)
00:55:08 DISPATCHER: trying to notify the job_runner thread.
00:55:08 HBMASTER: job (4, 0, 3) submitted to dispatcher
00:55:08 DISPATCHER: Trying to submit another job.
00:55:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:55:08 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:55:08 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:55:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:55:08 WORKER: start processing job (4, 0, 3)
00:55:08 WORKER: args: ()
00:55:08 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 942, 'last_n_outputs': 49, 'leak_rate': 0.804028372696082, 'lr': 0.007999853168636164, 'optimizer': 'SGD', 'sparsity': 0.8133521402515982, 'steps_to_train': 92, 'weight_decay': 0.06053640920116847}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:55:37 DISPATCHER: Starting worker discovery
00:55:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:55:37 DISPATCHER: Finished worker discovery
00:56:37 DISPATCHER: Starting worker discovery
00:56:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:56:37 DISPATCHER: Finished worker discovery
00:56:54 WORKER: done with job (4, 0, 3), trying to register it.
00:56:54 WORKER: registered result for job (4, 0, 3) with dispatcher
00:56:54 DISPATCHER: job (4, 0, 3) finished
00:56:54 DISPATCHER: register_result: lock acquired
00:56:54 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
00:56:54 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 942, 'last_n_outputs': 49, 'leak_rate': 0.804028372696082, 'lr': 0.007999853168636164, 'optimizer': 'SGD', 'sparsity': 0.8133521402515982, 'steps_to_train': 92, 'weight_decay': 0.06053640920116847}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.05718652882400489, 'info': {'sick_no_sick': 0.05718652882400489, 'config': "{'batch_size': 64, 'hidden_dim': 942, 'last_n_outputs': 49, 'leak_rate': 0.804028372696082, 'lr': 0.007999853168636164, 'optimizer': 'SGD', 'sparsity': 0.8133521402515982, 'steps_to_train': 92, 'weight_decay': 0.06053640920116847}"}}
exception: None

00:56:54 job_callback for (4, 0, 3) started
00:56:54 job_callback for (4, 0, 3) got condition
00:56:54 DISPATCHER: Trying to submit another job.
00:56:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:56:54 done building a new model for budget 44.444444 based on 10/26 split
Best loss for this budget:-0.234714





00:56:54 HBMASTER: Trying to run another job!
00:56:54 job_callback for (4, 0, 3) finished
00:56:54 start sampling a new configuration.
00:56:54 best_vector: [2, 0.8825527778499435, 0.14458177317211063, 0.1667914854646972, 0.38876990977251064, 1, 0.0635727068749319, 0.9282431433005514, 0.008203284495596114], 0.0014097369601544652, 0.4614375837436656, 0.0006505056166078167
00:56:54 done sampling a new configuration.
00:56:54 HBMASTER: schedule new run for iteration 4
00:56:54 HBMASTER: trying submitting job (4, 0, 4) to dispatcher
00:56:54 HBMASTER: submitting job (4, 0, 4) to dispatcher
00:56:54 DISPATCHER: trying to submit job (4, 0, 4)
00:56:54 DISPATCHER: trying to notify the job_runner thread.
00:56:54 HBMASTER: job (4, 0, 4) submitted to dispatcher
00:56:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:56:54 DISPATCHER: Trying to submit another job.
00:56:54 DISPATCHER: starting job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:56:54 DISPATCHER: job (4, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:56:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:56:54 WORKER: start processing job (4, 0, 4)
00:56:54 WORKER: args: ()
00:56:54 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 906, 'last_n_outputs': 15, 'leak_rate': 0.7916978713661743, 'lr': 0.005991558714310761, 'optimizer': 'SGD', 'sparsity': 0.7652574496499837, 'steps_to_train': 94, 'weight_decay': 0.010248792944180829}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:57:37 DISPATCHER: Starting worker discovery
00:57:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:57:37 DISPATCHER: Finished worker discovery
00:58:37 DISPATCHER: Starting worker discovery
00:58:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:58:37 DISPATCHER: Finished worker discovery
00:58:45 WORKER: done with job (4, 0, 4), trying to register it.
00:58:45 WORKER: registered result for job (4, 0, 4) with dispatcher
00:58:45 DISPATCHER: job (4, 0, 4) finished
00:58:45 DISPATCHER: register_result: lock acquired
00:58:45 DISPATCHER: job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
00:58:45 job_id: (4, 0, 4)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 906, 'last_n_outputs': 15, 'leak_rate': 0.7916978713661743, 'lr': 0.005991558714310761, 'optimizer': 'SGD', 'sparsity': 0.7652574496499837, 'steps_to_train': 94, 'weight_decay': 0.010248792944180829}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.06903049677767108, 'info': {'sick_no_sick': 0.06903049677767108, 'config': "{'batch_size': 64, 'hidden_dim': 906, 'last_n_outputs': 15, 'leak_rate': 0.7916978713661743, 'lr': 0.005991558714310761, 'optimizer': 'SGD', 'sparsity': 0.7652574496499837, 'steps_to_train': 94, 'weight_decay': 0.010248792944180829}"}}
exception: None

00:58:45 job_callback for (4, 0, 4) started
00:58:45 DISPATCHER: Trying to submit another job.
00:58:45 job_callback for (4, 0, 4) got condition
00:58:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:58:45 done building a new model for budget 44.444444 based on 10/27 split
Best loss for this budget:-0.234714





00:58:45 HBMASTER: Trying to run another job!
00:58:45 job_callback for (4, 0, 4) finished
00:58:45 start sampling a new configuration.
00:58:45 done sampling a new configuration.
00:58:45 HBMASTER: schedule new run for iteration 4
00:58:45 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
00:58:45 HBMASTER: submitting job (4, 0, 5) to dispatcher
00:58:45 DISPATCHER: trying to submit job (4, 0, 5)
00:58:45 DISPATCHER: trying to notify the job_runner thread.
00:58:45 HBMASTER: job (4, 0, 5) submitted to dispatcher
00:58:45 DISPATCHER: Trying to submit another job.
00:58:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:58:45 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:58:45 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:58:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:58:45 WORKER: start processing job (4, 0, 5)
00:58:45 WORKER: args: ()
00:58:45 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 642, 'last_n_outputs': 30, 'leak_rate': 0.9870047044516821, 'lr': 0.09016164466836907, 'optimizer': 'Adam', 'sparsity': 0.8385252432549273, 'steps_to_train': 32, 'weight_decay': 0.17504463855683716}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:59:37 DISPATCHER: Starting worker discovery
00:59:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:59:37 DISPATCHER: Finished worker discovery
01:00:32 WORKER: done with job (4, 0, 5), trying to register it.
01:00:32 WORKER: registered result for job (4, 0, 5) with dispatcher
01:00:32 DISPATCHER: job (4, 0, 5) finished
01:00:32 DISPATCHER: register_result: lock acquired
01:00:32 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:00:32 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 642, 'last_n_outputs': 30, 'leak_rate': 0.9870047044516821, 'lr': 0.09016164466836907, 'optimizer': 'Adam', 'sparsity': 0.8385252432549273, 'steps_to_train': 32, 'weight_decay': 0.17504463855683716}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.019544324904144997, 'info': {'sick_no_sick': 0.019544324904144997, 'config': "{'batch_size': 16, 'hidden_dim': 642, 'last_n_outputs': 30, 'leak_rate': 0.9870047044516821, 'lr': 0.09016164466836907, 'optimizer': 'Adam', 'sparsity': 0.8385252432549273, 'steps_to_train': 32, 'weight_decay': 0.17504463855683716}"}}
exception: None

01:00:32 job_callback for (4, 0, 5) started
01:00:32 DISPATCHER: Trying to submit another job.
01:00:32 job_callback for (4, 0, 5) got condition
01:00:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:00:32 done building a new model for budget 44.444444 based on 10/28 split
Best loss for this budget:-0.234714





01:00:32 HBMASTER: Trying to run another job!
01:00:32 job_callback for (4, 0, 5) finished
01:00:32 start sampling a new configuration.
01:00:32 best_vector: [2, 0.09996196313438654, 0.8176921686742779, 0.5977142092795757, 0.02600369109386051, 0, 0.7178407063082123, 0.23290622414663997, 0.4282986513355701], 0.004594479627460303, 0.3274650196522134, 0.001504531361497982
01:00:32 done sampling a new configuration.
01:00:32 HBMASTER: schedule new run for iteration 4
01:00:32 HBMASTER: trying submitting job (4, 0, 6) to dispatcher
01:00:32 HBMASTER: submitting job (4, 0, 6) to dispatcher
01:00:32 DISPATCHER: trying to submit job (4, 0, 6)
01:00:32 DISPATCHER: trying to notify the job_runner thread.
01:00:32 HBMASTER: job (4, 0, 6) submitted to dispatcher
01:00:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:00:32 DISPATCHER: Trying to submit another job.
01:00:32 DISPATCHER: starting job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:00:32 DISPATCHER: job (4, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:00:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:00:32 WORKER: start processing job (4, 0, 6)
01:00:32 WORKER: args: ()
01:00:32 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 280, 'last_n_outputs': 43, 'leak_rate': 0.8994285523198939, 'lr': 0.0011272166165707939, 'optimizer': 'Adam', 'sparsity': 0.9222817695139709, 'steps_to_train': 31, 'weight_decay': 0.0360769149428376}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:00:37 DISPATCHER: Starting worker discovery
01:00:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:00:37 DISPATCHER: Finished worker discovery
01:01:37 DISPATCHER: Starting worker discovery
01:01:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:01:37 DISPATCHER: Finished worker discovery
01:02:19 WORKER: done with job (4, 0, 6), trying to register it.
01:02:19 WORKER: registered result for job (4, 0, 6) with dispatcher
01:02:19 DISPATCHER: job (4, 0, 6) finished
01:02:19 DISPATCHER: register_result: lock acquired
01:02:19 DISPATCHER: job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:02:19 job_id: (4, 0, 6)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 280, 'last_n_outputs': 43, 'leak_rate': 0.8994285523198939, 'lr': 0.0011272166165707939, 'optimizer': 'Adam', 'sparsity': 0.9222817695139709, 'steps_to_train': 31, 'weight_decay': 0.0360769149428376}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1684292641347507, 'info': {'sick_no_sick': 0.1684292641347507, 'config': "{'batch_size': 64, 'hidden_dim': 280, 'last_n_outputs': 43, 'leak_rate': 0.8994285523198939, 'lr': 0.0011272166165707939, 'optimizer': 'Adam', 'sparsity': 0.9222817695139709, 'steps_to_train': 31, 'weight_decay': 0.0360769149428376}"}}
exception: None

01:02:19 job_callback for (4, 0, 6) started
01:02:19 DISPATCHER: Trying to submit another job.
01:02:19 job_callback for (4, 0, 6) got condition
01:02:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:02:19 done building a new model for budget 44.444444 based on 10/28 split
Best loss for this budget:-0.234714





01:02:19 HBMASTER: Trying to run another job!
01:02:19 job_callback for (4, 0, 6) finished
01:02:19 start sampling a new configuration.
01:02:20 best_vector: [0, 0.15102657357907334, 0.9846485990244387, 0.6164781094819811, 0.03765559524108397, 0, 0.8437900589928067, 0.08491875365860824, 0.9357655884283207], 0.007226989370050569, 0.05422110799099493, 0.0003918553710832843
01:02:20 done sampling a new configuration.
01:02:20 HBMASTER: schedule new run for iteration 4
01:02:20 HBMASTER: trying submitting job (4, 0, 7) to dispatcher
01:02:20 HBMASTER: submitting job (4, 0, 7) to dispatcher
01:02:20 DISPATCHER: trying to submit job (4, 0, 7)
01:02:20 DISPATCHER: trying to notify the job_runner thread.
01:02:20 HBMASTER: job (4, 0, 7) submitted to dispatcher
01:02:20 DISPATCHER: Trying to submit another job.
01:02:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:02:20 DISPATCHER: starting job (4, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:02:20 DISPATCHER: job (4, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:02:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:02:20 WORKER: start processing job (4, 0, 7)
01:02:20 WORKER: args: ()
01:02:20 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 320, 'last_n_outputs': 50, 'leak_rate': 0.9041195273704953, 'lr': 0.0011893541450531235, 'optimizer': 'Adam', 'sparsity': 0.9525096141582736, 'steps_to_train': 17, 'weight_decay': 0.16499056108684468}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:02:37 DISPATCHER: Starting worker discovery
01:02:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:02:37 DISPATCHER: Finished worker discovery
01:03:37 DISPATCHER: Starting worker discovery
01:03:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:03:37 DISPATCHER: Finished worker discovery
01:04:06 WORKER: done with job (4, 0, 7), trying to register it.
01:04:06 WORKER: registered result for job (4, 0, 7) with dispatcher
01:04:06 DISPATCHER: job (4, 0, 7) finished
01:04:06 DISPATCHER: register_result: lock acquired
01:04:06 DISPATCHER: job (4, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:04:06 job_id: (4, 0, 7)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 320, 'last_n_outputs': 50, 'leak_rate': 0.9041195273704953, 'lr': 0.0011893541450531235, 'optimizer': 'Adam', 'sparsity': 0.9525096141582736, 'steps_to_train': 17, 'weight_decay': 0.16499056108684468}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.04149823879096514, 'info': {'sick_no_sick': 0.04149823879096514, 'config': "{'batch_size': 16, 'hidden_dim': 320, 'last_n_outputs': 50, 'leak_rate': 0.9041195273704953, 'lr': 0.0011893541450531235, 'optimizer': 'Adam', 'sparsity': 0.9525096141582736, 'steps_to_train': 17, 'weight_decay': 0.16499056108684468}"}}
exception: None

01:04:06 job_callback for (4, 0, 7) started
01:04:06 job_callback for (4, 0, 7) got condition
01:04:06 DISPATCHER: Trying to submit another job.
01:04:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:04:06 done building a new model for budget 44.444444 based on 10/29 split
Best loss for this budget:-0.234714





01:04:06 HBMASTER: Trying to run another job!
01:04:06 job_callback for (4, 0, 7) finished
01:04:06 start sampling a new configuration.
01:04:06 best_vector: [0, 0.18793096452527275, 0.35371917690679205, 0.8772814186966795, 0.11610585030163528, 1, 0.6269314274368984, 0.305921546009674, 0.03872453846206786], 0.01087778650696422, 0.08416970968254828, 0.0009155801322799193
01:04:06 done sampling a new configuration.
01:04:06 HBMASTER: schedule new run for iteration 4
01:04:06 HBMASTER: trying submitting job (4, 0, 8) to dispatcher
01:04:06 HBMASTER: submitting job (4, 0, 8) to dispatcher
01:04:06 DISPATCHER: trying to submit job (4, 0, 8)
01:04:06 DISPATCHER: trying to notify the job_runner thread.
01:04:06 HBMASTER: job (4, 0, 8) submitted to dispatcher
01:04:06 DISPATCHER: Trying to submit another job.
01:04:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:04:06 DISPATCHER: starting job (4, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:04:06 DISPATCHER: job (4, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:04:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:04:06 WORKER: start processing job (4, 0, 8)
01:04:06 WORKER: args: ()
01:04:06 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 350, 'last_n_outputs': 24, 'leak_rate': 0.9693203546741699, 'lr': 0.0017069142363559566, 'optimizer': 'SGD', 'sparsity': 0.9004635425848556, 'steps_to_train': 37, 'weight_decay': 0.011230052487940984}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:04:37 DISPATCHER: Starting worker discovery
01:04:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:04:37 DISPATCHER: Finished worker discovery
01:05:37 DISPATCHER: Starting worker discovery
01:05:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:05:37 DISPATCHER: Finished worker discovery
01:05:53 WORKER: done with job (4, 0, 8), trying to register it.
01:05:53 WORKER: registered result for job (4, 0, 8) with dispatcher
01:05:53 DISPATCHER: job (4, 0, 8) finished
01:05:53 DISPATCHER: register_result: lock acquired
01:05:53 DISPATCHER: job (4, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:05:53 job_id: (4, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 350, 'last_n_outputs': 24, 'leak_rate': 0.9693203546741699, 'lr': 0.0017069142363559566, 'optimizer': 'SGD', 'sparsity': 0.9004635425848556, 'steps_to_train': 37, 'weight_decay': 0.011230052487940984}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.19484366557851682, 'info': {'sick_no_sick': 0.19484366557851682, 'config': "{'batch_size': 16, 'hidden_dim': 350, 'last_n_outputs': 24, 'leak_rate': 0.9693203546741699, 'lr': 0.0017069142363559566, 'optimizer': 'SGD', 'sparsity': 0.9004635425848556, 'steps_to_train': 37, 'weight_decay': 0.011230052487940984}"}}
exception: None

01:05:53 job_callback for (4, 0, 8) started
01:05:53 DISPATCHER: Trying to submit another job.
01:05:53 job_callback for (4, 0, 8) got condition
01:05:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:05:53 done building a new model for budget 44.444444 based on 10/30 split
Best loss for this budget:-0.234714





01:05:53 HBMASTER: Trying to run another job!
01:05:53 job_callback for (4, 0, 8) finished
01:05:53 start sampling a new configuration.
01:05:53 best_vector: [2, 0.23097462756146248, 0.9485822298521499, 0.9993707720533354, 0.002526011981964081, 0, 0.17307999822149311, 0.619571030729405, 0.32133732894901423], 0.02918583919178521, 0.009680620302508592, 0.00028253702742574686
01:05:53 done sampling a new configuration.
01:05:53 HBMASTER: schedule new run for iteration 4
01:05:53 HBMASTER: trying submitting job (4, 0, 9) to dispatcher
01:05:53 HBMASTER: submitting job (4, 0, 9) to dispatcher
01:05:53 DISPATCHER: trying to submit job (4, 0, 9)
01:05:53 DISPATCHER: trying to notify the job_runner thread.
01:05:53 HBMASTER: job (4, 0, 9) submitted to dispatcher
01:05:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:05:53 DISPATCHER: Trying to submit another job.
01:05:53 DISPATCHER: starting job (4, 0, 9) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:05:53 DISPATCHER: job (4, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:05:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:05:53 WORKER: start processing job (4, 0, 9)
01:05:53 WORKER: args: ()
01:05:53 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 385, 'last_n_outputs': 48, 'leak_rate': 0.9998426930133338, 'lr': 0.0010117006382201008, 'optimizer': 'Adam', 'sparsity': 0.7915391995731583, 'steps_to_train': 66, 'weight_decay': 0.02618602050937243}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:06:37 DISPATCHER: Starting worker discovery
01:06:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:06:37 DISPATCHER: Finished worker discovery
01:07:37 DISPATCHER: Starting worker discovery
01:07:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:07:37 DISPATCHER: Finished worker discovery
01:07:42 WORKER: done with job (4, 0, 9), trying to register it.
01:07:42 WORKER: registered result for job (4, 0, 9) with dispatcher
01:07:42 DISPATCHER: job (4, 0, 9) finished
01:07:42 DISPATCHER: register_result: lock acquired
01:07:42 DISPATCHER: job (4, 0, 9) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:07:42 job_id: (4, 0, 9)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 385, 'last_n_outputs': 48, 'leak_rate': 0.9998426930133338, 'lr': 0.0010117006382201008, 'optimizer': 'Adam', 'sparsity': 0.7915391995731583, 'steps_to_train': 66, 'weight_decay': 0.02618602050937243}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.13376326037121336, 'info': {'sick_no_sick': 0.13376326037121336, 'config': "{'batch_size': 64, 'hidden_dim': 385, 'last_n_outputs': 48, 'leak_rate': 0.9998426930133338, 'lr': 0.0010117006382201008, 'optimizer': 'Adam', 'sparsity': 0.7915391995731583, 'steps_to_train': 66, 'weight_decay': 0.02618602050937243}"}}
exception: None

01:07:42 job_callback for (4, 0, 9) started
01:07:42 job_callback for (4, 0, 9) got condition
01:07:42 DISPATCHER: Trying to submit another job.
01:07:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:07:42 done building a new model for budget 44.444444 based on 10/31 split
Best loss for this budget:-0.234714





01:07:42 HBMASTER: Trying to run another job!
01:07:42 job_callback for (4, 0, 9) finished
01:07:42 start sampling a new configuration.
01:07:42 done sampling a new configuration.
01:07:42 HBMASTER: schedule new run for iteration 4
01:07:42 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
01:07:42 HBMASTER: submitting job (4, 0, 10) to dispatcher
01:07:42 DISPATCHER: trying to submit job (4, 0, 10)
01:07:42 DISPATCHER: trying to notify the job_runner thread.
01:07:42 HBMASTER: job (4, 0, 10) submitted to dispatcher
01:07:42 DISPATCHER: Trying to submit another job.
01:07:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:07:42 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:07:42 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:07:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:07:42 WORKER: start processing job (4, 0, 10)
01:07:42 WORKER: args: ()
01:07:42 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 262, 'last_n_outputs': 22, 'leak_rate': 0.8765041790365095, 'lr': 0.007789282983602313, 'optimizer': 'Adam', 'sparsity': 0.9170299397817823, 'steps_to_train': 66, 'weight_decay': 0.04318144275904136}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:08:37 DISPATCHER: Starting worker discovery
01:08:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:08:37 DISPATCHER: Finished worker discovery
01:09:29 WORKER: done with job (4, 0, 10), trying to register it.
01:09:29 WORKER: registered result for job (4, 0, 10) with dispatcher
01:09:29 DISPATCHER: job (4, 0, 10) finished
01:09:29 DISPATCHER: register_result: lock acquired
01:09:29 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:09:29 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 262, 'last_n_outputs': 22, 'leak_rate': 0.8765041790365095, 'lr': 0.007789282983602313, 'optimizer': 'Adam', 'sparsity': 0.9170299397817823, 'steps_to_train': 66, 'weight_decay': 0.04318144275904136}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.10706010912686917, 'info': {'sick_no_sick': 0.10706010912686917, 'config': "{'batch_size': 16, 'hidden_dim': 262, 'last_n_outputs': 22, 'leak_rate': 0.8765041790365095, 'lr': 0.007789282983602313, 'optimizer': 'Adam', 'sparsity': 0.9170299397817823, 'steps_to_train': 66, 'weight_decay': 0.04318144275904136}"}}
exception: None

01:09:29 job_callback for (4, 0, 10) started
01:09:29 job_callback for (4, 0, 10) got condition
01:09:29 DISPATCHER: Trying to submit another job.
01:09:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:09:29 done building a new model for budget 44.444444 based on 10/32 split
Best loss for this budget:-0.234714





01:09:29 HBMASTER: Trying to run another job!
01:09:29 job_callback for (4, 0, 10) finished
01:09:29 start sampling a new configuration.
01:09:29 best_vector: [1, 0.21889561472133467, 0.2586285167861892, 0.5232733197743971, 0.18660821577293285, 1, 0.6169201767813592, 0.18401191992453322, 0.04196698472861207], 0.028550799151500356, 0.2682004474375198, 0.0076573371071311565
01:09:29 done sampling a new configuration.
01:09:29 HBMASTER: schedule new run for iteration 4
01:09:29 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
01:09:29 HBMASTER: submitting job (4, 0, 11) to dispatcher
01:09:29 DISPATCHER: trying to submit job (4, 0, 11)
01:09:29 DISPATCHER: trying to notify the job_runner thread.
01:09:29 HBMASTER: job (4, 0, 11) submitted to dispatcher
01:09:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:09:29 DISPATCHER: Trying to submit another job.
01:09:29 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:09:29 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:09:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:09:29 WORKER: start processing job (4, 0, 11)
01:09:29 WORKER: args: ()
01:09:29 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 375, 'last_n_outputs': 20, 'leak_rate': 0.8808183299435992, 'lr': 0.00236165487551652, 'optimizer': 'SGD', 'sparsity': 0.8980608424275263, 'steps_to_train': 26, 'weight_decay': 0.011339667122244086}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:09:37 DISPATCHER: Starting worker discovery
01:09:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:09:37 DISPATCHER: Finished worker discovery
01:10:37 DISPATCHER: Starting worker discovery
01:10:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:10:37 DISPATCHER: Finished worker discovery
01:11:17 WORKER: done with job (4, 0, 11), trying to register it.
01:11:17 WORKER: registered result for job (4, 0, 11) with dispatcher
01:11:17 DISPATCHER: job (4, 0, 11) finished
01:11:17 DISPATCHER: register_result: lock acquired
01:11:17 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:11:17 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 375, 'last_n_outputs': 20, 'leak_rate': 0.8808183299435992, 'lr': 0.00236165487551652, 'optimizer': 'SGD', 'sparsity': 0.8980608424275263, 'steps_to_train': 26, 'weight_decay': 0.011339667122244086}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2443214835897481, 'info': {'sick_no_sick': 0.2443214835897481, 'config': "{'batch_size': 32, 'hidden_dim': 375, 'last_n_outputs': 20, 'leak_rate': 0.8808183299435992, 'lr': 0.00236165487551652, 'optimizer': 'SGD', 'sparsity': 0.8980608424275263, 'steps_to_train': 26, 'weight_decay': 0.011339667122244086}"}}
exception: None

01:11:17 job_callback for (4, 0, 11) started
01:11:17 job_callback for (4, 0, 11) got condition
01:11:17 DISPATCHER: Trying to submit another job.
01:11:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:11:17 done building a new model for budget 44.444444 based on 10/33 split
Best loss for this budget:-0.244321





01:11:17 HBMASTER: Trying to run another job!
01:11:17 job_callback for (4, 0, 11) finished
01:11:17 start sampling a new configuration.
01:11:17 best_vector: [0, 0.6914371759895989, 0.5076824736423264, 0.01481918125067161, 0.11739628843342921, 1, 0.4884001636633089, 0.2287034268032878, 0.34411896045382306], 0.036081726470531296, 0.09860172926959686, 0.003557720625026973
01:11:17 done sampling a new configuration.
01:11:17 HBMASTER: schedule new run for iteration 4
01:11:17 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
01:11:17 HBMASTER: submitting job (4, 0, 12) to dispatcher
01:11:17 DISPATCHER: trying to submit job (4, 0, 12)
01:11:17 DISPATCHER: trying to notify the job_runner thread.
01:11:17 HBMASTER: job (4, 0, 12) submitted to dispatcher
01:11:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:11:17 DISPATCHER: Trying to submit another job.
01:11:17 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:11:17 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:11:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:11:17 WORKER: start processing job (4, 0, 12)
01:11:17 WORKER: args: ()
01:11:17 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 753, 'last_n_outputs': 30, 'leak_rate': 0.7537047953126679, 'lr': 0.0017170880938444503, 'optimizer': 'SGD', 'sparsity': 0.8672160392791941, 'steps_to_train': 30, 'weight_decay': 0.028035550590148027}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:11:37 DISPATCHER: Starting worker discovery
01:11:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:11:37 DISPATCHER: Finished worker discovery
01:12:37 DISPATCHER: Starting worker discovery
01:12:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:12:37 DISPATCHER: Finished worker discovery
01:13:04 WORKER: done with job (4, 0, 12), trying to register it.
01:13:04 WORKER: registered result for job (4, 0, 12) with dispatcher
01:13:04 DISPATCHER: job (4, 0, 12) finished
01:13:04 DISPATCHER: register_result: lock acquired
01:13:04 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:13:04 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 753, 'last_n_outputs': 30, 'leak_rate': 0.7537047953126679, 'lr': 0.0017170880938444503, 'optimizer': 'SGD', 'sparsity': 0.8672160392791941, 'steps_to_train': 30, 'weight_decay': 0.028035550590148027}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.20500424828804262, 'info': {'sick_no_sick': 0.20500424828804262, 'config': "{'batch_size': 16, 'hidden_dim': 753, 'last_n_outputs': 30, 'leak_rate': 0.7537047953126679, 'lr': 0.0017170880938444503, 'optimizer': 'SGD', 'sparsity': 0.8672160392791941, 'steps_to_train': 30, 'weight_decay': 0.028035550590148027}"}}
exception: None

01:13:04 job_callback for (4, 0, 12) started
01:13:04 DISPATCHER: Trying to submit another job.
01:13:04 job_callback for (4, 0, 12) got condition
01:13:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:13:04 done building a new model for budget 44.444444 based on 10/34 split
Best loss for this budget:-0.244321





01:13:04 HBMASTER: Trying to run another job!
01:13:04 job_callback for (4, 0, 12) finished
01:13:04 start sampling a new configuration.
01:13:04 best_vector: [2, 0.7257326395271455, 0.09399572279807311, 0.14088837059047155, 0.15447594381054933, 1, 0.5788962715478709, 0.42872978632592196, 0.3428903158360539], 0.030293530483402782, 0.16298215370051158, 0.004937304841377085
01:13:04 done sampling a new configuration.
01:13:04 HBMASTER: schedule new run for iteration 4
01:13:04 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
01:13:04 HBMASTER: submitting job (4, 0, 13) to dispatcher
01:13:04 DISPATCHER: trying to submit job (4, 0, 13)
01:13:04 DISPATCHER: trying to notify the job_runner thread.
01:13:04 HBMASTER: job (4, 0, 13) submitted to dispatcher
01:13:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:13:04 DISPATCHER: Trying to submit another job.
01:13:04 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:13:04 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:13:04 WORKER: start processing job (4, 0, 13)
01:13:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:13:04 WORKER: args: ()
01:13:04 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 781, 'last_n_outputs': 13, 'leak_rate': 0.7852220926476179, 'lr': 0.002036816420885702, 'optimizer': 'SGD', 'sparsity': 0.888935105171489, 'steps_to_train': 49, 'weight_decay': 0.02793255008284639}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:13:37 DISPATCHER: Starting worker discovery
01:13:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:13:37 DISPATCHER: Finished worker discovery
01:14:37 DISPATCHER: Starting worker discovery
01:14:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:14:37 DISPATCHER: Finished worker discovery
01:14:51 WORKER: done with job (4, 0, 13), trying to register it.
01:14:51 WORKER: registered result for job (4, 0, 13) with dispatcher
01:14:51 DISPATCHER: job (4, 0, 13) finished
01:14:51 DISPATCHER: register_result: lock acquired
01:14:51 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:14:51 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 781, 'last_n_outputs': 13, 'leak_rate': 0.7852220926476179, 'lr': 0.002036816420885702, 'optimizer': 'SGD', 'sparsity': 0.888935105171489, 'steps_to_train': 49, 'weight_decay': 0.02793255008284639}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2164328469049422, 'info': {'sick_no_sick': 0.2164328469049422, 'config': "{'batch_size': 64, 'hidden_dim': 781, 'last_n_outputs': 13, 'leak_rate': 0.7852220926476179, 'lr': 0.002036816420885702, 'optimizer': 'SGD', 'sparsity': 0.888935105171489, 'steps_to_train': 49, 'weight_decay': 0.02793255008284639}"}}
exception: None

01:14:51 job_callback for (4, 0, 13) started
01:14:51 DISPATCHER: Trying to submit another job.
01:14:51 job_callback for (4, 0, 13) got condition
01:14:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:14:51 done building a new model for budget 44.444444 based on 10/34 split
Best loss for this budget:-0.244321





01:14:51 HBMASTER: Trying to run another job!
01:14:51 job_callback for (4, 0, 13) finished
01:14:51 start sampling a new configuration.
01:14:51 best_vector: [0, 0.6111294661965369, 0.07064177688863643, 0.10499824094544019, 0.2829080252063526, 1, 0.6884079922701787, 0.2815902224068513, 0.8283412953308298], 0.05573225265352768, 0.04913953943370862, 0.0027386572269974354
01:14:51 done sampling a new configuration.
01:14:51 HBMASTER: schedule new run for iteration 4
01:14:51 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
01:14:51 HBMASTER: submitting job (4, 0, 14) to dispatcher
01:14:51 DISPATCHER: trying to submit job (4, 0, 14)
01:14:51 DISPATCHER: trying to notify the job_runner thread.
01:14:51 HBMASTER: job (4, 0, 14) submitted to dispatcher
01:14:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:14:51 DISPATCHER: Trying to submit another job.
01:14:51 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:14:51 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:14:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:14:51 WORKER: start processing job (4, 0, 14)
01:14:51 WORKER: args: ()
01:14:51 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 689, 'last_n_outputs': 12, 'leak_rate': 0.77624956023636, 'lr': 0.003679730821069723, 'optimizer': 'SGD', 'sparsity': 0.9152179181448429, 'steps_to_train': 35, 'weight_decay': 0.11959055238191452}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:15:37 DISPATCHER: Starting worker discovery
01:15:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:15:37 DISPATCHER: Finished worker discovery
01:16:37 DISPATCHER: Starting worker discovery
01:16:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:16:37 DISPATCHER: Finished worker discovery
01:16:38 WORKER: done with job (4, 0, 14), trying to register it.
01:16:38 WORKER: registered result for job (4, 0, 14) with dispatcher
01:16:38 DISPATCHER: job (4, 0, 14) finished
01:16:38 DISPATCHER: register_result: lock acquired
01:16:38 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:16:38 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 689, 'last_n_outputs': 12, 'leak_rate': 0.77624956023636, 'lr': 0.003679730821069723, 'optimizer': 'SGD', 'sparsity': 0.9152179181448429, 'steps_to_train': 35, 'weight_decay': 0.11959055238191452}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.01738484840633367, 'info': {'sick_no_sick': 0.01738484840633367, 'config': "{'batch_size': 16, 'hidden_dim': 689, 'last_n_outputs': 12, 'leak_rate': 0.77624956023636, 'lr': 0.003679730821069723, 'optimizer': 'SGD', 'sparsity': 0.9152179181448429, 'steps_to_train': 35, 'weight_decay': 0.11959055238191452}"}}
exception: None

01:16:38 job_callback for (4, 0, 14) started
01:16:38 DISPATCHER: Trying to submit another job.
01:16:38 job_callback for (4, 0, 14) got condition
01:16:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:16:38 done building a new model for budget 44.444444 based on 10/35 split
Best loss for this budget:-0.244321





01:16:38 HBMASTER: Trying to run another job!
01:16:38 job_callback for (4, 0, 14) finished
01:16:38 start sampling a new configuration.
01:16:38 best_vector: [1, 0.9588064727548212, 0.08835764261420531, 0.08625012325569584, 0.1270714739926701, 0, 0.5202012530775801, 0.7790906694510359, 0.3033543751834552], 0.029519980941743493, 0.1107350213388496, 0.0032688957195063993
01:16:38 done sampling a new configuration.
01:16:38 HBMASTER: schedule new run for iteration 4
01:16:38 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
01:16:38 HBMASTER: submitting job (4, 0, 15) to dispatcher
01:16:38 DISPATCHER: trying to submit job (4, 0, 15)
01:16:38 DISPATCHER: trying to notify the job_runner thread.
01:16:38 HBMASTER: job (4, 0, 15) submitted to dispatcher
01:16:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:16:38 DISPATCHER: Trying to submit another job.
01:16:38 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:16:38 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:16:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:16:38 WORKER: start processing job (4, 0, 15)
01:16:38 WORKER: args: ()
01:16:38 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 968, 'last_n_outputs': 13, 'leak_rate': 0.771562530813924, 'lr': 0.001795324460457618, 'optimizer': 'Adam', 'sparsity': 0.8748483007386192, 'steps_to_train': 80, 'weight_decay': 0.024812649535649673}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:17:37 DISPATCHER: Starting worker discovery
01:17:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:17:37 DISPATCHER: Finished worker discovery
01:18:29 WORKER: done with job (4, 0, 15), trying to register it.
01:18:29 WORKER: registered result for job (4, 0, 15) with dispatcher
01:18:29 DISPATCHER: job (4, 0, 15) finished
01:18:29 DISPATCHER: register_result: lock acquired
01:18:29 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:18:29 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 968, 'last_n_outputs': 13, 'leak_rate': 0.771562530813924, 'lr': 0.001795324460457618, 'optimizer': 'Adam', 'sparsity': 0.8748483007386192, 'steps_to_train': 80, 'weight_decay': 0.024812649535649673}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.14890639322837287, 'info': {'sick_no_sick': 0.14890639322837287, 'config': "{'batch_size': 32, 'hidden_dim': 968, 'last_n_outputs': 13, 'leak_rate': 0.771562530813924, 'lr': 0.001795324460457618, 'optimizer': 'Adam', 'sparsity': 0.8748483007386192, 'steps_to_train': 80, 'weight_decay': 0.024812649535649673}"}}
exception: None

01:18:29 job_callback for (4, 0, 15) started
01:18:29 job_callback for (4, 0, 15) got condition
01:18:29 DISPATCHER: Trying to submit another job.
01:18:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:18:29 done building a new model for budget 44.444444 based on 10/36 split
Best loss for this budget:-0.244321





01:18:29 HBMASTER: Trying to run another job!
01:18:29 job_callback for (4, 0, 15) finished
01:18:29 start sampling a new configuration.
01:18:29 done sampling a new configuration.
01:18:29 HBMASTER: schedule new run for iteration 4
01:18:29 HBMASTER: trying submitting job (4, 0, 16) to dispatcher
01:18:29 HBMASTER: submitting job (4, 0, 16) to dispatcher
01:18:29 DISPATCHER: trying to submit job (4, 0, 16)
01:18:29 DISPATCHER: trying to notify the job_runner thread.
01:18:29 HBMASTER: job (4, 0, 16) submitted to dispatcher
01:18:29 DISPATCHER: Trying to submit another job.
01:18:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:18:29 DISPATCHER: starting job (4, 0, 16) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:18:29 DISPATCHER: job (4, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:18:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:18:29 WORKER: start processing job (4, 0, 16)
01:18:29 WORKER: args: ()
01:18:29 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 607, 'last_n_outputs': 18, 'leak_rate': 0.8939521083433618, 'lr': 0.008989198763749307, 'optimizer': 'SGD', 'sparsity': 0.8281513922694972, 'steps_to_train': 17, 'weight_decay': 0.016001202941519722}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:18:37 DISPATCHER: Starting worker discovery
01:18:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:18:37 DISPATCHER: Finished worker discovery
01:19:37 DISPATCHER: Starting worker discovery
01:19:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:19:37 DISPATCHER: Finished worker discovery
01:20:15 WORKER: done with job (4, 0, 16), trying to register it.
01:20:15 WORKER: registered result for job (4, 0, 16) with dispatcher
01:20:15 DISPATCHER: job (4, 0, 16) finished
01:20:15 DISPATCHER: register_result: lock acquired
01:20:15 DISPATCHER: job (4, 0, 16) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:20:15 job_id: (4, 0, 16)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 607, 'last_n_outputs': 18, 'leak_rate': 0.8939521083433618, 'lr': 0.008989198763749307, 'optimizer': 'SGD', 'sparsity': 0.8281513922694972, 'steps_to_train': 17, 'weight_decay': 0.016001202941519722}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1416509866790766, 'info': {'sick_no_sick': 0.1416509866790766, 'config': "{'batch_size': 64, 'hidden_dim': 607, 'last_n_outputs': 18, 'leak_rate': 0.8939521083433618, 'lr': 0.008989198763749307, 'optimizer': 'SGD', 'sparsity': 0.8281513922694972, 'steps_to_train': 17, 'weight_decay': 0.016001202941519722}"}}
exception: None

01:20:15 job_callback for (4, 0, 16) started
01:20:15 job_callback for (4, 0, 16) got condition
01:20:15 DISPATCHER: Trying to submit another job.
01:20:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:20:15 done building a new model for budget 44.444444 based on 10/37 split
Best loss for this budget:-0.244321





01:20:15 HBMASTER: Trying to run another job!
01:20:15 job_callback for (4, 0, 16) finished
01:20:15 start sampling a new configuration.
01:20:15 done sampling a new configuration.
01:20:15 HBMASTER: schedule new run for iteration 4
01:20:15 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
01:20:15 HBMASTER: submitting job (4, 0, 17) to dispatcher
01:20:15 DISPATCHER: trying to submit job (4, 0, 17)
01:20:15 DISPATCHER: trying to notify the job_runner thread.
01:20:15 HBMASTER: job (4, 0, 17) submitted to dispatcher
01:20:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:20:15 DISPATCHER: Trying to submit another job.
01:20:15 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:20:15 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:20:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:20:15 WORKER: start processing job (4, 0, 17)
01:20:15 WORKER: args: ()
01:20:15 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 570, 'last_n_outputs': 29, 'leak_rate': 0.822516333593993, 'lr': 0.00520409969358784, 'optimizer': 'Adam', 'sparsity': 0.9357275128919497, 'steps_to_train': 19, 'weight_decay': 0.11820744278468373}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:20:37 DISPATCHER: Starting worker discovery
01:20:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:20:37 DISPATCHER: Finished worker discovery
01:21:37 DISPATCHER: Starting worker discovery
01:21:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:21:37 DISPATCHER: Finished worker discovery
01:22:02 WORKER: done with job (4, 0, 17), trying to register it.
01:22:02 WORKER: registered result for job (4, 0, 17) with dispatcher
01:22:02 DISPATCHER: job (4, 0, 17) finished
01:22:02 DISPATCHER: register_result: lock acquired
01:22:02 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:22:02 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 570, 'last_n_outputs': 29, 'leak_rate': 0.822516333593993, 'lr': 0.00520409969358784, 'optimizer': 'Adam', 'sparsity': 0.9357275128919497, 'steps_to_train': 19, 'weight_decay': 0.11820744278468373}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.08529333530470093, 'info': {'sick_no_sick': 0.08529333530470093, 'config': "{'batch_size': 16, 'hidden_dim': 570, 'last_n_outputs': 29, 'leak_rate': 0.822516333593993, 'lr': 0.00520409969358784, 'optimizer': 'Adam', 'sparsity': 0.9357275128919497, 'steps_to_train': 19, 'weight_decay': 0.11820744278468373}"}}
exception: None

01:22:02 job_callback for (4, 0, 17) started
01:22:02 DISPATCHER: Trying to submit another job.
01:22:02 job_callback for (4, 0, 17) got condition
01:22:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:22:02 done building a new model for budget 44.444444 based on 10/38 split
Best loss for this budget:-0.244321





01:22:02 HBMASTER: Trying to run another job!
01:22:02 job_callback for (4, 0, 17) finished
01:22:02 start sampling a new configuration.
01:22:02 best_vector: [3, 0.3381323750363717, 0.3158791886401656, 0.8995448255196268, 0.29981269224656226, 1, 0.8497986270872762, 0.42344038125888606, 0.09888478666877125], 0.010021093563488131, 0.3745546839589696, 0.0037534475325955614
01:22:02 done sampling a new configuration.
01:22:02 HBMASTER: schedule new run for iteration 4
01:22:02 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
01:22:02 HBMASTER: submitting job (4, 0, 18) to dispatcher
01:22:02 DISPATCHER: trying to submit job (4, 0, 18)
01:22:02 DISPATCHER: trying to notify the job_runner thread.
01:22:02 HBMASTER: job (4, 0, 18) submitted to dispatcher
01:22:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:22:02 DISPATCHER: Trying to submit another job.
01:22:02 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:22:02 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:22:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:22:02 WORKER: start processing job (4, 0, 18)
01:22:02 WORKER: args: ()
01:22:02 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 470, 'last_n_outputs': 22, 'leak_rate': 0.9748862063799066, 'lr': 0.00397763917708856, 'optimizer': 'SGD', 'sparsity': 0.9539516705009463, 'steps_to_train': 48, 'weight_decay': 0.013447825764468393}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:22:37 DISPATCHER: Starting worker discovery
01:22:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:22:37 DISPATCHER: Finished worker discovery
01:23:37 DISPATCHER: Starting worker discovery
01:23:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:23:37 DISPATCHER: Finished worker discovery
01:23:50 WORKER: done with job (4, 0, 18), trying to register it.
01:23:50 WORKER: registered result for job (4, 0, 18) with dispatcher
01:23:50 DISPATCHER: job (4, 0, 18) finished
01:23:50 DISPATCHER: register_result: lock acquired
01:23:50 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:23:50 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 470, 'last_n_outputs': 22, 'leak_rate': 0.9748862063799066, 'lr': 0.00397763917708856, 'optimizer': 'SGD', 'sparsity': 0.9539516705009463, 'steps_to_train': 48, 'weight_decay': 0.013447825764468393}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.08473777158478396, 'info': {'sick_no_sick': 0.08473777158478396, 'config': "{'batch_size': 128, 'hidden_dim': 470, 'last_n_outputs': 22, 'leak_rate': 0.9748862063799066, 'lr': 0.00397763917708856, 'optimizer': 'SGD', 'sparsity': 0.9539516705009463, 'steps_to_train': 48, 'weight_decay': 0.013447825764468393}"}}
exception: None

01:23:50 job_callback for (4, 0, 18) started
01:23:50 job_callback for (4, 0, 18) got condition
01:23:50 DISPATCHER: Trying to submit another job.
01:23:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:23:50 done building a new model for budget 44.444444 based on 10/39 split
Best loss for this budget:-0.244321





01:23:50 HBMASTER: Trying to run another job!
01:23:50 job_callback for (4, 0, 18) finished
01:23:50 start sampling a new configuration.
01:23:50 best_vector: [1, 0.0663256724935064, 0.3916763783038879, 0.8838458699005752, 0.0679452310926133, 1, 0.5335760840183009, 0.3614306999427294, 0.4454514088310382], 0.0724329029833101, 0.2812712183213674, 0.020373290868669038
01:23:50 done sampling a new configuration.
01:23:50 HBMASTER: schedule new run for iteration 4
01:23:50 HBMASTER: trying submitting job (4, 0, 19) to dispatcher
01:23:50 HBMASTER: submitting job (4, 0, 19) to dispatcher
01:23:50 DISPATCHER: trying to submit job (4, 0, 19)
01:23:50 DISPATCHER: trying to notify the job_runner thread.
01:23:50 HBMASTER: job (4, 0, 19) submitted to dispatcher
01:23:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:23:50 DISPATCHER: Trying to submit another job.
01:23:50 DISPATCHER: starting job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:23:50 DISPATCHER: job (4, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:23:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:23:50 WORKER: start processing job (4, 0, 19)
01:23:50 WORKER: args: ()
01:23:50 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 253, 'last_n_outputs': 26, 'leak_rate': 0.9709614674751438, 'lr': 0.0013673839003411504, 'optimizer': 'SGD', 'sparsity': 0.8780582601643923, 'steps_to_train': 42, 'weight_decay': 0.037979185312866245}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:24:37 DISPATCHER: Starting worker discovery
01:24:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:24:37 DISPATCHER: Finished worker discovery
01:25:37 DISPATCHER: Starting worker discovery
01:25:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:25:37 DISPATCHER: Finished worker discovery
01:25:38 WORKER: done with job (4, 0, 19), trying to register it.
01:25:38 WORKER: registered result for job (4, 0, 19) with dispatcher
01:25:38 DISPATCHER: job (4, 0, 19) finished
01:25:38 DISPATCHER: register_result: lock acquired
01:25:38 DISPATCHER: job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:25:38 job_id: (4, 0, 19)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 253, 'last_n_outputs': 26, 'leak_rate': 0.9709614674751438, 'lr': 0.0013673839003411504, 'optimizer': 'SGD', 'sparsity': 0.8780582601643923, 'steps_to_train': 42, 'weight_decay': 0.037979185312866245}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2506693557080345, 'info': {'sick_no_sick': 0.2506693557080345, 'config': "{'batch_size': 32, 'hidden_dim': 253, 'last_n_outputs': 26, 'leak_rate': 0.9709614674751438, 'lr': 0.0013673839003411504, 'optimizer': 'SGD', 'sparsity': 0.8780582601643923, 'steps_to_train': 42, 'weight_decay': 0.037979185312866245}"}}
exception: None

01:25:38 job_callback for (4, 0, 19) started
01:25:38 DISPATCHER: Trying to submit another job.
01:25:38 job_callback for (4, 0, 19) got condition
01:25:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:25:38 done building a new model for budget 44.444444 based on 10/39 split
Best loss for this budget:-0.250669





01:25:38 HBMASTER: Trying to run another job!
01:25:38 job_callback for (4, 0, 19) finished
01:25:38 start sampling a new configuration.
01:25:38 best_vector: [2, 0.5862897716908952, 0.7642500488353959, 0.4623561185434549, 0.6256155439095256, 1, 0.9097082062311852, 0.23798894360622508, 0.1829783948305656], 0.040132921039439114, 0.22250269077960166, 0.008929682920120492
01:25:38 done sampling a new configuration.
01:25:38 HBMASTER: schedule new run for iteration 4
01:25:38 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
01:25:38 HBMASTER: submitting job (4, 0, 20) to dispatcher
01:25:38 DISPATCHER: trying to submit job (4, 0, 20)
01:25:38 DISPATCHER: trying to notify the job_runner thread.
01:25:38 HBMASTER: job (4, 0, 20) submitted to dispatcher
01:25:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:25:38 DISPATCHER: Trying to submit another job.
01:25:38 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:25:38 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:25:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:25:38 WORKER: start processing job (4, 0, 20)
01:25:38 WORKER: args: ()
01:25:38 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 669, 'last_n_outputs': 41, 'leak_rate': 0.8655890296358637, 'lr': 0.01783327422429548, 'optimizer': 'SGD', 'sparsity': 0.9683299694954844, 'steps_to_train': 31, 'weight_decay': 0.01730056873382732}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:26:37 DISPATCHER: Starting worker discovery
01:26:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:26:37 DISPATCHER: Finished worker discovery
01:27:25 WORKER: done with job (4, 0, 20), trying to register it.
01:27:25 WORKER: registered result for job (4, 0, 20) with dispatcher
01:27:25 DISPATCHER: job (4, 0, 20) finished
01:27:25 DISPATCHER: register_result: lock acquired
01:27:25 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:27:25 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 669, 'last_n_outputs': 41, 'leak_rate': 0.8655890296358637, 'lr': 0.01783327422429548, 'optimizer': 'SGD', 'sparsity': 0.9683299694954844, 'steps_to_train': 31, 'weight_decay': 0.01730056873382732}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1830363220815016, 'info': {'sick_no_sick': 0.1830363220815016, 'config': "{'batch_size': 64, 'hidden_dim': 669, 'last_n_outputs': 41, 'leak_rate': 0.8655890296358637, 'lr': 0.01783327422429548, 'optimizer': 'SGD', 'sparsity': 0.9683299694954844, 'steps_to_train': 31, 'weight_decay': 0.01730056873382732}"}}
exception: None

01:27:25 job_callback for (4, 0, 20) started
01:27:25 DISPATCHER: Trying to submit another job.
01:27:25 job_callback for (4, 0, 20) got condition
01:27:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:27:25 done building a new model for budget 44.444444 based on 10/40 split
Best loss for this budget:-0.250669





01:27:25 HBMASTER: Trying to run another job!
01:27:25 job_callback for (4, 0, 20) finished
01:27:25 start sampling a new configuration.
01:27:25 done sampling a new configuration.
01:27:25 HBMASTER: schedule new run for iteration 4
01:27:25 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
01:27:25 HBMASTER: submitting job (4, 0, 21) to dispatcher
01:27:25 DISPATCHER: trying to submit job (4, 0, 21)
01:27:25 DISPATCHER: trying to notify the job_runner thread.
01:27:25 HBMASTER: job (4, 0, 21) submitted to dispatcher
01:27:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:27:25 DISPATCHER: Trying to submit another job.
01:27:25 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:27:25 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:27:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:27:25 WORKER: start processing job (4, 0, 21)
01:27:25 WORKER: args: ()
01:27:25 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 341, 'last_n_outputs': 10, 'leak_rate': 0.9996155582837447, 'lr': 0.006594248590777181, 'optimizer': 'SGD', 'sparsity': 0.7749325434071849, 'steps_to_train': 14, 'weight_decay': 0.01989216447573411}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:27:37 DISPATCHER: Starting worker discovery
01:27:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:27:37 DISPATCHER: Finished worker discovery
01:28:37 DISPATCHER: Starting worker discovery
01:28:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:28:37 DISPATCHER: Finished worker discovery
01:29:10 WORKER: done with job (4, 0, 21), trying to register it.
01:29:10 WORKER: registered result for job (4, 0, 21) with dispatcher
01:29:10 DISPATCHER: job (4, 0, 21) finished
01:29:10 DISPATCHER: register_result: lock acquired
01:29:10 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:29:10 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 341, 'last_n_outputs': 10, 'leak_rate': 0.9996155582837447, 'lr': 0.006594248590777181, 'optimizer': 'SGD', 'sparsity': 0.7749325434071849, 'steps_to_train': 14, 'weight_decay': 0.01989216447573411}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.16958484267579876, 'info': {'sick_no_sick': 0.16958484267579876, 'config': "{'batch_size': 64, 'hidden_dim': 341, 'last_n_outputs': 10, 'leak_rate': 0.9996155582837447, 'lr': 0.006594248590777181, 'optimizer': 'SGD', 'sparsity': 0.7749325434071849, 'steps_to_train': 14, 'weight_decay': 0.01989216447573411}"}}
exception: None

01:29:10 job_callback for (4, 0, 21) started
01:29:10 job_callback for (4, 0, 21) got condition
01:29:10 DISPATCHER: Trying to submit another job.
01:29:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:29:10 done building a new model for budget 44.444444 based on 10/41 split
Best loss for this budget:-0.250669





01:29:10 HBMASTER: Trying to run another job!
01:29:10 job_callback for (4, 0, 21) finished
01:29:10 start sampling a new configuration.
01:29:10 best_vector: [1, 0.53520727109766, 0.2793320281282356, 0.0964182527623388, 0.07121201880752906, 1, 0.4696929290302968, 0.1597168305198502, 0.3446821045029327], 0.015461953188604884, 1.4490200590104325, 0.022404680321768795
01:29:10 done sampling a new configuration.
01:29:10 HBMASTER: schedule new run for iteration 4
01:29:10 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
01:29:10 HBMASTER: submitting job (4, 0, 22) to dispatcher
01:29:10 DISPATCHER: trying to submit job (4, 0, 22)
01:29:10 DISPATCHER: trying to notify the job_runner thread.
01:29:10 HBMASTER: job (4, 0, 22) submitted to dispatcher
01:29:10 DISPATCHER: Trying to submit another job.
01:29:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:29:10 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:29:10 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:29:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:29:10 WORKER: start processing job (4, 0, 22)
01:29:10 WORKER: args: ()
01:29:10 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 628, 'last_n_outputs': 21, 'leak_rate': 0.7741045631905847, 'lr': 0.0013881104944886715, 'optimizer': 'SGD', 'sparsity': 0.8627263029672713, 'steps_to_train': 24, 'weight_decay': 0.028082887289450353}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:29:37 DISPATCHER: Starting worker discovery
01:29:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:29:37 DISPATCHER: Finished worker discovery
01:30:37 DISPATCHER: Starting worker discovery
01:30:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:30:37 DISPATCHER: Finished worker discovery
01:30:59 WORKER: done with job (4, 0, 22), trying to register it.
01:30:59 WORKER: registered result for job (4, 0, 22) with dispatcher
01:30:59 DISPATCHER: job (4, 0, 22) finished
01:30:59 DISPATCHER: register_result: lock acquired
01:30:59 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:30:59 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 628, 'last_n_outputs': 21, 'leak_rate': 0.7741045631905847, 'lr': 0.0013881104944886715, 'optimizer': 'SGD', 'sparsity': 0.8627263029672713, 'steps_to_train': 24, 'weight_decay': 0.028082887289450353}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2399720549469272, 'info': {'sick_no_sick': 0.2399720549469272, 'config': "{'batch_size': 32, 'hidden_dim': 628, 'last_n_outputs': 21, 'leak_rate': 0.7741045631905847, 'lr': 0.0013881104944886715, 'optimizer': 'SGD', 'sparsity': 0.8627263029672713, 'steps_to_train': 24, 'weight_decay': 0.028082887289450353}"}}
exception: None

01:30:59 job_callback for (4, 0, 22) started
01:30:59 DISPATCHER: Trying to submit another job.
01:30:59 job_callback for (4, 0, 22) got condition
01:30:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:30:59 done building a new model for budget 44.444444 based on 10/42 split
Best loss for this budget:-0.250669





01:30:59 HBMASTER: Trying to run another job!
01:30:59 job_callback for (4, 0, 22) finished
01:30:59 start sampling a new configuration.
01:30:59 done sampling a new configuration.
01:30:59 HBMASTER: schedule new run for iteration 4
01:30:59 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
01:30:59 HBMASTER: submitting job (4, 0, 23) to dispatcher
01:30:59 DISPATCHER: trying to submit job (4, 0, 23)
01:30:59 DISPATCHER: trying to notify the job_runner thread.
01:30:59 HBMASTER: job (4, 0, 23) submitted to dispatcher
01:30:59 DISPATCHER: Trying to submit another job.
01:30:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:30:59 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:30:59 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:30:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:30:59 WORKER: start processing job (4, 0, 23)
01:30:59 WORKER: args: ()
01:30:59 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 759, 'last_n_outputs': 45, 'leak_rate': 0.8627667792270187, 'lr': 0.004850578851988586, 'optimizer': 'SGD', 'sparsity': 0.8173036513403479, 'steps_to_train': 96, 'weight_decay': 0.017853595967431826}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:31:37 DISPATCHER: Starting worker discovery
01:31:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:31:37 DISPATCHER: Finished worker discovery
01:32:37 DISPATCHER: Starting worker discovery
01:32:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:32:37 DISPATCHER: Finished worker discovery
01:32:46 WORKER: done with job (4, 0, 23), trying to register it.
01:32:46 WORKER: registered result for job (4, 0, 23) with dispatcher
01:32:46 DISPATCHER: job (4, 0, 23) finished
01:32:46 DISPATCHER: register_result: lock acquired
01:32:46 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:32:46 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 759, 'last_n_outputs': 45, 'leak_rate': 0.8627667792270187, 'lr': 0.004850578851988586, 'optimizer': 'SGD', 'sparsity': 0.8173036513403479, 'steps_to_train': 96, 'weight_decay': 0.017853595967431826}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.14105994294783192, 'info': {'sick_no_sick': 0.14105994294783192, 'config': "{'batch_size': 128, 'hidden_dim': 759, 'last_n_outputs': 45, 'leak_rate': 0.8627667792270187, 'lr': 0.004850578851988586, 'optimizer': 'SGD', 'sparsity': 0.8173036513403479, 'steps_to_train': 96, 'weight_decay': 0.017853595967431826}"}}
exception: None

01:32:46 job_callback for (4, 0, 23) started
01:32:46 DISPATCHER: Trying to submit another job.
01:32:46 job_callback for (4, 0, 23) got condition
01:32:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:32:46 done building a new model for budget 44.444444 based on 10/43 split
Best loss for this budget:-0.250669





01:32:46 HBMASTER: Trying to run another job!
01:32:46 job_callback for (4, 0, 23) finished
01:32:46 start sampling a new configuration.
01:32:46 done sampling a new configuration.
01:32:46 HBMASTER: schedule new run for iteration 4
01:32:46 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
01:32:46 HBMASTER: submitting job (4, 0, 24) to dispatcher
01:32:46 DISPATCHER: trying to submit job (4, 0, 24)
01:32:46 DISPATCHER: trying to notify the job_runner thread.
01:32:46 HBMASTER: job (4, 0, 24) submitted to dispatcher
01:32:46 DISPATCHER: Trying to submit another job.
01:32:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:32:46 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:32:46 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:32:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:32:46 WORKER: start processing job (4, 0, 24)
01:32:46 WORKER: args: ()
01:32:46 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 980, 'last_n_outputs': 47, 'leak_rate': 0.8129161624445168, 'lr': 0.012741723693076376, 'optimizer': 'SGD', 'sparsity': 0.8305980202241721, 'steps_to_train': 50, 'weight_decay': 0.09812651017153913}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:33:37 DISPATCHER: Starting worker discovery
01:33:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:33:37 DISPATCHER: Finished worker discovery
01:34:33 WORKER: done with job (4, 0, 24), trying to register it.
01:34:33 WORKER: registered result for job (4, 0, 24) with dispatcher
01:34:33 DISPATCHER: job (4, 0, 24) finished
01:34:33 DISPATCHER: register_result: lock acquired
01:34:33 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:34:33 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 980, 'last_n_outputs': 47, 'leak_rate': 0.8129161624445168, 'lr': 0.012741723693076376, 'optimizer': 'SGD', 'sparsity': 0.8305980202241721, 'steps_to_train': 50, 'weight_decay': 0.09812651017153913}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0001895147047367672, 'info': {'sick_no_sick': 0.0001895147047367672, 'config': "{'batch_size': 128, 'hidden_dim': 980, 'last_n_outputs': 47, 'leak_rate': 0.8129161624445168, 'lr': 0.012741723693076376, 'optimizer': 'SGD', 'sparsity': 0.8305980202241721, 'steps_to_train': 50, 'weight_decay': 0.09812651017153913}"}}
exception: None

01:34:33 job_callback for (4, 0, 24) started
01:34:33 job_callback for (4, 0, 24) got condition
01:34:33 DISPATCHER: Trying to submit another job.
01:34:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:34:33 done building a new model for budget 44.444444 based on 10/44 split
Best loss for this budget:-0.250669





01:34:33 HBMASTER: Trying to run another job!
01:34:33 job_callback for (4, 0, 24) finished
01:34:33 start sampling a new configuration.
01:34:33 best_vector: [2, 0.297621904668797, 0.21558016173241956, 0.06161184141610775, 0.0028667474566083373, 1, 0.5412768275548843, 0.2706418169843442, 0.46182301588236446], 0.013353286069840526, 1.0027709137316645, 0.013390286873574292
01:34:33 done sampling a new configuration.
01:34:33 HBMASTER: schedule new run for iteration 4
01:34:33 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
01:34:33 HBMASTER: submitting job (4, 0, 25) to dispatcher
01:34:33 DISPATCHER: trying to submit job (4, 0, 25)
01:34:33 DISPATCHER: trying to notify the job_runner thread.
01:34:33 HBMASTER: job (4, 0, 25) submitted to dispatcher
01:34:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:34:33 DISPATCHER: Trying to submit another job.
01:34:33 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:34:33 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:34:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:34:33 WORKER: start processing job (4, 0, 25)
01:34:33 WORKER: args: ()
01:34:33 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 438, 'last_n_outputs': 18, 'leak_rate': 0.7654029603540269, 'lr': 0.0010132893892296805, 'optimizer': 'SGD', 'sparsity': 0.8799064386131722, 'steps_to_train': 34, 'weight_decay': 0.039888306323532526}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:34:37 DISPATCHER: Starting worker discovery
01:34:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:34:37 DISPATCHER: Finished worker discovery
01:35:37 DISPATCHER: Starting worker discovery
01:35:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:35:37 DISPATCHER: Finished worker discovery
01:36:22 WORKER: done with job (4, 0, 25), trying to register it.
01:36:22 WORKER: registered result for job (4, 0, 25) with dispatcher
01:36:22 DISPATCHER: job (4, 0, 25) finished
01:36:22 DISPATCHER: register_result: lock acquired
01:36:22 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:36:22 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 438, 'last_n_outputs': 18, 'leak_rate': 0.7654029603540269, 'lr': 0.0010132893892296805, 'optimizer': 'SGD', 'sparsity': 0.8799064386131722, 'steps_to_train': 34, 'weight_decay': 0.039888306323532526}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.14204666700002883, 'info': {'sick_no_sick': 0.14204666700002883, 'config': "{'batch_size': 64, 'hidden_dim': 438, 'last_n_outputs': 18, 'leak_rate': 0.7654029603540269, 'lr': 0.0010132893892296805, 'optimizer': 'SGD', 'sparsity': 0.8799064386131722, 'steps_to_train': 34, 'weight_decay': 0.039888306323532526}"}}
exception: None

01:36:22 job_callback for (4, 0, 25) started
01:36:22 DISPATCHER: Trying to submit another job.
01:36:22 job_callback for (4, 0, 25) got condition
01:36:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:36:22 done building a new model for budget 44.444444 based on 10/45 split
Best loss for this budget:-0.250669





01:36:22 HBMASTER: Trying to run another job!
01:36:22 job_callback for (4, 0, 25) finished
01:36:22 start sampling a new configuration.
01:36:22 done sampling a new configuration.
01:36:22 HBMASTER: schedule new run for iteration 4
01:36:22 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
01:36:22 HBMASTER: submitting job (4, 0, 26) to dispatcher
01:36:22 DISPATCHER: trying to submit job (4, 0, 26)
01:36:22 DISPATCHER: trying to notify the job_runner thread.
01:36:22 HBMASTER: job (4, 0, 26) submitted to dispatcher
01:36:22 DISPATCHER: Trying to submit another job.
01:36:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:36:22 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:36:22 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:36:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:36:22 WORKER: start processing job (4, 0, 26)
01:36:22 WORKER: args: ()
01:36:22 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 732, 'last_n_outputs': 26, 'leak_rate': 0.7689110530989925, 'lr': 0.03246017983576814, 'optimizer': 'SGD', 'sparsity': 0.9240782903601159, 'steps_to_train': 55, 'weight_decay': 0.02336334920451017}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:36:37 DISPATCHER: Starting worker discovery
01:36:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:36:37 DISPATCHER: Finished worker discovery
01:37:37 DISPATCHER: Starting worker discovery
01:37:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:37:37 DISPATCHER: Finished worker discovery
01:38:10 WORKER: done with job (4, 0, 26), trying to register it.
01:38:10 WORKER: registered result for job (4, 0, 26) with dispatcher
01:38:10 DISPATCHER: job (4, 0, 26) finished
01:38:10 DISPATCHER: register_result: lock acquired
01:38:10 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:38:10 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 732, 'last_n_outputs': 26, 'leak_rate': 0.7689110530989925, 'lr': 0.03246017983576814, 'optimizer': 'SGD', 'sparsity': 0.9240782903601159, 'steps_to_train': 55, 'weight_decay': 0.02336334920451017}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.012187247819167833, 'info': {'sick_no_sick': 0.012187247819167833, 'config': "{'batch_size': 128, 'hidden_dim': 732, 'last_n_outputs': 26, 'leak_rate': 0.7689110530989925, 'lr': 0.03246017983576814, 'optimizer': 'SGD', 'sparsity': 0.9240782903601159, 'steps_to_train': 55, 'weight_decay': 0.02336334920451017}"}}
exception: None

01:38:10 job_callback for (4, 0, 26) started
01:38:10 job_callback for (4, 0, 26) got condition
01:38:10 DISPATCHER: Trying to submit another job.
01:38:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:38:10 done building a new model for budget 44.444444 based on 10/45 split
Best loss for this budget:-0.250669





01:38:10 HBMASTER: Trying to run another job!
01:38:10 job_callback for (4, 0, 26) finished
01:38:10 ITERATION: Advancing config (4, 0, 0) to next budget 133.333333
01:38:10 ITERATION: Advancing config (4, 0, 1) to next budget 133.333333
01:38:10 ITERATION: Advancing config (4, 0, 8) to next budget 133.333333
01:38:10 ITERATION: Advancing config (4, 0, 11) to next budget 133.333333
01:38:10 ITERATION: Advancing config (4, 0, 12) to next budget 133.333333
01:38:10 ITERATION: Advancing config (4, 0, 13) to next budget 133.333333
01:38:10 ITERATION: Advancing config (4, 0, 19) to next budget 133.333333
01:38:10 ITERATION: Advancing config (4, 0, 20) to next budget 133.333333
01:38:10 ITERATION: Advancing config (4, 0, 22) to next budget 133.333333
01:38:10 HBMASTER: schedule new run for iteration 4
01:38:10 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
01:38:10 HBMASTER: submitting job (4, 0, 0) to dispatcher
01:38:10 DISPATCHER: trying to submit job (4, 0, 0)
01:38:10 DISPATCHER: trying to notify the job_runner thread.
01:38:10 HBMASTER: job (4, 0, 0) submitted to dispatcher
01:38:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:38:10 DISPATCHER: Trying to submit another job.
01:38:10 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:38:10 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:38:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:38:10 WORKER: start processing job (4, 0, 0)
01:38:10 WORKER: args: ()
01:38:10 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 743, 'last_n_outputs': 13, 'leak_rate': 0.813806288811964, 'lr': 0.005315157157747162, 'optimizer': 'SGD', 'sparsity': 0.7618154624928459, 'steps_to_train': 100, 'weight_decay': 0.01095261809141746}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:38:37 DISPATCHER: Starting worker discovery
01:38:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:38:37 DISPATCHER: Finished worker discovery
01:39:37 DISPATCHER: Starting worker discovery
01:39:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:39:37 DISPATCHER: Finished worker discovery
01:40:37 DISPATCHER: Starting worker discovery
01:40:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:40:37 DISPATCHER: Finished worker discovery
01:41:27 WORKER: done with job (4, 0, 0), trying to register it.
01:41:27 WORKER: registered result for job (4, 0, 0) with dispatcher
01:41:27 DISPATCHER: job (4, 0, 0) finished
01:41:27 DISPATCHER: register_result: lock acquired
01:41:27 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:41:27 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 743, 'last_n_outputs': 13, 'leak_rate': 0.813806288811964, 'lr': 0.005315157157747162, 'optimizer': 'SGD', 'sparsity': 0.7618154624928459, 'steps_to_train': 100, 'weight_decay': 0.01095261809141746}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0936556453958182, 'info': {'sick_no_sick': 0.0936556453958182, 'config': "{'batch_size': 128, 'hidden_dim': 743, 'last_n_outputs': 13, 'leak_rate': 0.813806288811964, 'lr': 0.005315157157747162, 'optimizer': 'SGD', 'sparsity': 0.7618154624928459, 'steps_to_train': 100, 'weight_decay': 0.01095261809141746}"}}
exception: None

01:41:27 job_callback for (4, 0, 0) started
01:41:27 job_callback for (4, 0, 0) got condition
01:41:27 DISPATCHER: Trying to submit another job.
01:41:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:41:27 HBMASTER: Trying to run another job!
01:41:27 job_callback for (4, 0, 0) finished
01:41:27 HBMASTER: schedule new run for iteration 4
01:41:27 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
01:41:27 HBMASTER: submitting job (4, 0, 1) to dispatcher
01:41:27 DISPATCHER: trying to submit job (4, 0, 1)
01:41:27 DISPATCHER: trying to notify the job_runner thread.
01:41:27 HBMASTER: job (4, 0, 1) submitted to dispatcher
01:41:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:41:27 DISPATCHER: Trying to submit another job.
01:41:27 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:41:27 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:41:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:41:27 WORKER: start processing job (4, 0, 1)
01:41:27 WORKER: args: ()
01:41:27 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 973, 'last_n_outputs': 13, 'leak_rate': 0.9726263389068501, 'lr': 0.008017699085751874, 'optimizer': 'Adam', 'sparsity': 0.7662864361193223, 'steps_to_train': 23, 'weight_decay': 0.011619259901505955}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:41:37 DISPATCHER: Starting worker discovery
01:41:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:41:37 DISPATCHER: Finished worker discovery
01:42:37 DISPATCHER: Starting worker discovery
01:42:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:42:37 DISPATCHER: Finished worker discovery
01:43:37 DISPATCHER: Starting worker discovery
01:43:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:43:37 DISPATCHER: Finished worker discovery
01:44:37 DISPATCHER: Starting worker discovery
01:44:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:44:37 DISPATCHER: Finished worker discovery
01:44:44 WORKER: done with job (4, 0, 1), trying to register it.
01:44:44 WORKER: registered result for job (4, 0, 1) with dispatcher
01:44:44 DISPATCHER: job (4, 0, 1) finished
01:44:44 DISPATCHER: register_result: lock acquired
01:44:44 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:44:44 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 973, 'last_n_outputs': 13, 'leak_rate': 0.9726263389068501, 'lr': 0.008017699085751874, 'optimizer': 'Adam', 'sparsity': 0.7662864361193223, 'steps_to_train': 23, 'weight_decay': 0.011619259901505955}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1389853441305475, 'info': {'sick_no_sick': 0.1389853441305475, 'config': "{'batch_size': 32, 'hidden_dim': 973, 'last_n_outputs': 13, 'leak_rate': 0.9726263389068501, 'lr': 0.008017699085751874, 'optimizer': 'Adam', 'sparsity': 0.7662864361193223, 'steps_to_train': 23, 'weight_decay': 0.011619259901505955}"}}
exception: None

01:44:44 job_callback for (4, 0, 1) started
01:44:44 job_callback for (4, 0, 1) got condition
01:44:44 DISPATCHER: Trying to submit another job.
01:44:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:44:44 done building a new model for budget 133.333333 based on 10/17 split
Best loss for this budget:-0.221690





01:44:44 HBMASTER: Trying to run another job!
01:44:44 job_callback for (4, 0, 1) finished
01:44:44 HBMASTER: schedule new run for iteration 4
01:44:44 HBMASTER: trying submitting job (4, 0, 8) to dispatcher
01:44:44 HBMASTER: submitting job (4, 0, 8) to dispatcher
01:44:44 DISPATCHER: trying to submit job (4, 0, 8)
01:44:44 DISPATCHER: trying to notify the job_runner thread.
01:44:44 HBMASTER: job (4, 0, 8) submitted to dispatcher
01:44:44 DISPATCHER: Trying to submit another job.
01:44:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:44:44 DISPATCHER: starting job (4, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:44:44 DISPATCHER: job (4, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:44:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:44:44 WORKER: start processing job (4, 0, 8)
01:44:44 WORKER: args: ()
01:44:44 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 350, 'last_n_outputs': 24, 'leak_rate': 0.9693203546741699, 'lr': 0.0017069142363559566, 'optimizer': 'SGD', 'sparsity': 0.9004635425848556, 'steps_to_train': 37, 'weight_decay': 0.011230052487940984}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:45:37 DISPATCHER: Starting worker discovery
01:45:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:45:37 DISPATCHER: Finished worker discovery
01:46:37 DISPATCHER: Starting worker discovery
01:46:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:46:37 DISPATCHER: Finished worker discovery
01:47:37 DISPATCHER: Starting worker discovery
01:47:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:47:37 DISPATCHER: Finished worker discovery
01:48:02 WORKER: done with job (4, 0, 8), trying to register it.
01:48:02 WORKER: registered result for job (4, 0, 8) with dispatcher
01:48:02 DISPATCHER: job (4, 0, 8) finished
01:48:02 DISPATCHER: register_result: lock acquired
01:48:02 DISPATCHER: job (4, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:48:02 job_id: (4, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 350, 'last_n_outputs': 24, 'leak_rate': 0.9693203546741699, 'lr': 0.0017069142363559566, 'optimizer': 'SGD', 'sparsity': 0.9004635425848556, 'steps_to_train': 37, 'weight_decay': 0.011230052487940984}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.213697090702565, 'info': {'sick_no_sick': 0.213697090702565, 'config': "{'batch_size': 16, 'hidden_dim': 350, 'last_n_outputs': 24, 'leak_rate': 0.9693203546741699, 'lr': 0.0017069142363559566, 'optimizer': 'SGD', 'sparsity': 0.9004635425848556, 'steps_to_train': 37, 'weight_decay': 0.011230052487940984}"}}
exception: None

01:48:02 job_callback for (4, 0, 8) started
01:48:02 job_callback for (4, 0, 8) got condition
01:48:02 DISPATCHER: Trying to submit another job.
01:48:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:48:02 done building a new model for budget 133.333333 based on 10/17 split
Best loss for this budget:-0.221690





01:48:02 HBMASTER: Trying to run another job!
01:48:02 job_callback for (4, 0, 8) finished
01:48:02 HBMASTER: schedule new run for iteration 4
01:48:02 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
01:48:02 HBMASTER: submitting job (4, 0, 11) to dispatcher
01:48:02 DISPATCHER: trying to submit job (4, 0, 11)
01:48:02 DISPATCHER: trying to notify the job_runner thread.
01:48:02 HBMASTER: job (4, 0, 11) submitted to dispatcher
01:48:02 DISPATCHER: Trying to submit another job.
01:48:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:48:02 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:48:02 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:48:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:48:02 WORKER: start processing job (4, 0, 11)
01:48:02 WORKER: args: ()
01:48:02 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 375, 'last_n_outputs': 20, 'leak_rate': 0.8808183299435992, 'lr': 0.00236165487551652, 'optimizer': 'SGD', 'sparsity': 0.8980608424275263, 'steps_to_train': 26, 'weight_decay': 0.011339667122244086}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:48:37 DISPATCHER: Starting worker discovery
01:48:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:48:37 DISPATCHER: Finished worker discovery
01:49:37 DISPATCHER: Starting worker discovery
01:49:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:49:37 DISPATCHER: Finished worker discovery
01:50:37 DISPATCHER: Starting worker discovery
01:50:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:50:37 DISPATCHER: Finished worker discovery
01:51:19 WORKER: done with job (4, 0, 11), trying to register it.
01:51:19 WORKER: registered result for job (4, 0, 11) with dispatcher
01:51:19 DISPATCHER: job (4, 0, 11) finished
01:51:19 DISPATCHER: register_result: lock acquired
01:51:19 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:51:19 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 375, 'last_n_outputs': 20, 'leak_rate': 0.8808183299435992, 'lr': 0.00236165487551652, 'optimizer': 'SGD', 'sparsity': 0.8980608424275263, 'steps_to_train': 26, 'weight_decay': 0.011339667122244086}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.04592109589140697, 'info': {'sick_no_sick': 0.04592109589140697, 'config': "{'batch_size': 32, 'hidden_dim': 375, 'last_n_outputs': 20, 'leak_rate': 0.8808183299435992, 'lr': 0.00236165487551652, 'optimizer': 'SGD', 'sparsity': 0.8980608424275263, 'steps_to_train': 26, 'weight_decay': 0.011339667122244086}"}}
exception: None

01:51:19 job_callback for (4, 0, 11) started
01:51:19 DISPATCHER: Trying to submit another job.
01:51:19 job_callback for (4, 0, 11) got condition
01:51:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:51:19 done building a new model for budget 133.333333 based on 10/18 split
Best loss for this budget:-0.221690





01:51:19 HBMASTER: Trying to run another job!
01:51:19 job_callback for (4, 0, 11) finished
01:51:19 HBMASTER: schedule new run for iteration 4
01:51:19 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
01:51:19 HBMASTER: submitting job (4, 0, 12) to dispatcher
01:51:19 DISPATCHER: trying to submit job (4, 0, 12)
01:51:19 DISPATCHER: trying to notify the job_runner thread.
01:51:19 HBMASTER: job (4, 0, 12) submitted to dispatcher
01:51:19 DISPATCHER: Trying to submit another job.
01:51:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:51:19 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:51:19 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:51:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:51:19 WORKER: start processing job (4, 0, 12)
01:51:19 WORKER: args: ()
01:51:19 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 753, 'last_n_outputs': 30, 'leak_rate': 0.7537047953126679, 'lr': 0.0017170880938444503, 'optimizer': 'SGD', 'sparsity': 0.8672160392791941, 'steps_to_train': 30, 'weight_decay': 0.028035550590148027}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:51:37 DISPATCHER: Starting worker discovery
01:51:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:51:37 DISPATCHER: Finished worker discovery
01:52:37 DISPATCHER: Starting worker discovery
01:52:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:52:37 DISPATCHER: Finished worker discovery
01:53:37 DISPATCHER: Starting worker discovery
01:53:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:53:37 DISPATCHER: Finished worker discovery
01:54:36 WORKER: done with job (4, 0, 12), trying to register it.
01:54:36 WORKER: registered result for job (4, 0, 12) with dispatcher
01:54:36 DISPATCHER: job (4, 0, 12) finished
01:54:36 DISPATCHER: register_result: lock acquired
01:54:36 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:54:36 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 753, 'last_n_outputs': 30, 'leak_rate': 0.7537047953126679, 'lr': 0.0017170880938444503, 'optimizer': 'SGD', 'sparsity': 0.8672160392791941, 'steps_to_train': 30, 'weight_decay': 0.028035550590148027}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.016961886505135637, 'info': {'sick_no_sick': 0.016961886505135637, 'config': "{'batch_size': 16, 'hidden_dim': 753, 'last_n_outputs': 30, 'leak_rate': 0.7537047953126679, 'lr': 0.0017170880938444503, 'optimizer': 'SGD', 'sparsity': 0.8672160392791941, 'steps_to_train': 30, 'weight_decay': 0.028035550590148027}"}}
exception: None

01:54:36 job_callback for (4, 0, 12) started
01:54:36 job_callback for (4, 0, 12) got condition
01:54:36 DISPATCHER: Trying to submit another job.
01:54:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:54:36 done building a new model for budget 133.333333 based on 10/19 split
Best loss for this budget:-0.221690





01:54:36 HBMASTER: Trying to run another job!
01:54:36 job_callback for (4, 0, 12) finished
01:54:36 HBMASTER: schedule new run for iteration 4
01:54:36 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
01:54:36 HBMASTER: submitting job (4, 0, 13) to dispatcher
01:54:36 DISPATCHER: trying to submit job (4, 0, 13)
01:54:36 DISPATCHER: trying to notify the job_runner thread.
01:54:36 HBMASTER: job (4, 0, 13) submitted to dispatcher
01:54:36 DISPATCHER: Trying to submit another job.
01:54:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:54:36 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:54:36 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:54:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:54:36 WORKER: start processing job (4, 0, 13)
01:54:36 WORKER: args: ()
01:54:36 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 781, 'last_n_outputs': 13, 'leak_rate': 0.7852220926476179, 'lr': 0.002036816420885702, 'optimizer': 'SGD', 'sparsity': 0.888935105171489, 'steps_to_train': 49, 'weight_decay': 0.02793255008284639}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:54:37 DISPATCHER: Starting worker discovery
01:54:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:54:37 DISPATCHER: Finished worker discovery
01:55:37 DISPATCHER: Starting worker discovery
01:55:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:55:37 DISPATCHER: Finished worker discovery
01:56:37 DISPATCHER: Starting worker discovery
01:56:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:56:37 DISPATCHER: Finished worker discovery
01:57:37 DISPATCHER: Starting worker discovery
01:57:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:57:37 DISPATCHER: Finished worker discovery
01:57:51 WORKER: done with job (4, 0, 13), trying to register it.
01:57:51 WORKER: registered result for job (4, 0, 13) with dispatcher
01:57:51 DISPATCHER: job (4, 0, 13) finished
01:57:51 DISPATCHER: register_result: lock acquired
01:57:51 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:57:51 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 781, 'last_n_outputs': 13, 'leak_rate': 0.7852220926476179, 'lr': 0.002036816420885702, 'optimizer': 'SGD', 'sparsity': 0.888935105171489, 'steps_to_train': 49, 'weight_decay': 0.02793255008284639}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.20378040742821046, 'info': {'sick_no_sick': 0.20378040742821046, 'config': "{'batch_size': 64, 'hidden_dim': 781, 'last_n_outputs': 13, 'leak_rate': 0.7852220926476179, 'lr': 0.002036816420885702, 'optimizer': 'SGD', 'sparsity': 0.888935105171489, 'steps_to_train': 49, 'weight_decay': 0.02793255008284639}"}}
exception: None

01:57:51 job_callback for (4, 0, 13) started
01:57:51 DISPATCHER: Trying to submit another job.
01:57:51 job_callback for (4, 0, 13) got condition
01:57:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:57:51 done building a new model for budget 133.333333 based on 10/20 split
Best loss for this budget:-0.221690





01:57:51 HBMASTER: Trying to run another job!
01:57:51 job_callback for (4, 0, 13) finished
01:57:51 HBMASTER: schedule new run for iteration 4
01:57:51 HBMASTER: trying submitting job (4, 0, 19) to dispatcher
01:57:51 HBMASTER: submitting job (4, 0, 19) to dispatcher
01:57:51 DISPATCHER: trying to submit job (4, 0, 19)
01:57:51 DISPATCHER: trying to notify the job_runner thread.
01:57:51 HBMASTER: job (4, 0, 19) submitted to dispatcher
01:57:51 DISPATCHER: Trying to submit another job.
01:57:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:57:51 DISPATCHER: starting job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:57:51 DISPATCHER: job (4, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:57:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:57:51 WORKER: start processing job (4, 0, 19)
01:57:51 WORKER: args: ()
01:57:51 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 253, 'last_n_outputs': 26, 'leak_rate': 0.9709614674751438, 'lr': 0.0013673839003411504, 'optimizer': 'SGD', 'sparsity': 0.8780582601643923, 'steps_to_train': 42, 'weight_decay': 0.037979185312866245}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:58:37 DISPATCHER: Starting worker discovery
01:58:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:58:37 DISPATCHER: Finished worker discovery
01:59:37 DISPATCHER: Starting worker discovery
01:59:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:59:37 DISPATCHER: Finished worker discovery
02:00:37 DISPATCHER: Starting worker discovery
02:00:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:00:37 DISPATCHER: Finished worker discovery
02:01:08 WORKER: done with job (4, 0, 19), trying to register it.
02:01:08 WORKER: registered result for job (4, 0, 19) with dispatcher
02:01:08 DISPATCHER: job (4, 0, 19) finished
02:01:08 DISPATCHER: register_result: lock acquired
02:01:08 DISPATCHER: job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:01:08 job_id: (4, 0, 19)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 253, 'last_n_outputs': 26, 'leak_rate': 0.9709614674751438, 'lr': 0.0013673839003411504, 'optimizer': 'SGD', 'sparsity': 0.8780582601643923, 'steps_to_train': 42, 'weight_decay': 0.037979185312866245}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.12043030222784903, 'info': {'sick_no_sick': 0.12043030222784903, 'config': "{'batch_size': 32, 'hidden_dim': 253, 'last_n_outputs': 26, 'leak_rate': 0.9709614674751438, 'lr': 0.0013673839003411504, 'optimizer': 'SGD', 'sparsity': 0.8780582601643923, 'steps_to_train': 42, 'weight_decay': 0.037979185312866245}"}}
exception: None

02:01:08 job_callback for (4, 0, 19) started
02:01:08 DISPATCHER: Trying to submit another job.
02:01:08 job_callback for (4, 0, 19) got condition
02:01:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:01:08 done building a new model for budget 133.333333 based on 10/21 split
Best loss for this budget:-0.221690





02:01:08 HBMASTER: Trying to run another job!
02:01:08 job_callback for (4, 0, 19) finished
02:01:08 HBMASTER: schedule new run for iteration 4
02:01:08 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
02:01:08 HBMASTER: submitting job (4, 0, 20) to dispatcher
02:01:08 DISPATCHER: trying to submit job (4, 0, 20)
02:01:08 DISPATCHER: trying to notify the job_runner thread.
02:01:08 HBMASTER: job (4, 0, 20) submitted to dispatcher
02:01:08 DISPATCHER: Trying to submit another job.
02:01:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:01:08 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:01:08 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:01:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:01:08 WORKER: start processing job (4, 0, 20)
02:01:08 WORKER: args: ()
02:01:08 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 669, 'last_n_outputs': 41, 'leak_rate': 0.8655890296358637, 'lr': 0.01783327422429548, 'optimizer': 'SGD', 'sparsity': 0.9683299694954844, 'steps_to_train': 31, 'weight_decay': 0.01730056873382732}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:01:37 DISPATCHER: Starting worker discovery
02:01:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:01:37 DISPATCHER: Finished worker discovery
02:02:37 DISPATCHER: Starting worker discovery
02:02:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:02:37 DISPATCHER: Finished worker discovery
02:03:37 DISPATCHER: Starting worker discovery
02:03:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:03:37 DISPATCHER: Finished worker discovery
02:04:23 WORKER: done with job (4, 0, 20), trying to register it.
02:04:23 WORKER: registered result for job (4, 0, 20) with dispatcher
02:04:23 DISPATCHER: job (4, 0, 20) finished
02:04:23 DISPATCHER: register_result: lock acquired
02:04:23 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:04:23 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 669, 'last_n_outputs': 41, 'leak_rate': 0.8655890296358637, 'lr': 0.01783327422429548, 'optimizer': 'SGD', 'sparsity': 0.9683299694954844, 'steps_to_train': 31, 'weight_decay': 0.01730056873382732}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.02017093373611375, 'info': {'sick_no_sick': 0.02017093373611375, 'config': "{'batch_size': 64, 'hidden_dim': 669, 'last_n_outputs': 41, 'leak_rate': 0.8655890296358637, 'lr': 0.01783327422429548, 'optimizer': 'SGD', 'sparsity': 0.9683299694954844, 'steps_to_train': 31, 'weight_decay': 0.01730056873382732}"}}
exception: None

02:04:23 job_callback for (4, 0, 20) started
02:04:23 DISPATCHER: Trying to submit another job.
02:04:23 job_callback for (4, 0, 20) got condition
02:04:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:04:23 done building a new model for budget 133.333333 based on 10/22 split
Best loss for this budget:-0.221690





02:04:23 HBMASTER: Trying to run another job!
02:04:23 job_callback for (4, 0, 20) finished
02:04:23 HBMASTER: schedule new run for iteration 4
02:04:23 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
02:04:23 HBMASTER: submitting job (4, 0, 22) to dispatcher
02:04:23 DISPATCHER: trying to submit job (4, 0, 22)
02:04:23 DISPATCHER: trying to notify the job_runner thread.
02:04:23 HBMASTER: job (4, 0, 22) submitted to dispatcher
02:04:23 DISPATCHER: Trying to submit another job.
02:04:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:04:23 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:04:23 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:04:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:04:23 WORKER: start processing job (4, 0, 22)
02:04:23 WORKER: args: ()
02:04:23 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 628, 'last_n_outputs': 21, 'leak_rate': 0.7741045631905847, 'lr': 0.0013881104944886715, 'optimizer': 'SGD', 'sparsity': 0.8627263029672713, 'steps_to_train': 24, 'weight_decay': 0.028082887289450353}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:04:37 DISPATCHER: Starting worker discovery
02:04:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:04:37 DISPATCHER: Finished worker discovery
02:05:37 DISPATCHER: Starting worker discovery
02:05:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:05:37 DISPATCHER: Finished worker discovery
02:06:37 DISPATCHER: Starting worker discovery
02:06:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:06:37 DISPATCHER: Finished worker discovery
02:07:37 DISPATCHER: Starting worker discovery
02:07:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:07:37 DISPATCHER: Finished worker discovery
02:07:38 WORKER: done with job (4, 0, 22), trying to register it.
02:07:38 WORKER: registered result for job (4, 0, 22) with dispatcher
02:07:38 DISPATCHER: job (4, 0, 22) finished
02:07:38 DISPATCHER: register_result: lock acquired
02:07:38 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:07:38 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 628, 'last_n_outputs': 21, 'leak_rate': 0.7741045631905847, 'lr': 0.0013881104944886715, 'optimizer': 'SGD', 'sparsity': 0.8627263029672713, 'steps_to_train': 24, 'weight_decay': 0.028082887289450353}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1145417220013912, 'info': {'sick_no_sick': 0.1145417220013912, 'config': "{'batch_size': 32, 'hidden_dim': 628, 'last_n_outputs': 21, 'leak_rate': 0.7741045631905847, 'lr': 0.0013881104944886715, 'optimizer': 'SGD', 'sparsity': 0.8627263029672713, 'steps_to_train': 24, 'weight_decay': 0.028082887289450353}"}}
exception: None

02:07:38 job_callback for (4, 0, 22) started
02:07:38 job_callback for (4, 0, 22) got condition
02:07:38 DISPATCHER: Trying to submit another job.
02:07:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:07:38 done building a new model for budget 133.333333 based on 10/22 split
Best loss for this budget:-0.221690





02:07:38 HBMASTER: Trying to run another job!
02:07:38 job_callback for (4, 0, 22) finished
02:07:38 ITERATION: Advancing config (4, 0, 1) to next budget 400.000000
02:07:38 ITERATION: Advancing config (4, 0, 8) to next budget 400.000000
02:07:38 ITERATION: Advancing config (4, 0, 13) to next budget 400.000000
02:07:38 HBMASTER: schedule new run for iteration 4
02:07:38 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
02:07:38 HBMASTER: submitting job (4, 0, 1) to dispatcher
02:07:38 DISPATCHER: trying to submit job (4, 0, 1)
02:07:38 DISPATCHER: trying to notify the job_runner thread.
02:07:38 HBMASTER: job (4, 0, 1) submitted to dispatcher
02:07:38 DISPATCHER: Trying to submit another job.
02:07:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:07:38 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:07:38 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:07:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:07:38 WORKER: start processing job (4, 0, 1)
02:07:38 WORKER: args: ()
02:07:38 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 973, 'last_n_outputs': 13, 'leak_rate': 0.9726263389068501, 'lr': 0.008017699085751874, 'optimizer': 'Adam', 'sparsity': 0.7662864361193223, 'steps_to_train': 23, 'weight_decay': 0.011619259901505955}, 'budget': 400.0, 'working_directory': '.'}
02:08:37 DISPATCHER: Starting worker discovery
02:08:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:08:37 DISPATCHER: Finished worker discovery
02:09:37 DISPATCHER: Starting worker discovery
02:09:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:09:37 DISPATCHER: Finished worker discovery
02:10:37 DISPATCHER: Starting worker discovery
02:10:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:10:37 DISPATCHER: Finished worker discovery
02:11:37 DISPATCHER: Starting worker discovery
02:11:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:11:37 DISPATCHER: Finished worker discovery
02:12:37 DISPATCHER: Starting worker discovery
02:12:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:12:37 DISPATCHER: Finished worker discovery
02:13:37 DISPATCHER: Starting worker discovery
02:13:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:13:37 DISPATCHER: Finished worker discovery
02:14:37 DISPATCHER: Starting worker discovery
02:14:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:14:37 DISPATCHER: Finished worker discovery
02:15:24 WORKER: done with job (4, 0, 1), trying to register it.
02:15:24 WORKER: registered result for job (4, 0, 1) with dispatcher
02:15:24 DISPATCHER: job (4, 0, 1) finished
02:15:24 DISPATCHER: register_result: lock acquired
02:15:24 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:15:24 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 973, 'last_n_outputs': 13, 'leak_rate': 0.9726263389068501, 'lr': 0.008017699085751874, 'optimizer': 'Adam', 'sparsity': 0.7662864361193223, 'steps_to_train': 23, 'weight_decay': 0.011619259901505955}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.20023338411711095, 'info': {'sick_no_sick': 0.20023338411711095, 'config': "{'batch_size': 32, 'hidden_dim': 973, 'last_n_outputs': 13, 'leak_rate': 0.9726263389068501, 'lr': 0.008017699085751874, 'optimizer': 'Adam', 'sparsity': 0.7662864361193223, 'steps_to_train': 23, 'weight_decay': 0.011619259901505955}"}}
exception: None

02:15:24 job_callback for (4, 0, 1) started
02:15:24 DISPATCHER: Trying to submit another job.
02:15:24 job_callback for (4, 0, 1) got condition
02:15:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:15:24 HBMASTER: Trying to run another job!
02:15:24 job_callback for (4, 0, 1) finished
02:15:24 HBMASTER: schedule new run for iteration 4
02:15:24 HBMASTER: trying submitting job (4, 0, 8) to dispatcher
02:15:24 HBMASTER: submitting job (4, 0, 8) to dispatcher
02:15:24 DISPATCHER: trying to submit job (4, 0, 8)
02:15:24 DISPATCHER: trying to notify the job_runner thread.
02:15:24 HBMASTER: job (4, 0, 8) submitted to dispatcher
02:15:24 DISPATCHER: Trying to submit another job.
02:15:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:15:24 DISPATCHER: starting job (4, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:15:24 DISPATCHER: job (4, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:15:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:15:24 WORKER: start processing job (4, 0, 8)
02:15:24 WORKER: args: ()
02:15:24 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 350, 'last_n_outputs': 24, 'leak_rate': 0.9693203546741699, 'lr': 0.0017069142363559566, 'optimizer': 'SGD', 'sparsity': 0.9004635425848556, 'steps_to_train': 37, 'weight_decay': 0.011230052487940984}, 'budget': 400.0, 'working_directory': '.'}
02:15:37 DISPATCHER: Starting worker discovery
02:15:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:15:37 DISPATCHER: Finished worker discovery
02:16:37 DISPATCHER: Starting worker discovery
02:16:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:16:37 DISPATCHER: Finished worker discovery
02:17:37 DISPATCHER: Starting worker discovery
02:17:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:17:37 DISPATCHER: Finished worker discovery
02:18:37 DISPATCHER: Starting worker discovery
02:18:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:18:37 DISPATCHER: Finished worker discovery
02:19:37 DISPATCHER: Starting worker discovery
02:19:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:19:37 DISPATCHER: Finished worker discovery
02:20:37 DISPATCHER: Starting worker discovery
02:20:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:20:37 DISPATCHER: Finished worker discovery
02:21:37 DISPATCHER: Starting worker discovery
02:21:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:21:37 DISPATCHER: Finished worker discovery
02:22:37 DISPATCHER: Starting worker discovery
02:22:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:22:37 DISPATCHER: Finished worker discovery
02:23:10 WORKER: done with job (4, 0, 8), trying to register it.
02:23:10 WORKER: registered result for job (4, 0, 8) with dispatcher
02:23:10 DISPATCHER: job (4, 0, 8) finished
02:23:10 DISPATCHER: register_result: lock acquired
02:23:10 DISPATCHER: job (4, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:23:10 job_id: (4, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 350, 'last_n_outputs': 24, 'leak_rate': 0.9693203546741699, 'lr': 0.0017069142363559566, 'optimizer': 'SGD', 'sparsity': 0.9004635425848556, 'steps_to_train': 37, 'weight_decay': 0.011230052487940984}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.1468739618774158, 'info': {'sick_no_sick': 0.1468739618774158, 'config': "{'batch_size': 16, 'hidden_dim': 350, 'last_n_outputs': 24, 'leak_rate': 0.9693203546741699, 'lr': 0.0017069142363559566, 'optimizer': 'SGD', 'sparsity': 0.9004635425848556, 'steps_to_train': 37, 'weight_decay': 0.011230052487940984}"}}
exception: None

02:23:10 job_callback for (4, 0, 8) started
02:23:10 DISPATCHER: Trying to submit another job.
02:23:10 job_callback for (4, 0, 8) got condition
02:23:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:23:10 HBMASTER: Trying to run another job!
02:23:10 job_callback for (4, 0, 8) finished
02:23:10 HBMASTER: schedule new run for iteration 4
02:23:10 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
02:23:10 HBMASTER: submitting job (4, 0, 13) to dispatcher
02:23:10 DISPATCHER: trying to submit job (4, 0, 13)
02:23:10 DISPATCHER: trying to notify the job_runner thread.
02:23:10 HBMASTER: job (4, 0, 13) submitted to dispatcher
02:23:10 DISPATCHER: Trying to submit another job.
02:23:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:23:10 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:23:10 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:23:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:23:10 WORKER: start processing job (4, 0, 13)
02:23:10 WORKER: args: ()
02:23:10 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 781, 'last_n_outputs': 13, 'leak_rate': 0.7852220926476179, 'lr': 0.002036816420885702, 'optimizer': 'SGD', 'sparsity': 0.888935105171489, 'steps_to_train': 49, 'weight_decay': 0.02793255008284639}, 'budget': 400.0, 'working_directory': '.'}
02:23:37 DISPATCHER: Starting worker discovery
02:23:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:23:37 DISPATCHER: Finished worker discovery
02:24:37 DISPATCHER: Starting worker discovery
02:24:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:24:37 DISPATCHER: Finished worker discovery
02:25:37 DISPATCHER: Starting worker discovery
02:25:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:25:37 DISPATCHER: Finished worker discovery
02:26:37 DISPATCHER: Starting worker discovery
02:26:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:26:37 DISPATCHER: Finished worker discovery
02:27:37 DISPATCHER: Starting worker discovery
02:27:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:27:37 DISPATCHER: Finished worker discovery
02:28:37 DISPATCHER: Starting worker discovery
02:28:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:28:37 DISPATCHER: Finished worker discovery
02:29:37 DISPATCHER: Starting worker discovery
02:29:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:29:37 DISPATCHER: Finished worker discovery
02:30:37 DISPATCHER: Starting worker discovery
02:30:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:30:37 DISPATCHER: Finished worker discovery
02:30:53 WORKER: done with job (4, 0, 13), trying to register it.
02:30:53 WORKER: registered result for job (4, 0, 13) with dispatcher
02:30:53 DISPATCHER: job (4, 0, 13) finished
02:30:53 DISPATCHER: register_result: lock acquired
02:30:53 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:30:53 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 781, 'last_n_outputs': 13, 'leak_rate': 0.7852220926476179, 'lr': 0.002036816420885702, 'optimizer': 'SGD', 'sparsity': 0.888935105171489, 'steps_to_train': 49, 'weight_decay': 0.02793255008284639}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.09775820758243477, 'info': {'sick_no_sick': 0.09775820758243477, 'config': "{'batch_size': 64, 'hidden_dim': 781, 'last_n_outputs': 13, 'leak_rate': 0.7852220926476179, 'lr': 0.002036816420885702, 'optimizer': 'SGD', 'sparsity': 0.888935105171489, 'steps_to_train': 49, 'weight_decay': 0.02793255008284639}"}}
exception: None

02:30:53 job_callback for (4, 0, 13) started
02:30:53 job_callback for (4, 0, 13) got condition
02:30:53 DISPATCHER: Trying to submit another job.
02:30:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:30:53 HBMASTER: Trying to run another job!
02:30:53 job_callback for (4, 0, 13) finished
02:30:53 ITERATION: Advancing config (4, 0, 1) to next budget 1200.000000
02:30:53 HBMASTER: schedule new run for iteration 4
02:30:53 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
02:30:53 HBMASTER: submitting job (4, 0, 1) to dispatcher
02:30:53 DISPATCHER: trying to submit job (4, 0, 1)
02:30:53 DISPATCHER: trying to notify the job_runner thread.
02:30:53 HBMASTER: job (4, 0, 1) submitted to dispatcher
02:30:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:30:53 DISPATCHER: Trying to submit another job.
02:30:53 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:30:53 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:30:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:30:53 WORKER: start processing job (4, 0, 1)
02:30:53 WORKER: args: ()
02:30:53 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 973, 'last_n_outputs': 13, 'leak_rate': 0.9726263389068501, 'lr': 0.008017699085751874, 'optimizer': 'Adam', 'sparsity': 0.7662864361193223, 'steps_to_train': 23, 'weight_decay': 0.011619259901505955}, 'budget': 1200.0, 'working_directory': '.'}
02:31:37 DISPATCHER: Starting worker discovery
02:31:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:31:37 DISPATCHER: Finished worker discovery
02:32:37 DISPATCHER: Starting worker discovery
02:32:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:32:37 DISPATCHER: Finished worker discovery
02:33:37 DISPATCHER: Starting worker discovery
02:33:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:33:37 DISPATCHER: Finished worker discovery
02:34:37 DISPATCHER: Starting worker discovery
02:34:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:34:37 DISPATCHER: Finished worker discovery
02:35:37 DISPATCHER: Starting worker discovery
02:35:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:35:37 DISPATCHER: Finished worker discovery
02:36:37 DISPATCHER: Starting worker discovery
02:36:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:36:37 DISPATCHER: Finished worker discovery
02:37:37 DISPATCHER: Starting worker discovery
02:37:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:37:37 DISPATCHER: Finished worker discovery
02:38:37 DISPATCHER: Starting worker discovery
02:38:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:38:37 DISPATCHER: Finished worker discovery
02:39:37 DISPATCHER: Starting worker discovery
02:39:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:39:37 DISPATCHER: Finished worker discovery
02:40:37 DISPATCHER: Starting worker discovery
02:40:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:40:37 DISPATCHER: Finished worker discovery
02:41:37 DISPATCHER: Starting worker discovery
02:41:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:41:37 DISPATCHER: Finished worker discovery
02:42:37 DISPATCHER: Starting worker discovery
02:42:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:42:37 DISPATCHER: Finished worker discovery
02:43:37 DISPATCHER: Starting worker discovery
02:43:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:43:37 DISPATCHER: Finished worker discovery
02:44:37 DISPATCHER: Starting worker discovery
02:44:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:44:37 DISPATCHER: Finished worker discovery
02:45:37 DISPATCHER: Starting worker discovery
02:45:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:45:37 DISPATCHER: Finished worker discovery
02:46:37 DISPATCHER: Starting worker discovery
02:46:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:46:37 DISPATCHER: Finished worker discovery
02:47:37 DISPATCHER: Starting worker discovery
02:47:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:47:37 DISPATCHER: Finished worker discovery
02:48:37 DISPATCHER: Starting worker discovery
02:48:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:48:37 DISPATCHER: Finished worker discovery
02:49:37 DISPATCHER: Starting worker discovery
02:49:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:49:37 DISPATCHER: Finished worker discovery
02:50:37 DISPATCHER: Starting worker discovery
02:50:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:50:37 DISPATCHER: Finished worker discovery
02:51:37 DISPATCHER: Starting worker discovery
02:51:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:51:37 DISPATCHER: Finished worker discovery
02:52:12 WORKER: done with job (4, 0, 1), trying to register it.
02:52:12 WORKER: registered result for job (4, 0, 1) with dispatcher
02:52:12 DISPATCHER: job (4, 0, 1) finished
02:52:12 DISPATCHER: register_result: lock acquired
02:52:12 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:52:12 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 973, 'last_n_outputs': 13, 'leak_rate': 0.9726263389068501, 'lr': 0.008017699085751874, 'optimizer': 'Adam', 'sparsity': 0.7662864361193223, 'steps_to_train': 23, 'weight_decay': 0.011619259901505955}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.17080666598232924, 'info': {'sick_no_sick': 0.17080666598232924, 'config': "{'batch_size': 32, 'hidden_dim': 973, 'last_n_outputs': 13, 'leak_rate': 0.9726263389068501, 'lr': 0.008017699085751874, 'optimizer': 'Adam', 'sparsity': 0.7662864361193223, 'steps_to_train': 23, 'weight_decay': 0.011619259901505955}"}}
exception: None

02:52:12 job_callback for (4, 0, 1) started
02:52:12 DISPATCHER: Trying to submit another job.
02:52:12 job_callback for (4, 0, 1) got condition
02:52:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:52:12 Only 9 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
02:52:12 HBMASTER: Trying to run another job!
02:52:12 job_callback for (4, 0, 1) finished
02:52:12 start sampling a new configuration.
02:52:12 done sampling a new configuration.
02:52:12 HBMASTER: schedule new run for iteration 5
02:52:12 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
02:52:12 HBMASTER: submitting job (5, 0, 0) to dispatcher
02:52:12 DISPATCHER: trying to submit job (5, 0, 0)
02:52:12 DISPATCHER: trying to notify the job_runner thread.
02:52:12 HBMASTER: job (5, 0, 0) submitted to dispatcher
02:52:12 DISPATCHER: Trying to submit another job.
02:52:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:52:12 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:52:12 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:52:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:52:12 WORKER: start processing job (5, 0, 0)
02:52:12 WORKER: args: ()
02:52:12 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 210, 'last_n_outputs': 43, 'leak_rate': 0.7566259737219866, 'lr': 0.044735334319059614, 'optimizer': 'Adam', 'sparsity': 0.8947508080443951, 'steps_to_train': 68, 'weight_decay': 0.023862100637330012}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:52:37 DISPATCHER: Starting worker discovery
02:52:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:52:37 DISPATCHER: Finished worker discovery
02:53:37 DISPATCHER: Starting worker discovery
02:53:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:53:37 DISPATCHER: Finished worker discovery
02:54:37 DISPATCHER: Starting worker discovery
02:54:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:54:37 DISPATCHER: Finished worker discovery
02:55:28 WORKER: done with job (5, 0, 0), trying to register it.
02:55:28 WORKER: registered result for job (5, 0, 0) with dispatcher
02:55:28 DISPATCHER: job (5, 0, 0) finished
02:55:28 DISPATCHER: register_result: lock acquired
02:55:28 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:55:28 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 210, 'last_n_outputs': 43, 'leak_rate': 0.7566259737219866, 'lr': 0.044735334319059614, 'optimizer': 'Adam', 'sparsity': 0.8947508080443951, 'steps_to_train': 68, 'weight_decay': 0.023862100637330012}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.10253754787121193, 'info': {'sick_no_sick': 0.10253754787121193, 'config': "{'batch_size': 64, 'hidden_dim': 210, 'last_n_outputs': 43, 'leak_rate': 0.7566259737219866, 'lr': 0.044735334319059614, 'optimizer': 'Adam', 'sparsity': 0.8947508080443951, 'steps_to_train': 68, 'weight_decay': 0.023862100637330012}"}}
exception: None

02:55:28 job_callback for (5, 0, 0) started
02:55:28 DISPATCHER: Trying to submit another job.
02:55:28 job_callback for (5, 0, 0) got condition
02:55:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:55:28 done building a new model for budget 133.333333 based on 10/23 split
Best loss for this budget:-0.221690





02:55:28 HBMASTER: Trying to run another job!
02:55:28 job_callback for (5, 0, 0) finished
02:55:28 start sampling a new configuration.
02:55:28 best_vector: [2, 0.35510305966661493, 0.8630027796464386, 0.2055259667679552, 0.09477245166566742, 1, 0.6785652906425897, 0.9297643434169827, 0.2546881522123249], 0.05385793583101698, 0.020441346335358313, 0.001100928719229322
02:55:28 done sampling a new configuration.
02:55:28 HBMASTER: schedule new run for iteration 5
02:55:28 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
02:55:28 HBMASTER: submitting job (5, 0, 1) to dispatcher
02:55:28 DISPATCHER: trying to submit job (5, 0, 1)
02:55:28 DISPATCHER: trying to notify the job_runner thread.
02:55:28 HBMASTER: job (5, 0, 1) submitted to dispatcher
02:55:28 DISPATCHER: Trying to submit another job.
02:55:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:55:28 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:55:28 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:55:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:55:28 WORKER: start processing job (5, 0, 1)
02:55:28 WORKER: args: ()
02:55:28 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 484, 'last_n_outputs': 45, 'leak_rate': 0.8013814916919888, 'lr': 0.001547194465902683, 'optimizer': 'SGD', 'sparsity': 0.9128556697542215, 'steps_to_train': 94, 'weight_decay': 0.02144652462855671}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:55:37 DISPATCHER: Starting worker discovery
02:55:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:55:37 DISPATCHER: Finished worker discovery
02:56:37 DISPATCHER: Starting worker discovery
02:56:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:56:37 DISPATCHER: Finished worker discovery
02:57:37 DISPATCHER: Starting worker discovery
02:57:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:57:37 DISPATCHER: Finished worker discovery
02:58:37 DISPATCHER: Starting worker discovery
02:58:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:58:37 DISPATCHER: Finished worker discovery
02:58:46 WORKER: done with job (5, 0, 1), trying to register it.
02:58:46 WORKER: registered result for job (5, 0, 1) with dispatcher
02:58:46 DISPATCHER: job (5, 0, 1) finished
02:58:46 DISPATCHER: register_result: lock acquired
02:58:46 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:58:46 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 484, 'last_n_outputs': 45, 'leak_rate': 0.8013814916919888, 'lr': 0.001547194465902683, 'optimizer': 'SGD', 'sparsity': 0.9128556697542215, 'steps_to_train': 94, 'weight_decay': 0.02144652462855671}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.18912760145336854, 'info': {'sick_no_sick': 0.18912760145336854, 'config': "{'batch_size': 64, 'hidden_dim': 484, 'last_n_outputs': 45, 'leak_rate': 0.8013814916919888, 'lr': 0.001547194465902683, 'optimizer': 'SGD', 'sparsity': 0.9128556697542215, 'steps_to_train': 94, 'weight_decay': 0.02144652462855671}"}}
exception: None

02:58:46 job_callback for (5, 0, 1) started
02:58:46 DISPATCHER: Trying to submit another job.
02:58:46 job_callback for (5, 0, 1) got condition
02:58:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:58:46 done building a new model for budget 133.333333 based on 10/24 split
Best loss for this budget:-0.221690





02:58:46 HBMASTER: Trying to run another job!
02:58:46 job_callback for (5, 0, 1) finished
02:58:46 start sampling a new configuration.
02:58:46 best_vector: [0, 0.06499782641791879, 0.5701134740846044, 0.1775940501994468, 0.24777424980860635, 0, 0.812325819418387, 0.9961414293309253, 0.35503008392691493], 0.025606070591629785, 0.06161641871389695, 0.0015777543671914639
02:58:46 done sampling a new configuration.
02:58:46 HBMASTER: schedule new run for iteration 5
02:58:46 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
02:58:46 HBMASTER: submitting job (5, 0, 2) to dispatcher
02:58:46 DISPATCHER: trying to submit job (5, 0, 2)
02:58:46 DISPATCHER: trying to notify the job_runner thread.
02:58:46 HBMASTER: job (5, 0, 2) submitted to dispatcher
02:58:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:58:46 DISPATCHER: Trying to submit another job.
02:58:46 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:58:46 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:58:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:58:46 WORKER: start processing job (5, 0, 2)
02:58:46 WORKER: args: ()
02:58:46 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 252, 'last_n_outputs': 33, 'leak_rate': 0.7943985125498617, 'lr': 0.003130029996567903, 'optimizer': 'Adam', 'sparsity': 0.9449581966604128, 'steps_to_train': 100, 'weight_decay': 0.028967084655590246}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:59:37 DISPATCHER: Starting worker discovery
02:59:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:59:37 DISPATCHER: Finished worker discovery
03:00:37 DISPATCHER: Starting worker discovery
03:00:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:00:38 DISPATCHER: Finished worker discovery
03:01:38 DISPATCHER: Starting worker discovery
03:01:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:01:38 DISPATCHER: Finished worker discovery
03:02:07 WORKER: done with job (5, 0, 2), trying to register it.
03:02:07 WORKER: registered result for job (5, 0, 2) with dispatcher
03:02:07 DISPATCHER: job (5, 0, 2) finished
03:02:07 DISPATCHER: register_result: lock acquired
03:02:07 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
03:02:07 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 252, 'last_n_outputs': 33, 'leak_rate': 0.7943985125498617, 'lr': 0.003130029996567903, 'optimizer': 'Adam', 'sparsity': 0.9449581966604128, 'steps_to_train': 100, 'weight_decay': 0.028967084655590246}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1332429185217352, 'info': {'sick_no_sick': 0.1332429185217352, 'config': "{'batch_size': 16, 'hidden_dim': 252, 'last_n_outputs': 33, 'leak_rate': 0.7943985125498617, 'lr': 0.003130029996567903, 'optimizer': 'Adam', 'sparsity': 0.9449581966604128, 'steps_to_train': 100, 'weight_decay': 0.028967084655590246}"}}
exception: None

03:02:07 job_callback for (5, 0, 2) started
03:02:07 DISPATCHER: Trying to submit another job.
03:02:07 job_callback for (5, 0, 2) got condition
03:02:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:02:07 done building a new model for budget 133.333333 based on 10/25 split
Best loss for this budget:-0.221690





03:02:07 HBMASTER: Trying to run another job!
03:02:07 job_callback for (5, 0, 2) finished
03:02:07 start sampling a new configuration.
03:02:07 best_vector: [2, 0.3631533443492144, 0.9989273656431379, 0.0198037555373827, 0.05874625340683084, 1, 0.52651109708973, 0.9948394658663338, 0.3973719571266563], 0.016328660516572707, 0.32472169951816976, 0.005302270393796725
03:02:07 done sampling a new configuration.
03:02:07 HBMASTER: schedule new run for iteration 5
03:02:07 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
03:02:07 HBMASTER: submitting job (5, 0, 3) to dispatcher
03:02:07 DISPATCHER: trying to submit job (5, 0, 3)
03:02:07 DISPATCHER: trying to notify the job_runner thread.
03:02:07 HBMASTER: job (5, 0, 3) submitted to dispatcher
03:02:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:02:07 DISPATCHER: Trying to submit another job.
03:02:07 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:02:07 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:02:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:02:07 WORKER: start processing job (5, 0, 3)
03:02:07 WORKER: args: ()
03:02:07 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 490, 'last_n_outputs': 50, 'leak_rate': 0.7549509388843457, 'lr': 0.00131066742830948, 'optimizer': 'SGD', 'sparsity': 0.8763626633015352, 'steps_to_train': 100, 'weight_decay': 0.032884620601707576}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:02:38 DISPATCHER: Starting worker discovery
03:02:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:02:38 DISPATCHER: Finished worker discovery
03:03:38 DISPATCHER: Starting worker discovery
03:03:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:03:38 DISPATCHER: Finished worker discovery
03:04:38 DISPATCHER: Starting worker discovery
03:04:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:04:38 DISPATCHER: Finished worker discovery
03:05:27 WORKER: done with job (5, 0, 3), trying to register it.
03:05:27 WORKER: registered result for job (5, 0, 3) with dispatcher
03:05:27 DISPATCHER: job (5, 0, 3) finished
03:05:27 DISPATCHER: register_result: lock acquired
03:05:27 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
03:05:27 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 490, 'last_n_outputs': 50, 'leak_rate': 0.7549509388843457, 'lr': 0.00131066742830948, 'optimizer': 'SGD', 'sparsity': 0.8763626633015352, 'steps_to_train': 100, 'weight_decay': 0.032884620601707576}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.13698821020018753, 'info': {'sick_no_sick': 0.13698821020018753, 'config': "{'batch_size': 64, 'hidden_dim': 490, 'last_n_outputs': 50, 'leak_rate': 0.7549509388843457, 'lr': 0.00131066742830948, 'optimizer': 'SGD', 'sparsity': 0.8763626633015352, 'steps_to_train': 100, 'weight_decay': 0.032884620601707576}"}}
exception: None

03:05:27 job_callback for (5, 0, 3) started
03:05:27 DISPATCHER: Trying to submit another job.
03:05:27 job_callback for (5, 0, 3) got condition
03:05:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:05:27 done building a new model for budget 133.333333 based on 10/26 split
Best loss for this budget:-0.221690





03:05:27 HBMASTER: Trying to run another job!
03:05:27 job_callback for (5, 0, 3) finished
03:05:27 start sampling a new configuration.
03:05:27 best_vector: [3, 0.6789909835559415, 0.9190862667755079, 0.6637448232654465, 0.008014720481362977, 1, 0.4478655969706111, 0.20167512833641937, 0.8725373071873171], 0.05445703732551924, 0.6056945164748748, 0.03298432889153459
03:05:27 done sampling a new configuration.
03:05:27 HBMASTER: schedule new run for iteration 5
03:05:27 HBMASTER: trying submitting job (5, 0, 4) to dispatcher
03:05:27 HBMASTER: submitting job (5, 0, 4) to dispatcher
03:05:27 DISPATCHER: trying to submit job (5, 0, 4)
03:05:27 DISPATCHER: trying to notify the job_runner thread.
03:05:27 HBMASTER: job (5, 0, 4) submitted to dispatcher
03:05:27 DISPATCHER: Trying to submit another job.
03:05:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:05:27 DISPATCHER: starting job (5, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:05:27 DISPATCHER: job (5, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:05:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:05:27 WORKER: start processing job (5, 0, 4)
03:05:27 WORKER: args: ()
03:05:27 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 743, 'last_n_outputs': 47, 'leak_rate': 0.9159362058163616, 'lr': 0.0010375987525873466, 'optimizer': 'SGD', 'sparsity': 0.8574877432729466, 'steps_to_train': 28, 'weight_decay': 0.13652029214990136}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:05:38 DISPATCHER: Starting worker discovery
03:05:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:05:38 DISPATCHER: Finished worker discovery
03:06:38 DISPATCHER: Starting worker discovery
03:06:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:06:38 DISPATCHER: Finished worker discovery
03:07:38 DISPATCHER: Starting worker discovery
03:07:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:07:38 DISPATCHER: Finished worker discovery
03:08:38 DISPATCHER: Starting worker discovery
03:08:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:08:38 DISPATCHER: Finished worker discovery
03:08:44 WORKER: done with job (5, 0, 4), trying to register it.
03:08:44 WORKER: registered result for job (5, 0, 4) with dispatcher
03:08:44 DISPATCHER: job (5, 0, 4) finished
03:08:44 DISPATCHER: register_result: lock acquired
03:08:44 DISPATCHER: job (5, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
03:08:44 job_id: (5, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 743, 'last_n_outputs': 47, 'leak_rate': 0.9159362058163616, 'lr': 0.0010375987525873466, 'optimizer': 'SGD', 'sparsity': 0.8574877432729466, 'steps_to_train': 28, 'weight_decay': 0.13652029214990136}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.16974524717722614, 'info': {'sick_no_sick': 0.16974524717722614, 'config': "{'batch_size': 128, 'hidden_dim': 743, 'last_n_outputs': 47, 'leak_rate': 0.9159362058163616, 'lr': 0.0010375987525873466, 'optimizer': 'SGD', 'sparsity': 0.8574877432729466, 'steps_to_train': 28, 'weight_decay': 0.13652029214990136}"}}
exception: None

03:08:44 job_callback for (5, 0, 4) started
03:08:44 job_callback for (5, 0, 4) got condition
03:08:44 DISPATCHER: Trying to submit another job.
03:08:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:08:44 done building a new model for budget 133.333333 based on 10/27 split
Best loss for this budget:-0.221690





03:08:44 HBMASTER: Trying to run another job!
03:08:44 job_callback for (5, 0, 4) finished
03:08:44 start sampling a new configuration.
03:08:44 best_vector: [1, 0.1653178171015433, 0.8314490095178766, 0.35092612929196654, 0.04055257163951986, 0, 0.6552494210399007, 0.3784380975383215, 0.10042881939723264], 0.05534141919555712, 1.0986262744084285, 0.06079953719129001
03:08:44 done sampling a new configuration.
03:08:44 HBMASTER: schedule new run for iteration 5
03:08:44 HBMASTER: trying submitting job (5, 0, 5) to dispatcher
03:08:44 HBMASTER: submitting job (5, 0, 5) to dispatcher
03:08:44 DISPATCHER: trying to submit job (5, 0, 5)
03:08:44 DISPATCHER: trying to notify the job_runner thread.
03:08:44 HBMASTER: job (5, 0, 5) submitted to dispatcher
03:08:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:08:44 DISPATCHER: Trying to submit another job.
03:08:44 DISPATCHER: starting job (5, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:08:44 DISPATCHER: job (5, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:08:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:08:44 WORKER: start processing job (5, 0, 5)
03:08:44 WORKER: args: ()
03:08:44 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 332, 'last_n_outputs': 44, 'leak_rate': 0.8377315323229917, 'lr': 0.0012053277165143524, 'optimizer': 'Adam', 'sparsity': 0.9072598610495761, 'steps_to_train': 44, 'weight_decay': 0.013510172881620557}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:09:38 DISPATCHER: Starting worker discovery
03:09:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:09:38 DISPATCHER: Finished worker discovery
03:10:38 DISPATCHER: Starting worker discovery
03:10:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:10:38 DISPATCHER: Finished worker discovery
03:11:38 DISPATCHER: Starting worker discovery
03:11:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:11:38 DISPATCHER: Finished worker discovery
03:12:01 WORKER: done with job (5, 0, 5), trying to register it.
03:12:01 WORKER: registered result for job (5, 0, 5) with dispatcher
03:12:01 DISPATCHER: job (5, 0, 5) finished
03:12:01 DISPATCHER: register_result: lock acquired
03:12:01 DISPATCHER: job (5, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
03:12:01 job_id: (5, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 332, 'last_n_outputs': 44, 'leak_rate': 0.8377315323229917, 'lr': 0.0012053277165143524, 'optimizer': 'Adam', 'sparsity': 0.9072598610495761, 'steps_to_train': 44, 'weight_decay': 0.013510172881620557}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.07777624404680301, 'info': {'sick_no_sick': 0.07777624404680301, 'config': "{'batch_size': 32, 'hidden_dim': 332, 'last_n_outputs': 44, 'leak_rate': 0.8377315323229917, 'lr': 0.0012053277165143524, 'optimizer': 'Adam', 'sparsity': 0.9072598610495761, 'steps_to_train': 44, 'weight_decay': 0.013510172881620557}"}}
exception: None

03:12:01 job_callback for (5, 0, 5) started
03:12:01 DISPATCHER: Trying to submit another job.
03:12:01 job_callback for (5, 0, 5) got condition
03:12:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:12:01 done building a new model for budget 133.333333 based on 10/28 split
Best loss for this budget:-0.221690





03:12:01 HBMASTER: Trying to run another job!
03:12:01 job_callback for (5, 0, 5) finished
03:12:01 start sampling a new configuration.
03:12:01 done sampling a new configuration.
03:12:01 HBMASTER: schedule new run for iteration 5
03:12:01 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
03:12:01 HBMASTER: submitting job (5, 0, 6) to dispatcher
03:12:01 DISPATCHER: trying to submit job (5, 0, 6)
03:12:01 DISPATCHER: trying to notify the job_runner thread.
03:12:01 HBMASTER: job (5, 0, 6) submitted to dispatcher
03:12:01 DISPATCHER: Trying to submit another job.
03:12:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:12:01 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:12:01 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:12:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:12:01 WORKER: start processing job (5, 0, 6)
03:12:01 WORKER: args: ()
03:12:01 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 545, 'last_n_outputs': 11, 'leak_rate': 0.7550907116174489, 'lr': 0.002895518635030978, 'optimizer': 'Adam', 'sparsity': 0.9461128310009035, 'steps_to_train': 98, 'weight_decay': 0.01432376646604708}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:12:38 DISPATCHER: Starting worker discovery
03:12:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:12:38 DISPATCHER: Finished worker discovery
03:13:38 DISPATCHER: Starting worker discovery
03:13:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:13:38 DISPATCHER: Finished worker discovery
03:14:38 DISPATCHER: Starting worker discovery
03:14:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:14:38 DISPATCHER: Finished worker discovery
03:15:18 WORKER: done with job (5, 0, 6), trying to register it.
03:15:18 WORKER: registered result for job (5, 0, 6) with dispatcher
03:15:18 DISPATCHER: job (5, 0, 6) finished
03:15:18 DISPATCHER: register_result: lock acquired
03:15:18 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
03:15:18 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 545, 'last_n_outputs': 11, 'leak_rate': 0.7550907116174489, 'lr': 0.002895518635030978, 'optimizer': 'Adam', 'sparsity': 0.9461128310009035, 'steps_to_train': 98, 'weight_decay': 0.01432376646604708}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.12830385877980846, 'info': {'sick_no_sick': 0.12830385877980846, 'config': "{'batch_size': 64, 'hidden_dim': 545, 'last_n_outputs': 11, 'leak_rate': 0.7550907116174489, 'lr': 0.002895518635030978, 'optimizer': 'Adam', 'sparsity': 0.9461128310009035, 'steps_to_train': 98, 'weight_decay': 0.01432376646604708}"}}
exception: None

03:15:18 job_callback for (5, 0, 6) started
03:15:18 job_callback for (5, 0, 6) got condition
03:15:18 DISPATCHER: Trying to submit another job.
03:15:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:15:18 done building a new model for budget 133.333333 based on 10/28 split
Best loss for this budget:-0.221690





03:15:18 HBMASTER: Trying to run another job!
03:15:18 job_callback for (5, 0, 6) finished
03:15:18 start sampling a new configuration.
03:15:18 best_vector: [2, 0.7791815703152996, 0.25529781964563686, 0.010191061633689213, 0.9160851823230304, 1, 0.7498600225061951, 0.289755457092074, 0.5120397433145012], 0.11647269624421415, 0.00617513858000568, 0.0007192350400949295
03:15:18 done sampling a new configuration.
03:15:18 HBMASTER: schedule new run for iteration 5
03:15:18 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
03:15:18 HBMASTER: submitting job (5, 0, 7) to dispatcher
03:15:18 DISPATCHER: trying to submit job (5, 0, 7)
03:15:18 DISPATCHER: trying to notify the job_runner thread.
03:15:18 HBMASTER: job (5, 0, 7) submitted to dispatcher
03:15:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:15:18 DISPATCHER: Trying to submit another job.
03:15:18 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:15:18 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:15:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:15:18 WORKER: start processing job (5, 0, 7)
03:15:18 WORKER: args: ()
03:15:18 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 824, 'last_n_outputs': 20, 'leak_rate': 0.7525477654084223, 'lr': 0.06794701222688387, 'optimizer': 'SGD', 'sparsity': 0.9299664054014868, 'steps_to_train': 36, 'weight_decay': 0.04636380440725315}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:15:38 DISPATCHER: Starting worker discovery
03:15:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:15:38 DISPATCHER: Finished worker discovery
03:16:38 DISPATCHER: Starting worker discovery
03:16:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:16:38 DISPATCHER: Finished worker discovery
03:17:38 DISPATCHER: Starting worker discovery
03:17:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:17:38 DISPATCHER: Finished worker discovery
03:18:35 WORKER: done with job (5, 0, 7), trying to register it.
03:18:35 WORKER: registered result for job (5, 0, 7) with dispatcher
03:18:35 DISPATCHER: job (5, 0, 7) finished
03:18:35 DISPATCHER: register_result: lock acquired
03:18:35 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
03:18:35 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 824, 'last_n_outputs': 20, 'leak_rate': 0.7525477654084223, 'lr': 0.06794701222688387, 'optimizer': 'SGD', 'sparsity': 0.9299664054014868, 'steps_to_train': 36, 'weight_decay': 0.04636380440725315}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.12086107099030877, 'info': {'sick_no_sick': 0.12086107099030877, 'config': "{'batch_size': 64, 'hidden_dim': 824, 'last_n_outputs': 20, 'leak_rate': 0.7525477654084223, 'lr': 0.06794701222688387, 'optimizer': 'SGD', 'sparsity': 0.9299664054014868, 'steps_to_train': 36, 'weight_decay': 0.04636380440725315}"}}
exception: None

03:18:35 job_callback for (5, 0, 7) started
03:18:35 job_callback for (5, 0, 7) got condition
03:18:35 DISPATCHER: Trying to submit another job.
03:18:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:18:35 done building a new model for budget 133.333333 based on 10/29 split
Best loss for this budget:-0.221690





03:18:35 HBMASTER: Trying to run another job!
03:18:35 job_callback for (5, 0, 7) finished
03:18:35 start sampling a new configuration.
03:18:35 best_vector: [1, 0.14771227745125165, 0.8017522080876337, 0.8593259089272386, 0.20359173737409816, 0, 0.5573869428734608, 0.6507498684549842, 0.18866516138851253], 0.040167453606250896, 0.8005310200098009, 0.032155292606608384
03:18:35 done sampling a new configuration.
03:18:35 HBMASTER: schedule new run for iteration 5
03:18:35 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
03:18:35 HBMASTER: submitting job (5, 0, 8) to dispatcher
03:18:35 DISPATCHER: trying to submit job (5, 0, 8)
03:18:35 DISPATCHER: trying to notify the job_runner thread.
03:18:35 HBMASTER: job (5, 0, 8) submitted to dispatcher
03:18:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:18:35 DISPATCHER: Trying to submit another job.
03:18:35 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:18:35 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:18:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:18:35 WORKER: start processing job (5, 0, 8)
03:18:35 WORKER: args: ()
03:18:35 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 318, 'last_n_outputs': 42, 'leak_rate': 0.9648314772318096, 'lr': 0.002553779960563944, 'optimizer': 'Adam', 'sparsity': 0.8837728662896306, 'steps_to_train': 69, 'weight_decay': 0.017597826601381296}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:18:38 DISPATCHER: Starting worker discovery
03:18:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:18:38 DISPATCHER: Finished worker discovery
03:19:38 DISPATCHER: Starting worker discovery
03:19:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:19:38 DISPATCHER: Finished worker discovery
03:20:38 DISPATCHER: Starting worker discovery
03:20:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:20:38 DISPATCHER: Finished worker discovery
03:21:38 DISPATCHER: Starting worker discovery
03:21:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:21:38 DISPATCHER: Finished worker discovery
03:21:50 WORKER: done with job (5, 0, 8), trying to register it.
03:21:50 WORKER: registered result for job (5, 0, 8) with dispatcher
03:21:50 DISPATCHER: job (5, 0, 8) finished
03:21:50 DISPATCHER: register_result: lock acquired
03:21:50 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
03:21:50 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 318, 'last_n_outputs': 42, 'leak_rate': 0.9648314772318096, 'lr': 0.002553779960563944, 'optimizer': 'Adam', 'sparsity': 0.8837728662896306, 'steps_to_train': 69, 'weight_decay': 0.017597826601381296}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.16002022326798432, 'info': {'sick_no_sick': 0.16002022326798432, 'config': "{'batch_size': 32, 'hidden_dim': 318, 'last_n_outputs': 42, 'leak_rate': 0.9648314772318096, 'lr': 0.002553779960563944, 'optimizer': 'Adam', 'sparsity': 0.8837728662896306, 'steps_to_train': 69, 'weight_decay': 0.017597826601381296}"}}
exception: None

03:21:50 job_callback for (5, 0, 8) started
03:21:50 job_callback for (5, 0, 8) got condition
03:21:50 DISPATCHER: Trying to submit another job.
03:21:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:21:50 done building a new model for budget 133.333333 based on 10/30 split
Best loss for this budget:-0.221690





03:21:50 HBMASTER: Trying to run another job!
03:21:50 job_callback for (5, 0, 8) finished
03:21:50 ITERATION: Advancing config (5, 0, 1) to next budget 400.000000
03:21:50 ITERATION: Advancing config (5, 0, 4) to next budget 400.000000
03:21:50 ITERATION: Advancing config (5, 0, 8) to next budget 400.000000
03:21:50 HBMASTER: schedule new run for iteration 5
03:21:50 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
03:21:50 HBMASTER: submitting job (5, 0, 1) to dispatcher
03:21:50 DISPATCHER: trying to submit job (5, 0, 1)
03:21:50 DISPATCHER: trying to notify the job_runner thread.
03:21:50 HBMASTER: job (5, 0, 1) submitted to dispatcher
03:21:50 DISPATCHER: Trying to submit another job.
03:21:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:21:50 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:21:50 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:21:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:21:50 WORKER: start processing job (5, 0, 1)
03:21:50 WORKER: args: ()
03:21:50 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 484, 'last_n_outputs': 45, 'leak_rate': 0.8013814916919888, 'lr': 0.001547194465902683, 'optimizer': 'SGD', 'sparsity': 0.9128556697542215, 'steps_to_train': 94, 'weight_decay': 0.02144652462855671}, 'budget': 400.0, 'working_directory': '.'}
03:22:38 DISPATCHER: Starting worker discovery
03:22:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:22:38 DISPATCHER: Finished worker discovery
03:23:38 DISPATCHER: Starting worker discovery
03:23:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:23:38 DISPATCHER: Finished worker discovery
03:24:38 DISPATCHER: Starting worker discovery
03:24:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:24:38 DISPATCHER: Finished worker discovery
03:25:38 DISPATCHER: Starting worker discovery
03:25:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:25:38 DISPATCHER: Finished worker discovery
03:26:38 DISPATCHER: Starting worker discovery
03:26:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:26:38 DISPATCHER: Finished worker discovery
03:27:38 DISPATCHER: Starting worker discovery
03:27:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:27:38 DISPATCHER: Finished worker discovery
03:28:38 DISPATCHER: Starting worker discovery
03:28:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:28:38 DISPATCHER: Finished worker discovery
03:29:37 WORKER: done with job (5, 0, 1), trying to register it.
03:29:37 WORKER: registered result for job (5, 0, 1) with dispatcher
03:29:37 DISPATCHER: job (5, 0, 1) finished
03:29:37 DISPATCHER: register_result: lock acquired
03:29:37 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
03:29:37 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 484, 'last_n_outputs': 45, 'leak_rate': 0.8013814916919888, 'lr': 0.001547194465902683, 'optimizer': 'SGD', 'sparsity': 0.9128556697542215, 'steps_to_train': 94, 'weight_decay': 0.02144652462855671}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.1656365741874301, 'info': {'sick_no_sick': 0.1656365741874301, 'config': "{'batch_size': 64, 'hidden_dim': 484, 'last_n_outputs': 45, 'leak_rate': 0.8013814916919888, 'lr': 0.001547194465902683, 'optimizer': 'SGD', 'sparsity': 0.9128556697542215, 'steps_to_train': 94, 'weight_decay': 0.02144652462855671}"}}
exception: None

03:29:37 job_callback for (5, 0, 1) started
03:29:37 job_callback for (5, 0, 1) got condition
03:29:37 DISPATCHER: Trying to submit another job.
03:29:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:29:37 HBMASTER: Trying to run another job!
03:29:37 job_callback for (5, 0, 1) finished
03:29:37 HBMASTER: schedule new run for iteration 5
03:29:37 HBMASTER: trying submitting job (5, 0, 4) to dispatcher
03:29:37 HBMASTER: submitting job (5, 0, 4) to dispatcher
03:29:37 DISPATCHER: trying to submit job (5, 0, 4)
03:29:37 DISPATCHER: trying to notify the job_runner thread.
03:29:37 HBMASTER: job (5, 0, 4) submitted to dispatcher
03:29:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:29:37 DISPATCHER: Trying to submit another job.
03:29:37 DISPATCHER: starting job (5, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:29:37 DISPATCHER: job (5, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:29:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:29:37 WORKER: start processing job (5, 0, 4)
03:29:37 WORKER: args: ()
03:29:37 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 743, 'last_n_outputs': 47, 'leak_rate': 0.9159362058163616, 'lr': 0.0010375987525873466, 'optimizer': 'SGD', 'sparsity': 0.8574877432729466, 'steps_to_train': 28, 'weight_decay': 0.13652029214990136}, 'budget': 400.0, 'working_directory': '.'}
03:29:38 DISPATCHER: Starting worker discovery
03:29:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:29:38 DISPATCHER: Finished worker discovery
03:30:38 DISPATCHER: Starting worker discovery
03:30:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:30:38 DISPATCHER: Finished worker discovery
03:31:38 DISPATCHER: Starting worker discovery
03:31:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:31:38 DISPATCHER: Finished worker discovery
03:32:38 DISPATCHER: Starting worker discovery
03:32:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:32:38 DISPATCHER: Finished worker discovery
03:33:38 DISPATCHER: Starting worker discovery
03:33:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:33:38 DISPATCHER: Finished worker discovery
03:34:38 DISPATCHER: Starting worker discovery
03:34:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:34:38 DISPATCHER: Finished worker discovery
03:35:38 DISPATCHER: Starting worker discovery
03:35:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:35:38 DISPATCHER: Finished worker discovery
03:36:38 DISPATCHER: Starting worker discovery
03:36:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:36:38 DISPATCHER: Finished worker discovery
03:37:22 WORKER: done with job (5, 0, 4), trying to register it.
03:37:22 WORKER: registered result for job (5, 0, 4) with dispatcher
03:37:22 DISPATCHER: job (5, 0, 4) finished
03:37:22 DISPATCHER: register_result: lock acquired
03:37:22 DISPATCHER: job (5, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
03:37:22 job_id: (5, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 743, 'last_n_outputs': 47, 'leak_rate': 0.9159362058163616, 'lr': 0.0010375987525873466, 'optimizer': 'SGD', 'sparsity': 0.8574877432729466, 'steps_to_train': 28, 'weight_decay': 0.13652029214990136}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.056913260027072574, 'info': {'sick_no_sick': 0.056913260027072574, 'config': "{'batch_size': 128, 'hidden_dim': 743, 'last_n_outputs': 47, 'leak_rate': 0.9159362058163616, 'lr': 0.0010375987525873466, 'optimizer': 'SGD', 'sparsity': 0.8574877432729466, 'steps_to_train': 28, 'weight_decay': 0.13652029214990136}"}}
exception: None

03:37:22 job_callback for (5, 0, 4) started
03:37:22 job_callback for (5, 0, 4) got condition
03:37:22 DISPATCHER: Trying to submit another job.
03:37:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:37:22 HBMASTER: Trying to run another job!
03:37:22 job_callback for (5, 0, 4) finished
03:37:22 HBMASTER: schedule new run for iteration 5
03:37:22 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
03:37:22 HBMASTER: submitting job (5, 0, 8) to dispatcher
03:37:22 DISPATCHER: trying to submit job (5, 0, 8)
03:37:22 DISPATCHER: trying to notify the job_runner thread.
03:37:22 HBMASTER: job (5, 0, 8) submitted to dispatcher
03:37:22 DISPATCHER: Trying to submit another job.
03:37:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:37:22 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:37:22 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:37:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:37:22 WORKER: start processing job (5, 0, 8)
03:37:22 WORKER: args: ()
03:37:22 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 318, 'last_n_outputs': 42, 'leak_rate': 0.9648314772318096, 'lr': 0.002553779960563944, 'optimizer': 'Adam', 'sparsity': 0.8837728662896306, 'steps_to_train': 69, 'weight_decay': 0.017597826601381296}, 'budget': 400.0, 'working_directory': '.'}
03:37:38 DISPATCHER: Starting worker discovery
03:37:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:37:38 DISPATCHER: Finished worker discovery
03:38:38 DISPATCHER: Starting worker discovery
03:38:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:38:38 DISPATCHER: Finished worker discovery
03:39:38 DISPATCHER: Starting worker discovery
03:39:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:39:38 DISPATCHER: Finished worker discovery
03:40:38 DISPATCHER: Starting worker discovery
03:40:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:40:38 DISPATCHER: Finished worker discovery
03:41:38 DISPATCHER: Starting worker discovery
03:41:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:41:38 DISPATCHER: Finished worker discovery
03:42:38 DISPATCHER: Starting worker discovery
03:42:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:42:38 DISPATCHER: Finished worker discovery
03:43:38 DISPATCHER: Starting worker discovery
03:43:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:43:38 DISPATCHER: Finished worker discovery
03:44:38 DISPATCHER: Starting worker discovery
03:44:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:44:38 DISPATCHER: Finished worker discovery
03:45:06 WORKER: done with job (5, 0, 8), trying to register it.
03:45:06 WORKER: registered result for job (5, 0, 8) with dispatcher
03:45:06 DISPATCHER: job (5, 0, 8) finished
03:45:06 DISPATCHER: register_result: lock acquired
03:45:06 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
03:45:06 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 318, 'last_n_outputs': 42, 'leak_rate': 0.9648314772318096, 'lr': 0.002553779960563944, 'optimizer': 'Adam', 'sparsity': 0.8837728662896306, 'steps_to_train': 69, 'weight_decay': 0.017597826601381296}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.12548647629570658, 'info': {'sick_no_sick': 0.12548647629570658, 'config': "{'batch_size': 32, 'hidden_dim': 318, 'last_n_outputs': 42, 'leak_rate': 0.9648314772318096, 'lr': 0.002553779960563944, 'optimizer': 'Adam', 'sparsity': 0.8837728662896306, 'steps_to_train': 69, 'weight_decay': 0.017597826601381296}"}}
exception: None

03:45:06 job_callback for (5, 0, 8) started
03:45:06 DISPATCHER: Trying to submit another job.
03:45:06 job_callback for (5, 0, 8) got condition
03:45:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:45:06 HBMASTER: Trying to run another job!
03:45:06 job_callback for (5, 0, 8) finished
03:45:06 ITERATION: Advancing config (5, 0, 1) to next budget 1200.000000
03:45:06 HBMASTER: schedule new run for iteration 5
03:45:06 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
03:45:06 HBMASTER: submitting job (5, 0, 1) to dispatcher
03:45:06 DISPATCHER: trying to submit job (5, 0, 1)
03:45:06 DISPATCHER: trying to notify the job_runner thread.
03:45:06 HBMASTER: job (5, 0, 1) submitted to dispatcher
03:45:06 DISPATCHER: Trying to submit another job.
03:45:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:45:06 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:45:06 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:45:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:45:06 WORKER: start processing job (5, 0, 1)
03:45:06 WORKER: args: ()
03:45:06 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 484, 'last_n_outputs': 45, 'leak_rate': 0.8013814916919888, 'lr': 0.001547194465902683, 'optimizer': 'SGD', 'sparsity': 0.9128556697542215, 'steps_to_train': 94, 'weight_decay': 0.02144652462855671}, 'budget': 1200.0, 'working_directory': '.'}
03:45:38 DISPATCHER: Starting worker discovery
03:45:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:45:38 DISPATCHER: Finished worker discovery
03:46:38 DISPATCHER: Starting worker discovery
03:46:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:46:38 DISPATCHER: Finished worker discovery
03:47:38 DISPATCHER: Starting worker discovery
03:47:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:47:38 DISPATCHER: Finished worker discovery
03:48:38 DISPATCHER: Starting worker discovery
03:48:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:48:38 DISPATCHER: Finished worker discovery
03:49:38 DISPATCHER: Starting worker discovery
03:49:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:49:38 DISPATCHER: Finished worker discovery
03:50:38 DISPATCHER: Starting worker discovery
03:50:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:50:38 DISPATCHER: Finished worker discovery
03:51:38 DISPATCHER: Starting worker discovery
03:51:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:51:38 DISPATCHER: Finished worker discovery
03:52:38 DISPATCHER: Starting worker discovery
03:52:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:52:38 DISPATCHER: Finished worker discovery
03:53:38 DISPATCHER: Starting worker discovery
03:53:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:53:38 DISPATCHER: Finished worker discovery
03:54:38 DISPATCHER: Starting worker discovery
03:54:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:54:38 DISPATCHER: Finished worker discovery
03:55:38 DISPATCHER: Starting worker discovery
03:55:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:55:38 DISPATCHER: Finished worker discovery
03:56:38 DISPATCHER: Starting worker discovery
03:56:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:56:38 DISPATCHER: Finished worker discovery
03:57:38 DISPATCHER: Starting worker discovery
03:57:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:57:38 DISPATCHER: Finished worker discovery
03:58:38 DISPATCHER: Starting worker discovery
03:58:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:58:38 DISPATCHER: Finished worker discovery
03:59:38 DISPATCHER: Starting worker discovery
03:59:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:59:38 DISPATCHER: Finished worker discovery
04:00:38 DISPATCHER: Starting worker discovery
04:00:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:00:38 DISPATCHER: Finished worker discovery
04:01:38 DISPATCHER: Starting worker discovery
04:01:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:01:38 DISPATCHER: Finished worker discovery
04:02:38 DISPATCHER: Starting worker discovery
04:02:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:02:38 DISPATCHER: Finished worker discovery
04:03:38 DISPATCHER: Starting worker discovery
04:03:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:03:38 DISPATCHER: Finished worker discovery
04:04:38 DISPATCHER: Starting worker discovery
04:04:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:04:38 DISPATCHER: Finished worker discovery
04:05:38 DISPATCHER: Starting worker discovery
04:05:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:05:38 DISPATCHER: Finished worker discovery
04:06:12 WORKER: done with job (5, 0, 1), trying to register it.
04:06:12 WORKER: registered result for job (5, 0, 1) with dispatcher
04:06:12 DISPATCHER: job (5, 0, 1) finished
04:06:12 DISPATCHER: register_result: lock acquired
04:06:12 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
04:06:12 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 484, 'last_n_outputs': 45, 'leak_rate': 0.8013814916919888, 'lr': 0.001547194465902683, 'optimizer': 'SGD', 'sparsity': 0.9128556697542215, 'steps_to_train': 94, 'weight_decay': 0.02144652462855671}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.17438411183828872, 'info': {'sick_no_sick': 0.17438411183828872, 'config': "{'batch_size': 64, 'hidden_dim': 484, 'last_n_outputs': 45, 'leak_rate': 0.8013814916919888, 'lr': 0.001547194465902683, 'optimizer': 'SGD', 'sparsity': 0.9128556697542215, 'steps_to_train': 94, 'weight_decay': 0.02144652462855671}"}}
exception: None

04:06:12 job_callback for (5, 0, 1) started
04:06:12 DISPATCHER: Trying to submit another job.
04:06:12 job_callback for (5, 0, 1) got condition
04:06:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:06:12 HBMASTER: Trying to run another job!
04:06:12 job_callback for (5, 0, 1) finished
04:06:12 start sampling a new configuration.
04:06:12 done sampling a new configuration.
04:06:12 HBMASTER: schedule new run for iteration 6
04:06:12 HBMASTER: trying submitting job (6, 0, 0) to dispatcher
04:06:12 HBMASTER: submitting job (6, 0, 0) to dispatcher
04:06:12 DISPATCHER: trying to submit job (6, 0, 0)
04:06:12 DISPATCHER: trying to notify the job_runner thread.
04:06:12 HBMASTER: job (6, 0, 0) submitted to dispatcher
04:06:12 DISPATCHER: Trying to submit another job.
04:06:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:06:12 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:06:12 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:06:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:06:12 WORKER: start processing job (6, 0, 0)
04:06:12 WORKER: args: ()
04:06:12 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 908, 'last_n_outputs': 13, 'leak_rate': 0.7525126452173374, 'lr': 0.0021939398130134237, 'optimizer': 'SGD', 'sparsity': 0.98790135282609, 'steps_to_train': 12, 'weight_decay': 0.029971763094917}, 'budget': 400.0, 'working_directory': '.'}
04:06:38 DISPATCHER: Starting worker discovery
04:06:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:06:38 DISPATCHER: Finished worker discovery
04:07:38 DISPATCHER: Starting worker discovery
04:07:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:07:38 DISPATCHER: Finished worker discovery
04:08:38 DISPATCHER: Starting worker discovery
04:08:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:08:38 DISPATCHER: Finished worker discovery
04:09:38 DISPATCHER: Starting worker discovery
04:09:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:09:38 DISPATCHER: Finished worker discovery
04:10:38 DISPATCHER: Starting worker discovery
04:10:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:10:38 DISPATCHER: Finished worker discovery
04:11:38 DISPATCHER: Starting worker discovery
04:11:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:11:38 DISPATCHER: Finished worker discovery
04:12:38 DISPATCHER: Starting worker discovery
04:12:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:12:38 DISPATCHER: Finished worker discovery
04:13:38 DISPATCHER: Starting worker discovery
04:13:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:13:38 DISPATCHER: Finished worker discovery
04:14:03 WORKER: done with job (6, 0, 0), trying to register it.
04:14:03 WORKER: registered result for job (6, 0, 0) with dispatcher
04:14:03 DISPATCHER: job (6, 0, 0) finished
04:14:03 DISPATCHER: register_result: lock acquired
04:14:03 DISPATCHER: job (6, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
04:14:03 job_id: (6, 0, 0)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 908, 'last_n_outputs': 13, 'leak_rate': 0.7525126452173374, 'lr': 0.0021939398130134237, 'optimizer': 'SGD', 'sparsity': 0.98790135282609, 'steps_to_train': 12, 'weight_decay': 0.029971763094917}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.13301066114140686, 'info': {'sick_no_sick': 0.13301066114140686, 'config': "{'batch_size': 64, 'hidden_dim': 908, 'last_n_outputs': 13, 'leak_rate': 0.7525126452173374, 'lr': 0.0021939398130134237, 'optimizer': 'SGD', 'sparsity': 0.98790135282609, 'steps_to_train': 12, 'weight_decay': 0.029971763094917}"}}
exception: None

04:14:03 job_callback for (6, 0, 0) started
04:14:03 DISPATCHER: Trying to submit another job.
04:14:03 job_callback for (6, 0, 0) got condition
04:14:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:14:03 HBMASTER: Trying to run another job!
04:14:03 job_callback for (6, 0, 0) finished
04:14:03 start sampling a new configuration.
04:14:03 best_vector: [0, 0.397879133307307, 0.8486609117720094, 0.18187266208548047, 0.060456959911623795, 0, 0.8684243800529338, 0.8671485918810387, 0.15393190892055136], 0.13141822604134343, 0.2857695525743479, 0.037555327655949225
04:14:03 done sampling a new configuration.
04:14:03 HBMASTER: schedule new run for iteration 6
04:14:03 HBMASTER: trying submitting job (6, 0, 1) to dispatcher
04:14:03 HBMASTER: submitting job (6, 0, 1) to dispatcher
04:14:03 DISPATCHER: trying to submit job (6, 0, 1)
04:14:03 DISPATCHER: trying to notify the job_runner thread.
04:14:03 HBMASTER: job (6, 0, 1) submitted to dispatcher
04:14:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:14:03 DISPATCHER: Trying to submit another job.
04:14:03 DISPATCHER: starting job (6, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:14:03 DISPATCHER: job (6, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:14:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:14:03 WORKER: start processing job (6, 0, 1)
04:14:03 WORKER: args: ()
04:14:03 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 518, 'last_n_outputs': 44, 'leak_rate': 0.7954681655213701, 'lr': 0.0013210337701854203, 'optimizer': 'Adam', 'sparsity': 0.9584218512127041, 'steps_to_train': 88, 'weight_decay': 0.015858789361536826}, 'budget': 400.0, 'working_directory': '.'}
04:14:38 DISPATCHER: Starting worker discovery
04:14:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:14:38 DISPATCHER: Finished worker discovery
04:15:38 DISPATCHER: Starting worker discovery
04:15:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:15:38 DISPATCHER: Finished worker discovery
04:16:38 DISPATCHER: Starting worker discovery
04:16:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:16:38 DISPATCHER: Finished worker discovery
04:17:38 DISPATCHER: Starting worker discovery
04:17:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:17:38 DISPATCHER: Finished worker discovery
04:18:38 DISPATCHER: Starting worker discovery
04:18:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:18:38 DISPATCHER: Finished worker discovery
04:19:38 DISPATCHER: Starting worker discovery
04:19:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:19:38 DISPATCHER: Finished worker discovery
04:20:38 DISPATCHER: Starting worker discovery
04:20:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:20:38 DISPATCHER: Finished worker discovery
04:21:38 DISPATCHER: Starting worker discovery
04:21:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:21:38 DISPATCHER: Finished worker discovery
04:21:51 WORKER: done with job (6, 0, 1), trying to register it.
04:21:51 WORKER: registered result for job (6, 0, 1) with dispatcher
04:21:51 DISPATCHER: job (6, 0, 1) finished
04:21:51 DISPATCHER: register_result: lock acquired
04:21:51 DISPATCHER: job (6, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
04:21:51 job_id: (6, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 518, 'last_n_outputs': 44, 'leak_rate': 0.7954681655213701, 'lr': 0.0013210337701854203, 'optimizer': 'Adam', 'sparsity': 0.9584218512127041, 'steps_to_train': 88, 'weight_decay': 0.015858789361536826}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.1078500327531026, 'info': {'sick_no_sick': 0.1078500327531026, 'config': "{'batch_size': 16, 'hidden_dim': 518, 'last_n_outputs': 44, 'leak_rate': 0.7954681655213701, 'lr': 0.0013210337701854203, 'optimizer': 'Adam', 'sparsity': 0.9584218512127041, 'steps_to_train': 88, 'weight_decay': 0.015858789361536826}"}}
exception: None

04:21:51 job_callback for (6, 0, 1) started
04:21:51 DISPATCHER: Trying to submit another job.
04:21:51 job_callback for (6, 0, 1) got condition
04:21:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:21:51 done building a new model for budget 400.000000 based on 10/17 split
Best loss for this budget:-0.208935





04:21:51 HBMASTER: Trying to run another job!
04:21:51 job_callback for (6, 0, 1) finished
04:21:51 start sampling a new configuration.
04:21:51 best_vector: [0, 0.0036108719476961593, 0.48786790463181967, 0.945187282437384, 0.4743940990330088, 0, 0.14803720968275969, 0.22430644626864626, 0.8176330944713347], 0.01499854217003484, 0.011812929738606471, 0.0001771767248361478
04:21:51 done sampling a new configuration.
04:21:51 HBMASTER: schedule new run for iteration 6
04:21:51 HBMASTER: trying submitting job (6, 0, 2) to dispatcher
04:21:51 HBMASTER: submitting job (6, 0, 2) to dispatcher
04:21:51 DISPATCHER: trying to submit job (6, 0, 2)
04:21:51 DISPATCHER: trying to notify the job_runner thread.
04:21:51 HBMASTER: job (6, 0, 2) submitted to dispatcher
04:21:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:21:51 DISPATCHER: Trying to submit another job.
04:21:51 DISPATCHER: starting job (6, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:21:51 DISPATCHER: job (6, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:21:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:21:51 WORKER: start processing job (6, 0, 2)
04:21:51 WORKER: args: ()
04:21:51 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 202, 'last_n_outputs': 30, 'leak_rate': 0.986296820609346, 'lr': 0.008887675673359964, 'optimizer': 'Adam', 'sparsity': 0.7855289303238623, 'steps_to_train': 30, 'weight_decay': 0.11581509862795163}, 'budget': 400.0, 'working_directory': '.'}
04:22:38 DISPATCHER: Starting worker discovery
04:22:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:22:38 DISPATCHER: Finished worker discovery
04:23:38 DISPATCHER: Starting worker discovery
04:23:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:23:38 DISPATCHER: Finished worker discovery
04:24:38 DISPATCHER: Starting worker discovery
04:24:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:24:38 DISPATCHER: Finished worker discovery
04:25:38 DISPATCHER: Starting worker discovery
04:25:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:25:38 DISPATCHER: Finished worker discovery
04:26:38 DISPATCHER: Starting worker discovery
04:26:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:26:38 DISPATCHER: Finished worker discovery
04:27:38 DISPATCHER: Starting worker discovery
04:27:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:27:38 DISPATCHER: Finished worker discovery
04:28:38 DISPATCHER: Starting worker discovery
04:28:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:28:38 DISPATCHER: Finished worker discovery
04:29:37 WORKER: done with job (6, 0, 2), trying to register it.
04:29:37 WORKER: registered result for job (6, 0, 2) with dispatcher
04:29:37 DISPATCHER: job (6, 0, 2) finished
04:29:37 DISPATCHER: register_result: lock acquired
04:29:37 DISPATCHER: job (6, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
04:29:37 job_id: (6, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 202, 'last_n_outputs': 30, 'leak_rate': 0.986296820609346, 'lr': 0.008887675673359964, 'optimizer': 'Adam', 'sparsity': 0.7855289303238623, 'steps_to_train': 30, 'weight_decay': 0.11581509862795163}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.07920550389944861, 'info': {'sick_no_sick': 0.07920550389944861, 'config': "{'batch_size': 16, 'hidden_dim': 202, 'last_n_outputs': 30, 'leak_rate': 0.986296820609346, 'lr': 0.008887675673359964, 'optimizer': 'Adam', 'sparsity': 0.7855289303238623, 'steps_to_train': 30, 'weight_decay': 0.11581509862795163}"}}
exception: None

04:29:37 job_callback for (6, 0, 2) started
04:29:37 DISPATCHER: Trying to submit another job.
04:29:37 job_callback for (6, 0, 2) got condition
04:29:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:29:37 done building a new model for budget 400.000000 based on 10/17 split
Best loss for this budget:-0.208935





04:29:37 HBMASTER: Trying to run another job!
04:29:37 job_callback for (6, 0, 2) finished
04:29:37 start sampling a new configuration.
04:29:37 best_vector: [0, 0.8019322827828581, 0.18424286701594764, 0.9566145125450445, 0.48488317480545345, 0, 0.2388052329535904, 0.049268577505735114, 0.34948359025295417], 0.0054166865720679785, 0.20915186762193527, 0.0011329101128706761
04:29:37 done sampling a new configuration.
04:29:37 HBMASTER: schedule new run for iteration 6
04:29:37 HBMASTER: trying submitting job (6, 0, 3) to dispatcher
04:29:37 HBMASTER: submitting job (6, 0, 3) to dispatcher
04:29:37 DISPATCHER: trying to submit job (6, 0, 3)
04:29:37 DISPATCHER: trying to notify the job_runner thread.
04:29:37 HBMASTER: job (6, 0, 3) submitted to dispatcher
04:29:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:29:37 DISPATCHER: Trying to submit another job.
04:29:37 DISPATCHER: starting job (6, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:29:37 DISPATCHER: job (6, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:29:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:29:37 WORKER: start processing job (6, 0, 3)
04:29:37 WORKER: args: ()
04:29:37 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 842, 'last_n_outputs': 17, 'leak_rate': 0.9891536281362612, 'lr': 0.009327523451119453, 'optimizer': 'Adam', 'sparsity': 0.8073132559088617, 'steps_to_train': 14, 'weight_decay': 0.028489749713102468}, 'budget': 400.0, 'working_directory': '.'}
04:29:38 DISPATCHER: Starting worker discovery
04:29:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:29:38 DISPATCHER: Finished worker discovery
04:30:38 DISPATCHER: Starting worker discovery
04:30:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:30:38 DISPATCHER: Finished worker discovery
04:31:38 DISPATCHER: Starting worker discovery
04:31:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:31:38 DISPATCHER: Finished worker discovery
04:32:38 DISPATCHER: Starting worker discovery
04:32:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:32:38 DISPATCHER: Finished worker discovery
04:33:38 DISPATCHER: Starting worker discovery
04:33:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:33:38 DISPATCHER: Finished worker discovery
04:34:38 DISPATCHER: Starting worker discovery
04:34:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:34:38 DISPATCHER: Finished worker discovery
04:35:38 DISPATCHER: Starting worker discovery
04:35:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:35:38 DISPATCHER: Finished worker discovery
04:36:38 DISPATCHER: Starting worker discovery
04:36:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:36:38 DISPATCHER: Finished worker discovery
04:37:27 WORKER: done with job (6, 0, 3), trying to register it.
04:37:27 WORKER: registered result for job (6, 0, 3) with dispatcher
04:37:27 DISPATCHER: job (6, 0, 3) finished
04:37:27 DISPATCHER: register_result: lock acquired
04:37:27 DISPATCHER: job (6, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
04:37:27 job_id: (6, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 842, 'last_n_outputs': 17, 'leak_rate': 0.9891536281362612, 'lr': 0.009327523451119453, 'optimizer': 'Adam', 'sparsity': 0.8073132559088617, 'steps_to_train': 14, 'weight_decay': 0.028489749713102468}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.14423881586907245, 'info': {'sick_no_sick': 0.14423881586907245, 'config': "{'batch_size': 16, 'hidden_dim': 842, 'last_n_outputs': 17, 'leak_rate': 0.9891536281362612, 'lr': 0.009327523451119453, 'optimizer': 'Adam', 'sparsity': 0.8073132559088617, 'steps_to_train': 14, 'weight_decay': 0.028489749713102468}"}}
exception: None

04:37:27 job_callback for (6, 0, 3) started
04:37:27 DISPATCHER: Trying to submit another job.
04:37:27 job_callback for (6, 0, 3) got condition
04:37:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:37:27 done building a new model for budget 400.000000 based on 10/18 split
Best loss for this budget:-0.208935





04:37:27 HBMASTER: Trying to run another job!
04:37:27 job_callback for (6, 0, 3) finished
04:37:27 start sampling a new configuration.
04:37:27 done sampling a new configuration.
04:37:27 HBMASTER: schedule new run for iteration 6
04:37:27 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
04:37:27 HBMASTER: submitting job (6, 0, 4) to dispatcher
04:37:27 DISPATCHER: trying to submit job (6, 0, 4)
04:37:27 DISPATCHER: trying to notify the job_runner thread.
04:37:27 HBMASTER: job (6, 0, 4) submitted to dispatcher
04:37:27 DISPATCHER: Trying to submit another job.
04:37:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:37:27 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:37:27 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:37:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:37:27 WORKER: start processing job (6, 0, 4)
04:37:27 WORKER: args: ()
04:37:27 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 922, 'last_n_outputs': 15, 'leak_rate': 0.8724488842275221, 'lr': 0.04482384177500114, 'optimizer': 'Adam', 'sparsity': 0.8668513876191963, 'steps_to_train': 65, 'weight_decay': 0.03900706513652291}, 'budget': 400.0, 'working_directory': '.'}
04:37:38 DISPATCHER: Starting worker discovery
04:37:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:37:38 DISPATCHER: Finished worker discovery
04:38:38 DISPATCHER: Starting worker discovery
04:38:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:38:38 DISPATCHER: Finished worker discovery
04:39:38 DISPATCHER: Starting worker discovery
04:39:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:39:38 DISPATCHER: Finished worker discovery
04:40:38 DISPATCHER: Starting worker discovery
04:40:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:40:38 DISPATCHER: Finished worker discovery
04:41:38 DISPATCHER: Starting worker discovery
04:41:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:41:38 DISPATCHER: Finished worker discovery
04:42:38 DISPATCHER: Starting worker discovery
04:42:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:42:38 DISPATCHER: Finished worker discovery
04:43:38 DISPATCHER: Starting worker discovery
04:43:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:43:38 DISPATCHER: Finished worker discovery
04:44:38 DISPATCHER: Starting worker discovery
04:44:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:44:38 DISPATCHER: Finished worker discovery
04:45:13 WORKER: done with job (6, 0, 4), trying to register it.
04:45:13 WORKER: registered result for job (6, 0, 4) with dispatcher
04:45:13 DISPATCHER: job (6, 0, 4) finished
04:45:13 DISPATCHER: register_result: lock acquired
04:45:13 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
04:45:13 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 922, 'last_n_outputs': 15, 'leak_rate': 0.8724488842275221, 'lr': 0.04482384177500114, 'optimizer': 'Adam', 'sparsity': 0.8668513876191963, 'steps_to_train': 65, 'weight_decay': 0.03900706513652291}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.1378911377858793, 'info': {'sick_no_sick': 0.1378911377858793, 'config': "{'batch_size': 32, 'hidden_dim': 922, 'last_n_outputs': 15, 'leak_rate': 0.8724488842275221, 'lr': 0.04482384177500114, 'optimizer': 'Adam', 'sparsity': 0.8668513876191963, 'steps_to_train': 65, 'weight_decay': 0.03900706513652291}"}}
exception: None

04:45:13 job_callback for (6, 0, 4) started
04:45:13 job_callback for (6, 0, 4) got condition
04:45:13 DISPATCHER: Trying to submit another job.
04:45:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:45:13 done building a new model for budget 400.000000 based on 10/19 split
Best loss for this budget:-0.208935





04:45:13 HBMASTER: Trying to run another job!
04:45:13 job_callback for (6, 0, 4) finished
04:45:13 start sampling a new configuration.
04:45:13 best_vector: [3, 0.8450125734782348, 0.1778239084182772, 0.5135382516668188, 0.15619838027001653, 1, 0.08226801462288423, 0.6954204132519974, 0.045342362098041544], 0.025987628823005305, 0.15380402606938456, 0.003997001940974998
04:45:13 done sampling a new configuration.
04:45:13 HBMASTER: schedule new run for iteration 6
04:45:13 HBMASTER: trying submitting job (6, 0, 5) to dispatcher
04:45:13 HBMASTER: submitting job (6, 0, 5) to dispatcher
04:45:13 DISPATCHER: trying to submit job (6, 0, 5)
04:45:13 DISPATCHER: trying to notify the job_runner thread.
04:45:13 HBMASTER: job (6, 0, 5) submitted to dispatcher
04:45:13 DISPATCHER: Trying to submit another job.
04:45:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:45:13 DISPATCHER: starting job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:45:13 DISPATCHER: job (6, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:45:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:45:13 WORKER: start processing job (6, 0, 5)
04:45:13 WORKER: args: ()
04:45:13 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 876, 'last_n_outputs': 17, 'leak_rate': 0.8783845629167046, 'lr': 0.0020530369253484587, 'optimizer': 'SGD', 'sparsity': 0.7697443235094922, 'steps_to_train': 73, 'weight_decay': 0.011454912422104379}, 'budget': 400.0, 'working_directory': '.'}
04:45:38 DISPATCHER: Starting worker discovery
04:45:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:45:38 DISPATCHER: Finished worker discovery
04:46:38 DISPATCHER: Starting worker discovery
04:46:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:46:38 DISPATCHER: Finished worker discovery
04:47:38 DISPATCHER: Starting worker discovery
04:47:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:47:38 DISPATCHER: Finished worker discovery
04:48:38 DISPATCHER: Starting worker discovery
04:48:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:48:38 DISPATCHER: Finished worker discovery
04:49:38 DISPATCHER: Starting worker discovery
04:49:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:49:38 DISPATCHER: Finished worker discovery
04:50:38 DISPATCHER: Starting worker discovery
04:50:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:50:38 DISPATCHER: Finished worker discovery
04:51:38 DISPATCHER: Starting worker discovery
04:51:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:51:38 DISPATCHER: Finished worker discovery
04:52:38 DISPATCHER: Starting worker discovery
04:52:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:52:38 DISPATCHER: Finished worker discovery
04:52:59 WORKER: done with job (6, 0, 5), trying to register it.
04:52:59 WORKER: registered result for job (6, 0, 5) with dispatcher
04:52:59 DISPATCHER: job (6, 0, 5) finished
04:52:59 DISPATCHER: register_result: lock acquired
04:52:59 DISPATCHER: job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
04:52:59 job_id: (6, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 876, 'last_n_outputs': 17, 'leak_rate': 0.8783845629167046, 'lr': 0.0020530369253484587, 'optimizer': 'SGD', 'sparsity': 0.7697443235094922, 'steps_to_train': 73, 'weight_decay': 0.011454912422104379}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.16006556735803001, 'info': {'sick_no_sick': 0.16006556735803001, 'config': "{'batch_size': 128, 'hidden_dim': 876, 'last_n_outputs': 17, 'leak_rate': 0.8783845629167046, 'lr': 0.0020530369253484587, 'optimizer': 'SGD', 'sparsity': 0.7697443235094922, 'steps_to_train': 73, 'weight_decay': 0.011454912422104379}"}}
exception: None

04:52:59 job_callback for (6, 0, 5) started
04:52:59 DISPATCHER: Trying to submit another job.
04:52:59 job_callback for (6, 0, 5) got condition
04:52:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:52:59 done building a new model for budget 400.000000 based on 10/20 split
Best loss for this budget:-0.208935





04:52:59 HBMASTER: Trying to run another job!
04:52:59 job_callback for (6, 0, 5) finished
04:52:59 ITERATION: Advancing config (6, 0, 3) to next budget 1200.000000
04:52:59 ITERATION: Advancing config (6, 0, 5) to next budget 1200.000000
04:52:59 HBMASTER: schedule new run for iteration 6
04:52:59 HBMASTER: trying submitting job (6, 0, 3) to dispatcher
04:52:59 HBMASTER: submitting job (6, 0, 3) to dispatcher
04:52:59 DISPATCHER: trying to submit job (6, 0, 3)
04:52:59 DISPATCHER: trying to notify the job_runner thread.
04:52:59 HBMASTER: job (6, 0, 3) submitted to dispatcher
04:52:59 DISPATCHER: Trying to submit another job.
04:52:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:52:59 DISPATCHER: starting job (6, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:52:59 DISPATCHER: job (6, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:52:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:52:59 WORKER: start processing job (6, 0, 3)
04:52:59 WORKER: args: ()
04:52:59 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 842, 'last_n_outputs': 17, 'leak_rate': 0.9891536281362612, 'lr': 0.009327523451119453, 'optimizer': 'Adam', 'sparsity': 0.8073132559088617, 'steps_to_train': 14, 'weight_decay': 0.028489749713102468}, 'budget': 1200.0, 'working_directory': '.'}
04:53:38 DISPATCHER: Starting worker discovery
04:53:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:53:38 DISPATCHER: Finished worker discovery
04:54:38 DISPATCHER: Starting worker discovery
04:54:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:54:38 DISPATCHER: Finished worker discovery
04:55:38 DISPATCHER: Starting worker discovery
04:55:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:55:38 DISPATCHER: Finished worker discovery
04:56:38 DISPATCHER: Starting worker discovery
04:56:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:56:38 DISPATCHER: Finished worker discovery
04:57:38 DISPATCHER: Starting worker discovery
04:57:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:57:38 DISPATCHER: Finished worker discovery
04:58:38 DISPATCHER: Starting worker discovery
04:58:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:58:38 DISPATCHER: Finished worker discovery
04:59:38 DISPATCHER: Starting worker discovery
04:59:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:59:38 DISPATCHER: Finished worker discovery
05:00:38 DISPATCHER: Starting worker discovery
05:00:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:00:38 DISPATCHER: Finished worker discovery
05:01:38 DISPATCHER: Starting worker discovery
05:01:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:01:38 DISPATCHER: Finished worker discovery
05:02:38 DISPATCHER: Starting worker discovery
05:02:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:02:38 DISPATCHER: Finished worker discovery
05:03:38 DISPATCHER: Starting worker discovery
05:03:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:03:38 DISPATCHER: Finished worker discovery
05:04:38 DISPATCHER: Starting worker discovery
05:04:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:04:38 DISPATCHER: Finished worker discovery
05:05:38 DISPATCHER: Starting worker discovery
05:05:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:05:38 DISPATCHER: Finished worker discovery
05:06:38 DISPATCHER: Starting worker discovery
05:06:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:06:38 DISPATCHER: Finished worker discovery
05:07:38 DISPATCHER: Starting worker discovery
05:07:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:07:38 DISPATCHER: Finished worker discovery
05:08:38 DISPATCHER: Starting worker discovery
05:08:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:08:38 DISPATCHER: Finished worker discovery
05:09:38 DISPATCHER: Starting worker discovery
05:09:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:09:38 DISPATCHER: Finished worker discovery
05:10:38 DISPATCHER: Starting worker discovery
05:10:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:10:38 DISPATCHER: Finished worker discovery
05:11:38 DISPATCHER: Starting worker discovery
05:11:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:11:38 DISPATCHER: Finished worker discovery
05:12:38 DISPATCHER: Starting worker discovery
05:12:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:12:38 DISPATCHER: Finished worker discovery
05:13:38 DISPATCHER: Starting worker discovery
05:13:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:13:38 DISPATCHER: Finished worker discovery
05:14:25 WORKER: done with job (6, 0, 3), trying to register it.
05:14:25 WORKER: registered result for job (6, 0, 3) with dispatcher
05:14:25 DISPATCHER: job (6, 0, 3) finished
05:14:25 DISPATCHER: register_result: lock acquired
05:14:25 DISPATCHER: job (6, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
05:14:25 job_id: (6, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 842, 'last_n_outputs': 17, 'leak_rate': 0.9891536281362612, 'lr': 0.009327523451119453, 'optimizer': 'Adam', 'sparsity': 0.8073132559088617, 'steps_to_train': 14, 'weight_decay': 0.028489749713102468}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.1395289929744303, 'info': {'sick_no_sick': 0.1395289929744303, 'config': "{'batch_size': 16, 'hidden_dim': 842, 'last_n_outputs': 17, 'leak_rate': 0.9891536281362612, 'lr': 0.009327523451119453, 'optimizer': 'Adam', 'sparsity': 0.8073132559088617, 'steps_to_train': 14, 'weight_decay': 0.028489749713102468}"}}
exception: None

05:14:25 job_callback for (6, 0, 3) started
05:14:25 DISPATCHER: Trying to submit another job.
05:14:25 job_callback for (6, 0, 3) got condition
05:14:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:14:25 HBMASTER: Trying to run another job!
05:14:25 job_callback for (6, 0, 3) finished
05:14:25 HBMASTER: schedule new run for iteration 6
05:14:25 HBMASTER: trying submitting job (6, 0, 5) to dispatcher
05:14:25 HBMASTER: submitting job (6, 0, 5) to dispatcher
05:14:25 DISPATCHER: trying to submit job (6, 0, 5)
05:14:25 DISPATCHER: trying to notify the job_runner thread.
05:14:25 HBMASTER: job (6, 0, 5) submitted to dispatcher
05:14:25 DISPATCHER: Trying to submit another job.
05:14:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:14:25 DISPATCHER: starting job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776
05:14:25 DISPATCHER: job (6, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
05:14:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:14:25 WORKER: start processing job (6, 0, 5)
05:14:25 WORKER: args: ()
05:14:25 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 876, 'last_n_outputs': 17, 'leak_rate': 0.8783845629167046, 'lr': 0.0020530369253484587, 'optimizer': 'SGD', 'sparsity': 0.7697443235094922, 'steps_to_train': 73, 'weight_decay': 0.011454912422104379}, 'budget': 1200.0, 'working_directory': '.'}
05:14:38 DISPATCHER: Starting worker discovery
05:14:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:14:38 DISPATCHER: Finished worker discovery
05:15:38 DISPATCHER: Starting worker discovery
05:15:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:15:38 DISPATCHER: Finished worker discovery
05:16:38 DISPATCHER: Starting worker discovery
05:16:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:16:38 DISPATCHER: Finished worker discovery
05:17:38 DISPATCHER: Starting worker discovery
05:17:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:17:38 DISPATCHER: Finished worker discovery
05:18:38 DISPATCHER: Starting worker discovery
05:18:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:18:38 DISPATCHER: Finished worker discovery
05:19:38 DISPATCHER: Starting worker discovery
05:19:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:19:38 DISPATCHER: Finished worker discovery
05:20:38 DISPATCHER: Starting worker discovery
05:20:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:20:38 DISPATCHER: Finished worker discovery
05:21:38 DISPATCHER: Starting worker discovery
05:21:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:21:38 DISPATCHER: Finished worker discovery
05:22:38 DISPATCHER: Starting worker discovery
05:22:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:22:38 DISPATCHER: Finished worker discovery
05:23:38 DISPATCHER: Starting worker discovery
05:23:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:23:38 DISPATCHER: Finished worker discovery
05:24:38 DISPATCHER: Starting worker discovery
05:24:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:24:38 DISPATCHER: Finished worker discovery
05:25:38 DISPATCHER: Starting worker discovery
05:25:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:25:38 DISPATCHER: Finished worker discovery
05:26:38 DISPATCHER: Starting worker discovery
05:26:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:26:38 DISPATCHER: Finished worker discovery
05:27:38 DISPATCHER: Starting worker discovery
05:27:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:27:38 DISPATCHER: Finished worker discovery
05:28:38 DISPATCHER: Starting worker discovery
05:28:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:28:38 DISPATCHER: Finished worker discovery
05:29:38 DISPATCHER: Starting worker discovery
05:29:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:29:38 DISPATCHER: Finished worker discovery
05:30:38 DISPATCHER: Starting worker discovery
05:30:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:30:38 DISPATCHER: Finished worker discovery
05:31:38 DISPATCHER: Starting worker discovery
05:31:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:31:38 DISPATCHER: Finished worker discovery
05:32:38 DISPATCHER: Starting worker discovery
05:32:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:32:38 DISPATCHER: Finished worker discovery
05:33:38 DISPATCHER: Starting worker discovery
05:33:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:33:38 DISPATCHER: Finished worker discovery
05:34:38 DISPATCHER: Starting worker discovery
05:34:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:34:38 DISPATCHER: Finished worker discovery
05:35:35 WORKER: done with job (6, 0, 5), trying to register it.
05:35:35 WORKER: registered result for job (6, 0, 5) with dispatcher
05:35:35 DISPATCHER: job (6, 0, 5) finished
05:35:35 DISPATCHER: register_result: lock acquired
05:35:35 DISPATCHER: job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
05:35:35 job_id: (6, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 876, 'last_n_outputs': 17, 'leak_rate': 0.8783845629167046, 'lr': 0.0020530369253484587, 'optimizer': 'SGD', 'sparsity': 0.7697443235094922, 'steps_to_train': 73, 'weight_decay': 0.011454912422104379}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.1791806647009907, 'info': {'sick_no_sick': 0.1791806647009907, 'config': "{'batch_size': 128, 'hidden_dim': 876, 'last_n_outputs': 17, 'leak_rate': 0.8783845629167046, 'lr': 0.0020530369253484587, 'optimizer': 'SGD', 'sparsity': 0.7697443235094922, 'steps_to_train': 73, 'weight_decay': 0.011454912422104379}"}}
exception: None

05:35:35 job_callback for (6, 0, 5) started
05:35:35 job_callback for (6, 0, 5) got condition
05:35:35 DISPATCHER: Trying to submit another job.
05:35:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:35:35 HBMASTER: Trying to run another job!
05:35:35 job_callback for (6, 0, 5) finished
05:35:35 start sampling a new configuration.
05:35:35 best_vector: [1, 0.8833818634003937, 0.9920608373895852, 0.7545580556401472, 0.11976063801736944, 0, 0.20168084027113936, 0.10420617567649926, 0.20780986879425634], 0.04693387613625451, 0.027734158334377385, 0.001301671552008939
05:35:35 done sampling a new configuration.
05:35:35 HBMASTER: schedule new run for iteration 7
05:35:35 HBMASTER: trying submitting job (7, 0, 0) to dispatcher
05:35:35 HBMASTER: submitting job (7, 0, 0) to dispatcher
05:35:35 DISPATCHER: trying to submit job (7, 0, 0)
05:35:35 DISPATCHER: trying to notify the job_runner thread.
05:35:35 HBMASTER: job (7, 0, 0) submitted to dispatcher
05:35:35 DISPATCHER: Trying to submit another job.
05:35:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:35:35 DISPATCHER: starting job (7, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
05:35:35 DISPATCHER: job (7, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
05:35:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:35:35 WORKER: start processing job (7, 0, 0)
05:35:35 WORKER: args: ()
05:35:35 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 907, 'last_n_outputs': 50, 'leak_rate': 0.9386395139100367, 'lr': 0.001735886301650768, 'optimizer': 'Adam', 'sparsity': 0.7984034016650734, 'steps_to_train': 19, 'weight_decay': 0.018636608097932106}, 'budget': 1200.0, 'working_directory': '.'}
05:35:38 DISPATCHER: Starting worker discovery
05:35:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:35:38 DISPATCHER: Finished worker discovery
05:36:38 DISPATCHER: Starting worker discovery
05:36:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:36:38 DISPATCHER: Finished worker discovery
05:37:38 DISPATCHER: Starting worker discovery
05:37:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:37:38 DISPATCHER: Finished worker discovery
05:38:38 DISPATCHER: Starting worker discovery
05:38:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:38:38 DISPATCHER: Finished worker discovery
05:39:38 DISPATCHER: Starting worker discovery
05:39:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:39:38 DISPATCHER: Finished worker discovery
05:40:38 DISPATCHER: Starting worker discovery
05:40:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:40:38 DISPATCHER: Finished worker discovery
05:41:38 DISPATCHER: Starting worker discovery
05:41:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:41:38 DISPATCHER: Finished worker discovery
05:42:38 DISPATCHER: Starting worker discovery
05:42:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:42:39 DISPATCHER: Finished worker discovery
05:43:39 DISPATCHER: Starting worker discovery
05:43:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:43:39 DISPATCHER: Finished worker discovery
05:44:39 DISPATCHER: Starting worker discovery
05:44:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:44:39 DISPATCHER: Finished worker discovery
05:45:39 DISPATCHER: Starting worker discovery
05:45:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:45:39 DISPATCHER: Finished worker discovery
05:46:39 DISPATCHER: Starting worker discovery
05:46:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:46:39 DISPATCHER: Finished worker discovery
05:47:39 DISPATCHER: Starting worker discovery
05:47:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:47:39 DISPATCHER: Finished worker discovery
05:48:39 DISPATCHER: Starting worker discovery
05:48:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:48:39 DISPATCHER: Finished worker discovery
05:49:39 DISPATCHER: Starting worker discovery
05:49:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:49:39 DISPATCHER: Finished worker discovery
05:50:39 DISPATCHER: Starting worker discovery
05:50:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:50:39 DISPATCHER: Finished worker discovery
05:51:39 DISPATCHER: Starting worker discovery
05:51:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:51:39 DISPATCHER: Finished worker discovery
05:52:39 DISPATCHER: Starting worker discovery
05:52:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:52:39 DISPATCHER: Finished worker discovery
05:53:39 DISPATCHER: Starting worker discovery
05:53:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:53:39 DISPATCHER: Finished worker discovery
05:54:39 DISPATCHER: Starting worker discovery
05:54:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:54:39 DISPATCHER: Finished worker discovery
05:55:39 DISPATCHER: Starting worker discovery
05:55:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:55:39 DISPATCHER: Finished worker discovery
05:56:39 DISPATCHER: Starting worker discovery
05:56:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:56:39 DISPATCHER: Finished worker discovery
05:56:54 WORKER: done with job (7, 0, 0), trying to register it.
05:56:54 WORKER: registered result for job (7, 0, 0) with dispatcher
05:56:54 DISPATCHER: job (7, 0, 0) finished
05:56:54 DISPATCHER: register_result: lock acquired
05:56:54 DISPATCHER: job (7, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
05:56:54 job_id: (7, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 907, 'last_n_outputs': 50, 'leak_rate': 0.9386395139100367, 'lr': 0.001735886301650768, 'optimizer': 'Adam', 'sparsity': 0.7984034016650734, 'steps_to_train': 19, 'weight_decay': 0.018636608097932106}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.20203286165949516, 'info': {'sick_no_sick': 0.20203286165949516, 'config': "{'batch_size': 32, 'hidden_dim': 907, 'last_n_outputs': 50, 'leak_rate': 0.9386395139100367, 'lr': 0.001735886301650768, 'optimizer': 'Adam', 'sparsity': 0.7984034016650734, 'steps_to_train': 19, 'weight_decay': 0.018636608097932106}"}}
exception: None

05:56:54 job_callback for (7, 0, 0) started
05:56:54 DISPATCHER: Trying to submit another job.
05:56:54 job_callback for (7, 0, 0) got condition
05:56:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:56:54 HBMASTER: Trying to run another job!
05:56:54 job_callback for (7, 0, 0) finished
05:56:54 start sampling a new configuration.
05:56:54 best_vector: [2, 0.9323671777275444, 0.6196807661035155, 0.7387106683815291, 0.21590204013003325, 0, 0.3066156438792065, 0.8429517400335769, 0.25348553027083326], 0.06382187509102062, 0.052128776437068924, 0.0033269562584143523
05:56:54 done sampling a new configuration.
05:56:54 HBMASTER: schedule new run for iteration 7
05:56:54 HBMASTER: trying submitting job (7, 0, 1) to dispatcher
05:56:54 HBMASTER: submitting job (7, 0, 1) to dispatcher
05:56:54 DISPATCHER: trying to submit job (7, 0, 1)
05:56:54 DISPATCHER: trying to notify the job_runner thread.
05:56:54 HBMASTER: job (7, 0, 1) submitted to dispatcher
05:56:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:56:54 DISPATCHER: Trying to submit another job.
05:56:54 DISPATCHER: starting job (7, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
05:56:54 DISPATCHER: job (7, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
05:56:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:56:54 WORKER: start processing job (7, 0, 1)
05:56:54 WORKER: args: ()
05:56:54 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 946, 'last_n_outputs': 35, 'leak_rate': 0.9346776670953822, 'lr': 0.0027027388244494016, 'optimizer': 'Adam', 'sparsity': 0.8235877545310095, 'steps_to_train': 86, 'weight_decay': 0.02136939753635469}, 'budget': 1200.0, 'working_directory': '.'}
05:57:39 DISPATCHER: Starting worker discovery
05:57:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:57:39 DISPATCHER: Finished worker discovery
05:58:39 DISPATCHER: Starting worker discovery
05:58:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:58:39 DISPATCHER: Finished worker discovery
05:59:39 DISPATCHER: Starting worker discovery
05:59:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:59:39 DISPATCHER: Finished worker discovery
06:00:39 DISPATCHER: Starting worker discovery
06:00:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:00:39 DISPATCHER: Finished worker discovery
06:01:39 DISPATCHER: Starting worker discovery
06:01:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:01:39 DISPATCHER: Finished worker discovery
06:02:39 DISPATCHER: Starting worker discovery
06:02:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:02:39 DISPATCHER: Finished worker discovery
06:03:39 DISPATCHER: Starting worker discovery
06:03:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:03:39 DISPATCHER: Finished worker discovery
06:04:39 DISPATCHER: Starting worker discovery
06:04:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:04:39 DISPATCHER: Finished worker discovery
06:05:39 DISPATCHER: Starting worker discovery
06:05:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:05:39 DISPATCHER: Finished worker discovery
06:06:39 DISPATCHER: Starting worker discovery
06:06:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:06:39 DISPATCHER: Finished worker discovery
06:07:39 DISPATCHER: Starting worker discovery
06:07:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:07:39 DISPATCHER: Finished worker discovery
06:08:39 DISPATCHER: Starting worker discovery
06:08:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:08:39 DISPATCHER: Finished worker discovery
06:09:39 DISPATCHER: Starting worker discovery
06:09:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:09:39 DISPATCHER: Finished worker discovery
06:10:39 DISPATCHER: Starting worker discovery
06:10:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:10:39 DISPATCHER: Finished worker discovery
06:11:39 DISPATCHER: Starting worker discovery
06:11:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:11:39 DISPATCHER: Finished worker discovery
06:12:39 DISPATCHER: Starting worker discovery
06:12:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:12:39 DISPATCHER: Finished worker discovery
06:13:39 DISPATCHER: Starting worker discovery
06:13:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:13:39 DISPATCHER: Finished worker discovery
06:14:39 DISPATCHER: Starting worker discovery
06:14:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:14:39 DISPATCHER: Finished worker discovery
06:15:39 DISPATCHER: Starting worker discovery
06:15:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:15:39 DISPATCHER: Finished worker discovery
06:16:39 DISPATCHER: Starting worker discovery
06:16:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:16:39 DISPATCHER: Finished worker discovery
06:17:39 DISPATCHER: Starting worker discovery
06:17:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:17:39 DISPATCHER: Finished worker discovery
06:18:02 WORKER: done with job (7, 0, 1), trying to register it.
06:18:02 WORKER: registered result for job (7, 0, 1) with dispatcher
06:18:02 DISPATCHER: job (7, 0, 1) finished
06:18:02 DISPATCHER: register_result: lock acquired
06:18:02 DISPATCHER: job (7, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
06:18:02 job_id: (7, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 946, 'last_n_outputs': 35, 'leak_rate': 0.9346776670953822, 'lr': 0.0027027388244494016, 'optimizer': 'Adam', 'sparsity': 0.8235877545310095, 'steps_to_train': 86, 'weight_decay': 0.02136939753635469}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.1201612401545279, 'info': {'sick_no_sick': 0.1201612401545279, 'config': "{'batch_size': 64, 'hidden_dim': 946, 'last_n_outputs': 35, 'leak_rate': 0.9346776670953822, 'lr': 0.0027027388244494016, 'optimizer': 'Adam', 'sparsity': 0.8235877545310095, 'steps_to_train': 86, 'weight_decay': 0.02136939753635469}"}}
exception: None

06:18:02 job_callback for (7, 0, 1) started
06:18:02 DISPATCHER: Trying to submit another job.
06:18:02 job_callback for (7, 0, 1) got condition
06:18:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:18:02 HBMASTER: Trying to run another job!
06:18:02 job_callback for (7, 0, 1) finished
06:18:02 start sampling a new configuration.
06:18:02 done sampling a new configuration.
06:18:02 HBMASTER: schedule new run for iteration 7
06:18:02 HBMASTER: trying submitting job (7, 0, 2) to dispatcher
06:18:02 HBMASTER: submitting job (7, 0, 2) to dispatcher
06:18:02 DISPATCHER: trying to submit job (7, 0, 2)
06:18:02 DISPATCHER: trying to notify the job_runner thread.
06:18:02 HBMASTER: job (7, 0, 2) submitted to dispatcher
06:18:02 DISPATCHER: Trying to submit another job.
06:18:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:18:02 DISPATCHER: starting job (7, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:18:02 DISPATCHER: job (7, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:18:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:18:02 WORKER: start processing job (7, 0, 2)
06:18:02 WORKER: args: ()
06:18:02 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 782, 'last_n_outputs': 42, 'leak_rate': 0.8832006604890632, 'lr': 0.006809267908127212, 'optimizer': 'SGD', 'sparsity': 0.815695633753873, 'steps_to_train': 76, 'weight_decay': 0.0810733216695734}, 'budget': 1200.0, 'working_directory': '.'}
06:18:39 DISPATCHER: Starting worker discovery
06:18:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:18:39 DISPATCHER: Finished worker discovery
06:19:39 DISPATCHER: Starting worker discovery
06:19:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:19:39 DISPATCHER: Finished worker discovery
06:20:39 DISPATCHER: Starting worker discovery
06:20:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:20:39 DISPATCHER: Finished worker discovery
06:21:39 DISPATCHER: Starting worker discovery
06:21:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:21:39 DISPATCHER: Finished worker discovery
06:22:39 DISPATCHER: Starting worker discovery
06:22:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:22:39 DISPATCHER: Finished worker discovery
06:23:39 DISPATCHER: Starting worker discovery
06:23:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:23:39 DISPATCHER: Finished worker discovery
06:24:39 DISPATCHER: Starting worker discovery
06:24:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:24:39 DISPATCHER: Finished worker discovery
06:25:39 DISPATCHER: Starting worker discovery
06:25:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:25:39 DISPATCHER: Finished worker discovery
06:26:39 DISPATCHER: Starting worker discovery
06:26:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:26:39 DISPATCHER: Finished worker discovery
06:27:39 DISPATCHER: Starting worker discovery
06:27:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:27:39 DISPATCHER: Finished worker discovery
06:28:39 DISPATCHER: Starting worker discovery
06:28:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:28:39 DISPATCHER: Finished worker discovery
06:29:39 DISPATCHER: Starting worker discovery
06:29:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:29:39 DISPATCHER: Finished worker discovery
06:30:39 DISPATCHER: Starting worker discovery
06:30:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:30:39 DISPATCHER: Finished worker discovery
06:31:39 DISPATCHER: Starting worker discovery
06:31:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:31:39 DISPATCHER: Finished worker discovery
06:32:39 DISPATCHER: Starting worker discovery
06:32:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:32:39 DISPATCHER: Finished worker discovery
06:33:39 DISPATCHER: Starting worker discovery
06:33:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:33:39 DISPATCHER: Finished worker discovery
06:34:39 DISPATCHER: Starting worker discovery
06:34:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:34:39 DISPATCHER: Finished worker discovery
06:35:39 DISPATCHER: Starting worker discovery
06:35:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:35:39 DISPATCHER: Finished worker discovery
06:36:39 DISPATCHER: Starting worker discovery
06:36:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:36:39 DISPATCHER: Finished worker discovery
06:37:39 DISPATCHER: Starting worker discovery
06:37:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:37:39 DISPATCHER: Finished worker discovery
06:38:39 DISPATCHER: Starting worker discovery
06:38:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:38:39 DISPATCHER: Finished worker discovery
06:39:10 WORKER: done with job (7, 0, 2), trying to register it.
06:39:10 WORKER: registered result for job (7, 0, 2) with dispatcher
06:39:10 DISPATCHER: job (7, 0, 2) finished
06:39:10 DISPATCHER: register_result: lock acquired
06:39:10 DISPATCHER: job (7, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
06:39:10 job_id: (7, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 782, 'last_n_outputs': 42, 'leak_rate': 0.8832006604890632, 'lr': 0.006809267908127212, 'optimizer': 'SGD', 'sparsity': 0.815695633753873, 'steps_to_train': 76, 'weight_decay': 0.0810733216695734}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.16695993293407227, 'info': {'sick_no_sick': 0.16695993293407227, 'config': "{'batch_size': 16, 'hidden_dim': 782, 'last_n_outputs': 42, 'leak_rate': 0.8832006604890632, 'lr': 0.006809267908127212, 'optimizer': 'SGD', 'sparsity': 0.815695633753873, 'steps_to_train': 76, 'weight_decay': 0.0810733216695734}"}}
exception: None

06:39:10 job_callback for (7, 0, 2) started
06:39:10 job_callback for (7, 0, 2) got condition
06:39:10 DISPATCHER: Trying to submit another job.
06:39:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:39:10 HBMASTER: Trying to run another job!
06:39:10 job_callback for (7, 0, 2) finished
06:39:10 start sampling a new configuration.
06:39:10 best_vector: [1, 0.8482060900282092, 0.634342512203732, 0.6647193585526542, 0.18020915877935373, 1, 0.08183404386024765, 0.8966396815035389, 0.10999554637926337], 0.004049414219944807, 0.14901101131176198, 0.0006034073081342054
06:39:10 done sampling a new configuration.
06:39:10 HBMASTER: schedule new run for iteration 7
06:39:10 HBMASTER: trying submitting job (7, 0, 3) to dispatcher
06:39:10 HBMASTER: submitting job (7, 0, 3) to dispatcher
06:39:10 DISPATCHER: trying to submit job (7, 0, 3)
06:39:10 DISPATCHER: trying to notify the job_runner thread.
06:39:10 HBMASTER: job (7, 0, 3) submitted to dispatcher
06:39:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:39:10 DISPATCHER: Trying to submit another job.
06:39:10 DISPATCHER: starting job (7, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:39:10 DISPATCHER: job (7, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:39:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:39:10 WORKER: start processing job (7, 0, 3)
06:39:10 WORKER: args: ()
06:39:10 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 879, 'last_n_outputs': 36, 'leak_rate': 0.9161798396381635, 'lr': 0.002293075306513826, 'optimizer': 'SGD', 'sparsity': 0.7696401705264594, 'steps_to_train': 91, 'weight_decay': 0.01390296742589592}, 'budget': 1200.0, 'working_directory': '.'}
06:39:39 DISPATCHER: Starting worker discovery
06:39:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:39:39 DISPATCHER: Finished worker discovery
06:40:39 DISPATCHER: Starting worker discovery
06:40:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:40:39 DISPATCHER: Finished worker discovery
06:41:39 DISPATCHER: Starting worker discovery
06:41:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:41:39 DISPATCHER: Finished worker discovery
06:42:39 DISPATCHER: Starting worker discovery
06:42:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:42:39 DISPATCHER: Finished worker discovery
06:43:39 DISPATCHER: Starting worker discovery
06:43:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:43:39 DISPATCHER: Finished worker discovery
06:44:39 DISPATCHER: Starting worker discovery
06:44:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:44:39 DISPATCHER: Finished worker discovery
06:45:39 DISPATCHER: Starting worker discovery
06:45:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:45:39 DISPATCHER: Finished worker discovery
06:46:39 DISPATCHER: Starting worker discovery
06:46:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:46:39 DISPATCHER: Finished worker discovery
06:47:39 DISPATCHER: Starting worker discovery
06:47:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:47:39 DISPATCHER: Finished worker discovery
06:48:39 DISPATCHER: Starting worker discovery
06:48:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:48:39 DISPATCHER: Finished worker discovery
06:49:39 DISPATCHER: Starting worker discovery
06:49:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:49:39 DISPATCHER: Finished worker discovery
06:50:39 DISPATCHER: Starting worker discovery
06:50:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:50:39 DISPATCHER: Finished worker discovery
06:51:39 DISPATCHER: Starting worker discovery
06:51:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:51:39 DISPATCHER: Finished worker discovery
06:52:39 DISPATCHER: Starting worker discovery
06:52:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:52:39 DISPATCHER: Finished worker discovery
06:53:39 DISPATCHER: Starting worker discovery
06:53:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:53:39 DISPATCHER: Finished worker discovery
06:54:39 DISPATCHER: Starting worker discovery
06:54:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:54:39 DISPATCHER: Finished worker discovery
06:55:39 DISPATCHER: Starting worker discovery
06:55:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:55:39 DISPATCHER: Finished worker discovery
06:56:39 DISPATCHER: Starting worker discovery
06:56:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:56:39 DISPATCHER: Finished worker discovery
06:57:39 DISPATCHER: Starting worker discovery
06:57:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:57:39 DISPATCHER: Finished worker discovery
06:58:39 DISPATCHER: Starting worker discovery
06:58:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:58:39 DISPATCHER: Finished worker discovery
06:59:39 DISPATCHER: Starting worker discovery
06:59:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:59:39 DISPATCHER: Finished worker discovery
07:00:18 WORKER: done with job (7, 0, 3), trying to register it.
07:00:18 WORKER: registered result for job (7, 0, 3) with dispatcher
07:00:18 DISPATCHER: job (7, 0, 3) finished
07:00:18 DISPATCHER: register_result: lock acquired
07:00:18 DISPATCHER: job (7, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
07:00:18 job_id: (7, 0, 3)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 879, 'last_n_outputs': 36, 'leak_rate': 0.9161798396381635, 'lr': 0.002293075306513826, 'optimizer': 'SGD', 'sparsity': 0.7696401705264594, 'steps_to_train': 91, 'weight_decay': 0.01390296742589592}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.09339078961362285, 'info': {'sick_no_sick': 0.09339078961362285, 'config': "{'batch_size': 32, 'hidden_dim': 879, 'last_n_outputs': 36, 'leak_rate': 0.9161798396381635, 'lr': 0.002293075306513826, 'optimizer': 'SGD', 'sparsity': 0.7696401705264594, 'steps_to_train': 91, 'weight_decay': 0.01390296742589592}"}}
exception: None

07:00:18 job_callback for (7, 0, 3) started
07:00:18 job_callback for (7, 0, 3) got condition
07:00:18 DISPATCHER: Trying to submit another job.
07:00:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:00:18 HBMASTER: Trying to run another job!
07:00:18 job_callback for (7, 0, 3) finished
07:00:18 start sampling a new configuration.
07:00:18 done sampling a new configuration.
07:00:18 HBMASTER: schedule new run for iteration 8
07:00:18 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
07:00:18 HBMASTER: submitting job (8, 0, 0) to dispatcher
07:00:18 DISPATCHER: trying to submit job (8, 0, 0)
07:00:18 DISPATCHER: trying to notify the job_runner thread.
07:00:18 HBMASTER: job (8, 0, 0) submitted to dispatcher
07:00:18 DISPATCHER: Trying to submit another job.
07:00:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:00:18 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:00:18 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:00:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:00:18 WORKER: start processing job (8, 0, 0)
07:00:18 WORKER: args: ()
07:00:18 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 744, 'last_n_outputs': 18, 'leak_rate': 0.7818873900420945, 'lr': 0.06519442365811802, 'optimizer': 'SGD', 'sparsity': 0.8219856276131269, 'steps_to_train': 57, 'weight_decay': 0.16380759736552447}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:00:39 DISPATCHER: Starting worker discovery
07:00:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:00:39 DISPATCHER: Finished worker discovery
07:01:39 DISPATCHER: Starting worker discovery
07:01:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:01:39 DISPATCHER: Finished worker discovery
07:02:06 WORKER: done with job (8, 0, 0), trying to register it.
07:02:06 WORKER: registered result for job (8, 0, 0) with dispatcher
07:02:06 DISPATCHER: job (8, 0, 0) finished
07:02:06 DISPATCHER: register_result: lock acquired
07:02:06 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
07:02:06 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 744, 'last_n_outputs': 18, 'leak_rate': 0.7818873900420945, 'lr': 0.06519442365811802, 'optimizer': 'SGD', 'sparsity': 0.8219856276131269, 'steps_to_train': 57, 'weight_decay': 0.16380759736552447}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.008892894502993853, 'info': {'sick_no_sick': 0.008892894502993853, 'config': "{'batch_size': 32, 'hidden_dim': 744, 'last_n_outputs': 18, 'leak_rate': 0.7818873900420945, 'lr': 0.06519442365811802, 'optimizer': 'SGD', 'sparsity': 0.8219856276131269, 'steps_to_train': 57, 'weight_decay': 0.16380759736552447}"}}
exception: None

07:02:06 job_callback for (8, 0, 0) started
07:02:06 DISPATCHER: Trying to submit another job.
07:02:06 job_callback for (8, 0, 0) got condition
07:02:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:02:06 HBMASTER: Trying to run another job!
07:02:06 job_callback for (8, 0, 0) finished
07:02:06 start sampling a new configuration.
07:02:06 done sampling a new configuration.
07:02:06 HBMASTER: schedule new run for iteration 8
07:02:06 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
07:02:06 HBMASTER: submitting job (8, 0, 1) to dispatcher
07:02:06 DISPATCHER: trying to submit job (8, 0, 1)
07:02:06 DISPATCHER: trying to notify the job_runner thread.
07:02:06 HBMASTER: job (8, 0, 1) submitted to dispatcher
07:02:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:02:06 DISPATCHER: Trying to submit another job.
07:02:06 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:02:06 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:02:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:02:06 WORKER: start processing job (8, 0, 1)
07:02:06 WORKER: args: ()
07:02:06 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 817, 'last_n_outputs': 27, 'leak_rate': 0.7568773933770823, 'lr': 0.06998354266203823, 'optimizer': 'SGD', 'sparsity': 0.7596823070420868, 'steps_to_train': 94, 'weight_decay': 0.03210024944795948}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:02:39 DISPATCHER: Starting worker discovery
07:02:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:02:39 DISPATCHER: Finished worker discovery
07:03:39 DISPATCHER: Starting worker discovery
07:03:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:03:39 DISPATCHER: Finished worker discovery
07:03:54 WORKER: done with job (8, 0, 1), trying to register it.
07:03:54 WORKER: registered result for job (8, 0, 1) with dispatcher
07:03:54 DISPATCHER: job (8, 0, 1) finished
07:03:54 DISPATCHER: register_result: lock acquired
07:03:54 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
07:03:54 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 817, 'last_n_outputs': 27, 'leak_rate': 0.7568773933770823, 'lr': 0.06998354266203823, 'optimizer': 'SGD', 'sparsity': 0.7596823070420868, 'steps_to_train': 94, 'weight_decay': 0.03210024944795948}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.020331862322245323, 'info': {'sick_no_sick': 0.020331862322245323, 'config': "{'batch_size': 128, 'hidden_dim': 817, 'last_n_outputs': 27, 'leak_rate': 0.7568773933770823, 'lr': 0.06998354266203823, 'optimizer': 'SGD', 'sparsity': 0.7596823070420868, 'steps_to_train': 94, 'weight_decay': 0.03210024944795948}"}}
exception: None

07:03:54 job_callback for (8, 0, 1) started
07:03:54 DISPATCHER: Trying to submit another job.
07:03:54 job_callback for (8, 0, 1) got condition
07:03:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:03:54 HBMASTER: Trying to run another job!
07:03:54 job_callback for (8, 0, 1) finished
07:03:54 start sampling a new configuration.
07:03:54 done sampling a new configuration.
07:03:54 HBMASTER: schedule new run for iteration 8
07:03:54 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
07:03:54 HBMASTER: submitting job (8, 0, 2) to dispatcher
07:03:54 DISPATCHER: trying to submit job (8, 0, 2)
07:03:54 DISPATCHER: trying to notify the job_runner thread.
07:03:54 HBMASTER: job (8, 0, 2) submitted to dispatcher
07:03:54 DISPATCHER: Trying to submit another job.
07:03:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:03:54 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:03:54 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:03:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:03:54 WORKER: start processing job (8, 0, 2)
07:03:54 WORKER: args: ()
07:03:54 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 323, 'last_n_outputs': 19, 'leak_rate': 0.9027920548909214, 'lr': 0.002324674070621149, 'optimizer': 'SGD', 'sparsity': 0.8974159384851641, 'steps_to_train': 62, 'weight_decay': 0.06458373611608595}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:04:39 DISPATCHER: Starting worker discovery
07:04:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:04:39 DISPATCHER: Finished worker discovery
07:05:39 DISPATCHER: Starting worker discovery
07:05:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:05:39 DISPATCHER: Finished worker discovery
07:05:40 WORKER: done with job (8, 0, 2), trying to register it.
07:05:40 WORKER: registered result for job (8, 0, 2) with dispatcher
07:05:40 DISPATCHER: job (8, 0, 2) finished
07:05:40 DISPATCHER: register_result: lock acquired
07:05:40 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
07:05:40 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 323, 'last_n_outputs': 19, 'leak_rate': 0.9027920548909214, 'lr': 0.002324674070621149, 'optimizer': 'SGD', 'sparsity': 0.8974159384851641, 'steps_to_train': 62, 'weight_decay': 0.06458373611608595}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.17073054698169982, 'info': {'sick_no_sick': 0.17073054698169982, 'config': "{'batch_size': 128, 'hidden_dim': 323, 'last_n_outputs': 19, 'leak_rate': 0.9027920548909214, 'lr': 0.002324674070621149, 'optimizer': 'SGD', 'sparsity': 0.8974159384851641, 'steps_to_train': 62, 'weight_decay': 0.06458373611608595}"}}
exception: None

07:05:40 job_callback for (8, 0, 2) started
07:05:40 DISPATCHER: Trying to submit another job.
07:05:40 job_callback for (8, 0, 2) got condition
07:05:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:05:40 HBMASTER: Trying to run another job!
07:05:40 job_callback for (8, 0, 2) finished
07:05:40 start sampling a new configuration.
07:05:40 done sampling a new configuration.
07:05:40 HBMASTER: schedule new run for iteration 8
07:05:40 HBMASTER: trying submitting job (8, 0, 3) to dispatcher
07:05:40 HBMASTER: submitting job (8, 0, 3) to dispatcher
07:05:40 DISPATCHER: trying to submit job (8, 0, 3)
07:05:40 DISPATCHER: trying to notify the job_runner thread.
07:05:40 HBMASTER: job (8, 0, 3) submitted to dispatcher
07:05:40 DISPATCHER: Trying to submit another job.
07:05:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:05:40 DISPATCHER: starting job (8, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:05:40 DISPATCHER: job (8, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:05:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:05:40 WORKER: start processing job (8, 0, 3)
07:05:40 WORKER: args: ()
07:05:40 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 364, 'last_n_outputs': 13, 'leak_rate': 0.9577038656274544, 'lr': 0.005729804582406669, 'optimizer': 'SGD', 'sparsity': 0.9314057416979906, 'steps_to_train': 14, 'weight_decay': 0.15160571160419276}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:06:39 DISPATCHER: Starting worker discovery
07:06:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:06:39 DISPATCHER: Finished worker discovery
07:07:28 WORKER: done with job (8, 0, 3), trying to register it.
07:07:28 WORKER: registered result for job (8, 0, 3) with dispatcher
07:07:28 DISPATCHER: job (8, 0, 3) finished
07:07:28 DISPATCHER: register_result: lock acquired
07:07:28 DISPATCHER: job (8, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
07:07:28 job_id: (8, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 364, 'last_n_outputs': 13, 'leak_rate': 0.9577038656274544, 'lr': 0.005729804582406669, 'optimizer': 'SGD', 'sparsity': 0.9314057416979906, 'steps_to_train': 14, 'weight_decay': 0.15160571160419276}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.13757533547271353, 'info': {'sick_no_sick': 0.13757533547271353, 'config': "{'batch_size': 128, 'hidden_dim': 364, 'last_n_outputs': 13, 'leak_rate': 0.9577038656274544, 'lr': 0.005729804582406669, 'optimizer': 'SGD', 'sparsity': 0.9314057416979906, 'steps_to_train': 14, 'weight_decay': 0.15160571160419276}"}}
exception: None

07:07:28 job_callback for (8, 0, 3) started
07:07:28 DISPATCHER: Trying to submit another job.
07:07:28 job_callback for (8, 0, 3) got condition
07:07:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:07:28 HBMASTER: Trying to run another job!
07:07:28 job_callback for (8, 0, 3) finished
07:07:28 start sampling a new configuration.
07:07:28 best_vector: [0, 0.8844362418763779, 0.4548654010797716, 0.7189947874316633, 0.15180177645891907, 0, 0.30754503392608823, 0.7279224572991944, 0.34040302689502644], 0.0702103528978246, 0.11197562322781, 0.007861848022778384
07:07:28 done sampling a new configuration.
07:07:28 HBMASTER: schedule new run for iteration 8
07:07:28 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
07:07:28 HBMASTER: submitting job (8, 0, 4) to dispatcher
07:07:28 DISPATCHER: trying to submit job (8, 0, 4)
07:07:28 DISPATCHER: trying to notify the job_runner thread.
07:07:28 HBMASTER: job (8, 0, 4) submitted to dispatcher
07:07:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:07:28 DISPATCHER: Trying to submit another job.
07:07:28 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:07:28 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:07:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:07:28 WORKER: start processing job (8, 0, 4)
07:07:28 WORKER: args: ()
07:07:28 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 908, 'last_n_outputs': 28, 'leak_rate': 0.9297486968579158, 'lr': 0.0020118868541185242, 'optimizer': 'Adam', 'sparsity': 0.8238108081422612, 'steps_to_train': 76, 'weight_decay': 0.027725191121352414}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:07:39 DISPATCHER: Starting worker discovery
07:07:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:07:39 DISPATCHER: Finished worker discovery
07:08:39 DISPATCHER: Starting worker discovery
07:08:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:08:39 DISPATCHER: Finished worker discovery
07:09:15 WORKER: done with job (8, 0, 4), trying to register it.
07:09:15 WORKER: registered result for job (8, 0, 4) with dispatcher
07:09:15 DISPATCHER: job (8, 0, 4) finished
07:09:15 DISPATCHER: register_result: lock acquired
07:09:15 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
07:09:15 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 908, 'last_n_outputs': 28, 'leak_rate': 0.9297486968579158, 'lr': 0.0020118868541185242, 'optimizer': 'Adam', 'sparsity': 0.8238108081422612, 'steps_to_train': 76, 'weight_decay': 0.027725191121352414}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.13211179822209748, 'info': {'sick_no_sick': 0.13211179822209748, 'config': "{'batch_size': 16, 'hidden_dim': 908, 'last_n_outputs': 28, 'leak_rate': 0.9297486968579158, 'lr': 0.0020118868541185242, 'optimizer': 'Adam', 'sparsity': 0.8238108081422612, 'steps_to_train': 76, 'weight_decay': 0.027725191121352414}"}}
exception: None

07:09:15 job_callback for (8, 0, 4) started
07:09:15 job_callback for (8, 0, 4) got condition
07:09:15 DISPATCHER: Trying to submit another job.
07:09:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:09:15 HBMASTER: Trying to run another job!
07:09:15 job_callback for (8, 0, 4) finished
07:09:15 start sampling a new configuration.
07:09:15 done sampling a new configuration.
07:09:15 HBMASTER: schedule new run for iteration 8
07:09:15 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
07:09:15 HBMASTER: submitting job (8, 0, 5) to dispatcher
07:09:15 DISPATCHER: trying to submit job (8, 0, 5)
07:09:15 DISPATCHER: trying to notify the job_runner thread.
07:09:15 HBMASTER: job (8, 0, 5) submitted to dispatcher
07:09:15 DISPATCHER: Trying to submit another job.
07:09:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:09:15 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:09:15 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:09:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:09:15 WORKER: start processing job (8, 0, 5)
07:09:15 WORKER: args: ()
07:09:15 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 827, 'last_n_outputs': 47, 'leak_rate': 0.8750433376373402, 'lr': 0.016918543865138583, 'optimizer': 'Adam', 'sparsity': 0.7982393140411596, 'steps_to_train': 45, 'weight_decay': 0.04761956050871154}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:09:39 DISPATCHER: Starting worker discovery
07:09:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:09:39 DISPATCHER: Finished worker discovery
07:10:39 DISPATCHER: Starting worker discovery
07:10:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:10:39 DISPATCHER: Finished worker discovery
07:11:01 WORKER: done with job (8, 0, 5), trying to register it.
07:11:01 WORKER: registered result for job (8, 0, 5) with dispatcher
07:11:01 DISPATCHER: job (8, 0, 5) finished
07:11:01 DISPATCHER: register_result: lock acquired
07:11:01 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
07:11:01 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 827, 'last_n_outputs': 47, 'leak_rate': 0.8750433376373402, 'lr': 0.016918543865138583, 'optimizer': 'Adam', 'sparsity': 0.7982393140411596, 'steps_to_train': 45, 'weight_decay': 0.04761956050871154}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.03463864554053815, 'info': {'sick_no_sick': 0.03463864554053815, 'config': "{'batch_size': 32, 'hidden_dim': 827, 'last_n_outputs': 47, 'leak_rate': 0.8750433376373402, 'lr': 0.016918543865138583, 'optimizer': 'Adam', 'sparsity': 0.7982393140411596, 'steps_to_train': 45, 'weight_decay': 0.04761956050871154}"}}
exception: None

07:11:01 job_callback for (8, 0, 5) started
07:11:01 job_callback for (8, 0, 5) got condition
07:11:01 DISPATCHER: Trying to submit another job.
07:11:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:11:01 HBMASTER: Trying to run another job!
07:11:01 job_callback for (8, 0, 5) finished
07:11:01 start sampling a new configuration.
07:11:02 best_vector: [1, 0.9829036253467478, 0.36510559051212677, 0.6487869014236379, 0.05142137037805078, 0, 0.1523595924101676, 0.4316945152175019, 0.1769337689790571], 0.0411464512141077, 0.18533056238916934, 0.007625694943829099
07:11:02 done sampling a new configuration.
07:11:02 HBMASTER: schedule new run for iteration 8
07:11:02 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
07:11:02 HBMASTER: submitting job (8, 0, 6) to dispatcher
07:11:02 DISPATCHER: trying to submit job (8, 0, 6)
07:11:02 DISPATCHER: trying to notify the job_runner thread.
07:11:02 HBMASTER: job (8, 0, 6) submitted to dispatcher
07:11:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:11:02 DISPATCHER: Trying to submit another job.
07:11:02 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:11:02 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:11:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:11:02 WORKER: start processing job (8, 0, 6)
07:11:02 WORKER: args: ()
07:11:02 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 987, 'last_n_outputs': 24, 'leak_rate': 0.9121967253559095, 'lr': 0.0012671929286757694, 'optimizer': 'Adam', 'sparsity': 0.7865663021784403, 'steps_to_train': 49, 'weight_decay': 0.016990108045229636}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:11:39 DISPATCHER: Starting worker discovery
07:11:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:11:39 DISPATCHER: Finished worker discovery
07:12:39 DISPATCHER: Starting worker discovery
07:12:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:12:39 DISPATCHER: Finished worker discovery
07:12:47 WORKER: done with job (8, 0, 6), trying to register it.
07:12:47 WORKER: registered result for job (8, 0, 6) with dispatcher
07:12:47 DISPATCHER: job (8, 0, 6) finished
07:12:47 DISPATCHER: register_result: lock acquired
07:12:47 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
07:12:47 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 987, 'last_n_outputs': 24, 'leak_rate': 0.9121967253559095, 'lr': 0.0012671929286757694, 'optimizer': 'Adam', 'sparsity': 0.7865663021784403, 'steps_to_train': 49, 'weight_decay': 0.016990108045229636}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.17147123166453443, 'info': {'sick_no_sick': 0.17147123166453443, 'config': "{'batch_size': 32, 'hidden_dim': 987, 'last_n_outputs': 24, 'leak_rate': 0.9121967253559095, 'lr': 0.0012671929286757694, 'optimizer': 'Adam', 'sparsity': 0.7865663021784403, 'steps_to_train': 49, 'weight_decay': 0.016990108045229636}"}}
exception: None

07:12:47 job_callback for (8, 0, 6) started
07:12:47 job_callback for (8, 0, 6) got condition
07:12:47 DISPATCHER: Trying to submit another job.
07:12:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:12:47 HBMASTER: Trying to run another job!
07:12:47 job_callback for (8, 0, 6) finished
07:12:47 start sampling a new configuration.
07:12:47 done sampling a new configuration.
07:12:47 HBMASTER: schedule new run for iteration 8
07:12:47 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
07:12:47 HBMASTER: submitting job (8, 0, 7) to dispatcher
07:12:47 DISPATCHER: trying to submit job (8, 0, 7)
07:12:47 DISPATCHER: trying to notify the job_runner thread.
07:12:47 HBMASTER: job (8, 0, 7) submitted to dispatcher
07:12:47 DISPATCHER: Trying to submit another job.
07:12:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:12:47 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:12:47 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:12:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:12:47 WORKER: start processing job (8, 0, 7)
07:12:47 WORKER: args: ()
07:12:47 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 862, 'last_n_outputs': 32, 'leak_rate': 0.8124975365087759, 'lr': 0.021364935435577895, 'optimizer': 'Adam', 'sparsity': 0.9010659473770326, 'steps_to_train': 49, 'weight_decay': 0.17432689812052357}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:13:39 DISPATCHER: Starting worker discovery
07:13:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:13:39 DISPATCHER: Finished worker discovery
07:14:34 WORKER: done with job (8, 0, 7), trying to register it.
07:14:34 WORKER: registered result for job (8, 0, 7) with dispatcher
07:14:34 DISPATCHER: job (8, 0, 7) finished
07:14:34 DISPATCHER: register_result: lock acquired
07:14:34 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
07:14:34 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 862, 'last_n_outputs': 32, 'leak_rate': 0.8124975365087759, 'lr': 0.021364935435577895, 'optimizer': 'Adam', 'sparsity': 0.9010659473770326, 'steps_to_train': 49, 'weight_decay': 0.17432689812052357}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1666244541768721, 'info': {'sick_no_sick': 0.1666244541768721, 'config': "{'batch_size': 128, 'hidden_dim': 862, 'last_n_outputs': 32, 'leak_rate': 0.8124975365087759, 'lr': 0.021364935435577895, 'optimizer': 'Adam', 'sparsity': 0.9010659473770326, 'steps_to_train': 49, 'weight_decay': 0.17432689812052357}"}}
exception: None

07:14:34 job_callback for (8, 0, 7) started
07:14:34 job_callback for (8, 0, 7) got condition
07:14:34 DISPATCHER: Trying to submit another job.
07:14:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:14:34 HBMASTER: Trying to run another job!
07:14:34 job_callback for (8, 0, 7) finished
07:14:34 start sampling a new configuration.
07:14:34 done sampling a new configuration.
07:14:34 HBMASTER: schedule new run for iteration 8
07:14:34 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
07:14:34 HBMASTER: submitting job (8, 0, 8) to dispatcher
07:14:34 DISPATCHER: trying to submit job (8, 0, 8)
07:14:34 DISPATCHER: trying to notify the job_runner thread.
07:14:34 HBMASTER: job (8, 0, 8) submitted to dispatcher
07:14:34 DISPATCHER: Trying to submit another job.
07:14:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:14:34 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:14:34 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:14:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:14:34 WORKER: start processing job (8, 0, 8)
07:14:34 WORKER: args: ()
07:14:34 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 485, 'last_n_outputs': 12, 'leak_rate': 0.8526778618738455, 'lr': 0.006484932005891691, 'optimizer': 'Adam', 'sparsity': 0.8571652320865712, 'steps_to_train': 64, 'weight_decay': 0.08814483764950902}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:14:39 DISPATCHER: Starting worker discovery
07:14:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:14:39 DISPATCHER: Finished worker discovery
07:15:39 DISPATCHER: Starting worker discovery
07:15:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:15:39 DISPATCHER: Finished worker discovery
07:16:22 WORKER: done with job (8, 0, 8), trying to register it.
07:16:22 WORKER: registered result for job (8, 0, 8) with dispatcher
07:16:22 DISPATCHER: job (8, 0, 8) finished
07:16:22 DISPATCHER: register_result: lock acquired
07:16:22 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
07:16:22 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 485, 'last_n_outputs': 12, 'leak_rate': 0.8526778618738455, 'lr': 0.006484932005891691, 'optimizer': 'Adam', 'sparsity': 0.8571652320865712, 'steps_to_train': 64, 'weight_decay': 0.08814483764950902}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2212159291484807, 'info': {'sick_no_sick': 0.2212159291484807, 'config': "{'batch_size': 128, 'hidden_dim': 485, 'last_n_outputs': 12, 'leak_rate': 0.8526778618738455, 'lr': 0.006484932005891691, 'optimizer': 'Adam', 'sparsity': 0.8571652320865712, 'steps_to_train': 64, 'weight_decay': 0.08814483764950902}"}}
exception: None

07:16:22 job_callback for (8, 0, 8) started
07:16:22 DISPATCHER: Trying to submit another job.
07:16:22 job_callback for (8, 0, 8) got condition
07:16:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:16:22 HBMASTER: Trying to run another job!
07:16:22 job_callback for (8, 0, 8) finished
07:16:22 start sampling a new configuration.
07:16:22 best_vector: [0, 0.5904208773859314, 0.8858141661116894, 0.6239001147149765, 0.05884163747909456, 1, 0.6159997839210626, 0.20099707422965468, 0.15647843968334504], 0.02838840476447805, 0.6408716547556251, 0.01819332393728352
07:16:22 done sampling a new configuration.
07:16:22 HBMASTER: schedule new run for iteration 8
07:16:22 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
07:16:22 HBMASTER: submitting job (8, 0, 9) to dispatcher
07:16:22 DISPATCHER: trying to submit job (8, 0, 9)
07:16:22 DISPATCHER: trying to notify the job_runner thread.
07:16:22 HBMASTER: job (8, 0, 9) submitted to dispatcher
07:16:22 DISPATCHER: Trying to submit another job.
07:16:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:16:22 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:16:22 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:16:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:16:22 WORKER: start processing job (8, 0, 9)
07:16:22 WORKER: args: ()
07:16:22 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 672, 'last_n_outputs': 46, 'leak_rate': 0.9059750286787441, 'lr': 0.0013112432783990336, 'optimizer': 'SGD', 'sparsity': 0.897839948141055, 'steps_to_train': 28, 'weight_decay': 0.015980234340918602}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:16:39 DISPATCHER: Starting worker discovery
07:16:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:16:39 DISPATCHER: Finished worker discovery
07:17:39 DISPATCHER: Starting worker discovery
07:17:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:17:39 DISPATCHER: Finished worker discovery
07:18:09 WORKER: done with job (8, 0, 9), trying to register it.
07:18:09 WORKER: registered result for job (8, 0, 9) with dispatcher
07:18:09 DISPATCHER: job (8, 0, 9) finished
07:18:09 DISPATCHER: register_result: lock acquired
07:18:09 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
07:18:09 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 672, 'last_n_outputs': 46, 'leak_rate': 0.9059750286787441, 'lr': 0.0013112432783990336, 'optimizer': 'SGD', 'sparsity': 0.897839948141055, 'steps_to_train': 28, 'weight_decay': 0.015980234340918602}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.02017839016514507, 'info': {'sick_no_sick': 0.02017839016514507, 'config': "{'batch_size': 16, 'hidden_dim': 672, 'last_n_outputs': 46, 'leak_rate': 0.9059750286787441, 'lr': 0.0013112432783990336, 'optimizer': 'SGD', 'sparsity': 0.897839948141055, 'steps_to_train': 28, 'weight_decay': 0.015980234340918602}"}}
exception: None

07:18:09 job_callback for (8, 0, 9) started
07:18:09 DISPATCHER: Trying to submit another job.
07:18:09 job_callback for (8, 0, 9) got condition
07:18:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:18:09 HBMASTER: Trying to run another job!
07:18:09 job_callback for (8, 0, 9) finished
07:18:09 start sampling a new configuration.
07:18:09 done sampling a new configuration.
07:18:09 HBMASTER: schedule new run for iteration 8
07:18:09 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
07:18:09 HBMASTER: submitting job (8, 0, 10) to dispatcher
07:18:09 DISPATCHER: trying to submit job (8, 0, 10)
07:18:09 DISPATCHER: trying to notify the job_runner thread.
07:18:09 HBMASTER: job (8, 0, 10) submitted to dispatcher
07:18:09 DISPATCHER: Trying to submit another job.
07:18:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:18:09 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:18:09 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:18:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:18:09 WORKER: start processing job (8, 0, 10)
07:18:09 WORKER: args: ()
07:18:09 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 731, 'last_n_outputs': 45, 'leak_rate': 0.8285918144680943, 'lr': 0.007603482251054948, 'optimizer': 'SGD', 'sparsity': 0.8989904052182145, 'steps_to_train': 80, 'weight_decay': 0.013433447681412422}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:18:39 DISPATCHER: Starting worker discovery
07:18:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:18:39 DISPATCHER: Finished worker discovery
07:19:39 DISPATCHER: Starting worker discovery
07:19:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:19:39 DISPATCHER: Finished worker discovery
07:19:56 WORKER: done with job (8, 0, 10), trying to register it.
07:19:56 WORKER: registered result for job (8, 0, 10) with dispatcher
07:19:56 DISPATCHER: job (8, 0, 10) finished
07:19:56 DISPATCHER: register_result: lock acquired
07:19:56 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
07:19:56 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 731, 'last_n_outputs': 45, 'leak_rate': 0.8285918144680943, 'lr': 0.007603482251054948, 'optimizer': 'SGD', 'sparsity': 0.8989904052182145, 'steps_to_train': 80, 'weight_decay': 0.013433447681412422}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.06532051646793237, 'info': {'sick_no_sick': 0.06532051646793237, 'config': "{'batch_size': 16, 'hidden_dim': 731, 'last_n_outputs': 45, 'leak_rate': 0.8285918144680943, 'lr': 0.007603482251054948, 'optimizer': 'SGD', 'sparsity': 0.8989904052182145, 'steps_to_train': 80, 'weight_decay': 0.013433447681412422}"}}
exception: None

07:19:56 job_callback for (8, 0, 10) started
07:19:56 DISPATCHER: Trying to submit another job.
07:19:56 job_callback for (8, 0, 10) got condition
07:19:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:19:56 HBMASTER: Trying to run another job!
07:19:56 job_callback for (8, 0, 10) finished
07:19:56 start sampling a new configuration.
07:19:56 best_vector: [3, 0.9044411582303042, 0.6915717920973445, 0.32978239856484737, 0.15227251230678443, 1, 0.027092536343879536, 0.8776667120987058, 0.07190471756180428], 0.0021564186306093414, 0.1136728994560829, 0.00024512635818247963
07:19:56 done sampling a new configuration.
07:19:56 HBMASTER: schedule new run for iteration 8
07:19:56 HBMASTER: trying submitting job (8, 0, 11) to dispatcher
07:19:56 HBMASTER: submitting job (8, 0, 11) to dispatcher
07:19:56 DISPATCHER: trying to submit job (8, 0, 11)
07:19:56 DISPATCHER: trying to notify the job_runner thread.
07:19:56 HBMASTER: job (8, 0, 11) submitted to dispatcher
07:19:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:19:56 DISPATCHER: Trying to submit another job.
07:19:56 DISPATCHER: starting job (8, 0, 11) on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:19:56 DISPATCHER: job (8, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:19:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:19:56 WORKER: start processing job (8, 0, 11)
07:19:56 WORKER: args: ()
07:19:56 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 924, 'last_n_outputs': 38, 'leak_rate': 0.8324455996412119, 'lr': 0.002016252990833729, 'optimizer': 'SGD', 'sparsity': 0.756502208722531, 'steps_to_train': 89, 'weight_decay': 0.012403669745124591}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:20:39 DISPATCHER: Starting worker discovery
07:20:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:20:39 DISPATCHER: Finished worker discovery
07:21:39 DISPATCHER: Starting worker discovery
07:21:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:21:39 DISPATCHER: Finished worker discovery
07:21:46 WORKER: done with job (8, 0, 11), trying to register it.
07:21:46 WORKER: registered result for job (8, 0, 11) with dispatcher
07:21:46 DISPATCHER: job (8, 0, 11) finished
07:21:46 DISPATCHER: register_result: lock acquired
07:21:46 DISPATCHER: job (8, 0, 11) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
07:21:46 job_id: (8, 0, 11)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 924, 'last_n_outputs': 38, 'leak_rate': 0.8324455996412119, 'lr': 0.002016252990833729, 'optimizer': 'SGD', 'sparsity': 0.756502208722531, 'steps_to_train': 89, 'weight_decay': 0.012403669745124591}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1949116427950528, 'info': {'sick_no_sick': 0.1949116427950528, 'config': "{'batch_size': 128, 'hidden_dim': 924, 'last_n_outputs': 38, 'leak_rate': 0.8324455996412119, 'lr': 0.002016252990833729, 'optimizer': 'SGD', 'sparsity': 0.756502208722531, 'steps_to_train': 89, 'weight_decay': 0.012403669745124591}"}}
exception: None

07:21:46 job_callback for (8, 0, 11) started
07:21:46 DISPATCHER: Trying to submit another job.
07:21:46 job_callback for (8, 0, 11) got condition
07:21:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:21:46 HBMASTER: Trying to run another job!
07:21:46 job_callback for (8, 0, 11) finished
07:21:46 start sampling a new configuration.
07:21:46 best_vector: [1, 0.9611798004049198, 0.6284624432406396, 0.8175516219968183, 0.23877287325289154, 1, 0.07868717828197247, 0.7714378621190938, 0.0705174022666891], 0.006932686517337999, 0.0619320330759117, 0.00042935537069670404
07:21:46 done sampling a new configuration.
07:21:46 HBMASTER: schedule new run for iteration 8
07:21:46 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
07:21:46 HBMASTER: submitting job (8, 0, 12) to dispatcher
07:21:46 DISPATCHER: trying to submit job (8, 0, 12)
07:21:46 DISPATCHER: trying to notify the job_runner thread.
07:21:46 HBMASTER: job (8, 0, 12) submitted to dispatcher
07:21:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:21:46 DISPATCHER: Trying to submit another job.
07:21:46 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:21:46 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:21:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:21:46 WORKER: start processing job (8, 0, 12)
07:21:46 WORKER: args: ()
07:21:46 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 969, 'last_n_outputs': 35, 'leak_rate': 0.9543879054992046, 'lr': 0.003002933718893063, 'optimizer': 'SGD', 'sparsity': 0.7688849227876734, 'steps_to_train': 80, 'weight_decay': 0.012352226754281196}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:22:39 DISPATCHER: Starting worker discovery
07:22:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:22:39 DISPATCHER: Finished worker discovery
07:23:33 WORKER: done with job (8, 0, 12), trying to register it.
07:23:33 WORKER: registered result for job (8, 0, 12) with dispatcher
07:23:33 DISPATCHER: job (8, 0, 12) finished
07:23:33 DISPATCHER: register_result: lock acquired
07:23:33 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
07:23:33 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 969, 'last_n_outputs': 35, 'leak_rate': 0.9543879054992046, 'lr': 0.003002933718893063, 'optimizer': 'SGD', 'sparsity': 0.7688849227876734, 'steps_to_train': 80, 'weight_decay': 0.012352226754281196}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2478325401766378, 'info': {'sick_no_sick': 0.2478325401766378, 'config': "{'batch_size': 32, 'hidden_dim': 969, 'last_n_outputs': 35, 'leak_rate': 0.9543879054992046, 'lr': 0.003002933718893063, 'optimizer': 'SGD', 'sparsity': 0.7688849227876734, 'steps_to_train': 80, 'weight_decay': 0.012352226754281196}"}}
exception: None

07:23:33 job_callback for (8, 0, 12) started
07:23:33 job_callback for (8, 0, 12) got condition
07:23:33 DISPATCHER: Trying to submit another job.
07:23:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:23:33 HBMASTER: Trying to run another job!
07:23:33 job_callback for (8, 0, 12) finished
07:23:33 start sampling a new configuration.
07:23:33 best_vector: [0, 0.8919187923414156, 0.32052730647356686, 0.3494434711176662, 0.2185156227497098, 1, 0.1654984498900257, 0.9664046777424737, 0.09663538354236173], 0.00657747591098411, 0.2890617164081011, 0.001901296476462005
07:23:33 done sampling a new configuration.
07:23:33 HBMASTER: schedule new run for iteration 8
07:23:33 HBMASTER: trying submitting job (8, 0, 13) to dispatcher
07:23:33 HBMASTER: submitting job (8, 0, 13) to dispatcher
07:23:33 DISPATCHER: trying to submit job (8, 0, 13)
07:23:33 DISPATCHER: trying to notify the job_runner thread.
07:23:33 HBMASTER: job (8, 0, 13) submitted to dispatcher
07:23:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:23:33 DISPATCHER: Trying to submit another job.
07:23:33 DISPATCHER: starting job (8, 0, 13) on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:23:33 DISPATCHER: job (8, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:23:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:23:33 WORKER: start processing job (8, 0, 13)
07:23:33 WORKER: args: ()
07:23:33 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 914, 'last_n_outputs': 23, 'leak_rate': 0.8373608677794165, 'lr': 0.0027354655234465273, 'optimizer': 'SGD', 'sparsity': 0.7897196279736062, 'steps_to_train': 97, 'weight_decay': 0.013357510757992947}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:23:39 DISPATCHER: Starting worker discovery
07:23:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:23:39 DISPATCHER: Finished worker discovery
07:24:39 DISPATCHER: Starting worker discovery
07:24:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:24:39 DISPATCHER: Finished worker discovery
07:25:24 WORKER: done with job (8, 0, 13), trying to register it.
07:25:24 WORKER: registered result for job (8, 0, 13) with dispatcher
07:25:24 DISPATCHER: job (8, 0, 13) finished
07:25:24 DISPATCHER: register_result: lock acquired
07:25:24 DISPATCHER: job (8, 0, 13) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
07:25:24 job_id: (8, 0, 13)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 914, 'last_n_outputs': 23, 'leak_rate': 0.8373608677794165, 'lr': 0.0027354655234465273, 'optimizer': 'SGD', 'sparsity': 0.7897196279736062, 'steps_to_train': 97, 'weight_decay': 0.013357510757992947}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0108375229108095, 'info': {'sick_no_sick': 0.0108375229108095, 'config': "{'batch_size': 16, 'hidden_dim': 914, 'last_n_outputs': 23, 'leak_rate': 0.8373608677794165, 'lr': 0.0027354655234465273, 'optimizer': 'SGD', 'sparsity': 0.7897196279736062, 'steps_to_train': 97, 'weight_decay': 0.013357510757992947}"}}
exception: None

07:25:24 job_callback for (8, 0, 13) started
07:25:24 job_callback for (8, 0, 13) got condition
07:25:24 DISPATCHER: Trying to submit another job.
07:25:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:25:24 HBMASTER: Trying to run another job!
07:25:24 job_callback for (8, 0, 13) finished
07:25:24 start sampling a new configuration.
07:25:24 best_vector: [3, 0.8182092862263671, 0.8863719615532628, 0.7100363820648132, 0.4334023849856936, 1, 0.07681780349903744, 0.28247884469524254, 0.4002819643577384], 0.09792982999199519, 0.051489727459475644, 0.005042380256440616
07:25:24 done sampling a new configuration.
07:25:24 HBMASTER: schedule new run for iteration 8
07:25:24 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
07:25:24 HBMASTER: submitting job (8, 0, 14) to dispatcher
07:25:24 DISPATCHER: trying to submit job (8, 0, 14)
07:25:24 DISPATCHER: trying to notify the job_runner thread.
07:25:24 HBMASTER: job (8, 0, 14) submitted to dispatcher
07:25:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:25:24 DISPATCHER: Trying to submit another job.
07:25:24 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:25:24 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:25:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:25:24 WORKER: start processing job (8, 0, 14)
07:25:24 WORKER: args: ()
07:25:24 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 855, 'last_n_outputs': 46, 'leak_rate': 0.9275090955162033, 'lr': 0.007358762219302203, 'optimizer': 'SGD', 'sparsity': 0.768436272839769, 'steps_to_train': 35, 'weight_decay': 0.033172548853629746}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:25:39 DISPATCHER: Starting worker discovery
07:25:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:25:39 DISPATCHER: Finished worker discovery
07:26:39 DISPATCHER: Starting worker discovery
07:26:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:26:39 DISPATCHER: Finished worker discovery
07:27:12 WORKER: done with job (8, 0, 14), trying to register it.
07:27:12 WORKER: registered result for job (8, 0, 14) with dispatcher
07:27:12 DISPATCHER: job (8, 0, 14) finished
07:27:12 DISPATCHER: register_result: lock acquired
07:27:12 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
07:27:12 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 855, 'last_n_outputs': 46, 'leak_rate': 0.9275090955162033, 'lr': 0.007358762219302203, 'optimizer': 'SGD', 'sparsity': 0.768436272839769, 'steps_to_train': 35, 'weight_decay': 0.033172548853629746}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1783117360308451, 'info': {'sick_no_sick': 0.1783117360308451, 'config': "{'batch_size': 128, 'hidden_dim': 855, 'last_n_outputs': 46, 'leak_rate': 0.9275090955162033, 'lr': 0.007358762219302203, 'optimizer': 'SGD', 'sparsity': 0.768436272839769, 'steps_to_train': 35, 'weight_decay': 0.033172548853629746}"}}
exception: None

07:27:12 job_callback for (8, 0, 14) started
07:27:12 DISPATCHER: Trying to submit another job.
07:27:12 job_callback for (8, 0, 14) got condition
07:27:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:27:12 HBMASTER: Trying to run another job!
07:27:12 job_callback for (8, 0, 14) finished
07:27:12 start sampling a new configuration.
07:27:13 best_vector: [3, 0.5867396246527838, 0.8973080038421644, 0.5255269424740989, 0.09578125300818936, 1, 0.17123577511063282, 0.29450580812727106, 0.23968627121552788], 0.0521398114671612, 0.09511663698245894, 0.0049593635196558215
07:27:13 done sampling a new configuration.
07:27:13 HBMASTER: schedule new run for iteration 8
07:27:13 HBMASTER: trying submitting job (8, 0, 15) to dispatcher
07:27:13 HBMASTER: submitting job (8, 0, 15) to dispatcher
07:27:13 DISPATCHER: trying to submit job (8, 0, 15)
07:27:13 DISPATCHER: trying to notify the job_runner thread.
07:27:13 HBMASTER: job (8, 0, 15) submitted to dispatcher
07:27:13 DISPATCHER: Trying to submit another job.
07:27:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:27:13 DISPATCHER: starting job (8, 0, 15) on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:27:13 DISPATCHER: job (8, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:27:13 WORKER: start processing job (8, 0, 15)
07:27:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:27:13 WORKER: args: ()
07:27:13 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 669, 'last_n_outputs': 46, 'leak_rate': 0.8813817356185247, 'lr': 0.0015543989922032263, 'optimizer': 'SGD', 'sparsity': 0.7910965860265519, 'steps_to_train': 36, 'weight_decay': 0.02050402054789804}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:27:39 DISPATCHER: Starting worker discovery
07:27:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:27:39 DISPATCHER: Finished worker discovery
07:28:39 DISPATCHER: Starting worker discovery
07:28:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:28:39 DISPATCHER: Finished worker discovery
07:29:03 WORKER: done with job (8, 0, 15), trying to register it.
07:29:03 WORKER: registered result for job (8, 0, 15) with dispatcher
07:29:03 DISPATCHER: job (8, 0, 15) finished
07:29:03 DISPATCHER: register_result: lock acquired
07:29:03 DISPATCHER: job (8, 0, 15) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
07:29:03 job_id: (8, 0, 15)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 669, 'last_n_outputs': 46, 'leak_rate': 0.8813817356185247, 'lr': 0.0015543989922032263, 'optimizer': 'SGD', 'sparsity': 0.7910965860265519, 'steps_to_train': 36, 'weight_decay': 0.02050402054789804}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.007556232027125138, 'info': {'sick_no_sick': 0.007556232027125138, 'config': "{'batch_size': 128, 'hidden_dim': 669, 'last_n_outputs': 46, 'leak_rate': 0.8813817356185247, 'lr': 0.0015543989922032263, 'optimizer': 'SGD', 'sparsity': 0.7910965860265519, 'steps_to_train': 36, 'weight_decay': 0.02050402054789804}"}}
exception: None

07:29:03 job_callback for (8, 0, 15) started
07:29:03 DISPATCHER: Trying to submit another job.
07:29:03 job_callback for (8, 0, 15) got condition
07:29:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:29:03 HBMASTER: Trying to run another job!
07:29:03 job_callback for (8, 0, 15) finished
07:29:03 start sampling a new configuration.
07:29:03 done sampling a new configuration.
07:29:03 HBMASTER: schedule new run for iteration 8
07:29:03 HBMASTER: trying submitting job (8, 0, 16) to dispatcher
07:29:03 HBMASTER: submitting job (8, 0, 16) to dispatcher
07:29:03 DISPATCHER: trying to submit job (8, 0, 16)
07:29:03 DISPATCHER: trying to notify the job_runner thread.
07:29:03 HBMASTER: job (8, 0, 16) submitted to dispatcher
07:29:03 DISPATCHER: Trying to submit another job.
07:29:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:29:03 DISPATCHER: starting job (8, 0, 16) on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:29:03 DISPATCHER: job (8, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:29:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:29:03 WORKER: start processing job (8, 0, 16)
07:29:03 WORKER: args: ()
07:29:03 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 210, 'last_n_outputs': 27, 'leak_rate': 0.9325192979656939, 'lr': 0.003376472374076844, 'optimizer': 'Adam', 'sparsity': 0.880142363292349, 'steps_to_train': 59, 'weight_decay': 0.09031882761311222}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:29:39 DISPATCHER: Starting worker discovery
07:29:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:29:39 DISPATCHER: Finished worker discovery
07:30:39 DISPATCHER: Starting worker discovery
07:30:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:30:39 DISPATCHER: Finished worker discovery
07:30:50 WORKER: done with job (8, 0, 16), trying to register it.
07:30:50 WORKER: registered result for job (8, 0, 16) with dispatcher
07:30:50 DISPATCHER: job (8, 0, 16) finished
07:30:50 DISPATCHER: register_result: lock acquired
07:30:50 DISPATCHER: job (8, 0, 16) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
07:30:50 job_id: (8, 0, 16)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 210, 'last_n_outputs': 27, 'leak_rate': 0.9325192979656939, 'lr': 0.003376472374076844, 'optimizer': 'Adam', 'sparsity': 0.880142363292349, 'steps_to_train': 59, 'weight_decay': 0.09031882761311222}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.06520643117063507, 'info': {'sick_no_sick': 0.06520643117063507, 'config': "{'batch_size': 64, 'hidden_dim': 210, 'last_n_outputs': 27, 'leak_rate': 0.9325192979656939, 'lr': 0.003376472374076844, 'optimizer': 'Adam', 'sparsity': 0.880142363292349, 'steps_to_train': 59, 'weight_decay': 0.09031882761311222}"}}
exception: None

07:30:50 job_callback for (8, 0, 16) started
07:30:50 DISPATCHER: Trying to submit another job.
07:30:50 job_callback for (8, 0, 16) got condition
07:30:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:30:50 HBMASTER: Trying to run another job!
07:30:50 job_callback for (8, 0, 16) finished
07:30:50 start sampling a new configuration.
07:30:50 best_vector: [2, 0.9573658627148397, 0.8894860083859837, 0.6646169725569441, 0.08201584272629192, 1, 0.6616983605235756, 0.5596389427660526, 0.3369971133338408], 0.055018102641800695, 0.2023795751109244, 0.011134540236056851
07:30:50 done sampling a new configuration.
07:30:50 HBMASTER: schedule new run for iteration 8
07:30:50 HBMASTER: trying submitting job (8, 0, 17) to dispatcher
07:30:50 HBMASTER: submitting job (8, 0, 17) to dispatcher
07:30:50 DISPATCHER: trying to submit job (8, 0, 17)
07:30:50 DISPATCHER: trying to notify the job_runner thread.
07:30:50 HBMASTER: job (8, 0, 17) submitted to dispatcher
07:30:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:30:50 DISPATCHER: Trying to submit another job.
07:30:50 DISPATCHER: starting job (8, 0, 17) on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:30:50 DISPATCHER: job (8, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:30:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:30:50 WORKER: start processing job (8, 0, 17)
07:30:50 WORKER: args: ()
07:30:50 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 966, 'last_n_outputs': 46, 'leak_rate': 0.916154243139236, 'lr': 0.0014589206969864421, 'optimizer': 'SGD', 'sparsity': 0.9088076065256581, 'steps_to_train': 60, 'weight_decay': 0.027443743582962456}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:31:39 DISPATCHER: Starting worker discovery
07:31:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:31:39 DISPATCHER: Finished worker discovery
07:32:39 WORKER: done with job (8, 0, 17), trying to register it.
07:32:39 WORKER: registered result for job (8, 0, 17) with dispatcher
07:32:39 DISPATCHER: job (8, 0, 17) finished
07:32:39 DISPATCHER: register_result: lock acquired
07:32:39 DISPATCHER: job (8, 0, 17) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
07:32:39 job_id: (8, 0, 17)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 966, 'last_n_outputs': 46, 'leak_rate': 0.916154243139236, 'lr': 0.0014589206969864421, 'optimizer': 'SGD', 'sparsity': 0.9088076065256581, 'steps_to_train': 60, 'weight_decay': 0.027443743582962456}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.14976047612776525, 'info': {'sick_no_sick': 0.14976047612776525, 'config': "{'batch_size': 64, 'hidden_dim': 966, 'last_n_outputs': 46, 'leak_rate': 0.916154243139236, 'lr': 0.0014589206969864421, 'optimizer': 'SGD', 'sparsity': 0.9088076065256581, 'steps_to_train': 60, 'weight_decay': 0.027443743582962456}"}}
exception: None

07:32:39 job_callback for (8, 0, 17) started
07:32:39 job_callback for (8, 0, 17) got condition
07:32:39 DISPATCHER: Trying to submit another job.
07:32:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:32:39 HBMASTER: Trying to run another job!
07:32:39 job_callback for (8, 0, 17) finished
07:32:39 start sampling a new configuration.
07:32:39 best_vector: [0, 0.8767869672506277, 0.2385626683904371, 0.3897943323956052, 0.29840550449044234, 0, 0.16955982107512965, 0.9696302162543582, 0.057927700226397844], 0.009616627667589554, 0.17367381769019768, 0.0016701564403354592
07:32:39 done sampling a new configuration.
07:32:39 HBMASTER: schedule new run for iteration 8
07:32:39 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
07:32:39 HBMASTER: submitting job (8, 0, 18) to dispatcher
07:32:39 DISPATCHER: trying to submit job (8, 0, 18)
07:32:39 DISPATCHER: trying to notify the job_runner thread.
07:32:39 HBMASTER: job (8, 0, 18) submitted to dispatcher
07:32:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:32:39 DISPATCHER: Trying to submit another job.
07:32:39 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:32:39 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:32:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:32:39 WORKER: start processing job (8, 0, 18)
07:32:39 WORKER: args: ()
07:32:39 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 902, 'last_n_outputs': 19, 'leak_rate': 0.8474485830989013, 'lr': 0.003951946066351055, 'optimizer': 'Adam', 'sparsity': 0.7906943570580311, 'steps_to_train': 98, 'weight_decay': 0.011895033666943205}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:32:39 DISPATCHER: Starting worker discovery
07:32:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:32:39 DISPATCHER: Finished worker discovery
07:33:39 DISPATCHER: Starting worker discovery
07:33:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:33:39 DISPATCHER: Finished worker discovery
07:34:26 WORKER: done with job (8, 0, 18), trying to register it.
07:34:26 WORKER: registered result for job (8, 0, 18) with dispatcher
07:34:26 DISPATCHER: job (8, 0, 18) finished
07:34:26 DISPATCHER: register_result: lock acquired
07:34:26 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
07:34:26 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 902, 'last_n_outputs': 19, 'leak_rate': 0.8474485830989013, 'lr': 0.003951946066351055, 'optimizer': 'Adam', 'sparsity': 0.7906943570580311, 'steps_to_train': 98, 'weight_decay': 0.011895033666943205}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.21131328637705243, 'info': {'sick_no_sick': 0.21131328637705243, 'config': "{'batch_size': 16, 'hidden_dim': 902, 'last_n_outputs': 19, 'leak_rate': 0.8474485830989013, 'lr': 0.003951946066351055, 'optimizer': 'Adam', 'sparsity': 0.7906943570580311, 'steps_to_train': 98, 'weight_decay': 0.011895033666943205}"}}
exception: None

07:34:26 job_callback for (8, 0, 18) started
07:34:26 DISPATCHER: Trying to submit another job.
07:34:26 job_callback for (8, 0, 18) got condition
07:34:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:34:26 HBMASTER: Trying to run another job!
07:34:26 job_callback for (8, 0, 18) finished
07:34:26 start sampling a new configuration.
07:34:26 best_vector: [1, 0.00257242895162918, 0.7989268389975737, 0.0690020558103964, 0.19620474654590087, 1, 0.511486007833567, 0.8437997224859743, 0.8344524210688686], 0.03288250550551081, 0.010307638226373065, 0.00033894097072752606
07:34:26 done sampling a new configuration.
07:34:26 HBMASTER: schedule new run for iteration 8
07:34:26 HBMASTER: trying submitting job (8, 0, 19) to dispatcher
07:34:26 HBMASTER: submitting job (8, 0, 19) to dispatcher
07:34:26 DISPATCHER: trying to submit job (8, 0, 19)
07:34:26 DISPATCHER: trying to notify the job_runner thread.
07:34:26 HBMASTER: job (8, 0, 19) submitted to dispatcher
07:34:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:34:26 DISPATCHER: Trying to submit another job.
07:34:26 DISPATCHER: starting job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:34:26 DISPATCHER: job (8, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:34:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:34:26 WORKER: start processing job (8, 0, 19)
07:34:26 WORKER: args: ()
07:34:26 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 202, 'last_n_outputs': 42, 'leak_rate': 0.7672505139525991, 'lr': 0.0024683656442524653, 'optimizer': 'SGD', 'sparsity': 0.8727566418800561, 'steps_to_train': 86, 'weight_decay': 0.12180009576644756}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:34:39 DISPATCHER: Starting worker discovery
07:34:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:34:39 DISPATCHER: Finished worker discovery
07:35:39 DISPATCHER: Starting worker discovery
07:35:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:35:39 DISPATCHER: Finished worker discovery
07:36:14 WORKER: done with job (8, 0, 19), trying to register it.
07:36:14 WORKER: registered result for job (8, 0, 19) with dispatcher
07:36:14 DISPATCHER: job (8, 0, 19) finished
07:36:14 DISPATCHER: register_result: lock acquired
07:36:14 DISPATCHER: job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
07:36:14 job_id: (8, 0, 19)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 202, 'last_n_outputs': 42, 'leak_rate': 0.7672505139525991, 'lr': 0.0024683656442524653, 'optimizer': 'SGD', 'sparsity': 0.8727566418800561, 'steps_to_train': 86, 'weight_decay': 0.12180009576644756}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.03713402482340031, 'info': {'sick_no_sick': 0.03713402482340031, 'config': "{'batch_size': 32, 'hidden_dim': 202, 'last_n_outputs': 42, 'leak_rate': 0.7672505139525991, 'lr': 0.0024683656442524653, 'optimizer': 'SGD', 'sparsity': 0.8727566418800561, 'steps_to_train': 86, 'weight_decay': 0.12180009576644756}"}}
exception: None

07:36:14 job_callback for (8, 0, 19) started
07:36:14 DISPATCHER: Trying to submit another job.
07:36:14 job_callback for (8, 0, 19) got condition
07:36:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:36:14 HBMASTER: Trying to run another job!
07:36:14 job_callback for (8, 0, 19) finished
07:36:14 start sampling a new configuration.
07:36:14 best_vector: [2, 0.959518802170043, 0.23891486460480543, 0.5941247791862362, 0.12211411406559239, 1, 0.7805667437200237, 0.959941192390183, 0.7290143215508105], 0.00963029457590677, 0.15975692376449074, 0.0015385062363927266
07:36:14 done sampling a new configuration.
07:36:14 HBMASTER: schedule new run for iteration 8
07:36:14 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
07:36:14 HBMASTER: submitting job (8, 0, 20) to dispatcher
07:36:14 DISPATCHER: trying to submit job (8, 0, 20)
07:36:14 DISPATCHER: trying to notify the job_runner thread.
07:36:14 HBMASTER: job (8, 0, 20) submitted to dispatcher
07:36:14 DISPATCHER: Trying to submit another job.
07:36:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:36:14 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:36:14 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:36:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:36:14 WORKER: start processing job (8, 0, 20)
07:36:14 WORKER: args: ()
07:36:14 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 968, 'last_n_outputs': 19, 'leak_rate': 0.8985311947965591, 'lr': 0.001754802434037904, 'optimizer': 'SGD', 'sparsity': 0.9373360184928057, 'steps_to_train': 97, 'weight_decay': 0.08881156019905115}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:36:39 DISPATCHER: Starting worker discovery
07:36:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:36:39 DISPATCHER: Finished worker discovery
07:37:39 DISPATCHER: Starting worker discovery
07:37:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:37:39 DISPATCHER: Finished worker discovery
07:38:04 WORKER: done with job (8, 0, 20), trying to register it.
07:38:04 WORKER: registered result for job (8, 0, 20) with dispatcher
07:38:04 DISPATCHER: job (8, 0, 20) finished
07:38:04 DISPATCHER: register_result: lock acquired
07:38:04 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
07:38:04 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 968, 'last_n_outputs': 19, 'leak_rate': 0.8985311947965591, 'lr': 0.001754802434037904, 'optimizer': 'SGD', 'sparsity': 0.9373360184928057, 'steps_to_train': 97, 'weight_decay': 0.08881156019905115}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.20413962591724555, 'info': {'sick_no_sick': 0.20413962591724555, 'config': "{'batch_size': 64, 'hidden_dim': 968, 'last_n_outputs': 19, 'leak_rate': 0.8985311947965591, 'lr': 0.001754802434037904, 'optimizer': 'SGD', 'sparsity': 0.9373360184928057, 'steps_to_train': 97, 'weight_decay': 0.08881156019905115}"}}
exception: None

07:38:04 job_callback for (8, 0, 20) started
07:38:04 DISPATCHER: Trying to submit another job.
07:38:04 job_callback for (8, 0, 20) got condition
07:38:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:38:04 HBMASTER: Trying to run another job!
07:38:04 job_callback for (8, 0, 20) finished
07:38:04 start sampling a new configuration.
07:38:04 done sampling a new configuration.
07:38:04 HBMASTER: schedule new run for iteration 8
07:38:04 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
07:38:04 HBMASTER: submitting job (8, 0, 21) to dispatcher
07:38:04 DISPATCHER: trying to submit job (8, 0, 21)
07:38:04 DISPATCHER: trying to notify the job_runner thread.
07:38:04 HBMASTER: job (8, 0, 21) submitted to dispatcher
07:38:04 DISPATCHER: Trying to submit another job.
07:38:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:38:04 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:38:04 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:38:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:38:04 WORKER: start processing job (8, 0, 21)
07:38:04 WORKER: args: ()
07:38:04 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 878, 'last_n_outputs': 10, 'leak_rate': 0.9668217516672875, 'lr': 0.005329475212586304, 'optimizer': 'SGD', 'sparsity': 0.9119191930637705, 'steps_to_train': 88, 'weight_decay': 0.047528103368486126}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:38:39 DISPATCHER: Starting worker discovery
07:38:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:38:39 DISPATCHER: Finished worker discovery
07:39:39 DISPATCHER: Starting worker discovery
07:39:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:39:39 DISPATCHER: Finished worker discovery
07:39:53 WORKER: done with job (8, 0, 21), trying to register it.
07:39:53 WORKER: registered result for job (8, 0, 21) with dispatcher
07:39:53 DISPATCHER: job (8, 0, 21) finished
07:39:53 DISPATCHER: register_result: lock acquired
07:39:53 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
07:39:53 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 878, 'last_n_outputs': 10, 'leak_rate': 0.9668217516672875, 'lr': 0.005329475212586304, 'optimizer': 'SGD', 'sparsity': 0.9119191930637705, 'steps_to_train': 88, 'weight_decay': 0.047528103368486126}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0144576216266809, 'info': {'sick_no_sick': 0.0144576216266809, 'config': "{'batch_size': 64, 'hidden_dim': 878, 'last_n_outputs': 10, 'leak_rate': 0.9668217516672875, 'lr': 0.005329475212586304, 'optimizer': 'SGD', 'sparsity': 0.9119191930637705, 'steps_to_train': 88, 'weight_decay': 0.047528103368486126}"}}
exception: None

07:39:53 job_callback for (8, 0, 21) started
07:39:53 job_callback for (8, 0, 21) got condition
07:39:53 DISPATCHER: Trying to submit another job.
07:39:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:39:53 HBMASTER: Trying to run another job!
07:39:53 job_callback for (8, 0, 21) finished
07:39:53 start sampling a new configuration.
07:39:53 done sampling a new configuration.
07:39:53 HBMASTER: schedule new run for iteration 8
07:39:53 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
07:39:53 HBMASTER: submitting job (8, 0, 22) to dispatcher
07:39:53 DISPATCHER: trying to submit job (8, 0, 22)
07:39:53 DISPATCHER: trying to notify the job_runner thread.
07:39:53 HBMASTER: job (8, 0, 22) submitted to dispatcher
07:39:53 DISPATCHER: Trying to submit another job.
07:39:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:39:53 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:39:53 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:39:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:39:53 WORKER: start processing job (8, 0, 22)
07:39:53 WORKER: args: ()
07:39:53 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 971, 'last_n_outputs': 30, 'leak_rate': 0.8204112267608615, 'lr': 0.020898308356141804, 'optimizer': 'Adam', 'sparsity': 0.8947469348764168, 'steps_to_train': 74, 'weight_decay': 0.017193277365448893}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:40:39 DISPATCHER: Starting worker discovery
07:40:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:40:39 DISPATCHER: Finished worker discovery
07:41:39 DISPATCHER: Starting worker discovery
07:41:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:41:39 DISPATCHER: Finished worker discovery
07:41:41 WORKER: done with job (8, 0, 22), trying to register it.
07:41:41 WORKER: registered result for job (8, 0, 22) with dispatcher
07:41:41 DISPATCHER: job (8, 0, 22) finished
07:41:41 DISPATCHER: register_result: lock acquired
07:41:41 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
07:41:41 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 971, 'last_n_outputs': 30, 'leak_rate': 0.8204112267608615, 'lr': 0.020898308356141804, 'optimizer': 'Adam', 'sparsity': 0.8947469348764168, 'steps_to_train': 74, 'weight_decay': 0.017193277365448893}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.08233699169870701, 'info': {'sick_no_sick': 0.08233699169870701, 'config': "{'batch_size': 32, 'hidden_dim': 971, 'last_n_outputs': 30, 'leak_rate': 0.8204112267608615, 'lr': 0.020898308356141804, 'optimizer': 'Adam', 'sparsity': 0.8947469348764168, 'steps_to_train': 74, 'weight_decay': 0.017193277365448893}"}}
exception: None

07:41:41 job_callback for (8, 0, 22) started
07:41:41 DISPATCHER: Trying to submit another job.
07:41:41 job_callback for (8, 0, 22) got condition
07:41:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:41:41 HBMASTER: Trying to run another job!
07:41:41 job_callback for (8, 0, 22) finished
07:41:41 start sampling a new configuration.
07:41:41 best_vector: [3, 0.7296380132313145, 0.3782883609806712, 0.7878884456587896, 0.29273164484748515, 1, 0.0013867176886062094, 0.6321427037433431, 0.1316511530879942], 0.024724976252314863, 0.1522964051899341, 0.0037655250016340423
07:41:41 done sampling a new configuration.
07:41:41 HBMASTER: schedule new run for iteration 8
07:41:41 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
07:41:41 HBMASTER: submitting job (8, 0, 23) to dispatcher
07:41:41 DISPATCHER: trying to submit job (8, 0, 23)
07:41:41 DISPATCHER: trying to notify the job_runner thread.
07:41:41 HBMASTER: job (8, 0, 23) submitted to dispatcher
07:41:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:41:41 DISPATCHER: Trying to submit another job.
07:41:41 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:41:41 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:41:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:41:41 WORKER: start processing job (8, 0, 23)
07:41:41 WORKER: args: ()
07:41:41 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 784, 'last_n_outputs': 25, 'leak_rate': 0.9469721114146974, 'lr': 0.00385002269599862, 'optimizer': 'SGD', 'sparsity': 0.7503328122452655, 'steps_to_train': 67, 'weight_decay': 0.014834813783459936}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:42:39 DISPATCHER: Starting worker discovery
07:42:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:42:39 DISPATCHER: Finished worker discovery
07:43:28 WORKER: done with job (8, 0, 23), trying to register it.
07:43:28 WORKER: registered result for job (8, 0, 23) with dispatcher
07:43:28 DISPATCHER: job (8, 0, 23) finished
07:43:28 DISPATCHER: register_result: lock acquired
07:43:28 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
07:43:28 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 784, 'last_n_outputs': 25, 'leak_rate': 0.9469721114146974, 'lr': 0.00385002269599862, 'optimizer': 'SGD', 'sparsity': 0.7503328122452655, 'steps_to_train': 67, 'weight_decay': 0.014834813783459936}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2500291286175394, 'info': {'sick_no_sick': 0.2500291286175394, 'config': "{'batch_size': 128, 'hidden_dim': 784, 'last_n_outputs': 25, 'leak_rate': 0.9469721114146974, 'lr': 0.00385002269599862, 'optimizer': 'SGD', 'sparsity': 0.7503328122452655, 'steps_to_train': 67, 'weight_decay': 0.014834813783459936}"}}
exception: None

07:43:28 job_callback for (8, 0, 23) started
07:43:28 job_callback for (8, 0, 23) got condition
07:43:28 DISPATCHER: Trying to submit another job.
07:43:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:43:28 HBMASTER: Trying to run another job!
07:43:28 job_callback for (8, 0, 23) finished
07:43:28 start sampling a new configuration.
07:43:28 done sampling a new configuration.
07:43:28 HBMASTER: schedule new run for iteration 8
07:43:28 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
07:43:28 HBMASTER: submitting job (8, 0, 24) to dispatcher
07:43:28 DISPATCHER: trying to submit job (8, 0, 24)
07:43:28 DISPATCHER: trying to notify the job_runner thread.
07:43:28 HBMASTER: job (8, 0, 24) submitted to dispatcher
07:43:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:43:28 DISPATCHER: Trying to submit another job.
07:43:28 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:43:28 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:43:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:43:28 WORKER: start processing job (8, 0, 24)
07:43:28 WORKER: args: ()
07:43:28 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 529, 'last_n_outputs': 26, 'leak_rate': 0.8971917001965346, 'lr': 0.02583900662654373, 'optimizer': 'SGD', 'sparsity': 0.794665706139505, 'steps_to_train': 46, 'weight_decay': 0.018402776087441456}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:43:39 DISPATCHER: Starting worker discovery
07:43:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:43:39 DISPATCHER: Finished worker discovery
07:44:39 DISPATCHER: Starting worker discovery
07:44:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:44:39 DISPATCHER: Finished worker discovery
07:45:14 WORKER: done with job (8, 0, 24), trying to register it.
07:45:14 WORKER: registered result for job (8, 0, 24) with dispatcher
07:45:14 DISPATCHER: job (8, 0, 24) finished
07:45:14 DISPATCHER: register_result: lock acquired
07:45:14 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
07:45:14 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 529, 'last_n_outputs': 26, 'leak_rate': 0.8971917001965346, 'lr': 0.02583900662654373, 'optimizer': 'SGD', 'sparsity': 0.794665706139505, 'steps_to_train': 46, 'weight_decay': 0.018402776087441456}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.17848626475474938, 'info': {'sick_no_sick': 0.17848626475474938, 'config': "{'batch_size': 16, 'hidden_dim': 529, 'last_n_outputs': 26, 'leak_rate': 0.8971917001965346, 'lr': 0.02583900662654373, 'optimizer': 'SGD', 'sparsity': 0.794665706139505, 'steps_to_train': 46, 'weight_decay': 0.018402776087441456}"}}
exception: None

07:45:14 job_callback for (8, 0, 24) started
07:45:14 job_callback for (8, 0, 24) got condition
07:45:14 DISPATCHER: Trying to submit another job.
07:45:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:45:14 HBMASTER: Trying to run another job!
07:45:14 job_callback for (8, 0, 24) finished
07:45:14 start sampling a new configuration.
07:45:15 best_vector: [3, 0.5373859749025156, 0.8943827476023175, 0.8608659634898704, 0.19015431006905556, 1, 0.04373560203528981, 0.3016236199577854, 0.1991048719477746], 0.06986714315045375, 0.057047821962917265, 0.00398576834350474
07:45:15 done sampling a new configuration.
07:45:15 HBMASTER: schedule new run for iteration 8
07:45:15 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
07:45:15 HBMASTER: submitting job (8, 0, 25) to dispatcher
07:45:15 DISPATCHER: trying to submit job (8, 0, 25)
07:45:15 DISPATCHER: trying to notify the job_runner thread.
07:45:15 HBMASTER: job (8, 0, 25) submitted to dispatcher
07:45:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:45:15 DISPATCHER: Trying to submit another job.
07:45:15 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:45:15 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:45:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:45:15 WORKER: start processing job (8, 0, 25)
07:45:15 WORKER: args: ()
07:45:15 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 630, 'last_n_outputs': 46, 'leak_rate': 0.9652164908724676, 'lr': 0.0024005381934069777, 'optimizer': 'SGD', 'sparsity': 0.7604965444884696, 'steps_to_train': 37, 'weight_decay': 0.01815688783404999}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:45:39 DISPATCHER: Starting worker discovery
07:45:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:45:39 DISPATCHER: Finished worker discovery
07:46:39 DISPATCHER: Starting worker discovery
07:46:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:46:39 DISPATCHER: Finished worker discovery
07:47:03 WORKER: done with job (8, 0, 25), trying to register it.
07:47:03 WORKER: registered result for job (8, 0, 25) with dispatcher
07:47:03 DISPATCHER: job (8, 0, 25) finished
07:47:03 DISPATCHER: register_result: lock acquired
07:47:03 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
07:47:03 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 630, 'last_n_outputs': 46, 'leak_rate': 0.9652164908724676, 'lr': 0.0024005381934069777, 'optimizer': 'SGD', 'sparsity': 0.7604965444884696, 'steps_to_train': 37, 'weight_decay': 0.01815688783404999}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.004967972699736566, 'info': {'sick_no_sick': 0.004967972699736566, 'config': "{'batch_size': 128, 'hidden_dim': 630, 'last_n_outputs': 46, 'leak_rate': 0.9652164908724676, 'lr': 0.0024005381934069777, 'optimizer': 'SGD', 'sparsity': 0.7604965444884696, 'steps_to_train': 37, 'weight_decay': 0.01815688783404999}"}}
exception: None

07:47:03 job_callback for (8, 0, 25) started
07:47:03 DISPATCHER: Trying to submit another job.
07:47:03 job_callback for (8, 0, 25) got condition
07:47:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:47:03 HBMASTER: Trying to run another job!
07:47:03 job_callback for (8, 0, 25) finished
07:47:03 start sampling a new configuration.
07:47:03 done sampling a new configuration.
07:47:03 HBMASTER: schedule new run for iteration 8
07:47:03 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
07:47:03 HBMASTER: submitting job (8, 0, 26) to dispatcher
07:47:03 DISPATCHER: trying to submit job (8, 0, 26)
07:47:03 DISPATCHER: trying to notify the job_runner thread.
07:47:03 HBMASTER: job (8, 0, 26) submitted to dispatcher
07:47:03 DISPATCHER: Trying to submit another job.
07:47:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:47:03 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:47:03 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:47:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:47:03 WORKER: start processing job (8, 0, 26)
07:47:03 WORKER: args: ()
07:47:03 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 956, 'last_n_outputs': 45, 'leak_rate': 0.754331117773672, 'lr': 0.0042284101434975525, 'optimizer': 'Adam', 'sparsity': 0.9169879587192004, 'steps_to_train': 48, 'weight_decay': 0.04680338571432161}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:47:39 DISPATCHER: Starting worker discovery
07:47:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:47:39 DISPATCHER: Finished worker discovery
07:48:39 DISPATCHER: Starting worker discovery
07:48:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:48:39 DISPATCHER: Finished worker discovery
07:48:50 WORKER: done with job (8, 0, 26), trying to register it.
07:48:50 WORKER: registered result for job (8, 0, 26) with dispatcher
07:48:50 DISPATCHER: job (8, 0, 26) finished
07:48:50 DISPATCHER: register_result: lock acquired
07:48:50 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
07:48:50 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 956, 'last_n_outputs': 45, 'leak_rate': 0.754331117773672, 'lr': 0.0042284101434975525, 'optimizer': 'Adam', 'sparsity': 0.9169879587192004, 'steps_to_train': 48, 'weight_decay': 0.04680338571432161}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.18648538394618894, 'info': {'sick_no_sick': 0.18648538394618894, 'config': "{'batch_size': 64, 'hidden_dim': 956, 'last_n_outputs': 45, 'leak_rate': 0.754331117773672, 'lr': 0.0042284101434975525, 'optimizer': 'Adam', 'sparsity': 0.9169879587192004, 'steps_to_train': 48, 'weight_decay': 0.04680338571432161}"}}
exception: None

07:48:50 job_callback for (8, 0, 26) started
07:48:50 job_callback for (8, 0, 26) got condition
07:48:50 DISPATCHER: Trying to submit another job.
07:48:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:48:50 HBMASTER: Trying to run another job!
07:48:50 job_callback for (8, 0, 26) finished
07:48:50 ITERATION: Advancing config (8, 0, 8) to next budget 133.333333
07:48:50 ITERATION: Advancing config (8, 0, 11) to next budget 133.333333
07:48:50 ITERATION: Advancing config (8, 0, 12) to next budget 133.333333
07:48:50 ITERATION: Advancing config (8, 0, 14) to next budget 133.333333
07:48:50 ITERATION: Advancing config (8, 0, 18) to next budget 133.333333
07:48:50 ITERATION: Advancing config (8, 0, 20) to next budget 133.333333
07:48:50 ITERATION: Advancing config (8, 0, 23) to next budget 133.333333
07:48:50 ITERATION: Advancing config (8, 0, 24) to next budget 133.333333
07:48:50 ITERATION: Advancing config (8, 0, 26) to next budget 133.333333
07:48:50 HBMASTER: schedule new run for iteration 8
07:48:50 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
07:48:50 HBMASTER: submitting job (8, 0, 8) to dispatcher
07:48:50 DISPATCHER: trying to submit job (8, 0, 8)
07:48:50 DISPATCHER: trying to notify the job_runner thread.
07:48:50 HBMASTER: job (8, 0, 8) submitted to dispatcher
07:48:50 DISPATCHER: Trying to submit another job.
07:48:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:48:50 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:48:50 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:48:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:48:50 WORKER: start processing job (8, 0, 8)
07:48:50 WORKER: args: ()
07:48:50 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 485, 'last_n_outputs': 12, 'leak_rate': 0.8526778618738455, 'lr': 0.006484932005891691, 'optimizer': 'Adam', 'sparsity': 0.8571652320865712, 'steps_to_train': 64, 'weight_decay': 0.08814483764950902}, 'budget': 133.33333333333331, 'working_directory': '.'}
07:49:39 DISPATCHER: Starting worker discovery
07:49:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:49:39 DISPATCHER: Finished worker discovery
07:50:39 DISPATCHER: Starting worker discovery
07:50:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:50:39 DISPATCHER: Finished worker discovery
07:51:39 DISPATCHER: Starting worker discovery
07:51:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:51:39 DISPATCHER: Finished worker discovery
07:52:08 WORKER: done with job (8, 0, 8), trying to register it.
07:52:08 WORKER: registered result for job (8, 0, 8) with dispatcher
07:52:08 DISPATCHER: job (8, 0, 8) finished
07:52:08 DISPATCHER: register_result: lock acquired
07:52:08 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
07:52:08 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 485, 'last_n_outputs': 12, 'leak_rate': 0.8526778618738455, 'lr': 0.006484932005891691, 'optimizer': 'Adam', 'sparsity': 0.8571652320865712, 'steps_to_train': 64, 'weight_decay': 0.08814483764950902}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.028203487910845284, 'info': {'sick_no_sick': 0.028203487910845284, 'config': "{'batch_size': 128, 'hidden_dim': 485, 'last_n_outputs': 12, 'leak_rate': 0.8526778618738455, 'lr': 0.006484932005891691, 'optimizer': 'Adam', 'sparsity': 0.8571652320865712, 'steps_to_train': 64, 'weight_decay': 0.08814483764950902}"}}
exception: None

07:52:08 job_callback for (8, 0, 8) started
07:52:08 job_callback for (8, 0, 8) got condition
07:52:08 DISPATCHER: Trying to submit another job.
07:52:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:52:08 HBMASTER: Trying to run another job!
07:52:08 job_callback for (8, 0, 8) finished
07:52:08 HBMASTER: schedule new run for iteration 8
07:52:08 HBMASTER: trying submitting job (8, 0, 11) to dispatcher
07:52:08 HBMASTER: submitting job (8, 0, 11) to dispatcher
07:52:08 DISPATCHER: trying to submit job (8, 0, 11)
07:52:08 DISPATCHER: trying to notify the job_runner thread.
07:52:08 HBMASTER: job (8, 0, 11) submitted to dispatcher
07:52:08 DISPATCHER: Trying to submit another job.
07:52:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:52:08 DISPATCHER: starting job (8, 0, 11) on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:52:08 DISPATCHER: job (8, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:52:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:52:08 WORKER: start processing job (8, 0, 11)
07:52:08 WORKER: args: ()
07:52:08 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 924, 'last_n_outputs': 38, 'leak_rate': 0.8324455996412119, 'lr': 0.002016252990833729, 'optimizer': 'SGD', 'sparsity': 0.756502208722531, 'steps_to_train': 89, 'weight_decay': 0.012403669745124591}, 'budget': 133.33333333333331, 'working_directory': '.'}
07:52:39 DISPATCHER: Starting worker discovery
07:52:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:52:39 DISPATCHER: Finished worker discovery
07:53:39 DISPATCHER: Starting worker discovery
07:53:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:53:39 DISPATCHER: Finished worker discovery
07:54:39 DISPATCHER: Starting worker discovery
07:54:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:54:39 DISPATCHER: Finished worker discovery
07:55:25 WORKER: done with job (8, 0, 11), trying to register it.
07:55:25 WORKER: registered result for job (8, 0, 11) with dispatcher
07:55:25 DISPATCHER: job (8, 0, 11) finished
07:55:25 DISPATCHER: register_result: lock acquired
07:55:25 DISPATCHER: job (8, 0, 11) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
07:55:25 job_id: (8, 0, 11)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 924, 'last_n_outputs': 38, 'leak_rate': 0.8324455996412119, 'lr': 0.002016252990833729, 'optimizer': 'SGD', 'sparsity': 0.756502208722531, 'steps_to_train': 89, 'weight_decay': 0.012403669745124591}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.021356654090042893, 'info': {'sick_no_sick': 0.021356654090042893, 'config': "{'batch_size': 128, 'hidden_dim': 924, 'last_n_outputs': 38, 'leak_rate': 0.8324455996412119, 'lr': 0.002016252990833729, 'optimizer': 'SGD', 'sparsity': 0.756502208722531, 'steps_to_train': 89, 'weight_decay': 0.012403669745124591}"}}
exception: None

07:55:25 job_callback for (8, 0, 11) started
07:55:25 DISPATCHER: Trying to submit another job.
07:55:25 job_callback for (8, 0, 11) got condition
07:55:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:55:25 HBMASTER: Trying to run another job!
07:55:25 job_callback for (8, 0, 11) finished
07:55:25 HBMASTER: schedule new run for iteration 8
07:55:25 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
07:55:25 HBMASTER: submitting job (8, 0, 12) to dispatcher
07:55:25 DISPATCHER: trying to submit job (8, 0, 12)
07:55:25 DISPATCHER: trying to notify the job_runner thread.
07:55:25 HBMASTER: job (8, 0, 12) submitted to dispatcher
07:55:25 DISPATCHER: Trying to submit another job.
07:55:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:55:25 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:55:25 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:55:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:55:25 WORKER: start processing job (8, 0, 12)
07:55:25 WORKER: args: ()
07:55:25 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 969, 'last_n_outputs': 35, 'leak_rate': 0.9543879054992046, 'lr': 0.003002933718893063, 'optimizer': 'SGD', 'sparsity': 0.7688849227876734, 'steps_to_train': 80, 'weight_decay': 0.012352226754281196}, 'budget': 133.33333333333331, 'working_directory': '.'}
07:55:39 DISPATCHER: Starting worker discovery
07:55:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:55:39 DISPATCHER: Finished worker discovery
07:56:39 DISPATCHER: Starting worker discovery
07:56:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:56:39 DISPATCHER: Finished worker discovery
07:57:39 DISPATCHER: Starting worker discovery
07:57:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:57:39 DISPATCHER: Finished worker discovery
07:58:39 DISPATCHER: Starting worker discovery
07:58:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:58:39 DISPATCHER: Finished worker discovery
07:58:44 WORKER: done with job (8, 0, 12), trying to register it.
07:58:44 WORKER: registered result for job (8, 0, 12) with dispatcher
07:58:44 DISPATCHER: job (8, 0, 12) finished
07:58:44 DISPATCHER: register_result: lock acquired
07:58:44 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
07:58:44 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 969, 'last_n_outputs': 35, 'leak_rate': 0.9543879054992046, 'lr': 0.003002933718893063, 'optimizer': 'SGD', 'sparsity': 0.7688849227876734, 'steps_to_train': 80, 'weight_decay': 0.012352226754281196}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2185861914766154, 'info': {'sick_no_sick': 0.2185861914766154, 'config': "{'batch_size': 32, 'hidden_dim': 969, 'last_n_outputs': 35, 'leak_rate': 0.9543879054992046, 'lr': 0.003002933718893063, 'optimizer': 'SGD', 'sparsity': 0.7688849227876734, 'steps_to_train': 80, 'weight_decay': 0.012352226754281196}"}}
exception: None

07:58:44 job_callback for (8, 0, 12) started
07:58:44 DISPATCHER: Trying to submit another job.
07:58:44 job_callback for (8, 0, 12) got condition
07:58:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:58:44 HBMASTER: Trying to run another job!
07:58:44 job_callback for (8, 0, 12) finished
07:58:44 HBMASTER: schedule new run for iteration 8
07:58:44 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
07:58:44 HBMASTER: submitting job (8, 0, 14) to dispatcher
07:58:44 DISPATCHER: trying to submit job (8, 0, 14)
07:58:44 DISPATCHER: trying to notify the job_runner thread.
07:58:44 HBMASTER: job (8, 0, 14) submitted to dispatcher
07:58:44 DISPATCHER: Trying to submit another job.
07:58:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:58:44 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:58:44 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:58:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:58:44 WORKER: start processing job (8, 0, 14)
07:58:44 WORKER: args: ()
07:58:44 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 855, 'last_n_outputs': 46, 'leak_rate': 0.9275090955162033, 'lr': 0.007358762219302203, 'optimizer': 'SGD', 'sparsity': 0.768436272839769, 'steps_to_train': 35, 'weight_decay': 0.033172548853629746}, 'budget': 133.33333333333331, 'working_directory': '.'}
07:59:39 DISPATCHER: Starting worker discovery
07:59:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:59:39 DISPATCHER: Finished worker discovery
08:00:39 DISPATCHER: Starting worker discovery
08:00:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:00:39 DISPATCHER: Finished worker discovery
08:01:39 DISPATCHER: Starting worker discovery
08:01:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:01:39 DISPATCHER: Finished worker discovery
08:02:01 WORKER: done with job (8, 0, 14), trying to register it.
08:02:01 WORKER: registered result for job (8, 0, 14) with dispatcher
08:02:01 DISPATCHER: job (8, 0, 14) finished
08:02:01 DISPATCHER: register_result: lock acquired
08:02:01 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:02:01 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 855, 'last_n_outputs': 46, 'leak_rate': 0.9275090955162033, 'lr': 0.007358762219302203, 'optimizer': 'SGD', 'sparsity': 0.768436272839769, 'steps_to_train': 35, 'weight_decay': 0.033172548853629746}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.14969953477336903, 'info': {'sick_no_sick': 0.14969953477336903, 'config': "{'batch_size': 128, 'hidden_dim': 855, 'last_n_outputs': 46, 'leak_rate': 0.9275090955162033, 'lr': 0.007358762219302203, 'optimizer': 'SGD', 'sparsity': 0.768436272839769, 'steps_to_train': 35, 'weight_decay': 0.033172548853629746}"}}
exception: None

08:02:01 job_callback for (8, 0, 14) started
08:02:01 DISPATCHER: Trying to submit another job.
08:02:01 job_callback for (8, 0, 14) got condition
08:02:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:02:01 HBMASTER: Trying to run another job!
08:02:01 job_callback for (8, 0, 14) finished
08:02:01 HBMASTER: schedule new run for iteration 8
08:02:01 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
08:02:01 HBMASTER: submitting job (8, 0, 18) to dispatcher
08:02:01 DISPATCHER: trying to submit job (8, 0, 18)
08:02:01 DISPATCHER: trying to notify the job_runner thread.
08:02:01 HBMASTER: job (8, 0, 18) submitted to dispatcher
08:02:01 DISPATCHER: Trying to submit another job.
08:02:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:02:01 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:02:01 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:02:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:02:01 WORKER: start processing job (8, 0, 18)
08:02:01 WORKER: args: ()
08:02:01 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 902, 'last_n_outputs': 19, 'leak_rate': 0.8474485830989013, 'lr': 0.003951946066351055, 'optimizer': 'Adam', 'sparsity': 0.7906943570580311, 'steps_to_train': 98, 'weight_decay': 0.011895033666943205}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:02:39 DISPATCHER: Starting worker discovery
08:02:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:02:39 DISPATCHER: Finished worker discovery
08:03:39 DISPATCHER: Starting worker discovery
08:03:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:03:39 DISPATCHER: Finished worker discovery
08:04:39 DISPATCHER: Starting worker discovery
08:04:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:04:39 DISPATCHER: Finished worker discovery
08:05:20 WORKER: done with job (8, 0, 18), trying to register it.
08:05:20 WORKER: registered result for job (8, 0, 18) with dispatcher
08:05:20 DISPATCHER: job (8, 0, 18) finished
08:05:20 DISPATCHER: register_result: lock acquired
08:05:20 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:05:20 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 902, 'last_n_outputs': 19, 'leak_rate': 0.8474485830989013, 'lr': 0.003951946066351055, 'optimizer': 'Adam', 'sparsity': 0.7906943570580311, 'steps_to_train': 98, 'weight_decay': 0.011895033666943205}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.15581929364872038, 'info': {'sick_no_sick': 0.15581929364872038, 'config': "{'batch_size': 16, 'hidden_dim': 902, 'last_n_outputs': 19, 'leak_rate': 0.8474485830989013, 'lr': 0.003951946066351055, 'optimizer': 'Adam', 'sparsity': 0.7906943570580311, 'steps_to_train': 98, 'weight_decay': 0.011895033666943205}"}}
exception: None

08:05:20 job_callback for (8, 0, 18) started
08:05:20 job_callback for (8, 0, 18) got condition
08:05:20 DISPATCHER: Trying to submit another job.
08:05:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:05:20 HBMASTER: Trying to run another job!
08:05:20 job_callback for (8, 0, 18) finished
08:05:20 HBMASTER: schedule new run for iteration 8
08:05:20 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
08:05:20 HBMASTER: submitting job (8, 0, 20) to dispatcher
08:05:20 DISPATCHER: trying to submit job (8, 0, 20)
08:05:20 DISPATCHER: trying to notify the job_runner thread.
08:05:20 HBMASTER: job (8, 0, 20) submitted to dispatcher
08:05:20 DISPATCHER: Trying to submit another job.
08:05:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:05:20 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:05:20 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:05:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:05:20 WORKER: start processing job (8, 0, 20)
08:05:20 WORKER: args: ()
08:05:20 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 968, 'last_n_outputs': 19, 'leak_rate': 0.8985311947965591, 'lr': 0.001754802434037904, 'optimizer': 'SGD', 'sparsity': 0.9373360184928057, 'steps_to_train': 97, 'weight_decay': 0.08881156019905115}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:05:39 DISPATCHER: Starting worker discovery
08:05:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:05:39 DISPATCHER: Finished worker discovery
08:06:39 DISPATCHER: Starting worker discovery
08:06:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:06:39 DISPATCHER: Finished worker discovery
08:07:39 DISPATCHER: Starting worker discovery
08:07:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:07:39 DISPATCHER: Finished worker discovery
08:08:39 WORKER: done with job (8, 0, 20), trying to register it.
08:08:39 WORKER: registered result for job (8, 0, 20) with dispatcher
08:08:39 DISPATCHER: job (8, 0, 20) finished
08:08:39 DISPATCHER: register_result: lock acquired
08:08:39 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:08:39 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 968, 'last_n_outputs': 19, 'leak_rate': 0.8985311947965591, 'lr': 0.001754802434037904, 'optimizer': 'SGD', 'sparsity': 0.9373360184928057, 'steps_to_train': 97, 'weight_decay': 0.08881156019905115}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.11424506927407971, 'info': {'sick_no_sick': 0.11424506927407971, 'config': "{'batch_size': 64, 'hidden_dim': 968, 'last_n_outputs': 19, 'leak_rate': 0.8985311947965591, 'lr': 0.001754802434037904, 'optimizer': 'SGD', 'sparsity': 0.9373360184928057, 'steps_to_train': 97, 'weight_decay': 0.08881156019905115}"}}
exception: None

08:08:39 job_callback for (8, 0, 20) started
08:08:39 DISPATCHER: Trying to submit another job.
08:08:39 job_callback for (8, 0, 20) got condition
08:08:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:08:39 HBMASTER: Trying to run another job!
08:08:39 job_callback for (8, 0, 20) finished
08:08:39 HBMASTER: schedule new run for iteration 8
08:08:39 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
08:08:39 HBMASTER: submitting job (8, 0, 23) to dispatcher
08:08:39 DISPATCHER: trying to submit job (8, 0, 23)
08:08:39 DISPATCHER: trying to notify the job_runner thread.
08:08:39 HBMASTER: job (8, 0, 23) submitted to dispatcher
08:08:39 DISPATCHER: Trying to submit another job.
08:08:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:08:39 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:08:39 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:08:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:08:39 WORKER: start processing job (8, 0, 23)
08:08:39 WORKER: args: ()
08:08:39 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 784, 'last_n_outputs': 25, 'leak_rate': 0.9469721114146974, 'lr': 0.00385002269599862, 'optimizer': 'SGD', 'sparsity': 0.7503328122452655, 'steps_to_train': 67, 'weight_decay': 0.014834813783459936}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:08:39 DISPATCHER: Starting worker discovery
08:08:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:08:40 DISPATCHER: Finished worker discovery
08:09:40 DISPATCHER: Starting worker discovery
08:09:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:09:40 DISPATCHER: Finished worker discovery
08:10:40 DISPATCHER: Starting worker discovery
08:10:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:10:40 DISPATCHER: Finished worker discovery
08:11:40 DISPATCHER: Starting worker discovery
08:11:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:11:40 DISPATCHER: Finished worker discovery
08:11:54 WORKER: done with job (8, 0, 23), trying to register it.
08:11:54 WORKER: registered result for job (8, 0, 23) with dispatcher
08:11:54 DISPATCHER: job (8, 0, 23) finished
08:11:54 DISPATCHER: register_result: lock acquired
08:11:54 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:11:54 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 784, 'last_n_outputs': 25, 'leak_rate': 0.9469721114146974, 'lr': 0.00385002269599862, 'optimizer': 'SGD', 'sparsity': 0.7503328122452655, 'steps_to_train': 67, 'weight_decay': 0.014834813783459936}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.09699116973192509, 'info': {'sick_no_sick': 0.09699116973192509, 'config': "{'batch_size': 128, 'hidden_dim': 784, 'last_n_outputs': 25, 'leak_rate': 0.9469721114146974, 'lr': 0.00385002269599862, 'optimizer': 'SGD', 'sparsity': 0.7503328122452655, 'steps_to_train': 67, 'weight_decay': 0.014834813783459936}"}}
exception: None

08:11:54 job_callback for (8, 0, 23) started
08:11:54 job_callback for (8, 0, 23) got condition
08:11:54 DISPATCHER: Trying to submit another job.
08:11:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:11:54 HBMASTER: Trying to run another job!
08:11:54 job_callback for (8, 0, 23) finished
08:11:54 HBMASTER: schedule new run for iteration 8
08:11:54 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
08:11:54 HBMASTER: submitting job (8, 0, 24) to dispatcher
08:11:54 DISPATCHER: trying to submit job (8, 0, 24)
08:11:54 DISPATCHER: trying to notify the job_runner thread.
08:11:54 HBMASTER: job (8, 0, 24) submitted to dispatcher
08:11:54 DISPATCHER: Trying to submit another job.
08:11:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:11:54 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:11:54 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:11:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:11:54 WORKER: start processing job (8, 0, 24)
08:11:54 WORKER: args: ()
08:11:54 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 529, 'last_n_outputs': 26, 'leak_rate': 0.8971917001965346, 'lr': 0.02583900662654373, 'optimizer': 'SGD', 'sparsity': 0.794665706139505, 'steps_to_train': 46, 'weight_decay': 0.018402776087441456}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:12:40 DISPATCHER: Starting worker discovery
08:12:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:12:40 DISPATCHER: Finished worker discovery
08:13:40 DISPATCHER: Starting worker discovery
08:13:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:13:40 DISPATCHER: Finished worker discovery
08:14:40 DISPATCHER: Starting worker discovery
08:14:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:14:40 DISPATCHER: Finished worker discovery
08:15:11 WORKER: done with job (8, 0, 24), trying to register it.
08:15:11 WORKER: registered result for job (8, 0, 24) with dispatcher
08:15:11 DISPATCHER: job (8, 0, 24) finished
08:15:11 DISPATCHER: register_result: lock acquired
08:15:11 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:15:11 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 529, 'last_n_outputs': 26, 'leak_rate': 0.8971917001965346, 'lr': 0.02583900662654373, 'optimizer': 'SGD', 'sparsity': 0.794665706139505, 'steps_to_train': 46, 'weight_decay': 0.018402776087441456}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.14688973085989582, 'info': {'sick_no_sick': 0.14688973085989582, 'config': "{'batch_size': 16, 'hidden_dim': 529, 'last_n_outputs': 26, 'leak_rate': 0.8971917001965346, 'lr': 0.02583900662654373, 'optimizer': 'SGD', 'sparsity': 0.794665706139505, 'steps_to_train': 46, 'weight_decay': 0.018402776087441456}"}}
exception: None

08:15:11 job_callback for (8, 0, 24) started
08:15:11 job_callback for (8, 0, 24) got condition
08:15:11 DISPATCHER: Trying to submit another job.
08:15:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:15:11 HBMASTER: Trying to run another job!
08:15:11 job_callback for (8, 0, 24) finished
08:15:11 HBMASTER: schedule new run for iteration 8
08:15:11 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
08:15:11 HBMASTER: submitting job (8, 0, 26) to dispatcher
08:15:11 DISPATCHER: trying to submit job (8, 0, 26)
08:15:11 DISPATCHER: trying to notify the job_runner thread.
08:15:11 HBMASTER: job (8, 0, 26) submitted to dispatcher
08:15:11 DISPATCHER: Trying to submit another job.
08:15:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:15:11 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:15:11 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:15:11 WORKER: start processing job (8, 0, 26)
08:15:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:15:11 WORKER: args: ()
08:15:11 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 956, 'last_n_outputs': 45, 'leak_rate': 0.754331117773672, 'lr': 0.0042284101434975525, 'optimizer': 'Adam', 'sparsity': 0.9169879587192004, 'steps_to_train': 48, 'weight_decay': 0.04680338571432161}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:15:40 DISPATCHER: Starting worker discovery
08:15:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:15:40 DISPATCHER: Finished worker discovery
08:16:40 DISPATCHER: Starting worker discovery
08:16:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:16:40 DISPATCHER: Finished worker discovery
08:17:40 DISPATCHER: Starting worker discovery
08:17:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:17:40 DISPATCHER: Finished worker discovery
08:18:29 WORKER: done with job (8, 0, 26), trying to register it.
08:18:29 WORKER: registered result for job (8, 0, 26) with dispatcher
08:18:29 DISPATCHER: job (8, 0, 26) finished
08:18:29 DISPATCHER: register_result: lock acquired
08:18:29 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:18:29 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 956, 'last_n_outputs': 45, 'leak_rate': 0.754331117773672, 'lr': 0.0042284101434975525, 'optimizer': 'Adam', 'sparsity': 0.9169879587192004, 'steps_to_train': 48, 'weight_decay': 0.04680338571432161}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.10342552120475806, 'info': {'sick_no_sick': 0.10342552120475806, 'config': "{'batch_size': 64, 'hidden_dim': 956, 'last_n_outputs': 45, 'leak_rate': 0.754331117773672, 'lr': 0.0042284101434975525, 'optimizer': 'Adam', 'sparsity': 0.9169879587192004, 'steps_to_train': 48, 'weight_decay': 0.04680338571432161}"}}
exception: None

08:18:29 job_callback for (8, 0, 26) started
08:18:29 DISPATCHER: Trying to submit another job.
08:18:29 job_callback for (8, 0, 26) got condition
08:18:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:18:29 HBMASTER: Trying to run another job!
08:18:29 job_callback for (8, 0, 26) finished
08:18:29 ITERATION: Advancing config (8, 0, 12) to next budget 400.000000
08:18:29 ITERATION: Advancing config (8, 0, 14) to next budget 400.000000
08:18:29 ITERATION: Advancing config (8, 0, 18) to next budget 400.000000
08:18:29 HBMASTER: schedule new run for iteration 8
08:18:29 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
08:18:29 HBMASTER: submitting job (8, 0, 12) to dispatcher
08:18:29 DISPATCHER: trying to submit job (8, 0, 12)
08:18:29 DISPATCHER: trying to notify the job_runner thread.
08:18:29 HBMASTER: job (8, 0, 12) submitted to dispatcher
08:18:29 DISPATCHER: Trying to submit another job.
08:18:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:18:29 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:18:29 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:18:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:18:29 WORKER: start processing job (8, 0, 12)
08:18:29 WORKER: args: ()
08:18:29 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 969, 'last_n_outputs': 35, 'leak_rate': 0.9543879054992046, 'lr': 0.003002933718893063, 'optimizer': 'SGD', 'sparsity': 0.7688849227876734, 'steps_to_train': 80, 'weight_decay': 0.012352226754281196}, 'budget': 400.0, 'working_directory': '.'}
08:18:40 DISPATCHER: Starting worker discovery
08:18:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:18:40 DISPATCHER: Finished worker discovery
08:19:40 DISPATCHER: Starting worker discovery
08:19:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:19:40 DISPATCHER: Finished worker discovery
08:20:40 DISPATCHER: Starting worker discovery
08:20:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:20:40 DISPATCHER: Finished worker discovery
08:21:40 DISPATCHER: Starting worker discovery
08:21:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:21:40 DISPATCHER: Finished worker discovery
08:22:40 DISPATCHER: Starting worker discovery
08:22:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:22:40 DISPATCHER: Finished worker discovery
08:23:40 DISPATCHER: Starting worker discovery
08:23:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:23:40 DISPATCHER: Finished worker discovery
08:24:40 DISPATCHER: Starting worker discovery
08:24:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:24:40 DISPATCHER: Finished worker discovery
08:25:40 DISPATCHER: Starting worker discovery
08:25:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:25:40 DISPATCHER: Finished worker discovery
08:26:14 WORKER: done with job (8, 0, 12), trying to register it.
08:26:14 WORKER: registered result for job (8, 0, 12) with dispatcher
08:26:14 DISPATCHER: job (8, 0, 12) finished
08:26:14 DISPATCHER: register_result: lock acquired
08:26:14 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:26:14 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 969, 'last_n_outputs': 35, 'leak_rate': 0.9543879054992046, 'lr': 0.003002933718893063, 'optimizer': 'SGD', 'sparsity': 0.7688849227876734, 'steps_to_train': 80, 'weight_decay': 0.012352226754281196}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.13055819091757592, 'info': {'sick_no_sick': 0.13055819091757592, 'config': "{'batch_size': 32, 'hidden_dim': 969, 'last_n_outputs': 35, 'leak_rate': 0.9543879054992046, 'lr': 0.003002933718893063, 'optimizer': 'SGD', 'sparsity': 0.7688849227876734, 'steps_to_train': 80, 'weight_decay': 0.012352226754281196}"}}
exception: None

08:26:14 job_callback for (8, 0, 12) started
08:26:14 DISPATCHER: Trying to submit another job.
08:26:14 job_callback for (8, 0, 12) got condition
08:26:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:26:14 done building a new model for budget 400.000000 based on 10/21 split
Best loss for this budget:-0.208935





08:26:14 HBMASTER: Trying to run another job!
08:26:14 job_callback for (8, 0, 12) finished
08:26:14 HBMASTER: schedule new run for iteration 8
08:26:14 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
08:26:14 HBMASTER: submitting job (8, 0, 14) to dispatcher
08:26:14 DISPATCHER: trying to submit job (8, 0, 14)
08:26:14 DISPATCHER: trying to notify the job_runner thread.
08:26:14 HBMASTER: job (8, 0, 14) submitted to dispatcher
08:26:14 DISPATCHER: Trying to submit another job.
08:26:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:26:14 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:26:14 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:26:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:26:14 WORKER: start processing job (8, 0, 14)
08:26:14 WORKER: args: ()
08:26:14 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 855, 'last_n_outputs': 46, 'leak_rate': 0.9275090955162033, 'lr': 0.007358762219302203, 'optimizer': 'SGD', 'sparsity': 0.768436272839769, 'steps_to_train': 35, 'weight_decay': 0.033172548853629746}, 'budget': 400.0, 'working_directory': '.'}
08:26:40 DISPATCHER: Starting worker discovery
08:26:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:26:40 DISPATCHER: Finished worker discovery
08:27:40 DISPATCHER: Starting worker discovery
08:27:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:27:40 DISPATCHER: Finished worker discovery
08:28:40 DISPATCHER: Starting worker discovery
08:28:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:28:40 DISPATCHER: Finished worker discovery
08:29:40 DISPATCHER: Starting worker discovery
08:29:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:29:40 DISPATCHER: Finished worker discovery
08:30:40 DISPATCHER: Starting worker discovery
08:30:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:30:40 DISPATCHER: Finished worker discovery
08:31:40 DISPATCHER: Starting worker discovery
08:31:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:31:40 DISPATCHER: Finished worker discovery
08:32:40 DISPATCHER: Starting worker discovery
08:32:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:32:40 DISPATCHER: Finished worker discovery
08:33:40 DISPATCHER: Starting worker discovery
08:33:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:33:40 DISPATCHER: Finished worker discovery
08:33:59 WORKER: done with job (8, 0, 14), trying to register it.
08:33:59 WORKER: registered result for job (8, 0, 14) with dispatcher
08:33:59 DISPATCHER: job (8, 0, 14) finished
08:33:59 DISPATCHER: register_result: lock acquired
08:33:59 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:33:59 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 855, 'last_n_outputs': 46, 'leak_rate': 0.9275090955162033, 'lr': 0.007358762219302203, 'optimizer': 'SGD', 'sparsity': 0.768436272839769, 'steps_to_train': 35, 'weight_decay': 0.033172548853629746}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.04687283824321978, 'info': {'sick_no_sick': 0.04687283824321978, 'config': "{'batch_size': 128, 'hidden_dim': 855, 'last_n_outputs': 46, 'leak_rate': 0.9275090955162033, 'lr': 0.007358762219302203, 'optimizer': 'SGD', 'sparsity': 0.768436272839769, 'steps_to_train': 35, 'weight_decay': 0.033172548853629746}"}}
exception: None

08:33:59 job_callback for (8, 0, 14) started
08:33:59 job_callback for (8, 0, 14) got condition
08:33:59 DISPATCHER: Trying to submit another job.
08:33:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:33:59 done building a new model for budget 400.000000 based on 10/22 split
Best loss for this budget:-0.208935





08:33:59 HBMASTER: Trying to run another job!
08:33:59 job_callback for (8, 0, 14) finished
08:33:59 HBMASTER: schedule new run for iteration 8
08:33:59 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
08:33:59 HBMASTER: submitting job (8, 0, 18) to dispatcher
08:33:59 DISPATCHER: trying to submit job (8, 0, 18)
08:33:59 DISPATCHER: trying to notify the job_runner thread.
08:33:59 HBMASTER: job (8, 0, 18) submitted to dispatcher
08:33:59 DISPATCHER: Trying to submit another job.
08:33:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:33:59 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:33:59 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:33:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:33:59 WORKER: start processing job (8, 0, 18)
08:33:59 WORKER: args: ()
08:33:59 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 902, 'last_n_outputs': 19, 'leak_rate': 0.8474485830989013, 'lr': 0.003951946066351055, 'optimizer': 'Adam', 'sparsity': 0.7906943570580311, 'steps_to_train': 98, 'weight_decay': 0.011895033666943205}, 'budget': 400.0, 'working_directory': '.'}
08:34:40 DISPATCHER: Starting worker discovery
08:34:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:34:40 DISPATCHER: Finished worker discovery
08:35:40 DISPATCHER: Starting worker discovery
08:35:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:35:40 DISPATCHER: Finished worker discovery
08:36:40 DISPATCHER: Starting worker discovery
08:36:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:36:40 DISPATCHER: Finished worker discovery
08:37:40 DISPATCHER: Starting worker discovery
08:37:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:37:40 DISPATCHER: Finished worker discovery
08:38:40 DISPATCHER: Starting worker discovery
08:38:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:38:40 DISPATCHER: Finished worker discovery
08:39:40 DISPATCHER: Starting worker discovery
08:39:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:39:40 DISPATCHER: Finished worker discovery
08:40:40 DISPATCHER: Starting worker discovery
08:40:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:40:40 DISPATCHER: Finished worker discovery
08:41:40 DISPATCHER: Starting worker discovery
08:41:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:41:40 DISPATCHER: Finished worker discovery
08:41:42 WORKER: done with job (8, 0, 18), trying to register it.
08:41:42 WORKER: registered result for job (8, 0, 18) with dispatcher
08:41:42 DISPATCHER: job (8, 0, 18) finished
08:41:42 DISPATCHER: register_result: lock acquired
08:41:42 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:41:42 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 902, 'last_n_outputs': 19, 'leak_rate': 0.8474485830989013, 'lr': 0.003951946066351055, 'optimizer': 'Adam', 'sparsity': 0.7906943570580311, 'steps_to_train': 98, 'weight_decay': 0.011895033666943205}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.11845394197848058, 'info': {'sick_no_sick': 0.11845394197848058, 'config': "{'batch_size': 16, 'hidden_dim': 902, 'last_n_outputs': 19, 'leak_rate': 0.8474485830989013, 'lr': 0.003951946066351055, 'optimizer': 'Adam', 'sparsity': 0.7906943570580311, 'steps_to_train': 98, 'weight_decay': 0.011895033666943205}"}}
exception: None

08:41:42 job_callback for (8, 0, 18) started
08:41:42 DISPATCHER: Trying to submit another job.
08:41:42 job_callback for (8, 0, 18) got condition
08:41:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:41:42 done building a new model for budget 400.000000 based on 10/22 split
Best loss for this budget:-0.208935





08:41:42 HBMASTER: Trying to run another job!
08:41:42 job_callback for (8, 0, 18) finished
08:41:42 ITERATION: Advancing config (8, 0, 12) to next budget 1200.000000
08:41:42 HBMASTER: schedule new run for iteration 8
08:41:42 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
08:41:42 HBMASTER: submitting job (8, 0, 12) to dispatcher
08:41:42 DISPATCHER: trying to submit job (8, 0, 12)
08:41:42 DISPATCHER: trying to notify the job_runner thread.
08:41:42 HBMASTER: job (8, 0, 12) submitted to dispatcher
08:41:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:41:42 DISPATCHER: Trying to submit another job.
08:41:42 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:41:42 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:41:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:41:42 WORKER: start processing job (8, 0, 12)
08:41:42 WORKER: args: ()
08:41:42 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 969, 'last_n_outputs': 35, 'leak_rate': 0.9543879054992046, 'lr': 0.003002933718893063, 'optimizer': 'SGD', 'sparsity': 0.7688849227876734, 'steps_to_train': 80, 'weight_decay': 0.012352226754281196}, 'budget': 1200.0, 'working_directory': '.'}
08:42:40 DISPATCHER: Starting worker discovery
08:42:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:42:40 DISPATCHER: Finished worker discovery
08:43:40 DISPATCHER: Starting worker discovery
08:43:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:43:40 DISPATCHER: Finished worker discovery
08:44:40 DISPATCHER: Starting worker discovery
08:44:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:44:40 DISPATCHER: Finished worker discovery
08:45:40 DISPATCHER: Starting worker discovery
08:45:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:45:40 DISPATCHER: Finished worker discovery
08:46:40 DISPATCHER: Starting worker discovery
08:46:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:46:40 DISPATCHER: Finished worker discovery
08:47:40 DISPATCHER: Starting worker discovery
08:47:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:47:40 DISPATCHER: Finished worker discovery
08:48:40 DISPATCHER: Starting worker discovery
08:48:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:48:40 DISPATCHER: Finished worker discovery
08:49:40 DISPATCHER: Starting worker discovery
08:49:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:49:40 DISPATCHER: Finished worker discovery
08:50:40 DISPATCHER: Starting worker discovery
08:50:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:50:40 DISPATCHER: Finished worker discovery
08:51:40 DISPATCHER: Starting worker discovery
08:51:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:51:40 DISPATCHER: Finished worker discovery
08:52:40 DISPATCHER: Starting worker discovery
08:52:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:52:40 DISPATCHER: Finished worker discovery
08:53:40 DISPATCHER: Starting worker discovery
08:53:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:53:40 DISPATCHER: Finished worker discovery
08:54:40 DISPATCHER: Starting worker discovery
08:54:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:54:40 DISPATCHER: Finished worker discovery
08:55:40 DISPATCHER: Starting worker discovery
08:55:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:55:40 DISPATCHER: Finished worker discovery
08:56:40 DISPATCHER: Starting worker discovery
08:56:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:56:40 DISPATCHER: Finished worker discovery
08:57:40 DISPATCHER: Starting worker discovery
08:57:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:57:40 DISPATCHER: Finished worker discovery
08:58:40 DISPATCHER: Starting worker discovery
08:58:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:58:40 DISPATCHER: Finished worker discovery
08:59:40 DISPATCHER: Starting worker discovery
08:59:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:59:40 DISPATCHER: Finished worker discovery
09:00:40 DISPATCHER: Starting worker discovery
09:00:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:00:40 DISPATCHER: Finished worker discovery
09:01:40 DISPATCHER: Starting worker discovery
09:01:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:01:40 DISPATCHER: Finished worker discovery
09:02:40 DISPATCHER: Starting worker discovery
09:02:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:02:40 DISPATCHER: Finished worker discovery
09:02:48 WORKER: done with job (8, 0, 12), trying to register it.
09:02:48 WORKER: registered result for job (8, 0, 12) with dispatcher
09:02:48 DISPATCHER: job (8, 0, 12) finished
09:02:48 DISPATCHER: register_result: lock acquired
09:02:48 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
09:02:48 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 969, 'last_n_outputs': 35, 'leak_rate': 0.9543879054992046, 'lr': 0.003002933718893063, 'optimizer': 'SGD', 'sparsity': 0.7688849227876734, 'steps_to_train': 80, 'weight_decay': 0.012352226754281196}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.15596789580812997, 'info': {'sick_no_sick': 0.15596789580812997, 'config': "{'batch_size': 32, 'hidden_dim': 969, 'last_n_outputs': 35, 'leak_rate': 0.9543879054992046, 'lr': 0.003002933718893063, 'optimizer': 'SGD', 'sparsity': 0.7688849227876734, 'steps_to_train': 80, 'weight_decay': 0.012352226754281196}"}}
exception: None

09:02:48 job_callback for (8, 0, 12) started
09:02:48 job_callback for (8, 0, 12) got condition
09:02:48 DISPATCHER: Trying to submit another job.
09:02:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:02:48 HBMASTER: Trying to run another job!
09:02:48 job_callback for (8, 0, 12) finished
09:02:48 start sampling a new configuration.
09:02:48 best_vector: [0, 0.1387860772539027, 0.9861850780840047, 0.4042162412335285, 0.6081869380262608, 1, 0.4565109239164241, 0.6696587497062225, 0.9819335783980272], 0.03386536006412891, 0.01278754776098302, 0.0004330549092629354
09:02:48 done sampling a new configuration.
09:02:48 HBMASTER: schedule new run for iteration 9
09:02:48 HBMASTER: trying submitting job (9, 0, 0) to dispatcher
09:02:48 HBMASTER: submitting job (9, 0, 0) to dispatcher
09:02:48 DISPATCHER: trying to submit job (9, 0, 0)
09:02:48 DISPATCHER: trying to notify the job_runner thread.
09:02:48 HBMASTER: job (9, 0, 0) submitted to dispatcher
09:02:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:02:48 DISPATCHER: Trying to submit another job.
09:02:48 DISPATCHER: starting job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:02:48 DISPATCHER: job (9, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:02:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:02:48 WORKER: start processing job (9, 0, 0)
09:02:48 WORKER: args: ()
09:02:48 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 311, 'last_n_outputs': 50, 'leak_rate': 0.8510540603083822, 'lr': 0.016457879417981835, 'optimizer': 'SGD', 'sparsity': 0.8595626217399418, 'steps_to_train': 70, 'weight_decay': 0.1894632746246225}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:03:40 DISPATCHER: Starting worker discovery
09:03:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:03:40 DISPATCHER: Finished worker discovery
09:04:40 DISPATCHER: Starting worker discovery
09:04:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:04:40 DISPATCHER: Finished worker discovery
09:05:40 DISPATCHER: Starting worker discovery
09:05:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:05:40 DISPATCHER: Finished worker discovery
09:06:06 WORKER: done with job (9, 0, 0), trying to register it.
09:06:06 WORKER: registered result for job (9, 0, 0) with dispatcher
09:06:06 DISPATCHER: job (9, 0, 0) finished
09:06:06 DISPATCHER: register_result: lock acquired
09:06:06 DISPATCHER: job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
09:06:06 job_id: (9, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 311, 'last_n_outputs': 50, 'leak_rate': 0.8510540603083822, 'lr': 0.016457879417981835, 'optimizer': 'SGD', 'sparsity': 0.8595626217399418, 'steps_to_train': 70, 'weight_decay': 0.1894632746246225}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.015193646209196861, 'info': {'sick_no_sick': 0.015193646209196861, 'config': "{'batch_size': 16, 'hidden_dim': 311, 'last_n_outputs': 50, 'leak_rate': 0.8510540603083822, 'lr': 0.016457879417981835, 'optimizer': 'SGD', 'sparsity': 0.8595626217399418, 'steps_to_train': 70, 'weight_decay': 0.1894632746246225}"}}
exception: None

09:06:06 job_callback for (9, 0, 0) started
09:06:06 DISPATCHER: Trying to submit another job.
09:06:06 job_callback for (9, 0, 0) got condition
09:06:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:06:06 HBMASTER: Trying to run another job!
09:06:06 job_callback for (9, 0, 0) finished
09:06:06 start sampling a new configuration.
09:06:07 best_vector: [2, 0.9969083398751333, 0.5807963553763605, 0.787370674163758, 0.19093319662985214, 1, 0.8950508535094635, 0.8541402463606907, 0.7870031260462445], 0.04533166111939045, 0.21087850354694798, 0.009559472860154423
09:06:07 done sampling a new configuration.
09:06:07 HBMASTER: schedule new run for iteration 9
09:06:07 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
09:06:07 HBMASTER: submitting job (9, 0, 1) to dispatcher
09:06:07 DISPATCHER: trying to submit job (9, 0, 1)
09:06:07 DISPATCHER: trying to notify the job_runner thread.
09:06:07 HBMASTER: job (9, 0, 1) submitted to dispatcher
09:06:07 DISPATCHER: Trying to submit another job.
09:06:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:06:07 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:06:07 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:06:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:06:07 WORKER: start processing job (9, 0, 1)
09:06:07 WORKER: args: ()
09:06:07 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 998, 'last_n_outputs': 33, 'leak_rate': 0.9468426685409395, 'lr': 0.0024091641572677913, 'optimizer': 'SGD', 'sparsity': 0.9648122048422713, 'steps_to_train': 87, 'weight_decay': 0.10566098954672119}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:06:40 DISPATCHER: Starting worker discovery
09:06:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:06:40 DISPATCHER: Finished worker discovery
09:07:40 DISPATCHER: Starting worker discovery
09:07:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:07:40 DISPATCHER: Finished worker discovery
09:08:40 DISPATCHER: Starting worker discovery
09:08:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:08:40 DISPATCHER: Finished worker discovery
09:09:22 WORKER: done with job (9, 0, 1), trying to register it.
09:09:22 WORKER: registered result for job (9, 0, 1) with dispatcher
09:09:22 DISPATCHER: job (9, 0, 1) finished
09:09:22 DISPATCHER: register_result: lock acquired
09:09:22 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
09:09:22 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 998, 'last_n_outputs': 33, 'leak_rate': 0.9468426685409395, 'lr': 0.0024091641572677913, 'optimizer': 'SGD', 'sparsity': 0.9648122048422713, 'steps_to_train': 87, 'weight_decay': 0.10566098954672119}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.14665854116388696, 'info': {'sick_no_sick': 0.14665854116388696, 'config': "{'batch_size': 64, 'hidden_dim': 998, 'last_n_outputs': 33, 'leak_rate': 0.9468426685409395, 'lr': 0.0024091641572677913, 'optimizer': 'SGD', 'sparsity': 0.9648122048422713, 'steps_to_train': 87, 'weight_decay': 0.10566098954672119}"}}
exception: None

09:09:22 job_callback for (9, 0, 1) started
09:09:22 DISPATCHER: Trying to submit another job.
09:09:22 job_callback for (9, 0, 1) got condition
09:09:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:09:22 HBMASTER: Trying to run another job!
09:09:22 job_callback for (9, 0, 1) finished
09:09:22 start sampling a new configuration.
09:09:22 best_vector: [0, 0.44306608274887477, 0.3342300505469543, 0.21837810895496107, 0.18723136289419273, 0, 0.9885116356895849, 0.9558106733432364, 0.9702497386311218], 0.0689645289734715, 0.0023051420843967093, 0.00015897303806734533
09:09:22 done sampling a new configuration.
09:09:22 HBMASTER: schedule new run for iteration 9
09:09:22 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
09:09:22 HBMASTER: submitting job (9, 0, 2) to dispatcher
09:09:22 DISPATCHER: trying to submit job (9, 0, 2)
09:09:22 DISPATCHER: trying to notify the job_runner thread.
09:09:22 HBMASTER: job (9, 0, 2) submitted to dispatcher
09:09:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:09:22 DISPATCHER: Trying to submit another job.
09:09:22 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:09:22 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:09:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:09:22 WORKER: start processing job (9, 0, 2)
09:09:22 WORKER: args: ()
09:09:22 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 554, 'last_n_outputs': 23, 'leak_rate': 0.8045945272387403, 'lr': 0.00236844184669796, 'optimizer': 'Adam', 'sparsity': 0.9872427925655004, 'steps_to_train': 96, 'weight_decay': 0.1829464612238511}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:09:40 DISPATCHER: Starting worker discovery
09:09:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:09:40 DISPATCHER: Finished worker discovery
09:10:40 DISPATCHER: Starting worker discovery
09:10:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:10:40 DISPATCHER: Finished worker discovery
09:11:40 DISPATCHER: Starting worker discovery
09:11:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:11:40 DISPATCHER: Finished worker discovery
09:12:40 WORKER: done with job (9, 0, 2), trying to register it.
09:12:40 WORKER: registered result for job (9, 0, 2) with dispatcher
09:12:40 DISPATCHER: job (9, 0, 2) finished
09:12:40 DISPATCHER: register_result: lock acquired
09:12:40 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
09:12:40 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 554, 'last_n_outputs': 23, 'leak_rate': 0.8045945272387403, 'lr': 0.00236844184669796, 'optimizer': 'Adam', 'sparsity': 0.9872427925655004, 'steps_to_train': 96, 'weight_decay': 0.1829464612238511}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.023157607857881665, 'info': {'sick_no_sick': 0.023157607857881665, 'config': "{'batch_size': 16, 'hidden_dim': 554, 'last_n_outputs': 23, 'leak_rate': 0.8045945272387403, 'lr': 0.00236844184669796, 'optimizer': 'Adam', 'sparsity': 0.9872427925655004, 'steps_to_train': 96, 'weight_decay': 0.1829464612238511}"}}
exception: None

09:12:40 job_callback for (9, 0, 2) started
09:12:40 DISPATCHER: Trying to submit another job.
09:12:40 job_callback for (9, 0, 2) got condition
09:12:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:12:40 HBMASTER: Trying to run another job!
09:12:40 job_callback for (9, 0, 2) finished
09:12:40 start sampling a new configuration.
09:12:40 best_vector: [3, 0.39359164973360017, 0.8411308590015328, 0.20566543584697417, 0.21511499695044928, 1, 0.296805235162303, 0.9209837955857918, 0.8543532027873739], 0.03318120564478342, 0.015134077708809224, 0.0005021669447001316
09:12:40 done sampling a new configuration.
09:12:40 HBMASTER: schedule new run for iteration 9
09:12:40 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
09:12:40 HBMASTER: submitting job (9, 0, 3) to dispatcher
09:12:40 DISPATCHER: trying to submit job (9, 0, 3)
09:12:40 DISPATCHER: trying to notify the job_runner thread.
09:12:40 HBMASTER: job (9, 0, 3) submitted to dispatcher
09:12:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:12:40 DISPATCHER: Trying to submit another job.
09:12:40 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:12:40 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:12:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:12:40 WORKER: start processing job (9, 0, 3)
09:12:40 WORKER: args: ()
09:12:40 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 515, 'last_n_outputs': 44, 'leak_rate': 0.8014163589617436, 'lr': 0.0026929605658432246, 'optimizer': 'SGD', 'sparsity': 0.8212332564389527, 'steps_to_train': 93, 'weight_decay': 0.1292823219963878}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:12:40 DISPATCHER: Starting worker discovery
09:12:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:12:40 DISPATCHER: Finished worker discovery
09:13:40 DISPATCHER: Starting worker discovery
09:13:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:13:40 DISPATCHER: Finished worker discovery
09:14:40 DISPATCHER: Starting worker discovery
09:14:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:14:40 DISPATCHER: Finished worker discovery
09:15:40 DISPATCHER: Starting worker discovery
09:15:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:15:40 DISPATCHER: Finished worker discovery
09:16:00 WORKER: done with job (9, 0, 3), trying to register it.
09:16:00 WORKER: registered result for job (9, 0, 3) with dispatcher
09:16:00 DISPATCHER: job (9, 0, 3) finished
09:16:00 DISPATCHER: register_result: lock acquired
09:16:00 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
09:16:00 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 515, 'last_n_outputs': 44, 'leak_rate': 0.8014163589617436, 'lr': 0.0026929605658432246, 'optimizer': 'SGD', 'sparsity': 0.8212332564389527, 'steps_to_train': 93, 'weight_decay': 0.1292823219963878}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.018495643716198707, 'info': {'sick_no_sick': 0.018495643716198707, 'config': "{'batch_size': 128, 'hidden_dim': 515, 'last_n_outputs': 44, 'leak_rate': 0.8014163589617436, 'lr': 0.0026929605658432246, 'optimizer': 'SGD', 'sparsity': 0.8212332564389527, 'steps_to_train': 93, 'weight_decay': 0.1292823219963878}"}}
exception: None

09:16:00 job_callback for (9, 0, 3) started
09:16:00 DISPATCHER: Trying to submit another job.
09:16:00 job_callback for (9, 0, 3) got condition
09:16:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:16:00 HBMASTER: Trying to run another job!
09:16:00 job_callback for (9, 0, 3) finished
09:16:00 start sampling a new configuration.
09:16:00 best_vector: [2, 0.3704957365013497, 0.688334200560413, 0.779896919067104, 0.10576462438843762, 1, 0.5843728088385657, 0.16742222177264696, 0.007405146209346319], 0.09516734180651734, 0.8051005354635581, 0.07661927784707057
09:16:00 done sampling a new configuration.
09:16:00 HBMASTER: schedule new run for iteration 9
09:16:00 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
09:16:00 HBMASTER: submitting job (9, 0, 4) to dispatcher
09:16:00 DISPATCHER: trying to submit job (9, 0, 4)
09:16:00 DISPATCHER: trying to notify the job_runner thread.
09:16:00 HBMASTER: job (9, 0, 4) submitted to dispatcher
09:16:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:16:00 DISPATCHER: Trying to submit another job.
09:16:00 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:16:00 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:16:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:16:00 WORKER: start processing job (9, 0, 4)
09:16:00 WORKER: args: ()
09:16:00 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 496, 'last_n_outputs': 38, 'leak_rate': 0.944974229766776, 'lr': 0.0016275309225744965, 'optimizer': 'SGD', 'sparsity': 0.8902494741212558, 'steps_to_train': 25, 'weight_decay': 0.010224317264318467}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:16:40 DISPATCHER: Starting worker discovery
09:16:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:16:40 DISPATCHER: Finished worker discovery
09:17:40 DISPATCHER: Starting worker discovery
09:17:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:17:40 DISPATCHER: Finished worker discovery
09:18:40 DISPATCHER: Starting worker discovery
09:18:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:18:40 DISPATCHER: Finished worker discovery
09:19:16 WORKER: done with job (9, 0, 4), trying to register it.
09:19:16 WORKER: registered result for job (9, 0, 4) with dispatcher
09:19:16 DISPATCHER: job (9, 0, 4) finished
09:19:16 DISPATCHER: register_result: lock acquired
09:19:16 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
09:19:16 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 496, 'last_n_outputs': 38, 'leak_rate': 0.944974229766776, 'lr': 0.0016275309225744965, 'optimizer': 'SGD', 'sparsity': 0.8902494741212558, 'steps_to_train': 25, 'weight_decay': 0.010224317264318467}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.15069956958380842, 'info': {'sick_no_sick': 0.15069956958380842, 'config': "{'batch_size': 64, 'hidden_dim': 496, 'last_n_outputs': 38, 'leak_rate': 0.944974229766776, 'lr': 0.0016275309225744965, 'optimizer': 'SGD', 'sparsity': 0.8902494741212558, 'steps_to_train': 25, 'weight_decay': 0.010224317264318467}"}}
exception: None

09:19:16 job_callback for (9, 0, 4) started
09:19:16 job_callback for (9, 0, 4) got condition
09:19:16 DISPATCHER: Trying to submit another job.
09:19:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:19:16 HBMASTER: Trying to run another job!
09:19:16 job_callback for (9, 0, 4) finished
09:19:16 start sampling a new configuration.
09:19:16 done sampling a new configuration.
09:19:16 HBMASTER: schedule new run for iteration 9
09:19:16 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
09:19:16 HBMASTER: submitting job (9, 0, 5) to dispatcher
09:19:16 DISPATCHER: trying to submit job (9, 0, 5)
09:19:16 DISPATCHER: trying to notify the job_runner thread.
09:19:16 HBMASTER: job (9, 0, 5) submitted to dispatcher
09:19:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:19:16 DISPATCHER: Trying to submit another job.
09:19:16 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:19:16 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:19:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:19:16 WORKER: start processing job (9, 0, 5)
09:19:16 WORKER: args: ()
09:19:16 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 674, 'last_n_outputs': 10, 'leak_rate': 0.9522630087889676, 'lr': 0.07577531962112839, 'optimizer': 'SGD', 'sparsity': 0.9138600224805498, 'steps_to_train': 93, 'weight_decay': 0.037330848979548976}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:19:40 DISPATCHER: Starting worker discovery
09:19:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:19:40 DISPATCHER: Finished worker discovery
09:20:40 DISPATCHER: Starting worker discovery
09:20:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:20:40 DISPATCHER: Finished worker discovery
09:21:40 DISPATCHER: Starting worker discovery
09:21:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:21:40 DISPATCHER: Finished worker discovery
09:22:36 WORKER: done with job (9, 0, 5), trying to register it.
09:22:36 WORKER: registered result for job (9, 0, 5) with dispatcher
09:22:36 DISPATCHER: job (9, 0, 5) finished
09:22:36 DISPATCHER: register_result: lock acquired
09:22:36 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
09:22:36 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 674, 'last_n_outputs': 10, 'leak_rate': 0.9522630087889676, 'lr': 0.07577531962112839, 'optimizer': 'SGD', 'sparsity': 0.9138600224805498, 'steps_to_train': 93, 'weight_decay': 0.037330848979548976}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.02309151770424142, 'info': {'sick_no_sick': 0.02309151770424142, 'config': "{'batch_size': 128, 'hidden_dim': 674, 'last_n_outputs': 10, 'leak_rate': 0.9522630087889676, 'lr': 0.07577531962112839, 'optimizer': 'SGD', 'sparsity': 0.9138600224805498, 'steps_to_train': 93, 'weight_decay': 0.037330848979548976}"}}
exception: None

09:22:36 job_callback for (9, 0, 5) started
09:22:36 job_callback for (9, 0, 5) got condition
09:22:36 DISPATCHER: Trying to submit another job.
09:22:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:22:36 HBMASTER: Trying to run another job!
09:22:36 job_callback for (9, 0, 5) finished
09:22:36 start sampling a new configuration.
09:22:36 done sampling a new configuration.
09:22:36 HBMASTER: schedule new run for iteration 9
09:22:36 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
09:22:36 HBMASTER: submitting job (9, 0, 6) to dispatcher
09:22:36 DISPATCHER: trying to submit job (9, 0, 6)
09:22:36 DISPATCHER: trying to notify the job_runner thread.
09:22:36 HBMASTER: job (9, 0, 6) submitted to dispatcher
09:22:36 DISPATCHER: Trying to submit another job.
09:22:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:22:36 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:22:36 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:22:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:22:36 WORKER: start processing job (9, 0, 6)
09:22:36 WORKER: args: ()
09:22:36 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 506, 'last_n_outputs': 50, 'leak_rate': 0.8236040894834222, 'lr': 0.005880180295516496, 'optimizer': 'Adam', 'sparsity': 0.9228721148168537, 'steps_to_train': 71, 'weight_decay': 0.058988687557450833}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:22:40 DISPATCHER: Starting worker discovery
09:22:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:22:40 DISPATCHER: Finished worker discovery
09:23:40 DISPATCHER: Starting worker discovery
09:23:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:23:40 DISPATCHER: Finished worker discovery
09:24:40 DISPATCHER: Starting worker discovery
09:24:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:24:40 DISPATCHER: Finished worker discovery
09:25:40 DISPATCHER: Starting worker discovery
09:25:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:25:40 DISPATCHER: Finished worker discovery
09:25:53 WORKER: done with job (9, 0, 6), trying to register it.
09:25:53 WORKER: registered result for job (9, 0, 6) with dispatcher
09:25:53 DISPATCHER: job (9, 0, 6) finished
09:25:53 DISPATCHER: register_result: lock acquired
09:25:53 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
09:25:53 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 506, 'last_n_outputs': 50, 'leak_rate': 0.8236040894834222, 'lr': 0.005880180295516496, 'optimizer': 'Adam', 'sparsity': 0.9228721148168537, 'steps_to_train': 71, 'weight_decay': 0.058988687557450833}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.10938005484908248, 'info': {'sick_no_sick': 0.10938005484908248, 'config': "{'batch_size': 128, 'hidden_dim': 506, 'last_n_outputs': 50, 'leak_rate': 0.8236040894834222, 'lr': 0.005880180295516496, 'optimizer': 'Adam', 'sparsity': 0.9228721148168537, 'steps_to_train': 71, 'weight_decay': 0.058988687557450833}"}}
exception: None

09:25:53 job_callback for (9, 0, 6) started
09:25:53 DISPATCHER: Trying to submit another job.
09:25:53 job_callback for (9, 0, 6) got condition
09:25:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:25:53 HBMASTER: Trying to run another job!
09:25:53 job_callback for (9, 0, 6) finished
09:25:53 start sampling a new configuration.
09:25:53 best_vector: [0, 0.2588521817426447, 0.8815475135736432, 0.4663121798483359, 0.7334786050431289, 0, 0.457838161510131, 0.3371470134949722, 0.6549746559848357], 0.05614265700520686, 0.08960217106717336, 0.005030503957146184
09:25:53 done sampling a new configuration.
09:25:53 HBMASTER: schedule new run for iteration 9
09:25:53 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
09:25:53 HBMASTER: submitting job (9, 0, 7) to dispatcher
09:25:53 DISPATCHER: trying to submit job (9, 0, 7)
09:25:53 DISPATCHER: trying to notify the job_runner thread.
09:25:53 HBMASTER: job (9, 0, 7) submitted to dispatcher
09:25:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:25:53 DISPATCHER: Trying to submit another job.
09:25:53 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:25:53 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:25:53 WORKER: start processing job (9, 0, 7)
09:25:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:25:53 WORKER: args: ()
09:25:53 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 407, 'last_n_outputs': 46, 'leak_rate': 0.866578044962084, 'lr': 0.029306044861334396, 'optimizer': 'Adam', 'sparsity': 0.8598811587624314, 'steps_to_train': 40, 'weight_decay': 0.07114455607722313}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:26:40 DISPATCHER: Starting worker discovery
09:26:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:26:40 DISPATCHER: Finished worker discovery
09:27:40 DISPATCHER: Starting worker discovery
09:27:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:27:40 DISPATCHER: Finished worker discovery
09:28:40 DISPATCHER: Starting worker discovery
09:28:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:28:40 DISPATCHER: Finished worker discovery
09:29:09 WORKER: done with job (9, 0, 7), trying to register it.
09:29:09 WORKER: registered result for job (9, 0, 7) with dispatcher
09:29:09 DISPATCHER: job (9, 0, 7) finished
09:29:09 DISPATCHER: register_result: lock acquired
09:29:09 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
09:29:09 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 407, 'last_n_outputs': 46, 'leak_rate': 0.866578044962084, 'lr': 0.029306044861334396, 'optimizer': 'Adam', 'sparsity': 0.8598811587624314, 'steps_to_train': 40, 'weight_decay': 0.07114455607722313}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0662455589803839, 'info': {'sick_no_sick': 0.0662455589803839, 'config': "{'batch_size': 16, 'hidden_dim': 407, 'last_n_outputs': 46, 'leak_rate': 0.866578044962084, 'lr': 0.029306044861334396, 'optimizer': 'Adam', 'sparsity': 0.8598811587624314, 'steps_to_train': 40, 'weight_decay': 0.07114455607722313}"}}
exception: None

09:29:09 job_callback for (9, 0, 7) started
09:29:09 job_callback for (9, 0, 7) got condition
09:29:09 DISPATCHER: Trying to submit another job.
09:29:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:29:09 HBMASTER: Trying to run another job!
09:29:09 job_callback for (9, 0, 7) finished
09:29:09 start sampling a new configuration.
09:29:09 best_vector: [2, 0.4443605562103418, 0.7234902986228446, 0.4319143495107893, 0.6420547812882663, 1, 0.4744181568033801, 0.13800056112052245, 0.9746728052079446], 0.0723080649016659, 0.05016128858790907, 0.003627065710765722
09:29:09 done sampling a new configuration.
09:29:09 HBMASTER: schedule new run for iteration 9
09:29:09 HBMASTER: trying submitting job (9, 0, 8) to dispatcher
09:29:09 HBMASTER: submitting job (9, 0, 8) to dispatcher
09:29:09 DISPATCHER: trying to submit job (9, 0, 8)
09:29:09 DISPATCHER: trying to notify the job_runner thread.
09:29:09 HBMASTER: job (9, 0, 8) submitted to dispatcher
09:29:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:29:09 DISPATCHER: Trying to submit another job.
09:29:09 DISPATCHER: starting job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:29:09 DISPATCHER: job (9, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:29:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:29:09 WORKER: start processing job (9, 0, 8)
09:29:09 WORKER: args: ()
09:29:09 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 555, 'last_n_outputs': 39, 'leak_rate': 0.8579785873776973, 'lr': 0.01923576942222788, 'optimizer': 'SGD', 'sparsity': 0.8638603576328112, 'steps_to_train': 22, 'weight_decay': 0.1853866922022033}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:29:40 DISPATCHER: Starting worker discovery
09:29:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:29:40 DISPATCHER: Finished worker discovery
09:30:40 DISPATCHER: Starting worker discovery
09:30:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:30:40 DISPATCHER: Finished worker discovery
09:31:40 DISPATCHER: Starting worker discovery
09:31:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:31:40 DISPATCHER: Finished worker discovery
09:32:25 WORKER: done with job (9, 0, 8), trying to register it.
09:32:25 WORKER: registered result for job (9, 0, 8) with dispatcher
09:32:25 DISPATCHER: job (9, 0, 8) finished
09:32:25 DISPATCHER: register_result: lock acquired
09:32:25 DISPATCHER: job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
09:32:25 job_id: (9, 0, 8)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 555, 'last_n_outputs': 39, 'leak_rate': 0.8579785873776973, 'lr': 0.01923576942222788, 'optimizer': 'SGD', 'sparsity': 0.8638603576328112, 'steps_to_train': 22, 'weight_decay': 0.1853866922022033}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.013224085378377723, 'info': {'sick_no_sick': 0.013224085378377723, 'config': "{'batch_size': 64, 'hidden_dim': 555, 'last_n_outputs': 39, 'leak_rate': 0.8579785873776973, 'lr': 0.01923576942222788, 'optimizer': 'SGD', 'sparsity': 0.8638603576328112, 'steps_to_train': 22, 'weight_decay': 0.1853866922022033}"}}
exception: None

09:32:25 job_callback for (9, 0, 8) started
09:32:25 job_callback for (9, 0, 8) got condition
09:32:25 DISPATCHER: Trying to submit another job.
09:32:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:32:25 HBMASTER: Trying to run another job!
09:32:25 job_callback for (9, 0, 8) finished
09:32:25 ITERATION: Advancing config (9, 0, 1) to next budget 400.000000
09:32:25 ITERATION: Advancing config (9, 0, 4) to next budget 400.000000
09:32:25 ITERATION: Advancing config (9, 0, 6) to next budget 400.000000
09:32:25 HBMASTER: schedule new run for iteration 9
09:32:25 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
09:32:25 HBMASTER: submitting job (9, 0, 1) to dispatcher
09:32:25 DISPATCHER: trying to submit job (9, 0, 1)
09:32:25 DISPATCHER: trying to notify the job_runner thread.
09:32:25 HBMASTER: job (9, 0, 1) submitted to dispatcher
09:32:25 DISPATCHER: Trying to submit another job.
09:32:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:32:25 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:32:25 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:32:25 WORKER: start processing job (9, 0, 1)
09:32:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:32:25 WORKER: args: ()
09:32:25 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 998, 'last_n_outputs': 33, 'leak_rate': 0.9468426685409395, 'lr': 0.0024091641572677913, 'optimizer': 'SGD', 'sparsity': 0.9648122048422713, 'steps_to_train': 87, 'weight_decay': 0.10566098954672119}, 'budget': 400.0, 'working_directory': '.'}
09:32:40 DISPATCHER: Starting worker discovery
09:32:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:32:40 DISPATCHER: Finished worker discovery
09:33:40 DISPATCHER: Starting worker discovery
09:33:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:33:40 DISPATCHER: Finished worker discovery
09:34:40 DISPATCHER: Starting worker discovery
09:34:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:34:40 DISPATCHER: Finished worker discovery
09:35:40 DISPATCHER: Starting worker discovery
09:35:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:35:40 DISPATCHER: Finished worker discovery
09:36:40 DISPATCHER: Starting worker discovery
09:36:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:36:40 DISPATCHER: Finished worker discovery
09:37:40 DISPATCHER: Starting worker discovery
09:37:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:37:40 DISPATCHER: Finished worker discovery
09:38:40 DISPATCHER: Starting worker discovery
09:38:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:38:40 DISPATCHER: Finished worker discovery
09:39:40 DISPATCHER: Starting worker discovery
09:39:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:39:40 DISPATCHER: Finished worker discovery
09:40:11 WORKER: done with job (9, 0, 1), trying to register it.
09:40:11 WORKER: registered result for job (9, 0, 1) with dispatcher
09:40:11 DISPATCHER: job (9, 0, 1) finished
09:40:11 DISPATCHER: register_result: lock acquired
09:40:11 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
09:40:11 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 998, 'last_n_outputs': 33, 'leak_rate': 0.9468426685409395, 'lr': 0.0024091641572677913, 'optimizer': 'SGD', 'sparsity': 0.9648122048422713, 'steps_to_train': 87, 'weight_decay': 0.10566098954672119}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.14213488369727756, 'info': {'sick_no_sick': 0.14213488369727756, 'config': "{'batch_size': 64, 'hidden_dim': 998, 'last_n_outputs': 33, 'leak_rate': 0.9468426685409395, 'lr': 0.0024091641572677913, 'optimizer': 'SGD', 'sparsity': 0.9648122048422713, 'steps_to_train': 87, 'weight_decay': 0.10566098954672119}"}}
exception: None

09:40:11 job_callback for (9, 0, 1) started
09:40:11 DISPATCHER: Trying to submit another job.
09:40:11 job_callback for (9, 0, 1) got condition
09:40:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:40:11 done building a new model for budget 400.000000 based on 10/23 split
Best loss for this budget:-0.208935





09:40:11 HBMASTER: Trying to run another job!
09:40:11 job_callback for (9, 0, 1) finished
09:40:11 HBMASTER: schedule new run for iteration 9
09:40:11 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
09:40:11 HBMASTER: submitting job (9, 0, 4) to dispatcher
09:40:11 DISPATCHER: trying to submit job (9, 0, 4)
09:40:11 DISPATCHER: trying to notify the job_runner thread.
09:40:11 HBMASTER: job (9, 0, 4) submitted to dispatcher
09:40:11 DISPATCHER: Trying to submit another job.
09:40:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:40:11 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:40:11 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:40:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:40:11 WORKER: start processing job (9, 0, 4)
09:40:11 WORKER: args: ()
09:40:11 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 496, 'last_n_outputs': 38, 'leak_rate': 0.944974229766776, 'lr': 0.0016275309225744965, 'optimizer': 'SGD', 'sparsity': 0.8902494741212558, 'steps_to_train': 25, 'weight_decay': 0.010224317264318467}, 'budget': 400.0, 'working_directory': '.'}
09:40:40 DISPATCHER: Starting worker discovery
09:40:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:40:40 DISPATCHER: Finished worker discovery
09:41:40 DISPATCHER: Starting worker discovery
09:41:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:41:40 DISPATCHER: Finished worker discovery
09:42:40 DISPATCHER: Starting worker discovery
09:42:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:42:40 DISPATCHER: Finished worker discovery
09:43:40 DISPATCHER: Starting worker discovery
09:43:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:43:40 DISPATCHER: Finished worker discovery
09:44:40 DISPATCHER: Starting worker discovery
09:44:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:44:40 DISPATCHER: Finished worker discovery
09:45:40 DISPATCHER: Starting worker discovery
09:45:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:45:40 DISPATCHER: Finished worker discovery
09:46:40 DISPATCHER: Starting worker discovery
09:46:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:46:40 DISPATCHER: Finished worker discovery
09:47:40 DISPATCHER: Starting worker discovery
09:47:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:47:40 DISPATCHER: Finished worker discovery
09:47:59 WORKER: done with job (9, 0, 4), trying to register it.
09:47:59 WORKER: registered result for job (9, 0, 4) with dispatcher
09:47:59 DISPATCHER: job (9, 0, 4) finished
09:47:59 DISPATCHER: register_result: lock acquired
09:47:59 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
09:47:59 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 496, 'last_n_outputs': 38, 'leak_rate': 0.944974229766776, 'lr': 0.0016275309225744965, 'optimizer': 'SGD', 'sparsity': 0.8902494741212558, 'steps_to_train': 25, 'weight_decay': 0.010224317264318467}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.13243376944898871, 'info': {'sick_no_sick': 0.13243376944898871, 'config': "{'batch_size': 64, 'hidden_dim': 496, 'last_n_outputs': 38, 'leak_rate': 0.944974229766776, 'lr': 0.0016275309225744965, 'optimizer': 'SGD', 'sparsity': 0.8902494741212558, 'steps_to_train': 25, 'weight_decay': 0.010224317264318467}"}}
exception: None

09:47:59 job_callback for (9, 0, 4) started
09:47:59 job_callback for (9, 0, 4) got condition
09:47:59 DISPATCHER: Trying to submit another job.
09:47:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:47:59 done building a new model for budget 400.000000 based on 10/24 split
Best loss for this budget:-0.208935





09:47:59 HBMASTER: Trying to run another job!
09:47:59 job_callback for (9, 0, 4) finished
09:47:59 HBMASTER: schedule new run for iteration 9
09:47:59 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
09:47:59 HBMASTER: submitting job (9, 0, 6) to dispatcher
09:47:59 DISPATCHER: trying to submit job (9, 0, 6)
09:47:59 DISPATCHER: trying to notify the job_runner thread.
09:47:59 HBMASTER: job (9, 0, 6) submitted to dispatcher
09:47:59 DISPATCHER: Trying to submit another job.
09:47:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:47:59 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:47:59 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:47:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:47:59 WORKER: start processing job (9, 0, 6)
09:48:00 WORKER: args: ()
09:48:00 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 506, 'last_n_outputs': 50, 'leak_rate': 0.8236040894834222, 'lr': 0.005880180295516496, 'optimizer': 'Adam', 'sparsity': 0.9228721148168537, 'steps_to_train': 71, 'weight_decay': 0.058988687557450833}, 'budget': 400.0, 'working_directory': '.'}
09:48:40 DISPATCHER: Starting worker discovery
09:48:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:48:40 DISPATCHER: Finished worker discovery
09:49:40 DISPATCHER: Starting worker discovery
09:49:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:49:40 DISPATCHER: Finished worker discovery
09:50:40 DISPATCHER: Starting worker discovery
09:50:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:50:40 DISPATCHER: Finished worker discovery
09:51:40 DISPATCHER: Starting worker discovery
09:51:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:51:40 DISPATCHER: Finished worker discovery
09:52:40 DISPATCHER: Starting worker discovery
09:52:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:52:40 DISPATCHER: Finished worker discovery
09:53:40 DISPATCHER: Starting worker discovery
09:53:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:53:40 DISPATCHER: Finished worker discovery
09:54:40 DISPATCHER: Starting worker discovery
09:54:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:54:40 DISPATCHER: Finished worker discovery
09:55:40 DISPATCHER: Starting worker discovery
09:55:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:55:40 DISPATCHER: Finished worker discovery
09:55:45 WORKER: done with job (9, 0, 6), trying to register it.
09:55:45 WORKER: registered result for job (9, 0, 6) with dispatcher
09:55:45 DISPATCHER: job (9, 0, 6) finished
09:55:45 DISPATCHER: register_result: lock acquired
09:55:45 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
09:55:45 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 506, 'last_n_outputs': 50, 'leak_rate': 0.8236040894834222, 'lr': 0.005880180295516496, 'optimizer': 'Adam', 'sparsity': 0.9228721148168537, 'steps_to_train': 71, 'weight_decay': 0.058988687557450833}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.1406997949546554, 'info': {'sick_no_sick': 0.1406997949546554, 'config': "{'batch_size': 128, 'hidden_dim': 506, 'last_n_outputs': 50, 'leak_rate': 0.8236040894834222, 'lr': 0.005880180295516496, 'optimizer': 'Adam', 'sparsity': 0.9228721148168537, 'steps_to_train': 71, 'weight_decay': 0.058988687557450833}"}}
exception: None

09:55:45 job_callback for (9, 0, 6) started
09:55:45 DISPATCHER: Trying to submit another job.
09:55:45 job_callback for (9, 0, 6) got condition
09:55:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:55:45 done building a new model for budget 400.000000 based on 10/25 split
Best loss for this budget:-0.208935





09:55:45 HBMASTER: Trying to run another job!
09:55:45 job_callback for (9, 0, 6) finished
09:55:45 ITERATION: Advancing config (9, 0, 1) to next budget 1200.000000
09:55:45 HBMASTER: schedule new run for iteration 9
09:55:45 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
09:55:45 HBMASTER: submitting job (9, 0, 1) to dispatcher
09:55:45 DISPATCHER: trying to submit job (9, 0, 1)
09:55:45 DISPATCHER: trying to notify the job_runner thread.
09:55:45 HBMASTER: job (9, 0, 1) submitted to dispatcher
09:55:45 DISPATCHER: Trying to submit another job.
09:55:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:55:45 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:55:45 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:55:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:55:45 WORKER: start processing job (9, 0, 1)
09:55:45 WORKER: args: ()
09:55:45 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 998, 'last_n_outputs': 33, 'leak_rate': 0.9468426685409395, 'lr': 0.0024091641572677913, 'optimizer': 'SGD', 'sparsity': 0.9648122048422713, 'steps_to_train': 87, 'weight_decay': 0.10566098954672119}, 'budget': 1200.0, 'working_directory': '.'}
09:56:40 DISPATCHER: Starting worker discovery
09:56:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:56:40 DISPATCHER: Finished worker discovery
09:57:40 DISPATCHER: Starting worker discovery
09:57:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:57:40 DISPATCHER: Finished worker discovery
09:58:40 DISPATCHER: Starting worker discovery
09:58:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:58:40 DISPATCHER: Finished worker discovery
09:59:40 DISPATCHER: Starting worker discovery
09:59:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:59:40 DISPATCHER: Finished worker discovery
10:00:40 DISPATCHER: Starting worker discovery
10:00:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:00:40 DISPATCHER: Finished worker discovery
10:01:40 DISPATCHER: Starting worker discovery
10:01:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:01:40 DISPATCHER: Finished worker discovery
10:02:40 DISPATCHER: Starting worker discovery
10:02:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:02:40 DISPATCHER: Finished worker discovery
10:03:40 DISPATCHER: Starting worker discovery
10:03:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:03:40 DISPATCHER: Finished worker discovery
10:04:40 DISPATCHER: Starting worker discovery
10:04:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:04:40 DISPATCHER: Finished worker discovery
10:05:40 DISPATCHER: Starting worker discovery
10:05:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:05:40 DISPATCHER: Finished worker discovery
10:06:40 DISPATCHER: Starting worker discovery
10:06:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:06:40 DISPATCHER: Finished worker discovery
10:07:40 DISPATCHER: Starting worker discovery
10:07:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:07:40 DISPATCHER: Finished worker discovery
10:08:40 DISPATCHER: Starting worker discovery
10:08:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:08:40 DISPATCHER: Finished worker discovery
10:09:40 DISPATCHER: Starting worker discovery
10:09:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:09:40 DISPATCHER: Finished worker discovery
10:10:40 DISPATCHER: Starting worker discovery
10:10:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:10:40 DISPATCHER: Finished worker discovery
10:11:40 DISPATCHER: Starting worker discovery
10:11:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:11:40 DISPATCHER: Finished worker discovery
10:12:40 DISPATCHER: Starting worker discovery
10:12:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:12:40 DISPATCHER: Finished worker discovery
10:13:40 DISPATCHER: Starting worker discovery
10:13:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:13:40 DISPATCHER: Finished worker discovery
10:14:40 DISPATCHER: Starting worker discovery
10:14:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:14:40 DISPATCHER: Finished worker discovery
10:15:40 DISPATCHER: Starting worker discovery
10:15:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:15:40 DISPATCHER: Finished worker discovery
10:16:40 DISPATCHER: Starting worker discovery
10:16:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:16:40 DISPATCHER: Finished worker discovery
10:16:54 WORKER: done with job (9, 0, 1), trying to register it.
10:16:54 WORKER: registered result for job (9, 0, 1) with dispatcher
10:16:54 DISPATCHER: job (9, 0, 1) finished
10:16:54 DISPATCHER: register_result: lock acquired
10:16:54 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
10:16:54 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 998, 'last_n_outputs': 33, 'leak_rate': 0.9468426685409395, 'lr': 0.0024091641572677913, 'optimizer': 'SGD', 'sparsity': 0.9648122048422713, 'steps_to_train': 87, 'weight_decay': 0.10566098954672119}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.08831370333069422, 'info': {'sick_no_sick': 0.08831370333069422, 'config': "{'batch_size': 64, 'hidden_dim': 998, 'last_n_outputs': 33, 'leak_rate': 0.9468426685409395, 'lr': 0.0024091641572677913, 'optimizer': 'SGD', 'sparsity': 0.9648122048422713, 'steps_to_train': 87, 'weight_decay': 0.10566098954672119}"}}
exception: None

10:16:54 job_callback for (9, 0, 1) started
10:16:54 DISPATCHER: Trying to submit another job.
10:16:54 job_callback for (9, 0, 1) got condition
10:16:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:16:55 HBMASTER: Trying to run another job!
10:16:55 job_callback for (9, 0, 1) finished
10:16:55 HBMASTER: shutdown initiated, shutdown_workers = True
10:16:55 WORKER: shutting down now!
10:16:55 DISPATCHER: Dispatcher shutting down
10:16:55 DISPATCHER: discover_workers shutting down
10:16:55 DISPATCHER: Trying to submit another job.
10:16:55 DISPATCHER: 'discover_worker' thread exited
10:16:55 DISPATCHER: job_runner shutting down
10:16:55 DISPATCHER: 'job_runner' thread exited
10:16:55 DISPATCHER: shut down complete
10:16:55 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7fb47c14e710; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:31920>
10:16:55 WORKER: No dispatcher found. Waiting for one to initiate contact.
10:16:55 WORKER: start listening for jobs
10:16:55 wait_for_workers trying to get the condition
10:16:55 DISPATCHER: started the 'discover_worker' thread
10:16:55 DISPATCHER: started the 'job_runner' thread
10:16:55 DISPATCHER: Pyro daemon running on localhost:45111
10:16:55 HBMASTER: only 0 worker(s) available, waiting for at least 1.
10:16:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:16:55 DISPATCHER: Starting worker discovery
10:16:55 DISPATCHER: Found 1 potential workers, 0 currently in the pool.
10:16:55 DISPATCHER: discovered new worker, hpbandster.run_0.worker.metagpuj.30598140416580691776
10:16:55 HBMASTER: number of workers changed to 1
10:16:55 adjust_queue_size: lock accquired
10:16:55 HBMASTER: adjusted queue size to (0, 1)
10:16:55 DISPATCHER: Finished worker discovery
10:16:55 DISPATCHER: Trying to submit another job.
10:16:55 DISPATCHER: A new worker triggered discover_worker
10:16:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:16:55 Enough workers to start this run!
10:16:55 HBMASTER: starting run at 1583831815.4451306
10:16:55 start sampling a new configuration.
10:16:55 done sampling a new configuration.
10:16:55 DISPATCHER: Starting worker discovery
10:16:55 HBMASTER: schedule new run for iteration 0
10:16:55 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
10:16:55 HBMASTER: submitting job (0, 0, 0) to dispatcher
10:16:55 DISPATCHER: trying to submit job (0, 0, 0)
10:16:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:16:55 DISPATCHER: Finished worker discovery
10:16:55 DISPATCHER: trying to notify the job_runner thread.
10:16:55 HBMASTER: job (0, 0, 0) submitted to dispatcher
10:16:55 DISPATCHER: Trying to submit another job.
10:16:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:16:55 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:16:55 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:16:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:16:55 WORKER: start processing job (0, 0, 0)
10:16:55 WORKER: args: ()
10:16:55 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.020851819725787084, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.013383736287803422, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 26, 'num_filters_3': 72, 'num_filters_4': 56}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:17:55 DISPATCHER: Starting worker discovery
10:17:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:17:55 DISPATCHER: Finished worker discovery
10:18:42 WORKER: done with job (0, 0, 0), trying to register it.
10:18:42 WORKER: registered result for job (0, 0, 0) with dispatcher
10:18:42 DISPATCHER: job (0, 0, 0) finished
10:18:42 DISPATCHER: register_result: lock acquired
10:18:42 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
10:18:42 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.020851819725787084, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.013383736287803422, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 26, 'num_filters_3': 72, 'num_filters_4': 56}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.020851819725787084, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.013383736287803422, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 26, 'num_filters_3': 72, 'num_filters_4': 56}"}}
exception: None

10:18:42 job_callback for (0, 0, 0) started
10:18:42 job_callback for (0, 0, 0) got condition
10:18:42 DISPATCHER: Trying to submit another job.
10:18:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:18:42 Only 1 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:18:42 HBMASTER: Trying to run another job!
10:18:42 job_callback for (0, 0, 0) finished
10:18:42 start sampling a new configuration.
10:18:42 done sampling a new configuration.
10:18:42 HBMASTER: schedule new run for iteration 0
10:18:42 HBMASTER: trying submitting job (0, 0, 1) to dispatcher
10:18:42 HBMASTER: submitting job (0, 0, 1) to dispatcher
10:18:42 DISPATCHER: trying to submit job (0, 0, 1)
10:18:42 DISPATCHER: trying to notify the job_runner thread.
10:18:42 HBMASTER: job (0, 0, 1) submitted to dispatcher
10:18:42 DISPATCHER: Trying to submit another job.
10:18:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:18:42 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:18:42 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:18:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:18:42 WORKER: start processing job (0, 0, 1)
10:18:42 WORKER: args: ()
10:18:42 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.024573729047300177, 'num_filters_1': 42, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.025383016053151138, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 26, 'num_filters_3': 58}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:18:55 DISPATCHER: Starting worker discovery
10:18:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:18:55 DISPATCHER: Finished worker discovery
10:19:55 DISPATCHER: Starting worker discovery
10:19:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:19:55 DISPATCHER: Finished worker discovery
10:20:30 WORKER: done with job (0, 0, 1), trying to register it.
10:20:30 WORKER: registered result for job (0, 0, 1) with dispatcher
10:20:30 DISPATCHER: job (0, 0, 1) finished
10:20:30 DISPATCHER: register_result: lock acquired
10:20:30 DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
10:20:30 job_id: (0, 0, 1)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.024573729047300177, 'num_filters_1': 42, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.025383016053151138, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 26, 'num_filters_3': 58}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.024573729047300177, 'num_filters_1': 42, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.025383016053151138, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 26, 'num_filters_3': 58}"}}
exception: None

10:20:30 job_callback for (0, 0, 1) started
10:20:30 job_callback for (0, 0, 1) got condition
10:20:30 DISPATCHER: Trying to submit another job.
10:20:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:20:30 Only 2 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:20:30 HBMASTER: Trying to run another job!
10:20:30 job_callback for (0, 0, 1) finished
10:20:30 start sampling a new configuration.
10:20:30 done sampling a new configuration.
10:20:30 HBMASTER: schedule new run for iteration 0
10:20:30 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
10:20:30 HBMASTER: submitting job (0, 0, 2) to dispatcher
10:20:30 DISPATCHER: trying to submit job (0, 0, 2)
10:20:30 DISPATCHER: trying to notify the job_runner thread.
10:20:30 HBMASTER: job (0, 0, 2) submitted to dispatcher
10:20:30 DISPATCHER: Trying to submit another job.
10:20:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:20:30 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:20:30 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:20:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:20:30 WORKER: start processing job (0, 0, 2)
10:20:30 WORKER: args: ()
10:20:30 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0017555389283153858, 'num_filters_1': 71, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.013059260893662524, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 84, 'num_filters_3': 46, 'num_filters_4': 28, 'num_filters_5': 42}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:20:55 DISPATCHER: Starting worker discovery
10:20:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:20:55 DISPATCHER: Finished worker discovery
10:21:55 DISPATCHER: Starting worker discovery
10:21:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:21:55 DISPATCHER: Finished worker discovery
10:22:19 WORKER: done with job (0, 0, 2), trying to register it.
10:22:19 WORKER: registered result for job (0, 0, 2) with dispatcher
10:22:19 DISPATCHER: job (0, 0, 2) finished
10:22:19 DISPATCHER: register_result: lock acquired
10:22:19 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
10:22:19 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0017555389283153858, 'num_filters_1': 71, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.013059260893662524, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 84, 'num_filters_3': 46, 'num_filters_4': 28, 'num_filters_5': 42}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6406577503722166, 'info': {'sick_no_sick': 0.6406577503722166, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0017555389283153858, 'num_filters_1': 71, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.013059260893662524, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 84, 'num_filters_3': 46, 'num_filters_4': 28, 'num_filters_5': 42}"}}
exception: None

10:22:19 job_callback for (0, 0, 2) started
10:22:19 DISPATCHER: Trying to submit another job.
10:22:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:22:19 job_callback for (0, 0, 2) got condition
10:22:19 Only 3 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:22:19 HBMASTER: Trying to run another job!
10:22:19 job_callback for (0, 0, 2) finished
10:22:19 start sampling a new configuration.
10:22:19 done sampling a new configuration.
10:22:19 HBMASTER: schedule new run for iteration 0
10:22:19 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
10:22:19 HBMASTER: submitting job (0, 0, 3) to dispatcher
10:22:19 DISPATCHER: trying to submit job (0, 0, 3)
10:22:19 DISPATCHER: trying to notify the job_runner thread.
10:22:19 HBMASTER: job (0, 0, 3) submitted to dispatcher
10:22:19 DISPATCHER: Trying to submit another job.
10:22:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:22:19 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:22:19 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:22:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:22:19 WORKER: start processing job (0, 0, 3)
10:22:19 WORKER: args: ()
10:22:19 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.022747550561226296, 'num_filters_1': 128, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.02109234621950553, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 60, 'num_filters_3': 74}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:22:55 DISPATCHER: Starting worker discovery
10:22:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:22:55 DISPATCHER: Finished worker discovery
10:23:55 DISPATCHER: Starting worker discovery
10:23:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:23:55 DISPATCHER: Finished worker discovery
10:24:11 WORKER: done with job (0, 0, 3), trying to register it.
10:24:11 WORKER: registered result for job (0, 0, 3) with dispatcher
10:24:11 DISPATCHER: job (0, 0, 3) finished
10:24:11 DISPATCHER: register_result: lock acquired
10:24:11 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
10:24:11 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.022747550561226296, 'num_filters_1': 128, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.02109234621950553, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 60, 'num_filters_3': 74}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5747138892116044, 'info': {'sick_no_sick': 0.5747138892116044, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.022747550561226296, 'num_filters_1': 128, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.02109234621950553, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 60, 'num_filters_3': 74}"}}
exception: None

10:24:11 job_callback for (0, 0, 3) started
10:24:11 DISPATCHER: Trying to submit another job.
10:24:11 job_callback for (0, 0, 3) got condition
10:24:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:24:11 Only 4 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:24:11 HBMASTER: Trying to run another job!
10:24:11 job_callback for (0, 0, 3) finished
10:24:11 start sampling a new configuration.
10:24:11 done sampling a new configuration.
10:24:11 HBMASTER: schedule new run for iteration 0
10:24:11 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
10:24:11 HBMASTER: submitting job (0, 0, 4) to dispatcher
10:24:11 DISPATCHER: trying to submit job (0, 0, 4)
10:24:11 DISPATCHER: trying to notify the job_runner thread.
10:24:11 HBMASTER: job (0, 0, 4) submitted to dispatcher
10:24:11 DISPATCHER: Trying to submit another job.
10:24:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:24:11 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:24:11 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:24:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:24:11 WORKER: start processing job (0, 0, 4)
10:24:11 WORKER: args: ()
10:24:11 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0070664445301997555, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.03015219503735817, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 28, 'num_filters_3': 103}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:24:55 DISPATCHER: Starting worker discovery
10:24:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:24:55 DISPATCHER: Finished worker discovery
10:25:55 DISPATCHER: Starting worker discovery
10:25:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:25:55 DISPATCHER: Finished worker discovery
10:25:57 WORKER: done with job (0, 0, 4), trying to register it.
10:25:57 WORKER: registered result for job (0, 0, 4) with dispatcher
10:25:57 DISPATCHER: job (0, 0, 4) finished
10:25:57 DISPATCHER: register_result: lock acquired
10:25:57 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
10:25:57 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0070664445301997555, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.03015219503735817, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 28, 'num_filters_3': 103}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5194980517710954, 'info': {'sick_no_sick': 0.5194980517710954, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0070664445301997555, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.03015219503735817, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 28, 'num_filters_3': 103}"}}
exception: None

10:25:57 job_callback for (0, 0, 4) started
10:25:57 DISPATCHER: Trying to submit another job.
10:25:57 job_callback for (0, 0, 4) got condition
10:25:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:25:57 Only 5 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:25:57 HBMASTER: Trying to run another job!
10:25:57 job_callback for (0, 0, 4) finished
10:25:57 start sampling a new configuration.
10:25:57 done sampling a new configuration.
10:25:57 HBMASTER: schedule new run for iteration 0
10:25:57 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
10:25:57 HBMASTER: submitting job (0, 0, 5) to dispatcher
10:25:57 DISPATCHER: trying to submit job (0, 0, 5)
10:25:57 DISPATCHER: trying to notify the job_runner thread.
10:25:57 HBMASTER: job (0, 0, 5) submitted to dispatcher
10:25:57 DISPATCHER: Trying to submit another job.
10:25:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:25:57 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:25:57 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:25:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:25:57 WORKER: start processing job (0, 0, 5)
10:25:57 WORKER: args: ()
10:25:57 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0024310514106905944, 'num_filters_1': 92, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.033379675856655765, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 54, 'num_filters_3': 93, 'num_filters_4': 58}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:26:55 DISPATCHER: Starting worker discovery
10:26:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:26:55 DISPATCHER: Finished worker discovery
10:27:43 WORKER: done with job (0, 0, 5), trying to register it.
10:27:43 WORKER: registered result for job (0, 0, 5) with dispatcher
10:27:43 DISPATCHER: job (0, 0, 5) finished
10:27:43 DISPATCHER: register_result: lock acquired
10:27:43 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
10:27:43 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0024310514106905944, 'num_filters_1': 92, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.033379675856655765, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 54, 'num_filters_3': 93, 'num_filters_4': 58}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5522033319437805, 'info': {'sick_no_sick': 0.5522033319437805, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0024310514106905944, 'num_filters_1': 92, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.033379675856655765, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 54, 'num_filters_3': 93, 'num_filters_4': 58}"}}
exception: None

10:27:43 job_callback for (0, 0, 5) started
10:27:43 job_callback for (0, 0, 5) got condition
10:27:43 DISPATCHER: Trying to submit another job.
10:27:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:27:43 Only 6 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:27:43 HBMASTER: Trying to run another job!
10:27:43 job_callback for (0, 0, 5) finished
10:27:43 start sampling a new configuration.
10:27:43 done sampling a new configuration.
10:27:43 HBMASTER: schedule new run for iteration 0
10:27:43 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
10:27:43 HBMASTER: submitting job (0, 0, 6) to dispatcher
10:27:43 DISPATCHER: trying to submit job (0, 0, 6)
10:27:43 DISPATCHER: trying to notify the job_runner thread.
10:27:43 HBMASTER: job (0, 0, 6) submitted to dispatcher
10:27:43 DISPATCHER: Trying to submit another job.
10:27:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:27:43 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:27:43 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:27:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:27:43 WORKER: start processing job (0, 0, 6)
10:27:43 WORKER: args: ()
10:27:43 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.008516813676211642, 'num_filters_1': 90, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.01646333750101569, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 52, 'num_filters_3': 33, 'num_filters_4': 122, 'num_filters_5': 46}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:27:55 DISPATCHER: Starting worker discovery
10:27:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:27:55 DISPATCHER: Finished worker discovery
10:28:55 DISPATCHER: Starting worker discovery
10:28:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:28:55 DISPATCHER: Finished worker discovery
10:29:29 WORKER: done with job (0, 0, 6), trying to register it.
10:29:29 WORKER: registered result for job (0, 0, 6) with dispatcher
10:29:29 DISPATCHER: job (0, 0, 6) finished
10:29:29 DISPATCHER: register_result: lock acquired
10:29:29 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
10:29:29 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.008516813676211642, 'num_filters_1': 90, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.01646333750101569, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 52, 'num_filters_3': 33, 'num_filters_4': 122, 'num_filters_5': 46}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6260038429114094, 'info': {'sick_no_sick': 0.6260038429114094, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.008516813676211642, 'num_filters_1': 90, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.01646333750101569, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 52, 'num_filters_3': 33, 'num_filters_4': 122, 'num_filters_5': 46}"}}
exception: None

10:29:29 job_callback for (0, 0, 6) started
10:29:29 job_callback for (0, 0, 6) got condition
10:29:29 DISPATCHER: Trying to submit another job.
10:29:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:29:29 Only 7 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:29:29 HBMASTER: Trying to run another job!
10:29:29 job_callback for (0, 0, 6) finished
10:29:29 start sampling a new configuration.
10:29:29 done sampling a new configuration.
10:29:29 HBMASTER: schedule new run for iteration 0
10:29:29 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
10:29:29 HBMASTER: submitting job (0, 0, 7) to dispatcher
10:29:29 DISPATCHER: trying to submit job (0, 0, 7)
10:29:29 DISPATCHER: trying to notify the job_runner thread.
10:29:29 HBMASTER: job (0, 0, 7) submitted to dispatcher
10:29:29 DISPATCHER: Trying to submit another job.
10:29:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:29:29 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:29:29 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:29:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:29:29 WORKER: start processing job (0, 0, 7)
10:29:29 WORKER: args: ()
10:29:29 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0018213223156072844, 'num_filters_1': 102, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.09355875370947672, 'kernel_size_2': 5, 'num_filters_2': 35}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:29:55 DISPATCHER: Starting worker discovery
10:29:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:29:55 DISPATCHER: Finished worker discovery
10:30:55 DISPATCHER: Starting worker discovery
10:30:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:30:55 DISPATCHER: Finished worker discovery
10:31:17 WORKER: done with job (0, 0, 7), trying to register it.
10:31:17 WORKER: registered result for job (0, 0, 7) with dispatcher
10:31:17 DISPATCHER: job (0, 0, 7) finished
10:31:17 DISPATCHER: register_result: lock acquired
10:31:17 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
10:31:17 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0018213223156072844, 'num_filters_1': 102, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.09355875370947672, 'kernel_size_2': 5, 'num_filters_2': 35}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3224615058987417, 'info': {'sick_no_sick': 0.3224615058987417, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0018213223156072844, 'num_filters_1': 102, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.09355875370947672, 'kernel_size_2': 5, 'num_filters_2': 35}"}}
exception: None

10:31:17 job_callback for (0, 0, 7) started
10:31:17 job_callback for (0, 0, 7) got condition
10:31:17 DISPATCHER: Trying to submit another job.
10:31:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:31:17 Only 8 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:31:17 HBMASTER: Trying to run another job!
10:31:17 job_callback for (0, 0, 7) finished
10:31:17 start sampling a new configuration.
10:31:17 done sampling a new configuration.
10:31:17 HBMASTER: schedule new run for iteration 0
10:31:17 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
10:31:17 HBMASTER: submitting job (0, 0, 8) to dispatcher
10:31:17 DISPATCHER: trying to submit job (0, 0, 8)
10:31:17 DISPATCHER: trying to notify the job_runner thread.
10:31:17 HBMASTER: job (0, 0, 8) submitted to dispatcher
10:31:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:31:17 DISPATCHER: Trying to submit another job.
10:31:17 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:31:17 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:31:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:31:17 WORKER: start processing job (0, 0, 8)
10:31:17 WORKER: args: ()
10:31:17 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.05795659300665869, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.027737319056544106, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 23, 'num_filters_3': 32, 'num_filters_4': 71}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:31:55 DISPATCHER: Starting worker discovery
10:31:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:31:55 DISPATCHER: Finished worker discovery
10:32:55 DISPATCHER: Starting worker discovery
10:32:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:32:55 DISPATCHER: Finished worker discovery
10:33:05 WORKER: done with job (0, 0, 8), trying to register it.
10:33:05 WORKER: registered result for job (0, 0, 8) with dispatcher
10:33:05 DISPATCHER: job (0, 0, 8) finished
10:33:05 DISPATCHER: register_result: lock acquired
10:33:05 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
10:33:05 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.05795659300665869, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.027737319056544106, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 23, 'num_filters_3': 32, 'num_filters_4': 71}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5239278002092247, 'info': {'sick_no_sick': 0.5239278002092247, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.05795659300665869, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.027737319056544106, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 23, 'num_filters_3': 32, 'num_filters_4': 71}"}}
exception: None

10:33:05 job_callback for (0, 0, 8) started
10:33:05 job_callback for (0, 0, 8) got condition
10:33:05 DISPATCHER: Trying to submit another job.
10:33:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:33:05 Only 9 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:33:05 HBMASTER: Trying to run another job!
10:33:05 job_callback for (0, 0, 8) finished
10:33:05 start sampling a new configuration.
10:33:05 done sampling a new configuration.
10:33:05 HBMASTER: schedule new run for iteration 0
10:33:05 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
10:33:05 HBMASTER: submitting job (0, 0, 9) to dispatcher
10:33:05 DISPATCHER: trying to submit job (0, 0, 9)
10:33:05 DISPATCHER: trying to notify the job_runner thread.
10:33:05 HBMASTER: job (0, 0, 9) submitted to dispatcher
10:33:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:33:05 DISPATCHER: Trying to submit another job.
10:33:05 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:33:05 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:33:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:33:05 WORKER: start processing job (0, 0, 9)
10:33:05 WORKER: args: ()
10:33:05 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0036976219184446627, 'num_filters_1': 22, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.017181694650003097, 'kernel_size_2': 5, 'num_filters_2': 24}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:33:55 DISPATCHER: Starting worker discovery
10:33:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:33:55 DISPATCHER: Finished worker discovery
10:34:53 WORKER: done with job (0, 0, 9), trying to register it.
10:34:53 WORKER: registered result for job (0, 0, 9) with dispatcher
10:34:53 DISPATCHER: job (0, 0, 9) finished
10:34:53 DISPATCHER: register_result: lock acquired
10:34:53 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
10:34:53 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0036976219184446627, 'num_filters_1': 22, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.017181694650003097, 'kernel_size_2': 5, 'num_filters_2': 24}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5747929338651996, 'info': {'sick_no_sick': 0.5747929338651996, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0036976219184446627, 'num_filters_1': 22, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.017181694650003097, 'kernel_size_2': 5, 'num_filters_2': 24}"}}
exception: None

10:34:53 job_callback for (0, 0, 9) started
10:34:53 job_callback for (0, 0, 9) got condition
10:34:53 DISPATCHER: Trying to submit another job.
10:34:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:34:53 Only 10 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:34:53 HBMASTER: Trying to run another job!
10:34:53 job_callback for (0, 0, 9) finished
10:34:53 start sampling a new configuration.
10:34:53 done sampling a new configuration.
10:34:53 HBMASTER: schedule new run for iteration 0
10:34:53 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
10:34:53 HBMASTER: submitting job (0, 0, 10) to dispatcher
10:34:53 DISPATCHER: trying to submit job (0, 0, 10)
10:34:53 DISPATCHER: trying to notify the job_runner thread.
10:34:53 HBMASTER: job (0, 0, 10) submitted to dispatcher
10:34:53 DISPATCHER: Trying to submit another job.
10:34:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:34:53 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:34:53 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:34:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:34:53 WORKER: start processing job (0, 0, 10)
10:34:53 WORKER: args: ()
10:34:53 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0014821748565220266, 'num_filters_1': 55, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.13112436696265084}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:34:55 DISPATCHER: Starting worker discovery
10:34:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:34:55 DISPATCHER: Finished worker discovery
10:35:55 DISPATCHER: Starting worker discovery
10:35:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:35:55 DISPATCHER: Finished worker discovery
10:36:40 WORKER: done with job (0, 0, 10), trying to register it.
10:36:40 WORKER: registered result for job (0, 0, 10) with dispatcher
10:36:40 DISPATCHER: job (0, 0, 10) finished
10:36:40 DISPATCHER: register_result: lock acquired
10:36:40 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
10:36:40 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0014821748565220266, 'num_filters_1': 55, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.13112436696265084}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4050897534287791, 'info': {'sick_no_sick': 0.4050897534287791, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0014821748565220266, 'num_filters_1': 55, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.13112436696265084}"}}
exception: None

10:36:40 job_callback for (0, 0, 10) started
10:36:40 job_callback for (0, 0, 10) got condition
10:36:40 DISPATCHER: Trying to submit another job.
10:36:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:36:40 Only 11 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:36:40 HBMASTER: Trying to run another job!
10:36:40 job_callback for (0, 0, 10) finished
10:36:40 start sampling a new configuration.
10:36:40 done sampling a new configuration.
10:36:40 HBMASTER: schedule new run for iteration 0
10:36:40 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
10:36:40 HBMASTER: submitting job (0, 0, 11) to dispatcher
10:36:40 DISPATCHER: trying to submit job (0, 0, 11)
10:36:40 DISPATCHER: trying to notify the job_runner thread.
10:36:40 HBMASTER: job (0, 0, 11) submitted to dispatcher
10:36:40 DISPATCHER: Trying to submit another job.
10:36:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:36:40 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:36:40 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:36:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:36:40 WORKER: start processing job (0, 0, 11)
10:36:40 WORKER: args: ()
10:36:40 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.08848453684332078, 'num_filters_1': 50, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.13562621625405546, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 74, 'num_filters_3': 30, 'num_filters_4': 45}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:36:55 DISPATCHER: Starting worker discovery
10:36:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:36:55 DISPATCHER: Finished worker discovery
10:37:55 DISPATCHER: Starting worker discovery
10:37:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:37:55 DISPATCHER: Finished worker discovery
10:38:27 WORKER: done with job (0, 0, 11), trying to register it.
10:38:27 WORKER: registered result for job (0, 0, 11) with dispatcher
10:38:27 DISPATCHER: job (0, 0, 11) finished
10:38:27 DISPATCHER: register_result: lock acquired
10:38:27 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
10:38:27 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.08848453684332078, 'num_filters_1': 50, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.13562621625405546, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 74, 'num_filters_3': 30, 'num_filters_4': 45}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.08848453684332078, 'num_filters_1': 50, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.13562621625405546, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 74, 'num_filters_3': 30, 'num_filters_4': 45}"}}
exception: None

10:38:27 job_callback for (0, 0, 11) started
10:38:27 DISPATCHER: Trying to submit another job.
10:38:27 job_callback for (0, 0, 11) got condition
10:38:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:38:27 Only 12 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:38:27 HBMASTER: Trying to run another job!
10:38:27 job_callback for (0, 0, 11) finished
10:38:27 start sampling a new configuration.
10:38:27 done sampling a new configuration.
10:38:27 HBMASTER: schedule new run for iteration 0
10:38:27 HBMASTER: trying submitting job (0, 0, 12) to dispatcher
10:38:27 HBMASTER: submitting job (0, 0, 12) to dispatcher
10:38:27 DISPATCHER: trying to submit job (0, 0, 12)
10:38:27 DISPATCHER: trying to notify the job_runner thread.
10:38:27 HBMASTER: job (0, 0, 12) submitted to dispatcher
10:38:27 DISPATCHER: Trying to submit another job.
10:38:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:38:27 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:38:27 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:38:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:38:27 WORKER: start processing job (0, 0, 12)
10:38:27 WORKER: args: ()
10:38:27 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.007449015200330031, 'num_filters_1': 104, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.05508045852592512, 'kernel_size_2': 5, 'num_filters_2': 39}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:38:55 DISPATCHER: Starting worker discovery
10:38:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:38:55 DISPATCHER: Finished worker discovery
10:39:55 DISPATCHER: Starting worker discovery
10:39:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:39:55 DISPATCHER: Finished worker discovery
10:40:15 WORKER: done with job (0, 0, 12), trying to register it.
10:40:15 WORKER: registered result for job (0, 0, 12) with dispatcher
10:40:15 DISPATCHER: job (0, 0, 12) finished
10:40:15 DISPATCHER: register_result: lock acquired
10:40:15 DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
10:40:15 job_id: (0, 0, 12)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.007449015200330031, 'num_filters_1': 104, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.05508045852592512, 'kernel_size_2': 5, 'num_filters_2': 39}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5212255437236712, 'info': {'sick_no_sick': 0.5212255437236712, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.007449015200330031, 'num_filters_1': 104, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.05508045852592512, 'kernel_size_2': 5, 'num_filters_2': 39}"}}
exception: None

10:40:15 job_callback for (0, 0, 12) started
10:40:15 job_callback for (0, 0, 12) got condition
10:40:15 DISPATCHER: Trying to submit another job.
10:40:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:40:15 Only 13 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:40:15 HBMASTER: Trying to run another job!
10:40:15 job_callback for (0, 0, 12) finished
10:40:15 start sampling a new configuration.
10:40:15 done sampling a new configuration.
10:40:15 HBMASTER: schedule new run for iteration 0
10:40:15 HBMASTER: trying submitting job (0, 0, 13) to dispatcher
10:40:15 HBMASTER: submitting job (0, 0, 13) to dispatcher
10:40:15 DISPATCHER: trying to submit job (0, 0, 13)
10:40:15 DISPATCHER: trying to notify the job_runner thread.
10:40:15 HBMASTER: job (0, 0, 13) submitted to dispatcher
10:40:15 DISPATCHER: Trying to submit another job.
10:40:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:40:15 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:40:15 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:40:15 WORKER: start processing job (0, 0, 13)
10:40:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:40:15 WORKER: args: ()
10:40:15 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.041540760036623665, 'num_filters_1': 24, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.05163896603767151, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 84, 'num_filters_3': 26}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:40:55 DISPATCHER: Starting worker discovery
10:40:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:40:55 DISPATCHER: Finished worker discovery
10:41:55 DISPATCHER: Starting worker discovery
10:41:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:41:55 DISPATCHER: Finished worker discovery
10:42:01 WORKER: done with job (0, 0, 13), trying to register it.
10:42:01 WORKER: registered result for job (0, 0, 13) with dispatcher
10:42:01 DISPATCHER: job (0, 0, 13) finished
10:42:01 DISPATCHER: register_result: lock acquired
10:42:01 DISPATCHER: job (0, 0, 13) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
10:42:01 job_id: (0, 0, 13)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.041540760036623665, 'num_filters_1': 24, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.05163896603767151, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 84, 'num_filters_3': 26}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.00011404209071418924, 'info': {'sick_no_sick': -0.00011404209071418924, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.041540760036623665, 'num_filters_1': 24, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.05163896603767151, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 84, 'num_filters_3': 26}"}}
exception: None

10:42:01 job_callback for (0, 0, 13) started
10:42:01 job_callback for (0, 0, 13) got condition
10:42:01 DISPATCHER: Trying to submit another job.
10:42:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:42:01 Only 14 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:42:01 HBMASTER: Trying to run another job!
10:42:01 job_callback for (0, 0, 13) finished
10:42:01 start sampling a new configuration.
10:42:01 done sampling a new configuration.
10:42:01 HBMASTER: schedule new run for iteration 0
10:42:01 HBMASTER: trying submitting job (0, 0, 14) to dispatcher
10:42:01 HBMASTER: submitting job (0, 0, 14) to dispatcher
10:42:01 DISPATCHER: trying to submit job (0, 0, 14)
10:42:01 DISPATCHER: trying to notify the job_runner thread.
10:42:01 HBMASTER: job (0, 0, 14) submitted to dispatcher
10:42:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:42:01 DISPATCHER: Trying to submit another job.
10:42:01 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:42:01 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:42:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:42:01 WORKER: start processing job (0, 0, 14)
10:42:01 WORKER: args: ()
10:42:01 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.06268786256784405, 'num_filters_1': 32, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.0750761168283615, 'kernel_size_2': 5, 'num_filters_2': 32}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:42:55 DISPATCHER: Starting worker discovery
10:42:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:42:55 DISPATCHER: Finished worker discovery
10:43:49 WORKER: done with job (0, 0, 14), trying to register it.
10:43:49 WORKER: registered result for job (0, 0, 14) with dispatcher
10:43:49 DISPATCHER: job (0, 0, 14) finished
10:43:49 DISPATCHER: register_result: lock acquired
10:43:49 DISPATCHER: job (0, 0, 14) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
10:43:49 job_id: (0, 0, 14)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.06268786256784405, 'num_filters_1': 32, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.0750761168283615, 'kernel_size_2': 5, 'num_filters_2': 32}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -7.909484925777975e-05, 'info': {'sick_no_sick': 7.909484925777975e-05, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.06268786256784405, 'num_filters_1': 32, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.0750761168283615, 'kernel_size_2': 5, 'num_filters_2': 32}"}}
exception: None

10:43:49 job_callback for (0, 0, 14) started
10:43:49 DISPATCHER: Trying to submit another job.
10:43:49 job_callback for (0, 0, 14) got condition
10:43:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:43:49 Only 15 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:43:49 HBMASTER: Trying to run another job!
10:43:49 job_callback for (0, 0, 14) finished
10:43:49 start sampling a new configuration.
10:43:49 done sampling a new configuration.
10:43:49 HBMASTER: schedule new run for iteration 0
10:43:49 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
10:43:49 HBMASTER: submitting job (0, 0, 15) to dispatcher
10:43:49 DISPATCHER: trying to submit job (0, 0, 15)
10:43:49 DISPATCHER: trying to notify the job_runner thread.
10:43:49 HBMASTER: job (0, 0, 15) submitted to dispatcher
10:43:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:43:49 DISPATCHER: Trying to submit another job.
10:43:49 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:43:49 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:43:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:43:49 WORKER: start processing job (0, 0, 15)
10:43:49 WORKER: args: ()
10:43:49 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.017726545915512888, 'num_filters_1': 60, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.1404231318870663, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 48, 'num_filters_3': 65, 'num_filters_4': 23}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:43:55 DISPATCHER: Starting worker discovery
10:43:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:43:55 DISPATCHER: Finished worker discovery
10:44:55 DISPATCHER: Starting worker discovery
10:44:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:44:55 DISPATCHER: Finished worker discovery
10:45:35 WORKER: done with job (0, 0, 15), trying to register it.
10:45:35 WORKER: registered result for job (0, 0, 15) with dispatcher
10:45:35 DISPATCHER: job (0, 0, 15) finished
10:45:35 DISPATCHER: register_result: lock acquired
10:45:35 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
10:45:35 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.017726545915512888, 'num_filters_1': 60, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.1404231318870663, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 48, 'num_filters_3': 65, 'num_filters_4': 23}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.004857270763223587, 'info': {'sick_no_sick': 0.004857270763223587, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.017726545915512888, 'num_filters_1': 60, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.1404231318870663, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 48, 'num_filters_3': 65, 'num_filters_4': 23}"}}
exception: None

10:45:35 job_callback for (0, 0, 15) started
10:45:35 DISPATCHER: Trying to submit another job.
10:45:35 job_callback for (0, 0, 15) got condition
10:45:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:45:35 Only 16 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
10:45:35 HBMASTER: Trying to run another job!
10:45:35 job_callback for (0, 0, 15) finished
10:45:35 start sampling a new configuration.
10:45:35 done sampling a new configuration.
10:45:35 HBMASTER: schedule new run for iteration 0
10:45:35 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
10:45:35 HBMASTER: submitting job (0, 0, 16) to dispatcher
10:45:35 DISPATCHER: trying to submit job (0, 0, 16)
10:45:35 DISPATCHER: trying to notify the job_runner thread.
10:45:35 HBMASTER: job (0, 0, 16) submitted to dispatcher
10:45:35 DISPATCHER: Trying to submit another job.
10:45:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:45:35 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:45:35 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:45:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:45:35 WORKER: start processing job (0, 0, 16)
10:45:35 WORKER: args: ()
10:45:35 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.026729064690250628, 'num_filters_1': 46, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.013106063241684875, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 31, 'num_filters_3': 95, 'num_filters_4': 22}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:45:55 DISPATCHER: Starting worker discovery
10:45:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:45:55 DISPATCHER: Finished worker discovery
10:46:55 DISPATCHER: Starting worker discovery
10:46:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:46:55 DISPATCHER: Finished worker discovery
10:47:21 WORKER: done with job (0, 0, 16), trying to register it.
10:47:21 WORKER: registered result for job (0, 0, 16) with dispatcher
10:47:21 DISPATCHER: job (0, 0, 16) finished
10:47:21 DISPATCHER: register_result: lock acquired
10:47:21 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
10:47:21 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.026729064690250628, 'num_filters_1': 46, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.013106063241684875, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 31, 'num_filters_3': 95, 'num_filters_4': 22}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6238879363530596, 'info': {'sick_no_sick': 0.6238879363530596, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.026729064690250628, 'num_filters_1': 46, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.013106063241684875, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 31, 'num_filters_3': 95, 'num_filters_4': 22}"}}
exception: None

10:47:21 job_callback for (0, 0, 16) started
10:47:21 DISPATCHER: Trying to submit another job.
10:47:21 job_callback for (0, 0, 16) got condition
10:47:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:47:21 HBMASTER: Trying to run another job!
10:47:21 job_callback for (0, 0, 16) finished
10:47:21 start sampling a new configuration.
10:47:21 done sampling a new configuration.
10:47:21 HBMASTER: schedule new run for iteration 0
10:47:21 HBMASTER: trying submitting job (0, 0, 17) to dispatcher
10:47:21 HBMASTER: submitting job (0, 0, 17) to dispatcher
10:47:21 DISPATCHER: trying to submit job (0, 0, 17)
10:47:21 DISPATCHER: trying to notify the job_runner thread.
10:47:21 HBMASTER: job (0, 0, 17) submitted to dispatcher
10:47:21 DISPATCHER: Trying to submit another job.
10:47:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:47:21 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:47:21 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:47:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:47:21 WORKER: start processing job (0, 0, 17)
10:47:21 WORKER: args: ()
10:47:21 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.018311239987877793, 'num_filters_1': 122, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.11905105141555351, 'kernel_size_2': 5, 'num_filters_2': 74}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:47:55 DISPATCHER: Starting worker discovery
10:47:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:47:55 DISPATCHER: Finished worker discovery
10:48:55 DISPATCHER: Starting worker discovery
10:48:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:48:55 DISPATCHER: Finished worker discovery
10:49:09 WORKER: done with job (0, 0, 17), trying to register it.
10:49:09 WORKER: registered result for job (0, 0, 17) with dispatcher
10:49:09 DISPATCHER: job (0, 0, 17) finished
10:49:09 DISPATCHER: register_result: lock acquired
10:49:09 DISPATCHER: job (0, 0, 17) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
10:49:09 job_id: (0, 0, 17)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.018311239987877793, 'num_filters_1': 122, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.11905105141555351, 'kernel_size_2': 5, 'num_filters_2': 74}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.013349762896228225, 'info': {'sick_no_sick': 0.013349762896228225, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.018311239987877793, 'num_filters_1': 122, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.11905105141555351, 'kernel_size_2': 5, 'num_filters_2': 74}"}}
exception: None

10:49:09 job_callback for (0, 0, 17) started
10:49:09 job_callback for (0, 0, 17) got condition
10:49:09 DISPATCHER: Trying to submit another job.
10:49:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:49:09 HBMASTER: Trying to run another job!
10:49:09 job_callback for (0, 0, 17) finished
10:49:09 start sampling a new configuration.
10:49:09 done sampling a new configuration.
10:49:09 HBMASTER: schedule new run for iteration 0
10:49:09 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
10:49:09 HBMASTER: submitting job (0, 0, 18) to dispatcher
10:49:09 DISPATCHER: trying to submit job (0, 0, 18)
10:49:09 DISPATCHER: trying to notify the job_runner thread.
10:49:09 HBMASTER: job (0, 0, 18) submitted to dispatcher
10:49:09 DISPATCHER: Trying to submit another job.
10:49:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:49:09 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:49:09 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:49:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:49:09 WORKER: start processing job (0, 0, 18)
10:49:09 WORKER: args: ()
10:49:09 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0010385177040361136, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.010773734136992903, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 68, 'num_filters_3': 22, 'num_filters_4': 18, 'num_filters_5': 109}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:49:55 DISPATCHER: Starting worker discovery
10:49:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:49:55 DISPATCHER: Finished worker discovery
10:50:55 DISPATCHER: Starting worker discovery
10:50:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:50:55 DISPATCHER: Finished worker discovery
10:50:58 WORKER: done with job (0, 0, 18), trying to register it.
10:50:58 WORKER: registered result for job (0, 0, 18) with dispatcher
10:50:58 DISPATCHER: job (0, 0, 18) finished
10:50:58 DISPATCHER: register_result: lock acquired
10:50:58 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
10:50:58 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0010385177040361136, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.010773734136992903, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 68, 'num_filters_3': 22, 'num_filters_4': 18, 'num_filters_5': 109}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5144176846069495, 'info': {'sick_no_sick': 0.5144176846069495, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0010385177040361136, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.010773734136992903, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 68, 'num_filters_3': 22, 'num_filters_4': 18, 'num_filters_5': 109}"}}
exception: None

10:50:58 job_callback for (0, 0, 18) started
10:50:58 DISPATCHER: Trying to submit another job.
10:50:58 job_callback for (0, 0, 18) got condition
10:50:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:50:58 HBMASTER: Trying to run another job!
10:50:58 job_callback for (0, 0, 18) finished
10:50:58 start sampling a new configuration.
10:50:58 done sampling a new configuration.
10:50:58 HBMASTER: schedule new run for iteration 0
10:50:58 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
10:50:58 HBMASTER: submitting job (0, 0, 19) to dispatcher
10:50:58 DISPATCHER: trying to submit job (0, 0, 19)
10:50:58 DISPATCHER: trying to notify the job_runner thread.
10:50:58 HBMASTER: job (0, 0, 19) submitted to dispatcher
10:50:58 DISPATCHER: Trying to submit another job.
10:50:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:50:58 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:50:58 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:50:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:50:58 WORKER: start processing job (0, 0, 19)
10:50:58 WORKER: args: ()
10:50:58 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.026732082711441358, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.07780522635766922, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 60, 'num_filters_3': 17, 'num_filters_4': 126}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:51:55 DISPATCHER: Starting worker discovery
10:51:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:51:55 DISPATCHER: Finished worker discovery
10:52:45 WORKER: done with job (0, 0, 19), trying to register it.
10:52:45 WORKER: registered result for job (0, 0, 19) with dispatcher
10:52:45 DISPATCHER: job (0, 0, 19) finished
10:52:45 DISPATCHER: register_result: lock acquired
10:52:45 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
10:52:45 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.026732082711441358, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.07780522635766922, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 60, 'num_filters_3': 17, 'num_filters_4': 126}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.545612326668487, 'info': {'sick_no_sick': 0.545612326668487, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.026732082711441358, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.07780522635766922, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 60, 'num_filters_3': 17, 'num_filters_4': 126}"}}
exception: None

10:52:45 job_callback for (0, 0, 19) started
10:52:45 job_callback for (0, 0, 19) got condition
10:52:45 DISPATCHER: Trying to submit another job.
10:52:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:52:45 HBMASTER: Trying to run another job!
10:52:45 job_callback for (0, 0, 19) finished
10:52:45 start sampling a new configuration.
10:52:45 done sampling a new configuration.
10:52:45 HBMASTER: schedule new run for iteration 0
10:52:45 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
10:52:45 HBMASTER: submitting job (0, 0, 20) to dispatcher
10:52:45 DISPATCHER: trying to submit job (0, 0, 20)
10:52:45 DISPATCHER: trying to notify the job_runner thread.
10:52:45 HBMASTER: job (0, 0, 20) submitted to dispatcher
10:52:45 DISPATCHER: Trying to submit another job.
10:52:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:52:45 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:52:45 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:52:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:52:45 WORKER: start processing job (0, 0, 20)
10:52:45 WORKER: args: ()
10:52:45 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.011630597429970255, 'num_filters_1': 36, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.17841279782732397, 'kernel_size_2': 5, 'num_filters_2': 23}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:52:55 DISPATCHER: Starting worker discovery
10:52:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:52:55 DISPATCHER: Finished worker discovery
10:53:55 DISPATCHER: Starting worker discovery
10:53:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:53:55 DISPATCHER: Finished worker discovery
10:54:33 WORKER: done with job (0, 0, 20), trying to register it.
10:54:33 WORKER: registered result for job (0, 0, 20) with dispatcher
10:54:33 DISPATCHER: job (0, 0, 20) finished
10:54:33 DISPATCHER: register_result: lock acquired
10:54:33 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
10:54:33 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.011630597429970255, 'num_filters_1': 36, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.17841279782732397, 'kernel_size_2': 5, 'num_filters_2': 23}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.011630597429970255, 'num_filters_1': 36, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.17841279782732397, 'kernel_size_2': 5, 'num_filters_2': 23}"}}
exception: None

10:54:33 job_callback for (0, 0, 20) started
10:54:33 DISPATCHER: Trying to submit another job.
10:54:33 job_callback for (0, 0, 20) got condition
10:54:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:54:33 HBMASTER: Trying to run another job!
10:54:33 job_callback for (0, 0, 20) finished
10:54:33 start sampling a new configuration.
10:54:33 done sampling a new configuration.
10:54:33 HBMASTER: schedule new run for iteration 0
10:54:33 HBMASTER: trying submitting job (0, 0, 21) to dispatcher
10:54:33 HBMASTER: submitting job (0, 0, 21) to dispatcher
10:54:33 DISPATCHER: trying to submit job (0, 0, 21)
10:54:33 DISPATCHER: trying to notify the job_runner thread.
10:54:33 HBMASTER: job (0, 0, 21) submitted to dispatcher
10:54:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:54:33 DISPATCHER: Trying to submit another job.
10:54:33 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:54:33 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:54:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:54:33 WORKER: start processing job (0, 0, 21)
10:54:33 WORKER: args: ()
10:54:33 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.013402310531036674, 'num_filters_1': 28, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.030158187119483662, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 67, 'num_filters_3': 25}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:54:55 DISPATCHER: Starting worker discovery
10:54:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:54:55 DISPATCHER: Finished worker discovery
10:55:55 DISPATCHER: Starting worker discovery
10:55:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:55:55 DISPATCHER: Finished worker discovery
10:56:25 WORKER: done with job (0, 0, 21), trying to register it.
10:56:25 WORKER: registered result for job (0, 0, 21) with dispatcher
10:56:25 DISPATCHER: job (0, 0, 21) finished
10:56:25 DISPATCHER: register_result: lock acquired
10:56:25 DISPATCHER: job (0, 0, 21) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
10:56:25 job_id: (0, 0, 21)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.013402310531036674, 'num_filters_1': 28, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.030158187119483662, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 67, 'num_filters_3': 25}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4960918704731366, 'info': {'sick_no_sick': 0.4960918704731366, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.013402310531036674, 'num_filters_1': 28, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.030158187119483662, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 67, 'num_filters_3': 25}"}}
exception: None

10:56:25 job_callback for (0, 0, 21) started
10:56:25 job_callback for (0, 0, 21) got condition
10:56:25 DISPATCHER: Trying to submit another job.
10:56:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:56:25 HBMASTER: Trying to run another job!
10:56:25 job_callback for (0, 0, 21) finished
10:56:25 start sampling a new configuration.
10:56:25 done sampling a new configuration.
10:56:25 HBMASTER: schedule new run for iteration 0
10:56:25 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
10:56:25 HBMASTER: submitting job (0, 0, 22) to dispatcher
10:56:25 DISPATCHER: trying to submit job (0, 0, 22)
10:56:25 DISPATCHER: trying to notify the job_runner thread.
10:56:25 HBMASTER: job (0, 0, 22) submitted to dispatcher
10:56:25 DISPATCHER: Trying to submit another job.
10:56:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:56:25 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:56:25 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:56:25 WORKER: start processing job (0, 0, 22)
10:56:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:56:25 WORKER: args: ()
10:56:25 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.022836451961144286, 'num_filters_1': 27, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.017924645252850153, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 49, 'num_filters_3': 103, 'num_filters_4': 25, 'num_filters_5': 83}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:56:55 DISPATCHER: Starting worker discovery
10:56:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:56:55 DISPATCHER: Finished worker discovery
10:57:55 DISPATCHER: Starting worker discovery
10:57:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:57:55 DISPATCHER: Finished worker discovery
10:58:14 WORKER: done with job (0, 0, 22), trying to register it.
10:58:14 WORKER: registered result for job (0, 0, 22) with dispatcher
10:58:14 DISPATCHER: job (0, 0, 22) finished
10:58:14 DISPATCHER: register_result: lock acquired
10:58:14 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
10:58:14 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.022836451961144286, 'num_filters_1': 27, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.017924645252850153, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 49, 'num_filters_3': 103, 'num_filters_4': 25, 'num_filters_5': 83}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.41173783130466424, 'info': {'sick_no_sick': 0.41173783130466424, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.022836451961144286, 'num_filters_1': 27, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.017924645252850153, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 49, 'num_filters_3': 103, 'num_filters_4': 25, 'num_filters_5': 83}"}}
exception: None

10:58:14 job_callback for (0, 0, 22) started
10:58:14 job_callback for (0, 0, 22) got condition
10:58:14 DISPATCHER: Trying to submit another job.
10:58:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:58:14 HBMASTER: Trying to run another job!
10:58:14 job_callback for (0, 0, 22) finished
10:58:14 start sampling a new configuration.
10:58:14 done sampling a new configuration.
10:58:14 HBMASTER: schedule new run for iteration 0
10:58:14 HBMASTER: trying submitting job (0, 0, 23) to dispatcher
10:58:14 HBMASTER: submitting job (0, 0, 23) to dispatcher
10:58:14 DISPATCHER: trying to submit job (0, 0, 23)
10:58:14 DISPATCHER: trying to notify the job_runner thread.
10:58:14 HBMASTER: job (0, 0, 23) submitted to dispatcher
10:58:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:58:14 DISPATCHER: Trying to submit another job.
10:58:14 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:58:14 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:58:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:58:14 WORKER: start processing job (0, 0, 23)
10:58:14 WORKER: args: ()
10:58:14 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0011906307142297884, 'num_filters_1': 90, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.023434395614465624, 'kernel_size_2': 5, 'num_filters_2': 48}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:58:55 DISPATCHER: Starting worker discovery
10:58:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:58:55 DISPATCHER: Finished worker discovery
10:59:55 DISPATCHER: Starting worker discovery
10:59:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:59:55 DISPATCHER: Finished worker discovery
11:00:01 WORKER: done with job (0, 0, 23), trying to register it.
11:00:01 WORKER: registered result for job (0, 0, 23) with dispatcher
11:00:01 DISPATCHER: job (0, 0, 23) finished
11:00:01 DISPATCHER: register_result: lock acquired
11:00:01 DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
11:00:01 job_id: (0, 0, 23)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0011906307142297884, 'num_filters_1': 90, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.023434395614465624, 'kernel_size_2': 5, 'num_filters_2': 48}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5690937029072644, 'info': {'sick_no_sick': 0.5690937029072644, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0011906307142297884, 'num_filters_1': 90, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.023434395614465624, 'kernel_size_2': 5, 'num_filters_2': 48}"}}
exception: None

11:00:01 job_callback for (0, 0, 23) started
11:00:01 DISPATCHER: Trying to submit another job.
11:00:01 job_callback for (0, 0, 23) got condition
11:00:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:00:01 HBMASTER: Trying to run another job!
11:00:01 job_callback for (0, 0, 23) finished
11:00:01 start sampling a new configuration.
11:00:01 done sampling a new configuration.
11:00:01 HBMASTER: schedule new run for iteration 0
11:00:01 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
11:00:01 HBMASTER: submitting job (0, 0, 24) to dispatcher
11:00:01 DISPATCHER: trying to submit job (0, 0, 24)
11:00:01 DISPATCHER: trying to notify the job_runner thread.
11:00:01 HBMASTER: job (0, 0, 24) submitted to dispatcher
11:00:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:00:01 DISPATCHER: Trying to submit another job.
11:00:01 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpuj.30598140416580691776
11:00:01 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
11:00:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:00:01 WORKER: start processing job (0, 0, 24)
11:00:01 WORKER: args: ()
11:00:01 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.06324458038220092, 'num_filters_1': 87, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.08670689512232799, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 76, 'num_filters_3': 18, 'num_filters_4': 102}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:00:55 DISPATCHER: Starting worker discovery
11:00:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:00:55 DISPATCHER: Finished worker discovery
11:01:48 WORKER: done with job (0, 0, 24), trying to register it.
11:01:48 WORKER: registered result for job (0, 0, 24) with dispatcher
11:01:48 DISPATCHER: job (0, 0, 24) finished
11:01:48 DISPATCHER: register_result: lock acquired
11:01:48 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
11:01:48 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.06324458038220092, 'num_filters_1': 87, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.08670689512232799, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 76, 'num_filters_3': 18, 'num_filters_4': 102}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.06324458038220092, 'num_filters_1': 87, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.08670689512232799, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 76, 'num_filters_3': 18, 'num_filters_4': 102}"}}
exception: None

11:01:48 job_callback for (0, 0, 24) started
11:01:48 DISPATCHER: Trying to submit another job.
11:01:48 job_callback for (0, 0, 24) got condition
11:01:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:01:48 HBMASTER: Trying to run another job!
11:01:48 job_callback for (0, 0, 24) finished
11:01:48 start sampling a new configuration.
11:01:48 done sampling a new configuration.
11:01:48 HBMASTER: schedule new run for iteration 0
11:01:48 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
11:01:48 HBMASTER: submitting job (0, 0, 25) to dispatcher
11:01:48 DISPATCHER: trying to submit job (0, 0, 25)
11:01:48 DISPATCHER: trying to notify the job_runner thread.
11:01:48 HBMASTER: job (0, 0, 25) submitted to dispatcher
11:01:48 DISPATCHER: Trying to submit another job.
11:01:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:01:48 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpuj.30598140416580691776
11:01:48 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
11:01:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:01:48 WORKER: start processing job (0, 0, 25)
11:01:48 WORKER: args: ()
11:01:48 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.012538326431478355, 'num_filters_1': 30, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.016492055280133543, 'kernel_size_2': 7, 'num_filters_2': 58}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:01:55 DISPATCHER: Starting worker discovery
11:01:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:01:55 DISPATCHER: Finished worker discovery
11:02:55 DISPATCHER: Starting worker discovery
11:02:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:02:55 DISPATCHER: Finished worker discovery
11:03:34 WORKER: done with job (0, 0, 25), trying to register it.
11:03:34 WORKER: registered result for job (0, 0, 25) with dispatcher
11:03:34 DISPATCHER: job (0, 0, 25) finished
11:03:34 DISPATCHER: register_result: lock acquired
11:03:34 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
11:03:34 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.012538326431478355, 'num_filters_1': 30, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.016492055280133543, 'kernel_size_2': 7, 'num_filters_2': 58}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5782037650696662, 'info': {'sick_no_sick': 0.5782037650696662, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.012538326431478355, 'num_filters_1': 30, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.016492055280133543, 'kernel_size_2': 7, 'num_filters_2': 58}"}}
exception: None

11:03:34 job_callback for (0, 0, 25) started
11:03:34 job_callback for (0, 0, 25) got condition
11:03:34 DISPATCHER: Trying to submit another job.
11:03:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:03:34 HBMASTER: Trying to run another job!
11:03:34 job_callback for (0, 0, 25) finished
11:03:34 start sampling a new configuration.
11:03:34 done sampling a new configuration.
11:03:34 HBMASTER: schedule new run for iteration 0
11:03:34 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
11:03:34 HBMASTER: submitting job (0, 0, 26) to dispatcher
11:03:34 DISPATCHER: trying to submit job (0, 0, 26)
11:03:34 DISPATCHER: trying to notify the job_runner thread.
11:03:34 HBMASTER: job (0, 0, 26) submitted to dispatcher
11:03:34 DISPATCHER: Trying to submit another job.
11:03:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:03:34 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.30598140416580691776
11:03:34 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
11:03:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:03:34 WORKER: start processing job (0, 0, 26)
11:03:34 WORKER: args: ()
11:03:34 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0625735025088217, 'num_filters_1': 49, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.14392595271187728, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 25, 'num_filters_3': 76}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:03:55 DISPATCHER: Starting worker discovery
11:03:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:03:55 DISPATCHER: Finished worker discovery
11:04:55 DISPATCHER: Starting worker discovery
11:04:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:04:55 DISPATCHER: Finished worker discovery
11:05:20 WORKER: done with job (0, 0, 26), trying to register it.
11:05:20 WORKER: registered result for job (0, 0, 26) with dispatcher
11:05:20 DISPATCHER: job (0, 0, 26) finished
11:05:20 DISPATCHER: register_result: lock acquired
11:05:20 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
11:05:20 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0625735025088217, 'num_filters_1': 49, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.14392595271187728, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 25, 'num_filters_3': 76}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.00024128753980848415, 'info': {'sick_no_sick': -0.00024128753980848415, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0625735025088217, 'num_filters_1': 49, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.14392595271187728, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 25, 'num_filters_3': 76}"}}
exception: None

11:05:20 job_callback for (0, 0, 26) started
11:05:20 DISPATCHER: Trying to submit another job.
11:05:20 job_callback for (0, 0, 26) got condition
11:05:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:05:20 HBMASTER: Trying to run another job!
11:05:20 job_callback for (0, 0, 26) finished
11:05:20 ITERATION: Advancing config (0, 0, 2) to next budget 133.333333
11:05:20 ITERATION: Advancing config (0, 0, 3) to next budget 133.333333
11:05:20 ITERATION: Advancing config (0, 0, 5) to next budget 133.333333
11:05:20 ITERATION: Advancing config (0, 0, 6) to next budget 133.333333
11:05:20 ITERATION: Advancing config (0, 0, 9) to next budget 133.333333
11:05:20 ITERATION: Advancing config (0, 0, 16) to next budget 133.333333
11:05:20 ITERATION: Advancing config (0, 0, 19) to next budget 133.333333
11:05:20 ITERATION: Advancing config (0, 0, 23) to next budget 133.333333
11:05:20 ITERATION: Advancing config (0, 0, 25) to next budget 133.333333
11:05:20 HBMASTER: schedule new run for iteration 0
11:05:20 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
11:05:20 HBMASTER: submitting job (0, 0, 2) to dispatcher
11:05:20 DISPATCHER: trying to submit job (0, 0, 2)
11:05:20 DISPATCHER: trying to notify the job_runner thread.
11:05:20 HBMASTER: job (0, 0, 2) submitted to dispatcher
11:05:20 DISPATCHER: Trying to submit another job.
11:05:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:05:20 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
11:05:20 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
11:05:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:05:20 WORKER: start processing job (0, 0, 2)
11:05:20 WORKER: args: ()
11:05:20 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0017555389283153858, 'num_filters_1': 71, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.013059260893662524, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 84, 'num_filters_3': 46, 'num_filters_4': 28, 'num_filters_5': 42}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:05:55 DISPATCHER: Starting worker discovery
11:05:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:05:55 DISPATCHER: Finished worker discovery
11:06:55 DISPATCHER: Starting worker discovery
11:06:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:06:55 DISPATCHER: Finished worker discovery
11:07:55 DISPATCHER: Starting worker discovery
11:07:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:07:55 DISPATCHER: Finished worker discovery
11:08:35 WORKER: done with job (0, 0, 2), trying to register it.
11:08:35 WORKER: registered result for job (0, 0, 2) with dispatcher
11:08:35 DISPATCHER: job (0, 0, 2) finished
11:08:35 DISPATCHER: register_result: lock acquired
11:08:35 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
11:08:35 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0017555389283153858, 'num_filters_1': 71, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.013059260893662524, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 84, 'num_filters_3': 46, 'num_filters_4': 28, 'num_filters_5': 42}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6451182081317101, 'info': {'sick_no_sick': 0.6451182081317101, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0017555389283153858, 'num_filters_1': 71, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.013059260893662524, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 84, 'num_filters_3': 46, 'num_filters_4': 28, 'num_filters_5': 42}"}}
exception: None

11:08:35 job_callback for (0, 0, 2) started
11:08:35 DISPATCHER: Trying to submit another job.
11:08:35 job_callback for (0, 0, 2) got condition
11:08:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:08:35 Only 1 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
11:08:35 HBMASTER: Trying to run another job!
11:08:35 job_callback for (0, 0, 2) finished
11:08:35 HBMASTER: schedule new run for iteration 0
11:08:35 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
11:08:35 HBMASTER: submitting job (0, 0, 3) to dispatcher
11:08:35 DISPATCHER: trying to submit job (0, 0, 3)
11:08:35 DISPATCHER: trying to notify the job_runner thread.
11:08:35 HBMASTER: job (0, 0, 3) submitted to dispatcher
11:08:35 DISPATCHER: Trying to submit another job.
11:08:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:08:35 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
11:08:35 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
11:08:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:08:35 WORKER: start processing job (0, 0, 3)
11:08:35 WORKER: args: ()
11:08:35 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.022747550561226296, 'num_filters_1': 128, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.02109234621950553, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 60, 'num_filters_3': 74}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:08:55 DISPATCHER: Starting worker discovery
11:08:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:08:55 DISPATCHER: Finished worker discovery
11:09:55 DISPATCHER: Starting worker discovery
11:09:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:09:55 DISPATCHER: Finished worker discovery
11:10:55 DISPATCHER: Starting worker discovery
11:10:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:10:55 DISPATCHER: Finished worker discovery
11:11:55 DISPATCHER: Starting worker discovery
11:11:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:11:55 DISPATCHER: Finished worker discovery
11:12:05 WORKER: done with job (0, 0, 3), trying to register it.
11:12:05 WORKER: registered result for job (0, 0, 3) with dispatcher
11:12:05 DISPATCHER: job (0, 0, 3) finished
11:12:05 DISPATCHER: register_result: lock acquired
11:12:05 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
11:12:05 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.022747550561226296, 'num_filters_1': 128, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.02109234621950553, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 60, 'num_filters_3': 74}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5110603248905925, 'info': {'sick_no_sick': 0.5110603248905925, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.022747550561226296, 'num_filters_1': 128, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.02109234621950553, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 60, 'num_filters_3': 74}"}}
exception: None

11:12:05 job_callback for (0, 0, 3) started
11:12:05 DISPATCHER: Trying to submit another job.
11:12:05 job_callback for (0, 0, 3) got condition
11:12:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:12:05 Only 2 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
11:12:05 HBMASTER: Trying to run another job!
11:12:05 job_callback for (0, 0, 3) finished
11:12:05 HBMASTER: schedule new run for iteration 0
11:12:05 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
11:12:05 HBMASTER: submitting job (0, 0, 5) to dispatcher
11:12:05 DISPATCHER: trying to submit job (0, 0, 5)
11:12:05 DISPATCHER: trying to notify the job_runner thread.
11:12:05 HBMASTER: job (0, 0, 5) submitted to dispatcher
11:12:05 DISPATCHER: Trying to submit another job.
11:12:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:12:05 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776
11:12:05 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
11:12:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:12:05 WORKER: start processing job (0, 0, 5)
11:12:05 WORKER: args: ()
11:12:05 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0024310514106905944, 'num_filters_1': 92, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.033379675856655765, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 54, 'num_filters_3': 93, 'num_filters_4': 58}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:12:55 DISPATCHER: Starting worker discovery
11:12:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:12:55 DISPATCHER: Finished worker discovery
11:13:55 DISPATCHER: Starting worker discovery
11:13:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:13:55 DISPATCHER: Finished worker discovery
11:14:55 DISPATCHER: Starting worker discovery
11:14:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:14:55 DISPATCHER: Finished worker discovery
11:15:22 WORKER: done with job (0, 0, 5), trying to register it.
11:15:22 WORKER: registered result for job (0, 0, 5) with dispatcher
11:15:22 DISPATCHER: job (0, 0, 5) finished
11:15:22 DISPATCHER: register_result: lock acquired
11:15:22 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
11:15:22 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0024310514106905944, 'num_filters_1': 92, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.033379675856655765, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 54, 'num_filters_3': 93, 'num_filters_4': 58}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5477174245456451, 'info': {'sick_no_sick': 0.5477174245456451, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0024310514106905944, 'num_filters_1': 92, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.033379675856655765, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 54, 'num_filters_3': 93, 'num_filters_4': 58}"}}
exception: None

11:15:22 job_callback for (0, 0, 5) started
11:15:22 job_callback for (0, 0, 5) got condition
11:15:22 DISPATCHER: Trying to submit another job.
11:15:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:15:22 Only 3 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
11:15:22 HBMASTER: Trying to run another job!
11:15:22 job_callback for (0, 0, 5) finished
11:15:22 HBMASTER: schedule new run for iteration 0
11:15:22 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
11:15:22 HBMASTER: submitting job (0, 0, 6) to dispatcher
11:15:22 DISPATCHER: trying to submit job (0, 0, 6)
11:15:22 DISPATCHER: trying to notify the job_runner thread.
11:15:22 HBMASTER: job (0, 0, 6) submitted to dispatcher
11:15:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:15:22 DISPATCHER: Trying to submit another job.
11:15:22 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776
11:15:22 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
11:15:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:15:22 WORKER: start processing job (0, 0, 6)
11:15:22 WORKER: args: ()
11:15:22 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.008516813676211642, 'num_filters_1': 90, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.01646333750101569, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 52, 'num_filters_3': 33, 'num_filters_4': 122, 'num_filters_5': 46}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:15:55 DISPATCHER: Starting worker discovery
11:15:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:15:55 DISPATCHER: Finished worker discovery
11:16:55 DISPATCHER: Starting worker discovery
11:16:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:16:55 DISPATCHER: Finished worker discovery
11:17:55 DISPATCHER: Starting worker discovery
11:17:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:17:55 DISPATCHER: Finished worker discovery
11:18:39 WORKER: done with job (0, 0, 6), trying to register it.
11:18:39 WORKER: registered result for job (0, 0, 6) with dispatcher
11:18:39 DISPATCHER: job (0, 0, 6) finished
11:18:39 DISPATCHER: register_result: lock acquired
11:18:39 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
11:18:39 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.008516813676211642, 'num_filters_1': 90, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.01646333750101569, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 52, 'num_filters_3': 33, 'num_filters_4': 122, 'num_filters_5': 46}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6418819818478164, 'info': {'sick_no_sick': 0.6418819818478164, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.008516813676211642, 'num_filters_1': 90, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.01646333750101569, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 52, 'num_filters_3': 33, 'num_filters_4': 122, 'num_filters_5': 46}"}}
exception: None

11:18:39 job_callback for (0, 0, 6) started
11:18:39 DISPATCHER: Trying to submit another job.
11:18:39 job_callback for (0, 0, 6) got condition
11:18:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:18:39 Only 4 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
11:18:39 HBMASTER: Trying to run another job!
11:18:39 job_callback for (0, 0, 6) finished
11:18:39 HBMASTER: schedule new run for iteration 0
11:18:39 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
11:18:39 HBMASTER: submitting job (0, 0, 9) to dispatcher
11:18:39 DISPATCHER: trying to submit job (0, 0, 9)
11:18:39 DISPATCHER: trying to notify the job_runner thread.
11:18:39 HBMASTER: job (0, 0, 9) submitted to dispatcher
11:18:39 DISPATCHER: Trying to submit another job.
11:18:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:18:39 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.30598140416580691776
11:18:39 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
11:18:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:18:39 WORKER: start processing job (0, 0, 9)
11:18:39 WORKER: args: ()
11:18:39 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0036976219184446627, 'num_filters_1': 22, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.017181694650003097, 'kernel_size_2': 5, 'num_filters_2': 24}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:18:55 DISPATCHER: Starting worker discovery
11:18:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:18:55 DISPATCHER: Finished worker discovery
11:19:55 DISPATCHER: Starting worker discovery
11:19:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:19:55 DISPATCHER: Finished worker discovery
11:20:55 DISPATCHER: Starting worker discovery
11:20:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:20:55 DISPATCHER: Finished worker discovery
11:21:55 DISPATCHER: Starting worker discovery
11:21:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:21:56 DISPATCHER: Finished worker discovery
11:22:00 WORKER: done with job (0, 0, 9), trying to register it.
11:22:00 WORKER: registered result for job (0, 0, 9) with dispatcher
11:22:00 DISPATCHER: job (0, 0, 9) finished
11:22:00 DISPATCHER: register_result: lock acquired
11:22:00 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
11:22:00 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0036976219184446627, 'num_filters_1': 22, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.017181694650003097, 'kernel_size_2': 5, 'num_filters_2': 24}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4825030650980843, 'info': {'sick_no_sick': 0.4825030650980843, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0036976219184446627, 'num_filters_1': 22, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.017181694650003097, 'kernel_size_2': 5, 'num_filters_2': 24}"}}
exception: None

11:22:00 job_callback for (0, 0, 9) started
11:22:00 DISPATCHER: Trying to submit another job.
11:22:00 job_callback for (0, 0, 9) got condition
11:22:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:22:00 Only 5 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
11:22:00 HBMASTER: Trying to run another job!
11:22:00 job_callback for (0, 0, 9) finished
11:22:00 HBMASTER: schedule new run for iteration 0
11:22:00 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
11:22:00 HBMASTER: submitting job (0, 0, 16) to dispatcher
11:22:00 DISPATCHER: trying to submit job (0, 0, 16)
11:22:00 DISPATCHER: trying to notify the job_runner thread.
11:22:00 HBMASTER: job (0, 0, 16) submitted to dispatcher
11:22:00 DISPATCHER: Trying to submit another job.
11:22:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:22:00 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.30598140416580691776
11:22:00 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
11:22:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:22:00 WORKER: start processing job (0, 0, 16)
11:22:00 WORKER: args: ()
11:22:00 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.026729064690250628, 'num_filters_1': 46, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.013106063241684875, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 31, 'num_filters_3': 95, 'num_filters_4': 22}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:22:56 DISPATCHER: Starting worker discovery
11:22:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:22:56 DISPATCHER: Finished worker discovery
11:23:56 DISPATCHER: Starting worker discovery
11:23:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:23:56 DISPATCHER: Finished worker discovery
11:24:56 DISPATCHER: Starting worker discovery
11:24:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:24:56 DISPATCHER: Finished worker discovery
11:25:19 WORKER: done with job (0, 0, 16), trying to register it.
11:25:19 WORKER: registered result for job (0, 0, 16) with dispatcher
11:25:19 DISPATCHER: job (0, 0, 16) finished
11:25:19 DISPATCHER: register_result: lock acquired
11:25:19 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
11:25:19 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.026729064690250628, 'num_filters_1': 46, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.013106063241684875, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 31, 'num_filters_3': 95, 'num_filters_4': 22}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5961637282268581, 'info': {'sick_no_sick': 0.5961637282268581, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.026729064690250628, 'num_filters_1': 46, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.013106063241684875, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 31, 'num_filters_3': 95, 'num_filters_4': 22}"}}
exception: None

11:25:19 job_callback for (0, 0, 16) started
11:25:19 job_callback for (0, 0, 16) got condition
11:25:19 DISPATCHER: Trying to submit another job.
11:25:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:25:19 Only 6 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
11:25:19 HBMASTER: Trying to run another job!
11:25:19 job_callback for (0, 0, 16) finished
11:25:19 HBMASTER: schedule new run for iteration 0
11:25:19 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
11:25:19 HBMASTER: submitting job (0, 0, 19) to dispatcher
11:25:19 DISPATCHER: trying to submit job (0, 0, 19)
11:25:19 DISPATCHER: trying to notify the job_runner thread.
11:25:19 HBMASTER: job (0, 0, 19) submitted to dispatcher
11:25:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:25:19 DISPATCHER: Trying to submit another job.
11:25:19 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.30598140416580691776
11:25:19 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
11:25:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:25:19 WORKER: start processing job (0, 0, 19)
11:25:19 WORKER: args: ()
11:25:19 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.026732082711441358, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.07780522635766922, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 60, 'num_filters_3': 17, 'num_filters_4': 126}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:25:56 DISPATCHER: Starting worker discovery
11:25:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:25:56 DISPATCHER: Finished worker discovery
11:26:56 DISPATCHER: Starting worker discovery
11:26:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:26:56 DISPATCHER: Finished worker discovery
11:27:56 DISPATCHER: Starting worker discovery
11:27:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:27:56 DISPATCHER: Finished worker discovery
11:28:38 WORKER: done with job (0, 0, 19), trying to register it.
11:28:38 WORKER: registered result for job (0, 0, 19) with dispatcher
11:28:38 DISPATCHER: job (0, 0, 19) finished
11:28:38 DISPATCHER: register_result: lock acquired
11:28:38 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
11:28:38 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.026732082711441358, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.07780522635766922, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 60, 'num_filters_3': 17, 'num_filters_4': 126}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5105177309513856, 'info': {'sick_no_sick': 0.5105177309513856, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.026732082711441358, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.07780522635766922, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 60, 'num_filters_3': 17, 'num_filters_4': 126}"}}
exception: None

11:28:38 job_callback for (0, 0, 19) started
11:28:38 DISPATCHER: Trying to submit another job.
11:28:38 job_callback for (0, 0, 19) got condition
11:28:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:28:38 Only 7 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
11:28:38 HBMASTER: Trying to run another job!
11:28:38 job_callback for (0, 0, 19) finished
11:28:38 HBMASTER: schedule new run for iteration 0
11:28:38 HBMASTER: trying submitting job (0, 0, 23) to dispatcher
11:28:38 HBMASTER: submitting job (0, 0, 23) to dispatcher
11:28:38 DISPATCHER: trying to submit job (0, 0, 23)
11:28:38 DISPATCHER: trying to notify the job_runner thread.
11:28:38 HBMASTER: job (0, 0, 23) submitted to dispatcher
11:28:38 DISPATCHER: Trying to submit another job.
11:28:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:28:38 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.30598140416580691776
11:28:38 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
11:28:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:28:38 WORKER: start processing job (0, 0, 23)
11:28:38 WORKER: args: ()
11:28:38 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0011906307142297884, 'num_filters_1': 90, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.023434395614465624, 'kernel_size_2': 5, 'num_filters_2': 48}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:28:56 DISPATCHER: Starting worker discovery
11:28:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:28:56 DISPATCHER: Finished worker discovery
11:29:56 DISPATCHER: Starting worker discovery
11:29:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:29:56 DISPATCHER: Finished worker discovery
11:30:56 DISPATCHER: Starting worker discovery
11:30:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:30:56 DISPATCHER: Finished worker discovery
11:31:54 WORKER: done with job (0, 0, 23), trying to register it.
11:31:54 WORKER: registered result for job (0, 0, 23) with dispatcher
11:31:54 DISPATCHER: job (0, 0, 23) finished
11:31:54 DISPATCHER: register_result: lock acquired
11:31:54 DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
11:31:54 job_id: (0, 0, 23)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0011906307142297884, 'num_filters_1': 90, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.023434395614465624, 'kernel_size_2': 5, 'num_filters_2': 48}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5872076484562518, 'info': {'sick_no_sick': 0.5872076484562518, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0011906307142297884, 'num_filters_1': 90, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.023434395614465624, 'kernel_size_2': 5, 'num_filters_2': 48}"}}
exception: None

11:31:54 job_callback for (0, 0, 23) started
11:31:54 job_callback for (0, 0, 23) got condition
11:31:54 DISPATCHER: Trying to submit another job.
11:31:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:31:54 Only 8 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
11:31:54 HBMASTER: Trying to run another job!
11:31:54 job_callback for (0, 0, 23) finished
11:31:54 HBMASTER: schedule new run for iteration 0
11:31:54 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
11:31:54 HBMASTER: submitting job (0, 0, 25) to dispatcher
11:31:54 DISPATCHER: trying to submit job (0, 0, 25)
11:31:54 DISPATCHER: trying to notify the job_runner thread.
11:31:54 HBMASTER: job (0, 0, 25) submitted to dispatcher
11:31:54 DISPATCHER: Trying to submit another job.
11:31:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:31:54 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpuj.30598140416580691776
11:31:54 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
11:31:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:31:54 WORKER: start processing job (0, 0, 25)
11:31:54 WORKER: args: ()
11:31:54 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.012538326431478355, 'num_filters_1': 30, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.016492055280133543, 'kernel_size_2': 7, 'num_filters_2': 58}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:31:56 DISPATCHER: Starting worker discovery
11:31:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:31:56 DISPATCHER: Finished worker discovery
11:32:56 DISPATCHER: Starting worker discovery
11:32:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:32:56 DISPATCHER: Finished worker discovery
11:33:56 DISPATCHER: Starting worker discovery
11:33:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:33:56 DISPATCHER: Finished worker discovery
11:34:56 DISPATCHER: Starting worker discovery
11:34:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:34:56 DISPATCHER: Finished worker discovery
11:35:13 WORKER: done with job (0, 0, 25), trying to register it.
11:35:13 WORKER: registered result for job (0, 0, 25) with dispatcher
11:35:13 DISPATCHER: job (0, 0, 25) finished
11:35:13 DISPATCHER: register_result: lock acquired
11:35:13 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
11:35:13 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.012538326431478355, 'num_filters_1': 30, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.016492055280133543, 'kernel_size_2': 7, 'num_filters_2': 58}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5695610271500955, 'info': {'sick_no_sick': 0.5695610271500955, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.012538326431478355, 'num_filters_1': 30, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.016492055280133543, 'kernel_size_2': 7, 'num_filters_2': 58}"}}
exception: None

11:35:13 job_callback for (0, 0, 25) started
11:35:13 DISPATCHER: Trying to submit another job.
11:35:13 job_callback for (0, 0, 25) got condition
11:35:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:35:13 Only 9 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
11:35:13 HBMASTER: Trying to run another job!
11:35:13 job_callback for (0, 0, 25) finished
11:35:13 ITERATION: Advancing config (0, 0, 2) to next budget 400.000000
11:35:13 ITERATION: Advancing config (0, 0, 6) to next budget 400.000000
11:35:13 ITERATION: Advancing config (0, 0, 16) to next budget 400.000000
11:35:13 HBMASTER: schedule new run for iteration 0
11:35:13 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
11:35:13 HBMASTER: submitting job (0, 0, 2) to dispatcher
11:35:13 DISPATCHER: trying to submit job (0, 0, 2)
11:35:13 DISPATCHER: trying to notify the job_runner thread.
11:35:13 HBMASTER: job (0, 0, 2) submitted to dispatcher
11:35:13 DISPATCHER: Trying to submit another job.
11:35:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:35:13 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
11:35:13 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
11:35:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:35:13 WORKER: start processing job (0, 0, 2)
11:35:13 WORKER: args: ()
11:35:13 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0017555389283153858, 'num_filters_1': 71, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.013059260893662524, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 84, 'num_filters_3': 46, 'num_filters_4': 28, 'num_filters_5': 42}, 'budget': 400.0, 'working_directory': '.'}
11:35:56 DISPATCHER: Starting worker discovery
11:35:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:35:56 DISPATCHER: Finished worker discovery
11:36:56 DISPATCHER: Starting worker discovery
11:36:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:36:56 DISPATCHER: Finished worker discovery
11:37:56 DISPATCHER: Starting worker discovery
11:37:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:37:56 DISPATCHER: Finished worker discovery
11:38:56 DISPATCHER: Starting worker discovery
11:38:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:38:56 DISPATCHER: Finished worker discovery
11:39:56 DISPATCHER: Starting worker discovery
11:39:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:39:56 DISPATCHER: Finished worker discovery
11:40:56 DISPATCHER: Starting worker discovery
11:40:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:40:56 DISPATCHER: Finished worker discovery
11:41:56 DISPATCHER: Starting worker discovery
11:41:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:41:56 DISPATCHER: Finished worker discovery
11:42:56 DISPATCHER: Starting worker discovery
11:42:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:42:56 DISPATCHER: Finished worker discovery
11:43:00 WORKER: done with job (0, 0, 2), trying to register it.
11:43:00 WORKER: registered result for job (0, 0, 2) with dispatcher
11:43:00 DISPATCHER: job (0, 0, 2) finished
11:43:00 DISPATCHER: register_result: lock acquired
11:43:00 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
11:43:00 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0017555389283153858, 'num_filters_1': 71, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.013059260893662524, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 84, 'num_filters_3': 46, 'num_filters_4': 28, 'num_filters_5': 42}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6365215729536119, 'info': {'sick_no_sick': 0.6365215729536119, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0017555389283153858, 'num_filters_1': 71, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.013059260893662524, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 84, 'num_filters_3': 46, 'num_filters_4': 28, 'num_filters_5': 42}"}}
exception: None

11:43:00 job_callback for (0, 0, 2) started
11:43:00 DISPATCHER: Trying to submit another job.
11:43:00 job_callback for (0, 0, 2) got condition
11:43:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:43:00 Only 1 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
11:43:00 HBMASTER: Trying to run another job!
11:43:00 job_callback for (0, 0, 2) finished
11:43:00 HBMASTER: schedule new run for iteration 0
11:43:00 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
11:43:00 HBMASTER: submitting job (0, 0, 6) to dispatcher
11:43:00 DISPATCHER: trying to submit job (0, 0, 6)
11:43:00 DISPATCHER: trying to notify the job_runner thread.
11:43:00 HBMASTER: job (0, 0, 6) submitted to dispatcher
11:43:00 DISPATCHER: Trying to submit another job.
11:43:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:43:00 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776
11:43:00 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
11:43:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:43:00 WORKER: start processing job (0, 0, 6)
11:43:00 WORKER: args: ()
11:43:00 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.008516813676211642, 'num_filters_1': 90, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.01646333750101569, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 52, 'num_filters_3': 33, 'num_filters_4': 122, 'num_filters_5': 46}, 'budget': 400.0, 'working_directory': '.'}
11:43:56 DISPATCHER: Starting worker discovery
11:43:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:43:56 DISPATCHER: Finished worker discovery
11:44:56 DISPATCHER: Starting worker discovery
11:44:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:44:56 DISPATCHER: Finished worker discovery
11:45:56 DISPATCHER: Starting worker discovery
11:45:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:45:56 DISPATCHER: Finished worker discovery
11:46:56 DISPATCHER: Starting worker discovery
11:46:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:46:56 DISPATCHER: Finished worker discovery
11:47:56 DISPATCHER: Starting worker discovery
11:47:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:47:56 DISPATCHER: Finished worker discovery
11:48:56 DISPATCHER: Starting worker discovery
11:48:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:48:56 DISPATCHER: Finished worker discovery
11:49:56 DISPATCHER: Starting worker discovery
11:49:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:49:56 DISPATCHER: Finished worker discovery
11:50:49 WORKER: done with job (0, 0, 6), trying to register it.
11:50:49 WORKER: registered result for job (0, 0, 6) with dispatcher
11:50:49 DISPATCHER: job (0, 0, 6) finished
11:50:49 DISPATCHER: register_result: lock acquired
11:50:49 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
11:50:49 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.008516813676211642, 'num_filters_1': 90, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.01646333750101569, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 52, 'num_filters_3': 33, 'num_filters_4': 122, 'num_filters_5': 46}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5936617180017595, 'info': {'sick_no_sick': 0.5936617180017595, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.008516813676211642, 'num_filters_1': 90, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.01646333750101569, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 52, 'num_filters_3': 33, 'num_filters_4': 122, 'num_filters_5': 46}"}}
exception: None

11:50:49 job_callback for (0, 0, 6) started
11:50:49 DISPATCHER: Trying to submit another job.
11:50:49 job_callback for (0, 0, 6) got condition
11:50:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:50:49 Only 2 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
11:50:49 HBMASTER: Trying to run another job!
11:50:49 job_callback for (0, 0, 6) finished
11:50:49 HBMASTER: schedule new run for iteration 0
11:50:49 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
11:50:49 HBMASTER: submitting job (0, 0, 16) to dispatcher
11:50:49 DISPATCHER: trying to submit job (0, 0, 16)
11:50:49 DISPATCHER: trying to notify the job_runner thread.
11:50:49 HBMASTER: job (0, 0, 16) submitted to dispatcher
11:50:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:50:49 DISPATCHER: Trying to submit another job.
11:50:49 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.30598140416580691776
11:50:49 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
11:50:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:50:49 WORKER: start processing job (0, 0, 16)
11:50:49 WORKER: args: ()
11:50:49 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.026729064690250628, 'num_filters_1': 46, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.013106063241684875, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 31, 'num_filters_3': 95, 'num_filters_4': 22}, 'budget': 400.0, 'working_directory': '.'}
11:50:56 DISPATCHER: Starting worker discovery
11:50:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:50:56 DISPATCHER: Finished worker discovery
11:51:56 DISPATCHER: Starting worker discovery
11:51:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:51:56 DISPATCHER: Finished worker discovery
11:52:56 DISPATCHER: Starting worker discovery
11:52:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:52:56 DISPATCHER: Finished worker discovery
11:53:56 DISPATCHER: Starting worker discovery
11:53:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:53:56 DISPATCHER: Finished worker discovery
11:54:56 DISPATCHER: Starting worker discovery
11:54:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:54:56 DISPATCHER: Finished worker discovery
11:55:56 DISPATCHER: Starting worker discovery
11:55:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:55:56 DISPATCHER: Finished worker discovery
11:56:56 DISPATCHER: Starting worker discovery
11:56:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:56:56 DISPATCHER: Finished worker discovery
11:57:56 DISPATCHER: Starting worker discovery
11:57:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:57:56 DISPATCHER: Finished worker discovery
11:58:45 WORKER: done with job (0, 0, 16), trying to register it.
11:58:45 WORKER: registered result for job (0, 0, 16) with dispatcher
11:58:45 DISPATCHER: job (0, 0, 16) finished
11:58:45 DISPATCHER: register_result: lock acquired
11:58:45 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
11:58:45 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.026729064690250628, 'num_filters_1': 46, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.013106063241684875, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 31, 'num_filters_3': 95, 'num_filters_4': 22}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6083044061329914, 'info': {'sick_no_sick': 0.6083044061329914, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.026729064690250628, 'num_filters_1': 46, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.013106063241684875, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 31, 'num_filters_3': 95, 'num_filters_4': 22}"}}
exception: None

11:58:45 job_callback for (0, 0, 16) started
11:58:45 job_callback for (0, 0, 16) got condition
11:58:45 DISPATCHER: Trying to submit another job.
11:58:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:58:45 Only 3 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
11:58:45 HBMASTER: Trying to run another job!
11:58:45 job_callback for (0, 0, 16) finished
11:58:45 ITERATION: Advancing config (0, 0, 2) to next budget 1200.000000
11:58:45 HBMASTER: schedule new run for iteration 0
11:58:45 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
11:58:45 HBMASTER: submitting job (0, 0, 2) to dispatcher
11:58:45 DISPATCHER: trying to submit job (0, 0, 2)
11:58:45 DISPATCHER: trying to notify the job_runner thread.
11:58:45 HBMASTER: job (0, 0, 2) submitted to dispatcher
11:58:45 DISPATCHER: Trying to submit another job.
11:58:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:58:45 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
11:58:45 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
11:58:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:58:45 WORKER: start processing job (0, 0, 2)
11:58:45 WORKER: args: ()
11:58:45 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0017555389283153858, 'num_filters_1': 71, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.013059260893662524, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 84, 'num_filters_3': 46, 'num_filters_4': 28, 'num_filters_5': 42}, 'budget': 1200.0, 'working_directory': '.'}
11:58:56 DISPATCHER: Starting worker discovery
11:58:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:58:56 DISPATCHER: Finished worker discovery
11:59:56 DISPATCHER: Starting worker discovery
11:59:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:59:56 DISPATCHER: Finished worker discovery
12:00:56 DISPATCHER: Starting worker discovery
12:00:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:00:56 DISPATCHER: Finished worker discovery
12:01:56 DISPATCHER: Starting worker discovery
12:01:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:01:56 DISPATCHER: Finished worker discovery
12:02:56 DISPATCHER: Starting worker discovery
12:02:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:02:56 DISPATCHER: Finished worker discovery
12:03:56 DISPATCHER: Starting worker discovery
12:03:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:03:56 DISPATCHER: Finished worker discovery
12:04:56 DISPATCHER: Starting worker discovery
12:04:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:04:56 DISPATCHER: Finished worker discovery
12:05:56 DISPATCHER: Starting worker discovery
12:05:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:05:56 DISPATCHER: Finished worker discovery
12:06:56 DISPATCHER: Starting worker discovery
12:06:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:06:56 DISPATCHER: Finished worker discovery
12:07:56 DISPATCHER: Starting worker discovery
12:07:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:07:56 DISPATCHER: Finished worker discovery
12:08:56 DISPATCHER: Starting worker discovery
12:08:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:08:56 DISPATCHER: Finished worker discovery
12:09:56 DISPATCHER: Starting worker discovery
12:09:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:09:56 DISPATCHER: Finished worker discovery
12:10:56 DISPATCHER: Starting worker discovery
12:10:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:10:56 DISPATCHER: Finished worker discovery
12:11:56 DISPATCHER: Starting worker discovery
12:11:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:11:56 DISPATCHER: Finished worker discovery
12:12:56 DISPATCHER: Starting worker discovery
12:12:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:12:56 DISPATCHER: Finished worker discovery
12:13:56 DISPATCHER: Starting worker discovery
12:13:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:13:56 DISPATCHER: Finished worker discovery
12:14:56 DISPATCHER: Starting worker discovery
12:14:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:14:56 DISPATCHER: Finished worker discovery
12:15:56 DISPATCHER: Starting worker discovery
12:15:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:15:56 DISPATCHER: Finished worker discovery
12:16:56 DISPATCHER: Starting worker discovery
12:16:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:16:56 DISPATCHER: Finished worker discovery
12:17:56 DISPATCHER: Starting worker discovery
12:17:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:17:56 DISPATCHER: Finished worker discovery
12:18:56 DISPATCHER: Starting worker discovery
12:18:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:18:56 DISPATCHER: Finished worker discovery
12:19:56 DISPATCHER: Starting worker discovery
12:19:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:19:56 DISPATCHER: Finished worker discovery
12:20:00 WORKER: done with job (0, 0, 2), trying to register it.
12:20:00 WORKER: registered result for job (0, 0, 2) with dispatcher
12:20:00 DISPATCHER: job (0, 0, 2) finished
12:20:00 DISPATCHER: register_result: lock acquired
12:20:00 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
12:20:00 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0017555389283153858, 'num_filters_1': 71, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.013059260893662524, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 84, 'num_filters_3': 46, 'num_filters_4': 28, 'num_filters_5': 42}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5989775945246402, 'info': {'sick_no_sick': 0.5989775945246402, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0017555389283153858, 'num_filters_1': 71, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.013059260893662524, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 84, 'num_filters_3': 46, 'num_filters_4': 28, 'num_filters_5': 42}"}}
exception: None

12:20:00 job_callback for (0, 0, 2) started
12:20:00 job_callback for (0, 0, 2) got condition
12:20:00 DISPATCHER: Trying to submit another job.
12:20:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:20:00 Only 1 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
12:20:00 HBMASTER: Trying to run another job!
12:20:00 job_callback for (0, 0, 2) finished
12:20:00 start sampling a new configuration.
12:20:00 done sampling a new configuration.
12:20:00 HBMASTER: schedule new run for iteration 1
12:20:00 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
12:20:00 HBMASTER: submitting job (1, 0, 0) to dispatcher
12:20:00 DISPATCHER: trying to submit job (1, 0, 0)
12:20:00 DISPATCHER: trying to notify the job_runner thread.
12:20:00 HBMASTER: job (1, 0, 0) submitted to dispatcher
12:20:00 DISPATCHER: Trying to submit another job.
12:20:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:20:00 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
12:20:00 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
12:20:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:20:00 WORKER: start processing job (1, 0, 0)
12:20:00 WORKER: args: ()
12:20:00 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.011583563032750913, 'num_filters_1': 124, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.013022856895546567}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:20:56 DISPATCHER: Starting worker discovery
12:20:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:20:56 DISPATCHER: Finished worker discovery
12:21:56 DISPATCHER: Starting worker discovery
12:21:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:21:56 DISPATCHER: Finished worker discovery
12:22:56 DISPATCHER: Starting worker discovery
12:22:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:22:56 DISPATCHER: Finished worker discovery
12:23:18 WORKER: done with job (1, 0, 0), trying to register it.
12:23:18 WORKER: registered result for job (1, 0, 0) with dispatcher
12:23:18 DISPATCHER: job (1, 0, 0) finished
12:23:18 DISPATCHER: register_result: lock acquired
12:23:18 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
12:23:18 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.011583563032750913, 'num_filters_1': 124, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.013022856895546567}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4830928328793079, 'info': {'sick_no_sick': 0.4830928328793079, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.011583563032750913, 'num_filters_1': 124, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.013022856895546567}"}}
exception: None

12:23:18 job_callback for (1, 0, 0) started
12:23:18 job_callback for (1, 0, 0) got condition
12:23:18 DISPATCHER: Trying to submit another job.
12:23:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:23:18 Only 10 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:23:18 HBMASTER: Trying to run another job!
12:23:18 job_callback for (1, 0, 0) finished
12:23:18 start sampling a new configuration.
12:23:18 done sampling a new configuration.
12:23:18 HBMASTER: schedule new run for iteration 1
12:23:18 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
12:23:18 HBMASTER: submitting job (1, 0, 1) to dispatcher
12:23:18 DISPATCHER: trying to submit job (1, 0, 1)
12:23:18 DISPATCHER: trying to notify the job_runner thread.
12:23:18 HBMASTER: job (1, 0, 1) submitted to dispatcher
12:23:18 DISPATCHER: Trying to submit another job.
12:23:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:23:18 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
12:23:18 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
12:23:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:23:18 WORKER: start processing job (1, 0, 1)
12:23:18 WORKER: args: ()
12:23:18 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.003519902995796606, 'num_filters_1': 49, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.021175219044660316, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 24, 'num_filters_3': 63, 'num_filters_4': 106, 'num_filters_5': 24}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:23:56 DISPATCHER: Starting worker discovery
12:23:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:23:56 DISPATCHER: Finished worker discovery
12:24:56 DISPATCHER: Starting worker discovery
12:24:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:24:56 DISPATCHER: Finished worker discovery
12:25:56 DISPATCHER: Starting worker discovery
12:25:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:25:56 DISPATCHER: Finished worker discovery
12:26:42 WORKER: done with job (1, 0, 1), trying to register it.
12:26:42 WORKER: registered result for job (1, 0, 1) with dispatcher
12:26:42 DISPATCHER: job (1, 0, 1) finished
12:26:42 DISPATCHER: register_result: lock acquired
12:26:42 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
12:26:42 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.003519902995796606, 'num_filters_1': 49, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.021175219044660316, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 24, 'num_filters_3': 63, 'num_filters_4': 106, 'num_filters_5': 24}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6063378381761628, 'info': {'sick_no_sick': 0.6063378381761628, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.003519902995796606, 'num_filters_1': 49, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.021175219044660316, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 24, 'num_filters_3': 63, 'num_filters_4': 106, 'num_filters_5': 24}"}}
exception: None

12:26:42 job_callback for (1, 0, 1) started
12:26:42 DISPATCHER: Trying to submit another job.
12:26:42 job_callback for (1, 0, 1) got condition
12:26:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:26:42 Only 11 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:26:42 HBMASTER: Trying to run another job!
12:26:42 job_callback for (1, 0, 1) finished
12:26:42 start sampling a new configuration.
12:26:42 done sampling a new configuration.
12:26:42 HBMASTER: schedule new run for iteration 1
12:26:42 HBMASTER: trying submitting job (1, 0, 2) to dispatcher
12:26:42 HBMASTER: submitting job (1, 0, 2) to dispatcher
12:26:42 DISPATCHER: trying to submit job (1, 0, 2)
12:26:42 DISPATCHER: trying to notify the job_runner thread.
12:26:42 HBMASTER: job (1, 0, 2) submitted to dispatcher
12:26:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:26:42 DISPATCHER: Trying to submit another job.
12:26:42 DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
12:26:42 DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
12:26:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:26:42 WORKER: start processing job (1, 0, 2)
12:26:42 WORKER: args: ()
12:26:42 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.017118013406379282, 'num_filters_1': 83, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.028930646690086485, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 30, 'num_filters_3': 29}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:26:56 DISPATCHER: Starting worker discovery
12:26:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:26:56 DISPATCHER: Finished worker discovery
12:27:56 DISPATCHER: Starting worker discovery
12:27:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:27:56 DISPATCHER: Finished worker discovery
12:28:56 DISPATCHER: Starting worker discovery
12:28:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:28:56 DISPATCHER: Finished worker discovery
12:29:56 DISPATCHER: Starting worker discovery
12:29:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:29:56 DISPATCHER: Finished worker discovery
12:30:01 WORKER: done with job (1, 0, 2), trying to register it.
12:30:01 WORKER: registered result for job (1, 0, 2) with dispatcher
12:30:01 DISPATCHER: job (1, 0, 2) finished
12:30:01 DISPATCHER: register_result: lock acquired
12:30:01 DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
12:30:01 job_id: (1, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.017118013406379282, 'num_filters_1': 83, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.028930646690086485, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 30, 'num_filters_3': 29}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.017118013406379282, 'num_filters_1': 83, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.028930646690086485, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 30, 'num_filters_3': 29}"}}
exception: None

12:30:01 job_callback for (1, 0, 2) started
12:30:01 job_callback for (1, 0, 2) got condition
12:30:01 DISPATCHER: Trying to submit another job.
12:30:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:30:01 Only 12 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:30:01 HBMASTER: Trying to run another job!
12:30:01 job_callback for (1, 0, 2) finished
12:30:01 start sampling a new configuration.
12:30:01 done sampling a new configuration.
12:30:01 HBMASTER: schedule new run for iteration 1
12:30:01 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
12:30:01 HBMASTER: submitting job (1, 0, 3) to dispatcher
12:30:01 DISPATCHER: trying to submit job (1, 0, 3)
12:30:01 DISPATCHER: trying to notify the job_runner thread.
12:30:01 HBMASTER: job (1, 0, 3) submitted to dispatcher
12:30:01 DISPATCHER: Trying to submit another job.
12:30:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:30:01 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
12:30:01 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
12:30:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:30:01 WORKER: start processing job (1, 0, 3)
12:30:01 WORKER: args: ()
12:30:01 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0011350912084360856, 'num_filters_1': 110, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.1119353334053381}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:30:56 DISPATCHER: Starting worker discovery
12:30:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:30:56 DISPATCHER: Finished worker discovery
12:31:56 DISPATCHER: Starting worker discovery
12:31:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:31:56 DISPATCHER: Finished worker discovery
12:32:56 DISPATCHER: Starting worker discovery
12:32:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:32:56 DISPATCHER: Finished worker discovery
12:33:19 WORKER: done with job (1, 0, 3), trying to register it.
12:33:19 WORKER: registered result for job (1, 0, 3) with dispatcher
12:33:19 DISPATCHER: job (1, 0, 3) finished
12:33:19 DISPATCHER: register_result: lock acquired
12:33:19 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
12:33:19 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0011350912084360856, 'num_filters_1': 110, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.1119353334053381}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3686262881970773, 'info': {'sick_no_sick': 0.3686262881970773, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0011350912084360856, 'num_filters_1': 110, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.1119353334053381}"}}
exception: None

12:33:19 job_callback for (1, 0, 3) started
12:33:19 job_callback for (1, 0, 3) got condition
12:33:19 DISPATCHER: Trying to submit another job.
12:33:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:33:19 Only 13 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:33:19 HBMASTER: Trying to run another job!
12:33:19 job_callback for (1, 0, 3) finished
12:33:19 start sampling a new configuration.
12:33:19 done sampling a new configuration.
12:33:19 HBMASTER: schedule new run for iteration 1
12:33:19 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
12:33:19 HBMASTER: submitting job (1, 0, 4) to dispatcher
12:33:19 DISPATCHER: trying to submit job (1, 0, 4)
12:33:19 DISPATCHER: trying to notify the job_runner thread.
12:33:19 HBMASTER: job (1, 0, 4) submitted to dispatcher
12:33:19 DISPATCHER: Trying to submit another job.
12:33:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:33:19 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776
12:33:19 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
12:33:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:33:19 WORKER: start processing job (1, 0, 4)
12:33:19 WORKER: args: ()
12:33:19 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0684486577934162, 'num_filters_1': 16, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.034275130653106486, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 100, 'num_filters_3': 48}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:33:56 DISPATCHER: Starting worker discovery
12:33:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:33:56 DISPATCHER: Finished worker discovery
12:34:56 DISPATCHER: Starting worker discovery
12:34:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:34:56 DISPATCHER: Finished worker discovery
12:35:56 DISPATCHER: Starting worker discovery
12:35:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:35:56 DISPATCHER: Finished worker discovery
12:36:37 WORKER: done with job (1, 0, 4), trying to register it.
12:36:37 WORKER: registered result for job (1, 0, 4) with dispatcher
12:36:38 DISPATCHER: job (1, 0, 4) finished
12:36:38 DISPATCHER: register_result: lock acquired
12:36:38 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
12:36:38 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0684486577934162, 'num_filters_1': 16, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.034275130653106486, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 100, 'num_filters_3': 48}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0684486577934162, 'num_filters_1': 16, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.034275130653106486, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 100, 'num_filters_3': 48}"}}
exception: None

12:36:38 job_callback for (1, 0, 4) started
12:36:38 job_callback for (1, 0, 4) got condition
12:36:38 DISPATCHER: Trying to submit another job.
12:36:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:36:38 Only 14 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:36:38 HBMASTER: Trying to run another job!
12:36:38 job_callback for (1, 0, 4) finished
12:36:38 start sampling a new configuration.
12:36:38 done sampling a new configuration.
12:36:38 HBMASTER: schedule new run for iteration 1
12:36:38 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
12:36:38 HBMASTER: submitting job (1, 0, 5) to dispatcher
12:36:38 DISPATCHER: trying to submit job (1, 0, 5)
12:36:38 DISPATCHER: trying to notify the job_runner thread.
12:36:38 HBMASTER: job (1, 0, 5) submitted to dispatcher
12:36:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:36:38 DISPATCHER: Trying to submit another job.
12:36:38 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776
12:36:38 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
12:36:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:36:38 WORKER: start processing job (1, 0, 5)
12:36:38 WORKER: args: ()
12:36:38 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002467265933271762, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.026783213951170667, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 60, 'num_filters_3': 106, 'num_filters_4': 20, 'num_filters_5': 28}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:36:56 DISPATCHER: Starting worker discovery
12:36:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:36:56 DISPATCHER: Finished worker discovery
12:37:56 DISPATCHER: Starting worker discovery
12:37:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:37:56 DISPATCHER: Finished worker discovery
12:38:56 DISPATCHER: Starting worker discovery
12:38:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:38:56 DISPATCHER: Finished worker discovery
12:39:56 WORKER: done with job (1, 0, 5), trying to register it.
12:39:56 WORKER: registered result for job (1, 0, 5) with dispatcher
12:39:56 DISPATCHER: job (1, 0, 5) finished
12:39:56 DISPATCHER: register_result: lock acquired
12:39:56 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
12:39:56 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002467265933271762, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.026783213951170667, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 60, 'num_filters_3': 106, 'num_filters_4': 20, 'num_filters_5': 28}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.571657470390329, 'info': {'sick_no_sick': 0.571657470390329, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002467265933271762, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.026783213951170667, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 60, 'num_filters_3': 106, 'num_filters_4': 20, 'num_filters_5': 28}"}}
exception: None

12:39:56 job_callback for (1, 0, 5) started
12:39:56 DISPATCHER: Trying to submit another job.
12:39:56 job_callback for (1, 0, 5) got condition
12:39:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:39:56 Only 15 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:39:56 HBMASTER: Trying to run another job!
12:39:56 job_callback for (1, 0, 5) finished
12:39:56 start sampling a new configuration.
12:39:56 done sampling a new configuration.
12:39:56 HBMASTER: schedule new run for iteration 1
12:39:56 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
12:39:56 HBMASTER: submitting job (1, 0, 6) to dispatcher
12:39:56 DISPATCHER: trying to submit job (1, 0, 6)
12:39:56 DISPATCHER: trying to notify the job_runner thread.
12:39:56 HBMASTER: job (1, 0, 6) submitted to dispatcher
12:39:56 DISPATCHER: Trying to submit another job.
12:39:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:39:56 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776
12:39:56 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
12:39:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:39:56 WORKER: start processing job (1, 0, 6)
12:39:56 WORKER: args: ()
12:39:56 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.016958527024442407, 'num_filters_1': 57, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.19106976883388482, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 107, 'num_filters_3': 19, 'num_filters_4': 35}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:39:56 DISPATCHER: Starting worker discovery
12:39:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:39:56 DISPATCHER: Finished worker discovery
12:40:56 DISPATCHER: Starting worker discovery
12:40:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:40:56 DISPATCHER: Finished worker discovery
12:41:56 DISPATCHER: Starting worker discovery
12:41:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:41:56 DISPATCHER: Finished worker discovery
12:42:56 DISPATCHER: Starting worker discovery
12:42:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:42:56 DISPATCHER: Finished worker discovery
12:43:14 WORKER: done with job (1, 0, 6), trying to register it.
12:43:14 WORKER: registered result for job (1, 0, 6) with dispatcher
12:43:14 DISPATCHER: job (1, 0, 6) finished
12:43:14 DISPATCHER: register_result: lock acquired
12:43:14 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
12:43:14 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.016958527024442407, 'num_filters_1': 57, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.19106976883388482, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 107, 'num_filters_3': 19, 'num_filters_4': 35}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.016958527024442407, 'num_filters_1': 57, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.19106976883388482, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 107, 'num_filters_3': 19, 'num_filters_4': 35}"}}
exception: None

12:43:14 job_callback for (1, 0, 6) started
12:43:14 DISPATCHER: Trying to submit another job.
12:43:14 job_callback for (1, 0, 6) got condition
12:43:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:43:14 Only 16 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:43:14 HBMASTER: Trying to run another job!
12:43:14 job_callback for (1, 0, 6) finished
12:43:14 start sampling a new configuration.
12:43:14 done sampling a new configuration.
12:43:14 HBMASTER: schedule new run for iteration 1
12:43:14 HBMASTER: trying submitting job (1, 0, 7) to dispatcher
12:43:14 HBMASTER: submitting job (1, 0, 7) to dispatcher
12:43:14 DISPATCHER: trying to submit job (1, 0, 7)
12:43:14 DISPATCHER: trying to notify the job_runner thread.
12:43:14 HBMASTER: job (1, 0, 7) submitted to dispatcher
12:43:14 DISPATCHER: Trying to submit another job.
12:43:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:43:14 DISPATCHER: starting job (1, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776
12:43:14 DISPATCHER: job (1, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
12:43:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:43:14 WORKER: start processing job (1, 0, 7)
12:43:14 WORKER: args: ()
12:43:14 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0010837602188186453, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.0374616775571284, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 19, 'num_filters_3': 24, 'num_filters_4': 78}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:43:56 DISPATCHER: Starting worker discovery
12:43:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:43:56 DISPATCHER: Finished worker discovery
12:44:56 DISPATCHER: Starting worker discovery
12:44:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:44:56 DISPATCHER: Finished worker discovery
12:45:56 DISPATCHER: Starting worker discovery
12:45:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:45:56 DISPATCHER: Finished worker discovery
12:46:30 WORKER: done with job (1, 0, 7), trying to register it.
12:46:30 WORKER: registered result for job (1, 0, 7) with dispatcher
12:46:30 DISPATCHER: job (1, 0, 7) finished
12:46:30 DISPATCHER: register_result: lock acquired
12:46:30 DISPATCHER: job (1, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
12:46:30 job_id: (1, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0010837602188186453, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.0374616775571284, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 19, 'num_filters_3': 24, 'num_filters_4': 78}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.54968101680545, 'info': {'sick_no_sick': 0.54968101680545, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0010837602188186453, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.0374616775571284, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 19, 'num_filters_3': 24, 'num_filters_4': 78}"}}
exception: None

12:46:30 job_callback for (1, 0, 7) started
12:46:30 DISPATCHER: Trying to submit another job.
12:46:30 job_callback for (1, 0, 7) got condition
12:46:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:46:30 HBMASTER: Trying to run another job!
12:46:30 job_callback for (1, 0, 7) finished
12:46:30 start sampling a new configuration.
12:46:30 done sampling a new configuration.
12:46:30 HBMASTER: schedule new run for iteration 1
12:46:30 HBMASTER: trying submitting job (1, 0, 8) to dispatcher
12:46:30 HBMASTER: submitting job (1, 0, 8) to dispatcher
12:46:30 DISPATCHER: trying to submit job (1, 0, 8)
12:46:30 DISPATCHER: trying to notify the job_runner thread.
12:46:30 HBMASTER: job (1, 0, 8) submitted to dispatcher
12:46:30 DISPATCHER: Trying to submit another job.
12:46:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:46:30 DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776
12:46:30 DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
12:46:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:46:30 WORKER: start processing job (1, 0, 8)
12:46:30 WORKER: args: ()
12:46:30 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.006370451063180768, 'num_filters_1': 102, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.04877095670381167}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:46:56 DISPATCHER: Starting worker discovery
12:46:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:46:56 DISPATCHER: Finished worker discovery
12:47:56 DISPATCHER: Starting worker discovery
12:47:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:47:56 DISPATCHER: Finished worker discovery
12:48:56 DISPATCHER: Starting worker discovery
12:48:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:48:56 DISPATCHER: Finished worker discovery
12:49:49 WORKER: done with job (1, 0, 8), trying to register it.
12:49:49 WORKER: registered result for job (1, 0, 8) with dispatcher
12:49:49 DISPATCHER: job (1, 0, 8) finished
12:49:49 DISPATCHER: register_result: lock acquired
12:49:49 DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
12:49:49 job_id: (1, 0, 8)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.006370451063180768, 'num_filters_1': 102, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.04877095670381167}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.43939919957538215, 'info': {'sick_no_sick': 0.43939919957538215, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.006370451063180768, 'num_filters_1': 102, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.04877095670381167}"}}
exception: None

12:49:49 job_callback for (1, 0, 8) started
12:49:49 DISPATCHER: Trying to submit another job.
12:49:49 job_callback for (1, 0, 8) got condition
12:49:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:49:49 HBMASTER: Trying to run another job!
12:49:49 job_callback for (1, 0, 8) finished
12:49:49 ITERATION: Advancing config (1, 0, 1) to next budget 400.000000
12:49:49 ITERATION: Advancing config (1, 0, 5) to next budget 400.000000
12:49:49 ITERATION: Advancing config (1, 0, 7) to next budget 400.000000
12:49:49 HBMASTER: schedule new run for iteration 1
12:49:49 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
12:49:49 HBMASTER: submitting job (1, 0, 1) to dispatcher
12:49:49 DISPATCHER: trying to submit job (1, 0, 1)
12:49:49 DISPATCHER: trying to notify the job_runner thread.
12:49:49 HBMASTER: job (1, 0, 1) submitted to dispatcher
12:49:49 DISPATCHER: Trying to submit another job.
12:49:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:49:49 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
12:49:49 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
12:49:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:49:49 WORKER: start processing job (1, 0, 1)
12:49:49 WORKER: args: ()
12:49:49 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.003519902995796606, 'num_filters_1': 49, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.021175219044660316, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 24, 'num_filters_3': 63, 'num_filters_4': 106, 'num_filters_5': 24}, 'budget': 400.0, 'working_directory': '.'}
12:49:56 DISPATCHER: Starting worker discovery
12:49:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:49:56 DISPATCHER: Finished worker discovery
12:50:56 DISPATCHER: Starting worker discovery
12:50:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:50:56 DISPATCHER: Finished worker discovery
12:51:56 DISPATCHER: Starting worker discovery
12:51:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:51:56 DISPATCHER: Finished worker discovery
12:52:56 DISPATCHER: Starting worker discovery
12:52:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:52:56 DISPATCHER: Finished worker discovery
12:53:56 DISPATCHER: Starting worker discovery
12:53:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:53:56 DISPATCHER: Finished worker discovery
12:54:56 DISPATCHER: Starting worker discovery
12:54:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:54:56 DISPATCHER: Finished worker discovery
12:55:56 DISPATCHER: Starting worker discovery
12:55:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:55:56 DISPATCHER: Finished worker discovery
12:56:56 DISPATCHER: Starting worker discovery
12:56:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:56:56 DISPATCHER: Finished worker discovery
12:57:50 WORKER: done with job (1, 0, 1), trying to register it.
12:57:50 WORKER: registered result for job (1, 0, 1) with dispatcher
12:57:50 DISPATCHER: job (1, 0, 1) finished
12:57:50 DISPATCHER: register_result: lock acquired
12:57:50 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
12:57:50 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.003519902995796606, 'num_filters_1': 49, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.021175219044660316, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 24, 'num_filters_3': 63, 'num_filters_4': 106, 'num_filters_5': 24}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5892651247616031, 'info': {'sick_no_sick': 0.5892651247616031, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.003519902995796606, 'num_filters_1': 49, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.021175219044660316, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 24, 'num_filters_3': 63, 'num_filters_4': 106, 'num_filters_5': 24}"}}
exception: None

12:57:50 job_callback for (1, 0, 1) started
12:57:50 DISPATCHER: Trying to submit another job.
12:57:50 job_callback for (1, 0, 1) got condition
12:57:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:57:50 Only 4 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
12:57:50 HBMASTER: Trying to run another job!
12:57:50 job_callback for (1, 0, 1) finished
12:57:50 HBMASTER: schedule new run for iteration 1
12:57:50 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
12:57:50 HBMASTER: submitting job (1, 0, 5) to dispatcher
12:57:50 DISPATCHER: trying to submit job (1, 0, 5)
12:57:50 DISPATCHER: trying to notify the job_runner thread.
12:57:50 HBMASTER: job (1, 0, 5) submitted to dispatcher
12:57:50 DISPATCHER: Trying to submit another job.
12:57:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:57:50 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776
12:57:50 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
12:57:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:57:50 WORKER: start processing job (1, 0, 5)
12:57:50 WORKER: args: ()
12:57:50 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002467265933271762, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.026783213951170667, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 60, 'num_filters_3': 106, 'num_filters_4': 20, 'num_filters_5': 28}, 'budget': 400.0, 'working_directory': '.'}
12:57:56 DISPATCHER: Starting worker discovery
12:57:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:57:56 DISPATCHER: Finished worker discovery
12:58:56 DISPATCHER: Starting worker discovery
12:58:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:58:56 DISPATCHER: Finished worker discovery
12:59:56 DISPATCHER: Starting worker discovery
12:59:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:59:56 DISPATCHER: Finished worker discovery
13:00:56 DISPATCHER: Starting worker discovery
13:00:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:00:56 DISPATCHER: Finished worker discovery
13:01:56 DISPATCHER: Starting worker discovery
13:01:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:01:56 DISPATCHER: Finished worker discovery
13:02:56 DISPATCHER: Starting worker discovery
13:02:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:02:56 DISPATCHER: Finished worker discovery
13:03:56 DISPATCHER: Starting worker discovery
13:03:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:03:56 DISPATCHER: Finished worker discovery
13:04:56 DISPATCHER: Starting worker discovery
13:04:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:04:56 DISPATCHER: Finished worker discovery
13:05:39 WORKER: done with job (1, 0, 5), trying to register it.
13:05:39 WORKER: registered result for job (1, 0, 5) with dispatcher
13:05:39 DISPATCHER: job (1, 0, 5) finished
13:05:39 DISPATCHER: register_result: lock acquired
13:05:39 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
13:05:39 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002467265933271762, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.026783213951170667, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 60, 'num_filters_3': 106, 'num_filters_4': 20, 'num_filters_5': 28}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5317427358579212, 'info': {'sick_no_sick': 0.5317427358579212, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002467265933271762, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.026783213951170667, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 60, 'num_filters_3': 106, 'num_filters_4': 20, 'num_filters_5': 28}"}}
exception: None

13:05:39 job_callback for (1, 0, 5) started
13:05:39 DISPATCHER: Trying to submit another job.
13:05:39 job_callback for (1, 0, 5) got condition
13:05:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:05:39 Only 5 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
13:05:39 HBMASTER: Trying to run another job!
13:05:39 job_callback for (1, 0, 5) finished
13:05:39 HBMASTER: schedule new run for iteration 1
13:05:39 HBMASTER: trying submitting job (1, 0, 7) to dispatcher
13:05:39 HBMASTER: submitting job (1, 0, 7) to dispatcher
13:05:39 DISPATCHER: trying to submit job (1, 0, 7)
13:05:39 DISPATCHER: trying to notify the job_runner thread.
13:05:39 HBMASTER: job (1, 0, 7) submitted to dispatcher
13:05:39 DISPATCHER: Trying to submit another job.
13:05:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:05:39 DISPATCHER: starting job (1, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776
13:05:39 DISPATCHER: job (1, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
13:05:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:05:39 WORKER: start processing job (1, 0, 7)
13:05:39 WORKER: args: ()
13:05:39 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0010837602188186453, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.0374616775571284, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 19, 'num_filters_3': 24, 'num_filters_4': 78}, 'budget': 400.0, 'working_directory': '.'}
13:05:56 DISPATCHER: Starting worker discovery
13:05:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:05:56 DISPATCHER: Finished worker discovery
13:06:56 DISPATCHER: Starting worker discovery
13:06:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:06:56 DISPATCHER: Finished worker discovery
13:07:56 DISPATCHER: Starting worker discovery
13:07:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:07:56 DISPATCHER: Finished worker discovery
13:08:56 DISPATCHER: Starting worker discovery
13:08:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:08:56 DISPATCHER: Finished worker discovery
13:09:56 DISPATCHER: Starting worker discovery
13:09:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:09:56 DISPATCHER: Finished worker discovery
13:10:56 DISPATCHER: Starting worker discovery
13:10:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:10:56 DISPATCHER: Finished worker discovery
13:11:56 DISPATCHER: Starting worker discovery
13:11:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:11:56 DISPATCHER: Finished worker discovery
13:12:56 DISPATCHER: Starting worker discovery
13:12:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:12:57 DISPATCHER: Finished worker discovery
13:13:27 WORKER: done with job (1, 0, 7), trying to register it.
13:13:27 WORKER: registered result for job (1, 0, 7) with dispatcher
13:13:27 DISPATCHER: job (1, 0, 7) finished
13:13:27 DISPATCHER: register_result: lock acquired
13:13:27 DISPATCHER: job (1, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
13:13:27 job_id: (1, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0010837602188186453, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.0374616775571284, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 19, 'num_filters_3': 24, 'num_filters_4': 78}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5982114650577659, 'info': {'sick_no_sick': 0.5982114650577659, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0010837602188186453, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.0374616775571284, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 19, 'num_filters_3': 24, 'num_filters_4': 78}"}}
exception: None

13:13:27 job_callback for (1, 0, 7) started
13:13:27 job_callback for (1, 0, 7) got condition
13:13:27 DISPATCHER: Trying to submit another job.
13:13:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:13:27 Only 6 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
13:13:27 HBMASTER: Trying to run another job!
13:13:27 job_callback for (1, 0, 7) finished
13:13:27 ITERATION: Advancing config (1, 0, 7) to next budget 1200.000000
13:13:27 HBMASTER: schedule new run for iteration 1
13:13:27 HBMASTER: trying submitting job (1, 0, 7) to dispatcher
13:13:27 HBMASTER: submitting job (1, 0, 7) to dispatcher
13:13:27 DISPATCHER: trying to submit job (1, 0, 7)
13:13:27 DISPATCHER: trying to notify the job_runner thread.
13:13:27 HBMASTER: job (1, 0, 7) submitted to dispatcher
13:13:27 DISPATCHER: Trying to submit another job.
13:13:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:13:27 DISPATCHER: starting job (1, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776
13:13:27 DISPATCHER: job (1, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
13:13:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:13:27 WORKER: start processing job (1, 0, 7)
13:13:27 WORKER: args: ()
13:13:27 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0010837602188186453, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.0374616775571284, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 19, 'num_filters_3': 24, 'num_filters_4': 78}, 'budget': 1200.0, 'working_directory': '.'}
13:13:57 DISPATCHER: Starting worker discovery
13:13:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:13:57 DISPATCHER: Finished worker discovery
13:14:57 DISPATCHER: Starting worker discovery
13:14:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:14:57 DISPATCHER: Finished worker discovery
13:15:57 DISPATCHER: Starting worker discovery
13:15:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:15:57 DISPATCHER: Finished worker discovery
13:16:57 DISPATCHER: Starting worker discovery
13:16:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:16:57 DISPATCHER: Finished worker discovery
13:17:57 DISPATCHER: Starting worker discovery
13:17:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:17:57 DISPATCHER: Finished worker discovery
13:18:57 DISPATCHER: Starting worker discovery
13:18:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:18:57 DISPATCHER: Finished worker discovery
13:19:57 DISPATCHER: Starting worker discovery
13:19:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:19:57 DISPATCHER: Finished worker discovery
13:20:57 DISPATCHER: Starting worker discovery
13:20:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:20:57 DISPATCHER: Finished worker discovery
13:21:57 DISPATCHER: Starting worker discovery
13:21:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:21:57 DISPATCHER: Finished worker discovery
13:22:57 DISPATCHER: Starting worker discovery
13:22:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:22:57 DISPATCHER: Finished worker discovery
13:23:57 DISPATCHER: Starting worker discovery
13:23:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:23:57 DISPATCHER: Finished worker discovery
13:24:57 DISPATCHER: Starting worker discovery
13:24:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:24:57 DISPATCHER: Finished worker discovery
13:25:57 DISPATCHER: Starting worker discovery
13:25:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:25:57 DISPATCHER: Finished worker discovery
13:26:57 DISPATCHER: Starting worker discovery
13:26:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:26:57 DISPATCHER: Finished worker discovery
13:27:57 DISPATCHER: Starting worker discovery
13:27:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:27:57 DISPATCHER: Finished worker discovery
13:28:57 DISPATCHER: Starting worker discovery
13:28:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:28:57 DISPATCHER: Finished worker discovery
13:29:57 DISPATCHER: Starting worker discovery
13:29:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:29:57 DISPATCHER: Finished worker discovery
13:30:57 DISPATCHER: Starting worker discovery
13:30:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:30:57 DISPATCHER: Finished worker discovery
13:31:57 DISPATCHER: Starting worker discovery
13:31:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:31:57 DISPATCHER: Finished worker discovery
13:32:57 DISPATCHER: Starting worker discovery
13:32:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:32:57 DISPATCHER: Finished worker discovery
13:33:57 DISPATCHER: Starting worker discovery
13:33:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:33:57 DISPATCHER: Finished worker discovery
13:34:47 WORKER: done with job (1, 0, 7), trying to register it.
13:34:47 WORKER: registered result for job (1, 0, 7) with dispatcher
13:34:47 DISPATCHER: job (1, 0, 7) finished
13:34:47 DISPATCHER: register_result: lock acquired
13:34:47 DISPATCHER: job (1, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
13:34:47 job_id: (1, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0010837602188186453, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.0374616775571284, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 19, 'num_filters_3': 24, 'num_filters_4': 78}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.562487666252935, 'info': {'sick_no_sick': 0.562487666252935, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0010837602188186453, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.0374616775571284, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 19, 'num_filters_3': 24, 'num_filters_4': 78}"}}
exception: None

13:34:47 job_callback for (1, 0, 7) started
13:34:47 DISPATCHER: Trying to submit another job.
13:34:47 job_callback for (1, 0, 7) got condition
13:34:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:34:47 Only 2 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
13:34:47 HBMASTER: Trying to run another job!
13:34:47 job_callback for (1, 0, 7) finished
13:34:47 start sampling a new configuration.
13:34:47 done sampling a new configuration.
13:34:47 HBMASTER: schedule new run for iteration 2
13:34:47 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
13:34:47 HBMASTER: submitting job (2, 0, 0) to dispatcher
13:34:47 DISPATCHER: trying to submit job (2, 0, 0)
13:34:47 DISPATCHER: trying to notify the job_runner thread.
13:34:47 HBMASTER: job (2, 0, 0) submitted to dispatcher
13:34:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:34:47 DISPATCHER: Trying to submit another job.
13:34:47 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
13:34:47 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
13:34:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:34:47 WORKER: start processing job (2, 0, 0)
13:34:47 WORKER: args: ()
13:34:47 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.010620509207681492, 'num_filters_1': 88, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.01721504941240509, 'kernel_size_2': 3, 'num_filters_2': 21}, 'budget': 400.0, 'working_directory': '.'}
13:34:57 DISPATCHER: Starting worker discovery
13:34:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:34:57 DISPATCHER: Finished worker discovery
13:35:57 DISPATCHER: Starting worker discovery
13:35:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:35:57 DISPATCHER: Finished worker discovery
13:36:57 DISPATCHER: Starting worker discovery
13:36:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:36:57 DISPATCHER: Finished worker discovery
13:37:57 DISPATCHER: Starting worker discovery
13:37:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:37:57 DISPATCHER: Finished worker discovery
13:38:57 DISPATCHER: Starting worker discovery
13:38:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:38:57 DISPATCHER: Finished worker discovery
13:39:57 DISPATCHER: Starting worker discovery
13:39:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:39:57 DISPATCHER: Finished worker discovery
13:40:57 DISPATCHER: Starting worker discovery
13:40:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:40:57 DISPATCHER: Finished worker discovery
13:41:57 DISPATCHER: Starting worker discovery
13:41:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:41:57 DISPATCHER: Finished worker discovery
13:42:33 WORKER: done with job (2, 0, 0), trying to register it.
13:42:33 WORKER: registered result for job (2, 0, 0) with dispatcher
13:42:33 DISPATCHER: job (2, 0, 0) finished
13:42:33 DISPATCHER: register_result: lock acquired
13:42:33 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
13:42:33 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.010620509207681492, 'num_filters_1': 88, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.01721504941240509, 'kernel_size_2': 3, 'num_filters_2': 21}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5135828743835884, 'info': {'sick_no_sick': 0.5135828743835884, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.010620509207681492, 'num_filters_1': 88, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.01721504941240509, 'kernel_size_2': 3, 'num_filters_2': 21}"}}
exception: None

13:42:33 job_callback for (2, 0, 0) started
13:42:33 DISPATCHER: Trying to submit another job.
13:42:33 job_callback for (2, 0, 0) got condition
13:42:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:42:33 Only 7 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
13:42:33 HBMASTER: Trying to run another job!
13:42:33 job_callback for (2, 0, 0) finished
13:42:33 start sampling a new configuration.
13:42:33 done sampling a new configuration.
13:42:33 HBMASTER: schedule new run for iteration 2
13:42:33 HBMASTER: trying submitting job (2, 0, 1) to dispatcher
13:42:33 HBMASTER: submitting job (2, 0, 1) to dispatcher
13:42:33 DISPATCHER: trying to submit job (2, 0, 1)
13:42:33 DISPATCHER: trying to notify the job_runner thread.
13:42:33 HBMASTER: job (2, 0, 1) submitted to dispatcher
13:42:33 DISPATCHER: Trying to submit another job.
13:42:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:42:33 DISPATCHER: starting job (2, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
13:42:33 DISPATCHER: job (2, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
13:42:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:42:33 WORKER: start processing job (2, 0, 1)
13:42:33 WORKER: args: ()
13:42:33 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.008781881597374294, 'num_filters_1': 52, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.1210109870560121, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 22, 'num_filters_3': 34, 'num_filters_4': 17}, 'budget': 400.0, 'working_directory': '.'}
13:42:57 DISPATCHER: Starting worker discovery
13:42:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:42:57 DISPATCHER: Finished worker discovery
13:43:57 DISPATCHER: Starting worker discovery
13:43:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:43:57 DISPATCHER: Finished worker discovery
13:44:57 DISPATCHER: Starting worker discovery
13:44:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:44:57 DISPATCHER: Finished worker discovery
13:45:57 DISPATCHER: Starting worker discovery
13:45:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:45:57 DISPATCHER: Finished worker discovery
13:46:57 DISPATCHER: Starting worker discovery
13:46:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:46:57 DISPATCHER: Finished worker discovery
13:47:57 DISPATCHER: Starting worker discovery
13:47:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:47:57 DISPATCHER: Finished worker discovery
13:48:57 DISPATCHER: Starting worker discovery
13:48:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:48:57 DISPATCHER: Finished worker discovery
13:49:57 DISPATCHER: Starting worker discovery
13:49:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:49:57 DISPATCHER: Finished worker discovery
13:50:21 WORKER: done with job (2, 0, 1), trying to register it.
13:50:21 WORKER: registered result for job (2, 0, 1) with dispatcher
13:50:21 DISPATCHER: job (2, 0, 1) finished
13:50:21 DISPATCHER: register_result: lock acquired
13:50:21 DISPATCHER: job (2, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
13:50:21 job_id: (2, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.008781881597374294, 'num_filters_1': 52, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.1210109870560121, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 22, 'num_filters_3': 34, 'num_filters_4': 17}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3200658688229857, 'info': {'sick_no_sick': 0.3200658688229857, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.008781881597374294, 'num_filters_1': 52, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.1210109870560121, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 22, 'num_filters_3': 34, 'num_filters_4': 17}"}}
exception: None

13:50:21 job_callback for (2, 0, 1) started
13:50:21 DISPATCHER: Trying to submit another job.
13:50:21 job_callback for (2, 0, 1) got condition
13:50:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:50:21 Only 8 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
13:50:21 HBMASTER: Trying to run another job!
13:50:21 job_callback for (2, 0, 1) finished
13:50:21 start sampling a new configuration.
13:50:21 done sampling a new configuration.
13:50:21 HBMASTER: schedule new run for iteration 2
13:50:21 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
13:50:21 HBMASTER: submitting job (2, 0, 2) to dispatcher
13:50:21 DISPATCHER: trying to submit job (2, 0, 2)
13:50:21 DISPATCHER: trying to notify the job_runner thread.
13:50:21 HBMASTER: job (2, 0, 2) submitted to dispatcher
13:50:21 DISPATCHER: Trying to submit another job.
13:50:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:50:21 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
13:50:21 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
13:50:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:50:21 WORKER: start processing job (2, 0, 2)
13:50:21 WORKER: args: ()
13:50:21 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0214753345369918, 'num_filters_1': 33, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.013674088130313638}, 'budget': 400.0, 'working_directory': '.'}
13:50:57 DISPATCHER: Starting worker discovery
13:50:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:50:57 DISPATCHER: Finished worker discovery
13:51:57 DISPATCHER: Starting worker discovery
13:51:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:51:57 DISPATCHER: Finished worker discovery
13:52:57 DISPATCHER: Starting worker discovery
13:52:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:52:57 DISPATCHER: Finished worker discovery
13:53:57 DISPATCHER: Starting worker discovery
13:53:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:53:57 DISPATCHER: Finished worker discovery
13:54:57 DISPATCHER: Starting worker discovery
13:54:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:54:57 DISPATCHER: Finished worker discovery
13:55:57 DISPATCHER: Starting worker discovery
13:55:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:55:57 DISPATCHER: Finished worker discovery
13:56:57 DISPATCHER: Starting worker discovery
13:56:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:56:57 DISPATCHER: Finished worker discovery
13:57:57 DISPATCHER: Starting worker discovery
13:57:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:57:57 DISPATCHER: Finished worker discovery
13:58:15 WORKER: done with job (2, 0, 2), trying to register it.
13:58:15 WORKER: registered result for job (2, 0, 2) with dispatcher
13:58:15 DISPATCHER: job (2, 0, 2) finished
13:58:15 DISPATCHER: register_result: lock acquired
13:58:15 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
13:58:15 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0214753345369918, 'num_filters_1': 33, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.013674088130313638}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.35743897893584453, 'info': {'sick_no_sick': 0.35743897893584453, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0214753345369918, 'num_filters_1': 33, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.013674088130313638}"}}
exception: None

13:58:15 job_callback for (2, 0, 2) started
13:58:15 DISPATCHER: Trying to submit another job.
13:58:15 job_callback for (2, 0, 2) got condition
13:58:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:58:15 Only 9 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
13:58:15 HBMASTER: Trying to run another job!
13:58:15 job_callback for (2, 0, 2) finished
13:58:15 start sampling a new configuration.
13:58:15 done sampling a new configuration.
13:58:15 HBMASTER: schedule new run for iteration 2
13:58:15 HBMASTER: trying submitting job (2, 0, 3) to dispatcher
13:58:15 HBMASTER: submitting job (2, 0, 3) to dispatcher
13:58:15 DISPATCHER: trying to submit job (2, 0, 3)
13:58:15 DISPATCHER: trying to notify the job_runner thread.
13:58:15 HBMASTER: job (2, 0, 3) submitted to dispatcher
13:58:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:58:15 DISPATCHER: Trying to submit another job.
13:58:15 DISPATCHER: starting job (2, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
13:58:15 DISPATCHER: job (2, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
13:58:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:58:15 WORKER: start processing job (2, 0, 3)
13:58:15 WORKER: args: ()
13:58:15 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.047454600903832404, 'num_filters_1': 100, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.19850916089215925, 'kernel_size_2': 7, 'num_filters_2': 20}, 'budget': 400.0, 'working_directory': '.'}
13:58:57 DISPATCHER: Starting worker discovery
13:58:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:58:57 DISPATCHER: Finished worker discovery
13:59:57 DISPATCHER: Starting worker discovery
13:59:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:59:57 DISPATCHER: Finished worker discovery
14:00:57 DISPATCHER: Starting worker discovery
14:00:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:00:57 DISPATCHER: Finished worker discovery
14:01:57 DISPATCHER: Starting worker discovery
14:01:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:01:57 DISPATCHER: Finished worker discovery
14:02:57 DISPATCHER: Starting worker discovery
14:02:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:02:57 DISPATCHER: Finished worker discovery
14:03:57 DISPATCHER: Starting worker discovery
14:03:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:03:57 DISPATCHER: Finished worker discovery
14:04:57 DISPATCHER: Starting worker discovery
14:04:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:04:57 DISPATCHER: Finished worker discovery
14:05:57 DISPATCHER: Starting worker discovery
14:05:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:05:57 DISPATCHER: Finished worker discovery
14:06:01 WORKER: done with job (2, 0, 3), trying to register it.
14:06:01 WORKER: registered result for job (2, 0, 3) with dispatcher
14:06:01 DISPATCHER: job (2, 0, 3) finished
14:06:01 DISPATCHER: register_result: lock acquired
14:06:01 DISPATCHER: job (2, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
14:06:01 job_id: (2, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.047454600903832404, 'num_filters_1': 100, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.19850916089215925, 'kernel_size_2': 7, 'num_filters_2': 20}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.047454600903832404, 'num_filters_1': 100, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.19850916089215925, 'kernel_size_2': 7, 'num_filters_2': 20}"}}
exception: None

14:06:01 job_callback for (2, 0, 3) started
14:06:01 DISPATCHER: Trying to submit another job.
14:06:01 job_callback for (2, 0, 3) got condition
14:06:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:06:01 Only 10 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
14:06:01 HBMASTER: Trying to run another job!
14:06:01 job_callback for (2, 0, 3) finished
14:06:01 start sampling a new configuration.
14:06:01 done sampling a new configuration.
14:06:02 HBMASTER: schedule new run for iteration 2
14:06:02 HBMASTER: trying submitting job (2, 0, 4) to dispatcher
14:06:02 HBMASTER: submitting job (2, 0, 4) to dispatcher
14:06:02 DISPATCHER: trying to submit job (2, 0, 4)
14:06:02 DISPATCHER: trying to notify the job_runner thread.
14:06:02 HBMASTER: job (2, 0, 4) submitted to dispatcher
14:06:02 DISPATCHER: Trying to submit another job.
14:06:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:06:02 DISPATCHER: starting job (2, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:06:02 DISPATCHER: job (2, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:06:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:06:02 WORKER: start processing job (2, 0, 4)
14:06:02 WORKER: args: ()
14:06:02 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.01415140137215639, 'num_filters_1': 35, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.17612325271477597, 'kernel_size_2': 3, 'num_filters_2': 39}, 'budget': 400.0, 'working_directory': '.'}
14:06:57 DISPATCHER: Starting worker discovery
14:06:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:06:57 DISPATCHER: Finished worker discovery
14:07:57 DISPATCHER: Starting worker discovery
14:07:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:07:57 DISPATCHER: Finished worker discovery
14:08:57 DISPATCHER: Starting worker discovery
14:08:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:08:57 DISPATCHER: Finished worker discovery
14:09:57 DISPATCHER: Starting worker discovery
14:09:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:09:57 DISPATCHER: Finished worker discovery
14:10:57 DISPATCHER: Starting worker discovery
14:10:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:10:57 DISPATCHER: Finished worker discovery
14:11:57 DISPATCHER: Starting worker discovery
14:11:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:11:57 DISPATCHER: Finished worker discovery
14:12:57 DISPATCHER: Starting worker discovery
14:12:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:12:57 DISPATCHER: Finished worker discovery
14:13:49 WORKER: done with job (2, 0, 4), trying to register it.
14:13:49 WORKER: registered result for job (2, 0, 4) with dispatcher
14:13:49 DISPATCHER: job (2, 0, 4) finished
14:13:49 DISPATCHER: register_result: lock acquired
14:13:49 DISPATCHER: job (2, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
14:13:49 job_id: (2, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.01415140137215639, 'num_filters_1': 35, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.17612325271477597, 'kernel_size_2': 3, 'num_filters_2': 39}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.004184154390490979, 'info': {'sick_no_sick': 0.004184154390490979, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.01415140137215639, 'num_filters_1': 35, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.17612325271477597, 'kernel_size_2': 3, 'num_filters_2': 39}"}}
exception: None

14:13:49 job_callback for (2, 0, 4) started
14:13:49 DISPATCHER: Trying to submit another job.
14:13:49 job_callback for (2, 0, 4) got condition
14:13:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:13:49 Only 11 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
14:13:49 HBMASTER: Trying to run another job!
14:13:49 job_callback for (2, 0, 4) finished
14:13:49 start sampling a new configuration.
14:13:49 done sampling a new configuration.
14:13:49 HBMASTER: schedule new run for iteration 2
14:13:49 HBMASTER: trying submitting job (2, 0, 5) to dispatcher
14:13:49 HBMASTER: submitting job (2, 0, 5) to dispatcher
14:13:49 DISPATCHER: trying to submit job (2, 0, 5)
14:13:49 DISPATCHER: trying to notify the job_runner thread.
14:13:49 HBMASTER: job (2, 0, 5) submitted to dispatcher
14:13:49 DISPATCHER: Trying to submit another job.
14:13:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:13:49 DISPATCHER: starting job (2, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:13:49 DISPATCHER: job (2, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:13:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:13:49 WORKER: start processing job (2, 0, 5)
14:13:49 WORKER: args: ()
14:13:49 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.04112320246681437, 'num_filters_1': 56, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.056560628025571394, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 90, 'num_filters_3': 22, 'num_filters_4': 22, 'num_filters_5': 95}, 'budget': 400.0, 'working_directory': '.'}
14:13:57 DISPATCHER: Starting worker discovery
14:13:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:13:57 DISPATCHER: Finished worker discovery
14:14:57 DISPATCHER: Starting worker discovery
14:14:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:14:57 DISPATCHER: Finished worker discovery
14:15:57 DISPATCHER: Starting worker discovery
14:15:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:15:57 DISPATCHER: Finished worker discovery
14:16:57 DISPATCHER: Starting worker discovery
14:16:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:16:57 DISPATCHER: Finished worker discovery
14:17:57 DISPATCHER: Starting worker discovery
14:17:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:17:57 DISPATCHER: Finished worker discovery
14:18:57 DISPATCHER: Starting worker discovery
14:18:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:18:57 DISPATCHER: Finished worker discovery
14:19:57 DISPATCHER: Starting worker discovery
14:19:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:19:57 DISPATCHER: Finished worker discovery
14:20:57 DISPATCHER: Starting worker discovery
14:20:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:20:57 DISPATCHER: Finished worker discovery
14:21:36 WORKER: done with job (2, 0, 5), trying to register it.
14:21:36 WORKER: registered result for job (2, 0, 5) with dispatcher
14:21:36 DISPATCHER: job (2, 0, 5) finished
14:21:36 DISPATCHER: register_result: lock acquired
14:21:36 DISPATCHER: job (2, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
14:21:36 job_id: (2, 0, 5)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.04112320246681437, 'num_filters_1': 56, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.056560628025571394, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 90, 'num_filters_3': 22, 'num_filters_4': 22, 'num_filters_5': 95}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.04112320246681437, 'num_filters_1': 56, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.056560628025571394, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 90, 'num_filters_3': 22, 'num_filters_4': 22, 'num_filters_5': 95}"}}
exception: None

14:21:36 job_callback for (2, 0, 5) started
14:21:36 DISPATCHER: Trying to submit another job.
14:21:36 job_callback for (2, 0, 5) got condition
14:21:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:21:36 Only 12 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
14:21:36 HBMASTER: Trying to run another job!
14:21:36 job_callback for (2, 0, 5) finished
14:21:36 ITERATION: Advancing config (2, 0, 0) to next budget 1200.000000
14:21:36 ITERATION: Advancing config (2, 0, 2) to next budget 1200.000000
14:21:36 HBMASTER: schedule new run for iteration 2
14:21:36 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
14:21:36 HBMASTER: submitting job (2, 0, 0) to dispatcher
14:21:36 DISPATCHER: trying to submit job (2, 0, 0)
14:21:36 DISPATCHER: trying to notify the job_runner thread.
14:21:36 HBMASTER: job (2, 0, 0) submitted to dispatcher
14:21:36 DISPATCHER: Trying to submit another job.
14:21:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:21:36 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:21:36 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:21:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:21:36 WORKER: start processing job (2, 0, 0)
14:21:36 WORKER: args: ()
14:21:36 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.010620509207681492, 'num_filters_1': 88, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.01721504941240509, 'kernel_size_2': 3, 'num_filters_2': 21}, 'budget': 1200.0, 'working_directory': '.'}
14:21:57 DISPATCHER: Starting worker discovery
14:21:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:21:57 DISPATCHER: Finished worker discovery
14:22:57 DISPATCHER: Starting worker discovery
14:22:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:22:57 DISPATCHER: Finished worker discovery
14:23:57 DISPATCHER: Starting worker discovery
14:23:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:23:57 DISPATCHER: Finished worker discovery
14:24:57 DISPATCHER: Starting worker discovery
14:24:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:24:57 DISPATCHER: Finished worker discovery
14:25:57 DISPATCHER: Starting worker discovery
14:25:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:25:57 DISPATCHER: Finished worker discovery
14:26:57 DISPATCHER: Starting worker discovery
14:26:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:26:57 DISPATCHER: Finished worker discovery
14:27:57 DISPATCHER: Starting worker discovery
14:27:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:27:57 DISPATCHER: Finished worker discovery
14:28:57 DISPATCHER: Starting worker discovery
14:28:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:28:57 DISPATCHER: Finished worker discovery
14:29:57 DISPATCHER: Starting worker discovery
14:29:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:29:57 DISPATCHER: Finished worker discovery
14:30:57 DISPATCHER: Starting worker discovery
14:30:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:30:57 DISPATCHER: Finished worker discovery
14:31:57 DISPATCHER: Starting worker discovery
14:31:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:31:57 DISPATCHER: Finished worker discovery
14:32:57 DISPATCHER: Starting worker discovery
14:32:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:32:57 DISPATCHER: Finished worker discovery
14:33:57 DISPATCHER: Starting worker discovery
14:33:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:33:57 DISPATCHER: Finished worker discovery
14:34:57 DISPATCHER: Starting worker discovery
14:34:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:34:57 DISPATCHER: Finished worker discovery
14:35:57 DISPATCHER: Starting worker discovery
14:35:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:35:57 DISPATCHER: Finished worker discovery
14:36:57 DISPATCHER: Starting worker discovery
14:36:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:36:57 DISPATCHER: Finished worker discovery
14:37:57 DISPATCHER: Starting worker discovery
14:37:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:37:57 DISPATCHER: Finished worker discovery
14:38:57 DISPATCHER: Starting worker discovery
14:38:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:38:57 DISPATCHER: Finished worker discovery
14:39:57 DISPATCHER: Starting worker discovery
14:39:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:39:57 DISPATCHER: Finished worker discovery
14:40:57 DISPATCHER: Starting worker discovery
14:40:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:40:57 DISPATCHER: Finished worker discovery
14:41:57 DISPATCHER: Starting worker discovery
14:41:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:41:57 DISPATCHER: Finished worker discovery
14:42:47 WORKER: done with job (2, 0, 0), trying to register it.
14:42:47 WORKER: registered result for job (2, 0, 0) with dispatcher
14:42:47 DISPATCHER: job (2, 0, 0) finished
14:42:47 DISPATCHER: register_result: lock acquired
14:42:47 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
14:42:47 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.010620509207681492, 'num_filters_1': 88, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.01721504941240509, 'kernel_size_2': 3, 'num_filters_2': 21}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5292013724300616, 'info': {'sick_no_sick': 0.5292013724300616, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.010620509207681492, 'num_filters_1': 88, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.01721504941240509, 'kernel_size_2': 3, 'num_filters_2': 21}"}}
exception: None

14:42:47 job_callback for (2, 0, 0) started
14:42:47 DISPATCHER: Trying to submit another job.
14:42:47 job_callback for (2, 0, 0) got condition
14:42:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:42:47 Only 3 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
14:42:47 HBMASTER: Trying to run another job!
14:42:47 job_callback for (2, 0, 0) finished
14:42:47 HBMASTER: schedule new run for iteration 2
14:42:47 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
14:42:47 HBMASTER: submitting job (2, 0, 2) to dispatcher
14:42:47 DISPATCHER: trying to submit job (2, 0, 2)
14:42:47 DISPATCHER: trying to notify the job_runner thread.
14:42:47 HBMASTER: job (2, 0, 2) submitted to dispatcher
14:42:47 DISPATCHER: Trying to submit another job.
14:42:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:42:47 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:42:47 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:42:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:42:47 WORKER: start processing job (2, 0, 2)
14:42:47 WORKER: args: ()
14:42:47 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0214753345369918, 'num_filters_1': 33, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.013674088130313638}, 'budget': 1200.0, 'working_directory': '.'}
14:42:57 DISPATCHER: Starting worker discovery
14:42:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:42:57 DISPATCHER: Finished worker discovery
14:43:57 DISPATCHER: Starting worker discovery
14:43:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:43:57 DISPATCHER: Finished worker discovery
14:44:57 DISPATCHER: Starting worker discovery
14:44:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:44:57 DISPATCHER: Finished worker discovery
14:45:57 DISPATCHER: Starting worker discovery
14:45:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:45:57 DISPATCHER: Finished worker discovery
14:46:57 DISPATCHER: Starting worker discovery
14:46:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:46:57 DISPATCHER: Finished worker discovery
14:47:57 DISPATCHER: Starting worker discovery
14:47:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:47:57 DISPATCHER: Finished worker discovery
14:48:57 DISPATCHER: Starting worker discovery
14:48:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:48:57 DISPATCHER: Finished worker discovery
14:49:57 DISPATCHER: Starting worker discovery
14:49:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:49:57 DISPATCHER: Finished worker discovery
14:50:57 DISPATCHER: Starting worker discovery
14:50:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:50:57 DISPATCHER: Finished worker discovery
14:51:57 DISPATCHER: Starting worker discovery
14:51:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:51:57 DISPATCHER: Finished worker discovery
14:52:57 DISPATCHER: Starting worker discovery
14:52:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:52:57 DISPATCHER: Finished worker discovery
14:53:57 DISPATCHER: Starting worker discovery
14:53:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:53:57 DISPATCHER: Finished worker discovery
14:54:57 DISPATCHER: Starting worker discovery
14:54:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:54:57 DISPATCHER: Finished worker discovery
14:55:57 DISPATCHER: Starting worker discovery
14:55:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:55:57 DISPATCHER: Finished worker discovery
14:56:57 DISPATCHER: Starting worker discovery
14:56:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:56:57 DISPATCHER: Finished worker discovery
14:57:57 DISPATCHER: Starting worker discovery
14:57:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:57:57 DISPATCHER: Finished worker discovery
14:58:57 DISPATCHER: Starting worker discovery
14:58:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:58:57 DISPATCHER: Finished worker discovery
14:59:57 DISPATCHER: Starting worker discovery
14:59:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:59:57 DISPATCHER: Finished worker discovery
15:00:57 DISPATCHER: Starting worker discovery
15:00:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:00:57 DISPATCHER: Finished worker discovery
15:01:57 DISPATCHER: Starting worker discovery
15:01:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:01:57 DISPATCHER: Finished worker discovery
15:02:57 DISPATCHER: Starting worker discovery
15:02:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:02:57 DISPATCHER: Finished worker discovery
15:03:57 DISPATCHER: Starting worker discovery
15:03:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:03:58 DISPATCHER: Finished worker discovery
15:04:21 WORKER: done with job (2, 0, 2), trying to register it.
15:04:21 WORKER: registered result for job (2, 0, 2) with dispatcher
15:04:21 DISPATCHER: job (2, 0, 2) finished
15:04:21 DISPATCHER: register_result: lock acquired
15:04:21 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
15:04:21 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0214753345369918, 'num_filters_1': 33, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.013674088130313638}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.24733985414618298, 'info': {'sick_no_sick': 0.24733985414618298, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0214753345369918, 'num_filters_1': 33, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.013674088130313638}"}}
exception: None

15:04:21 job_callback for (2, 0, 2) started
15:04:21 DISPATCHER: Trying to submit another job.
15:04:21 job_callback for (2, 0, 2) got condition
15:04:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:04:21 Only 4 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
15:04:21 HBMASTER: Trying to run another job!
15:04:21 job_callback for (2, 0, 2) finished
15:04:21 start sampling a new configuration.
15:04:21 done sampling a new configuration.
15:04:21 HBMASTER: schedule new run for iteration 3
15:04:21 HBMASTER: trying submitting job (3, 0, 0) to dispatcher
15:04:21 HBMASTER: submitting job (3, 0, 0) to dispatcher
15:04:21 DISPATCHER: trying to submit job (3, 0, 0)
15:04:21 DISPATCHER: trying to notify the job_runner thread.
15:04:21 HBMASTER: job (3, 0, 0) submitted to dispatcher
15:04:21 DISPATCHER: Trying to submit another job.
15:04:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:04:21 DISPATCHER: starting job (3, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
15:04:21 DISPATCHER: job (3, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
15:04:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:04:21 WORKER: start processing job (3, 0, 0)
15:04:21 WORKER: args: ()
15:04:21 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.006885807556420582, 'num_filters_1': 17, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.013535339460799437}, 'budget': 1200.0, 'working_directory': '.'}
15:04:58 DISPATCHER: Starting worker discovery
15:04:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:04:58 DISPATCHER: Finished worker discovery
15:05:58 DISPATCHER: Starting worker discovery
15:05:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:05:58 DISPATCHER: Finished worker discovery
15:06:58 DISPATCHER: Starting worker discovery
15:06:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:06:58 DISPATCHER: Finished worker discovery
15:07:58 DISPATCHER: Starting worker discovery
15:07:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:07:58 DISPATCHER: Finished worker discovery
15:08:58 DISPATCHER: Starting worker discovery
15:08:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:08:58 DISPATCHER: Finished worker discovery
15:09:58 DISPATCHER: Starting worker discovery
15:09:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:09:58 DISPATCHER: Finished worker discovery
15:10:58 DISPATCHER: Starting worker discovery
15:10:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:10:58 DISPATCHER: Finished worker discovery
15:11:58 DISPATCHER: Starting worker discovery
15:11:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:11:58 DISPATCHER: Finished worker discovery
15:12:58 DISPATCHER: Starting worker discovery
15:12:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:12:58 DISPATCHER: Finished worker discovery
15:13:58 DISPATCHER: Starting worker discovery
15:13:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:13:58 DISPATCHER: Finished worker discovery
15:14:58 DISPATCHER: Starting worker discovery
15:14:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:14:58 DISPATCHER: Finished worker discovery
15:15:58 DISPATCHER: Starting worker discovery
15:15:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:15:58 DISPATCHER: Finished worker discovery
15:16:58 DISPATCHER: Starting worker discovery
15:16:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:16:58 DISPATCHER: Finished worker discovery
15:17:58 DISPATCHER: Starting worker discovery
15:17:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:17:58 DISPATCHER: Finished worker discovery
15:18:58 DISPATCHER: Starting worker discovery
15:18:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:18:58 DISPATCHER: Finished worker discovery
15:19:58 DISPATCHER: Starting worker discovery
15:19:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:19:58 DISPATCHER: Finished worker discovery
15:20:58 DISPATCHER: Starting worker discovery
15:20:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:20:58 DISPATCHER: Finished worker discovery
15:21:58 DISPATCHER: Starting worker discovery
15:21:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:21:58 DISPATCHER: Finished worker discovery
15:22:58 DISPATCHER: Starting worker discovery
15:22:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:22:58 DISPATCHER: Finished worker discovery
15:23:58 DISPATCHER: Starting worker discovery
15:23:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:23:58 DISPATCHER: Finished worker discovery
15:24:58 DISPATCHER: Starting worker discovery
15:24:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:24:58 DISPATCHER: Finished worker discovery
15:25:45 WORKER: done with job (3, 0, 0), trying to register it.
15:25:45 WORKER: registered result for job (3, 0, 0) with dispatcher
15:25:45 DISPATCHER: job (3, 0, 0) finished
15:25:45 DISPATCHER: register_result: lock acquired
15:25:45 DISPATCHER: job (3, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
15:25:45 job_id: (3, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.006885807556420582, 'num_filters_1': 17, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.013535339460799437}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.3432711799579355, 'info': {'sick_no_sick': 0.3432711799579355, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.006885807556420582, 'num_filters_1': 17, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.013535339460799437}"}}
exception: None

15:25:45 job_callback for (3, 0, 0) started
15:25:45 DISPATCHER: Trying to submit another job.
15:25:45 job_callback for (3, 0, 0) got condition
15:25:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:25:45 Only 5 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
15:25:45 HBMASTER: Trying to run another job!
15:25:45 job_callback for (3, 0, 0) finished
15:25:45 start sampling a new configuration.
15:25:45 done sampling a new configuration.
15:25:45 HBMASTER: schedule new run for iteration 3
15:25:45 HBMASTER: trying submitting job (3, 0, 1) to dispatcher
15:25:45 HBMASTER: submitting job (3, 0, 1) to dispatcher
15:25:45 DISPATCHER: trying to submit job (3, 0, 1)
15:25:45 DISPATCHER: trying to notify the job_runner thread.
15:25:45 HBMASTER: job (3, 0, 1) submitted to dispatcher
15:25:45 DISPATCHER: Trying to submit another job.
15:25:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:25:45 DISPATCHER: starting job (3, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
15:25:45 DISPATCHER: job (3, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
15:25:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:25:45 WORKER: start processing job (3, 0, 1)
15:25:45 WORKER: args: ()
15:25:45 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.003563876695035518, 'num_filters_1': 24, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.11649933709658887}, 'budget': 1200.0, 'working_directory': '.'}
15:25:58 DISPATCHER: Starting worker discovery
15:25:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:25:58 DISPATCHER: Finished worker discovery
15:26:58 DISPATCHER: Starting worker discovery
15:26:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:26:58 DISPATCHER: Finished worker discovery
15:27:58 DISPATCHER: Starting worker discovery
15:27:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:27:58 DISPATCHER: Finished worker discovery
15:28:58 DISPATCHER: Starting worker discovery
15:28:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:28:58 DISPATCHER: Finished worker discovery
15:29:58 DISPATCHER: Starting worker discovery
15:29:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:29:58 DISPATCHER: Finished worker discovery
15:30:58 DISPATCHER: Starting worker discovery
15:30:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:30:58 DISPATCHER: Finished worker discovery
15:31:58 DISPATCHER: Starting worker discovery
15:31:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:31:58 DISPATCHER: Finished worker discovery
15:32:58 DISPATCHER: Starting worker discovery
15:32:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:32:58 DISPATCHER: Finished worker discovery
15:33:58 DISPATCHER: Starting worker discovery
15:33:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:33:58 DISPATCHER: Finished worker discovery
15:34:58 DISPATCHER: Starting worker discovery
15:34:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:34:58 DISPATCHER: Finished worker discovery
15:35:58 DISPATCHER: Starting worker discovery
15:35:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:35:58 DISPATCHER: Finished worker discovery
15:36:58 DISPATCHER: Starting worker discovery
15:36:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:36:58 DISPATCHER: Finished worker discovery
15:37:58 DISPATCHER: Starting worker discovery
15:37:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:37:58 DISPATCHER: Finished worker discovery
15:38:58 DISPATCHER: Starting worker discovery
15:38:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:38:58 DISPATCHER: Finished worker discovery
15:39:58 DISPATCHER: Starting worker discovery
15:39:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:39:58 DISPATCHER: Finished worker discovery
15:40:58 DISPATCHER: Starting worker discovery
15:40:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:40:58 DISPATCHER: Finished worker discovery
15:41:58 DISPATCHER: Starting worker discovery
15:41:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:41:58 DISPATCHER: Finished worker discovery
15:42:58 DISPATCHER: Starting worker discovery
15:42:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:42:58 DISPATCHER: Finished worker discovery
15:43:58 DISPATCHER: Starting worker discovery
15:43:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:43:58 DISPATCHER: Finished worker discovery
15:44:58 DISPATCHER: Starting worker discovery
15:44:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:44:58 DISPATCHER: Finished worker discovery
15:45:58 DISPATCHER: Starting worker discovery
15:45:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:45:58 DISPATCHER: Finished worker discovery
15:46:58 DISPATCHER: Starting worker discovery
15:46:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:46:58 DISPATCHER: Finished worker discovery
15:47:13 WORKER: done with job (3, 0, 1), trying to register it.
15:47:13 WORKER: registered result for job (3, 0, 1) with dispatcher
15:47:13 DISPATCHER: job (3, 0, 1) finished
15:47:13 DISPATCHER: register_result: lock acquired
15:47:13 DISPATCHER: job (3, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
15:47:13 job_id: (3, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.003563876695035518, 'num_filters_1': 24, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.11649933709658887}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.33576871993733015, 'info': {'sick_no_sick': 0.33576871993733015, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.003563876695035518, 'num_filters_1': 24, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.11649933709658887}"}}
exception: None

15:47:13 job_callback for (3, 0, 1) started
15:47:13 job_callback for (3, 0, 1) got condition
15:47:13 DISPATCHER: Trying to submit another job.
15:47:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:47:13 Only 6 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
15:47:13 HBMASTER: Trying to run another job!
15:47:13 job_callback for (3, 0, 1) finished
15:47:13 start sampling a new configuration.
15:47:13 done sampling a new configuration.
15:47:13 HBMASTER: schedule new run for iteration 3
15:47:13 HBMASTER: trying submitting job (3, 0, 2) to dispatcher
15:47:13 HBMASTER: submitting job (3, 0, 2) to dispatcher
15:47:13 DISPATCHER: trying to submit job (3, 0, 2)
15:47:13 DISPATCHER: trying to notify the job_runner thread.
15:47:13 HBMASTER: job (3, 0, 2) submitted to dispatcher
15:47:13 DISPATCHER: Trying to submit another job.
15:47:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:47:13 DISPATCHER: starting job (3, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
15:47:13 DISPATCHER: job (3, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
15:47:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:47:13 WORKER: start processing job (3, 0, 2)
15:47:13 WORKER: args: ()
15:47:13 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.02365224229070913, 'num_filters_1': 54, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.013726013985095795}, 'budget': 1200.0, 'working_directory': '.'}
15:47:58 DISPATCHER: Starting worker discovery
15:47:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:47:58 DISPATCHER: Finished worker discovery
15:48:58 DISPATCHER: Starting worker discovery
15:48:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:48:58 DISPATCHER: Finished worker discovery
15:49:58 DISPATCHER: Starting worker discovery
15:49:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:49:58 DISPATCHER: Finished worker discovery
15:50:58 DISPATCHER: Starting worker discovery
15:50:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:50:58 DISPATCHER: Finished worker discovery
15:51:58 DISPATCHER: Starting worker discovery
15:51:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:51:58 DISPATCHER: Finished worker discovery
15:52:58 DISPATCHER: Starting worker discovery
15:52:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:52:58 DISPATCHER: Finished worker discovery
15:53:58 DISPATCHER: Starting worker discovery
15:53:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:53:58 DISPATCHER: Finished worker discovery
15:54:58 DISPATCHER: Starting worker discovery
15:54:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:54:58 DISPATCHER: Finished worker discovery
15:55:58 DISPATCHER: Starting worker discovery
15:55:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:55:58 DISPATCHER: Finished worker discovery
15:56:58 DISPATCHER: Starting worker discovery
15:56:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:56:58 DISPATCHER: Finished worker discovery
15:57:58 DISPATCHER: Starting worker discovery
15:57:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:57:58 DISPATCHER: Finished worker discovery
15:58:58 DISPATCHER: Starting worker discovery
15:58:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:58:58 DISPATCHER: Finished worker discovery
15:59:58 DISPATCHER: Starting worker discovery
15:59:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:59:58 DISPATCHER: Finished worker discovery
16:00:58 DISPATCHER: Starting worker discovery
16:00:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:00:58 DISPATCHER: Finished worker discovery
16:01:58 DISPATCHER: Starting worker discovery
16:01:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:01:58 DISPATCHER: Finished worker discovery
16:02:58 DISPATCHER: Starting worker discovery
16:02:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:02:58 DISPATCHER: Finished worker discovery
16:03:58 DISPATCHER: Starting worker discovery
16:03:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:03:58 DISPATCHER: Finished worker discovery
16:04:58 DISPATCHER: Starting worker discovery
16:04:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:04:58 DISPATCHER: Finished worker discovery
16:05:58 DISPATCHER: Starting worker discovery
16:05:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:05:58 DISPATCHER: Finished worker discovery
16:06:58 DISPATCHER: Starting worker discovery
16:06:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:06:58 DISPATCHER: Finished worker discovery
16:07:58 DISPATCHER: Starting worker discovery
16:07:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:07:58 DISPATCHER: Finished worker discovery
16:08:27 WORKER: done with job (3, 0, 2), trying to register it.
16:08:27 WORKER: registered result for job (3, 0, 2) with dispatcher
16:08:27 DISPATCHER: job (3, 0, 2) finished
16:08:27 DISPATCHER: register_result: lock acquired
16:08:27 DISPATCHER: job (3, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
16:08:27 job_id: (3, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.02365224229070913, 'num_filters_1': 54, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.013726013985095795}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.10730338351647684, 'info': {'sick_no_sick': 0.10730338351647684, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.02365224229070913, 'num_filters_1': 54, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.013726013985095795}"}}
exception: None

16:08:27 job_callback for (3, 0, 2) started
16:08:27 job_callback for (3, 0, 2) got condition
16:08:27 DISPATCHER: Trying to submit another job.
16:08:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:08:27 Only 7 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
16:08:27 HBMASTER: Trying to run another job!
16:08:27 job_callback for (3, 0, 2) finished
16:08:27 start sampling a new configuration.
16:08:27 done sampling a new configuration.
16:08:27 HBMASTER: schedule new run for iteration 3
16:08:27 HBMASTER: trying submitting job (3, 0, 3) to dispatcher
16:08:27 HBMASTER: submitting job (3, 0, 3) to dispatcher
16:08:27 DISPATCHER: trying to submit job (3, 0, 3)
16:08:27 DISPATCHER: trying to notify the job_runner thread.
16:08:27 HBMASTER: job (3, 0, 3) submitted to dispatcher
16:08:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:08:27 DISPATCHER: Trying to submit another job.
16:08:27 DISPATCHER: starting job (3, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:08:27 DISPATCHER: job (3, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:08:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:08:27 WORKER: start processing job (3, 0, 3)
16:08:27 WORKER: args: ()
16:08:27 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.007121354915152372, 'num_filters_1': 81, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.014473411962347658}, 'budget': 1200.0, 'working_directory': '.'}
16:08:58 DISPATCHER: Starting worker discovery
16:08:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:08:58 DISPATCHER: Finished worker discovery
16:09:58 DISPATCHER: Starting worker discovery
16:09:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:09:58 DISPATCHER: Finished worker discovery
16:10:58 DISPATCHER: Starting worker discovery
16:10:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:10:58 DISPATCHER: Finished worker discovery
16:11:58 DISPATCHER: Starting worker discovery
16:11:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:11:58 DISPATCHER: Finished worker discovery
16:12:58 DISPATCHER: Starting worker discovery
16:12:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:12:58 DISPATCHER: Finished worker discovery
16:13:58 DISPATCHER: Starting worker discovery
16:13:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:13:58 DISPATCHER: Finished worker discovery
16:14:58 DISPATCHER: Starting worker discovery
16:14:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:14:58 DISPATCHER: Finished worker discovery
16:15:58 DISPATCHER: Starting worker discovery
16:15:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:15:58 DISPATCHER: Finished worker discovery
16:16:58 DISPATCHER: Starting worker discovery
16:16:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:16:58 DISPATCHER: Finished worker discovery
16:17:58 DISPATCHER: Starting worker discovery
16:17:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:17:58 DISPATCHER: Finished worker discovery
16:18:58 DISPATCHER: Starting worker discovery
16:18:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:18:58 DISPATCHER: Finished worker discovery
16:19:58 DISPATCHER: Starting worker discovery
16:19:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:19:58 DISPATCHER: Finished worker discovery
16:20:58 DISPATCHER: Starting worker discovery
16:20:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:20:58 DISPATCHER: Finished worker discovery
16:21:58 DISPATCHER: Starting worker discovery
16:21:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:21:58 DISPATCHER: Finished worker discovery
16:22:58 DISPATCHER: Starting worker discovery
16:22:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:22:58 DISPATCHER: Finished worker discovery
16:23:58 DISPATCHER: Starting worker discovery
16:23:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:23:58 DISPATCHER: Finished worker discovery
16:24:58 DISPATCHER: Starting worker discovery
16:24:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:24:58 DISPATCHER: Finished worker discovery
16:25:58 DISPATCHER: Starting worker discovery
16:25:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:25:58 DISPATCHER: Finished worker discovery
16:26:58 DISPATCHER: Starting worker discovery
16:26:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:26:58 DISPATCHER: Finished worker discovery
16:27:58 DISPATCHER: Starting worker discovery
16:27:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:27:58 DISPATCHER: Finished worker discovery
16:28:58 DISPATCHER: Starting worker discovery
16:28:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:28:58 DISPATCHER: Finished worker discovery
16:29:58 DISPATCHER: Starting worker discovery
16:29:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:29:58 DISPATCHER: Finished worker discovery
16:30:39 WORKER: done with job (3, 0, 3), trying to register it.
16:30:39 WORKER: registered result for job (3, 0, 3) with dispatcher
16:30:39 DISPATCHER: job (3, 0, 3) finished
16:30:39 DISPATCHER: register_result: lock acquired
16:30:39 DISPATCHER: job (3, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
16:30:39 job_id: (3, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.007121354915152372, 'num_filters_1': 81, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.014473411962347658}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.436154444136977, 'info': {'sick_no_sick': 0.436154444136977, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.007121354915152372, 'num_filters_1': 81, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.014473411962347658}"}}
exception: None

16:30:39 job_callback for (3, 0, 3) started
16:30:39 DISPATCHER: Trying to submit another job.
16:30:39 job_callback for (3, 0, 3) got condition
16:30:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:30:39 Only 8 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
16:30:39 HBMASTER: Trying to run another job!
16:30:39 job_callback for (3, 0, 3) finished
16:30:39 start sampling a new configuration.
16:30:39 done sampling a new configuration.
16:30:39 HBMASTER: schedule new run for iteration 4
16:30:39 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
16:30:39 HBMASTER: submitting job (4, 0, 0) to dispatcher
16:30:39 DISPATCHER: trying to submit job (4, 0, 0)
16:30:39 DISPATCHER: trying to notify the job_runner thread.
16:30:39 HBMASTER: job (4, 0, 0) submitted to dispatcher
16:30:39 DISPATCHER: Trying to submit another job.
16:30:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:30:39 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:30:39 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:30:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:30:39 WORKER: start processing job (4, 0, 0)
16:30:39 WORKER: args: ()
16:30:39 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.04633255813014039, 'num_filters_1': 50, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.18139788320827152}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:30:58 DISPATCHER: Starting worker discovery
16:30:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:30:58 DISPATCHER: Finished worker discovery
16:31:58 DISPATCHER: Starting worker discovery
16:31:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:31:58 DISPATCHER: Finished worker discovery
16:32:26 WORKER: done with job (4, 0, 0), trying to register it.
16:32:26 WORKER: registered result for job (4, 0, 0) with dispatcher
16:32:26 DISPATCHER: job (4, 0, 0) finished
16:32:26 DISPATCHER: register_result: lock acquired
16:32:26 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
16:32:26 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.04633255813014039, 'num_filters_1': 50, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.18139788320827152}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.000956910822517929, 'info': {'sick_no_sick': 0.000956910822517929, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.04633255813014039, 'num_filters_1': 50, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.18139788320827152}"}}
exception: None

16:32:26 job_callback for (4, 0, 0) started
16:32:26 DISPATCHER: Trying to submit another job.
16:32:26 job_callback for (4, 0, 0) got condition
16:32:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:32:26 HBMASTER: Trying to run another job!
16:32:26 job_callback for (4, 0, 0) finished
16:32:26 start sampling a new configuration.
16:32:26 done sampling a new configuration.
16:32:26 HBMASTER: schedule new run for iteration 4
16:32:26 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
16:32:26 HBMASTER: submitting job (4, 0, 1) to dispatcher
16:32:26 DISPATCHER: trying to submit job (4, 0, 1)
16:32:26 DISPATCHER: trying to notify the job_runner thread.
16:32:26 HBMASTER: job (4, 0, 1) submitted to dispatcher
16:32:26 DISPATCHER: Trying to submit another job.
16:32:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:32:26 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:32:26 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:32:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:32:26 WORKER: start processing job (4, 0, 1)
16:32:26 WORKER: args: ()
16:32:26 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.021040066429554704, 'num_filters_1': 58, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.17423169381360362, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 27, 'num_filters_3': 72, 'num_filters_4': 91, 'num_filters_5': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:32:58 DISPATCHER: Starting worker discovery
16:32:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:32:58 DISPATCHER: Finished worker discovery
16:33:58 DISPATCHER: Starting worker discovery
16:33:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:33:58 DISPATCHER: Finished worker discovery
16:34:13 WORKER: done with job (4, 0, 1), trying to register it.
16:34:13 WORKER: registered result for job (4, 0, 1) with dispatcher
16:34:13 DISPATCHER: job (4, 0, 1) finished
16:34:13 DISPATCHER: register_result: lock acquired
16:34:13 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
16:34:13 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.021040066429554704, 'num_filters_1': 58, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.17423169381360362, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 27, 'num_filters_3': 72, 'num_filters_4': 91, 'num_filters_5': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.021040066429554704, 'num_filters_1': 58, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.17423169381360362, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 27, 'num_filters_3': 72, 'num_filters_4': 91, 'num_filters_5': 19}"}}
exception: None

16:34:13 job_callback for (4, 0, 1) started
16:34:13 DISPATCHER: Trying to submit another job.
16:34:13 job_callback for (4, 0, 1) got condition
16:34:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:34:13 HBMASTER: Trying to run another job!
16:34:13 job_callback for (4, 0, 1) finished
16:34:13 start sampling a new configuration.
16:34:13 done sampling a new configuration.
16:34:13 HBMASTER: schedule new run for iteration 4
16:34:13 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
16:34:13 HBMASTER: submitting job (4, 0, 2) to dispatcher
16:34:13 DISPATCHER: trying to submit job (4, 0, 2)
16:34:13 DISPATCHER: trying to notify the job_runner thread.
16:34:13 HBMASTER: job (4, 0, 2) submitted to dispatcher
16:34:13 DISPATCHER: Trying to submit another job.
16:34:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:34:13 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:34:13 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:34:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:34:13 WORKER: start processing job (4, 0, 2)
16:34:13 WORKER: args: ()
16:34:13 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.007898927492500398, 'num_filters_1': 98, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.028444837407532418, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 122, 'num_filters_3': 30}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:34:58 DISPATCHER: Starting worker discovery
16:34:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:34:58 DISPATCHER: Finished worker discovery
16:35:58 DISPATCHER: Starting worker discovery
16:35:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:35:58 DISPATCHER: Finished worker discovery
16:36:01 WORKER: done with job (4, 0, 2), trying to register it.
16:36:01 WORKER: registered result for job (4, 0, 2) with dispatcher
16:36:01 DISPATCHER: job (4, 0, 2) finished
16:36:01 DISPATCHER: register_result: lock acquired
16:36:01 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
16:36:01 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.007898927492500398, 'num_filters_1': 98, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.028444837407532418, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 122, 'num_filters_3': 30}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.007898927492500398, 'num_filters_1': 98, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.028444837407532418, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 122, 'num_filters_3': 30}"}}
exception: None

16:36:01 job_callback for (4, 0, 2) started
16:36:01 DISPATCHER: Trying to submit another job.
16:36:01 job_callback for (4, 0, 2) got condition
16:36:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:36:01 HBMASTER: Trying to run another job!
16:36:01 job_callback for (4, 0, 2) finished
16:36:01 start sampling a new configuration.
16:36:01 done sampling a new configuration.
16:36:01 HBMASTER: schedule new run for iteration 4
16:36:01 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
16:36:01 HBMASTER: submitting job (4, 0, 3) to dispatcher
16:36:01 DISPATCHER: trying to submit job (4, 0, 3)
16:36:01 DISPATCHER: trying to notify the job_runner thread.
16:36:01 HBMASTER: job (4, 0, 3) submitted to dispatcher
16:36:01 DISPATCHER: Trying to submit another job.
16:36:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:36:01 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:36:01 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:36:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:36:01 WORKER: start processing job (4, 0, 3)
16:36:01 WORKER: args: ()
16:36:01 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.012624155986469243, 'num_filters_1': 107, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.07605682339897438, 'kernel_size_2': 5, 'num_filters_2': 118}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:36:58 DISPATCHER: Starting worker discovery
16:36:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:36:58 DISPATCHER: Finished worker discovery
16:37:49 WORKER: done with job (4, 0, 3), trying to register it.
16:37:49 WORKER: registered result for job (4, 0, 3) with dispatcher
16:37:49 DISPATCHER: job (4, 0, 3) finished
16:37:49 DISPATCHER: register_result: lock acquired
16:37:49 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
16:37:49 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.012624155986469243, 'num_filters_1': 107, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.07605682339897438, 'kernel_size_2': 5, 'num_filters_2': 118}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.46974443803839483, 'info': {'sick_no_sick': 0.46974443803839483, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.012624155986469243, 'num_filters_1': 107, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.07605682339897438, 'kernel_size_2': 5, 'num_filters_2': 118}"}}
exception: None

16:37:49 job_callback for (4, 0, 3) started
16:37:49 job_callback for (4, 0, 3) got condition
16:37:49 DISPATCHER: Trying to submit another job.
16:37:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:37:49 HBMASTER: Trying to run another job!
16:37:49 job_callback for (4, 0, 3) finished
16:37:49 start sampling a new configuration.
16:37:49 done sampling a new configuration.
16:37:49 HBMASTER: schedule new run for iteration 4
16:37:49 HBMASTER: trying submitting job (4, 0, 4) to dispatcher
16:37:49 HBMASTER: submitting job (4, 0, 4) to dispatcher
16:37:49 DISPATCHER: trying to submit job (4, 0, 4)
16:37:49 DISPATCHER: trying to notify the job_runner thread.
16:37:49 HBMASTER: job (4, 0, 4) submitted to dispatcher
16:37:49 DISPATCHER: Trying to submit another job.
16:37:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:37:49 DISPATCHER: starting job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:37:49 DISPATCHER: job (4, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:37:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:37:49 WORKER: start processing job (4, 0, 4)
16:37:49 WORKER: args: ()
16:37:49 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.022457529216308232, 'num_filters_1': 30, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.07414087771659601, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 75, 'num_filters_3': 22, 'num_filters_4': 92, 'num_filters_5': 30}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:37:58 DISPATCHER: Starting worker discovery
16:37:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:37:58 DISPATCHER: Finished worker discovery
16:38:58 DISPATCHER: Starting worker discovery
16:38:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:38:58 DISPATCHER: Finished worker discovery
16:39:37 WORKER: done with job (4, 0, 4), trying to register it.
16:39:37 WORKER: registered result for job (4, 0, 4) with dispatcher
16:39:37 DISPATCHER: job (4, 0, 4) finished
16:39:37 DISPATCHER: register_result: lock acquired
16:39:37 DISPATCHER: job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
16:39:37 job_id: (4, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.022457529216308232, 'num_filters_1': 30, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.07414087771659601, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 75, 'num_filters_3': 22, 'num_filters_4': 92, 'num_filters_5': 30}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.49395189501855624, 'info': {'sick_no_sick': 0.49395189501855624, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.022457529216308232, 'num_filters_1': 30, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.07414087771659601, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 75, 'num_filters_3': 22, 'num_filters_4': 92, 'num_filters_5': 30}"}}
exception: None

16:39:37 job_callback for (4, 0, 4) started
16:39:37 job_callback for (4, 0, 4) got condition
16:39:37 DISPATCHER: Trying to submit another job.
16:39:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:39:37 HBMASTER: Trying to run another job!
16:39:37 job_callback for (4, 0, 4) finished
16:39:37 start sampling a new configuration.
16:39:37 done sampling a new configuration.
16:39:37 HBMASTER: schedule new run for iteration 4
16:39:37 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
16:39:37 HBMASTER: submitting job (4, 0, 5) to dispatcher
16:39:37 DISPATCHER: trying to submit job (4, 0, 5)
16:39:37 DISPATCHER: trying to notify the job_runner thread.
16:39:37 HBMASTER: job (4, 0, 5) submitted to dispatcher
16:39:37 DISPATCHER: Trying to submit another job.
16:39:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:39:37 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:39:37 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:39:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:39:37 WORKER: start processing job (4, 0, 5)
16:39:37 WORKER: args: ()
16:39:37 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.002163510771883302, 'num_filters_1': 36, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.12998616154042805, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 47, 'num_filters_3': 106, 'num_filters_4': 62, 'num_filters_5': 122}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:39:58 DISPATCHER: Starting worker discovery
16:39:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:39:58 DISPATCHER: Finished worker discovery
16:40:58 DISPATCHER: Starting worker discovery
16:40:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:40:58 DISPATCHER: Finished worker discovery
16:41:27 WORKER: done with job (4, 0, 5), trying to register it.
16:41:27 WORKER: registered result for job (4, 0, 5) with dispatcher
16:41:27 DISPATCHER: job (4, 0, 5) finished
16:41:27 DISPATCHER: register_result: lock acquired
16:41:27 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
16:41:27 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.002163510771883302, 'num_filters_1': 36, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.12998616154042805, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 47, 'num_filters_3': 106, 'num_filters_4': 62, 'num_filters_5': 122}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.002163510771883302, 'num_filters_1': 36, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.12998616154042805, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 47, 'num_filters_3': 106, 'num_filters_4': 62, 'num_filters_5': 122}"}}
exception: None

16:41:27 job_callback for (4, 0, 5) started
16:41:27 DISPATCHER: Trying to submit another job.
16:41:27 job_callback for (4, 0, 5) got condition
16:41:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:41:27 HBMASTER: Trying to run another job!
16:41:27 job_callback for (4, 0, 5) finished
16:41:27 start sampling a new configuration.
16:41:27 done sampling a new configuration.
16:41:27 HBMASTER: schedule new run for iteration 4
16:41:27 HBMASTER: trying submitting job (4, 0, 6) to dispatcher
16:41:27 HBMASTER: submitting job (4, 0, 6) to dispatcher
16:41:27 DISPATCHER: trying to submit job (4, 0, 6)
16:41:27 DISPATCHER: trying to notify the job_runner thread.
16:41:27 HBMASTER: job (4, 0, 6) submitted to dispatcher
16:41:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:41:27 DISPATCHER: Trying to submit another job.
16:41:27 DISPATCHER: starting job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:41:27 DISPATCHER: job (4, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:41:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:41:27 WORKER: start processing job (4, 0, 6)
16:41:27 WORKER: args: ()
16:41:27 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0012314966090417859, 'num_filters_1': 53, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.01428435005167114}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:41:58 DISPATCHER: Starting worker discovery
16:41:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:41:58 DISPATCHER: Finished worker discovery
16:42:58 DISPATCHER: Starting worker discovery
16:42:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:42:58 DISPATCHER: Finished worker discovery
16:43:14 WORKER: done with job (4, 0, 6), trying to register it.
16:43:14 WORKER: registered result for job (4, 0, 6) with dispatcher
16:43:14 DISPATCHER: job (4, 0, 6) finished
16:43:14 DISPATCHER: register_result: lock acquired
16:43:14 DISPATCHER: job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
16:43:14 job_id: (4, 0, 6)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0012314966090417859, 'num_filters_1': 53, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.01428435005167114}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.43214987232917884, 'info': {'sick_no_sick': 0.43214987232917884, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0012314966090417859, 'num_filters_1': 53, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.01428435005167114}"}}
exception: None

16:43:14 job_callback for (4, 0, 6) started
16:43:14 DISPATCHER: Trying to submit another job.
16:43:14 job_callback for (4, 0, 6) got condition
16:43:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:43:14 done building a new model for budget 44.444444 based on 17/28 split
Best loss for this budget:-0.640658





16:43:14 HBMASTER: Trying to run another job!
16:43:14 job_callback for (4, 0, 6) finished
16:43:14 start sampling a new configuration.
16:43:14 best_vector: [3, 2, 0.9183534715640029, 0.925483004203547, 0.3970503963773361, 1, 0.18256982376592185, 0.23276911263074918, 1, 2, 2, 2, 0.6823503057325514, 0.4293982888023958, 0.32939217185614844, 0.14513398645933107], 0.0052379763640370445, 0.0009239147367289311, 4.83944355337165e-06
16:43:14 done sampling a new configuration.
16:43:14 HBMASTER: schedule new run for iteration 4
16:43:14 HBMASTER: trying submitting job (4, 0, 7) to dispatcher
16:43:14 HBMASTER: submitting job (4, 0, 7) to dispatcher
16:43:14 DISPATCHER: trying to submit job (4, 0, 7)
16:43:14 DISPATCHER: trying to notify the job_runner thread.
16:43:14 HBMASTER: job (4, 0, 7) submitted to dispatcher
16:43:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:43:14 DISPATCHER: Trying to submit another job.
16:43:14 DISPATCHER: starting job (4, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:43:14 DISPATCHER: job (4, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:43:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:43:14 WORKER: start processing job (4, 0, 7)
16:43:14 WORKER: args: ()
16:43:14 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.06866049706007867, 'num_filters_1': 110, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.02008350910917672, 'kernel_size_2': 5, 'num_filters_2': 66}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:43:58 DISPATCHER: Starting worker discovery
16:43:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:43:58 DISPATCHER: Finished worker discovery
16:44:58 DISPATCHER: Starting worker discovery
16:44:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:44:58 DISPATCHER: Finished worker discovery
16:45:03 WORKER: done with job (4, 0, 7), trying to register it.
16:45:03 WORKER: registered result for job (4, 0, 7) with dispatcher
16:45:03 DISPATCHER: job (4, 0, 7) finished
16:45:03 DISPATCHER: register_result: lock acquired
16:45:03 DISPATCHER: job (4, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
16:45:03 job_id: (4, 0, 7)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.06866049706007867, 'num_filters_1': 110, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.02008350910917672, 'kernel_size_2': 5, 'num_filters_2': 66}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.23413400163357992, 'info': {'sick_no_sick': 0.23413400163357992, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.06866049706007867, 'num_filters_1': 110, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.02008350910917672, 'kernel_size_2': 5, 'num_filters_2': 66}"}}
exception: None

16:45:03 job_callback for (4, 0, 7) started
16:45:03 DISPATCHER: Trying to submit another job.
16:45:03 job_callback for (4, 0, 7) got condition
16:45:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:45:03 done building a new model for budget 44.444444 based on 17/29 split
Best loss for this budget:-0.640658





16:45:03 HBMASTER: Trying to run another job!
16:45:03 job_callback for (4, 0, 7) finished
16:45:03 start sampling a new configuration.
16:45:03 best_vector: [1, 0, 0.648735930366086, 0.11292753084736462, 0.19297271984137898, 1, 0.6589442723976917, 0.22003195208873372, 2, 1, 2, 1, 0.7153174181462091, 0.04673397306017571, 0.8157937737147671, 0.43366209606888767], 0.0016686135007158733, 0.0021929064599197417, 3.659113324829133e-06
16:45:03 done sampling a new configuration.
16:45:03 HBMASTER: schedule new run for iteration 4
16:45:03 HBMASTER: trying submitting job (4, 0, 8) to dispatcher
16:45:03 HBMASTER: submitting job (4, 0, 8) to dispatcher
16:45:03 DISPATCHER: trying to submit job (4, 0, 8)
16:45:03 DISPATCHER: trying to notify the job_runner thread.
16:45:03 HBMASTER: job (4, 0, 8) submitted to dispatcher
16:45:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:45:03 DISPATCHER: Trying to submit another job.
16:45:03 DISPATCHER: starting job (4, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:45:03 DISPATCHER: job (4, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:45:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:45:03 WORKER: start processing job (4, 0, 8)
16:45:03 WORKER: args: ()
16:45:03 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.019836811239051694, 'num_filters_1': 20, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.019331616439458903}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:45:58 DISPATCHER: Starting worker discovery
16:45:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:45:58 DISPATCHER: Finished worker discovery
16:46:48 WORKER: done with job (4, 0, 8), trying to register it.
16:46:48 WORKER: registered result for job (4, 0, 8) with dispatcher
16:46:48 DISPATCHER: job (4, 0, 8) finished
16:46:48 DISPATCHER: register_result: lock acquired
16:46:48 DISPATCHER: job (4, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
16:46:48 job_id: (4, 0, 8)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.019836811239051694, 'num_filters_1': 20, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.019331616439458903}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.40251233527591257, 'info': {'sick_no_sick': 0.40251233527591257, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.019836811239051694, 'num_filters_1': 20, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.019331616439458903}"}}
exception: None

16:46:48 job_callback for (4, 0, 8) started
16:46:48 job_callback for (4, 0, 8) got condition
16:46:48 DISPATCHER: Trying to submit another job.
16:46:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:46:49 done building a new model for budget 44.444444 based on 17/30 split
Best loss for this budget:-0.640658





16:46:49 HBMASTER: Trying to run another job!
16:46:49 job_callback for (4, 0, 8) finished
16:46:49 start sampling a new configuration.
16:46:49 done sampling a new configuration.
16:46:49 HBMASTER: schedule new run for iteration 4
16:46:49 HBMASTER: trying submitting job (4, 0, 9) to dispatcher
16:46:49 HBMASTER: submitting job (4, 0, 9) to dispatcher
16:46:49 DISPATCHER: trying to submit job (4, 0, 9)
16:46:49 DISPATCHER: trying to notify the job_runner thread.
16:46:49 HBMASTER: job (4, 0, 9) submitted to dispatcher
16:46:49 DISPATCHER: Trying to submit another job.
16:46:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:46:49 DISPATCHER: starting job (4, 0, 9) on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:46:49 DISPATCHER: job (4, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:46:49 WORKER: start processing job (4, 0, 9)
16:46:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:46:49 WORKER: args: ()
16:46:49 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.005238356598403305, 'num_filters_1': 94, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.13605557712680014, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 91, 'num_filters_3': 80, 'num_filters_4': 35, 'num_filters_5': 101}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:46:58 DISPATCHER: Starting worker discovery
16:46:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:46:59 DISPATCHER: Finished worker discovery
16:47:59 DISPATCHER: Starting worker discovery
16:47:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:47:59 DISPATCHER: Finished worker discovery
16:48:36 WORKER: done with job (4, 0, 9), trying to register it.
16:48:36 WORKER: registered result for job (4, 0, 9) with dispatcher
16:48:36 DISPATCHER: job (4, 0, 9) finished
16:48:36 DISPATCHER: register_result: lock acquired
16:48:36 DISPATCHER: job (4, 0, 9) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
16:48:36 job_id: (4, 0, 9)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.005238356598403305, 'num_filters_1': 94, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.13605557712680014, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 91, 'num_filters_3': 80, 'num_filters_4': 35, 'num_filters_5': 101}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.01937327550750053, 'info': {'sick_no_sick': 0.01937327550750053, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.005238356598403305, 'num_filters_1': 94, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.13605557712680014, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 91, 'num_filters_3': 80, 'num_filters_4': 35, 'num_filters_5': 101}"}}
exception: None

16:48:36 job_callback for (4, 0, 9) started
16:48:36 DISPATCHER: Trying to submit another job.
16:48:36 job_callback for (4, 0, 9) got condition
16:48:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:48:36 done building a new model for budget 44.444444 based on 17/31 split
Best loss for this budget:-0.640658





16:48:36 HBMASTER: Trying to run another job!
16:48:36 job_callback for (4, 0, 9) finished
16:48:36 start sampling a new configuration.
16:48:36 best_vector: [2, 2, 0.943890224270328, 0.15024810049488785, 0.80582933323676, 1, 0.24072057975461925, 0.12216001538918311, 1, 1, 2, 2, 0.012464981552845006, 0.6617409253451595, 0.8098752593761104, 0.3548935582407569], 0.0013546956341798323, 0.001829420234285475, 2.478307604466779e-06
16:48:36 done sampling a new configuration.
16:48:36 HBMASTER: schedule new run for iteration 4
16:48:36 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
16:48:36 HBMASTER: submitting job (4, 0, 10) to dispatcher
16:48:36 DISPATCHER: trying to submit job (4, 0, 10)
16:48:36 DISPATCHER: trying to notify the job_runner thread.
16:48:36 HBMASTER: job (4, 0, 10) submitted to dispatcher
16:48:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:48:36 DISPATCHER: Trying to submit another job.
16:48:36 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:48:36 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:48:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:48:36 WORKER: start processing job (4, 0, 10)
16:48:36 WORKER: args: ()
16:48:36 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.07722900660262609, 'num_filters_1': 21, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.014418956920544432, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 16, 'num_filters_3': 63, 'num_filters_4': 86, 'num_filters_5': 33}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:48:59 DISPATCHER: Starting worker discovery
16:48:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:48:59 DISPATCHER: Finished worker discovery
16:49:59 DISPATCHER: Starting worker discovery
16:49:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:49:59 DISPATCHER: Finished worker discovery
16:50:22 WORKER: done with job (4, 0, 10), trying to register it.
16:50:22 WORKER: registered result for job (4, 0, 10) with dispatcher
16:50:22 DISPATCHER: job (4, 0, 10) finished
16:50:22 DISPATCHER: register_result: lock acquired
16:50:22 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
16:50:22 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.07722900660262609, 'num_filters_1': 21, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.014418956920544432, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 16, 'num_filters_3': 63, 'num_filters_4': 86, 'num_filters_5': 33}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5966064700197566, 'info': {'sick_no_sick': 0.5966064700197566, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.07722900660262609, 'num_filters_1': 21, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.014418956920544432, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 16, 'num_filters_3': 63, 'num_filters_4': 86, 'num_filters_5': 33}"}}
exception: None

16:50:22 job_callback for (4, 0, 10) started
16:50:22 job_callback for (4, 0, 10) got condition
16:50:22 DISPATCHER: Trying to submit another job.
16:50:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:50:22 done building a new model for budget 44.444444 based on 17/32 split
Best loss for this budget:-0.640658





16:50:22 HBMASTER: Trying to run another job!
16:50:22 job_callback for (4, 0, 10) finished
16:50:22 start sampling a new configuration.
16:50:22 best_vector: [3, 1, 0.04759440738348272, 0.09678511156484726, 0.8068541349439124, 1, 0.309863984622833, 0.017407910437808927, 1, 1, 2, 2, 0.9369713434462985, 0.21087076486730083, 0.550521080842285, 0.5731453000453673], 0.0024936032290548047, 0.00018113087490798755, 4.5166853455207966e-07
16:50:22 done sampling a new configuration.
16:50:22 HBMASTER: schedule new run for iteration 4
16:50:22 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
16:50:22 HBMASTER: submitting job (4, 0, 11) to dispatcher
16:50:22 DISPATCHER: trying to submit job (4, 0, 11)
16:50:22 DISPATCHER: trying to notify the job_runner thread.
16:50:22 HBMASTER: job (4, 0, 11) submitted to dispatcher
16:50:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:50:22 DISPATCHER: Trying to submit another job.
16:50:22 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:50:22 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:50:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:50:22 WORKER: start processing job (4, 0, 11)
16:50:22 WORKER: args: ()
16:50:22 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.001245055797152259, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.01053533169813305, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 112, 'num_filters_3': 24, 'num_filters_4': 50, 'num_filters_5': 52}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:50:59 DISPATCHER: Starting worker discovery
16:50:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:50:59 DISPATCHER: Finished worker discovery
16:51:59 DISPATCHER: Starting worker discovery
16:51:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:51:59 DISPATCHER: Finished worker discovery
16:52:08 WORKER: done with job (4, 0, 11), trying to register it.
16:52:08 WORKER: registered result for job (4, 0, 11) with dispatcher
16:52:08 DISPATCHER: job (4, 0, 11) finished
16:52:08 DISPATCHER: register_result: lock acquired
16:52:08 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
16:52:08 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.001245055797152259, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.01053533169813305, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 112, 'num_filters_3': 24, 'num_filters_4': 50, 'num_filters_5': 52}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5160334072464423, 'info': {'sick_no_sick': 0.5160334072464423, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.001245055797152259, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.01053533169813305, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 112, 'num_filters_3': 24, 'num_filters_4': 50, 'num_filters_5': 52}"}}
exception: None

16:52:08 job_callback for (4, 0, 11) started
16:52:08 DISPATCHER: Trying to submit another job.
16:52:08 job_callback for (4, 0, 11) got condition
16:52:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:52:08 done building a new model for budget 44.444444 based on 17/33 split
Best loss for this budget:-0.640658





16:52:08 HBMASTER: Trying to run another job!
16:52:08 job_callback for (4, 0, 11) finished
16:52:08 start sampling a new configuration.
16:52:09 best_vector: [0, 2, 0.2982062302581041, 0.8907957377447678, 0.6658733235355659, 1, 0.02997345990230446, 0.017198748011634457, 2, 2, 1, 2, 0.36129156902311865, 0.0498097943342814, 0.10136359702561071, 0.518111929979144], 0.0010335732101645393, 5.294485591739578e-05, 5.472238469224177e-08
16:52:09 done sampling a new configuration.
16:52:09 HBMASTER: schedule new run for iteration 4
16:52:09 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
16:52:09 HBMASTER: submitting job (4, 0, 12) to dispatcher
16:52:09 DISPATCHER: trying to submit job (4, 0, 12)
16:52:09 DISPATCHER: trying to notify the job_runner thread.
16:52:09 HBMASTER: job (4, 0, 12) submitted to dispatcher
16:52:09 DISPATCHER: Trying to submit another job.
16:52:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:52:09 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:52:09 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:52:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:52:09 WORKER: start processing job (4, 0, 12)
16:52:09 WORKER: args: ()
16:52:09 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.003948321061608176, 'num_filters_1': 102, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.010528732383623845, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 33, 'num_filters_3': 17, 'num_filters_4': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:52:59 DISPATCHER: Starting worker discovery
16:52:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:52:59 DISPATCHER: Finished worker discovery
16:53:58 WORKER: done with job (4, 0, 12), trying to register it.
16:53:58 WORKER: registered result for job (4, 0, 12) with dispatcher
16:53:58 DISPATCHER: job (4, 0, 12) finished
16:53:58 DISPATCHER: register_result: lock acquired
16:53:58 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
16:53:58 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.003948321061608176, 'num_filters_1': 102, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.010528732383623845, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 33, 'num_filters_3': 17, 'num_filters_4': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.40939744007577017, 'info': {'sick_no_sick': 0.40939744007577017, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.003948321061608176, 'num_filters_1': 102, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.010528732383623845, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 33, 'num_filters_3': 17, 'num_filters_4': 19}"}}
exception: None

16:53:58 job_callback for (4, 0, 12) started
16:53:58 job_callback for (4, 0, 12) got condition
16:53:58 DISPATCHER: Trying to submit another job.
16:53:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:53:58 done building a new model for budget 44.444444 based on 17/34 split
Best loss for this budget:-0.640658





16:53:58 HBMASTER: Trying to run another job!
16:53:58 job_callback for (4, 0, 12) finished
16:53:58 start sampling a new configuration.
16:53:58 best_vector: [0, 1, 0.3316708110276581, 0.6489721737575119, 0.8731489116940668, 1, 0.8605659418783387, 0.11387738520262669, 0, 2, 0, 0, 0.8788909257200745, 0.7865063149663444, 0.9227909160848821, 0.4338748711067022], 0.002418899220943443, 0.00034402274057891637, 8.321563391731691e-07
16:53:58 done sampling a new configuration.
16:53:58 HBMASTER: schedule new run for iteration 4
16:53:58 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
16:53:58 HBMASTER: submitting job (4, 0, 13) to dispatcher
16:53:58 DISPATCHER: trying to submit job (4, 0, 13)
16:53:58 DISPATCHER: trying to notify the job_runner thread.
16:53:58 HBMASTER: job (4, 0, 13) submitted to dispatcher
16:53:58 DISPATCHER: Trying to submit another job.
16:53:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:53:58 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:53:58 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:53:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:53:58 WORKER: start processing job (4, 0, 13)
16:53:58 WORKER: args: ()
16:53:58 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.004606187602094473, 'num_filters_1': 61, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.014065588057730005, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 99, 'num_filters_3': 82, 'num_filters_4': 109, 'num_filters_5': 39}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:53:59 DISPATCHER: Starting worker discovery
16:53:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:53:59 DISPATCHER: Finished worker discovery
16:54:59 DISPATCHER: Starting worker discovery
16:54:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:54:59 DISPATCHER: Finished worker discovery
16:55:46 WORKER: done with job (4, 0, 13), trying to register it.
16:55:46 WORKER: registered result for job (4, 0, 13) with dispatcher
16:55:46 DISPATCHER: job (4, 0, 13) finished
16:55:46 DISPATCHER: register_result: lock acquired
16:55:46 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
16:55:46 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.004606187602094473, 'num_filters_1': 61, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.014065588057730005, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 99, 'num_filters_3': 82, 'num_filters_4': 109, 'num_filters_5': 39}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5849513360960192, 'info': {'sick_no_sick': 0.5849513360960192, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.004606187602094473, 'num_filters_1': 61, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.014065588057730005, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 99, 'num_filters_3': 82, 'num_filters_4': 109, 'num_filters_5': 39}"}}
exception: None

16:55:46 job_callback for (4, 0, 13) started
16:55:46 DISPATCHER: Trying to submit another job.
16:55:46 job_callback for (4, 0, 13) got condition
16:55:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:55:46 done building a new model for budget 44.444444 based on 17/34 split
Best loss for this budget:-0.640658





16:55:46 HBMASTER: Trying to run another job!
16:55:46 job_callback for (4, 0, 13) finished
16:55:46 start sampling a new configuration.
16:55:46 best_vector: [2, 1, 0.04603002614003604, 0.9826882386624909, 0.603571790033574, 1, 0.9948249538824665, 0.19756341983615666, 1, 1, 1, 2, 0.44196247073715705, 0.8078783916605873, 0.6301063610311335, 0.26044228573798933], 0.006220941775706027, 0.0011459610341558162, 7.128956870711199e-06
16:55:46 done sampling a new configuration.
16:55:46 HBMASTER: schedule new run for iteration 4
16:55:46 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
16:55:46 HBMASTER: submitting job (4, 0, 14) to dispatcher
16:55:46 DISPATCHER: trying to submit job (4, 0, 14)
16:55:46 DISPATCHER: trying to notify the job_runner thread.
16:55:46 HBMASTER: job (4, 0, 14) submitted to dispatcher
16:55:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:55:46 DISPATCHER: Trying to submit another job.
16:55:46 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:55:46 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:55:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:55:46 WORKER: start processing job (4, 0, 14)
16:55:46 WORKER: args: ()
16:55:46 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0012361183464914434, 'num_filters_1': 124, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.018073236649726095, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 39, 'num_filters_3': 86, 'num_filters_4': 59}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:55:59 DISPATCHER: Starting worker discovery
16:55:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:55:59 DISPATCHER: Finished worker discovery
16:56:59 DISPATCHER: Starting worker discovery
16:56:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:56:59 DISPATCHER: Finished worker discovery
16:57:33 WORKER: done with job (4, 0, 14), trying to register it.
16:57:33 WORKER: registered result for job (4, 0, 14) with dispatcher
16:57:33 DISPATCHER: job (4, 0, 14) finished
16:57:33 DISPATCHER: register_result: lock acquired
16:57:33 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
16:57:33 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0012361183464914434, 'num_filters_1': 124, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.018073236649726095, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 39, 'num_filters_3': 86, 'num_filters_4': 59}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5269987152767307, 'info': {'sick_no_sick': 0.5269987152767307, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0012361183464914434, 'num_filters_1': 124, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.018073236649726095, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 39, 'num_filters_3': 86, 'num_filters_4': 59}"}}
exception: None

16:57:33 job_callback for (4, 0, 14) started
16:57:33 job_callback for (4, 0, 14) got condition
16:57:33 DISPATCHER: Trying to submit another job.
16:57:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:57:33 done building a new model for budget 44.444444 based on 17/35 split
Best loss for this budget:-0.640658





16:57:33 HBMASTER: Trying to run another job!
16:57:33 job_callback for (4, 0, 14) finished
16:57:33 start sampling a new configuration.
16:57:33 done sampling a new configuration.
16:57:33 HBMASTER: schedule new run for iteration 4
16:57:33 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
16:57:33 HBMASTER: submitting job (4, 0, 15) to dispatcher
16:57:33 DISPATCHER: trying to submit job (4, 0, 15)
16:57:33 DISPATCHER: trying to notify the job_runner thread.
16:57:33 HBMASTER: job (4, 0, 15) submitted to dispatcher
16:57:33 DISPATCHER: Trying to submit another job.
16:57:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:57:33 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:57:33 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:57:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:57:33 WORKER: start processing job (4, 0, 15)
16:57:33 WORKER: args: ()
16:57:33 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0015378825825955668, 'num_filters_1': 77, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.023157672993507378, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 18, 'num_filters_3': 55, 'num_filters_4': 44}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:57:59 DISPATCHER: Starting worker discovery
16:57:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:57:59 DISPATCHER: Finished worker discovery
16:58:59 DISPATCHER: Starting worker discovery
16:58:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:58:59 DISPATCHER: Finished worker discovery
16:59:22 WORKER: done with job (4, 0, 15), trying to register it.
16:59:22 WORKER: registered result for job (4, 0, 15) with dispatcher
16:59:22 DISPATCHER: job (4, 0, 15) finished
16:59:22 DISPATCHER: register_result: lock acquired
16:59:22 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
16:59:22 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0015378825825955668, 'num_filters_1': 77, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.023157672993507378, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 18, 'num_filters_3': 55, 'num_filters_4': 44}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5418565443847672, 'info': {'sick_no_sick': 0.5418565443847672, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0015378825825955668, 'num_filters_1': 77, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.023157672993507378, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 18, 'num_filters_3': 55, 'num_filters_4': 44}"}}
exception: None

16:59:22 job_callback for (4, 0, 15) started
16:59:22 job_callback for (4, 0, 15) got condition
16:59:22 DISPATCHER: Trying to submit another job.
16:59:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:59:22 done building a new model for budget 44.444444 based on 17/36 split
Best loss for this budget:-0.640658





16:59:22 HBMASTER: Trying to run another job!
16:59:22 job_callback for (4, 0, 15) finished
16:59:22 start sampling a new configuration.
16:59:22 best_vector: [0, 1, 0.11635528031044012, 0.2711162827181959, 0.9211494597274364, 1, 0.9450892652451592, 0.6580509988106273, 1, 1, 0, 0, 0.5251577011612514, 0.8290705241780315, 0.283150946041139, 0.48579969395026507], 0.004260686870112503, 0.00045998247828917373, 1.959841305728492e-06
16:59:22 done sampling a new configuration.
16:59:22 HBMASTER: schedule new run for iteration 4
16:59:22 HBMASTER: trying submitting job (4, 0, 16) to dispatcher
16:59:22 HBMASTER: submitting job (4, 0, 16) to dispatcher
16:59:22 DISPATCHER: trying to submit job (4, 0, 16)
16:59:22 DISPATCHER: trying to notify the job_runner thread.
16:59:22 HBMASTER: job (4, 0, 16) submitted to dispatcher
16:59:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:59:22 DISPATCHER: Trying to submit another job.
16:59:22 DISPATCHER: starting job (4, 0, 16) on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:59:22 DISPATCHER: job (4, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:59:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:59:22 WORKER: start processing job (4, 0, 16)
16:59:22 WORKER: args: ()
16:59:22 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0017088760400180655, 'num_filters_1': 28, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.07180324771103874, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 47, 'num_filters_3': 90, 'num_filters_4': 28, 'num_filters_5': 43}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:59:59 DISPATCHER: Starting worker discovery
16:59:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:59:59 DISPATCHER: Finished worker discovery
17:00:59 DISPATCHER: Starting worker discovery
17:00:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:00:59 DISPATCHER: Finished worker discovery
17:01:11 WORKER: done with job (4, 0, 16), trying to register it.
17:01:11 WORKER: registered result for job (4, 0, 16) with dispatcher
17:01:11 DISPATCHER: job (4, 0, 16) finished
17:01:11 DISPATCHER: register_result: lock acquired
17:01:11 DISPATCHER: job (4, 0, 16) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
17:01:11 job_id: (4, 0, 16)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0017088760400180655, 'num_filters_1': 28, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.07180324771103874, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 47, 'num_filters_3': 90, 'num_filters_4': 28, 'num_filters_5': 43}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.45342306624476497, 'info': {'sick_no_sick': 0.45342306624476497, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0017088760400180655, 'num_filters_1': 28, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.07180324771103874, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 47, 'num_filters_3': 90, 'num_filters_4': 28, 'num_filters_5': 43}"}}
exception: None

17:01:11 job_callback for (4, 0, 16) started
17:01:11 DISPATCHER: Trying to submit another job.
17:01:11 job_callback for (4, 0, 16) got condition
17:01:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:01:11 done building a new model for budget 44.444444 based on 17/37 split
Best loss for this budget:-0.640658





17:01:11 HBMASTER: Trying to run another job!
17:01:11 job_callback for (4, 0, 16) finished
17:01:11 start sampling a new configuration.
17:01:11 best_vector: [3, 1, 0.3751830291100519, 0.9225265968667948, 0.18282337605396448, 1, 0.04908350431788744, 0.36880556297496214, 0, 2, 1, 2, 0.05433707383083125, 0.5797258603410818, 0.8772649834275256, 0.569546983353908], 0.002471437593092143, 0.00016395883804654247, 4.0521403606793145e-07
17:01:11 done sampling a new configuration.
17:01:11 HBMASTER: schedule new run for iteration 4
17:01:11 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
17:01:11 HBMASTER: submitting job (4, 0, 17) to dispatcher
17:01:11 DISPATCHER: trying to submit job (4, 0, 17)
17:01:11 DISPATCHER: trying to notify the job_runner thread.
17:01:11 HBMASTER: job (4, 0, 17) submitted to dispatcher
17:01:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:01:11 DISPATCHER: Trying to submit another job.
17:01:11 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:01:11 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:01:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:01:11 WORKER: start processing job (4, 0, 17)
17:01:11 WORKER: args: ()
17:01:11 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.005628155113724307, 'num_filters_1': 109, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.030187496656782782}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:01:59 DISPATCHER: Starting worker discovery
17:01:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:01:59 DISPATCHER: Finished worker discovery
17:02:59 DISPATCHER: Starting worker discovery
17:02:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:02:59 DISPATCHER: Finished worker discovery
17:03:00 WORKER: done with job (4, 0, 17), trying to register it.
17:03:00 WORKER: registered result for job (4, 0, 17) with dispatcher
17:03:00 DISPATCHER: job (4, 0, 17) finished
17:03:00 DISPATCHER: register_result: lock acquired
17:03:00 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
17:03:00 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.005628155113724307, 'num_filters_1': 109, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.030187496656782782}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4624411939740329, 'info': {'sick_no_sick': 0.4624411939740329, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.005628155113724307, 'num_filters_1': 109, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.030187496656782782}"}}
exception: None

17:03:00 job_callback for (4, 0, 17) started
17:03:00 DISPATCHER: Trying to submit another job.
17:03:00 job_callback for (4, 0, 17) got condition
17:03:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:03:00 done building a new model for budget 44.444444 based on 17/38 split
Best loss for this budget:-0.640658





17:03:00 HBMASTER: Trying to run another job!
17:03:00 job_callback for (4, 0, 17) finished
17:03:00 start sampling a new configuration.
17:03:00 best_vector: [3, 1, 0.9705268290363464, 0.9862750488725072, 0.9977748224690126, 1, 0.10618919166666918, 0.315586367185015, 1, 1, 2, 1, 0.4602731906974787, 0.3130767793850775, 0.7782695817398217, 0.4325079918686641], 0.004440984500106324, 0.0008590853859355632, 3.815184883207696e-06
17:03:01 done sampling a new configuration.
17:03:01 HBMASTER: schedule new run for iteration 4
17:03:01 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
17:03:01 HBMASTER: submitting job (4, 0, 18) to dispatcher
17:03:01 DISPATCHER: trying to submit job (4, 0, 18)
17:03:01 DISPATCHER: trying to notify the job_runner thread.
17:03:01 HBMASTER: job (4, 0, 18) submitted to dispatcher
17:03:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:03:01 DISPATCHER: Trying to submit another job.
17:03:01 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:03:01 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:03:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:03:01 WORKER: start processing job (4, 0, 18)
17:03:01 WORKER: args: ()
17:03:01 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.08730792326528689, 'num_filters_1': 125, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.025738742788611626, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 41, 'num_filters_3': 30, 'num_filters_4': 80, 'num_filters_5': 39}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:03:59 DISPATCHER: Starting worker discovery
17:03:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:03:59 DISPATCHER: Finished worker discovery
17:04:49 WORKER: done with job (4, 0, 18), trying to register it.
17:04:49 WORKER: registered result for job (4, 0, 18) with dispatcher
17:04:49 DISPATCHER: job (4, 0, 18) finished
17:04:49 DISPATCHER: register_result: lock acquired
17:04:49 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
17:04:49 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.08730792326528689, 'num_filters_1': 125, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.025738742788611626, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 41, 'num_filters_3': 30, 'num_filters_4': 80, 'num_filters_5': 39}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4412275900550985, 'info': {'sick_no_sick': 0.4412275900550985, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.08730792326528689, 'num_filters_1': 125, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.025738742788611626, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 41, 'num_filters_3': 30, 'num_filters_4': 80, 'num_filters_5': 39}"}}
exception: None

17:04:49 job_callback for (4, 0, 18) started
17:04:49 DISPATCHER: Trying to submit another job.
17:04:49 job_callback for (4, 0, 18) got condition
17:04:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:04:49 done building a new model for budget 44.444444 based on 17/39 split
Best loss for this budget:-0.640658





17:04:49 HBMASTER: Trying to run another job!
17:04:49 job_callback for (4, 0, 18) finished
17:04:49 start sampling a new configuration.
17:04:49 best_vector: [0, 0, 0.21134189414125376, 0.3336343323799924, 0.9284986948396058, 1, 0.7966231367202675, 0.09412850895017011, 1, 2, 1, 1, 0.289028182267632, 0.13083031190637262, 0.07019233225494759, 0.40437910776946695], 0.003166875560387765, 0.00018173994739298783, 5.755477977450112e-07
17:04:49 done sampling a new configuration.
17:04:49 HBMASTER: schedule new run for iteration 4
17:04:49 HBMASTER: trying submitting job (4, 0, 19) to dispatcher
17:04:49 HBMASTER: submitting job (4, 0, 19) to dispatcher
17:04:49 DISPATCHER: trying to submit job (4, 0, 19)
17:04:49 DISPATCHER: trying to notify the job_runner thread.
17:04:49 HBMASTER: job (4, 0, 19) submitted to dispatcher
17:04:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:04:49 DISPATCHER: Trying to submit another job.
17:04:49 DISPATCHER: starting job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:04:49 DISPATCHER: job (4, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:04:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:04:49 WORKER: start processing job (4, 0, 19)
17:04:49 WORKER: args: ()
17:04:49 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002646572455899281, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.01325757258618368, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 29, 'num_filters_3': 20, 'num_filters_4': 18, 'num_filters_5': 36}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:04:59 DISPATCHER: Starting worker discovery
17:04:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:04:59 DISPATCHER: Finished worker discovery
17:05:59 DISPATCHER: Starting worker discovery
17:05:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:05:59 DISPATCHER: Finished worker discovery
17:06:37 WORKER: done with job (4, 0, 19), trying to register it.
17:06:37 WORKER: registered result for job (4, 0, 19) with dispatcher
17:06:37 DISPATCHER: job (4, 0, 19) finished
17:06:37 DISPATCHER: register_result: lock acquired
17:06:37 DISPATCHER: job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
17:06:37 job_id: (4, 0, 19)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002646572455899281, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.01325757258618368, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 29, 'num_filters_3': 20, 'num_filters_4': 18, 'num_filters_5': 36}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5804744946799966, 'info': {'sick_no_sick': 0.5804744946799966, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002646572455899281, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.01325757258618368, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 29, 'num_filters_3': 20, 'num_filters_4': 18, 'num_filters_5': 36}"}}
exception: None

17:06:37 job_callback for (4, 0, 19) started
17:06:37 DISPATCHER: Trying to submit another job.
17:06:37 job_callback for (4, 0, 19) got condition
17:06:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:06:37 done building a new model for budget 44.444444 based on 17/39 split
Best loss for this budget:-0.640658





17:06:37 HBMASTER: Trying to run another job!
17:06:37 job_callback for (4, 0, 19) finished
17:06:37 start sampling a new configuration.
17:06:37 best_vector: [0, 2, 0.4021315449264468, 0.2008403876796086, 0.044799343746179054, 0, 0.13022265914653225, 0.05733089146540314, 1, 2, 0, 2, 0.02336204815657497, 0.4445951120146421, 0.04538584384779509, 0.41036815803853127], 0.0004525097146909424, 0.0011796033017973967, 5.337819535448337e-07
17:06:37 done sampling a new configuration.
17:06:37 HBMASTER: schedule new run for iteration 4
17:06:37 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
17:06:37 HBMASTER: submitting job (4, 0, 20) to dispatcher
17:06:37 DISPATCHER: trying to submit job (4, 0, 20)
17:06:37 DISPATCHER: trying to notify the job_runner thread.
17:06:37 HBMASTER: job (4, 0, 20) submitted to dispatcher
17:06:37 DISPATCHER: Trying to submit another job.
17:06:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:06:37 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:06:37 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:06:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:06:37 WORKER: start processing job (4, 0, 20)
17:06:37 WORKER: args: ()
17:06:37 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0063718140008028525, 'num_filters_1': 24, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.011873785782861959}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:06:59 DISPATCHER: Starting worker discovery
17:06:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:06:59 DISPATCHER: Finished worker discovery
17:07:59 DISPATCHER: Starting worker discovery
17:07:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:07:59 DISPATCHER: Finished worker discovery
17:08:28 WORKER: done with job (4, 0, 20), trying to register it.
17:08:28 WORKER: registered result for job (4, 0, 20) with dispatcher
17:08:28 DISPATCHER: job (4, 0, 20) finished
17:08:28 DISPATCHER: register_result: lock acquired
17:08:28 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
17:08:28 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0063718140008028525, 'num_filters_1': 24, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.011873785782861959}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.43374995568437924, 'info': {'sick_no_sick': 0.43374995568437924, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0063718140008028525, 'num_filters_1': 24, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.011873785782861959}"}}
exception: None

17:08:28 job_callback for (4, 0, 20) started
17:08:28 DISPATCHER: Trying to submit another job.
17:08:28 job_callback for (4, 0, 20) got condition
17:08:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:08:28 done building a new model for budget 44.444444 based on 17/40 split
Best loss for this budget:-0.640658





17:08:28 HBMASTER: Trying to run another job!
17:08:28 job_callback for (4, 0, 20) finished
17:08:28 start sampling a new configuration.
17:08:28 done sampling a new configuration.
17:08:28 HBMASTER: schedule new run for iteration 4
17:08:28 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
17:08:28 HBMASTER: submitting job (4, 0, 21) to dispatcher
17:08:28 DISPATCHER: trying to submit job (4, 0, 21)
17:08:28 DISPATCHER: trying to notify the job_runner thread.
17:08:28 HBMASTER: job (4, 0, 21) submitted to dispatcher
17:08:28 DISPATCHER: Trying to submit another job.
17:08:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:08:28 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:08:28 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:08:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:08:28 WORKER: start processing job (4, 0, 21)
17:08:28 WORKER: args: ()
17:08:28 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.009624158038516226, 'num_filters_1': 53, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.12740602657558117, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 41, 'num_filters_3': 37, 'num_filters_4': 91}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:08:59 DISPATCHER: Starting worker discovery
17:08:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:08:59 DISPATCHER: Finished worker discovery
17:09:59 DISPATCHER: Starting worker discovery
17:09:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:09:59 DISPATCHER: Finished worker discovery
17:10:16 WORKER: done with job (4, 0, 21), trying to register it.
17:10:16 WORKER: registered result for job (4, 0, 21) with dispatcher
17:10:16 DISPATCHER: job (4, 0, 21) finished
17:10:16 DISPATCHER: register_result: lock acquired
17:10:16 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
17:10:16 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.009624158038516226, 'num_filters_1': 53, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.12740602657558117, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 41, 'num_filters_3': 37, 'num_filters_4': 91}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.009624158038516226, 'num_filters_1': 53, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.12740602657558117, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 41, 'num_filters_3': 37, 'num_filters_4': 91}"}}
exception: None

17:10:16 job_callback for (4, 0, 21) started
17:10:16 DISPATCHER: Trying to submit another job.
17:10:16 job_callback for (4, 0, 21) got condition
17:10:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:10:16 done building a new model for budget 44.444444 based on 17/41 split
Best loss for this budget:-0.640658





17:10:16 HBMASTER: Trying to run another job!
17:10:16 job_callback for (4, 0, 21) finished
17:10:16 start sampling a new configuration.
17:10:16 best_vector: [0, 2, 0.3671869643332761, 0.7889369550853942, 0.49390676587491766, 1, 0.9225590831271377, 0.07698214613774054, 0, 2, 0, 0, 0.9793725167163144, 0.9427677035053359, 0.9528079649912489, 0.5043184337937222], 0.003058834429241489, 0.0002209388798950656, 6.758154525810769e-07
17:10:16 done sampling a new configuration.
17:10:16 HBMASTER: schedule new run for iteration 4
17:10:16 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
17:10:16 HBMASTER: submitting job (4, 0, 22) to dispatcher
17:10:16 DISPATCHER: trying to submit job (4, 0, 22)
17:10:16 DISPATCHER: trying to notify the job_runner thread.
17:10:16 HBMASTER: job (4, 0, 22) submitted to dispatcher
17:10:16 DISPATCHER: Trying to submit another job.
17:10:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:10:16 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:10:16 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:10:16 WORKER: start processing job (4, 0, 22)
17:10:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:10:16 WORKER: args: ()
17:10:16 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.005424677555202626, 'num_filters_1': 82, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.012593779387793843, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 123, 'num_filters_3': 114}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:10:59 DISPATCHER: Starting worker discovery
17:10:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:10:59 DISPATCHER: Finished worker discovery
17:11:59 DISPATCHER: Starting worker discovery
17:11:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:11:59 DISPATCHER: Finished worker discovery
17:12:04 WORKER: done with job (4, 0, 22), trying to register it.
17:12:04 WORKER: registered result for job (4, 0, 22) with dispatcher
17:12:04 DISPATCHER: job (4, 0, 22) finished
17:12:04 DISPATCHER: register_result: lock acquired
17:12:04 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
17:12:04 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.005424677555202626, 'num_filters_1': 82, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.012593779387793843, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 123, 'num_filters_3': 114}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5048487440325419, 'info': {'sick_no_sick': 0.5048487440325419, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.005424677555202626, 'num_filters_1': 82, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.012593779387793843, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 123, 'num_filters_3': 114}"}}
exception: None

17:12:04 job_callback for (4, 0, 22) started
17:12:04 job_callback for (4, 0, 22) got condition
17:12:04 DISPATCHER: Trying to submit another job.
17:12:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:12:04 done building a new model for budget 44.444444 based on 17/42 split
Best loss for this budget:-0.640658





17:12:04 HBMASTER: Trying to run another job!
17:12:04 job_callback for (4, 0, 22) finished
17:12:04 start sampling a new configuration.
17:12:04 best_vector: [0, 0, 0.03713384409092992, 0.9637055753542099, 0.9411466000102502, 1, 0.12099737646730035, 0.07763639440626444, 1, 0, 0, 0, 0.7258616078070709, 0.3992589071287489, 0.12354320433926186, 0.4468290899933173], 0.002063879377391726, 0.000514769682322644, 1.0624225314521952e-06
17:12:04 done sampling a new configuration.
17:12:04 HBMASTER: schedule new run for iteration 4
17:12:04 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
17:12:04 HBMASTER: submitting job (4, 0, 23) to dispatcher
17:12:04 DISPATCHER: trying to submit job (4, 0, 23)
17:12:04 DISPATCHER: trying to notify the job_runner thread.
17:12:04 HBMASTER: job (4, 0, 23) submitted to dispatcher
17:12:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:12:04 DISPATCHER: Trying to submit another job.
17:12:04 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:12:04 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:12:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:12:04 WORKER: start processing job (4, 0, 23)
17:12:04 WORKER: args: ()
17:12:04 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0011864998514561408, 'num_filters_1': 119, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.012618486803888988, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 72, 'num_filters_3': 36, 'num_filters_4': 20, 'num_filters_5': 40}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:12:59 DISPATCHER: Starting worker discovery
17:12:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:12:59 DISPATCHER: Finished worker discovery
17:13:53 WORKER: done with job (4, 0, 23), trying to register it.
17:13:53 WORKER: registered result for job (4, 0, 23) with dispatcher
17:13:53 DISPATCHER: job (4, 0, 23) finished
17:13:53 DISPATCHER: register_result: lock acquired
17:13:53 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
17:13:53 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0011864998514561408, 'num_filters_1': 119, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.012618486803888988, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 72, 'num_filters_3': 36, 'num_filters_4': 20, 'num_filters_5': 40}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.41179189724044774, 'info': {'sick_no_sick': 0.41179189724044774, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0011864998514561408, 'num_filters_1': 119, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.012618486803888988, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 72, 'num_filters_3': 36, 'num_filters_4': 20, 'num_filters_5': 40}"}}
exception: None

17:13:53 job_callback for (4, 0, 23) started
17:13:53 job_callback for (4, 0, 23) got condition
17:13:53 DISPATCHER: Trying to submit another job.
17:13:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:13:53 done building a new model for budget 44.444444 based on 17/43 split
Best loss for this budget:-0.640658





17:13:53 HBMASTER: Trying to run another job!
17:13:53 job_callback for (4, 0, 23) finished
17:13:53 start sampling a new configuration.
17:13:53 best_vector: [0, 0, 0.11124659274024834, 0.5966119703134537, 0.7843855917662441, 1, 0.8645782443539458, 0.15851714424776814, 1, 2, 1, 1, 0.6651562241981817, 0.876728607826596, 0.8091982569476498, 0.4978309992333924], 0.0010762276768597821, 0.004777745912419481, 5.141942383949538e-06
17:13:53 done sampling a new configuration.
17:13:53 HBMASTER: schedule new run for iteration 4
17:13:53 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
17:13:53 HBMASTER: submitting job (4, 0, 24) to dispatcher
17:13:53 DISPATCHER: trying to submit job (4, 0, 24)
17:13:53 DISPATCHER: trying to notify the job_runner thread.
17:13:53 HBMASTER: job (4, 0, 24) submitted to dispatcher
17:13:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:13:53 DISPATCHER: Trying to submit another job.
17:13:53 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:13:53 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:13:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:13:53 WORKER: start processing job (4, 0, 24)
17:13:53 WORKER: args: ()
17:13:53 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0016691416164860738, 'num_filters_1': 55, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.01607813087582132, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 63, 'num_filters_3': 99, 'num_filters_4': 86}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:13:59 DISPATCHER: Starting worker discovery
17:13:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:13:59 DISPATCHER: Finished worker discovery
17:14:59 DISPATCHER: Starting worker discovery
17:14:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:14:59 DISPATCHER: Finished worker discovery
17:15:38 WORKER: done with job (4, 0, 24), trying to register it.
17:15:38 WORKER: registered result for job (4, 0, 24) with dispatcher
17:15:38 DISPATCHER: job (4, 0, 24) finished
17:15:38 DISPATCHER: register_result: lock acquired
17:15:38 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
17:15:38 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0016691416164860738, 'num_filters_1': 55, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.01607813087582132, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 63, 'num_filters_3': 99, 'num_filters_4': 86}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.49566736452243704, 'info': {'sick_no_sick': 0.49566736452243704, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0016691416164860738, 'num_filters_1': 55, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.01607813087582132, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 63, 'num_filters_3': 99, 'num_filters_4': 86}"}}
exception: None

17:15:38 job_callback for (4, 0, 24) started
17:15:38 DISPATCHER: Trying to submit another job.
17:15:38 job_callback for (4, 0, 24) got condition
17:15:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:15:38 done building a new model for budget 44.444444 based on 17/44 split
Best loss for this budget:-0.640658





17:15:38 HBMASTER: Trying to run another job!
17:15:38 job_callback for (4, 0, 24) finished
17:15:38 start sampling a new configuration.
17:15:38 done sampling a new configuration.
17:15:38 HBMASTER: schedule new run for iteration 4
17:15:38 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
17:15:38 HBMASTER: submitting job (4, 0, 25) to dispatcher
17:15:38 DISPATCHER: trying to submit job (4, 0, 25)
17:15:38 DISPATCHER: trying to notify the job_runner thread.
17:15:38 HBMASTER: job (4, 0, 25) submitted to dispatcher
17:15:38 DISPATCHER: Trying to submit another job.
17:15:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:15:38 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:15:38 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:15:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:15:38 WORKER: start processing job (4, 0, 25)
17:15:38 WORKER: args: ()
17:15:38 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.008279465875548425, 'num_filters_1': 105, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 68, 'weight_decay': 0.014922816488552065, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 44, 'num_filters_3': 36, 'num_filters_4': 85, 'num_filters_5': 104}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:15:59 DISPATCHER: Starting worker discovery
17:15:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:15:59 DISPATCHER: Finished worker discovery
17:16:59 DISPATCHER: Starting worker discovery
17:16:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:16:59 DISPATCHER: Finished worker discovery
17:17:26 WORKER: done with job (4, 0, 25), trying to register it.
17:17:26 WORKER: registered result for job (4, 0, 25) with dispatcher
17:17:26 DISPATCHER: job (4, 0, 25) finished
17:17:26 DISPATCHER: register_result: lock acquired
17:17:26 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
17:17:26 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.008279465875548425, 'num_filters_1': 105, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 68, 'weight_decay': 0.014922816488552065, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 44, 'num_filters_3': 36, 'num_filters_4': 85, 'num_filters_5': 104}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5570577256977788, 'info': {'sick_no_sick': 0.5570577256977788, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.008279465875548425, 'num_filters_1': 105, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 68, 'weight_decay': 0.014922816488552065, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 44, 'num_filters_3': 36, 'num_filters_4': 85, 'num_filters_5': 104}"}}
exception: None

17:17:26 job_callback for (4, 0, 25) started
17:17:26 DISPATCHER: Trying to submit another job.
17:17:26 job_callback for (4, 0, 25) got condition
17:17:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:17:26 done building a new model for budget 44.444444 based on 17/45 split
Best loss for this budget:-0.640658





17:17:26 HBMASTER: Trying to run another job!
17:17:26 job_callback for (4, 0, 25) finished
17:17:26 start sampling a new configuration.
17:17:26 done sampling a new configuration.
17:17:26 HBMASTER: schedule new run for iteration 4
17:17:26 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
17:17:26 HBMASTER: submitting job (4, 0, 26) to dispatcher
17:17:26 DISPATCHER: trying to submit job (4, 0, 26)
17:17:26 DISPATCHER: trying to notify the job_runner thread.
17:17:26 HBMASTER: job (4, 0, 26) submitted to dispatcher
17:17:26 DISPATCHER: Trying to submit another job.
17:17:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:17:26 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:17:26 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:17:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:17:26 WORKER: start processing job (4, 0, 26)
17:17:26 WORKER: args: ()
17:17:26 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.03699214335635067, 'num_filters_1': 47, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.08684776398499115, 'kernel_size_2': 5, 'num_filters_2': 25}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:17:59 DISPATCHER: Starting worker discovery
17:17:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:17:59 DISPATCHER: Finished worker discovery
17:18:59 DISPATCHER: Starting worker discovery
17:18:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:18:59 DISPATCHER: Finished worker discovery
17:19:13 WORKER: done with job (4, 0, 26), trying to register it.
17:19:13 WORKER: registered result for job (4, 0, 26) with dispatcher
17:19:13 DISPATCHER: job (4, 0, 26) finished
17:19:13 DISPATCHER: register_result: lock acquired
17:19:13 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
17:19:13 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.03699214335635067, 'num_filters_1': 47, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.08684776398499115, 'kernel_size_2': 5, 'num_filters_2': 25}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.01894504900250158, 'info': {'sick_no_sick': 0.01894504900250158, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.03699214335635067, 'num_filters_1': 47, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.08684776398499115, 'kernel_size_2': 5, 'num_filters_2': 25}"}}
exception: None

17:19:13 job_callback for (4, 0, 26) started
17:19:13 job_callback for (4, 0, 26) got condition
17:19:13 DISPATCHER: Trying to submit another job.
17:19:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:19:13 done building a new model for budget 44.444444 based on 17/45 split
Best loss for this budget:-0.640658





17:19:13 HBMASTER: Trying to run another job!
17:19:13 job_callback for (4, 0, 26) finished
17:19:13 ITERATION: Advancing config (4, 0, 10) to next budget 133.333333
17:19:13 ITERATION: Advancing config (4, 0, 11) to next budget 133.333333
17:19:13 ITERATION: Advancing config (4, 0, 13) to next budget 133.333333
17:19:13 ITERATION: Advancing config (4, 0, 14) to next budget 133.333333
17:19:13 ITERATION: Advancing config (4, 0, 15) to next budget 133.333333
17:19:13 ITERATION: Advancing config (4, 0, 19) to next budget 133.333333
17:19:13 ITERATION: Advancing config (4, 0, 22) to next budget 133.333333
17:19:13 ITERATION: Advancing config (4, 0, 24) to next budget 133.333333
17:19:13 ITERATION: Advancing config (4, 0, 25) to next budget 133.333333
17:19:13 HBMASTER: schedule new run for iteration 4
17:19:13 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
17:19:13 HBMASTER: submitting job (4, 0, 10) to dispatcher
17:19:13 DISPATCHER: trying to submit job (4, 0, 10)
17:19:13 DISPATCHER: trying to notify the job_runner thread.
17:19:13 HBMASTER: job (4, 0, 10) submitted to dispatcher
17:19:13 DISPATCHER: Trying to submit another job.
17:19:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:19:13 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:19:13 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:19:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:19:13 WORKER: start processing job (4, 0, 10)
17:19:13 WORKER: args: ()
17:19:13 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.07722900660262609, 'num_filters_1': 21, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.014418956920544432, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 16, 'num_filters_3': 63, 'num_filters_4': 86, 'num_filters_5': 33}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:19:59 DISPATCHER: Starting worker discovery
17:19:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:19:59 DISPATCHER: Finished worker discovery
17:20:59 DISPATCHER: Starting worker discovery
17:20:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:20:59 DISPATCHER: Finished worker discovery
17:21:59 DISPATCHER: Starting worker discovery
17:21:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:21:59 DISPATCHER: Finished worker discovery
17:22:30 WORKER: done with job (4, 0, 10), trying to register it.
17:22:30 WORKER: registered result for job (4, 0, 10) with dispatcher
17:22:30 DISPATCHER: job (4, 0, 10) finished
17:22:30 DISPATCHER: register_result: lock acquired
17:22:30 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
17:22:30 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.07722900660262609, 'num_filters_1': 21, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.014418956920544432, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 16, 'num_filters_3': 63, 'num_filters_4': 86, 'num_filters_5': 33}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.599627497369313, 'info': {'sick_no_sick': 0.599627497369313, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.07722900660262609, 'num_filters_1': 21, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.014418956920544432, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 16, 'num_filters_3': 63, 'num_filters_4': 86, 'num_filters_5': 33}"}}
exception: None

17:22:30 job_callback for (4, 0, 10) started
17:22:30 DISPATCHER: Trying to submit another job.
17:22:30 job_callback for (4, 0, 10) got condition
17:22:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:22:30 HBMASTER: Trying to run another job!
17:22:30 job_callback for (4, 0, 10) finished
17:22:30 HBMASTER: schedule new run for iteration 4
17:22:30 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
17:22:30 HBMASTER: submitting job (4, 0, 11) to dispatcher
17:22:30 DISPATCHER: trying to submit job (4, 0, 11)
17:22:30 DISPATCHER: trying to notify the job_runner thread.
17:22:30 HBMASTER: job (4, 0, 11) submitted to dispatcher
17:22:30 DISPATCHER: Trying to submit another job.
17:22:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:22:30 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:22:30 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:22:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:22:30 WORKER: start processing job (4, 0, 11)
17:22:30 WORKER: args: ()
17:22:30 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.001245055797152259, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.01053533169813305, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 112, 'num_filters_3': 24, 'num_filters_4': 50, 'num_filters_5': 52}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:22:59 DISPATCHER: Starting worker discovery
17:22:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:22:59 DISPATCHER: Finished worker discovery
17:23:59 DISPATCHER: Starting worker discovery
17:23:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:23:59 DISPATCHER: Finished worker discovery
17:24:59 DISPATCHER: Starting worker discovery
17:24:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:24:59 DISPATCHER: Finished worker discovery
17:25:48 WORKER: done with job (4, 0, 11), trying to register it.
17:25:48 WORKER: registered result for job (4, 0, 11) with dispatcher
17:25:48 DISPATCHER: job (4, 0, 11) finished
17:25:48 DISPATCHER: register_result: lock acquired
17:25:48 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
17:25:48 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.001245055797152259, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.01053533169813305, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 112, 'num_filters_3': 24, 'num_filters_4': 50, 'num_filters_5': 52}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.540015391362224, 'info': {'sick_no_sick': 0.540015391362224, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.001245055797152259, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.01053533169813305, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 112, 'num_filters_3': 24, 'num_filters_4': 50, 'num_filters_5': 52}"}}
exception: None

17:25:48 job_callback for (4, 0, 11) started
17:25:48 job_callback for (4, 0, 11) got condition
17:25:48 DISPATCHER: Trying to submit another job.
17:25:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:25:48 HBMASTER: Trying to run another job!
17:25:48 job_callback for (4, 0, 11) finished
17:25:48 HBMASTER: schedule new run for iteration 4
17:25:48 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
17:25:48 HBMASTER: submitting job (4, 0, 13) to dispatcher
17:25:48 DISPATCHER: trying to submit job (4, 0, 13)
17:25:48 DISPATCHER: trying to notify the job_runner thread.
17:25:48 HBMASTER: job (4, 0, 13) submitted to dispatcher
17:25:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:25:48 DISPATCHER: Trying to submit another job.
17:25:48 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:25:48 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:25:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:25:48 WORKER: start processing job (4, 0, 13)
17:25:48 WORKER: args: ()
17:25:48 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.004606187602094473, 'num_filters_1': 61, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.014065588057730005, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 99, 'num_filters_3': 82, 'num_filters_4': 109, 'num_filters_5': 39}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:25:59 DISPATCHER: Starting worker discovery
17:25:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:25:59 DISPATCHER: Finished worker discovery
17:26:59 DISPATCHER: Starting worker discovery
17:26:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:26:59 DISPATCHER: Finished worker discovery
17:27:59 DISPATCHER: Starting worker discovery
17:27:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:27:59 DISPATCHER: Finished worker discovery
17:28:59 DISPATCHER: Starting worker discovery
17:28:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:28:59 DISPATCHER: Finished worker discovery
17:29:05 WORKER: done with job (4, 0, 13), trying to register it.
17:29:05 WORKER: registered result for job (4, 0, 13) with dispatcher
17:29:05 DISPATCHER: job (4, 0, 13) finished
17:29:05 DISPATCHER: register_result: lock acquired
17:29:05 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
17:29:05 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.004606187602094473, 'num_filters_1': 61, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.014065588057730005, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 99, 'num_filters_3': 82, 'num_filters_4': 109, 'num_filters_5': 39}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6025415998480048, 'info': {'sick_no_sick': 0.6025415998480048, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.004606187602094473, 'num_filters_1': 61, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.014065588057730005, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 99, 'num_filters_3': 82, 'num_filters_4': 109, 'num_filters_5': 39}"}}
exception: None

17:29:05 job_callback for (4, 0, 13) started
17:29:05 job_callback for (4, 0, 13) got condition
17:29:05 DISPATCHER: Trying to submit another job.
17:29:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:29:05 HBMASTER: Trying to run another job!
17:29:05 job_callback for (4, 0, 13) finished
17:29:05 HBMASTER: schedule new run for iteration 4
17:29:05 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
17:29:05 HBMASTER: submitting job (4, 0, 14) to dispatcher
17:29:05 DISPATCHER: trying to submit job (4, 0, 14)
17:29:05 DISPATCHER: trying to notify the job_runner thread.
17:29:05 HBMASTER: job (4, 0, 14) submitted to dispatcher
17:29:05 DISPATCHER: Trying to submit another job.
17:29:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:29:05 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:29:05 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:29:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:29:05 WORKER: start processing job (4, 0, 14)
17:29:05 WORKER: args: ()
17:29:05 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0012361183464914434, 'num_filters_1': 124, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.018073236649726095, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 39, 'num_filters_3': 86, 'num_filters_4': 59}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:29:59 DISPATCHER: Starting worker discovery
17:29:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:29:59 DISPATCHER: Finished worker discovery
17:30:59 DISPATCHER: Starting worker discovery
17:30:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:30:59 DISPATCHER: Finished worker discovery
17:31:59 DISPATCHER: Starting worker discovery
17:31:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:31:59 DISPATCHER: Finished worker discovery
17:32:21 WORKER: done with job (4, 0, 14), trying to register it.
17:32:21 WORKER: registered result for job (4, 0, 14) with dispatcher
17:32:21 DISPATCHER: job (4, 0, 14) finished
17:32:21 DISPATCHER: register_result: lock acquired
17:32:21 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
17:32:21 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0012361183464914434, 'num_filters_1': 124, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.018073236649726095, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 39, 'num_filters_3': 86, 'num_filters_4': 59}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.575123406794262, 'info': {'sick_no_sick': 0.575123406794262, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0012361183464914434, 'num_filters_1': 124, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.018073236649726095, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 39, 'num_filters_3': 86, 'num_filters_4': 59}"}}
exception: None

17:32:21 job_callback for (4, 0, 14) started
17:32:21 DISPATCHER: Trying to submit another job.
17:32:21 job_callback for (4, 0, 14) got condition
17:32:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:32:21 HBMASTER: Trying to run another job!
17:32:21 job_callback for (4, 0, 14) finished
17:32:21 HBMASTER: schedule new run for iteration 4
17:32:21 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
17:32:21 HBMASTER: submitting job (4, 0, 15) to dispatcher
17:32:21 DISPATCHER: trying to submit job (4, 0, 15)
17:32:21 DISPATCHER: trying to notify the job_runner thread.
17:32:21 HBMASTER: job (4, 0, 15) submitted to dispatcher
17:32:21 DISPATCHER: Trying to submit another job.
17:32:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:32:21 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:32:21 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:32:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:32:21 WORKER: start processing job (4, 0, 15)
17:32:21 WORKER: args: ()
17:32:21 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0015378825825955668, 'num_filters_1': 77, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.023157672993507378, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 18, 'num_filters_3': 55, 'num_filters_4': 44}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:32:59 DISPATCHER: Starting worker discovery
17:32:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:32:59 DISPATCHER: Finished worker discovery
17:33:59 DISPATCHER: Starting worker discovery
17:33:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:33:59 DISPATCHER: Finished worker discovery
17:34:59 DISPATCHER: Starting worker discovery
17:34:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:34:59 DISPATCHER: Finished worker discovery
17:35:37 WORKER: done with job (4, 0, 15), trying to register it.
17:35:37 WORKER: registered result for job (4, 0, 15) with dispatcher
17:35:37 DISPATCHER: job (4, 0, 15) finished
17:35:37 DISPATCHER: register_result: lock acquired
17:35:37 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
17:35:37 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0015378825825955668, 'num_filters_1': 77, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.023157672993507378, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 18, 'num_filters_3': 55, 'num_filters_4': 44}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5468263769349905, 'info': {'sick_no_sick': 0.5468263769349905, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0015378825825955668, 'num_filters_1': 77, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.023157672993507378, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 18, 'num_filters_3': 55, 'num_filters_4': 44}"}}
exception: None

17:35:37 job_callback for (4, 0, 15) started
17:35:37 job_callback for (4, 0, 15) got condition
17:35:37 DISPATCHER: Trying to submit another job.
17:35:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:35:37 HBMASTER: Trying to run another job!
17:35:37 job_callback for (4, 0, 15) finished
17:35:37 HBMASTER: schedule new run for iteration 4
17:35:37 HBMASTER: trying submitting job (4, 0, 19) to dispatcher
17:35:37 HBMASTER: submitting job (4, 0, 19) to dispatcher
17:35:37 DISPATCHER: trying to submit job (4, 0, 19)
17:35:37 DISPATCHER: trying to notify the job_runner thread.
17:35:37 HBMASTER: job (4, 0, 19) submitted to dispatcher
17:35:37 DISPATCHER: Trying to submit another job.
17:35:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:35:37 DISPATCHER: starting job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:35:37 DISPATCHER: job (4, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:35:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:35:37 WORKER: start processing job (4, 0, 19)
17:35:37 WORKER: args: ()
17:35:37 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002646572455899281, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.01325757258618368, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 29, 'num_filters_3': 20, 'num_filters_4': 18, 'num_filters_5': 36}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:35:59 DISPATCHER: Starting worker discovery
17:35:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:35:59 DISPATCHER: Finished worker discovery
17:36:59 DISPATCHER: Starting worker discovery
17:36:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:36:59 DISPATCHER: Finished worker discovery
17:37:59 DISPATCHER: Starting worker discovery
17:37:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:37:59 DISPATCHER: Finished worker discovery
17:38:54 WORKER: done with job (4, 0, 19), trying to register it.
17:38:54 WORKER: registered result for job (4, 0, 19) with dispatcher
17:38:54 DISPATCHER: job (4, 0, 19) finished
17:38:54 DISPATCHER: register_result: lock acquired
17:38:54 DISPATCHER: job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
17:38:54 job_id: (4, 0, 19)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002646572455899281, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.01325757258618368, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 29, 'num_filters_3': 20, 'num_filters_4': 18, 'num_filters_5': 36}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5670543278664182, 'info': {'sick_no_sick': 0.5670543278664182, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002646572455899281, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.01325757258618368, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 29, 'num_filters_3': 20, 'num_filters_4': 18, 'num_filters_5': 36}"}}
exception: None

17:38:54 job_callback for (4, 0, 19) started
17:38:54 job_callback for (4, 0, 19) got condition
17:38:54 DISPATCHER: Trying to submit another job.
17:38:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:38:54 HBMASTER: Trying to run another job!
17:38:54 job_callback for (4, 0, 19) finished
17:38:54 HBMASTER: schedule new run for iteration 4
17:38:54 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
17:38:54 HBMASTER: submitting job (4, 0, 22) to dispatcher
17:38:54 DISPATCHER: trying to submit job (4, 0, 22)
17:38:54 DISPATCHER: trying to notify the job_runner thread.
17:38:54 HBMASTER: job (4, 0, 22) submitted to dispatcher
17:38:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:38:54 DISPATCHER: Trying to submit another job.
17:38:54 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:38:54 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:38:54 WORKER: start processing job (4, 0, 22)
17:38:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:38:54 WORKER: args: ()
17:38:54 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.005424677555202626, 'num_filters_1': 82, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.012593779387793843, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 123, 'num_filters_3': 114}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:38:59 DISPATCHER: Starting worker discovery
17:38:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:38:59 DISPATCHER: Finished worker discovery
17:39:59 DISPATCHER: Starting worker discovery
17:39:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:39:59 DISPATCHER: Finished worker discovery
17:40:59 DISPATCHER: Starting worker discovery
17:40:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:40:59 DISPATCHER: Finished worker discovery
17:41:59 DISPATCHER: Starting worker discovery
17:41:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:41:59 DISPATCHER: Finished worker discovery
17:42:11 WORKER: done with job (4, 0, 22), trying to register it.
17:42:11 WORKER: registered result for job (4, 0, 22) with dispatcher
17:42:11 DISPATCHER: job (4, 0, 22) finished
17:42:11 DISPATCHER: register_result: lock acquired
17:42:11 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
17:42:11 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.005424677555202626, 'num_filters_1': 82, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.012593779387793843, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 123, 'num_filters_3': 114}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.525408418686178, 'info': {'sick_no_sick': 0.525408418686178, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.005424677555202626, 'num_filters_1': 82, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.012593779387793843, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 123, 'num_filters_3': 114}"}}
exception: None

17:42:11 job_callback for (4, 0, 22) started
17:42:11 job_callback for (4, 0, 22) got condition
17:42:11 DISPATCHER: Trying to submit another job.
17:42:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:42:11 HBMASTER: Trying to run another job!
17:42:11 job_callback for (4, 0, 22) finished
17:42:11 HBMASTER: schedule new run for iteration 4
17:42:11 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
17:42:11 HBMASTER: submitting job (4, 0, 24) to dispatcher
17:42:11 DISPATCHER: trying to submit job (4, 0, 24)
17:42:11 DISPATCHER: trying to notify the job_runner thread.
17:42:11 HBMASTER: job (4, 0, 24) submitted to dispatcher
17:42:11 DISPATCHER: Trying to submit another job.
17:42:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:42:11 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:42:11 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:42:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:42:11 WORKER: start processing job (4, 0, 24)
17:42:11 WORKER: args: ()
17:42:11 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0016691416164860738, 'num_filters_1': 55, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.01607813087582132, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 63, 'num_filters_3': 99, 'num_filters_4': 86}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:42:59 DISPATCHER: Starting worker discovery
17:42:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:42:59 DISPATCHER: Finished worker discovery
17:43:59 DISPATCHER: Starting worker discovery
17:43:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:43:59 DISPATCHER: Finished worker discovery
17:44:59 DISPATCHER: Starting worker discovery
17:44:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:44:59 DISPATCHER: Finished worker discovery
17:45:29 WORKER: done with job (4, 0, 24), trying to register it.
17:45:29 WORKER: registered result for job (4, 0, 24) with dispatcher
17:45:29 DISPATCHER: job (4, 0, 24) finished
17:45:29 DISPATCHER: register_result: lock acquired
17:45:29 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
17:45:29 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0016691416164860738, 'num_filters_1': 55, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.01607813087582132, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 63, 'num_filters_3': 99, 'num_filters_4': 86}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6306744693609828, 'info': {'sick_no_sick': 0.6306744693609828, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0016691416164860738, 'num_filters_1': 55, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.01607813087582132, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 63, 'num_filters_3': 99, 'num_filters_4': 86}"}}
exception: None

17:45:29 job_callback for (4, 0, 24) started
17:45:29 job_callback for (4, 0, 24) got condition
17:45:29 DISPATCHER: Trying to submit another job.
17:45:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:45:29 HBMASTER: Trying to run another job!
17:45:29 job_callback for (4, 0, 24) finished
17:45:29 HBMASTER: schedule new run for iteration 4
17:45:29 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
17:45:29 HBMASTER: submitting job (4, 0, 25) to dispatcher
17:45:29 DISPATCHER: trying to submit job (4, 0, 25)
17:45:29 DISPATCHER: trying to notify the job_runner thread.
17:45:29 HBMASTER: job (4, 0, 25) submitted to dispatcher
17:45:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:45:29 DISPATCHER: Trying to submit another job.
17:45:29 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:45:29 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:45:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:45:29 WORKER: start processing job (4, 0, 25)
17:45:29 WORKER: args: ()
17:45:29 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.008279465875548425, 'num_filters_1': 105, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 68, 'weight_decay': 0.014922816488552065, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 44, 'num_filters_3': 36, 'num_filters_4': 85, 'num_filters_5': 104}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:45:59 DISPATCHER: Starting worker discovery
17:45:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:45:59 DISPATCHER: Finished worker discovery
17:46:59 DISPATCHER: Starting worker discovery
17:46:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:46:59 DISPATCHER: Finished worker discovery
17:47:59 DISPATCHER: Starting worker discovery
17:47:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:47:59 DISPATCHER: Finished worker discovery
17:48:46 WORKER: done with job (4, 0, 25), trying to register it.
17:48:46 WORKER: registered result for job (4, 0, 25) with dispatcher
17:48:46 DISPATCHER: job (4, 0, 25) finished
17:48:46 DISPATCHER: register_result: lock acquired
17:48:46 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
17:48:46 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.008279465875548425, 'num_filters_1': 105, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 68, 'weight_decay': 0.014922816488552065, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 44, 'num_filters_3': 36, 'num_filters_4': 85, 'num_filters_5': 104}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5827951925440245, 'info': {'sick_no_sick': 0.5827951925440245, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.008279465875548425, 'num_filters_1': 105, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 68, 'weight_decay': 0.014922816488552065, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 44, 'num_filters_3': 36, 'num_filters_4': 85, 'num_filters_5': 104}"}}
exception: None

17:48:46 job_callback for (4, 0, 25) started
17:48:46 DISPATCHER: Trying to submit another job.
17:48:46 job_callback for (4, 0, 25) got condition
17:48:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:48:46 HBMASTER: Trying to run another job!
17:48:46 job_callback for (4, 0, 25) finished
17:48:46 ITERATION: Advancing config (4, 0, 10) to next budget 400.000000
17:48:46 ITERATION: Advancing config (4, 0, 13) to next budget 400.000000
17:48:46 ITERATION: Advancing config (4, 0, 24) to next budget 400.000000
17:48:46 HBMASTER: schedule new run for iteration 4
17:48:46 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
17:48:46 HBMASTER: submitting job (4, 0, 10) to dispatcher
17:48:46 DISPATCHER: trying to submit job (4, 0, 10)
17:48:46 DISPATCHER: trying to notify the job_runner thread.
17:48:46 HBMASTER: job (4, 0, 10) submitted to dispatcher
17:48:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:48:46 DISPATCHER: Trying to submit another job.
17:48:46 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:48:46 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:48:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:48:46 WORKER: start processing job (4, 0, 10)
17:48:46 WORKER: args: ()
17:48:46 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.07722900660262609, 'num_filters_1': 21, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.014418956920544432, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 16, 'num_filters_3': 63, 'num_filters_4': 86, 'num_filters_5': 33}, 'budget': 400.0, 'working_directory': '.'}
17:48:59 DISPATCHER: Starting worker discovery
17:48:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:48:59 DISPATCHER: Finished worker discovery
17:49:59 DISPATCHER: Starting worker discovery
17:49:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:49:59 DISPATCHER: Finished worker discovery
17:50:59 DISPATCHER: Starting worker discovery
17:50:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:50:59 DISPATCHER: Finished worker discovery
17:51:59 DISPATCHER: Starting worker discovery
17:51:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:51:59 DISPATCHER: Finished worker discovery
17:52:59 DISPATCHER: Starting worker discovery
17:52:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:52:59 DISPATCHER: Finished worker discovery
17:53:59 DISPATCHER: Starting worker discovery
17:53:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:53:59 DISPATCHER: Finished worker discovery
17:54:59 DISPATCHER: Starting worker discovery
17:54:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:54:59 DISPATCHER: Finished worker discovery
17:55:59 DISPATCHER: Starting worker discovery
17:55:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:55:59 DISPATCHER: Finished worker discovery
17:56:37 WORKER: done with job (4, 0, 10), trying to register it.
17:56:37 WORKER: registered result for job (4, 0, 10) with dispatcher
17:56:37 DISPATCHER: job (4, 0, 10) finished
17:56:37 DISPATCHER: register_result: lock acquired
17:56:37 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
17:56:37 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.07722900660262609, 'num_filters_1': 21, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.014418956920544432, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 16, 'num_filters_3': 63, 'num_filters_4': 86, 'num_filters_5': 33}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.4728342713875229, 'info': {'sick_no_sick': 0.4728342713875229, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.07722900660262609, 'num_filters_1': 21, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.014418956920544432, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 16, 'num_filters_3': 63, 'num_filters_4': 86, 'num_filters_5': 33}"}}
exception: None

17:56:37 job_callback for (4, 0, 10) started
17:56:37 DISPATCHER: Trying to submit another job.
17:56:37 job_callback for (4, 0, 10) got condition
17:56:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:56:37 Only 13 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
17:56:37 HBMASTER: Trying to run another job!
17:56:37 job_callback for (4, 0, 10) finished
17:56:37 HBMASTER: schedule new run for iteration 4
17:56:37 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
17:56:37 HBMASTER: submitting job (4, 0, 13) to dispatcher
17:56:37 DISPATCHER: trying to submit job (4, 0, 13)
17:56:37 DISPATCHER: trying to notify the job_runner thread.
17:56:37 HBMASTER: job (4, 0, 13) submitted to dispatcher
17:56:37 DISPATCHER: Trying to submit another job.
17:56:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:56:37 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:56:37 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:56:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:56:37 WORKER: start processing job (4, 0, 13)
17:56:37 WORKER: args: ()
17:56:37 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.004606187602094473, 'num_filters_1': 61, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.014065588057730005, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 99, 'num_filters_3': 82, 'num_filters_4': 109, 'num_filters_5': 39}, 'budget': 400.0, 'working_directory': '.'}
17:56:59 DISPATCHER: Starting worker discovery
17:56:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:56:59 DISPATCHER: Finished worker discovery
17:57:59 DISPATCHER: Starting worker discovery
17:57:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:57:59 DISPATCHER: Finished worker discovery
17:58:59 DISPATCHER: Starting worker discovery
17:58:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:58:59 DISPATCHER: Finished worker discovery
17:59:59 DISPATCHER: Starting worker discovery
17:59:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:59:59 DISPATCHER: Finished worker discovery
18:00:59 DISPATCHER: Starting worker discovery
18:00:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:00:59 DISPATCHER: Finished worker discovery
18:01:59 DISPATCHER: Starting worker discovery
18:01:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:01:59 DISPATCHER: Finished worker discovery
18:02:59 DISPATCHER: Starting worker discovery
18:02:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:02:59 DISPATCHER: Finished worker discovery
18:03:59 DISPATCHER: Starting worker discovery
18:03:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:03:59 DISPATCHER: Finished worker discovery
18:04:25 WORKER: done with job (4, 0, 13), trying to register it.
18:04:25 WORKER: registered result for job (4, 0, 13) with dispatcher
18:04:25 DISPATCHER: job (4, 0, 13) finished
18:04:25 DISPATCHER: register_result: lock acquired
18:04:25 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
18:04:25 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.004606187602094473, 'num_filters_1': 61, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.014065588057730005, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 99, 'num_filters_3': 82, 'num_filters_4': 109, 'num_filters_5': 39}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5491372229036356, 'info': {'sick_no_sick': 0.5491372229036356, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.004606187602094473, 'num_filters_1': 61, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.014065588057730005, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 99, 'num_filters_3': 82, 'num_filters_4': 109, 'num_filters_5': 39}"}}
exception: None

18:04:25 job_callback for (4, 0, 13) started
18:04:25 DISPATCHER: Trying to submit another job.
18:04:25 job_callback for (4, 0, 13) got condition
18:04:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:04:25 Only 14 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
18:04:25 HBMASTER: Trying to run another job!
18:04:25 job_callback for (4, 0, 13) finished
18:04:25 HBMASTER: schedule new run for iteration 4
18:04:25 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
18:04:25 HBMASTER: submitting job (4, 0, 24) to dispatcher
18:04:25 DISPATCHER: trying to submit job (4, 0, 24)
18:04:25 DISPATCHER: trying to notify the job_runner thread.
18:04:25 HBMASTER: job (4, 0, 24) submitted to dispatcher
18:04:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:04:25 DISPATCHER: Trying to submit another job.
18:04:25 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:04:25 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:04:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:04:25 WORKER: start processing job (4, 0, 24)
18:04:25 WORKER: args: ()
18:04:25 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0016691416164860738, 'num_filters_1': 55, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.01607813087582132, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 63, 'num_filters_3': 99, 'num_filters_4': 86}, 'budget': 400.0, 'working_directory': '.'}
18:04:59 DISPATCHER: Starting worker discovery
18:04:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:04:59 DISPATCHER: Finished worker discovery
18:05:59 DISPATCHER: Starting worker discovery
18:05:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:05:59 DISPATCHER: Finished worker discovery
18:06:59 DISPATCHER: Starting worker discovery
18:06:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:06:59 DISPATCHER: Finished worker discovery
18:07:59 DISPATCHER: Starting worker discovery
18:07:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:07:59 DISPATCHER: Finished worker discovery
18:08:59 DISPATCHER: Starting worker discovery
18:08:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:08:59 DISPATCHER: Finished worker discovery
18:09:59 DISPATCHER: Starting worker discovery
18:09:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:09:59 DISPATCHER: Finished worker discovery
18:10:59 DISPATCHER: Starting worker discovery
18:10:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:10:59 DISPATCHER: Finished worker discovery
18:11:59 DISPATCHER: Starting worker discovery
18:11:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:11:59 DISPATCHER: Finished worker discovery
18:12:13 WORKER: done with job (4, 0, 24), trying to register it.
18:12:13 WORKER: registered result for job (4, 0, 24) with dispatcher
18:12:13 DISPATCHER: job (4, 0, 24) finished
18:12:13 DISPATCHER: register_result: lock acquired
18:12:13 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
18:12:13 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0016691416164860738, 'num_filters_1': 55, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.01607813087582132, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 63, 'num_filters_3': 99, 'num_filters_4': 86}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.559506497483494, 'info': {'sick_no_sick': 0.559506497483494, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0016691416164860738, 'num_filters_1': 55, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.01607813087582132, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 63, 'num_filters_3': 99, 'num_filters_4': 86}"}}
exception: None

18:12:13 job_callback for (4, 0, 24) started
18:12:13 DISPATCHER: Trying to submit another job.
18:12:13 job_callback for (4, 0, 24) got condition
18:12:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:12:13 Only 15 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
18:12:13 HBMASTER: Trying to run another job!
18:12:13 job_callback for (4, 0, 24) finished
18:12:13 ITERATION: Advancing config (4, 0, 24) to next budget 1200.000000
18:12:13 HBMASTER: schedule new run for iteration 4
18:12:13 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
18:12:13 HBMASTER: submitting job (4, 0, 24) to dispatcher
18:12:13 DISPATCHER: trying to submit job (4, 0, 24)
18:12:13 DISPATCHER: trying to notify the job_runner thread.
18:12:13 HBMASTER: job (4, 0, 24) submitted to dispatcher
18:12:13 DISPATCHER: Trying to submit another job.
18:12:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:12:13 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:12:13 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:12:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:12:13 WORKER: start processing job (4, 0, 24)
18:12:13 WORKER: args: ()
18:12:13 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0016691416164860738, 'num_filters_1': 55, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.01607813087582132, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 63, 'num_filters_3': 99, 'num_filters_4': 86}, 'budget': 1200.0, 'working_directory': '.'}
18:12:59 DISPATCHER: Starting worker discovery
18:12:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:12:59 DISPATCHER: Finished worker discovery
18:13:59 DISPATCHER: Starting worker discovery
18:13:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:13:59 DISPATCHER: Finished worker discovery
18:14:59 DISPATCHER: Starting worker discovery
18:14:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:14:59 DISPATCHER: Finished worker discovery
18:15:59 DISPATCHER: Starting worker discovery
18:15:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:15:59 DISPATCHER: Finished worker discovery
18:16:59 DISPATCHER: Starting worker discovery
18:16:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:16:59 DISPATCHER: Finished worker discovery
18:17:59 DISPATCHER: Starting worker discovery
18:17:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:17:59 DISPATCHER: Finished worker discovery
18:18:59 DISPATCHER: Starting worker discovery
18:18:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:18:59 DISPATCHER: Finished worker discovery
18:19:59 DISPATCHER: Starting worker discovery
18:19:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:19:59 DISPATCHER: Finished worker discovery
18:20:59 DISPATCHER: Starting worker discovery
18:20:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:20:59 DISPATCHER: Finished worker discovery
18:21:59 DISPATCHER: Starting worker discovery
18:21:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:21:59 DISPATCHER: Finished worker discovery
18:22:59 DISPATCHER: Starting worker discovery
18:22:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:22:59 DISPATCHER: Finished worker discovery
18:23:59 DISPATCHER: Starting worker discovery
18:23:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:23:59 DISPATCHER: Finished worker discovery
18:24:59 DISPATCHER: Starting worker discovery
18:24:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:24:59 DISPATCHER: Finished worker discovery
18:25:59 DISPATCHER: Starting worker discovery
18:25:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:25:59 DISPATCHER: Finished worker discovery
18:26:59 DISPATCHER: Starting worker discovery
18:26:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:26:59 DISPATCHER: Finished worker discovery
18:27:59 DISPATCHER: Starting worker discovery
18:27:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:27:59 DISPATCHER: Finished worker discovery
18:28:59 DISPATCHER: Starting worker discovery
18:28:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:28:59 DISPATCHER: Finished worker discovery
18:29:59 DISPATCHER: Starting worker discovery
18:29:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:29:59 DISPATCHER: Finished worker discovery
18:30:59 DISPATCHER: Starting worker discovery
18:30:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:30:59 DISPATCHER: Finished worker discovery
18:31:59 DISPATCHER: Starting worker discovery
18:31:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:31:59 DISPATCHER: Finished worker discovery
18:32:59 DISPATCHER: Starting worker discovery
18:32:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:32:59 DISPATCHER: Finished worker discovery
18:33:36 WORKER: done with job (4, 0, 24), trying to register it.
18:33:36 WORKER: registered result for job (4, 0, 24) with dispatcher
18:33:36 DISPATCHER: job (4, 0, 24) finished
18:33:36 DISPATCHER: register_result: lock acquired
18:33:36 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
18:33:36 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0016691416164860738, 'num_filters_1': 55, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.01607813087582132, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 63, 'num_filters_3': 99, 'num_filters_4': 86}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5742473019464944, 'info': {'sick_no_sick': 0.5742473019464944, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0016691416164860738, 'num_filters_1': 55, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.01607813087582132, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 63, 'num_filters_3': 99, 'num_filters_4': 86}"}}
exception: None

18:33:36 job_callback for (4, 0, 24) started
18:33:36 DISPATCHER: Trying to submit another job.
18:33:36 job_callback for (4, 0, 24) got condition
18:33:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:33:36 Only 9 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
18:33:36 HBMASTER: Trying to run another job!
18:33:36 job_callback for (4, 0, 24) finished
18:33:36 start sampling a new configuration.
18:33:36 best_vector: [0, 0, 0.06146569445002481, 0.7848264515704295, 0.9524754646454554, 1, 0.5327637136683628, 0.21914917647740906, 2, 0, 2, 2, 0.24845671280976217, 0.7524337583532847, 0.9377101654121257, 0.4911071985827207], 0.0006156402536652102, 0.001046192500918566, 6.440782166481467e-07
18:33:36 done sampling a new configuration.
18:33:36 HBMASTER: schedule new run for iteration 5
18:33:36 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
18:33:36 HBMASTER: submitting job (5, 0, 0) to dispatcher
18:33:36 DISPATCHER: trying to submit job (5, 0, 0)
18:33:36 DISPATCHER: trying to notify the job_runner thread.
18:33:36 HBMASTER: job (5, 0, 0) submitted to dispatcher
18:33:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:33:36 DISPATCHER: Trying to submit another job.
18:33:36 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:33:36 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:33:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:33:36 WORKER: start processing job (5, 0, 0)
18:33:36 WORKER: args: ()
18:33:36 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001327184768673305, 'num_filters_1': 82, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.01928056037185381, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 26, 'num_filters_3': 76, 'num_filters_4': 113, 'num_filters_5': 44}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:33:59 DISPATCHER: Starting worker discovery
18:33:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:33:59 DISPATCHER: Finished worker discovery
18:34:59 DISPATCHER: Starting worker discovery
18:34:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:34:59 DISPATCHER: Finished worker discovery
18:35:59 DISPATCHER: Starting worker discovery
18:35:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:35:59 DISPATCHER: Finished worker discovery
18:36:55 WORKER: done with job (5, 0, 0), trying to register it.
18:36:55 WORKER: registered result for job (5, 0, 0) with dispatcher
18:36:55 DISPATCHER: job (5, 0, 0) finished
18:36:55 DISPATCHER: register_result: lock acquired
18:36:55 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
18:36:55 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001327184768673305, 'num_filters_1': 82, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.01928056037185381, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 26, 'num_filters_3': 76, 'num_filters_4': 113, 'num_filters_5': 44}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5522932109218064, 'info': {'sick_no_sick': 0.5522932109218064, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001327184768673305, 'num_filters_1': 82, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.01928056037185381, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 26, 'num_filters_3': 76, 'num_filters_4': 113, 'num_filters_5': 44}"}}
exception: None

18:36:55 job_callback for (5, 0, 0) started
18:36:55 DISPATCHER: Trying to submit another job.
18:36:55 job_callback for (5, 0, 0) got condition
18:36:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:36:55 HBMASTER: Trying to run another job!
18:36:55 job_callback for (5, 0, 0) finished
18:36:55 start sampling a new configuration.
18:36:55 best_vector: [1, 1, 0.34241798779019683, 0.004720545802073706, 0.18059879255811429, 1, 0.23786041925000603, 0.6663436012243799, 2, 2, 1, 0, 0.43162044362914254, 0.2926793042656456, 0.8776315619462631, 0.5487292865404418], 1.4738874864095376e-27, 6.784778412333558e-06, -5.903097103175536e-07
18:36:55 done sampling a new configuration.
18:36:55 HBMASTER: schedule new run for iteration 5
18:36:55 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
18:36:55 HBMASTER: submitting job (5, 0, 1) to dispatcher
18:36:55 DISPATCHER: trying to submit job (5, 0, 1)
18:36:55 DISPATCHER: trying to notify the job_runner thread.
18:36:55 HBMASTER: job (5, 0, 1) submitted to dispatcher
18:36:55 DISPATCHER: Trying to submit another job.
18:36:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:36:55 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:36:55 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:36:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:36:55 WORKER: start processing job (5, 0, 1)
18:36:55 WORKER: args: ()
18:36:55 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.004839895398028665, 'num_filters_1': 16, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.07360935506052899}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:36:59 DISPATCHER: Starting worker discovery
18:36:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:36:59 DISPATCHER: Finished worker discovery
18:37:59 DISPATCHER: Starting worker discovery
18:37:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:37:59 DISPATCHER: Finished worker discovery
18:38:59 DISPATCHER: Starting worker discovery
18:38:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:38:59 DISPATCHER: Finished worker discovery
18:39:59 DISPATCHER: Starting worker discovery
18:39:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:39:59 DISPATCHER: Finished worker discovery
18:40:18 WORKER: done with job (5, 0, 1), trying to register it.
18:40:18 WORKER: registered result for job (5, 0, 1) with dispatcher
18:40:18 DISPATCHER: job (5, 0, 1) finished
18:40:18 DISPATCHER: register_result: lock acquired
18:40:18 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
18:40:18 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.004839895398028665, 'num_filters_1': 16, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.07360935506052899}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2709827489328305, 'info': {'sick_no_sick': 0.2709827489328305, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.004839895398028665, 'num_filters_1': 16, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.07360935506052899}"}}
exception: None

18:40:18 job_callback for (5, 0, 1) started
18:40:18 DISPATCHER: Trying to submit another job.
18:40:18 job_callback for (5, 0, 1) got condition
18:40:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:40:18 HBMASTER: Trying to run another job!
18:40:18 job_callback for (5, 0, 1) finished
18:40:18 start sampling a new configuration.
18:40:18 done sampling a new configuration.
18:40:18 HBMASTER: schedule new run for iteration 5
18:40:18 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
18:40:18 HBMASTER: submitting job (5, 0, 2) to dispatcher
18:40:18 DISPATCHER: trying to submit job (5, 0, 2)
18:40:18 DISPATCHER: trying to notify the job_runner thread.
18:40:18 HBMASTER: job (5, 0, 2) submitted to dispatcher
18:40:18 DISPATCHER: Trying to submit another job.
18:40:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:40:18 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:40:18 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:40:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:40:18 WORKER: start processing job (5, 0, 2)
18:40:18 WORKER: args: ()
18:40:18 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.050388203206614406, 'num_filters_1': 28, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.05617943279966497, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 21, 'num_filters_3': 105, 'num_filters_4': 49}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:40:59 DISPATCHER: Starting worker discovery
18:40:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:40:59 DISPATCHER: Finished worker discovery
18:41:59 DISPATCHER: Starting worker discovery
18:41:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:41:59 DISPATCHER: Finished worker discovery
18:42:59 DISPATCHER: Starting worker discovery
18:42:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:42:59 DISPATCHER: Finished worker discovery
18:43:35 WORKER: done with job (5, 0, 2), trying to register it.
18:43:35 WORKER: registered result for job (5, 0, 2) with dispatcher
18:43:35 DISPATCHER: job (5, 0, 2) finished
18:43:35 DISPATCHER: register_result: lock acquired
18:43:35 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
18:43:35 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.050388203206614406, 'num_filters_1': 28, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.05617943279966497, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 21, 'num_filters_3': 105, 'num_filters_4': 49}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.02512369939865647, 'info': {'sick_no_sick': 0.02512369939865647, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.050388203206614406, 'num_filters_1': 28, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.05617943279966497, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 21, 'num_filters_3': 105, 'num_filters_4': 49}"}}
exception: None

18:43:35 job_callback for (5, 0, 2) started
18:43:35 job_callback for (5, 0, 2) got condition
18:43:35 DISPATCHER: Trying to submit another job.
18:43:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:43:35 HBMASTER: Trying to run another job!
18:43:35 job_callback for (5, 0, 2) finished
18:43:35 start sampling a new configuration.
18:43:35 best_vector: [0, 0, 0.47546035449840174, 0.6255062050786228, 0.8615988940038604, 1, 0.9787716940266951, 0.10926943256261064, 1, 1, 0, 0, 0.994006635244316, 0.7424872200562012, 0.33750737960055005, 0.5315753650555732], 1.1901603187941205e-29, 0.0008402229382115577, -2.5163359861115274e-08
18:43:35 done sampling a new configuration.
18:43:35 HBMASTER: schedule new run for iteration 5
18:43:35 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
18:43:35 HBMASTER: submitting job (5, 0, 3) to dispatcher
18:43:35 DISPATCHER: trying to submit job (5, 0, 3)
18:43:35 DISPATCHER: trying to notify the job_runner thread.
18:43:35 HBMASTER: job (5, 0, 3) submitted to dispatcher
18:43:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:43:35 DISPATCHER: Trying to submit another job.
18:43:35 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:43:35 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:43:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:43:35 WORKER: start processing job (5, 0, 3)
18:43:35 WORKER: args: ()
18:43:35 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.008931424040135584, 'num_filters_1': 58, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.013872757967319037, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 127, 'num_filters_3': 75, 'num_filters_4': 32, 'num_filters_5': 48}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:43:59 DISPATCHER: Starting worker discovery
18:43:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:43:59 DISPATCHER: Finished worker discovery
18:44:59 DISPATCHER: Starting worker discovery
18:44:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:44:59 DISPATCHER: Finished worker discovery
18:45:59 DISPATCHER: Starting worker discovery
18:45:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:45:59 DISPATCHER: Finished worker discovery
18:46:51 WORKER: done with job (5, 0, 3), trying to register it.
18:46:51 WORKER: registered result for job (5, 0, 3) with dispatcher
18:46:51 DISPATCHER: job (5, 0, 3) finished
18:46:51 DISPATCHER: register_result: lock acquired
18:46:51 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
18:46:51 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.008931424040135584, 'num_filters_1': 58, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.013872757967319037, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 127, 'num_filters_3': 75, 'num_filters_4': 32, 'num_filters_5': 48}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6366178644554404, 'info': {'sick_no_sick': 0.6366178644554404, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.008931424040135584, 'num_filters_1': 58, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.013872757967319037, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 127, 'num_filters_3': 75, 'num_filters_4': 32, 'num_filters_5': 48}"}}
exception: None

18:46:51 job_callback for (5, 0, 3) started
18:46:51 DISPATCHER: Trying to submit another job.
18:46:51 job_callback for (5, 0, 3) got condition
18:46:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:46:51 HBMASTER: Trying to run another job!
18:46:51 job_callback for (5, 0, 3) finished
18:46:51 start sampling a new configuration.
18:46:51 best_vector: [0, 0, 0.10958187647325525, 0.6826206863233042, 0.7044071967792769, 0, 0.14454472866165302, 0.15858412684333606, 1, 0, 0, 2, 0.43371684529924937, 0.3254085709807184, 0.06562345197912747, 0.3755585500429269], 6.183121897912607e-29, 0.00016173059766743324, -1.9353213268552733e-06
18:46:51 done sampling a new configuration.
18:46:51 HBMASTER: schedule new run for iteration 5
18:46:51 HBMASTER: trying submitting job (5, 0, 4) to dispatcher
18:46:51 HBMASTER: submitting job (5, 0, 4) to dispatcher
18:46:51 DISPATCHER: trying to submit job (5, 0, 4)
18:46:51 DISPATCHER: trying to notify the job_runner thread.
18:46:51 HBMASTER: job (5, 0, 4) submitted to dispatcher
18:46:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:46:51 DISPATCHER: Trying to submit another job.
18:46:51 DISPATCHER: starting job (5, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:46:51 DISPATCHER: job (5, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:46:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:46:51 WORKER: start processing job (5, 0, 4)
18:46:51 WORKER: args: ()
18:46:51 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0016563943976836857, 'num_filters_1': 66, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.016081357468202377, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 39, 'num_filters_3': 31, 'num_filters_4': 18}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:46:59 DISPATCHER: Starting worker discovery
18:46:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:46:59 DISPATCHER: Finished worker discovery
18:47:59 DISPATCHER: Starting worker discovery
18:47:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:47:59 DISPATCHER: Finished worker discovery
18:48:59 DISPATCHER: Starting worker discovery
18:48:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:48:59 DISPATCHER: Finished worker discovery
18:49:59 DISPATCHER: Starting worker discovery
18:49:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:49:59 DISPATCHER: Finished worker discovery
18:50:11 WORKER: done with job (5, 0, 4), trying to register it.
18:50:11 WORKER: registered result for job (5, 0, 4) with dispatcher
18:50:11 DISPATCHER: job (5, 0, 4) finished
18:50:11 DISPATCHER: register_result: lock acquired
18:50:11 DISPATCHER: job (5, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
18:50:11 job_id: (5, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0016563943976836857, 'num_filters_1': 66, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.016081357468202377, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 39, 'num_filters_3': 31, 'num_filters_4': 18}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5337777727724985, 'info': {'sick_no_sick': 0.5337777727724985, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0016563943976836857, 'num_filters_1': 66, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.016081357468202377, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 39, 'num_filters_3': 31, 'num_filters_4': 18}"}}
exception: None

18:50:11 job_callback for (5, 0, 4) started
18:50:11 DISPATCHER: Trying to submit another job.
18:50:11 job_callback for (5, 0, 4) got condition
18:50:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:50:11 HBMASTER: Trying to run another job!
18:50:11 job_callback for (5, 0, 4) finished
18:50:11 start sampling a new configuration.
18:50:11 done sampling a new configuration.
18:50:11 HBMASTER: schedule new run for iteration 5
18:50:11 HBMASTER: trying submitting job (5, 0, 5) to dispatcher
18:50:11 HBMASTER: submitting job (5, 0, 5) to dispatcher
18:50:11 DISPATCHER: trying to submit job (5, 0, 5)
18:50:11 DISPATCHER: trying to notify the job_runner thread.
18:50:11 HBMASTER: job (5, 0, 5) submitted to dispatcher
18:50:11 DISPATCHER: Trying to submit another job.
18:50:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:50:11 DISPATCHER: starting job (5, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:50:11 DISPATCHER: job (5, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:50:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:50:11 WORKER: start processing job (5, 0, 5)
18:50:11 WORKER: args: ()
18:50:11 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.03130089202647846, 'num_filters_1': 21, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.05676206988104787, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 92, 'num_filters_3': 38, 'num_filters_4': 39}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:50:59 DISPATCHER: Starting worker discovery
18:50:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:50:59 DISPATCHER: Finished worker discovery
18:51:59 DISPATCHER: Starting worker discovery
18:51:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:51:59 DISPATCHER: Finished worker discovery
18:52:59 DISPATCHER: Starting worker discovery
18:52:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:52:59 DISPATCHER: Finished worker discovery
18:53:29 WORKER: done with job (5, 0, 5), trying to register it.
18:53:29 WORKER: registered result for job (5, 0, 5) with dispatcher
18:53:29 DISPATCHER: job (5, 0, 5) finished
18:53:29 DISPATCHER: register_result: lock acquired
18:53:29 DISPATCHER: job (5, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
18:53:29 job_id: (5, 0, 5)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.03130089202647846, 'num_filters_1': 21, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.05676206988104787, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 92, 'num_filters_3': 38, 'num_filters_4': 39}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5186946527401378, 'info': {'sick_no_sick': 0.5186946527401378, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.03130089202647846, 'num_filters_1': 21, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.05676206988104787, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 92, 'num_filters_3': 38, 'num_filters_4': 39}"}}
exception: None

18:53:29 job_callback for (5, 0, 5) started
18:53:29 DISPATCHER: Trying to submit another job.
18:53:29 job_callback for (5, 0, 5) got condition
18:53:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:53:29 HBMASTER: Trying to run another job!
18:53:29 job_callback for (5, 0, 5) finished
18:53:29 start sampling a new configuration.
18:53:29 best_vector: [0, 0, 0.7065028944366043, 0.33009788206140467, 0.8943184414025931, 1, 0.7756713337034786, 0.18915075675756401, 2, 0, 1, 1, 0.36995737055894334, 0.834596988455982, 0.8334807423461437, 0.27978420801898773], 6.828041918326297e-29, 0.00014645487124442287, -5.476580596097241e-07
18:53:29 done sampling a new configuration.
18:53:29 HBMASTER: schedule new run for iteration 5
18:53:29 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
18:53:29 HBMASTER: submitting job (5, 0, 6) to dispatcher
18:53:29 DISPATCHER: trying to submit job (5, 0, 6)
18:53:29 DISPATCHER: trying to notify the job_runner thread.
18:53:29 HBMASTER: job (5, 0, 6) submitted to dispatcher
18:53:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:53:29 DISPATCHER: Trying to submit another job.
18:53:29 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:53:29 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:53:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:53:29 WORKER: start processing job (5, 0, 6)
18:53:29 WORKER: args: ()
18:53:29 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.02588247414638772, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.017623445030384405, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 34, 'num_filters_3': 91, 'num_filters_4': 90, 'num_filters_5': 28}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:53:59 DISPATCHER: Starting worker discovery
18:53:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:53:59 DISPATCHER: Finished worker discovery
18:54:59 DISPATCHER: Starting worker discovery
18:54:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:54:59 DISPATCHER: Finished worker discovery
18:55:59 DISPATCHER: Starting worker discovery
18:55:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:55:59 DISPATCHER: Finished worker discovery
18:56:47 WORKER: done with job (5, 0, 6), trying to register it.
18:56:47 WORKER: registered result for job (5, 0, 6) with dispatcher
18:56:47 DISPATCHER: job (5, 0, 6) finished
18:56:47 DISPATCHER: register_result: lock acquired
18:56:47 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
18:56:47 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.02588247414638772, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.017623445030384405, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 34, 'num_filters_3': 91, 'num_filters_4': 90, 'num_filters_5': 28}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5184238505178664, 'info': {'sick_no_sick': 0.5184238505178664, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.02588247414638772, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.017623445030384405, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 34, 'num_filters_3': 91, 'num_filters_4': 90, 'num_filters_5': 28}"}}
exception: None

18:56:47 job_callback for (5, 0, 6) started
18:56:47 DISPATCHER: Trying to submit another job.
18:56:47 job_callback for (5, 0, 6) got condition
18:56:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:56:47 done building a new model for budget 133.333333 based on 17/28 split
Best loss for this budget:-0.645118





18:56:47 HBMASTER: Trying to run another job!
18:56:47 job_callback for (5, 0, 6) finished
18:56:47 start sampling a new configuration.
18:56:47 best_vector: [3, 1, 0.05417789649612749, 0.16272865602809083, 0.8756262943341425, 1, 0.4685515002259908, 0.08363759673361447, 0, 0, 0, 0, 0.28611748211106336, 0.34208059732207385, 0.4454078740558026, 0.7366369775373178], 4.4147415339407674e-29, 0.00022651382698442182, -1.4385528401418473e-05
18:56:47 done sampling a new configuration.
18:56:47 HBMASTER: schedule new run for iteration 5
18:56:47 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
18:56:47 HBMASTER: submitting job (5, 0, 7) to dispatcher
18:56:47 DISPATCHER: trying to submit job (5, 0, 7)
18:56:47 DISPATCHER: trying to notify the job_runner thread.
18:56:47 HBMASTER: job (5, 0, 7) submitted to dispatcher
18:56:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:56:47 DISPATCHER: Trying to submit another job.
18:56:47 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:56:47 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:56:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:56:47 WORKER: start processing job (5, 0, 7)
18:56:47 WORKER: args: ()
18:56:47 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0012833815542725683, 'num_filters_1': 22, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.012847393378104394, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 28, 'num_filters_3': 32, 'num_filters_4': 40, 'num_filters_5': 74}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:56:59 DISPATCHER: Starting worker discovery
18:56:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:56:59 DISPATCHER: Finished worker discovery
18:57:59 DISPATCHER: Starting worker discovery
18:57:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:57:59 DISPATCHER: Finished worker discovery
18:58:59 DISPATCHER: Starting worker discovery
18:58:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:58:59 DISPATCHER: Finished worker discovery
18:59:59 DISPATCHER: Starting worker discovery
18:59:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:00:00 DISPATCHER: Finished worker discovery
19:00:04 WORKER: done with job (5, 0, 7), trying to register it.
19:00:04 WORKER: registered result for job (5, 0, 7) with dispatcher
19:00:04 DISPATCHER: job (5, 0, 7) finished
19:00:04 DISPATCHER: register_result: lock acquired
19:00:04 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
19:00:04 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0012833815542725683, 'num_filters_1': 22, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.012847393378104394, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 28, 'num_filters_3': 32, 'num_filters_4': 40, 'num_filters_5': 74}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5639843066449716, 'info': {'sick_no_sick': 0.5639843066449716, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0012833815542725683, 'num_filters_1': 22, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.012847393378104394, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 28, 'num_filters_3': 32, 'num_filters_4': 40, 'num_filters_5': 74}"}}
exception: None

19:00:04 job_callback for (5, 0, 7) started
19:00:04 job_callback for (5, 0, 7) got condition
19:00:04 DISPATCHER: Trying to submit another job.
19:00:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:00:04 done building a new model for budget 133.333333 based on 17/29 split
Best loss for this budget:-0.645118





19:00:04 HBMASTER: Trying to run another job!
19:00:04 job_callback for (5, 0, 7) finished
19:00:04 start sampling a new configuration.
19:00:04 best_vector: [0, 1, 0.504917992709116, 0.46753631015611424, 0.82027444137836, 1, 0.9146895759778975, 0.006911260979029804, 2, 2, 0, 1, 0.37821593305650497, 0.1897960644378886, 0.9998895363356687, 0.398308655453366], 2.5210328452738645e-28, 3.966628209048058e-05, -2.5657582718290797e-07
19:00:04 done sampling a new configuration.
19:00:04 HBMASTER: schedule new run for iteration 5
19:00:04 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
19:00:04 HBMASTER: submitting job (5, 0, 8) to dispatcher
19:00:04 DISPATCHER: trying to submit job (5, 0, 8)
19:00:04 DISPATCHER: trying to notify the job_runner thread.
19:00:04 HBMASTER: job (5, 0, 8) submitted to dispatcher
19:00:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:00:04 DISPATCHER: Trying to submit another job.
19:00:04 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:00:04 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:00:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:00:04 WORKER: start processing job (5, 0, 8)
19:00:04 WORKER: args: ()
19:00:04 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.010229066109402916, 'num_filters_1': 42, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.01020920108225226, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 34, 'num_filters_3': 23, 'num_filters_4': 128, 'num_filters_5': 36}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:01:00 DISPATCHER: Starting worker discovery
19:01:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:01:00 DISPATCHER: Finished worker discovery
19:02:00 DISPATCHER: Starting worker discovery
19:02:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:02:00 DISPATCHER: Finished worker discovery
19:03:00 DISPATCHER: Starting worker discovery
19:03:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:03:00 DISPATCHER: Finished worker discovery
19:03:22 WORKER: done with job (5, 0, 8), trying to register it.
19:03:22 WORKER: registered result for job (5, 0, 8) with dispatcher
19:03:22 DISPATCHER: job (5, 0, 8) finished
19:03:22 DISPATCHER: register_result: lock acquired
19:03:22 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
19:03:22 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.010229066109402916, 'num_filters_1': 42, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.01020920108225226, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 34, 'num_filters_3': 23, 'num_filters_4': 128, 'num_filters_5': 36}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6055792733267291, 'info': {'sick_no_sick': 0.6055792733267291, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.010229066109402916, 'num_filters_1': 42, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.01020920108225226, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 34, 'num_filters_3': 23, 'num_filters_4': 128, 'num_filters_5': 36}"}}
exception: None

19:03:22 job_callback for (5, 0, 8) started
19:03:22 DISPATCHER: Trying to submit another job.
19:03:22 job_callback for (5, 0, 8) got condition
19:03:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:03:22 done building a new model for budget 133.333333 based on 17/30 split
Best loss for this budget:-0.645118





19:03:22 HBMASTER: Trying to run another job!
19:03:22 job_callback for (5, 0, 8) finished
19:03:22 ITERATION: Advancing config (5, 0, 3) to next budget 400.000000
19:03:22 ITERATION: Advancing config (5, 0, 7) to next budget 400.000000
19:03:22 ITERATION: Advancing config (5, 0, 8) to next budget 400.000000
19:03:22 HBMASTER: schedule new run for iteration 5
19:03:22 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
19:03:22 HBMASTER: submitting job (5, 0, 3) to dispatcher
19:03:22 DISPATCHER: trying to submit job (5, 0, 3)
19:03:22 DISPATCHER: trying to notify the job_runner thread.
19:03:22 HBMASTER: job (5, 0, 3) submitted to dispatcher
19:03:22 DISPATCHER: Trying to submit another job.
19:03:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:03:22 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:03:22 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:03:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:03:22 WORKER: start processing job (5, 0, 3)
19:03:22 WORKER: args: ()
19:03:22 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.008931424040135584, 'num_filters_1': 58, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.013872757967319037, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 127, 'num_filters_3': 75, 'num_filters_4': 32, 'num_filters_5': 48}, 'budget': 400.0, 'working_directory': '.'}
19:04:00 DISPATCHER: Starting worker discovery
19:04:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:04:00 DISPATCHER: Finished worker discovery
19:05:00 DISPATCHER: Starting worker discovery
19:05:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:05:00 DISPATCHER: Finished worker discovery
19:06:00 DISPATCHER: Starting worker discovery
19:06:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:06:00 DISPATCHER: Finished worker discovery
19:07:00 DISPATCHER: Starting worker discovery
19:07:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:07:00 DISPATCHER: Finished worker discovery
19:08:00 DISPATCHER: Starting worker discovery
19:08:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:08:00 DISPATCHER: Finished worker discovery
19:09:00 DISPATCHER: Starting worker discovery
19:09:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:09:00 DISPATCHER: Finished worker discovery
19:10:00 DISPATCHER: Starting worker discovery
19:10:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:10:00 DISPATCHER: Finished worker discovery
19:11:00 DISPATCHER: Starting worker discovery
19:11:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:11:00 DISPATCHER: Finished worker discovery
19:11:12 WORKER: done with job (5, 0, 3), trying to register it.
19:11:12 WORKER: registered result for job (5, 0, 3) with dispatcher
19:11:12 DISPATCHER: job (5, 0, 3) finished
19:11:12 DISPATCHER: register_result: lock acquired
19:11:12 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
19:11:12 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.008931424040135584, 'num_filters_1': 58, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.013872757967319037, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 127, 'num_filters_3': 75, 'num_filters_4': 32, 'num_filters_5': 48}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.574593612797996, 'info': {'sick_no_sick': 0.574593612797996, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.008931424040135584, 'num_filters_1': 58, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.013872757967319037, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 127, 'num_filters_3': 75, 'num_filters_4': 32, 'num_filters_5': 48}"}}
exception: None

19:11:12 job_callback for (5, 0, 3) started
19:11:12 DISPATCHER: Trying to submit another job.
19:11:12 job_callback for (5, 0, 3) got condition
19:11:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:11:12 Only 16 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
19:11:12 HBMASTER: Trying to run another job!
19:11:12 job_callback for (5, 0, 3) finished
19:11:12 HBMASTER: schedule new run for iteration 5
19:11:12 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
19:11:12 HBMASTER: submitting job (5, 0, 7) to dispatcher
19:11:12 DISPATCHER: trying to submit job (5, 0, 7)
19:11:12 DISPATCHER: trying to notify the job_runner thread.
19:11:12 HBMASTER: job (5, 0, 7) submitted to dispatcher
19:11:12 DISPATCHER: Trying to submit another job.
19:11:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:11:12 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:11:12 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:11:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:11:12 WORKER: start processing job (5, 0, 7)
19:11:12 WORKER: args: ()
19:11:12 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0012833815542725683, 'num_filters_1': 22, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.012847393378104394, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 28, 'num_filters_3': 32, 'num_filters_4': 40, 'num_filters_5': 74}, 'budget': 400.0, 'working_directory': '.'}
19:12:00 DISPATCHER: Starting worker discovery
19:12:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:12:00 DISPATCHER: Finished worker discovery
19:13:00 DISPATCHER: Starting worker discovery
19:13:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:13:00 DISPATCHER: Finished worker discovery
19:14:00 DISPATCHER: Starting worker discovery
19:14:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:14:00 DISPATCHER: Finished worker discovery
19:15:00 DISPATCHER: Starting worker discovery
19:15:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:15:00 DISPATCHER: Finished worker discovery
19:16:00 DISPATCHER: Starting worker discovery
19:16:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:16:00 DISPATCHER: Finished worker discovery
19:17:00 DISPATCHER: Starting worker discovery
19:17:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:17:00 DISPATCHER: Finished worker discovery
19:18:00 DISPATCHER: Starting worker discovery
19:18:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:18:00 DISPATCHER: Finished worker discovery
19:19:00 DISPATCHER: Starting worker discovery
19:19:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:19:00 DISPATCHER: Finished worker discovery
19:19:01 WORKER: done with job (5, 0, 7), trying to register it.
19:19:01 WORKER: registered result for job (5, 0, 7) with dispatcher
19:19:01 DISPATCHER: job (5, 0, 7) finished
19:19:01 DISPATCHER: register_result: lock acquired
19:19:01 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
19:19:01 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0012833815542725683, 'num_filters_1': 22, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.012847393378104394, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 28, 'num_filters_3': 32, 'num_filters_4': 40, 'num_filters_5': 74}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5435419175639381, 'info': {'sick_no_sick': 0.5435419175639381, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0012833815542725683, 'num_filters_1': 22, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.012847393378104394, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 28, 'num_filters_3': 32, 'num_filters_4': 40, 'num_filters_5': 74}"}}
exception: None

19:19:01 job_callback for (5, 0, 7) started
19:19:01 DISPATCHER: Trying to submit another job.
19:19:01 job_callback for (5, 0, 7) got condition
19:19:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:19:01 HBMASTER: Trying to run another job!
19:19:01 job_callback for (5, 0, 7) finished
19:19:01 HBMASTER: schedule new run for iteration 5
19:19:01 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
19:19:01 HBMASTER: submitting job (5, 0, 8) to dispatcher
19:19:01 DISPATCHER: trying to submit job (5, 0, 8)
19:19:01 DISPATCHER: trying to notify the job_runner thread.
19:19:01 HBMASTER: job (5, 0, 8) submitted to dispatcher
19:19:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:19:01 DISPATCHER: Trying to submit another job.
19:19:01 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:19:01 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:19:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:19:01 WORKER: start processing job (5, 0, 8)
19:19:01 WORKER: args: ()
19:19:01 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.010229066109402916, 'num_filters_1': 42, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.01020920108225226, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 34, 'num_filters_3': 23, 'num_filters_4': 128, 'num_filters_5': 36}, 'budget': 400.0, 'working_directory': '.'}
19:20:00 DISPATCHER: Starting worker discovery
19:20:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:20:00 DISPATCHER: Finished worker discovery
19:21:00 DISPATCHER: Starting worker discovery
19:21:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:21:00 DISPATCHER: Finished worker discovery
19:22:00 DISPATCHER: Starting worker discovery
19:22:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:22:00 DISPATCHER: Finished worker discovery
19:23:00 DISPATCHER: Starting worker discovery
19:23:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:23:00 DISPATCHER: Finished worker discovery
19:24:00 DISPATCHER: Starting worker discovery
19:24:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:24:00 DISPATCHER: Finished worker discovery
19:25:00 DISPATCHER: Starting worker discovery
19:25:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:25:00 DISPATCHER: Finished worker discovery
19:26:00 DISPATCHER: Starting worker discovery
19:26:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:26:00 DISPATCHER: Finished worker discovery
19:26:52 WORKER: done with job (5, 0, 8), trying to register it.
19:26:52 WORKER: registered result for job (5, 0, 8) with dispatcher
19:26:52 DISPATCHER: job (5, 0, 8) finished
19:26:52 DISPATCHER: register_result: lock acquired
19:26:52 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
19:26:52 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.010229066109402916, 'num_filters_1': 42, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.01020920108225226, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 34, 'num_filters_3': 23, 'num_filters_4': 128, 'num_filters_5': 36}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5861483308265929, 'info': {'sick_no_sick': 0.5861483308265929, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.010229066109402916, 'num_filters_1': 42, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.01020920108225226, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 34, 'num_filters_3': 23, 'num_filters_4': 128, 'num_filters_5': 36}"}}
exception: None

19:26:52 job_callback for (5, 0, 8) started
19:26:52 DISPATCHER: Trying to submit another job.
19:26:52 job_callback for (5, 0, 8) got condition
19:26:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:26:52 HBMASTER: Trying to run another job!
19:26:52 job_callback for (5, 0, 8) finished
19:26:52 ITERATION: Advancing config (5, 0, 8) to next budget 1200.000000
19:26:52 HBMASTER: schedule new run for iteration 5
19:26:52 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
19:26:52 HBMASTER: submitting job (5, 0, 8) to dispatcher
19:26:52 DISPATCHER: trying to submit job (5, 0, 8)
19:26:52 DISPATCHER: trying to notify the job_runner thread.
19:26:52 HBMASTER: job (5, 0, 8) submitted to dispatcher
19:26:52 DISPATCHER: Trying to submit another job.
19:26:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:26:52 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:26:52 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:26:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:26:52 WORKER: start processing job (5, 0, 8)
19:26:52 WORKER: args: ()
19:26:52 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.010229066109402916, 'num_filters_1': 42, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.01020920108225226, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 34, 'num_filters_3': 23, 'num_filters_4': 128, 'num_filters_5': 36}, 'budget': 1200.0, 'working_directory': '.'}
19:27:00 DISPATCHER: Starting worker discovery
19:27:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:27:00 DISPATCHER: Finished worker discovery
19:28:00 DISPATCHER: Starting worker discovery
19:28:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:28:00 DISPATCHER: Finished worker discovery
19:29:00 DISPATCHER: Starting worker discovery
19:29:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:29:00 DISPATCHER: Finished worker discovery
19:30:00 DISPATCHER: Starting worker discovery
19:30:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:30:00 DISPATCHER: Finished worker discovery
19:31:00 DISPATCHER: Starting worker discovery
19:31:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:31:00 DISPATCHER: Finished worker discovery
19:32:00 DISPATCHER: Starting worker discovery
19:32:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:32:00 DISPATCHER: Finished worker discovery
19:33:00 DISPATCHER: Starting worker discovery
19:33:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:33:00 DISPATCHER: Finished worker discovery
19:34:00 DISPATCHER: Starting worker discovery
19:34:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:34:00 DISPATCHER: Finished worker discovery
19:35:00 DISPATCHER: Starting worker discovery
19:35:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:35:00 DISPATCHER: Finished worker discovery
19:36:00 DISPATCHER: Starting worker discovery
19:36:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:36:00 DISPATCHER: Finished worker discovery
19:37:00 DISPATCHER: Starting worker discovery
19:37:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:37:00 DISPATCHER: Finished worker discovery
19:38:00 DISPATCHER: Starting worker discovery
19:38:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:38:00 DISPATCHER: Finished worker discovery
19:39:00 DISPATCHER: Starting worker discovery
19:39:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:39:00 DISPATCHER: Finished worker discovery
19:40:00 DISPATCHER: Starting worker discovery
19:40:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:40:00 DISPATCHER: Finished worker discovery
19:41:00 DISPATCHER: Starting worker discovery
19:41:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:41:00 DISPATCHER: Finished worker discovery
19:42:00 DISPATCHER: Starting worker discovery
19:42:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:42:00 DISPATCHER: Finished worker discovery
19:43:00 DISPATCHER: Starting worker discovery
19:43:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:43:00 DISPATCHER: Finished worker discovery
19:44:00 DISPATCHER: Starting worker discovery
19:44:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:44:00 DISPATCHER: Finished worker discovery
19:45:00 DISPATCHER: Starting worker discovery
19:45:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:45:00 DISPATCHER: Finished worker discovery
19:46:00 DISPATCHER: Starting worker discovery
19:46:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:46:00 DISPATCHER: Finished worker discovery
19:47:00 DISPATCHER: Starting worker discovery
19:47:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:47:00 DISPATCHER: Finished worker discovery
19:48:00 DISPATCHER: Starting worker discovery
19:48:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:48:00 DISPATCHER: Finished worker discovery
19:48:13 WORKER: done with job (5, 0, 8), trying to register it.
19:48:13 WORKER: registered result for job (5, 0, 8) with dispatcher
19:48:13 DISPATCHER: job (5, 0, 8) finished
19:48:13 DISPATCHER: register_result: lock acquired
19:48:13 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
19:48:13 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.010229066109402916, 'num_filters_1': 42, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.01020920108225226, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 34, 'num_filters_3': 23, 'num_filters_4': 128, 'num_filters_5': 36}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5914426804359869, 'info': {'sick_no_sick': 0.5914426804359869, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.010229066109402916, 'num_filters_1': 42, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.01020920108225226, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 34, 'num_filters_3': 23, 'num_filters_4': 128, 'num_filters_5': 36}"}}
exception: None

19:48:13 job_callback for (5, 0, 8) started
19:48:13 DISPATCHER: Trying to submit another job.
19:48:13 job_callback for (5, 0, 8) got condition
19:48:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:48:13 Only 10 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
19:48:13 HBMASTER: Trying to run another job!
19:48:13 job_callback for (5, 0, 8) finished
19:48:13 start sampling a new configuration.
19:48:13 best_vector: [3, 0, 0.07735965460615662, 0.5538239958530526, 0.5275988420679081, 1, 0.7917029118592903, 0.11704367399843874, 2, 1, 1, 2, 0.9320004092819031, 0.9791986482694184, 0.5035589317690873, 0.9497640155445211], 0.0013541862865483556, 0.003352151903587017, 4.539438138264504e-06
19:48:13 done sampling a new configuration.
19:48:13 HBMASTER: schedule new run for iteration 6
19:48:13 HBMASTER: trying submitting job (6, 0, 0) to dispatcher
19:48:13 HBMASTER: submitting job (6, 0, 0) to dispatcher
19:48:13 DISPATCHER: trying to submit job (6, 0, 0)
19:48:13 DISPATCHER: trying to notify the job_runner thread.
19:48:13 HBMASTER: job (6, 0, 0) submitted to dispatcher
19:48:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:48:13 DISPATCHER: Trying to submit another job.
19:48:13 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:48:13 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:48:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:48:13 WORKER: start processing job (6, 0, 0)
19:48:13 WORKER: args: ()
19:48:13 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0014279707421122859, 'num_filters_1': 50, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.014199639892556038, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 111, 'num_filters_3': 123}, 'budget': 400.0, 'working_directory': '.'}
19:49:00 DISPATCHER: Starting worker discovery
19:49:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:49:00 DISPATCHER: Finished worker discovery
19:50:00 DISPATCHER: Starting worker discovery
19:50:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:50:00 DISPATCHER: Finished worker discovery
19:51:00 DISPATCHER: Starting worker discovery
19:51:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:51:00 DISPATCHER: Finished worker discovery
19:52:00 DISPATCHER: Starting worker discovery
19:52:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:52:00 DISPATCHER: Finished worker discovery
19:53:00 DISPATCHER: Starting worker discovery
19:53:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:53:00 DISPATCHER: Finished worker discovery
19:54:00 DISPATCHER: Starting worker discovery
19:54:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:54:00 DISPATCHER: Finished worker discovery
19:55:00 DISPATCHER: Starting worker discovery
19:55:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:55:00 DISPATCHER: Finished worker discovery
19:55:57 WORKER: done with job (6, 0, 0), trying to register it.
19:55:57 WORKER: registered result for job (6, 0, 0) with dispatcher
19:55:57 DISPATCHER: job (6, 0, 0) finished
19:55:57 DISPATCHER: register_result: lock acquired
19:55:57 DISPATCHER: job (6, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
19:55:57 job_id: (6, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0014279707421122859, 'num_filters_1': 50, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.014199639892556038, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 111, 'num_filters_3': 123}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5527757793230967, 'info': {'sick_no_sick': 0.5527757793230967, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0014279707421122859, 'num_filters_1': 50, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.014199639892556038, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 111, 'num_filters_3': 123}"}}
exception: None

19:55:57 job_callback for (6, 0, 0) started
19:55:57 DISPATCHER: Trying to submit another job.
19:55:57 job_callback for (6, 0, 0) got condition
19:55:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:55:57 HBMASTER: Trying to run another job!
19:55:57 job_callback for (6, 0, 0) finished
19:55:57 start sampling a new configuration.
19:55:57 done sampling a new configuration.
19:55:57 HBMASTER: schedule new run for iteration 6
19:55:57 HBMASTER: trying submitting job (6, 0, 1) to dispatcher
19:55:57 HBMASTER: submitting job (6, 0, 1) to dispatcher
19:55:57 DISPATCHER: trying to submit job (6, 0, 1)
19:55:57 DISPATCHER: trying to notify the job_runner thread.
19:55:57 HBMASTER: job (6, 0, 1) submitted to dispatcher
19:55:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:55:57 DISPATCHER: Trying to submit another job.
19:55:57 DISPATCHER: starting job (6, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:55:57 DISPATCHER: job (6, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:55:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:55:57 WORKER: start processing job (6, 0, 1)
19:55:57 WORKER: args: ()
19:55:57 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.005774180881716853, 'num_filters_1': 33, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.011931522974802653, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 17, 'num_filters_3': 54, 'num_filters_4': 20, 'num_filters_5': 24}, 'budget': 400.0, 'working_directory': '.'}
19:56:00 DISPATCHER: Starting worker discovery
19:56:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:56:00 DISPATCHER: Finished worker discovery
19:57:00 DISPATCHER: Starting worker discovery
19:57:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:57:00 DISPATCHER: Finished worker discovery
19:58:00 DISPATCHER: Starting worker discovery
19:58:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:58:00 DISPATCHER: Finished worker discovery
19:59:00 DISPATCHER: Starting worker discovery
19:59:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:59:00 DISPATCHER: Finished worker discovery
20:00:00 DISPATCHER: Starting worker discovery
20:00:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:00:00 DISPATCHER: Finished worker discovery
20:01:00 DISPATCHER: Starting worker discovery
20:01:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:01:00 DISPATCHER: Finished worker discovery
20:02:00 DISPATCHER: Starting worker discovery
20:02:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:02:00 DISPATCHER: Finished worker discovery
20:03:00 DISPATCHER: Starting worker discovery
20:03:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:03:00 DISPATCHER: Finished worker discovery
20:04:00 DISPATCHER: Starting worker discovery
20:04:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:04:00 DISPATCHER: Finished worker discovery
20:04:16 WORKER: done with job (6, 0, 1), trying to register it.
20:04:16 WORKER: registered result for job (6, 0, 1) with dispatcher
20:04:16 DISPATCHER: job (6, 0, 1) finished
20:04:16 DISPATCHER: register_result: lock acquired
20:04:16 DISPATCHER: job (6, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
20:04:16 job_id: (6, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.005774180881716853, 'num_filters_1': 33, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.011931522974802653, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 17, 'num_filters_3': 54, 'num_filters_4': 20, 'num_filters_5': 24}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5943191350884519, 'info': {'sick_no_sick': 0.5943191350884519, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.005774180881716853, 'num_filters_1': 33, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.011931522974802653, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 17, 'num_filters_3': 54, 'num_filters_4': 20, 'num_filters_5': 24}"}}
exception: None

20:04:16 job_callback for (6, 0, 1) started
20:04:16 DISPATCHER: Trying to submit another job.
20:04:16 job_callback for (6, 0, 1) got condition
20:04:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:04:16 HBMASTER: Trying to run another job!
20:04:16 job_callback for (6, 0, 1) finished
20:04:16 start sampling a new configuration.
20:04:16 best_vector: [0, 0, 0.19999806541581977, 0.7019188359595829, 0.999247157469072, 1, 0.7482208560571694, 0.11532103166779202, 1, 1, 1, 0, 0.8749365441761789, 0.2236194626003548, 0.1774708537028996, 0.18579596967921075], 0.0008530727661051893, 0.0011965618803207055, 1.0207543530612108e-06
20:04:16 done sampling a new configuration.
20:04:16 HBMASTER: schedule new run for iteration 6
20:04:16 HBMASTER: trying submitting job (6, 0, 2) to dispatcher
20:04:16 HBMASTER: submitting job (6, 0, 2) to dispatcher
20:04:16 DISPATCHER: trying to submit job (6, 0, 2)
20:04:16 DISPATCHER: trying to notify the job_runner thread.
20:04:16 HBMASTER: job (6, 0, 2) submitted to dispatcher
20:04:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:04:16 DISPATCHER: Trying to submit another job.
20:04:16 DISPATCHER: starting job (6, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
20:04:16 DISPATCHER: job (6, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
20:04:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:04:16 WORKER: start processing job (6, 0, 2)
20:04:16 WORKER: args: ()
20:04:16 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0025118640529885133, 'num_filters_1': 68, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.014126550336994574, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 99, 'num_filters_3': 25, 'num_filters_4': 23, 'num_filters_5': 23}, 'budget': 400.0, 'working_directory': '.'}
20:05:00 DISPATCHER: Starting worker discovery
20:05:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:05:00 DISPATCHER: Finished worker discovery
20:06:00 DISPATCHER: Starting worker discovery
20:06:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:06:00 DISPATCHER: Finished worker discovery
20:07:00 DISPATCHER: Starting worker discovery
20:07:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:07:00 DISPATCHER: Finished worker discovery
20:08:00 DISPATCHER: Starting worker discovery
20:08:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:08:00 DISPATCHER: Finished worker discovery
20:09:00 DISPATCHER: Starting worker discovery
20:09:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:09:00 DISPATCHER: Finished worker discovery
20:10:00 DISPATCHER: Starting worker discovery
20:10:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:10:00 DISPATCHER: Finished worker discovery
20:11:00 DISPATCHER: Starting worker discovery
20:11:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:11:00 DISPATCHER: Finished worker discovery
20:12:00 DISPATCHER: Starting worker discovery
20:12:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:12:00 DISPATCHER: Finished worker discovery
20:12:07 WORKER: done with job (6, 0, 2), trying to register it.
20:12:07 WORKER: registered result for job (6, 0, 2) with dispatcher
20:12:07 DISPATCHER: job (6, 0, 2) finished
20:12:07 DISPATCHER: register_result: lock acquired
20:12:07 DISPATCHER: job (6, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
20:12:07 job_id: (6, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0025118640529885133, 'num_filters_1': 68, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.014126550336994574, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 99, 'num_filters_3': 25, 'num_filters_4': 23, 'num_filters_5': 23}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5858248056608066, 'info': {'sick_no_sick': 0.5858248056608066, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0025118640529885133, 'num_filters_1': 68, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.014126550336994574, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 99, 'num_filters_3': 25, 'num_filters_4': 23, 'num_filters_5': 23}"}}
exception: None

20:12:07 job_callback for (6, 0, 2) started
20:12:07 DISPATCHER: Trying to submit another job.
20:12:07 job_callback for (6, 0, 2) got condition
20:12:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:12:07 HBMASTER: Trying to run another job!
20:12:07 job_callback for (6, 0, 2) finished
20:12:07 start sampling a new configuration.
20:12:07 done sampling a new configuration.
20:12:07 HBMASTER: schedule new run for iteration 6
20:12:07 HBMASTER: trying submitting job (6, 0, 3) to dispatcher
20:12:07 HBMASTER: submitting job (6, 0, 3) to dispatcher
20:12:07 DISPATCHER: trying to submit job (6, 0, 3)
20:12:07 DISPATCHER: trying to notify the job_runner thread.
20:12:07 HBMASTER: job (6, 0, 3) submitted to dispatcher
20:12:07 DISPATCHER: Trying to submit another job.
20:12:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:12:07 DISPATCHER: starting job (6, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
20:12:07 DISPATCHER: job (6, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
20:12:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:12:07 WORKER: start processing job (6, 0, 3)
20:12:07 WORKER: args: ()
20:12:07 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.013487019381250336, 'num_filters_1': 42, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.011263177218491557, 'kernel_size_2': 7, 'num_filters_2': 50}, 'budget': 400.0, 'working_directory': '.'}
20:13:00 DISPATCHER: Starting worker discovery
20:13:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:13:00 DISPATCHER: Finished worker discovery
20:14:00 DISPATCHER: Starting worker discovery
20:14:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:14:00 DISPATCHER: Finished worker discovery
20:15:00 DISPATCHER: Starting worker discovery
20:15:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:15:00 DISPATCHER: Finished worker discovery
20:16:00 DISPATCHER: Starting worker discovery
20:16:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:16:00 DISPATCHER: Finished worker discovery
20:17:00 DISPATCHER: Starting worker discovery
20:17:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:17:00 DISPATCHER: Finished worker discovery
20:18:00 DISPATCHER: Starting worker discovery
20:18:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:18:00 DISPATCHER: Finished worker discovery
20:19:00 DISPATCHER: Starting worker discovery
20:19:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:19:00 DISPATCHER: Finished worker discovery
20:20:00 WORKER: done with job (6, 0, 3), trying to register it.
20:20:00 WORKER: registered result for job (6, 0, 3) with dispatcher
20:20:00 DISPATCHER: job (6, 0, 3) finished
20:20:00 DISPATCHER: register_result: lock acquired
20:20:00 DISPATCHER: job (6, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
20:20:00 job_id: (6, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.013487019381250336, 'num_filters_1': 42, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.011263177218491557, 'kernel_size_2': 7, 'num_filters_2': 50}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5272019792476346, 'info': {'sick_no_sick': 0.5272019792476346, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.013487019381250336, 'num_filters_1': 42, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.011263177218491557, 'kernel_size_2': 7, 'num_filters_2': 50}"}}
exception: None

20:20:00 job_callback for (6, 0, 3) started
20:20:00 job_callback for (6, 0, 3) got condition
20:20:00 DISPATCHER: Trying to submit another job.
20:20:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:20:00 HBMASTER: Trying to run another job!
20:20:00 job_callback for (6, 0, 3) finished
20:20:00 start sampling a new configuration.
20:20:00 done sampling a new configuration.
20:20:00 HBMASTER: schedule new run for iteration 6
20:20:00 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
20:20:00 HBMASTER: submitting job (6, 0, 4) to dispatcher
20:20:00 DISPATCHER: trying to submit job (6, 0, 4)
20:20:00 DISPATCHER: trying to notify the job_runner thread.
20:20:00 HBMASTER: job (6, 0, 4) submitted to dispatcher
20:20:00 DISPATCHER: Trying to submit another job.
20:20:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:20:00 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776
20:20:00 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
20:20:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:20:00 WORKER: start processing job (6, 0, 4)
20:20:00 WORKER: args: ()
20:20:00 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.005390642702380795, 'num_filters_1': 17, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.046258479156405644, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 59, 'num_filters_3': 27, 'num_filters_4': 79, 'num_filters_5': 69}, 'budget': 400.0, 'working_directory': '.'}
20:20:00 DISPATCHER: Starting worker discovery
20:20:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:20:00 DISPATCHER: Finished worker discovery
20:21:00 DISPATCHER: Starting worker discovery
20:21:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:21:00 DISPATCHER: Finished worker discovery
20:22:00 DISPATCHER: Starting worker discovery
20:22:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:22:00 DISPATCHER: Finished worker discovery
20:23:00 DISPATCHER: Starting worker discovery
20:23:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:23:00 DISPATCHER: Finished worker discovery
20:24:00 DISPATCHER: Starting worker discovery
20:24:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:24:00 DISPATCHER: Finished worker discovery
20:25:00 DISPATCHER: Starting worker discovery
20:25:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:25:00 DISPATCHER: Finished worker discovery
20:26:00 DISPATCHER: Starting worker discovery
20:26:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:26:00 DISPATCHER: Finished worker discovery
20:27:00 DISPATCHER: Starting worker discovery
20:27:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:27:00 DISPATCHER: Finished worker discovery
20:27:46 WORKER: done with job (6, 0, 4), trying to register it.
20:27:46 WORKER: registered result for job (6, 0, 4) with dispatcher
20:27:46 DISPATCHER: job (6, 0, 4) finished
20:27:46 DISPATCHER: register_result: lock acquired
20:27:46 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
20:27:46 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.005390642702380795, 'num_filters_1': 17, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.046258479156405644, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 59, 'num_filters_3': 27, 'num_filters_4': 79, 'num_filters_5': 69}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.005390642702380795, 'num_filters_1': 17, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.046258479156405644, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 59, 'num_filters_3': 27, 'num_filters_4': 79, 'num_filters_5': 69}"}}
exception: None

20:27:46 job_callback for (6, 0, 4) started
20:27:46 DISPATCHER: Trying to submit another job.
20:27:46 job_callback for (6, 0, 4) got condition
20:27:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:27:46 HBMASTER: Trying to run another job!
20:27:46 job_callback for (6, 0, 4) finished
20:27:46 start sampling a new configuration.
20:27:46 best_vector: [2, 0, 0.39607887905617034, 0.5949727548726481, 0.5739927088130056, 1, 0.15901455211254004, 0.022698200781325006, 0, 0, 2, 1, 0.14622604016209328, 0.7497619865028451, 0.3834277000684667, 0.9086853371713444], 0.00154077784518037, 0.003071255295745441, 4.732122116577461e-06
20:27:46 done sampling a new configuration.
20:27:46 HBMASTER: schedule new run for iteration 6
20:27:46 HBMASTER: trying submitting job (6, 0, 5) to dispatcher
20:27:46 HBMASTER: submitting job (6, 0, 5) to dispatcher
20:27:46 DISPATCHER: trying to submit job (6, 0, 5)
20:27:46 DISPATCHER: trying to notify the job_runner thread.
20:27:46 HBMASTER: job (6, 0, 5) submitted to dispatcher
20:27:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:27:46 DISPATCHER: Trying to submit another job.
20:27:46 DISPATCHER: starting job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776
20:27:46 DISPATCHER: job (6, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
20:27:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:27:46 WORKER: start processing job (6, 0, 5)
20:27:46 WORKER: args: ()
20:27:46 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.006196661288357782, 'num_filters_1': 55, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.010703628815697166, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 21, 'num_filters_3': 76}, 'budget': 400.0, 'working_directory': '.'}
20:28:00 DISPATCHER: Starting worker discovery
20:28:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:28:00 DISPATCHER: Finished worker discovery
20:29:00 DISPATCHER: Starting worker discovery
20:29:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:29:00 DISPATCHER: Finished worker discovery
20:30:00 DISPATCHER: Starting worker discovery
20:30:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:30:00 DISPATCHER: Finished worker discovery
20:31:00 DISPATCHER: Starting worker discovery
20:31:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:31:00 DISPATCHER: Finished worker discovery
20:32:00 DISPATCHER: Starting worker discovery
20:32:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:32:00 DISPATCHER: Finished worker discovery
20:33:00 DISPATCHER: Starting worker discovery
20:33:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:33:00 DISPATCHER: Finished worker discovery
20:34:00 DISPATCHER: Starting worker discovery
20:34:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:34:00 DISPATCHER: Finished worker discovery
20:35:00 DISPATCHER: Starting worker discovery
20:35:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:35:00 DISPATCHER: Finished worker discovery
20:35:44 WORKER: done with job (6, 0, 5), trying to register it.
20:35:44 WORKER: registered result for job (6, 0, 5) with dispatcher
20:35:44 DISPATCHER: job (6, 0, 5) finished
20:35:44 DISPATCHER: register_result: lock acquired
20:35:44 DISPATCHER: job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
20:35:44 job_id: (6, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.006196661288357782, 'num_filters_1': 55, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.010703628815697166, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 21, 'num_filters_3': 76}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5302258708920082, 'info': {'sick_no_sick': 0.5302258708920082, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.006196661288357782, 'num_filters_1': 55, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.010703628815697166, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 21, 'num_filters_3': 76}"}}
exception: None

20:35:44 job_callback for (6, 0, 5) started
20:35:44 job_callback for (6, 0, 5) got condition
20:35:44 DISPATCHER: Trying to submit another job.
20:35:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:35:44 HBMASTER: Trying to run another job!
20:35:44 job_callback for (6, 0, 5) finished
20:35:44 ITERATION: Advancing config (6, 0, 1) to next budget 1200.000000
20:35:44 ITERATION: Advancing config (6, 0, 2) to next budget 1200.000000
20:35:44 HBMASTER: schedule new run for iteration 6
20:35:44 HBMASTER: trying submitting job (6, 0, 1) to dispatcher
20:35:44 HBMASTER: submitting job (6, 0, 1) to dispatcher
20:35:44 DISPATCHER: trying to submit job (6, 0, 1)
20:35:44 DISPATCHER: trying to notify the job_runner thread.
20:35:44 HBMASTER: job (6, 0, 1) submitted to dispatcher
20:35:44 DISPATCHER: Trying to submit another job.
20:35:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:35:44 DISPATCHER: starting job (6, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
20:35:44 DISPATCHER: job (6, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
20:35:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:35:44 WORKER: start processing job (6, 0, 1)
20:35:44 WORKER: args: ()
20:35:44 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.005774180881716853, 'num_filters_1': 33, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.011931522974802653, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 17, 'num_filters_3': 54, 'num_filters_4': 20, 'num_filters_5': 24}, 'budget': 1200.0, 'working_directory': '.'}
20:36:00 DISPATCHER: Starting worker discovery
20:36:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:36:00 DISPATCHER: Finished worker discovery
20:37:00 DISPATCHER: Starting worker discovery
20:37:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:37:01 DISPATCHER: Finished worker discovery
20:38:01 DISPATCHER: Starting worker discovery
20:38:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:38:01 DISPATCHER: Finished worker discovery
20:39:01 DISPATCHER: Starting worker discovery
20:39:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:39:01 DISPATCHER: Finished worker discovery
20:40:01 DISPATCHER: Starting worker discovery
20:40:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:40:01 DISPATCHER: Finished worker discovery
20:41:01 DISPATCHER: Starting worker discovery
20:41:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:41:01 DISPATCHER: Finished worker discovery
20:42:01 DISPATCHER: Starting worker discovery
20:42:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:42:01 DISPATCHER: Finished worker discovery
20:43:01 DISPATCHER: Starting worker discovery
20:43:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:43:01 DISPATCHER: Finished worker discovery
20:44:01 DISPATCHER: Starting worker discovery
20:44:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:44:01 DISPATCHER: Finished worker discovery
20:45:01 DISPATCHER: Starting worker discovery
20:45:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:45:01 DISPATCHER: Finished worker discovery
20:46:01 DISPATCHER: Starting worker discovery
20:46:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:46:01 DISPATCHER: Finished worker discovery
20:47:01 DISPATCHER: Starting worker discovery
20:47:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:47:01 DISPATCHER: Finished worker discovery
20:48:01 DISPATCHER: Starting worker discovery
20:48:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:48:01 DISPATCHER: Finished worker discovery
20:49:01 DISPATCHER: Starting worker discovery
20:49:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:49:01 DISPATCHER: Finished worker discovery
20:50:01 DISPATCHER: Starting worker discovery
20:50:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:50:01 DISPATCHER: Finished worker discovery
20:51:01 DISPATCHER: Starting worker discovery
20:51:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:51:01 DISPATCHER: Finished worker discovery
20:52:01 DISPATCHER: Starting worker discovery
20:52:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:52:01 DISPATCHER: Finished worker discovery
20:53:01 DISPATCHER: Starting worker discovery
20:53:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:53:01 DISPATCHER: Finished worker discovery
20:54:01 DISPATCHER: Starting worker discovery
20:54:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:54:01 DISPATCHER: Finished worker discovery
20:55:01 DISPATCHER: Starting worker discovery
20:55:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:55:01 DISPATCHER: Finished worker discovery
20:56:01 DISPATCHER: Starting worker discovery
20:56:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:56:01 DISPATCHER: Finished worker discovery
20:57:01 DISPATCHER: Starting worker discovery
20:57:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:57:01 DISPATCHER: Finished worker discovery
20:58:01 DISPATCHER: Starting worker discovery
20:58:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:58:01 DISPATCHER: Finished worker discovery
20:58:34 WORKER: done with job (6, 0, 1), trying to register it.
20:58:34 WORKER: registered result for job (6, 0, 1) with dispatcher
20:58:34 DISPATCHER: job (6, 0, 1) finished
20:58:34 DISPATCHER: register_result: lock acquired
20:58:34 DISPATCHER: job (6, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
20:58:34 job_id: (6, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.005774180881716853, 'num_filters_1': 33, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.011931522974802653, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 17, 'num_filters_3': 54, 'num_filters_4': 20, 'num_filters_5': 24}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5708768263240016, 'info': {'sick_no_sick': 0.5708768263240016, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.005774180881716853, 'num_filters_1': 33, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.011931522974802653, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 17, 'num_filters_3': 54, 'num_filters_4': 20, 'num_filters_5': 24}"}}
exception: None

20:58:34 job_callback for (6, 0, 1) started
20:58:34 DISPATCHER: Trying to submit another job.
20:58:34 job_callback for (6, 0, 1) got condition
20:58:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:58:34 Only 11 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
20:58:34 HBMASTER: Trying to run another job!
20:58:34 job_callback for (6, 0, 1) finished
20:58:34 HBMASTER: schedule new run for iteration 6
20:58:34 HBMASTER: trying submitting job (6, 0, 2) to dispatcher
20:58:34 HBMASTER: submitting job (6, 0, 2) to dispatcher
20:58:34 DISPATCHER: trying to submit job (6, 0, 2)
20:58:34 DISPATCHER: trying to notify the job_runner thread.
20:58:34 HBMASTER: job (6, 0, 2) submitted to dispatcher
20:58:34 DISPATCHER: Trying to submit another job.
20:58:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:58:34 DISPATCHER: starting job (6, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
20:58:34 DISPATCHER: job (6, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
20:58:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:58:34 WORKER: start processing job (6, 0, 2)
20:58:34 WORKER: args: ()
20:58:34 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0025118640529885133, 'num_filters_1': 68, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.014126550336994574, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 99, 'num_filters_3': 25, 'num_filters_4': 23, 'num_filters_5': 23}, 'budget': 1200.0, 'working_directory': '.'}
20:59:01 DISPATCHER: Starting worker discovery
20:59:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:59:01 DISPATCHER: Finished worker discovery
21:00:01 DISPATCHER: Starting worker discovery
21:00:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:00:01 DISPATCHER: Finished worker discovery
21:01:01 DISPATCHER: Starting worker discovery
21:01:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:01:01 DISPATCHER: Finished worker discovery
21:02:01 DISPATCHER: Starting worker discovery
21:02:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:02:01 DISPATCHER: Finished worker discovery
21:03:01 DISPATCHER: Starting worker discovery
21:03:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:03:01 DISPATCHER: Finished worker discovery
21:04:01 DISPATCHER: Starting worker discovery
21:04:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:04:01 DISPATCHER: Finished worker discovery
21:05:01 DISPATCHER: Starting worker discovery
21:05:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:05:01 DISPATCHER: Finished worker discovery
21:06:01 DISPATCHER: Starting worker discovery
21:06:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:06:01 DISPATCHER: Finished worker discovery
21:07:01 DISPATCHER: Starting worker discovery
21:07:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:07:01 DISPATCHER: Finished worker discovery
21:08:01 DISPATCHER: Starting worker discovery
21:08:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:08:01 DISPATCHER: Finished worker discovery
21:09:01 DISPATCHER: Starting worker discovery
21:09:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:09:01 DISPATCHER: Finished worker discovery
21:10:01 DISPATCHER: Starting worker discovery
21:10:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:10:01 DISPATCHER: Finished worker discovery
21:11:01 DISPATCHER: Starting worker discovery
21:11:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:11:01 DISPATCHER: Finished worker discovery
21:12:01 DISPATCHER: Starting worker discovery
21:12:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:12:01 DISPATCHER: Finished worker discovery
21:13:01 DISPATCHER: Starting worker discovery
21:13:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:13:01 DISPATCHER: Finished worker discovery
21:14:01 DISPATCHER: Starting worker discovery
21:14:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:14:01 DISPATCHER: Finished worker discovery
21:15:01 DISPATCHER: Starting worker discovery
21:15:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:15:01 DISPATCHER: Finished worker discovery
21:16:01 DISPATCHER: Starting worker discovery
21:16:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:16:01 DISPATCHER: Finished worker discovery
21:17:01 DISPATCHER: Starting worker discovery
21:17:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:17:01 DISPATCHER: Finished worker discovery
21:18:01 DISPATCHER: Starting worker discovery
21:18:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:18:01 DISPATCHER: Finished worker discovery
21:19:01 DISPATCHER: Starting worker discovery
21:19:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:19:01 DISPATCHER: Finished worker discovery
21:20:00 WORKER: done with job (6, 0, 2), trying to register it.
21:20:00 WORKER: registered result for job (6, 0, 2) with dispatcher
21:20:00 DISPATCHER: job (6, 0, 2) finished
21:20:00 DISPATCHER: register_result: lock acquired
21:20:00 DISPATCHER: job (6, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
21:20:00 job_id: (6, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0025118640529885133, 'num_filters_1': 68, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.014126550336994574, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 99, 'num_filters_3': 25, 'num_filters_4': 23, 'num_filters_5': 23}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5898047504489208, 'info': {'sick_no_sick': 0.5898047504489208, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0025118640529885133, 'num_filters_1': 68, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.014126550336994574, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 99, 'num_filters_3': 25, 'num_filters_4': 23, 'num_filters_5': 23}"}}
exception: None

21:20:00 job_callback for (6, 0, 2) started
21:20:00 DISPATCHER: Trying to submit another job.
21:20:00 job_callback for (6, 0, 2) got condition
21:20:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:20:00 Only 12 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
21:20:00 HBMASTER: Trying to run another job!
21:20:00 job_callback for (6, 0, 2) finished
21:20:00 start sampling a new configuration.
21:20:00 best_vector: [0, 0, 0.4941636699761528, 0.7165374969068803, 0.7357503887250976, 0, 0.5244641506491061, 0.19489805180696232, 1, 1, 1, 0, 0.6504970139133639, 0.09453287854882131, 0.5163836531649606, 0.8387540024798978], 0.008877747148522838, 0.001492233534684724, 1.3247672007477465e-05
21:20:00 done sampling a new configuration.
21:20:00 HBMASTER: schedule new run for iteration 7
21:20:00 HBMASTER: trying submitting job (7, 0, 0) to dispatcher
21:20:00 HBMASTER: submitting job (7, 0, 0) to dispatcher
21:20:00 DISPATCHER: trying to submit job (7, 0, 0)
21:20:00 DISPATCHER: trying to notify the job_runner thread.
21:20:00 HBMASTER: job (7, 0, 0) submitted to dispatcher
21:20:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:20:00 DISPATCHER: Trying to submit another job.
21:20:00 DISPATCHER: starting job (7, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
21:20:00 DISPATCHER: job (7, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
21:20:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:20:00 WORKER: start processing job (7, 0, 0)
21:20:00 WORKER: args: ()
21:20:00 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.009734806870696146, 'num_filters_1': 71, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.017929501359790406, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 61, 'num_filters_3': 19, 'num_filters_4': 46}, 'budget': 1200.0, 'working_directory': '.'}
21:20:01 DISPATCHER: Starting worker discovery
21:20:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:20:01 DISPATCHER: Finished worker discovery
21:21:01 DISPATCHER: Starting worker discovery
21:21:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:21:01 DISPATCHER: Finished worker discovery
21:22:01 DISPATCHER: Starting worker discovery
21:22:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:22:01 DISPATCHER: Finished worker discovery
21:23:01 DISPATCHER: Starting worker discovery
21:23:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:23:01 DISPATCHER: Finished worker discovery
21:24:01 DISPATCHER: Starting worker discovery
21:24:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:24:01 DISPATCHER: Finished worker discovery
21:25:01 DISPATCHER: Starting worker discovery
21:25:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:25:01 DISPATCHER: Finished worker discovery
21:26:01 DISPATCHER: Starting worker discovery
21:26:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:26:01 DISPATCHER: Finished worker discovery
21:27:01 DISPATCHER: Starting worker discovery
21:27:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:27:01 DISPATCHER: Finished worker discovery
21:28:01 DISPATCHER: Starting worker discovery
21:28:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:28:01 DISPATCHER: Finished worker discovery
21:29:01 DISPATCHER: Starting worker discovery
21:29:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:29:01 DISPATCHER: Finished worker discovery
21:30:01 DISPATCHER: Starting worker discovery
21:30:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:30:01 DISPATCHER: Finished worker discovery
21:31:01 DISPATCHER: Starting worker discovery
21:31:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:31:01 DISPATCHER: Finished worker discovery
21:32:01 DISPATCHER: Starting worker discovery
21:32:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:32:01 DISPATCHER: Finished worker discovery
21:33:01 DISPATCHER: Starting worker discovery
21:33:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:33:01 DISPATCHER: Finished worker discovery
21:34:01 DISPATCHER: Starting worker discovery
21:34:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:34:01 DISPATCHER: Finished worker discovery
21:35:01 DISPATCHER: Starting worker discovery
21:35:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:35:01 DISPATCHER: Finished worker discovery
21:36:01 DISPATCHER: Starting worker discovery
21:36:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:36:01 DISPATCHER: Finished worker discovery
21:37:01 DISPATCHER: Starting worker discovery
21:37:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:37:01 DISPATCHER: Finished worker discovery
21:38:01 DISPATCHER: Starting worker discovery
21:38:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:38:01 DISPATCHER: Finished worker discovery
21:39:01 DISPATCHER: Starting worker discovery
21:39:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:39:01 DISPATCHER: Finished worker discovery
21:40:01 DISPATCHER: Starting worker discovery
21:40:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:40:01 DISPATCHER: Finished worker discovery
21:41:01 DISPATCHER: Starting worker discovery
21:41:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:41:01 DISPATCHER: Finished worker discovery
21:41:27 WORKER: done with job (7, 0, 0), trying to register it.
21:41:27 WORKER: registered result for job (7, 0, 0) with dispatcher
21:41:27 DISPATCHER: job (7, 0, 0) finished
21:41:27 DISPATCHER: register_result: lock acquired
21:41:27 DISPATCHER: job (7, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
21:41:27 job_id: (7, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.009734806870696146, 'num_filters_1': 71, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.017929501359790406, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 61, 'num_filters_3': 19, 'num_filters_4': 46}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.009734806870696146, 'num_filters_1': 71, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.017929501359790406, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 61, 'num_filters_3': 19, 'num_filters_4': 46}"}}
exception: None

21:41:27 job_callback for (7, 0, 0) started
21:41:27 job_callback for (7, 0, 0) got condition
21:41:27 DISPATCHER: Trying to submit another job.
21:41:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:41:27 Only 13 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
21:41:27 HBMASTER: Trying to run another job!
21:41:27 job_callback for (7, 0, 0) finished
21:41:27 start sampling a new configuration.
21:41:27 done sampling a new configuration.
21:41:27 HBMASTER: schedule new run for iteration 7
21:41:27 HBMASTER: trying submitting job (7, 0, 1) to dispatcher
21:41:27 HBMASTER: submitting job (7, 0, 1) to dispatcher
21:41:27 DISPATCHER: trying to submit job (7, 0, 1)
21:41:27 DISPATCHER: trying to notify the job_runner thread.
21:41:27 HBMASTER: job (7, 0, 1) submitted to dispatcher
21:41:27 DISPATCHER: Trying to submit another job.
21:41:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:41:27 DISPATCHER: starting job (7, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
21:41:27 DISPATCHER: job (7, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
21:41:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:41:27 WORKER: start processing job (7, 0, 1)
21:41:27 WORKER: args: ()
21:41:27 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.031899530261317983, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.08145328367656264, 'kernel_size_2': 7, 'num_filters_2': 74}, 'budget': 1200.0, 'working_directory': '.'}
21:42:01 DISPATCHER: Starting worker discovery
21:42:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:42:01 DISPATCHER: Finished worker discovery
21:43:01 DISPATCHER: Starting worker discovery
21:43:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:43:01 DISPATCHER: Finished worker discovery
21:44:01 DISPATCHER: Starting worker discovery
21:44:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:44:01 DISPATCHER: Finished worker discovery
21:45:01 DISPATCHER: Starting worker discovery
21:45:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:45:01 DISPATCHER: Finished worker discovery
21:46:01 DISPATCHER: Starting worker discovery
21:46:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:46:01 DISPATCHER: Finished worker discovery
21:47:01 DISPATCHER: Starting worker discovery
21:47:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:47:01 DISPATCHER: Finished worker discovery
21:48:01 DISPATCHER: Starting worker discovery
21:48:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:48:01 DISPATCHER: Finished worker discovery
21:49:01 DISPATCHER: Starting worker discovery
21:49:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:49:01 DISPATCHER: Finished worker discovery
21:50:01 DISPATCHER: Starting worker discovery
21:50:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:50:01 DISPATCHER: Finished worker discovery
21:51:01 DISPATCHER: Starting worker discovery
21:51:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:51:01 DISPATCHER: Finished worker discovery
21:52:01 DISPATCHER: Starting worker discovery
21:52:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:52:01 DISPATCHER: Finished worker discovery
21:53:01 DISPATCHER: Starting worker discovery
21:53:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:53:01 DISPATCHER: Finished worker discovery
21:54:01 DISPATCHER: Starting worker discovery
21:54:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:54:01 DISPATCHER: Finished worker discovery
21:55:01 DISPATCHER: Starting worker discovery
21:55:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:55:01 DISPATCHER: Finished worker discovery
21:56:01 DISPATCHER: Starting worker discovery
21:56:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:56:01 DISPATCHER: Finished worker discovery
21:57:01 DISPATCHER: Starting worker discovery
21:57:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:57:01 DISPATCHER: Finished worker discovery
21:58:01 DISPATCHER: Starting worker discovery
21:58:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:58:01 DISPATCHER: Finished worker discovery
21:59:01 DISPATCHER: Starting worker discovery
21:59:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:59:01 DISPATCHER: Finished worker discovery
22:00:01 DISPATCHER: Starting worker discovery
22:00:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:00:01 DISPATCHER: Finished worker discovery
22:01:01 DISPATCHER: Starting worker discovery
22:01:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:01:01 DISPATCHER: Finished worker discovery
22:02:01 DISPATCHER: Starting worker discovery
22:02:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:02:01 DISPATCHER: Finished worker discovery
22:02:47 WORKER: done with job (7, 0, 1), trying to register it.
22:02:47 WORKER: registered result for job (7, 0, 1) with dispatcher
22:02:47 DISPATCHER: job (7, 0, 1) finished
22:02:47 DISPATCHER: register_result: lock acquired
22:02:47 DISPATCHER: job (7, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
22:02:47 job_id: (7, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.031899530261317983, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.08145328367656264, 'kernel_size_2': 7, 'num_filters_2': 74}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.058276170048945995, 'info': {'sick_no_sick': 0.058276170048945995, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.031899530261317983, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.08145328367656264, 'kernel_size_2': 7, 'num_filters_2': 74}"}}
exception: None

22:02:47 job_callback for (7, 0, 1) started
22:02:47 DISPATCHER: Trying to submit another job.
22:02:47 job_callback for (7, 0, 1) got condition
22:02:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:02:47 Only 14 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
22:02:47 HBMASTER: Trying to run another job!
22:02:47 job_callback for (7, 0, 1) finished
22:02:47 start sampling a new configuration.
22:02:47 best_vector: [2, 1, 0.6707984625308195, 0.6108363547872782, 0.9727523903592071, 0, 0.9607447503988318, 0.16041734850980216, 2, 1, 2, 1, 0.6230466785442526, 0.8450391341506742, 0.0025431341652488726, 0.6315313713789523], 0.007452581257185513, 0.0009479051479729679, 7.064340139373001e-06
22:02:47 done sampling a new configuration.
22:02:47 HBMASTER: schedule new run for iteration 7
22:02:47 HBMASTER: trying submitting job (7, 0, 2) to dispatcher
22:02:47 HBMASTER: submitting job (7, 0, 2) to dispatcher
22:02:47 DISPATCHER: trying to submit job (7, 0, 2)
22:02:47 DISPATCHER: trying to notify the job_runner thread.
22:02:47 HBMASTER: job (7, 0, 2) submitted to dispatcher
22:02:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:02:47 DISPATCHER: Trying to submit another job.
22:02:47 DISPATCHER: starting job (7, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
22:02:47 DISPATCHER: job (7, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
22:02:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:02:47 WORKER: start processing job (7, 0, 2)
22:02:47 WORKER: args: ()
22:02:47 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.021958209538311728, 'num_filters_1': 56, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.016169916685483027, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 58, 'num_filters_3': 93, 'num_filters_4': 16, 'num_filters_5': 59}, 'budget': 1200.0, 'working_directory': '.'}
22:03:01 DISPATCHER: Starting worker discovery
22:03:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:03:02 DISPATCHER: Finished worker discovery
22:04:02 DISPATCHER: Starting worker discovery
22:04:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:04:02 DISPATCHER: Finished worker discovery
22:05:02 DISPATCHER: Starting worker discovery
22:05:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:05:02 DISPATCHER: Finished worker discovery
22:06:02 DISPATCHER: Starting worker discovery
22:06:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:06:02 DISPATCHER: Finished worker discovery
22:07:02 DISPATCHER: Starting worker discovery
22:07:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:07:02 DISPATCHER: Finished worker discovery
22:08:02 DISPATCHER: Starting worker discovery
22:08:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:08:02 DISPATCHER: Finished worker discovery
22:09:02 DISPATCHER: Starting worker discovery
22:09:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:09:02 DISPATCHER: Finished worker discovery
22:10:02 DISPATCHER: Starting worker discovery
22:10:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:10:02 DISPATCHER: Finished worker discovery
22:11:02 DISPATCHER: Starting worker discovery
22:11:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:11:02 DISPATCHER: Finished worker discovery
22:12:02 DISPATCHER: Starting worker discovery
22:12:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:12:02 DISPATCHER: Finished worker discovery
22:13:02 DISPATCHER: Starting worker discovery
22:13:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:13:02 DISPATCHER: Finished worker discovery
22:14:02 DISPATCHER: Starting worker discovery
22:14:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:14:02 DISPATCHER: Finished worker discovery
22:15:02 DISPATCHER: Starting worker discovery
22:15:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:15:02 DISPATCHER: Finished worker discovery
22:16:02 DISPATCHER: Starting worker discovery
22:16:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:16:02 DISPATCHER: Finished worker discovery
22:17:02 DISPATCHER: Starting worker discovery
22:17:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:17:02 DISPATCHER: Finished worker discovery
22:18:02 DISPATCHER: Starting worker discovery
22:18:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:18:02 DISPATCHER: Finished worker discovery
22:19:02 DISPATCHER: Starting worker discovery
22:19:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:19:02 DISPATCHER: Finished worker discovery
22:20:02 DISPATCHER: Starting worker discovery
22:20:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:20:02 DISPATCHER: Finished worker discovery
22:21:02 DISPATCHER: Starting worker discovery
22:21:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:21:02 DISPATCHER: Finished worker discovery
22:22:02 DISPATCHER: Starting worker discovery
22:22:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:22:02 DISPATCHER: Finished worker discovery
22:23:02 DISPATCHER: Starting worker discovery
22:23:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:23:02 DISPATCHER: Finished worker discovery
22:24:02 DISPATCHER: Starting worker discovery
22:24:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:24:02 DISPATCHER: Finished worker discovery
22:24:16 WORKER: done with job (7, 0, 2), trying to register it.
22:24:16 WORKER: registered result for job (7, 0, 2) with dispatcher
22:24:16 DISPATCHER: job (7, 0, 2) finished
22:24:16 DISPATCHER: register_result: lock acquired
22:24:16 DISPATCHER: job (7, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
22:24:16 job_id: (7, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.021958209538311728, 'num_filters_1': 56, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.016169916685483027, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 58, 'num_filters_3': 93, 'num_filters_4': 16, 'num_filters_5': 59}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.021958209538311728, 'num_filters_1': 56, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.016169916685483027, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 58, 'num_filters_3': 93, 'num_filters_4': 16, 'num_filters_5': 59}"}}
exception: None

22:24:16 job_callback for (7, 0, 2) started
22:24:16 DISPATCHER: Trying to submit another job.
22:24:16 job_callback for (7, 0, 2) got condition
22:24:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:24:16 Only 15 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
22:24:16 HBMASTER: Trying to run another job!
22:24:16 job_callback for (7, 0, 2) finished
22:24:16 start sampling a new configuration.
22:24:16 done sampling a new configuration.
22:24:16 HBMASTER: schedule new run for iteration 7
22:24:16 HBMASTER: trying submitting job (7, 0, 3) to dispatcher
22:24:16 HBMASTER: submitting job (7, 0, 3) to dispatcher
22:24:16 DISPATCHER: trying to submit job (7, 0, 3)
22:24:16 DISPATCHER: trying to notify the job_runner thread.
22:24:16 HBMASTER: job (7, 0, 3) submitted to dispatcher
22:24:16 DISPATCHER: Trying to submit another job.
22:24:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:24:16 DISPATCHER: starting job (7, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
22:24:16 DISPATCHER: job (7, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
22:24:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:24:16 WORKER: start processing job (7, 0, 3)
22:24:16 WORKER: args: ()
22:24:16 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.08101018480057723, 'num_filters_1': 78, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.010083470231249168, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 54, 'num_filters_3': 117}, 'budget': 1200.0, 'working_directory': '.'}
22:25:02 DISPATCHER: Starting worker discovery
22:25:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:25:02 DISPATCHER: Finished worker discovery
22:26:02 DISPATCHER: Starting worker discovery
22:26:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:26:02 DISPATCHER: Finished worker discovery
22:27:02 DISPATCHER: Starting worker discovery
22:27:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:27:02 DISPATCHER: Finished worker discovery
22:28:02 DISPATCHER: Starting worker discovery
22:28:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:28:02 DISPATCHER: Finished worker discovery
22:29:02 DISPATCHER: Starting worker discovery
22:29:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:29:02 DISPATCHER: Finished worker discovery
22:30:02 DISPATCHER: Starting worker discovery
22:30:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:30:02 DISPATCHER: Finished worker discovery
22:31:02 DISPATCHER: Starting worker discovery
22:31:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:31:02 DISPATCHER: Finished worker discovery
22:32:02 DISPATCHER: Starting worker discovery
22:32:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:32:02 DISPATCHER: Finished worker discovery
22:33:02 DISPATCHER: Starting worker discovery
22:33:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:33:02 DISPATCHER: Finished worker discovery
22:34:02 DISPATCHER: Starting worker discovery
22:34:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:34:02 DISPATCHER: Finished worker discovery
22:35:02 DISPATCHER: Starting worker discovery
22:35:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:35:02 DISPATCHER: Finished worker discovery
22:36:02 DISPATCHER: Starting worker discovery
22:36:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:36:02 DISPATCHER: Finished worker discovery
22:37:02 DISPATCHER: Starting worker discovery
22:37:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:37:02 DISPATCHER: Finished worker discovery
22:38:02 DISPATCHER: Starting worker discovery
22:38:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:38:02 DISPATCHER: Finished worker discovery
22:39:02 DISPATCHER: Starting worker discovery
22:39:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:39:02 DISPATCHER: Finished worker discovery
22:40:02 DISPATCHER: Starting worker discovery
22:40:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:40:02 DISPATCHER: Finished worker discovery
22:41:02 DISPATCHER: Starting worker discovery
22:41:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:41:02 DISPATCHER: Finished worker discovery
22:42:02 DISPATCHER: Starting worker discovery
22:42:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:42:02 DISPATCHER: Finished worker discovery
22:43:02 DISPATCHER: Starting worker discovery
22:43:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:43:02 DISPATCHER: Finished worker discovery
22:44:02 DISPATCHER: Starting worker discovery
22:44:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:44:02 DISPATCHER: Finished worker discovery
22:45:02 DISPATCHER: Starting worker discovery
22:45:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:45:02 DISPATCHER: Finished worker discovery
22:46:02 DISPATCHER: Starting worker discovery
22:46:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:46:02 DISPATCHER: Finished worker discovery
22:46:14 WORKER: done with job (7, 0, 3), trying to register it.
22:46:14 WORKER: registered result for job (7, 0, 3) with dispatcher
22:46:14 DISPATCHER: job (7, 0, 3) finished
22:46:14 DISPATCHER: register_result: lock acquired
22:46:14 DISPATCHER: job (7, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
22:46:14 job_id: (7, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.08101018480057723, 'num_filters_1': 78, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.010083470231249168, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 54, 'num_filters_3': 117}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5112281715567499, 'info': {'sick_no_sick': 0.5112281715567499, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.08101018480057723, 'num_filters_1': 78, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.010083470231249168, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 54, 'num_filters_3': 117}"}}
exception: None

22:46:14 job_callback for (7, 0, 3) started
22:46:14 DISPATCHER: Trying to submit another job.
22:46:14 job_callback for (7, 0, 3) got condition
22:46:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:46:14 Only 16 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
22:46:14 HBMASTER: Trying to run another job!
22:46:14 job_callback for (7, 0, 3) finished
22:46:14 start sampling a new configuration.
22:46:14 best_vector: [1, 1, 0.26317977383156343, 0.8281063844936587, 0.24380348171093208, 0, 0.7375413608984213, 0.25083759214549894, 0, 2, 0, 0, 0.3591221755824371, 0.7629508203594134, 0.5269417334948459, 0.6628562683681852], 0.03394652384599578, 0.0044221637428934, 0.00015011708694902877
22:46:14 done sampling a new configuration.
22:46:14 HBMASTER: schedule new run for iteration 8
22:46:14 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
22:46:14 HBMASTER: submitting job (8, 0, 0) to dispatcher
22:46:14 DISPATCHER: trying to submit job (8, 0, 0)
22:46:14 DISPATCHER: trying to notify the job_runner thread.
22:46:14 HBMASTER: job (8, 0, 0) submitted to dispatcher
22:46:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:46:14 DISPATCHER: Trying to submit another job.
22:46:14 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
22:46:14 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
22:46:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:46:14 WORKER: start processing job (8, 0, 0)
22:46:14 WORKER: args: ()
22:46:14 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0033601568283976274, 'num_filters_1': 89, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.021200555055636842, 'kernel_size_2': 3, 'num_filters_2': 33}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:47:02 DISPATCHER: Starting worker discovery
22:47:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:47:02 DISPATCHER: Finished worker discovery
22:48:01 WORKER: done with job (8, 0, 0), trying to register it.
22:48:01 WORKER: registered result for job (8, 0, 0) with dispatcher
22:48:01 DISPATCHER: job (8, 0, 0) finished
22:48:01 DISPATCHER: register_result: lock acquired
22:48:01 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
22:48:01 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0033601568283976274, 'num_filters_1': 89, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.021200555055636842, 'kernel_size_2': 3, 'num_filters_2': 33}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5692730120653904, 'info': {'sick_no_sick': 0.5692730120653904, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0033601568283976274, 'num_filters_1': 89, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.021200555055636842, 'kernel_size_2': 3, 'num_filters_2': 33}"}}
exception: None

22:48:01 job_callback for (8, 0, 0) started
22:48:01 DISPATCHER: Trying to submit another job.
22:48:01 job_callback for (8, 0, 0) got condition
22:48:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:48:01 HBMASTER: Trying to run another job!
22:48:01 job_callback for (8, 0, 0) finished
22:48:01 start sampling a new configuration.
22:48:01 best_vector: [1, 0, 0.5756039635749537, 0.7082887573164829, 0.40347532570466743, 1, 0.6805604599807307, 0.05377124536051958, 2, 1, 2, 1, 0.7664762270336849, 0.6069939785415701, 0.8120629277875635, 0.962458448563064], 0.0005604865683577008, 0.0003405670802189831, 1.9088327408753963e-07
22:48:01 done sampling a new configuration.
22:48:01 HBMASTER: schedule new run for iteration 8
22:48:01 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
22:48:01 HBMASTER: submitting job (8, 0, 1) to dispatcher
22:48:01 DISPATCHER: trying to submit job (8, 0, 1)
22:48:01 DISPATCHER: trying to notify the job_runner thread.
22:48:01 HBMASTER: job (8, 0, 1) submitted to dispatcher
22:48:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:48:01 DISPATCHER: Trying to submit another job.
22:48:01 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
22:48:01 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
22:48:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:48:01 WORKER: start processing job (8, 0, 1)
22:48:01 WORKER: args: ()
22:48:01 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.014164717817730403, 'num_filters_1': 69, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.011747839462014464, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 78, 'num_filters_3': 56}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:48:02 DISPATCHER: Starting worker discovery
22:48:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:48:02 DISPATCHER: Finished worker discovery
22:49:02 DISPATCHER: Starting worker discovery
22:49:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:49:02 DISPATCHER: Finished worker discovery
22:49:47 WORKER: done with job (8, 0, 1), trying to register it.
22:49:47 WORKER: registered result for job (8, 0, 1) with dispatcher
22:49:47 DISPATCHER: job (8, 0, 1) finished
22:49:47 DISPATCHER: register_result: lock acquired
22:49:47 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
22:49:47 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.014164717817730403, 'num_filters_1': 69, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.011747839462014464, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 78, 'num_filters_3': 56}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.56798116302064, 'info': {'sick_no_sick': 0.56798116302064, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.014164717817730403, 'num_filters_1': 69, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.011747839462014464, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 78, 'num_filters_3': 56}"}}
exception: None

22:49:47 job_callback for (8, 0, 1) started
22:49:47 job_callback for (8, 0, 1) got condition
22:49:47 DISPATCHER: Trying to submit another job.
22:49:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:49:47 HBMASTER: Trying to run another job!
22:49:47 job_callback for (8, 0, 1) finished
22:49:47 start sampling a new configuration.
22:49:47 best_vector: [1, 1, 0.2754525515430444, 0.907537429355433, 0.7938335583356785, 0, 0.4292057244613827, 0.19372086523591747, 2, 1, 2, 2, 0.818390234103582, 0.7972555548278407, 0.4396588025876425, 0.9528766502661257], 0.0017724237902728218, 0.00029403932095926525, 5.211622877438677e-07
22:49:47 done sampling a new configuration.
22:49:47 HBMASTER: schedule new run for iteration 8
22:49:47 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
22:49:47 HBMASTER: submitting job (8, 0, 2) to dispatcher
22:49:47 DISPATCHER: trying to submit job (8, 0, 2)
22:49:47 DISPATCHER: trying to notify the job_runner thread.
22:49:47 HBMASTER: job (8, 0, 2) submitted to dispatcher
22:49:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:49:47 DISPATCHER: Trying to submit another job.
22:49:47 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
22:49:47 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
22:49:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:49:47 WORKER: start processing job (8, 0, 2)
22:49:47 WORKER: args: ()
22:49:47 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0035555361869216216, 'num_filters_1': 106, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.01786638369009176, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 88, 'num_filters_3': 84, 'num_filters_4': 39}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:50:02 DISPATCHER: Starting worker discovery
22:50:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:50:02 DISPATCHER: Finished worker discovery
22:51:02 DISPATCHER: Starting worker discovery
22:51:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:51:02 DISPATCHER: Finished worker discovery
22:51:35 WORKER: done with job (8, 0, 2), trying to register it.
22:51:35 WORKER: registered result for job (8, 0, 2) with dispatcher
22:51:35 DISPATCHER: job (8, 0, 2) finished
22:51:35 DISPATCHER: register_result: lock acquired
22:51:35 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
22:51:35 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0035555361869216216, 'num_filters_1': 106, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.01786638369009176, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 88, 'num_filters_3': 84, 'num_filters_4': 39}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.44404149223083855, 'info': {'sick_no_sick': 0.44404149223083855, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0035555361869216216, 'num_filters_1': 106, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.01786638369009176, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 88, 'num_filters_3': 84, 'num_filters_4': 39}"}}
exception: None

22:51:35 job_callback for (8, 0, 2) started
22:51:35 DISPATCHER: Trying to submit another job.
22:51:35 job_callback for (8, 0, 2) got condition
22:51:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:51:35 HBMASTER: Trying to run another job!
22:51:35 job_callback for (8, 0, 2) finished
22:51:35 start sampling a new configuration.
22:51:35 done sampling a new configuration.
22:51:35 HBMASTER: schedule new run for iteration 8
22:51:35 HBMASTER: trying submitting job (8, 0, 3) to dispatcher
22:51:35 HBMASTER: submitting job (8, 0, 3) to dispatcher
22:51:35 DISPATCHER: trying to submit job (8, 0, 3)
22:51:35 DISPATCHER: trying to notify the job_runner thread.
22:51:35 HBMASTER: job (8, 0, 3) submitted to dispatcher
22:51:35 DISPATCHER: Trying to submit another job.
22:51:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:51:35 DISPATCHER: starting job (8, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
22:51:35 DISPATCHER: job (8, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
22:51:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:51:35 WORKER: start processing job (8, 0, 3)
22:51:35 WORKER: args: ()
22:51:35 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.001981274098122893, 'num_filters_1': 97, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.19252121125134633, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 93, 'num_filters_3': 44}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:52:02 DISPATCHER: Starting worker discovery
22:52:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:52:02 DISPATCHER: Finished worker discovery
22:53:02 DISPATCHER: Starting worker discovery
22:53:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:53:02 DISPATCHER: Finished worker discovery
22:53:23 WORKER: done with job (8, 0, 3), trying to register it.
22:53:23 WORKER: registered result for job (8, 0, 3) with dispatcher
22:53:23 DISPATCHER: job (8, 0, 3) finished
22:53:23 DISPATCHER: register_result: lock acquired
22:53:23 DISPATCHER: job (8, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
22:53:23 job_id: (8, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.001981274098122893, 'num_filters_1': 97, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.19252121125134633, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 93, 'num_filters_3': 44}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.02284693440832893, 'info': {'sick_no_sick': 0.02284693440832893, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.001981274098122893, 'num_filters_1': 97, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.19252121125134633, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 93, 'num_filters_3': 44}"}}
exception: None

22:53:23 job_callback for (8, 0, 3) started
22:53:23 DISPATCHER: Trying to submit another job.
22:53:23 job_callback for (8, 0, 3) got condition
22:53:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:53:23 HBMASTER: Trying to run another job!
22:53:23 job_callback for (8, 0, 3) finished
22:53:23 start sampling a new configuration.
22:53:23 best_vector: [0, 2, 0.34198239951441733, 0.4806685595602872, 0.934705375658286, 1, 0.10844207782561338, 0.3289481069972432, 0, 2, 0, 1, 0.13209060061054853, 0.44493645557392675, 0.8999227585882354, 0.32037076267972003], 0.013872015178705583, 0.006465488466442681, 8.968935414423874e-05
22:53:23 done sampling a new configuration.
22:53:23 HBMASTER: schedule new run for iteration 8
22:53:23 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
22:53:23 HBMASTER: submitting job (8, 0, 4) to dispatcher
22:53:23 DISPATCHER: trying to submit job (8, 0, 4)
22:53:23 DISPATCHER: trying to notify the job_runner thread.
22:53:23 HBMASTER: job (8, 0, 4) submitted to dispatcher
22:53:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:53:23 DISPATCHER: Trying to submit another job.
22:53:23 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776
22:53:23 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
22:53:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:53:23 WORKER: start processing job (8, 0, 4)
22:53:23 WORKER: args: ()
22:53:23 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.004830196501495956, 'num_filters_1': 43, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.026789916144582423, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 20, 'num_filters_3': 40, 'num_filters_4': 104, 'num_filters_5': 31}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:54:02 DISPATCHER: Starting worker discovery
22:54:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:54:02 DISPATCHER: Finished worker discovery
22:55:02 DISPATCHER: Starting worker discovery
22:55:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:55:02 DISPATCHER: Finished worker discovery
22:55:13 WORKER: done with job (8, 0, 4), trying to register it.
22:55:13 WORKER: registered result for job (8, 0, 4) with dispatcher
22:55:13 DISPATCHER: job (8, 0, 4) finished
22:55:13 DISPATCHER: register_result: lock acquired
22:55:13 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
22:55:13 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.004830196501495956, 'num_filters_1': 43, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.026789916144582423, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 20, 'num_filters_3': 40, 'num_filters_4': 104, 'num_filters_5': 31}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.50474483210637, 'info': {'sick_no_sick': 0.50474483210637, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.004830196501495956, 'num_filters_1': 43, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.026789916144582423, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 20, 'num_filters_3': 40, 'num_filters_4': 104, 'num_filters_5': 31}"}}
exception: None

22:55:13 job_callback for (8, 0, 4) started
22:55:13 DISPATCHER: Trying to submit another job.
22:55:13 job_callback for (8, 0, 4) got condition
22:55:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:55:13 HBMASTER: Trying to run another job!
22:55:13 job_callback for (8, 0, 4) finished
22:55:13 start sampling a new configuration.
22:55:13 best_vector: [2, 2, 0.8388308864065851, 0.474685013738272, 0.6101488780868075, 1, 0.4629278775502146, 0.06907351353968957, 0, 2, 0, 0, 0.46095401433557653, 0.8761541508219062, 0.8836198843209384, 0.9487758891836554], 0.001136006186086478, 0.0007165442087360017, 8.139986537285385e-07
22:55:13 done sampling a new configuration.
22:55:13 HBMASTER: schedule new run for iteration 8
22:55:13 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
22:55:13 HBMASTER: submitting job (8, 0, 5) to dispatcher
22:55:13 DISPATCHER: trying to submit job (8, 0, 5)
22:55:13 DISPATCHER: trying to notify the job_runner thread.
22:55:13 HBMASTER: job (8, 0, 5) submitted to dispatcher
22:55:13 DISPATCHER: Trying to submit another job.
22:55:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:55:13 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776
22:55:13 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
22:55:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:55:13 WORKER: start processing job (8, 0, 5)
22:55:13 WORKER: args: ()
22:55:13 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.04760600882861511, 'num_filters_1': 42, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.012298912535878895, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 41, 'num_filters_3': 99, 'num_filters_4': 100}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:56:02 DISPATCHER: Starting worker discovery
22:56:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:56:02 DISPATCHER: Finished worker discovery
22:56:59 WORKER: done with job (8, 0, 5), trying to register it.
22:56:59 WORKER: registered result for job (8, 0, 5) with dispatcher
22:56:59 DISPATCHER: job (8, 0, 5) finished
22:56:59 DISPATCHER: register_result: lock acquired
22:56:59 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
22:56:59 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.04760600882861511, 'num_filters_1': 42, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.012298912535878895, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 41, 'num_filters_3': 99, 'num_filters_4': 100}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4413590453717926, 'info': {'sick_no_sick': 0.4413590453717926, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.04760600882861511, 'num_filters_1': 42, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.012298912535878895, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 41, 'num_filters_3': 99, 'num_filters_4': 100}"}}
exception: None

22:56:59 job_callback for (8, 0, 5) started
22:56:59 job_callback for (8, 0, 5) got condition
22:56:59 DISPATCHER: Trying to submit another job.
22:56:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:56:59 HBMASTER: Trying to run another job!
22:56:59 job_callback for (8, 0, 5) finished
22:56:59 start sampling a new configuration.
22:56:59 best_vector: [3, 1, 0.8972511126678957, 0.11485566873033222, 0.25920880628717746, 1, 0.11370230496873346, 0.11581159223234133, 2, 1, 1, 0, 0.7065530609782904, 0.9113011202831751, 0.10333089452959843, 0.01121829517609163], 6.2582112914468666e-27, 1.5979006675065538e-06, -2.128555498119582e-08
22:56:59 done sampling a new configuration.
22:56:59 HBMASTER: schedule new run for iteration 8
22:56:59 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
22:56:59 HBMASTER: submitting job (8, 0, 6) to dispatcher
22:56:59 DISPATCHER: trying to submit job (8, 0, 6)
22:56:59 DISPATCHER: trying to notify the job_runner thread.
22:56:59 HBMASTER: job (8, 0, 6) submitted to dispatcher
22:56:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:56:59 DISPATCHER: Trying to submit another job.
22:56:59 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776
22:56:59 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
22:56:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:56:59 WORKER: start processing job (8, 0, 6)
22:56:59 WORKER: args: ()
22:56:59 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.062302033979269485, 'num_filters_1': 20, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.014147325809435406, 'kernel_size_2': 7, 'num_filters_2': 69}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:57:02 DISPATCHER: Starting worker discovery
22:57:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:57:02 DISPATCHER: Finished worker discovery
22:58:02 DISPATCHER: Starting worker discovery
22:58:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:58:02 DISPATCHER: Finished worker discovery
22:58:47 WORKER: done with job (8, 0, 6), trying to register it.
22:58:47 WORKER: registered result for job (8, 0, 6) with dispatcher
22:58:47 DISPATCHER: job (8, 0, 6) finished
22:58:47 DISPATCHER: register_result: lock acquired
22:58:47 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
22:58:47 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.062302033979269485, 'num_filters_1': 20, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.014147325809435406, 'kernel_size_2': 7, 'num_filters_2': 69}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4522998614765494, 'info': {'sick_no_sick': 0.4522998614765494, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.062302033979269485, 'num_filters_1': 20, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.014147325809435406, 'kernel_size_2': 7, 'num_filters_2': 69}"}}
exception: None

22:58:47 job_callback for (8, 0, 6) started
22:58:47 DISPATCHER: Trying to submit another job.
22:58:47 job_callback for (8, 0, 6) got condition
22:58:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:58:47 HBMASTER: Trying to run another job!
22:58:47 job_callback for (8, 0, 6) finished
22:58:47 start sampling a new configuration.
22:58:47 best_vector: [0, 1, 0.425039330074667, 0.4408900963292344, 0.7707889839254358, 1, 0.17924529369457676, 0.24841463403379246, 0, 0, 2, 1, 0.19742733979425356, 0.6250937724432692, 0.34617388390601433, 0.14288418909084294], 0.0035838754067515958, 0.003751565520744664, 1.3445143406614045e-05
22:58:47 done sampling a new configuration.
22:58:47 HBMASTER: schedule new run for iteration 8
22:58:47 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
22:58:47 HBMASTER: submitting job (8, 0, 7) to dispatcher
22:58:47 DISPATCHER: trying to submit job (8, 0, 7)
22:58:47 DISPATCHER: trying to notify the job_runner thread.
22:58:47 HBMASTER: job (8, 0, 7) submitted to dispatcher
22:58:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:58:47 DISPATCHER: Trying to submit another job.
22:58:47 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776
22:58:47 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
22:58:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:58:47 WORKER: start processing job (8, 0, 7)
22:58:47 WORKER: args: ()
22:58:47 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.007080740203319061, 'num_filters_1': 39, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.02104722725063498, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 24, 'num_filters_3': 58, 'num_filters_4': 32}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:59:02 DISPATCHER: Starting worker discovery
22:59:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:59:02 DISPATCHER: Finished worker discovery
23:00:02 DISPATCHER: Starting worker discovery
23:00:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:00:02 DISPATCHER: Finished worker discovery
23:00:36 WORKER: done with job (8, 0, 7), trying to register it.
23:00:36 WORKER: registered result for job (8, 0, 7) with dispatcher
23:00:36 DISPATCHER: job (8, 0, 7) finished
23:00:36 DISPATCHER: register_result: lock acquired
23:00:36 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
23:00:36 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.007080740203319061, 'num_filters_1': 39, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.02104722725063498, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 24, 'num_filters_3': 58, 'num_filters_4': 32}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5624637064415396, 'info': {'sick_no_sick': 0.5624637064415396, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.007080740203319061, 'num_filters_1': 39, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.02104722725063498, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 24, 'num_filters_3': 58, 'num_filters_4': 32}"}}
exception: None

23:00:36 job_callback for (8, 0, 7) started
23:00:36 job_callback for (8, 0, 7) got condition
23:00:36 DISPATCHER: Trying to submit another job.
23:00:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:00:36 HBMASTER: Trying to run another job!
23:00:36 job_callback for (8, 0, 7) finished
23:00:36 start sampling a new configuration.
23:00:36 done sampling a new configuration.
23:00:36 HBMASTER: schedule new run for iteration 8
23:00:36 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
23:00:36 HBMASTER: submitting job (8, 0, 8) to dispatcher
23:00:36 DISPATCHER: trying to submit job (8, 0, 8)
23:00:36 DISPATCHER: trying to notify the job_runner thread.
23:00:36 HBMASTER: job (8, 0, 8) submitted to dispatcher
23:00:36 DISPATCHER: Trying to submit another job.
23:00:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:00:36 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:00:36 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:00:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:00:36 WORKER: start processing job (8, 0, 8)
23:00:36 WORKER: args: ()
23:00:36 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.03999853881273107, 'num_filters_1': 39, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.023955117149443313, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 54, 'num_filters_3': 53, 'num_filters_4': 22}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:01:02 DISPATCHER: Starting worker discovery
23:01:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:01:02 DISPATCHER: Finished worker discovery
23:02:02 DISPATCHER: Starting worker discovery
23:02:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:02:02 DISPATCHER: Finished worker discovery
23:02:21 WORKER: done with job (8, 0, 8), trying to register it.
23:02:21 WORKER: registered result for job (8, 0, 8) with dispatcher
23:02:21 DISPATCHER: job (8, 0, 8) finished
23:02:21 DISPATCHER: register_result: lock acquired
23:02:21 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
23:02:21 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.03999853881273107, 'num_filters_1': 39, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.023955117149443313, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 54, 'num_filters_3': 53, 'num_filters_4': 22}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5071829854196702, 'info': {'sick_no_sick': 0.5071829854196702, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.03999853881273107, 'num_filters_1': 39, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.023955117149443313, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 54, 'num_filters_3': 53, 'num_filters_4': 22}"}}
exception: None

23:02:21 job_callback for (8, 0, 8) started
23:02:21 DISPATCHER: Trying to submit another job.
23:02:21 job_callback for (8, 0, 8) got condition
23:02:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:02:21 HBMASTER: Trying to run another job!
23:02:21 job_callback for (8, 0, 8) finished
23:02:21 start sampling a new configuration.
23:02:21 best_vector: [1, 0, 0.6514180089541615, 0.3921323244976962, 0.6003732056568274, 1, 0.5239600527299153, 0.14258833178578123, 0, 2, 2, 2, 0.712458948457592, 0.7649833211946078, 0.3295487956945785, 0.9665246256190435], 0.0008564772672878273, 0.0023841006801188155, 2.0419280354472135e-06
23:02:21 done sampling a new configuration.
23:02:21 HBMASTER: schedule new run for iteration 8
23:02:21 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
23:02:21 HBMASTER: submitting job (8, 0, 9) to dispatcher
23:02:21 DISPATCHER: trying to submit job (8, 0, 9)
23:02:21 DISPATCHER: trying to notify the job_runner thread.
23:02:21 HBMASTER: job (8, 0, 9) submitted to dispatcher
23:02:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:02:21 DISPATCHER: Trying to submit another job.
23:02:21 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:02:21 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:02:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:02:21 WORKER: start processing job (8, 0, 9)
23:02:21 WORKER: args: ()
23:02:21 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.020083343570790484, 'num_filters_1': 36, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.015328924906064313, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 70, 'num_filters_3': 78, 'num_filters_4': 31}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:03:02 DISPATCHER: Starting worker discovery
23:03:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:03:02 DISPATCHER: Finished worker discovery
23:04:02 DISPATCHER: Starting worker discovery
23:04:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:04:02 DISPATCHER: Finished worker discovery
23:04:09 WORKER: done with job (8, 0, 9), trying to register it.
23:04:09 WORKER: registered result for job (8, 0, 9) with dispatcher
23:04:09 DISPATCHER: job (8, 0, 9) finished
23:04:09 DISPATCHER: register_result: lock acquired
23:04:09 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
23:04:09 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.020083343570790484, 'num_filters_1': 36, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.015328924906064313, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 70, 'num_filters_3': 78, 'num_filters_4': 31}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5856468326297763, 'info': {'sick_no_sick': 0.5856468326297763, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.020083343570790484, 'num_filters_1': 36, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.015328924906064313, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 70, 'num_filters_3': 78, 'num_filters_4': 31}"}}
exception: None

23:04:09 job_callback for (8, 0, 9) started
23:04:09 DISPATCHER: Trying to submit another job.
23:04:09 job_callback for (8, 0, 9) got condition
23:04:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:04:09 HBMASTER: Trying to run another job!
23:04:09 job_callback for (8, 0, 9) finished
23:04:09 start sampling a new configuration.
23:04:09 done sampling a new configuration.
23:04:09 HBMASTER: schedule new run for iteration 8
23:04:09 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
23:04:09 HBMASTER: submitting job (8, 0, 10) to dispatcher
23:04:09 DISPATCHER: trying to submit job (8, 0, 10)
23:04:09 DISPATCHER: trying to notify the job_runner thread.
23:04:09 HBMASTER: job (8, 0, 10) submitted to dispatcher
23:04:09 DISPATCHER: Trying to submit another job.
23:04:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:04:09 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:04:09 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:04:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:04:09 WORKER: start processing job (8, 0, 10)
23:04:09 WORKER: args: ()
23:04:09 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.029760401920892056, 'num_filters_1': 119, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.010295631669521597, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 36, 'num_filters_3': 38, 'num_filters_4': 43, 'num_filters_5': 112}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:05:02 DISPATCHER: Starting worker discovery
23:05:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:05:02 DISPATCHER: Finished worker discovery
23:05:58 WORKER: done with job (8, 0, 10), trying to register it.
23:05:58 WORKER: registered result for job (8, 0, 10) with dispatcher
23:05:58 DISPATCHER: job (8, 0, 10) finished
23:05:58 DISPATCHER: register_result: lock acquired
23:05:58 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
23:05:58 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.029760401920892056, 'num_filters_1': 119, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.010295631669521597, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 36, 'num_filters_3': 38, 'num_filters_4': 43, 'num_filters_5': 112}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.029760401920892056, 'num_filters_1': 119, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.010295631669521597, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 36, 'num_filters_3': 38, 'num_filters_4': 43, 'num_filters_5': 112}"}}
exception: None

23:05:58 job_callback for (8, 0, 10) started
23:05:58 job_callback for (8, 0, 10) got condition
23:05:58 DISPATCHER: Trying to submit another job.
23:05:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:05:58 HBMASTER: Trying to run another job!
23:05:58 job_callback for (8, 0, 10) finished
23:05:58 start sampling a new configuration.
23:05:58 best_vector: [2, 0, 0.7686645995400772, 0.2758511074673452, 0.7281746518506701, 0, 0.28455892535381555, 0.1339327522171354, 0, 2, 2, 0, 0.45544207633822753, 0.6432567486225814, 0.7132785097295414, 0.9995108560420064], 0.00039552164969066473, 0.0009625326630084876, 3.807025067542657e-07
23:05:58 done sampling a new configuration.
23:05:58 HBMASTER: schedule new run for iteration 8
23:05:58 HBMASTER: trying submitting job (8, 0, 11) to dispatcher
23:05:58 HBMASTER: submitting job (8, 0, 11) to dispatcher
23:05:58 DISPATCHER: trying to submit job (8, 0, 11)
23:05:58 DISPATCHER: trying to notify the job_runner thread.
23:05:58 HBMASTER: job (8, 0, 11) submitted to dispatcher
23:05:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:05:58 DISPATCHER: Trying to submit another job.
23:05:58 DISPATCHER: starting job (8, 0, 11) on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:05:58 DISPATCHER: job (8, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:05:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:05:58 WORKER: start processing job (8, 0, 11)
23:05:58 WORKER: args: ()
23:05:58 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.03446110500265683, 'num_filters_1': 28, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.014936557945558409, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 41, 'num_filters_3': 60, 'num_filters_4': 70}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:06:02 DISPATCHER: Starting worker discovery
23:06:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:06:02 DISPATCHER: Finished worker discovery
23:07:02 DISPATCHER: Starting worker discovery
23:07:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:07:02 DISPATCHER: Finished worker discovery
23:07:45 WORKER: done with job (8, 0, 11), trying to register it.
23:07:45 WORKER: registered result for job (8, 0, 11) with dispatcher
23:07:45 DISPATCHER: job (8, 0, 11) finished
23:07:45 DISPATCHER: register_result: lock acquired
23:07:45 DISPATCHER: job (8, 0, 11) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
23:07:45 job_id: (8, 0, 11)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.03446110500265683, 'num_filters_1': 28, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.014936557945558409, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 41, 'num_filters_3': 60, 'num_filters_4': 70}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.03446110500265683, 'num_filters_1': 28, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.014936557945558409, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 41, 'num_filters_3': 60, 'num_filters_4': 70}"}}
exception: None

23:07:45 DISPATCHER: Trying to submit another job.
23:07:45 job_callback for (8, 0, 11) started
23:07:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:07:45 job_callback for (8, 0, 11) got condition
23:07:45 HBMASTER: Trying to run another job!
23:07:45 job_callback for (8, 0, 11) finished
23:07:45 start sampling a new configuration.
23:07:45 best_vector: [3, 1, 0.43139219118227007, 0.7799250561388027, 0.9149328122108362, 1, 0.036534120546070636, 0.16502695235892959, 0, 0, 0, 1, 0.1702971643440021, 0.2959708717898229, 0.8479304371423546, 0.815477144613616], 0.0001305023798789098, 0.0014184777709407507, 1.8511472491309906e-07
23:07:45 done sampling a new configuration.
23:07:45 HBMASTER: schedule new run for iteration 8
23:07:45 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
23:07:45 HBMASTER: submitting job (8, 0, 12) to dispatcher
23:07:45 DISPATCHER: trying to submit job (8, 0, 12)
23:07:45 DISPATCHER: trying to notify the job_runner thread.
23:07:45 HBMASTER: job (8, 0, 12) submitted to dispatcher
23:07:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:07:45 DISPATCHER: Trying to submit another job.
23:07:45 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:07:45 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:07:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:07:45 WORKER: start processing job (8, 0, 12)
23:07:45 WORKER: args: ()
23:07:45 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.007290954405701793, 'num_filters_1': 81, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.01639475817365358, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 22, 'num_filters_3': 29, 'num_filters_4': 93, 'num_filters_5': 87}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:08:02 DISPATCHER: Starting worker discovery
23:08:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:08:02 DISPATCHER: Finished worker discovery
23:09:02 DISPATCHER: Starting worker discovery
23:09:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:09:02 DISPATCHER: Finished worker discovery
23:09:34 WORKER: done with job (8, 0, 12), trying to register it.
23:09:34 WORKER: registered result for job (8, 0, 12) with dispatcher
23:09:34 DISPATCHER: job (8, 0, 12) finished
23:09:34 DISPATCHER: register_result: lock acquired
23:09:34 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
23:09:34 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.007290954405701793, 'num_filters_1': 81, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.01639475817365358, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 22, 'num_filters_3': 29, 'num_filters_4': 93, 'num_filters_5': 87}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5300647152207529, 'info': {'sick_no_sick': 0.5300647152207529, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.007290954405701793, 'num_filters_1': 81, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.01639475817365358, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 22, 'num_filters_3': 29, 'num_filters_4': 93, 'num_filters_5': 87}"}}
exception: None

23:09:34 job_callback for (8, 0, 12) started
23:09:34 DISPATCHER: Trying to submit another job.
23:09:34 job_callback for (8, 0, 12) got condition
23:09:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:09:34 HBMASTER: Trying to run another job!
23:09:34 job_callback for (8, 0, 12) finished
23:09:34 start sampling a new configuration.
23:09:34 done sampling a new configuration.
23:09:34 HBMASTER: schedule new run for iteration 8
23:09:34 HBMASTER: trying submitting job (8, 0, 13) to dispatcher
23:09:34 HBMASTER: submitting job (8, 0, 13) to dispatcher
23:09:34 DISPATCHER: trying to submit job (8, 0, 13)
23:09:34 DISPATCHER: trying to notify the job_runner thread.
23:09:34 HBMASTER: job (8, 0, 13) submitted to dispatcher
23:09:34 DISPATCHER: Trying to submit another job.
23:09:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:09:34 DISPATCHER: starting job (8, 0, 13) on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:09:34 DISPATCHER: job (8, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:09:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:09:34 WORKER: start processing job (8, 0, 13)
23:09:34 WORKER: args: ()
23:09:34 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.007995176536755676, 'num_filters_1': 67, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.15333318302004217}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:10:02 DISPATCHER: Starting worker discovery
23:10:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:10:02 DISPATCHER: Finished worker discovery
23:11:02 DISPATCHER: Starting worker discovery
23:11:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:11:02 DISPATCHER: Finished worker discovery
23:11:22 WORKER: done with job (8, 0, 13), trying to register it.
23:11:22 WORKER: registered result for job (8, 0, 13) with dispatcher
23:11:22 DISPATCHER: job (8, 0, 13) finished
23:11:22 DISPATCHER: register_result: lock acquired
23:11:22 DISPATCHER: job (8, 0, 13) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
23:11:22 job_id: (8, 0, 13)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.007995176536755676, 'num_filters_1': 67, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.15333318302004217}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.07498661150333831, 'info': {'sick_no_sick': 0.07498661150333831, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.007995176536755676, 'num_filters_1': 67, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.15333318302004217}"}}
exception: None

23:11:22 job_callback for (8, 0, 13) started
23:11:22 job_callback for (8, 0, 13) got condition
23:11:22 DISPATCHER: Trying to submit another job.
23:11:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:11:22 HBMASTER: Trying to run another job!
23:11:22 job_callback for (8, 0, 13) finished
23:11:22 start sampling a new configuration.
23:11:22 done sampling a new configuration.
23:11:22 HBMASTER: schedule new run for iteration 8
23:11:22 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
23:11:22 HBMASTER: submitting job (8, 0, 14) to dispatcher
23:11:22 DISPATCHER: trying to submit job (8, 0, 14)
23:11:22 DISPATCHER: trying to notify the job_runner thread.
23:11:22 HBMASTER: job (8, 0, 14) submitted to dispatcher
23:11:22 DISPATCHER: Trying to submit another job.
23:11:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:11:22 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:11:22 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:11:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:11:22 WORKER: start processing job (8, 0, 14)
23:11:23 WORKER: args: ()
23:11:23 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.003348053027619993, 'num_filters_1': 21, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.05083271449796802, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 34, 'num_filters_3': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:12:02 DISPATCHER: Starting worker discovery
23:12:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:12:02 DISPATCHER: Finished worker discovery
23:13:02 DISPATCHER: Starting worker discovery
23:13:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:13:02 DISPATCHER: Finished worker discovery
23:13:12 WORKER: done with job (8, 0, 14), trying to register it.
23:13:12 WORKER: registered result for job (8, 0, 14) with dispatcher
23:13:12 DISPATCHER: job (8, 0, 14) finished
23:13:12 DISPATCHER: register_result: lock acquired
23:13:12 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
23:13:12 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.003348053027619993, 'num_filters_1': 21, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.05083271449796802, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 34, 'num_filters_3': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5182911989800192, 'info': {'sick_no_sick': 0.5182911989800192, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.003348053027619993, 'num_filters_1': 21, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.05083271449796802, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 34, 'num_filters_3': 16}"}}
exception: None

23:13:12 job_callback for (8, 0, 14) started
23:13:12 DISPATCHER: Trying to submit another job.
23:13:12 job_callback for (8, 0, 14) got condition
23:13:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:13:12 HBMASTER: Trying to run another job!
23:13:12 job_callback for (8, 0, 14) finished
23:13:12 start sampling a new configuration.
23:13:12 best_vector: [0, 1, 0.9885365247677634, 0.9582554115592054, 0.6953062663597824, 0, 0.35967517891726575, 0.039529593398945, 0, 2, 1, 2, 0.6701885366942004, 0.5648468740954834, 0.7252339948725148, 0.9902630444748277], 0.0019237465456674002, 3.4172917038884314e-05, 6.574003110893234e-08
23:13:12 done sampling a new configuration.
23:13:12 HBMASTER: schedule new run for iteration 8
23:13:12 HBMASTER: trying submitting job (8, 0, 15) to dispatcher
23:13:12 HBMASTER: submitting job (8, 0, 15) to dispatcher
23:13:12 DISPATCHER: trying to submit job (8, 0, 15)
23:13:12 DISPATCHER: trying to notify the job_runner thread.
23:13:12 HBMASTER: job (8, 0, 15) submitted to dispatcher
23:13:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:13:12 DISPATCHER: Trying to submit another job.
23:13:12 DISPATCHER: starting job (8, 0, 15) on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:13:12 DISPATCHER: job (8, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:13:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:13:12 WORKER: start processing job (8, 0, 15)
23:13:12 WORKER: args: ()
23:13:12 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.094857800333218, 'num_filters_1': 118, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.011257169017548611, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 64, 'num_filters_3': 51, 'num_filters_4': 72}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:14:02 DISPATCHER: Starting worker discovery
23:14:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:14:02 DISPATCHER: Finished worker discovery
23:15:00 WORKER: done with job (8, 0, 15), trying to register it.
23:15:00 WORKER: registered result for job (8, 0, 15) with dispatcher
23:15:00 DISPATCHER: job (8, 0, 15) finished
23:15:00 DISPATCHER: register_result: lock acquired
23:15:00 DISPATCHER: job (8, 0, 15) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
23:15:00 job_id: (8, 0, 15)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.094857800333218, 'num_filters_1': 118, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.011257169017548611, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 64, 'num_filters_3': 51, 'num_filters_4': 72}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.094857800333218, 'num_filters_1': 118, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.011257169017548611, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 64, 'num_filters_3': 51, 'num_filters_4': 72}"}}
exception: None

23:15:00 job_callback for (8, 0, 15) started
23:15:00 DISPATCHER: Trying to submit another job.
23:15:00 job_callback for (8, 0, 15) got condition
23:15:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:15:00 HBMASTER: Trying to run another job!
23:15:00 job_callback for (8, 0, 15) finished
23:15:00 start sampling a new configuration.
23:15:00 best_vector: [0, 2, 0.19421162784113244, 0.7471795805933512, 0.9208754748521837, 1, 0.061591720566775435, 0.5112442670705666, 2, 0, 0, 1, 0.3713497420498927, 0.5092718821661566, 0.05261998398780332, 0.10310738691605613], 1.133757425440978e-26, 8.82022889165244e-07, -1.8317145872194335e-07
23:15:00 done sampling a new configuration.
23:15:00 HBMASTER: schedule new run for iteration 8
23:15:00 HBMASTER: trying submitting job (8, 0, 16) to dispatcher
23:15:00 HBMASTER: submitting job (8, 0, 16) to dispatcher
23:15:00 DISPATCHER: trying to submit job (8, 0, 16)
23:15:00 DISPATCHER: trying to notify the job_runner thread.
23:15:00 HBMASTER: job (8, 0, 16) submitted to dispatcher
23:15:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:15:00 DISPATCHER: Trying to submit another job.
23:15:00 DISPATCHER: starting job (8, 0, 16) on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:15:00 DISPATCHER: job (8, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:15:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:15:00 WORKER: start processing job (8, 0, 16)
23:15:00 WORKER: args: ()
23:15:00 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0024458130374525205, 'num_filters_1': 75, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.046253449433663864, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 34, 'num_filters_3': 46, 'num_filters_4': 17, 'num_filters_5': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:15:02 DISPATCHER: Starting worker discovery
23:15:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:15:02 DISPATCHER: Finished worker discovery
23:16:02 DISPATCHER: Starting worker discovery
23:16:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:16:02 DISPATCHER: Finished worker discovery
23:16:50 WORKER: done with job (8, 0, 16), trying to register it.
23:16:50 WORKER: registered result for job (8, 0, 16) with dispatcher
23:16:50 DISPATCHER: job (8, 0, 16) finished
23:16:50 DISPATCHER: register_result: lock acquired
23:16:50 DISPATCHER: job (8, 0, 16) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
23:16:50 job_id: (8, 0, 16)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0024458130374525205, 'num_filters_1': 75, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.046253449433663864, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 34, 'num_filters_3': 46, 'num_filters_4': 17, 'num_filters_5': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4083239754546952, 'info': {'sick_no_sick': 0.4083239754546952, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0024458130374525205, 'num_filters_1': 75, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.046253449433663864, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 34, 'num_filters_3': 46, 'num_filters_4': 17, 'num_filters_5': 19}"}}
exception: None

23:16:50 job_callback for (8, 0, 16) started
23:16:50 DISPATCHER: Trying to submit another job.
23:16:50 job_callback for (8, 0, 16) got condition
23:16:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:16:50 HBMASTER: Trying to run another job!
23:16:50 job_callback for (8, 0, 16) finished
23:16:50 start sampling a new configuration.
23:16:50 done sampling a new configuration.
23:16:50 HBMASTER: schedule new run for iteration 8
23:16:50 HBMASTER: trying submitting job (8, 0, 17) to dispatcher
23:16:50 HBMASTER: submitting job (8, 0, 17) to dispatcher
23:16:50 DISPATCHER: trying to submit job (8, 0, 17)
23:16:50 DISPATCHER: trying to notify the job_runner thread.
23:16:50 HBMASTER: job (8, 0, 17) submitted to dispatcher
23:16:50 DISPATCHER: Trying to submit another job.
23:16:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:16:50 DISPATCHER: starting job (8, 0, 17) on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:16:50 DISPATCHER: job (8, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:16:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:16:50 WORKER: start processing job (8, 0, 17)
23:16:50 WORKER: args: ()
23:16:50 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0010016033217479952, 'num_filters_1': 118, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.05044683190881027, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 94, 'num_filters_3': 49}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:17:02 DISPATCHER: Starting worker discovery
23:17:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:17:02 DISPATCHER: Finished worker discovery
23:18:02 DISPATCHER: Starting worker discovery
23:18:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:18:02 DISPATCHER: Finished worker discovery
23:18:39 WORKER: done with job (8, 0, 17), trying to register it.
23:18:39 WORKER: registered result for job (8, 0, 17) with dispatcher
23:18:39 DISPATCHER: job (8, 0, 17) finished
23:18:39 DISPATCHER: register_result: lock acquired
23:18:39 DISPATCHER: job (8, 0, 17) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
23:18:39 job_id: (8, 0, 17)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0010016033217479952, 'num_filters_1': 118, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.05044683190881027, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 94, 'num_filters_3': 49}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4311812000739737, 'info': {'sick_no_sick': 0.4311812000739737, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0010016033217479952, 'num_filters_1': 118, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.05044683190881027, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 94, 'num_filters_3': 49}"}}
exception: None

23:18:39 job_callback for (8, 0, 17) started
23:18:39 DISPATCHER: Trying to submit another job.
23:18:39 job_callback for (8, 0, 17) got condition
23:18:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:18:39 HBMASTER: Trying to run another job!
23:18:39 job_callback for (8, 0, 17) finished
23:18:39 start sampling a new configuration.
23:18:39 done sampling a new configuration.
23:18:39 HBMASTER: schedule new run for iteration 8
23:18:39 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
23:18:39 HBMASTER: submitting job (8, 0, 18) to dispatcher
23:18:39 DISPATCHER: trying to submit job (8, 0, 18)
23:18:39 DISPATCHER: trying to notify the job_runner thread.
23:18:39 HBMASTER: job (8, 0, 18) submitted to dispatcher
23:18:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:18:39 DISPATCHER: Trying to submit another job.
23:18:39 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:18:39 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:18:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:18:39 WORKER: start processing job (8, 0, 18)
23:18:39 WORKER: args: ()
23:18:39 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0024190435937741853, 'num_filters_1': 17, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.03640179251715459, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 68, 'num_filters_3': 102, 'num_filters_4': 85, 'num_filters_5': 57}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:19:02 DISPATCHER: Starting worker discovery
23:19:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:19:02 DISPATCHER: Finished worker discovery
23:20:02 DISPATCHER: Starting worker discovery
23:20:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:20:02 DISPATCHER: Finished worker discovery
23:20:29 WORKER: done with job (8, 0, 18), trying to register it.
23:20:29 WORKER: registered result for job (8, 0, 18) with dispatcher
23:20:29 DISPATCHER: job (8, 0, 18) finished
23:20:29 DISPATCHER: register_result: lock acquired
23:20:29 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
23:20:29 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0024190435937741853, 'num_filters_1': 17, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.03640179251715459, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 68, 'num_filters_3': 102, 'num_filters_4': 85, 'num_filters_5': 57}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0024190435937741853, 'num_filters_1': 17, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.03640179251715459, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 68, 'num_filters_3': 102, 'num_filters_4': 85, 'num_filters_5': 57}"}}
exception: None

23:20:29 job_callback for (8, 0, 18) started
23:20:29 job_callback for (8, 0, 18) got condition
23:20:29 DISPATCHER: Trying to submit another job.
23:20:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:20:29 HBMASTER: Trying to run another job!
23:20:29 job_callback for (8, 0, 18) finished
23:20:29 start sampling a new configuration.
23:20:29 best_vector: [3, 1, 0.5145348622995811, 0.5482563942068948, 0.6885853002432433, 0, 0.21226038057946484, 0.23040184363235786, 2, 1, 0, 1, 0.5206189884791326, 0.9783125924238111, 0.11575680983843628, 0.9414393938943741], 0.00756823101006013, 0.0007578563709974167, 5.735632088154284e-06
23:20:29 done sampling a new configuration.
23:20:29 HBMASTER: schedule new run for iteration 8
23:20:29 HBMASTER: trying submitting job (8, 0, 19) to dispatcher
23:20:29 HBMASTER: submitting job (8, 0, 19) to dispatcher
23:20:29 DISPATCHER: trying to submit job (8, 0, 19)
23:20:29 DISPATCHER: trying to notify the job_runner thread.
23:20:29 HBMASTER: job (8, 0, 19) submitted to dispatcher
23:20:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:20:29 DISPATCHER: Trying to submit another job.
23:20:29 DISPATCHER: starting job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:20:29 DISPATCHER: job (8, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:20:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:20:29 WORKER: start processing job (8, 0, 19)
23:20:29 WORKER: args: ()
23:20:29 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.010692265263650847, 'num_filters_1': 49, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.019941586635405316, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 47, 'num_filters_3': 123, 'num_filters_4': 20}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:21:02 DISPATCHER: Starting worker discovery
23:21:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:21:02 DISPATCHER: Finished worker discovery
23:22:02 DISPATCHER: Starting worker discovery
23:22:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:22:02 DISPATCHER: Finished worker discovery
23:22:17 WORKER: done with job (8, 0, 19), trying to register it.
23:22:17 WORKER: registered result for job (8, 0, 19) with dispatcher
23:22:17 DISPATCHER: job (8, 0, 19) finished
23:22:17 DISPATCHER: register_result: lock acquired
23:22:17 DISPATCHER: job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
23:22:17 job_id: (8, 0, 19)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.010692265263650847, 'num_filters_1': 49, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.019941586635405316, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 47, 'num_filters_3': 123, 'num_filters_4': 20}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.010692265263650847, 'num_filters_1': 49, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.019941586635405316, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 47, 'num_filters_3': 123, 'num_filters_4': 20}"}}
exception: None

23:22:17 job_callback for (8, 0, 19) started
23:22:17 DISPATCHER: Trying to submit another job.
23:22:17 job_callback for (8, 0, 19) got condition
23:22:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:22:17 HBMASTER: Trying to run another job!
23:22:17 job_callback for (8, 0, 19) finished
23:22:17 start sampling a new configuration.
23:22:17 best_vector: [2, 0, 0.029530576489587686, 0.43486386220106343, 0.9873850365235961, 1, 0.31894954848743157, 0.10356488774583146, 2, 1, 2, 2, 0.16772213531371138, 0.3445318938881399, 0.13137019618078027, 0.9389659055977962], 0.0005443608933289116, 0.0029963702451116575, 1.6311067833731518e-06
23:22:17 done sampling a new configuration.
23:22:17 HBMASTER: schedule new run for iteration 8
23:22:17 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
23:22:17 HBMASTER: submitting job (8, 0, 20) to dispatcher
23:22:17 DISPATCHER: trying to submit job (8, 0, 20)
23:22:17 DISPATCHER: trying to notify the job_runner thread.
23:22:17 HBMASTER: job (8, 0, 20) submitted to dispatcher
23:22:17 DISPATCHER: Trying to submit another job.
23:22:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:22:17 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:22:17 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:22:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:22:17 WORKER: start processing job (8, 0, 20)
23:22:17 WORKER: args: ()
23:22:17 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0011456742524089025, 'num_filters_1': 39, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.013637696633193652, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 22, 'num_filters_3': 32, 'num_filters_4': 20, 'num_filters_5': 113}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:23:02 DISPATCHER: Starting worker discovery
23:23:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:23:02 DISPATCHER: Finished worker discovery
23:24:02 DISPATCHER: Starting worker discovery
23:24:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:24:02 DISPATCHER: Finished worker discovery
23:24:05 WORKER: done with job (8, 0, 20), trying to register it.
23:24:05 WORKER: registered result for job (8, 0, 20) with dispatcher
23:24:05 DISPATCHER: job (8, 0, 20) finished
23:24:05 DISPATCHER: register_result: lock acquired
23:24:05 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
23:24:05 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0011456742524089025, 'num_filters_1': 39, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.013637696633193652, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 22, 'num_filters_3': 32, 'num_filters_4': 20, 'num_filters_5': 113}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5890055160305326, 'info': {'sick_no_sick': 0.5890055160305326, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0011456742524089025, 'num_filters_1': 39, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.013637696633193652, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 22, 'num_filters_3': 32, 'num_filters_4': 20, 'num_filters_5': 113}"}}
exception: None

23:24:05 DISPATCHER: Trying to submit another job.
23:24:05 job_callback for (8, 0, 20) started
23:24:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:24:05 job_callback for (8, 0, 20) got condition
23:24:05 HBMASTER: Trying to run another job!
23:24:05 job_callback for (8, 0, 20) finished
23:24:05 start sampling a new configuration.
23:24:05 done sampling a new configuration.
23:24:05 HBMASTER: schedule new run for iteration 8
23:24:05 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
23:24:05 HBMASTER: submitting job (8, 0, 21) to dispatcher
23:24:05 DISPATCHER: trying to submit job (8, 0, 21)
23:24:05 DISPATCHER: trying to notify the job_runner thread.
23:24:05 HBMASTER: job (8, 0, 21) submitted to dispatcher
23:24:05 DISPATCHER: Trying to submit another job.
23:24:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:24:05 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:24:05 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:24:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:24:05 WORKER: start processing job (8, 0, 21)
23:24:05 WORKER: args: ()
23:24:05 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0036911220518985274, 'num_filters_1': 61, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.1082465587574942, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 28, 'num_filters_3': 71}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:25:02 DISPATCHER: Starting worker discovery
23:25:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:25:02 DISPATCHER: Finished worker discovery
23:25:55 WORKER: done with job (8, 0, 21), trying to register it.
23:25:55 WORKER: registered result for job (8, 0, 21) with dispatcher
23:25:55 DISPATCHER: job (8, 0, 21) finished
23:25:55 DISPATCHER: register_result: lock acquired
23:25:55 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
23:25:55 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0036911220518985274, 'num_filters_1': 61, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.1082465587574942, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 28, 'num_filters_3': 71}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0017624788514974394, 'info': {'sick_no_sick': 0.0017624788514974394, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0036911220518985274, 'num_filters_1': 61, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.1082465587574942, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 28, 'num_filters_3': 71}"}}
exception: None

23:25:55 job_callback for (8, 0, 21) started
23:25:55 job_callback for (8, 0, 21) got condition
23:25:55 DISPATCHER: Trying to submit another job.
23:25:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:25:55 HBMASTER: Trying to run another job!
23:25:55 job_callback for (8, 0, 21) finished
23:25:55 start sampling a new configuration.
23:25:55 best_vector: [2, 0, 0.17895702952790865, 0.8663979668916252, 0.831981898981449, 1, 0.8793750103799676, 0.12104727666502597, 2, 1, 2, 1, 0.9971491993086137, 0.37834164130655645, 0.8057915804161362, 0.9924252040108755], 0.00025585205232644536, 0.0015286257290692733, 3.911020300213824e-07
23:25:55 done sampling a new configuration.
23:25:55 HBMASTER: schedule new run for iteration 8
23:25:55 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
23:25:55 HBMASTER: submitting job (8, 0, 22) to dispatcher
23:25:55 DISPATCHER: trying to submit job (8, 0, 22)
23:25:55 DISPATCHER: trying to notify the job_runner thread.
23:25:55 HBMASTER: job (8, 0, 22) submitted to dispatcher
23:25:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:25:55 DISPATCHER: Trying to submit another job.
23:25:55 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:25:55 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:25:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:25:55 WORKER: start processing job (8, 0, 22)
23:25:55 WORKER: args: ()
23:25:55 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0022798908681058066, 'num_filters_1': 97, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.014370971821847565, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 128, 'num_filters_3': 35, 'num_filters_4': 85, 'num_filters_5': 126}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:26:02 DISPATCHER: Starting worker discovery
23:26:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:26:02 DISPATCHER: Finished worker discovery
23:27:02 DISPATCHER: Starting worker discovery
23:27:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:27:02 DISPATCHER: Finished worker discovery
23:27:43 WORKER: done with job (8, 0, 22), trying to register it.
23:27:43 WORKER: registered result for job (8, 0, 22) with dispatcher
23:27:43 DISPATCHER: job (8, 0, 22) finished
23:27:43 DISPATCHER: register_result: lock acquired
23:27:43 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
23:27:43 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0022798908681058066, 'num_filters_1': 97, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.014370971821847565, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 128, 'num_filters_3': 35, 'num_filters_4': 85, 'num_filters_5': 126}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.549067767634007, 'info': {'sick_no_sick': 0.549067767634007, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0022798908681058066, 'num_filters_1': 97, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.014370971821847565, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 128, 'num_filters_3': 35, 'num_filters_4': 85, 'num_filters_5': 126}"}}
exception: None

23:27:43 job_callback for (8, 0, 22) started
23:27:43 DISPATCHER: Trying to submit another job.
23:27:43 job_callback for (8, 0, 22) got condition
23:27:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:27:43 HBMASTER: Trying to run another job!
23:27:43 job_callback for (8, 0, 22) finished
23:27:43 start sampling a new configuration.
23:27:43 done sampling a new configuration.
23:27:43 HBMASTER: schedule new run for iteration 8
23:27:43 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
23:27:43 HBMASTER: submitting job (8, 0, 23) to dispatcher
23:27:43 DISPATCHER: trying to submit job (8, 0, 23)
23:27:43 DISPATCHER: trying to notify the job_runner thread.
23:27:43 HBMASTER: job (8, 0, 23) submitted to dispatcher
23:27:43 DISPATCHER: Trying to submit another job.
23:27:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:27:43 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:27:43 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:27:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:27:43 WORKER: start processing job (8, 0, 23)
23:27:43 WORKER: args: ()
23:27:43 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.004400238493427607, 'num_filters_1': 89, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.016299099665218697, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 61, 'num_filters_3': 24, 'num_filters_4': 30, 'num_filters_5': 43}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:28:02 DISPATCHER: Starting worker discovery
23:28:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:28:02 DISPATCHER: Finished worker discovery
23:29:02 DISPATCHER: Starting worker discovery
23:29:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:29:02 DISPATCHER: Finished worker discovery
23:29:31 WORKER: done with job (8, 0, 23), trying to register it.
23:29:31 WORKER: registered result for job (8, 0, 23) with dispatcher
23:29:31 DISPATCHER: job (8, 0, 23) finished
23:29:31 DISPATCHER: register_result: lock acquired
23:29:31 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
23:29:31 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.004400238493427607, 'num_filters_1': 89, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.016299099665218697, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 61, 'num_filters_3': 24, 'num_filters_4': 30, 'num_filters_5': 43}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.004400238493427607, 'num_filters_1': 89, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.016299099665218697, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 61, 'num_filters_3': 24, 'num_filters_4': 30, 'num_filters_5': 43}"}}
exception: None

23:29:31 job_callback for (8, 0, 23) started
23:29:31 job_callback for (8, 0, 23) got condition
23:29:31 DISPATCHER: Trying to submit another job.
23:29:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:29:31 HBMASTER: Trying to run another job!
23:29:31 job_callback for (8, 0, 23) finished
23:29:31 start sampling a new configuration.
23:29:31 done sampling a new configuration.
23:29:31 HBMASTER: schedule new run for iteration 8
23:29:31 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
23:29:31 HBMASTER: submitting job (8, 0, 24) to dispatcher
23:29:31 DISPATCHER: trying to submit job (8, 0, 24)
23:29:31 DISPATCHER: trying to notify the job_runner thread.
23:29:31 HBMASTER: job (8, 0, 24) submitted to dispatcher
23:29:31 DISPATCHER: Trying to submit another job.
23:29:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:29:31 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:29:31 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:29:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:29:31 WORKER: start processing job (8, 0, 24)
23:29:31 WORKER: args: ()
23:29:31 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.006813785215507625, 'num_filters_1': 56, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.019560560584926775, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 40, 'num_filters_3': 125}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:30:02 DISPATCHER: Starting worker discovery
23:30:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:30:02 DISPATCHER: Finished worker discovery
23:31:02 DISPATCHER: Starting worker discovery
23:31:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:31:02 DISPATCHER: Finished worker discovery
23:31:19 WORKER: done with job (8, 0, 24), trying to register it.
23:31:19 WORKER: registered result for job (8, 0, 24) with dispatcher
23:31:19 DISPATCHER: job (8, 0, 24) finished
23:31:19 DISPATCHER: register_result: lock acquired
23:31:19 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
23:31:19 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.006813785215507625, 'num_filters_1': 56, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.019560560584926775, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 40, 'num_filters_3': 125}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5933455813982161, 'info': {'sick_no_sick': 0.5933455813982161, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.006813785215507625, 'num_filters_1': 56, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.019560560584926775, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 40, 'num_filters_3': 125}"}}
exception: None

23:31:19 job_callback for (8, 0, 24) started
23:31:19 job_callback for (8, 0, 24) got condition
23:31:19 DISPATCHER: Trying to submit another job.
23:31:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:31:19 HBMASTER: Trying to run another job!
23:31:19 job_callback for (8, 0, 24) finished
23:31:19 start sampling a new configuration.
23:31:19 done sampling a new configuration.
23:31:19 HBMASTER: schedule new run for iteration 8
23:31:19 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
23:31:19 HBMASTER: submitting job (8, 0, 25) to dispatcher
23:31:19 DISPATCHER: trying to submit job (8, 0, 25)
23:31:19 DISPATCHER: trying to notify the job_runner thread.
23:31:19 HBMASTER: job (8, 0, 25) submitted to dispatcher
23:31:19 DISPATCHER: Trying to submit another job.
23:31:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:31:19 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:31:19 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:31:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:31:19 WORKER: start processing job (8, 0, 25)
23:31:19 WORKER: args: ()
23:31:19 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.029282264997608595, 'num_filters_1': 95, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.11203315740506134, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 123, 'num_filters_3': 82, 'num_filters_4': 48}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:32:02 DISPATCHER: Starting worker discovery
23:32:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:32:02 DISPATCHER: Finished worker discovery
23:33:02 DISPATCHER: Starting worker discovery
23:33:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:33:02 DISPATCHER: Finished worker discovery
23:33:07 WORKER: done with job (8, 0, 25), trying to register it.
23:33:07 WORKER: registered result for job (8, 0, 25) with dispatcher
23:33:07 DISPATCHER: job (8, 0, 25) finished
23:33:07 DISPATCHER: register_result: lock acquired
23:33:07 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
23:33:07 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.029282264997608595, 'num_filters_1': 95, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.11203315740506134, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 123, 'num_filters_3': 82, 'num_filters_4': 48}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0035766400723600275, 'info': {'sick_no_sick': 0.0035766400723600275, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.029282264997608595, 'num_filters_1': 95, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.11203315740506134, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 123, 'num_filters_3': 82, 'num_filters_4': 48}"}}
exception: None

23:33:07 job_callback for (8, 0, 25) started
23:33:07 DISPATCHER: Trying to submit another job.
23:33:07 job_callback for (8, 0, 25) got condition
23:33:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:33:07 HBMASTER: Trying to run another job!
23:33:07 job_callback for (8, 0, 25) finished
23:33:07 start sampling a new configuration.
23:33:07 best_vector: [3, 1, 0.37125622271289405, 0.5385465321931978, 0.9623152969629731, 1, 0.17803257567821723, 0.20993799572676491, 2, 1, 0, 1, 0.3231727439329811, 0.07240964227907204, 0.6414018834214259, 0.8199779933326714], 0.0006334875037069338, 0.00039370203511508175, 2.4940531942939273e-07
23:33:07 done sampling a new configuration.
23:33:07 HBMASTER: schedule new run for iteration 8
23:33:07 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
23:33:07 HBMASTER: submitting job (8, 0, 26) to dispatcher
23:33:07 DISPATCHER: trying to submit job (8, 0, 26)
23:33:07 DISPATCHER: trying to notify the job_runner thread.
23:33:07 HBMASTER: job (8, 0, 26) submitted to dispatcher
23:33:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:33:07 DISPATCHER: Trying to submit another job.
23:33:07 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:33:07 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:33:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:33:07 WORKER: start processing job (8, 0, 26)
23:33:07 WORKER: args: ()
23:33:07 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.00552729247087112, 'num_filters_1': 48, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.01875580158152464, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 31, 'num_filters_3': 18, 'num_filters_4': 60, 'num_filters_5': 88}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:34:02 DISPATCHER: Starting worker discovery
23:34:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:34:02 DISPATCHER: Finished worker discovery
23:34:55 WORKER: done with job (8, 0, 26), trying to register it.
23:34:55 WORKER: registered result for job (8, 0, 26) with dispatcher
23:34:55 DISPATCHER: job (8, 0, 26) finished
23:34:55 DISPATCHER: register_result: lock acquired
23:34:55 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
23:34:55 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.00552729247087112, 'num_filters_1': 48, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.01875580158152464, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 31, 'num_filters_3': 18, 'num_filters_4': 60, 'num_filters_5': 88}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6352057221748626, 'info': {'sick_no_sick': 0.6352057221748626, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.00552729247087112, 'num_filters_1': 48, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.01875580158152464, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 31, 'num_filters_3': 18, 'num_filters_4': 60, 'num_filters_5': 88}"}}
exception: None

23:34:55 job_callback for (8, 0, 26) started
23:34:55 job_callback for (8, 0, 26) got condition
23:34:55 DISPATCHER: Trying to submit another job.
23:34:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:34:55 HBMASTER: Trying to run another job!
23:34:55 job_callback for (8, 0, 26) finished
23:34:55 ITERATION: Advancing config (8, 0, 0) to next budget 133.333333
23:34:55 ITERATION: Advancing config (8, 0, 1) to next budget 133.333333
23:34:55 ITERATION: Advancing config (8, 0, 7) to next budget 133.333333
23:34:55 ITERATION: Advancing config (8, 0, 9) to next budget 133.333333
23:34:55 ITERATION: Advancing config (8, 0, 12) to next budget 133.333333
23:34:55 ITERATION: Advancing config (8, 0, 20) to next budget 133.333333
23:34:55 ITERATION: Advancing config (8, 0, 22) to next budget 133.333333
23:34:55 ITERATION: Advancing config (8, 0, 24) to next budget 133.333333
23:34:55 ITERATION: Advancing config (8, 0, 26) to next budget 133.333333
23:34:55 HBMASTER: schedule new run for iteration 8
23:34:55 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
23:34:55 HBMASTER: submitting job (8, 0, 0) to dispatcher
23:34:55 DISPATCHER: trying to submit job (8, 0, 0)
23:34:55 DISPATCHER: trying to notify the job_runner thread.
23:34:55 HBMASTER: job (8, 0, 0) submitted to dispatcher
23:34:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:34:55 DISPATCHER: Trying to submit another job.
23:34:55 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:34:55 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:34:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:34:55 WORKER: start processing job (8, 0, 0)
23:34:55 WORKER: args: ()
23:34:55 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0033601568283976274, 'num_filters_1': 89, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.021200555055636842, 'kernel_size_2': 3, 'num_filters_2': 33}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:35:02 DISPATCHER: Starting worker discovery
23:35:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:35:02 DISPATCHER: Finished worker discovery
23:36:02 DISPATCHER: Starting worker discovery
23:36:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:36:02 DISPATCHER: Finished worker discovery
23:37:02 DISPATCHER: Starting worker discovery
23:37:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:37:02 DISPATCHER: Finished worker discovery
23:38:02 DISPATCHER: Starting worker discovery
23:38:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:38:02 DISPATCHER: Finished worker discovery
23:38:12 WORKER: done with job (8, 0, 0), trying to register it.
23:38:12 WORKER: registered result for job (8, 0, 0) with dispatcher
23:38:12 DISPATCHER: job (8, 0, 0) finished
23:38:12 DISPATCHER: register_result: lock acquired
23:38:12 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
23:38:12 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0033601568283976274, 'num_filters_1': 89, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.021200555055636842, 'kernel_size_2': 3, 'num_filters_2': 33}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5412592390384664, 'info': {'sick_no_sick': 0.5412592390384664, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0033601568283976274, 'num_filters_1': 89, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.021200555055636842, 'kernel_size_2': 3, 'num_filters_2': 33}"}}
exception: None

23:38:12 job_callback for (8, 0, 0) started
23:38:12 DISPATCHER: Trying to submit another job.
23:38:12 job_callback for (8, 0, 0) got condition
23:38:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:38:12 done building a new model for budget 133.333333 based on 17/31 split
Best loss for this budget:-0.645118





23:38:12 HBMASTER: Trying to run another job!
23:38:12 job_callback for (8, 0, 0) finished
23:38:12 HBMASTER: schedule new run for iteration 8
23:38:12 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
23:38:12 HBMASTER: submitting job (8, 0, 1) to dispatcher
23:38:12 DISPATCHER: trying to submit job (8, 0, 1)
23:38:12 DISPATCHER: trying to notify the job_runner thread.
23:38:12 HBMASTER: job (8, 0, 1) submitted to dispatcher
23:38:12 DISPATCHER: Trying to submit another job.
23:38:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:38:12 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:38:12 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:38:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:38:12 WORKER: start processing job (8, 0, 1)
23:38:12 WORKER: args: ()
23:38:12 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.014164717817730403, 'num_filters_1': 69, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.011747839462014464, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 78, 'num_filters_3': 56}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:39:02 DISPATCHER: Starting worker discovery
23:39:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:39:02 DISPATCHER: Finished worker discovery
23:40:02 DISPATCHER: Starting worker discovery
23:40:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:40:02 DISPATCHER: Finished worker discovery
23:41:02 DISPATCHER: Starting worker discovery
23:41:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:41:02 DISPATCHER: Finished worker discovery
23:41:29 WORKER: done with job (8, 0, 1), trying to register it.
23:41:29 WORKER: registered result for job (8, 0, 1) with dispatcher
23:41:29 DISPATCHER: job (8, 0, 1) finished
23:41:29 DISPATCHER: register_result: lock acquired
23:41:29 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
23:41:29 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.014164717817730403, 'num_filters_1': 69, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.011747839462014464, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 78, 'num_filters_3': 56}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3338635267228136, 'info': {'sick_no_sick': 0.3338635267228136, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.014164717817730403, 'num_filters_1': 69, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.011747839462014464, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 78, 'num_filters_3': 56}"}}
exception: None

23:41:29 job_callback for (8, 0, 1) started
23:41:29 job_callback for (8, 0, 1) got condition
23:41:29 DISPATCHER: Trying to submit another job.
23:41:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:41:29 done building a new model for budget 133.333333 based on 17/32 split
Best loss for this budget:-0.645118





23:41:29 HBMASTER: Trying to run another job!
23:41:29 job_callback for (8, 0, 1) finished
23:41:29 HBMASTER: schedule new run for iteration 8
23:41:29 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
23:41:29 HBMASTER: submitting job (8, 0, 7) to dispatcher
23:41:29 DISPATCHER: trying to submit job (8, 0, 7)
23:41:29 DISPATCHER: trying to notify the job_runner thread.
23:41:29 HBMASTER: job (8, 0, 7) submitted to dispatcher
23:41:29 DISPATCHER: Trying to submit another job.
23:41:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:41:29 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:41:29 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:41:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:41:29 WORKER: start processing job (8, 0, 7)
23:41:29 WORKER: args: ()
23:41:29 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.007080740203319061, 'num_filters_1': 39, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.02104722725063498, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 24, 'num_filters_3': 58, 'num_filters_4': 32}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:42:02 DISPATCHER: Starting worker discovery
23:42:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:42:02 DISPATCHER: Finished worker discovery
23:43:02 DISPATCHER: Starting worker discovery
23:43:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:43:02 DISPATCHER: Finished worker discovery
23:44:02 DISPATCHER: Starting worker discovery
23:44:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:44:02 DISPATCHER: Finished worker discovery
23:44:50 WORKER: done with job (8, 0, 7), trying to register it.
23:44:50 WORKER: registered result for job (8, 0, 7) with dispatcher
23:44:50 DISPATCHER: job (8, 0, 7) finished
23:44:50 DISPATCHER: register_result: lock acquired
23:44:50 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
23:44:50 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.007080740203319061, 'num_filters_1': 39, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.02104722725063498, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 24, 'num_filters_3': 58, 'num_filters_4': 32}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5799694474527607, 'info': {'sick_no_sick': 0.5799694474527607, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.007080740203319061, 'num_filters_1': 39, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.02104722725063498, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 24, 'num_filters_3': 58, 'num_filters_4': 32}"}}
exception: None

23:44:50 job_callback for (8, 0, 7) started
23:44:50 DISPATCHER: Trying to submit another job.
23:44:50 job_callback for (8, 0, 7) got condition
23:44:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:44:50 done building a new model for budget 133.333333 based on 17/33 split
Best loss for this budget:-0.645118





23:44:50 HBMASTER: Trying to run another job!
23:44:50 job_callback for (8, 0, 7) finished
23:44:50 HBMASTER: schedule new run for iteration 8
23:44:50 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
23:44:50 HBMASTER: submitting job (8, 0, 9) to dispatcher
23:44:50 DISPATCHER: trying to submit job (8, 0, 9)
23:44:50 DISPATCHER: trying to notify the job_runner thread.
23:44:50 HBMASTER: job (8, 0, 9) submitted to dispatcher
23:44:50 DISPATCHER: Trying to submit another job.
23:44:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:44:50 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:44:50 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:44:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:44:50 WORKER: start processing job (8, 0, 9)
23:44:50 WORKER: args: ()
23:44:50 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.020083343570790484, 'num_filters_1': 36, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.015328924906064313, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 70, 'num_filters_3': 78, 'num_filters_4': 31}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:45:02 DISPATCHER: Starting worker discovery
23:45:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:45:02 DISPATCHER: Finished worker discovery
23:46:02 DISPATCHER: Starting worker discovery
23:46:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:46:02 DISPATCHER: Finished worker discovery
23:47:02 DISPATCHER: Starting worker discovery
23:47:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:47:02 DISPATCHER: Finished worker discovery
23:48:02 DISPATCHER: Starting worker discovery
23:48:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:48:02 DISPATCHER: Finished worker discovery
23:48:07 WORKER: done with job (8, 0, 9), trying to register it.
23:48:07 WORKER: registered result for job (8, 0, 9) with dispatcher
23:48:07 DISPATCHER: job (8, 0, 9) finished
23:48:07 DISPATCHER: register_result: lock acquired
23:48:07 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
23:48:07 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.020083343570790484, 'num_filters_1': 36, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.015328924906064313, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 70, 'num_filters_3': 78, 'num_filters_4': 31}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6328485835061729, 'info': {'sick_no_sick': 0.6328485835061729, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.020083343570790484, 'num_filters_1': 36, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.015328924906064313, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 70, 'num_filters_3': 78, 'num_filters_4': 31}"}}
exception: None

23:48:07 job_callback for (8, 0, 9) started
23:48:07 DISPATCHER: Trying to submit another job.
23:48:07 job_callback for (8, 0, 9) got condition
23:48:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:48:07 done building a new model for budget 133.333333 based on 17/34 split
Best loss for this budget:-0.645118





23:48:07 HBMASTER: Trying to run another job!
23:48:07 job_callback for (8, 0, 9) finished
23:48:07 HBMASTER: schedule new run for iteration 8
23:48:07 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
23:48:07 HBMASTER: submitting job (8, 0, 12) to dispatcher
23:48:07 DISPATCHER: trying to submit job (8, 0, 12)
23:48:07 DISPATCHER: trying to notify the job_runner thread.
23:48:07 HBMASTER: job (8, 0, 12) submitted to dispatcher
23:48:07 DISPATCHER: Trying to submit another job.
23:48:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:48:07 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:48:07 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:48:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:48:07 WORKER: start processing job (8, 0, 12)
23:48:07 WORKER: args: ()
23:48:07 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.007290954405701793, 'num_filters_1': 81, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.01639475817365358, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 22, 'num_filters_3': 29, 'num_filters_4': 93, 'num_filters_5': 87}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:49:02 DISPATCHER: Starting worker discovery
23:49:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:49:02 DISPATCHER: Finished worker discovery
23:50:02 DISPATCHER: Starting worker discovery
23:50:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:50:02 DISPATCHER: Finished worker discovery
23:51:02 DISPATCHER: Starting worker discovery
23:51:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:51:03 DISPATCHER: Finished worker discovery
23:51:29 WORKER: done with job (8, 0, 12), trying to register it.
23:51:29 WORKER: registered result for job (8, 0, 12) with dispatcher
23:51:29 DISPATCHER: job (8, 0, 12) finished
23:51:29 DISPATCHER: register_result: lock acquired
23:51:29 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
23:51:29 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.007290954405701793, 'num_filters_1': 81, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.01639475817365358, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 22, 'num_filters_3': 29, 'num_filters_4': 93, 'num_filters_5': 87}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5797369903138446, 'info': {'sick_no_sick': 0.5797369903138446, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.007290954405701793, 'num_filters_1': 81, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.01639475817365358, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 22, 'num_filters_3': 29, 'num_filters_4': 93, 'num_filters_5': 87}"}}
exception: None

23:51:29 job_callback for (8, 0, 12) started
23:51:29 job_callback for (8, 0, 12) got condition
23:51:29 DISPATCHER: Trying to submit another job.
23:51:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:51:29 done building a new model for budget 133.333333 based on 17/34 split
Best loss for this budget:-0.645118





23:51:29 HBMASTER: Trying to run another job!
23:51:29 job_callback for (8, 0, 12) finished
23:51:29 HBMASTER: schedule new run for iteration 8
23:51:29 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
23:51:29 HBMASTER: submitting job (8, 0, 20) to dispatcher
23:51:29 DISPATCHER: trying to submit job (8, 0, 20)
23:51:29 DISPATCHER: trying to notify the job_runner thread.
23:51:29 HBMASTER: job (8, 0, 20) submitted to dispatcher
23:51:29 DISPATCHER: Trying to submit another job.
23:51:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:51:29 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:51:29 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:51:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:51:29 WORKER: start processing job (8, 0, 20)
23:51:29 WORKER: args: ()
23:51:29 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0011456742524089025, 'num_filters_1': 39, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.013637696633193652, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 22, 'num_filters_3': 32, 'num_filters_4': 20, 'num_filters_5': 113}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:52:03 DISPATCHER: Starting worker discovery
23:52:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:52:03 DISPATCHER: Finished worker discovery
23:53:03 DISPATCHER: Starting worker discovery
23:53:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:53:03 DISPATCHER: Finished worker discovery
23:54:03 DISPATCHER: Starting worker discovery
23:54:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:54:03 DISPATCHER: Finished worker discovery
23:54:50 WORKER: done with job (8, 0, 20), trying to register it.
23:54:51 WORKER: registered result for job (8, 0, 20) with dispatcher
23:54:51 DISPATCHER: job (8, 0, 20) finished
23:54:51 DISPATCHER: register_result: lock acquired
23:54:51 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
23:54:51 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0011456742524089025, 'num_filters_1': 39, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.013637696633193652, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 22, 'num_filters_3': 32, 'num_filters_4': 20, 'num_filters_5': 113}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5749039929067944, 'info': {'sick_no_sick': 0.5749039929067944, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0011456742524089025, 'num_filters_1': 39, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.013637696633193652, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 22, 'num_filters_3': 32, 'num_filters_4': 20, 'num_filters_5': 113}"}}
exception: None

23:54:51 job_callback for (8, 0, 20) started
23:54:51 job_callback for (8, 0, 20) got condition
23:54:51 DISPATCHER: Trying to submit another job.
23:54:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:54:51 done building a new model for budget 133.333333 based on 17/35 split
Best loss for this budget:-0.645118





23:54:51 HBMASTER: Trying to run another job!
23:54:51 job_callback for (8, 0, 20) finished
23:54:51 HBMASTER: schedule new run for iteration 8
23:54:51 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
23:54:51 HBMASTER: submitting job (8, 0, 22) to dispatcher
23:54:51 DISPATCHER: trying to submit job (8, 0, 22)
23:54:51 DISPATCHER: trying to notify the job_runner thread.
23:54:51 HBMASTER: job (8, 0, 22) submitted to dispatcher
23:54:51 DISPATCHER: Trying to submit another job.
23:54:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:54:51 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:54:51 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:54:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:54:51 WORKER: start processing job (8, 0, 22)
23:54:51 WORKER: args: ()
23:54:51 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0022798908681058066, 'num_filters_1': 97, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.014370971821847565, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 128, 'num_filters_3': 35, 'num_filters_4': 85, 'num_filters_5': 126}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:55:03 DISPATCHER: Starting worker discovery
23:55:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:55:03 DISPATCHER: Finished worker discovery
23:56:03 DISPATCHER: Starting worker discovery
23:56:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:56:03 DISPATCHER: Finished worker discovery
23:57:03 DISPATCHER: Starting worker discovery
23:57:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:57:03 DISPATCHER: Finished worker discovery
23:58:03 DISPATCHER: Starting worker discovery
23:58:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:58:03 DISPATCHER: Finished worker discovery
23:58:08 WORKER: done with job (8, 0, 22), trying to register it.
23:58:08 WORKER: registered result for job (8, 0, 22) with dispatcher
23:58:08 DISPATCHER: job (8, 0, 22) finished
23:58:08 DISPATCHER: register_result: lock acquired
23:58:08 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
23:58:08 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0022798908681058066, 'num_filters_1': 97, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.014370971821847565, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 128, 'num_filters_3': 35, 'num_filters_4': 85, 'num_filters_5': 126}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6290447003155364, 'info': {'sick_no_sick': 0.6290447003155364, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0022798908681058066, 'num_filters_1': 97, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.014370971821847565, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 128, 'num_filters_3': 35, 'num_filters_4': 85, 'num_filters_5': 126}"}}
exception: None

23:58:08 job_callback for (8, 0, 22) started
23:58:08 DISPATCHER: Trying to submit another job.
23:58:08 job_callback for (8, 0, 22) got condition
23:58:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:58:08 done building a new model for budget 133.333333 based on 17/36 split
Best loss for this budget:-0.645118





23:58:08 HBMASTER: Trying to run another job!
23:58:08 job_callback for (8, 0, 22) finished
23:58:08 HBMASTER: schedule new run for iteration 8
23:58:08 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
23:58:08 HBMASTER: submitting job (8, 0, 24) to dispatcher
23:58:08 DISPATCHER: trying to submit job (8, 0, 24)
23:58:08 DISPATCHER: trying to notify the job_runner thread.
23:58:08 HBMASTER: job (8, 0, 24) submitted to dispatcher
23:58:08 DISPATCHER: Trying to submit another job.
23:58:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:58:08 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:58:08 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:58:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:58:08 WORKER: start processing job (8, 0, 24)
23:58:08 WORKER: args: ()
23:58:08 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.006813785215507625, 'num_filters_1': 56, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.019560560584926775, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 40, 'num_filters_3': 125}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:59:03 DISPATCHER: Starting worker discovery
23:59:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:59:03 DISPATCHER: Finished worker discovery
00:00:03 DISPATCHER: Starting worker discovery
00:00:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:00:03 DISPATCHER: Finished worker discovery
00:01:03 DISPATCHER: Starting worker discovery
00:01:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:01:03 DISPATCHER: Finished worker discovery
00:01:27 WORKER: done with job (8, 0, 24), trying to register it.
00:01:27 WORKER: registered result for job (8, 0, 24) with dispatcher
00:01:27 DISPATCHER: job (8, 0, 24) finished
00:01:27 DISPATCHER: register_result: lock acquired
00:01:27 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
00:01:27 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.006813785215507625, 'num_filters_1': 56, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.019560560584926775, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 40, 'num_filters_3': 125}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.596255426279913, 'info': {'sick_no_sick': 0.596255426279913, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.006813785215507625, 'num_filters_1': 56, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.019560560584926775, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 40, 'num_filters_3': 125}"}}
exception: None

00:01:27 job_callback for (8, 0, 24) started
00:01:27 DISPATCHER: Trying to submit another job.
00:01:27 job_callback for (8, 0, 24) got condition
00:01:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:01:27 done building a new model for budget 133.333333 based on 17/37 split
Best loss for this budget:-0.645118





00:01:27 HBMASTER: Trying to run another job!
00:01:27 job_callback for (8, 0, 24) finished
00:01:27 HBMASTER: schedule new run for iteration 8
00:01:27 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
00:01:27 HBMASTER: submitting job (8, 0, 26) to dispatcher
00:01:27 DISPATCHER: trying to submit job (8, 0, 26)
00:01:27 DISPATCHER: trying to notify the job_runner thread.
00:01:27 HBMASTER: job (8, 0, 26) submitted to dispatcher
00:01:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:01:27 DISPATCHER: Trying to submit another job.
00:01:27 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:01:27 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:01:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:01:27 WORKER: start processing job (8, 0, 26)
00:01:27 WORKER: args: ()
00:01:27 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.00552729247087112, 'num_filters_1': 48, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.01875580158152464, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 31, 'num_filters_3': 18, 'num_filters_4': 60, 'num_filters_5': 88}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:02:03 DISPATCHER: Starting worker discovery
00:02:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:02:03 DISPATCHER: Finished worker discovery
00:03:03 DISPATCHER: Starting worker discovery
00:03:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:03:03 DISPATCHER: Finished worker discovery
00:04:03 DISPATCHER: Starting worker discovery
00:04:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:04:03 DISPATCHER: Finished worker discovery
00:04:48 WORKER: done with job (8, 0, 26), trying to register it.
00:04:48 WORKER: registered result for job (8, 0, 26) with dispatcher
00:04:48 DISPATCHER: job (8, 0, 26) finished
00:04:48 DISPATCHER: register_result: lock acquired
00:04:48 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
00:04:48 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.00552729247087112, 'num_filters_1': 48, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.01875580158152464, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 31, 'num_filters_3': 18, 'num_filters_4': 60, 'num_filters_5': 88}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6372305103124777, 'info': {'sick_no_sick': 0.6372305103124777, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.00552729247087112, 'num_filters_1': 48, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.01875580158152464, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 31, 'num_filters_3': 18, 'num_filters_4': 60, 'num_filters_5': 88}"}}
exception: None

00:04:48 job_callback for (8, 0, 26) started
00:04:48 DISPATCHER: Trying to submit another job.
00:04:48 job_callback for (8, 0, 26) got condition
00:04:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:04:48 done building a new model for budget 133.333333 based on 17/38 split
Best loss for this budget:-0.645118





00:04:48 HBMASTER: Trying to run another job!
00:04:48 job_callback for (8, 0, 26) finished
00:04:48 ITERATION: Advancing config (8, 0, 9) to next budget 400.000000
00:04:48 ITERATION: Advancing config (8, 0, 22) to next budget 400.000000
00:04:48 ITERATION: Advancing config (8, 0, 26) to next budget 400.000000
00:04:48 HBMASTER: schedule new run for iteration 8
00:04:48 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
00:04:48 HBMASTER: submitting job (8, 0, 9) to dispatcher
00:04:48 DISPATCHER: trying to submit job (8, 0, 9)
00:04:48 DISPATCHER: trying to notify the job_runner thread.
00:04:48 HBMASTER: job (8, 0, 9) submitted to dispatcher
00:04:48 DISPATCHER: Trying to submit another job.
00:04:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:04:48 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:04:48 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:04:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:04:48 WORKER: start processing job (8, 0, 9)
00:04:48 WORKER: args: ()
00:04:48 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.020083343570790484, 'num_filters_1': 36, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.015328924906064313, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 70, 'num_filters_3': 78, 'num_filters_4': 31}, 'budget': 400.0, 'working_directory': '.'}
00:05:03 DISPATCHER: Starting worker discovery
00:05:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:05:03 DISPATCHER: Finished worker discovery
00:06:03 DISPATCHER: Starting worker discovery
00:06:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:06:03 DISPATCHER: Finished worker discovery
00:07:03 DISPATCHER: Starting worker discovery
00:07:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:07:03 DISPATCHER: Finished worker discovery
00:08:03 DISPATCHER: Starting worker discovery
00:08:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:08:03 DISPATCHER: Finished worker discovery
00:09:03 DISPATCHER: Starting worker discovery
00:09:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:09:03 DISPATCHER: Finished worker discovery
00:10:03 DISPATCHER: Starting worker discovery
00:10:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:10:03 DISPATCHER: Finished worker discovery
00:11:03 DISPATCHER: Starting worker discovery
00:11:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:11:03 DISPATCHER: Finished worker discovery
00:12:03 DISPATCHER: Starting worker discovery
00:12:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:12:03 DISPATCHER: Finished worker discovery
00:12:40 WORKER: done with job (8, 0, 9), trying to register it.
00:12:40 WORKER: registered result for job (8, 0, 9) with dispatcher
00:12:40 DISPATCHER: job (8, 0, 9) finished
00:12:40 DISPATCHER: register_result: lock acquired
00:12:40 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
00:12:40 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.020083343570790484, 'num_filters_1': 36, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.015328924906064313, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 70, 'num_filters_3': 78, 'num_filters_4': 31}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6207397653296174, 'info': {'sick_no_sick': 0.6207397653296174, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.020083343570790484, 'num_filters_1': 36, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.015328924906064313, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 70, 'num_filters_3': 78, 'num_filters_4': 31}"}}
exception: None

00:12:40 job_callback for (8, 0, 9) started
00:12:40 DISPATCHER: Trying to submit another job.
00:12:40 job_callback for (8, 0, 9) got condition
00:12:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:12:40 HBMASTER: Trying to run another job!
00:12:40 job_callback for (8, 0, 9) finished
00:12:40 HBMASTER: schedule new run for iteration 8
00:12:40 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
00:12:40 HBMASTER: submitting job (8, 0, 22) to dispatcher
00:12:40 DISPATCHER: trying to submit job (8, 0, 22)
00:12:40 DISPATCHER: trying to notify the job_runner thread.
00:12:40 HBMASTER: job (8, 0, 22) submitted to dispatcher
00:12:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:12:40 DISPATCHER: Trying to submit another job.
00:12:40 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:12:40 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:12:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:12:40 WORKER: start processing job (8, 0, 22)
00:12:40 WORKER: args: ()
00:12:40 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0022798908681058066, 'num_filters_1': 97, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.014370971821847565, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 128, 'num_filters_3': 35, 'num_filters_4': 85, 'num_filters_5': 126}, 'budget': 400.0, 'working_directory': '.'}
00:13:03 DISPATCHER: Starting worker discovery
00:13:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:13:03 DISPATCHER: Finished worker discovery
00:14:03 DISPATCHER: Starting worker discovery
00:14:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:14:03 DISPATCHER: Finished worker discovery
00:15:03 DISPATCHER: Starting worker discovery
00:15:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:15:03 DISPATCHER: Finished worker discovery
00:16:03 DISPATCHER: Starting worker discovery
00:16:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:16:03 DISPATCHER: Finished worker discovery
00:17:03 DISPATCHER: Starting worker discovery
00:17:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:17:03 DISPATCHER: Finished worker discovery
00:18:03 DISPATCHER: Starting worker discovery
00:18:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:18:03 DISPATCHER: Finished worker discovery
00:19:03 DISPATCHER: Starting worker discovery
00:19:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:19:03 DISPATCHER: Finished worker discovery
00:20:03 DISPATCHER: Starting worker discovery
00:20:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:20:03 DISPATCHER: Finished worker discovery
00:20:25 WORKER: done with job (8, 0, 22), trying to register it.
00:20:25 WORKER: registered result for job (8, 0, 22) with dispatcher
00:20:25 DISPATCHER: job (8, 0, 22) finished
00:20:25 DISPATCHER: register_result: lock acquired
00:20:25 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
00:20:25 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0022798908681058066, 'num_filters_1': 97, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.014370971821847565, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 128, 'num_filters_3': 35, 'num_filters_4': 85, 'num_filters_5': 126}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5460939024656006, 'info': {'sick_no_sick': 0.5460939024656006, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0022798908681058066, 'num_filters_1': 97, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.014370971821847565, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 128, 'num_filters_3': 35, 'num_filters_4': 85, 'num_filters_5': 126}"}}
exception: None

00:20:25 job_callback for (8, 0, 22) started
00:20:25 DISPATCHER: Trying to submit another job.
00:20:25 job_callback for (8, 0, 22) got condition
00:20:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:20:25 HBMASTER: Trying to run another job!
00:20:25 job_callback for (8, 0, 22) finished
00:20:25 HBMASTER: schedule new run for iteration 8
00:20:25 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
00:20:25 HBMASTER: submitting job (8, 0, 26) to dispatcher
00:20:25 DISPATCHER: trying to submit job (8, 0, 26)
00:20:25 DISPATCHER: trying to notify the job_runner thread.
00:20:25 HBMASTER: job (8, 0, 26) submitted to dispatcher
00:20:25 DISPATCHER: Trying to submit another job.
00:20:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:20:25 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:20:25 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:20:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:20:25 WORKER: start processing job (8, 0, 26)
00:20:25 WORKER: args: ()
00:20:25 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.00552729247087112, 'num_filters_1': 48, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.01875580158152464, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 31, 'num_filters_3': 18, 'num_filters_4': 60, 'num_filters_5': 88}, 'budget': 400.0, 'working_directory': '.'}
00:21:03 DISPATCHER: Starting worker discovery
00:21:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:21:03 DISPATCHER: Finished worker discovery
00:22:03 DISPATCHER: Starting worker discovery
00:22:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:22:03 DISPATCHER: Finished worker discovery
00:23:03 DISPATCHER: Starting worker discovery
00:23:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:23:03 DISPATCHER: Finished worker discovery
00:24:03 DISPATCHER: Starting worker discovery
00:24:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:24:03 DISPATCHER: Finished worker discovery
00:25:03 DISPATCHER: Starting worker discovery
00:25:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:25:03 DISPATCHER: Finished worker discovery
00:26:03 DISPATCHER: Starting worker discovery
00:26:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:26:03 DISPATCHER: Finished worker discovery
00:27:03 DISPATCHER: Starting worker discovery
00:27:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:27:03 DISPATCHER: Finished worker discovery
00:28:03 DISPATCHER: Starting worker discovery
00:28:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:28:03 DISPATCHER: Finished worker discovery
00:28:16 WORKER: done with job (8, 0, 26), trying to register it.
00:28:16 WORKER: registered result for job (8, 0, 26) with dispatcher
00:28:16 DISPATCHER: job (8, 0, 26) finished
00:28:16 DISPATCHER: register_result: lock acquired
00:28:16 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
00:28:16 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.00552729247087112, 'num_filters_1': 48, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.01875580158152464, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 31, 'num_filters_3': 18, 'num_filters_4': 60, 'num_filters_5': 88}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6139603330543354, 'info': {'sick_no_sick': 0.6139603330543354, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.00552729247087112, 'num_filters_1': 48, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.01875580158152464, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 31, 'num_filters_3': 18, 'num_filters_4': 60, 'num_filters_5': 88}"}}
exception: None

00:28:16 job_callback for (8, 0, 26) started
00:28:16 DISPATCHER: Trying to submit another job.
00:28:16 job_callback for (8, 0, 26) got condition
00:28:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:28:16 HBMASTER: Trying to run another job!
00:28:16 job_callback for (8, 0, 26) finished
00:28:16 ITERATION: Advancing config (8, 0, 9) to next budget 1200.000000
00:28:16 HBMASTER: schedule new run for iteration 8
00:28:16 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
00:28:16 HBMASTER: submitting job (8, 0, 9) to dispatcher
00:28:16 DISPATCHER: trying to submit job (8, 0, 9)
00:28:16 DISPATCHER: trying to notify the job_runner thread.
00:28:16 HBMASTER: job (8, 0, 9) submitted to dispatcher
00:28:16 DISPATCHER: Trying to submit another job.
00:28:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:28:16 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:28:16 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:28:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:28:16 WORKER: start processing job (8, 0, 9)
00:28:16 WORKER: args: ()
00:28:16 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.020083343570790484, 'num_filters_1': 36, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.015328924906064313, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 70, 'num_filters_3': 78, 'num_filters_4': 31}, 'budget': 1200.0, 'working_directory': '.'}
00:29:03 DISPATCHER: Starting worker discovery
00:29:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:29:03 DISPATCHER: Finished worker discovery
00:30:03 DISPATCHER: Starting worker discovery
00:30:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:30:03 DISPATCHER: Finished worker discovery
00:31:03 DISPATCHER: Starting worker discovery
00:31:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:31:03 DISPATCHER: Finished worker discovery
00:32:03 DISPATCHER: Starting worker discovery
00:32:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:32:03 DISPATCHER: Finished worker discovery
00:33:03 DISPATCHER: Starting worker discovery
00:33:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:33:03 DISPATCHER: Finished worker discovery
00:34:03 DISPATCHER: Starting worker discovery
00:34:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:34:03 DISPATCHER: Finished worker discovery
00:35:03 DISPATCHER: Starting worker discovery
00:35:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:35:03 DISPATCHER: Finished worker discovery
00:36:03 DISPATCHER: Starting worker discovery
00:36:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:36:03 DISPATCHER: Finished worker discovery
00:37:03 DISPATCHER: Starting worker discovery
00:37:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:37:03 DISPATCHER: Finished worker discovery
00:38:03 DISPATCHER: Starting worker discovery
00:38:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:38:03 DISPATCHER: Finished worker discovery
00:39:03 DISPATCHER: Starting worker discovery
00:39:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:39:03 DISPATCHER: Finished worker discovery
00:40:03 DISPATCHER: Starting worker discovery
00:40:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:40:03 DISPATCHER: Finished worker discovery
00:41:03 DISPATCHER: Starting worker discovery
00:41:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:41:03 DISPATCHER: Finished worker discovery
00:42:03 DISPATCHER: Starting worker discovery
00:42:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:42:03 DISPATCHER: Finished worker discovery
00:43:03 DISPATCHER: Starting worker discovery
00:43:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:43:03 DISPATCHER: Finished worker discovery
00:44:03 DISPATCHER: Starting worker discovery
00:44:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:44:03 DISPATCHER: Finished worker discovery
00:45:03 DISPATCHER: Starting worker discovery
00:45:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:45:03 DISPATCHER: Finished worker discovery
00:46:03 DISPATCHER: Starting worker discovery
00:46:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:46:03 DISPATCHER: Finished worker discovery
00:47:03 DISPATCHER: Starting worker discovery
00:47:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:47:03 DISPATCHER: Finished worker discovery
00:48:03 DISPATCHER: Starting worker discovery
00:48:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:48:03 DISPATCHER: Finished worker discovery
00:49:03 DISPATCHER: Starting worker discovery
00:49:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:49:03 DISPATCHER: Finished worker discovery
00:49:43 WORKER: done with job (8, 0, 9), trying to register it.
00:49:43 WORKER: registered result for job (8, 0, 9) with dispatcher
00:49:43 DISPATCHER: job (8, 0, 9) finished
00:49:43 DISPATCHER: register_result: lock acquired
00:49:43 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
00:49:43 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.020083343570790484, 'num_filters_1': 36, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.015328924906064313, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 70, 'num_filters_3': 78, 'num_filters_4': 31}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.626562602871733, 'info': {'sick_no_sick': 0.626562602871733, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.020083343570790484, 'num_filters_1': 36, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.015328924906064313, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 70, 'num_filters_3': 78, 'num_filters_4': 31}"}}
exception: None

00:49:43 job_callback for (8, 0, 9) started
00:49:43 DISPATCHER: Trying to submit another job.
00:49:43 job_callback for (8, 0, 9) got condition
00:49:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:49:43 HBMASTER: Trying to run another job!
00:49:43 job_callback for (8, 0, 9) finished
00:49:43 start sampling a new configuration.
00:49:43 best_vector: [3, 1, 0.420705985375391, 0.41487092210612725, 0.7144672311188436, 1, 0.27207208647111314, 0.1510935555869361, 0, 1, 1, 2, 0.8665796225554065, 0.4894082496039931, 0.8901842459642819, 0.4525618464252013], 0.0142694000422562, 0.0018826014512942097, 2.686359322864918e-05
00:49:43 done sampling a new configuration.
00:49:43 HBMASTER: schedule new run for iteration 9
00:49:43 HBMASTER: trying submitting job (9, 0, 0) to dispatcher
00:49:43 HBMASTER: submitting job (9, 0, 0) to dispatcher
00:49:43 DISPATCHER: trying to submit job (9, 0, 0)
00:49:43 DISPATCHER: trying to notify the job_runner thread.
00:49:43 HBMASTER: job (9, 0, 0) submitted to dispatcher
00:49:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:49:43 DISPATCHER: Trying to submit another job.
00:49:43 DISPATCHER: starting job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:49:43 DISPATCHER: job (9, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:49:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:49:43 WORKER: start processing job (9, 0, 0)
00:49:43 WORKER: args: ()
00:49:43 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.006940839002318496, 'num_filters_1': 37, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.01572451459569609, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 97, 'num_filters_3': 44, 'num_filters_4': 102}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:50:03 DISPATCHER: Starting worker discovery
00:50:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:50:03 DISPATCHER: Finished worker discovery
00:51:03 DISPATCHER: Starting worker discovery
00:51:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:51:03 DISPATCHER: Finished worker discovery
00:52:03 DISPATCHER: Starting worker discovery
00:52:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:52:03 DISPATCHER: Finished worker discovery
00:53:03 WORKER: done with job (9, 0, 0), trying to register it.
00:53:03 WORKER: registered result for job (9, 0, 0) with dispatcher
00:53:03 DISPATCHER: job (9, 0, 0) finished
00:53:03 DISPATCHER: register_result: lock acquired
00:53:03 DISPATCHER: job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
00:53:03 job_id: (9, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.006940839002318496, 'num_filters_1': 37, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.01572451459569609, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 97, 'num_filters_3': 44, 'num_filters_4': 102}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.598315859852722, 'info': {'sick_no_sick': 0.598315859852722, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.006940839002318496, 'num_filters_1': 37, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.01572451459569609, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 97, 'num_filters_3': 44, 'num_filters_4': 102}"}}
exception: None

00:53:03 job_callback for (9, 0, 0) started
00:53:03 DISPATCHER: Trying to submit another job.
00:53:03 job_callback for (9, 0, 0) got condition
00:53:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:53:03 done building a new model for budget 133.333333 based on 17/39 split
Best loss for this budget:-0.645118





00:53:03 HBMASTER: Trying to run another job!
00:53:03 job_callback for (9, 0, 0) finished
00:53:03 start sampling a new configuration.
00:53:03 best_vector: [3, 2, 0.8965294575225331, 0.25647765075763773, 0.8509500962917703, 1, 0.2788641765409534, 0.17819002271315965, 2, 2, 1, 1, 0.012295886727999583, 0.13171022046168204, 0.6940828421181633, 0.20537405117957355], 0.0034199450574506885, 0.0017158580046860907, 5.868140102413396e-06
00:53:03 done sampling a new configuration.
00:53:03 HBMASTER: schedule new run for iteration 9
00:53:03 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
00:53:03 HBMASTER: submitting job (9, 0, 1) to dispatcher
00:53:03 DISPATCHER: trying to submit job (9, 0, 1)
00:53:03 DISPATCHER: trying to notify the job_runner thread.
00:53:03 HBMASTER: job (9, 0, 1) submitted to dispatcher
00:53:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:53:03 DISPATCHER: Trying to submit another job.
00:53:03 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:53:03 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:53:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:53:03 WORKER: start processing job (9, 0, 1)
00:53:03 WORKER: args: ()
00:53:03 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.06209532651144829, 'num_filters_1': 27, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.01705416908342585, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 16, 'num_filters_3': 20, 'num_filters_4': 67, 'num_filters_5': 24}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:53:03 DISPATCHER: Starting worker discovery
00:53:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:53:03 DISPATCHER: Finished worker discovery
00:54:03 DISPATCHER: Starting worker discovery
00:54:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:54:03 DISPATCHER: Finished worker discovery
Exception in thread Thread-381:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

00:55:03 DISPATCHER: Starting worker discovery
00:55:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:55:03 DISPATCHER: Finished worker discovery
00:56:03 DISPATCHER: Starting worker discovery
00:56:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:56:03 DISPATCHER: Finished worker discovery
00:56:17 WORKER: done with job (9, 0, 1), trying to register it.
00:56:17 WORKER: registered result for job (9, 0, 1) with dispatcher
00:56:17 DISPATCHER: job (9, 0, 1) finished
00:56:17 DISPATCHER: register_result: lock acquired
00:56:17 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
00:56:17 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.06209532651144829, 'num_filters_1': 27, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.01705416908342585, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 16, 'num_filters_3': 20, 'num_filters_4': 67, 'num_filters_5': 24}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.27727747593228963, 'info': {'sick_no_sick': 0.27727747593228963, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.06209532651144829, 'num_filters_1': 27, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.01705416908342585, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 16, 'num_filters_3': 20, 'num_filters_4': 67, 'num_filters_5': 24}"}}
exception: None

00:56:17 job_callback for (9, 0, 1) started
00:56:17 job_callback for (9, 0, 1) got condition
00:56:17 DISPATCHER: Trying to submit another job.
00:56:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:56:17 done building a new model for budget 133.333333 based on 17/39 split
Best loss for this budget:-0.645118





00:56:17 HBMASTER: Trying to run another job!
00:56:17 job_callback for (9, 0, 1) finished
00:56:17 start sampling a new configuration.
00:56:17 done sampling a new configuration.
00:56:17 HBMASTER: schedule new run for iteration 9
00:56:17 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
00:56:17 HBMASTER: submitting job (9, 0, 2) to dispatcher
00:56:17 DISPATCHER: trying to submit job (9, 0, 2)
00:56:17 DISPATCHER: trying to notify the job_runner thread.
00:56:17 HBMASTER: job (9, 0, 2) submitted to dispatcher
00:56:17 DISPATCHER: Trying to submit another job.
00:56:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:56:17 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:56:17 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:56:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:56:17 WORKER: start processing job (9, 0, 2)
00:56:17 WORKER: args: ()
00:56:17 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.07077044763627693, 'num_filters_1': 36, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.0503627528657991, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 40, 'num_filters_3': 22}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:57:03 DISPATCHER: Starting worker discovery
00:57:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:57:03 DISPATCHER: Finished worker discovery
00:58:03 DISPATCHER: Starting worker discovery
00:58:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:58:03 DISPATCHER: Finished worker discovery
00:59:03 DISPATCHER: Starting worker discovery
00:59:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:59:03 DISPATCHER: Finished worker discovery
00:59:35 WORKER: done with job (9, 0, 2), trying to register it.
00:59:35 WORKER: registered result for job (9, 0, 2) with dispatcher
00:59:35 DISPATCHER: job (9, 0, 2) finished
00:59:35 DISPATCHER: register_result: lock acquired
00:59:35 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
00:59:35 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.07077044763627693, 'num_filters_1': 36, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.0503627528657991, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 40, 'num_filters_3': 22}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': 0.0001846580623964297, 'info': {'sick_no_sick': -0.0001846580623964297, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.07077044763627693, 'num_filters_1': 36, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.0503627528657991, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 40, 'num_filters_3': 22}"}}
exception: None

00:59:35 job_callback for (9, 0, 2) started
00:59:35 job_callback for (9, 0, 2) got condition
00:59:35 DISPATCHER: Trying to submit another job.
00:59:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:59:35 done building a new model for budget 133.333333 based on 17/40 split
Best loss for this budget:-0.645118





00:59:35 HBMASTER: Trying to run another job!
00:59:35 job_callback for (9, 0, 2) finished
00:59:35 start sampling a new configuration.
00:59:35 best_vector: [1, 1, 0.687965193627712, 0.6033178300357487, 0.842146655366333, 1, 0.12771716102159347, 0.06074251853403325, 0, 0, 0, 2, 0.7765184825718879, 0.5391250416534153, 0.8657872653546143, 0.19743439033892257], 0.0029354384830544253, 0.0019240657689448821, 5.647976702088511e-06
00:59:35 done sampling a new configuration.
00:59:35 HBMASTER: schedule new run for iteration 9
00:59:35 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
00:59:35 HBMASTER: submitting job (9, 0, 3) to dispatcher
00:59:35 DISPATCHER: trying to submit job (9, 0, 3)
00:59:35 DISPATCHER: trying to notify the job_runner thread.
00:59:35 HBMASTER: job (9, 0, 3) submitted to dispatcher
00:59:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:59:35 DISPATCHER: Trying to submit another job.
00:59:35 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:59:35 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:59:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:59:35 WORKER: start processing job (9, 0, 3)
00:59:35 WORKER: args: ()
00:59:35 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.023764593351673483, 'num_filters_1': 56, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.011995761944820712, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 80, 'num_filters_3': 48, 'num_filters_4': 97, 'num_filters_5': 24}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:00:03 DISPATCHER: Starting worker discovery
01:00:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:00:03 DISPATCHER: Finished worker discovery
01:01:03 DISPATCHER: Starting worker discovery
01:01:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:01:03 DISPATCHER: Finished worker discovery
01:02:03 DISPATCHER: Starting worker discovery
01:02:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:02:03 DISPATCHER: Finished worker discovery
01:02:58 WORKER: done with job (9, 0, 3), trying to register it.
01:02:58 WORKER: registered result for job (9, 0, 3) with dispatcher
01:02:58 DISPATCHER: job (9, 0, 3) finished
01:02:58 DISPATCHER: register_result: lock acquired
01:02:58 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:02:58 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.023764593351673483, 'num_filters_1': 56, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.011995761944820712, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 80, 'num_filters_3': 48, 'num_filters_4': 97, 'num_filters_5': 24}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6273250054140944, 'info': {'sick_no_sick': 0.6273250054140944, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.023764593351673483, 'num_filters_1': 56, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.011995761944820712, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 80, 'num_filters_3': 48, 'num_filters_4': 97, 'num_filters_5': 24}"}}
exception: None

01:02:58 job_callback for (9, 0, 3) started
01:02:58 DISPATCHER: Trying to submit another job.
01:02:58 job_callback for (9, 0, 3) got condition
01:02:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:02:58 done building a new model for budget 133.333333 based on 17/41 split
Best loss for this budget:-0.645118





01:02:58 HBMASTER: Trying to run another job!
01:02:58 job_callback for (9, 0, 3) finished
01:02:58 start sampling a new configuration.
01:02:58 best_vector: [3, 2, 0.904705457009223, 0.1153922180898328, 0.8684860951948385, 1, 0.11818639759481764, 0.13768591514399536, 0, 0, 1, 0, 0.6837229519154919, 0.45610654532304784, 0.6838509320878349, 0.5456689828540816], 0.007257979248439158, 0.0008501291131373372, 6.170219461644778e-06
01:02:58 done sampling a new configuration.
01:02:58 HBMASTER: schedule new run for iteration 9
01:02:58 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
01:02:58 HBMASTER: submitting job (9, 0, 4) to dispatcher
01:02:58 DISPATCHER: trying to submit job (9, 0, 4)
01:02:58 DISPATCHER: trying to notify the job_runner thread.
01:02:58 HBMASTER: job (9, 0, 4) submitted to dispatcher
01:02:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:02:58 DISPATCHER: Trying to submit another job.
01:02:58 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:02:58 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:02:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:02:58 WORKER: start processing job (9, 0, 4)
01:02:58 WORKER: args: ()
01:02:58 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.06447790440318323, 'num_filters_1': 20, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.015105444361892881, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 66, 'num_filters_3': 41, 'num_filters_4': 66, 'num_filters_5': 49}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:03:03 DISPATCHER: Starting worker discovery
01:03:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:03:03 DISPATCHER: Finished worker discovery
01:04:03 DISPATCHER: Starting worker discovery
01:04:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:04:03 DISPATCHER: Finished worker discovery
01:05:03 DISPATCHER: Starting worker discovery
01:05:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:05:03 DISPATCHER: Finished worker discovery
01:06:03 DISPATCHER: Starting worker discovery
01:06:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:06:03 DISPATCHER: Finished worker discovery
01:06:20 WORKER: done with job (9, 0, 4), trying to register it.
01:06:20 WORKER: registered result for job (9, 0, 4) with dispatcher
01:06:20 DISPATCHER: job (9, 0, 4) finished
01:06:20 DISPATCHER: register_result: lock acquired
01:06:20 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:06:20 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.06447790440318323, 'num_filters_1': 20, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.015105444361892881, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 66, 'num_filters_3': 41, 'num_filters_4': 66, 'num_filters_5': 49}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.09029327724118666, 'info': {'sick_no_sick': 0.09029327724118666, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.06447790440318323, 'num_filters_1': 20, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.015105444361892881, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 66, 'num_filters_3': 41, 'num_filters_4': 66, 'num_filters_5': 49}"}}
exception: None

01:06:20 job_callback for (9, 0, 4) started
01:06:20 DISPATCHER: Trying to submit another job.
01:06:20 job_callback for (9, 0, 4) got condition
01:06:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:06:20 done building a new model for budget 133.333333 based on 17/42 split
Best loss for this budget:-0.645118





01:06:20 HBMASTER: Trying to run another job!
01:06:20 job_callback for (9, 0, 4) finished
01:06:20 start sampling a new configuration.
01:06:20 done sampling a new configuration.
01:06:20 HBMASTER: schedule new run for iteration 9
01:06:20 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
01:06:20 HBMASTER: submitting job (9, 0, 5) to dispatcher
01:06:20 DISPATCHER: trying to submit job (9, 0, 5)
01:06:20 DISPATCHER: trying to notify the job_runner thread.
01:06:20 HBMASTER: job (9, 0, 5) submitted to dispatcher
01:06:20 DISPATCHER: Trying to submit another job.
01:06:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:06:20 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:06:20 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:06:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:06:20 WORKER: start processing job (9, 0, 5)
01:06:20 WORKER: args: ()
01:06:20 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.03758447908375863, 'num_filters_1': 32, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.02230086996133172, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 53, 'num_filters_3': 21, 'num_filters_4': 18, 'num_filters_5': 19}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:07:03 DISPATCHER: Starting worker discovery
01:07:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:07:03 DISPATCHER: Finished worker discovery
01:08:03 DISPATCHER: Starting worker discovery
01:08:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:08:03 DISPATCHER: Finished worker discovery
01:09:03 DISPATCHER: Starting worker discovery
01:09:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:09:03 DISPATCHER: Finished worker discovery
01:09:36 WORKER: done with job (9, 0, 5), trying to register it.
01:09:36 WORKER: registered result for job (9, 0, 5) with dispatcher
01:09:36 DISPATCHER: job (9, 0, 5) finished
01:09:36 DISPATCHER: register_result: lock acquired
01:09:36 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:09:36 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.03758447908375863, 'num_filters_1': 32, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.02230086996133172, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 53, 'num_filters_3': 21, 'num_filters_4': 18, 'num_filters_5': 19}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.03758447908375863, 'num_filters_1': 32, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.02230086996133172, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 53, 'num_filters_3': 21, 'num_filters_4': 18, 'num_filters_5': 19}"}}
exception: None

01:09:36 job_callback for (9, 0, 5) started
01:09:36 job_callback for (9, 0, 5) got condition
01:09:36 DISPATCHER: Trying to submit another job.
01:09:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:09:36 done building a new model for budget 133.333333 based on 17/43 split
Best loss for this budget:-0.645118





01:09:36 HBMASTER: Trying to run another job!
01:09:36 job_callback for (9, 0, 5) finished
01:09:36 start sampling a new configuration.
01:09:36 best_vector: [0, 2, 0.8018170523784769, 0.4805980793519412, 0.8794437431990629, 1, 0.33131047816260945, 0.12562092497204438, 0, 2, 2, 0, 0.8125077189164699, 0.5351694306186285, 0.9259775409275782, 0.17521974471680718], 0.0034377625049640723, 0.014099459929065666, 4.847059468438535e-05
01:09:36 done sampling a new configuration.
01:09:36 HBMASTER: schedule new run for iteration 9
01:09:36 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
01:09:36 HBMASTER: submitting job (9, 0, 6) to dispatcher
01:09:36 DISPATCHER: trying to submit job (9, 0, 6)
01:09:36 DISPATCHER: trying to notify the job_runner thread.
01:09:36 HBMASTER: job (9, 0, 6) submitted to dispatcher
01:09:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:09:36 DISPATCHER: Trying to submit another job.
01:09:36 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:09:36 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:09:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:09:36 WORKER: start processing job (9, 0, 6)
01:09:36 WORKER: args: ()
01:09:36 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.04014524426675188, 'num_filters_1': 43, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.01456922973300975, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 86, 'num_filters_3': 48, 'num_filters_4': 110, 'num_filters_5': 22}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:10:03 DISPATCHER: Starting worker discovery
01:10:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:10:03 DISPATCHER: Finished worker discovery
01:11:03 DISPATCHER: Starting worker discovery
01:11:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:11:03 DISPATCHER: Finished worker discovery
01:12:03 DISPATCHER: Starting worker discovery
01:12:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:12:03 DISPATCHER: Finished worker discovery
01:12:55 WORKER: done with job (9, 0, 6), trying to register it.
01:12:55 WORKER: registered result for job (9, 0, 6) with dispatcher
01:12:55 DISPATCHER: job (9, 0, 6) finished
01:12:55 DISPATCHER: register_result: lock acquired
01:12:55 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:12:55 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.04014524426675188, 'num_filters_1': 43, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.01456922973300975, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 86, 'num_filters_3': 48, 'num_filters_4': 110, 'num_filters_5': 22}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6254829511051552, 'info': {'sick_no_sick': 0.6254829511051552, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.04014524426675188, 'num_filters_1': 43, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.01456922973300975, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 86, 'num_filters_3': 48, 'num_filters_4': 110, 'num_filters_5': 22}"}}
exception: None

01:12:55 job_callback for (9, 0, 6) started
01:12:55 DISPATCHER: Trying to submit another job.
01:12:55 job_callback for (9, 0, 6) got condition
01:12:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:12:55 done building a new model for budget 133.333333 based on 17/44 split
Best loss for this budget:-0.645118





01:12:55 HBMASTER: Trying to run another job!
01:12:55 job_callback for (9, 0, 6) finished
01:12:55 start sampling a new configuration.
01:12:55 done sampling a new configuration.
01:12:55 HBMASTER: schedule new run for iteration 9
01:12:55 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
01:12:55 HBMASTER: submitting job (9, 0, 7) to dispatcher
01:12:55 DISPATCHER: trying to submit job (9, 0, 7)
01:12:55 DISPATCHER: trying to notify the job_runner thread.
01:12:55 HBMASTER: job (9, 0, 7) submitted to dispatcher
01:12:55 DISPATCHER: Trying to submit another job.
01:12:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:12:55 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:12:55 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:12:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:12:55 WORKER: start processing job (9, 0, 7)
01:12:55 WORKER: args: ()
01:12:55 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0031319882892617058, 'num_filters_1': 83, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.01353306513791656, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 26, 'num_filters_3': 24, 'num_filters_4': 27}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:13:03 DISPATCHER: Starting worker discovery
01:13:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:13:03 DISPATCHER: Finished worker discovery
01:14:03 DISPATCHER: Starting worker discovery
01:14:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:14:03 DISPATCHER: Finished worker discovery
01:15:03 DISPATCHER: Starting worker discovery
01:15:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:15:03 DISPATCHER: Finished worker discovery
01:16:03 DISPATCHER: Starting worker discovery
01:16:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:16:03 DISPATCHER: Finished worker discovery
01:16:13 WORKER: done with job (9, 0, 7), trying to register it.
01:16:13 WORKER: registered result for job (9, 0, 7) with dispatcher
01:16:13 DISPATCHER: job (9, 0, 7) finished
01:16:13 DISPATCHER: register_result: lock acquired
01:16:13 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:16:13 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0031319882892617058, 'num_filters_1': 83, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.01353306513791656, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 26, 'num_filters_3': 24, 'num_filters_4': 27}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5278770157375992, 'info': {'sick_no_sick': 0.5278770157375992, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0031319882892617058, 'num_filters_1': 83, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.01353306513791656, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 26, 'num_filters_3': 24, 'num_filters_4': 27}"}}
exception: None

01:16:13 job_callback for (9, 0, 7) started
01:16:13 job_callback for (9, 0, 7) got condition
01:16:13 DISPATCHER: Trying to submit another job.
01:16:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:16:13 done building a new model for budget 133.333333 based on 17/45 split
Best loss for this budget:-0.645118





01:16:13 HBMASTER: Trying to run another job!
01:16:13 job_callback for (9, 0, 7) finished
01:16:13 start sampling a new configuration.
01:16:13 done sampling a new configuration.
01:16:13 HBMASTER: schedule new run for iteration 9
01:16:13 HBMASTER: trying submitting job (9, 0, 8) to dispatcher
01:16:13 HBMASTER: submitting job (9, 0, 8) to dispatcher
01:16:13 DISPATCHER: trying to submit job (9, 0, 8)
01:16:13 DISPATCHER: trying to notify the job_runner thread.
01:16:13 HBMASTER: job (9, 0, 8) submitted to dispatcher
01:16:13 DISPATCHER: Trying to submit another job.
01:16:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:16:13 DISPATCHER: starting job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:16:13 DISPATCHER: job (9, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:16:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:16:13 WORKER: start processing job (9, 0, 8)
01:16:13 WORKER: args: ()
01:16:13 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0018625582240361662, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.16468203224585565, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 103, 'num_filters_3': 46, 'num_filters_4': 49, 'num_filters_5': 48}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:17:03 DISPATCHER: Starting worker discovery
01:17:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:17:03 DISPATCHER: Finished worker discovery
01:18:03 DISPATCHER: Starting worker discovery
01:18:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:18:03 DISPATCHER: Finished worker discovery
01:19:03 DISPATCHER: Starting worker discovery
01:19:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:19:03 DISPATCHER: Finished worker discovery
01:19:30 WORKER: done with job (9, 0, 8), trying to register it.
01:19:30 WORKER: registered result for job (9, 0, 8) with dispatcher
01:19:30 DISPATCHER: job (9, 0, 8) finished
01:19:30 DISPATCHER: register_result: lock acquired
01:19:30 DISPATCHER: job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:19:30 job_id: (9, 0, 8)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0018625582240361662, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.16468203224585565, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 103, 'num_filters_3': 46, 'num_filters_4': 49, 'num_filters_5': 48}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.05898378444441699, 'info': {'sick_no_sick': 0.05898378444441699, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0018625582240361662, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.16468203224585565, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 103, 'num_filters_3': 46, 'num_filters_4': 49, 'num_filters_5': 48}"}}
exception: None

01:19:30 job_callback for (9, 0, 8) started
01:19:30 DISPATCHER: Trying to submit another job.
01:19:30 job_callback for (9, 0, 8) got condition
01:19:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:19:30 done building a new model for budget 133.333333 based on 17/45 split
Best loss for this budget:-0.645118





01:19:30 HBMASTER: Trying to run another job!
01:19:30 job_callback for (9, 0, 8) finished
01:19:30 ITERATION: Advancing config (9, 0, 0) to next budget 400.000000
01:19:30 ITERATION: Advancing config (9, 0, 3) to next budget 400.000000
01:19:30 ITERATION: Advancing config (9, 0, 6) to next budget 400.000000
01:19:30 HBMASTER: schedule new run for iteration 9
01:19:30 HBMASTER: trying submitting job (9, 0, 0) to dispatcher
01:19:30 HBMASTER: submitting job (9, 0, 0) to dispatcher
01:19:30 DISPATCHER: trying to submit job (9, 0, 0)
01:19:30 DISPATCHER: trying to notify the job_runner thread.
01:19:30 HBMASTER: job (9, 0, 0) submitted to dispatcher
01:19:30 DISPATCHER: Trying to submit another job.
01:19:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:19:30 DISPATCHER: starting job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:19:30 DISPATCHER: job (9, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:19:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:19:30 WORKER: start processing job (9, 0, 0)
01:19:30 WORKER: args: ()
01:19:30 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.006940839002318496, 'num_filters_1': 37, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.01572451459569609, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 97, 'num_filters_3': 44, 'num_filters_4': 102}, 'budget': 400.0, 'working_directory': '.'}
01:20:03 DISPATCHER: Starting worker discovery
01:20:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:20:03 DISPATCHER: Finished worker discovery
01:21:03 DISPATCHER: Starting worker discovery
01:21:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:21:03 DISPATCHER: Finished worker discovery
01:22:03 DISPATCHER: Starting worker discovery
01:22:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:22:03 DISPATCHER: Finished worker discovery
01:23:03 DISPATCHER: Starting worker discovery
01:23:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:23:03 DISPATCHER: Finished worker discovery
01:24:03 DISPATCHER: Starting worker discovery
01:24:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:24:03 DISPATCHER: Finished worker discovery
01:25:03 DISPATCHER: Starting worker discovery
01:25:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:25:03 DISPATCHER: Finished worker discovery
01:26:03 DISPATCHER: Starting worker discovery
01:26:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:26:03 DISPATCHER: Finished worker discovery
01:27:03 DISPATCHER: Starting worker discovery
01:27:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:27:03 DISPATCHER: Finished worker discovery
01:27:20 WORKER: done with job (9, 0, 0), trying to register it.
01:27:20 WORKER: registered result for job (9, 0, 0) with dispatcher
01:27:20 DISPATCHER: job (9, 0, 0) finished
01:27:20 DISPATCHER: register_result: lock acquired
01:27:20 DISPATCHER: job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:27:20 job_id: (9, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.006940839002318496, 'num_filters_1': 37, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.01572451459569609, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 97, 'num_filters_3': 44, 'num_filters_4': 102}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5876925602541214, 'info': {'sick_no_sick': 0.5876925602541214, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.006940839002318496, 'num_filters_1': 37, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.01572451459569609, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 97, 'num_filters_3': 44, 'num_filters_4': 102}"}}
exception: None

01:27:20 job_callback for (9, 0, 0) started
01:27:20 DISPATCHER: Trying to submit another job.
01:27:20 job_callback for (9, 0, 0) got condition
01:27:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:27:20 HBMASTER: Trying to run another job!
01:27:20 job_callback for (9, 0, 0) finished
01:27:20 HBMASTER: schedule new run for iteration 9
01:27:20 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
01:27:20 HBMASTER: submitting job (9, 0, 3) to dispatcher
01:27:20 DISPATCHER: trying to submit job (9, 0, 3)
01:27:20 DISPATCHER: trying to notify the job_runner thread.
01:27:20 HBMASTER: job (9, 0, 3) submitted to dispatcher
01:27:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:27:20 DISPATCHER: Trying to submit another job.
01:27:20 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:27:20 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:27:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:27:20 WORKER: start processing job (9, 0, 3)
01:27:20 WORKER: args: ()
01:27:20 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.023764593351673483, 'num_filters_1': 56, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.011995761944820712, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 80, 'num_filters_3': 48, 'num_filters_4': 97, 'num_filters_5': 24}, 'budget': 400.0, 'working_directory': '.'}
01:28:03 DISPATCHER: Starting worker discovery
01:28:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:28:03 DISPATCHER: Finished worker discovery
01:29:03 DISPATCHER: Starting worker discovery
01:29:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:29:03 DISPATCHER: Finished worker discovery
01:30:03 DISPATCHER: Starting worker discovery
01:30:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:30:03 DISPATCHER: Finished worker discovery
01:31:03 DISPATCHER: Starting worker discovery
01:31:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:31:03 DISPATCHER: Finished worker discovery
01:32:03 DISPATCHER: Starting worker discovery
01:32:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:32:03 DISPATCHER: Finished worker discovery
01:33:03 DISPATCHER: Starting worker discovery
01:33:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:33:03 DISPATCHER: Finished worker discovery
01:34:03 DISPATCHER: Starting worker discovery
01:34:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:34:03 DISPATCHER: Finished worker discovery
01:35:03 DISPATCHER: Starting worker discovery
01:35:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:35:03 DISPATCHER: Finished worker discovery
01:35:22 WORKER: done with job (9, 0, 3), trying to register it.
01:35:22 WORKER: registered result for job (9, 0, 3) with dispatcher
01:35:22 DISPATCHER: job (9, 0, 3) finished
01:35:22 DISPATCHER: register_result: lock acquired
01:35:22 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:35:22 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.023764593351673483, 'num_filters_1': 56, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.011995761944820712, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 80, 'num_filters_3': 48, 'num_filters_4': 97, 'num_filters_5': 24}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6553786318191721, 'info': {'sick_no_sick': 0.6553786318191721, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.023764593351673483, 'num_filters_1': 56, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.011995761944820712, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 80, 'num_filters_3': 48, 'num_filters_4': 97, 'num_filters_5': 24}"}}
exception: None

01:35:22 job_callback for (9, 0, 3) started
01:35:22 job_callback for (9, 0, 3) got condition
01:35:22 DISPATCHER: Trying to submit another job.
01:35:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:35:22 HBMASTER: Trying to run another job!
01:35:22 job_callback for (9, 0, 3) finished
01:35:22 HBMASTER: schedule new run for iteration 9
01:35:22 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
01:35:22 HBMASTER: submitting job (9, 0, 6) to dispatcher
01:35:22 DISPATCHER: trying to submit job (9, 0, 6)
01:35:22 DISPATCHER: trying to notify the job_runner thread.
01:35:22 HBMASTER: job (9, 0, 6) submitted to dispatcher
01:35:22 DISPATCHER: Trying to submit another job.
01:35:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:35:22 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:35:22 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:35:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:35:22 WORKER: start processing job (9, 0, 6)
01:35:22 WORKER: args: ()
01:35:22 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.04014524426675188, 'num_filters_1': 43, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.01456922973300975, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 86, 'num_filters_3': 48, 'num_filters_4': 110, 'num_filters_5': 22}, 'budget': 400.0, 'working_directory': '.'}
01:36:03 DISPATCHER: Starting worker discovery
01:36:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:36:03 DISPATCHER: Finished worker discovery
01:37:03 DISPATCHER: Starting worker discovery
01:37:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:37:03 DISPATCHER: Finished worker discovery
01:38:03 DISPATCHER: Starting worker discovery
01:38:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:38:03 DISPATCHER: Finished worker discovery
01:39:03 DISPATCHER: Starting worker discovery
01:39:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:39:03 DISPATCHER: Finished worker discovery
01:40:03 DISPATCHER: Starting worker discovery
01:40:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:40:03 DISPATCHER: Finished worker discovery
01:41:03 DISPATCHER: Starting worker discovery
01:41:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:41:03 DISPATCHER: Finished worker discovery
01:42:03 DISPATCHER: Starting worker discovery
01:42:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:42:03 DISPATCHER: Finished worker discovery
01:43:03 DISPATCHER: Starting worker discovery
01:43:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:43:03 DISPATCHER: Finished worker discovery
01:43:18 WORKER: done with job (9, 0, 6), trying to register it.
01:43:18 WORKER: registered result for job (9, 0, 6) with dispatcher
01:43:18 DISPATCHER: job (9, 0, 6) finished
01:43:18 DISPATCHER: register_result: lock acquired
01:43:18 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:43:18 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.04014524426675188, 'num_filters_1': 43, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.01456922973300975, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 86, 'num_filters_3': 48, 'num_filters_4': 110, 'num_filters_5': 22}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.430639658341043, 'info': {'sick_no_sick': 0.430639658341043, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.04014524426675188, 'num_filters_1': 43, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.01456922973300975, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 86, 'num_filters_3': 48, 'num_filters_4': 110, 'num_filters_5': 22}"}}
exception: None

01:43:18 job_callback for (9, 0, 6) started
01:43:18 DISPATCHER: Trying to submit another job.
01:43:18 job_callback for (9, 0, 6) got condition
01:43:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:43:18 HBMASTER: Trying to run another job!
01:43:18 job_callback for (9, 0, 6) finished
01:43:18 ITERATION: Advancing config (9, 0, 3) to next budget 1200.000000
01:43:18 HBMASTER: schedule new run for iteration 9
01:43:18 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
01:43:18 HBMASTER: submitting job (9, 0, 3) to dispatcher
01:43:18 DISPATCHER: trying to submit job (9, 0, 3)
01:43:18 DISPATCHER: trying to notify the job_runner thread.
01:43:18 HBMASTER: job (9, 0, 3) submitted to dispatcher
01:43:18 DISPATCHER: Trying to submit another job.
01:43:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:43:18 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:43:18 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:43:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:43:18 WORKER: start processing job (9, 0, 3)
01:43:18 WORKER: args: ()
01:43:18 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.023764593351673483, 'num_filters_1': 56, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.011995761944820712, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 80, 'num_filters_3': 48, 'num_filters_4': 97, 'num_filters_5': 24}, 'budget': 1200.0, 'working_directory': '.'}
01:44:03 DISPATCHER: Starting worker discovery
01:44:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:44:03 DISPATCHER: Finished worker discovery
01:45:03 DISPATCHER: Starting worker discovery
01:45:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:45:03 DISPATCHER: Finished worker discovery
01:46:03 DISPATCHER: Starting worker discovery
01:46:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:46:03 DISPATCHER: Finished worker discovery
01:47:03 DISPATCHER: Starting worker discovery
01:47:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:47:03 DISPATCHER: Finished worker discovery
01:48:03 DISPATCHER: Starting worker discovery
01:48:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:48:03 DISPATCHER: Finished worker discovery
01:49:03 DISPATCHER: Starting worker discovery
01:49:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:49:03 DISPATCHER: Finished worker discovery
01:50:03 DISPATCHER: Starting worker discovery
01:50:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:50:03 DISPATCHER: Finished worker discovery
01:51:03 DISPATCHER: Starting worker discovery
01:51:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:51:03 DISPATCHER: Finished worker discovery
01:52:03 DISPATCHER: Starting worker discovery
01:52:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:52:03 DISPATCHER: Finished worker discovery
01:53:03 DISPATCHER: Starting worker discovery
01:53:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:53:03 DISPATCHER: Finished worker discovery
01:54:03 DISPATCHER: Starting worker discovery
01:54:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:54:03 DISPATCHER: Finished worker discovery
01:55:03 DISPATCHER: Starting worker discovery
01:55:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:55:03 DISPATCHER: Finished worker discovery
01:56:03 DISPATCHER: Starting worker discovery
01:56:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:56:03 DISPATCHER: Finished worker discovery
01:57:03 DISPATCHER: Starting worker discovery
01:57:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:57:04 DISPATCHER: Finished worker discovery
01:58:04 DISPATCHER: Starting worker discovery
01:58:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:58:04 DISPATCHER: Finished worker discovery
01:59:04 DISPATCHER: Starting worker discovery
01:59:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:59:04 DISPATCHER: Finished worker discovery
02:00:04 DISPATCHER: Starting worker discovery
02:00:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:00:04 DISPATCHER: Finished worker discovery
02:01:04 DISPATCHER: Starting worker discovery
02:01:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:01:04 DISPATCHER: Finished worker discovery
02:02:04 DISPATCHER: Starting worker discovery
02:02:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:02:04 DISPATCHER: Finished worker discovery
02:03:04 DISPATCHER: Starting worker discovery
02:03:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:03:04 DISPATCHER: Finished worker discovery
02:04:04 DISPATCHER: Starting worker discovery
02:04:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:04:04 DISPATCHER: Finished worker discovery
02:05:04 DISPATCHER: Starting worker discovery
02:05:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:05:04 DISPATCHER: Finished worker discovery
02:05:19 WORKER: done with job (9, 0, 3), trying to register it.
02:05:19 WORKER: registered result for job (9, 0, 3) with dispatcher
02:05:19 DISPATCHER: job (9, 0, 3) finished
02:05:19 DISPATCHER: register_result: lock acquired
02:05:19 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:05:19 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.023764593351673483, 'num_filters_1': 56, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.011995761944820712, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 80, 'num_filters_3': 48, 'num_filters_4': 97, 'num_filters_5': 24}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.6402300482212646, 'info': {'sick_no_sick': 0.6402300482212646, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.023764593351673483, 'num_filters_1': 56, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.011995761944820712, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 80, 'num_filters_3': 48, 'num_filters_4': 97, 'num_filters_5': 24}"}}
exception: None

02:05:19 job_callback for (9, 0, 3) started
02:05:19 job_callback for (9, 0, 3) got condition
02:05:19 DISPATCHER: Trying to submit another job.
02:05:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:05:19 HBMASTER: Trying to run another job!
02:05:19 job_callback for (9, 0, 3) finished
02:05:19 HBMASTER: shutdown initiated, shutdown_workers = True
02:05:19 WORKER: shutting down now!
02:05:19 DISPATCHER: Dispatcher shutting down
02:05:19 DISPATCHER: discover_workers shutting down
02:05:19 DISPATCHER: Trying to submit another job.
02:05:19 DISPATCHER: 'discover_worker' thread exited
02:05:19 DISPATCHER: job_runner shutting down
02:05:19 DISPATCHER: 'job_runner' thread exited
02:05:19 DISPATCHER: shut down complete
02:05:19 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7fb46c708d68; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:31157>
02:05:19 WORKER: No dispatcher found. Waiting for one to initiate contact.
02:05:19 WORKER: start listening for jobs
02:05:19 wait_for_workers trying to get the condition
02:05:19 DISPATCHER: started the 'discover_worker' thread
02:05:19 DISPATCHER: started the 'job_runner' thread
02:05:19 DISPATCHER: Pyro daemon running on localhost:42077
02:05:19 HBMASTER: only 0 worker(s) available, waiting for at least 1.
02:05:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:05:19 DISPATCHER: Starting worker discovery
02:05:19 DISPATCHER: Found 1 potential workers, 0 currently in the pool.
02:05:19 DISPATCHER: discovered new worker, hpbandster.run_0.worker.metagpuj.30598140416580691776
02:05:19 HBMASTER: number of workers changed to 1
02:05:19 adjust_queue_size: lock accquired
02:05:19 HBMASTER: adjusted queue size to (0, 1)
02:05:19 DISPATCHER: Finished worker discovery
02:05:19 DISPATCHER: A new worker triggered discover_worker
02:05:19 DISPATCHER: Trying to submit another job.
02:05:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:05:19 Enough workers to start this run!
02:05:19 HBMASTER: starting run at 1583888719.9427116
02:05:19 start sampling a new configuration.
02:05:19 done sampling a new configuration.
02:05:19 DISPATCHER: Starting worker discovery
02:05:19 HBMASTER: schedule new run for iteration 0
02:05:19 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
02:05:19 HBMASTER: submitting job (0, 0, 0) to dispatcher
02:05:19 DISPATCHER: trying to submit job (0, 0, 0)
02:05:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:05:19 DISPATCHER: Finished worker discovery
02:05:19 DISPATCHER: trying to notify the job_runner thread.
02:05:19 HBMASTER: job (0, 0, 0) submitted to dispatcher
02:05:19 DISPATCHER: Trying to submit another job.
02:05:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:05:19 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:05:19 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:05:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:05:19 WORKER: start processing job (0, 0, 0)
02:05:19 WORKER: args: ()
02:05:19 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 32, 'last_n_outputs': 20, 'lr': 0.01724559650070543, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.026271262323894828}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:06:19 DISPATCHER: Starting worker discovery
02:06:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:06:19 DISPATCHER: Finished worker discovery
Exception in thread Thread-406:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:07:04 WORKER: done with job (0, 0, 0), trying to register it.
02:07:04 WORKER: registered result for job (0, 0, 0) with dispatcher
02:07:04 DISPATCHER: job (0, 0, 0) finished
02:07:04 DISPATCHER: register_result: lock acquired
02:07:04 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:07:04 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 32, 'last_n_outputs': 20, 'lr': 0.01724559650070543, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.026271262323894828}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.0009870704494772656, 'info': {'sick_no_sick': -0.0009870704494772656, 'config': "{'batch_size': 16, 'hidden_dim': 32, 'last_n_outputs': 20, 'lr': 0.01724559650070543, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.026271262323894828}"}}
exception: None

02:07:04 job_callback for (0, 0, 0) started
02:07:04 DISPATCHER: Trying to submit another job.
02:07:04 job_callback for (0, 0, 0) got condition
02:07:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:07:04 Only 1 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
02:07:04 HBMASTER: Trying to run another job!
02:07:04 job_callback for (0, 0, 0) finished
02:07:04 start sampling a new configuration.
02:07:04 done sampling a new configuration.
02:07:04 HBMASTER: schedule new run for iteration 0
02:07:04 HBMASTER: trying submitting job (0, 0, 1) to dispatcher
02:07:04 HBMASTER: submitting job (0, 0, 1) to dispatcher
02:07:04 DISPATCHER: trying to submit job (0, 0, 1)
02:07:04 DISPATCHER: trying to notify the job_runner thread.
02:07:04 HBMASTER: job (0, 0, 1) submitted to dispatcher
02:07:04 DISPATCHER: Trying to submit another job.
02:07:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:07:04 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:07:04 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:07:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:07:04 WORKER: start processing job (0, 0, 1)
02:07:04 WORKER: args: ()
02:07:04 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 40, 'last_n_outputs': 4, 'lr': 0.07487088553926516, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.03303658063815241}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:07:19 DISPATCHER: Starting worker discovery
02:07:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:07:19 DISPATCHER: Finished worker discovery
Exception in thread Thread-407:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:08:19 DISPATCHER: Starting worker discovery
02:08:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:08:19 DISPATCHER: Finished worker discovery
02:08:52 WORKER: done with job (0, 0, 1), trying to register it.
02:08:52 WORKER: registered result for job (0, 0, 1) with dispatcher
02:08:52 DISPATCHER: job (0, 0, 1) finished
02:08:52 DISPATCHER: register_result: lock acquired
02:08:52 DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:08:52 job_id: (0, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 40, 'last_n_outputs': 4, 'lr': 0.07487088553926516, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.03303658063815241}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 40, 'last_n_outputs': 4, 'lr': 0.07487088553926516, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.03303658063815241}"}}
exception: None

02:08:52 job_callback for (0, 0, 1) started
02:08:52 DISPATCHER: Trying to submit another job.
02:08:52 job_callback for (0, 0, 1) got condition
02:08:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:08:52 Only 2 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
02:08:52 HBMASTER: Trying to run another job!
02:08:52 job_callback for (0, 0, 1) finished
02:08:52 start sampling a new configuration.
02:08:52 done sampling a new configuration.
02:08:52 HBMASTER: schedule new run for iteration 0
02:08:52 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
02:08:52 HBMASTER: submitting job (0, 0, 2) to dispatcher
02:08:52 DISPATCHER: trying to submit job (0, 0, 2)
02:08:52 DISPATCHER: trying to notify the job_runner thread.
02:08:52 HBMASTER: job (0, 0, 2) submitted to dispatcher
02:08:52 DISPATCHER: Trying to submit another job.
02:08:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:08:52 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:08:52 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:08:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:08:52 WORKER: start processing job (0, 0, 2)
02:08:52 WORKER: args: ()
02:08:52 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 54, 'last_n_outputs': 20, 'lr': 0.0017023446516865935, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.05118707951538481}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:09:19 DISPATCHER: Starting worker discovery
02:09:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:09:19 DISPATCHER: Finished worker discovery
Exception in thread Thread-408:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:10:19 DISPATCHER: Starting worker discovery
02:10:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:10:19 DISPATCHER: Finished worker discovery
02:10:38 WORKER: done with job (0, 0, 2), trying to register it.
02:10:38 WORKER: registered result for job (0, 0, 2) with dispatcher
02:10:38 DISPATCHER: job (0, 0, 2) finished
02:10:38 DISPATCHER: register_result: lock acquired
02:10:38 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:10:38 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 54, 'last_n_outputs': 20, 'lr': 0.0017023446516865935, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.05118707951538481}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 54, 'last_n_outputs': 20, 'lr': 0.0017023446516865935, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.05118707951538481}"}}
exception: None

02:10:38 job_callback for (0, 0, 2) started
02:10:38 job_callback for (0, 0, 2) got condition
02:10:38 DISPATCHER: Trying to submit another job.
02:10:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:10:38 Only 3 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
02:10:38 HBMASTER: Trying to run another job!
02:10:38 job_callback for (0, 0, 2) finished
02:10:38 start sampling a new configuration.
02:10:38 done sampling a new configuration.
02:10:38 HBMASTER: schedule new run for iteration 0
02:10:38 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
02:10:38 HBMASTER: submitting job (0, 0, 3) to dispatcher
02:10:38 DISPATCHER: trying to submit job (0, 0, 3)
02:10:38 DISPATCHER: trying to notify the job_runner thread.
02:10:38 HBMASTER: job (0, 0, 3) submitted to dispatcher
02:10:38 DISPATCHER: Trying to submit another job.
02:10:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:10:38 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:10:38 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:10:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:10:38 WORKER: start processing job (0, 0, 3)
02:10:38 WORKER: args: ()
02:10:38 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 42, 'last_n_outputs': 44, 'lr': 0.011844108747859704, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.04954518270413494}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:11:19 DISPATCHER: Starting worker discovery
02:11:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:11:19 DISPATCHER: Finished worker discovery
Exception in thread Thread-409:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:12:19 DISPATCHER: Starting worker discovery
02:12:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:12:19 DISPATCHER: Finished worker discovery
02:12:27 WORKER: done with job (0, 0, 3), trying to register it.
02:12:27 WORKER: registered result for job (0, 0, 3) with dispatcher
02:12:27 DISPATCHER: job (0, 0, 3) finished
02:12:27 DISPATCHER: register_result: lock acquired
02:12:27 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:12:27 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 42, 'last_n_outputs': 44, 'lr': 0.011844108747859704, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.04954518270413494}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.014136996537976542, 'info': {'sick_no_sick': 0.014136996537976542, 'config': "{'batch_size': 128, 'hidden_dim': 42, 'last_n_outputs': 44, 'lr': 0.011844108747859704, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.04954518270413494}"}}
exception: None

02:12:27 job_callback for (0, 0, 3) started
02:12:27 DISPATCHER: Trying to submit another job.
02:12:27 job_callback for (0, 0, 3) got condition
02:12:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:12:27 Only 4 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
02:12:27 HBMASTER: Trying to run another job!
02:12:27 job_callback for (0, 0, 3) finished
02:12:27 start sampling a new configuration.
02:12:27 done sampling a new configuration.
02:12:27 HBMASTER: schedule new run for iteration 0
02:12:27 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
02:12:27 HBMASTER: submitting job (0, 0, 4) to dispatcher
02:12:27 DISPATCHER: trying to submit job (0, 0, 4)
02:12:27 DISPATCHER: trying to notify the job_runner thread.
02:12:27 HBMASTER: job (0, 0, 4) submitted to dispatcher
02:12:27 DISPATCHER: Trying to submit another job.
02:12:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:12:27 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:12:27 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:12:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:12:27 WORKER: start processing job (0, 0, 4)
02:12:27 WORKER: args: ()
02:12:27 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 81, 'last_n_outputs': 7, 'lr': 0.0010055823303069147, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.07242844705004603}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:13:19 DISPATCHER: Starting worker discovery
02:13:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:13:19 DISPATCHER: Finished worker discovery
Exception in thread Thread-410:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:14:13 WORKER: done with job (0, 0, 4), trying to register it.
02:14:13 WORKER: registered result for job (0, 0, 4) with dispatcher
02:14:13 DISPATCHER: job (0, 0, 4) finished
02:14:13 DISPATCHER: register_result: lock acquired
02:14:13 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:14:13 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 81, 'last_n_outputs': 7, 'lr': 0.0010055823303069147, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.07242844705004603}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.03389534472261461, 'info': {'sick_no_sick': -0.03389534472261461, 'config': "{'batch_size': 64, 'hidden_dim': 81, 'last_n_outputs': 7, 'lr': 0.0010055823303069147, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.07242844705004603}"}}
exception: None

02:14:13 job_callback for (0, 0, 4) started
02:14:13 DISPATCHER: Trying to submit another job.
02:14:13 job_callback for (0, 0, 4) got condition
02:14:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:14:13 Only 5 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
02:14:13 HBMASTER: Trying to run another job!
02:14:13 job_callback for (0, 0, 4) finished
02:14:13 start sampling a new configuration.
02:14:13 done sampling a new configuration.
02:14:13 HBMASTER: schedule new run for iteration 0
02:14:13 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
02:14:13 HBMASTER: submitting job (0, 0, 5) to dispatcher
02:14:13 DISPATCHER: trying to submit job (0, 0, 5)
02:14:13 DISPATCHER: trying to notify the job_runner thread.
02:14:13 HBMASTER: job (0, 0, 5) submitted to dispatcher
02:14:13 DISPATCHER: Trying to submit another job.
02:14:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:14:13 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:14:13 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:14:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:14:13 WORKER: start processing job (0, 0, 5)
02:14:13 WORKER: args: ()
02:14:13 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 46, 'last_n_outputs': 21, 'lr': 0.046394216990087216, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.025998303202951965}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:14:19 DISPATCHER: Starting worker discovery
02:14:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:14:19 DISPATCHER: Finished worker discovery
Exception in thread Thread-411:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:15:19 DISPATCHER: Starting worker discovery
02:15:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:15:20 DISPATCHER: Finished worker discovery
02:15:59 WORKER: done with job (0, 0, 5), trying to register it.
02:15:59 WORKER: registered result for job (0, 0, 5) with dispatcher
02:15:59 DISPATCHER: job (0, 0, 5) finished
02:15:59 DISPATCHER: register_result: lock acquired
02:15:59 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:15:59 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 46, 'last_n_outputs': 21, 'lr': 0.046394216990087216, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.025998303202951965}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 46, 'last_n_outputs': 21, 'lr': 0.046394216990087216, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.025998303202951965}"}}
exception: None

02:15:59 job_callback for (0, 0, 5) started
02:15:59 DISPATCHER: Trying to submit another job.
02:15:59 job_callback for (0, 0, 5) got condition
02:15:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:15:59 Only 6 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
02:15:59 HBMASTER: Trying to run another job!
02:15:59 job_callback for (0, 0, 5) finished
02:15:59 start sampling a new configuration.
02:15:59 done sampling a new configuration.
02:15:59 HBMASTER: schedule new run for iteration 0
02:15:59 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
02:15:59 HBMASTER: submitting job (0, 0, 6) to dispatcher
02:15:59 DISPATCHER: trying to submit job (0, 0, 6)
02:15:59 DISPATCHER: trying to notify the job_runner thread.
02:15:59 HBMASTER: job (0, 0, 6) submitted to dispatcher
02:15:59 DISPATCHER: Trying to submit another job.
02:15:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:15:59 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:15:59 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:15:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:15:59 WORKER: start processing job (0, 0, 6)
02:15:59 WORKER: args: ()
02:15:59 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 51, 'last_n_outputs': 22, 'lr': 0.07624975771967074, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.024822749370024193}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:16:20 DISPATCHER: Starting worker discovery
02:16:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:16:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-412:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

02:17:20 DISPATCHER: Starting worker discovery
02:17:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:17:20 DISPATCHER: Finished worker discovery
02:17:43 WORKER: done with job (0, 0, 6), trying to register it.
02:17:43 WORKER: registered result for job (0, 0, 6) with dispatcher
02:17:44 DISPATCHER: job (0, 0, 6) finished
02:17:44 DISPATCHER: register_result: lock acquired
02:17:44 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:17:44 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 51, 'last_n_outputs': 22, 'lr': 0.07624975771967074, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.024822749370024193}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 51, 'last_n_outputs': 22, 'lr': 0.07624975771967074, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.024822749370024193}"}}
exception: None

02:17:44 job_callback for (0, 0, 6) started
02:17:44 job_callback for (0, 0, 6) got condition
02:17:44 DISPATCHER: Trying to submit another job.
02:17:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:17:44 Only 7 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
02:17:44 HBMASTER: Trying to run another job!
02:17:44 job_callback for (0, 0, 6) finished
02:17:44 start sampling a new configuration.
02:17:44 done sampling a new configuration.
02:17:44 HBMASTER: schedule new run for iteration 0
02:17:44 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
02:17:44 HBMASTER: submitting job (0, 0, 7) to dispatcher
02:17:44 DISPATCHER: trying to submit job (0, 0, 7)
02:17:44 DISPATCHER: trying to notify the job_runner thread.
02:17:44 HBMASTER: job (0, 0, 7) submitted to dispatcher
02:17:44 DISPATCHER: Trying to submit another job.
02:17:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:17:44 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:17:44 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:17:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:17:44 WORKER: start processing job (0, 0, 7)
02:17:44 WORKER: args: ()
02:17:44 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 97, 'last_n_outputs': 3, 'lr': 0.002213625651733379, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.13225046293926596}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:18:20 DISPATCHER: Starting worker discovery
02:18:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:18:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-413:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:19:20 DISPATCHER: Starting worker discovery
02:19:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:19:20 DISPATCHER: Finished worker discovery
02:19:30 WORKER: done with job (0, 0, 7), trying to register it.
02:19:30 WORKER: registered result for job (0, 0, 7) with dispatcher
02:19:30 DISPATCHER: job (0, 0, 7) finished
02:19:30 DISPATCHER: register_result: lock acquired
02:19:30 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:19:30 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 97, 'last_n_outputs': 3, 'lr': 0.002213625651733379, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.13225046293926596}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 97, 'last_n_outputs': 3, 'lr': 0.002213625651733379, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.13225046293926596}"}}
exception: None

02:19:30 job_callback for (0, 0, 7) started
02:19:30 job_callback for (0, 0, 7) got condition
02:19:30 DISPATCHER: Trying to submit another job.
02:19:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:19:30 Only 8 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
02:19:30 HBMASTER: Trying to run another job!
02:19:30 job_callback for (0, 0, 7) finished
02:19:30 start sampling a new configuration.
02:19:30 done sampling a new configuration.
02:19:30 HBMASTER: schedule new run for iteration 0
02:19:30 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
02:19:30 HBMASTER: submitting job (0, 0, 8) to dispatcher
02:19:30 DISPATCHER: trying to submit job (0, 0, 8)
02:19:30 DISPATCHER: trying to notify the job_runner thread.
02:19:30 HBMASTER: job (0, 0, 8) submitted to dispatcher
02:19:30 DISPATCHER: Trying to submit another job.
02:19:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:19:30 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:19:30 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:19:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:19:30 WORKER: start processing job (0, 0, 8)
02:19:30 WORKER: args: ()
02:19:30 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 94, 'last_n_outputs': 30, 'lr': 0.0012957247483038148, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.14473003747192065}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:20:20 DISPATCHER: Starting worker discovery
02:20:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:20:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-414:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:21:16 WORKER: done with job (0, 0, 8), trying to register it.
02:21:16 WORKER: registered result for job (0, 0, 8) with dispatcher
02:21:16 DISPATCHER: job (0, 0, 8) finished
02:21:16 DISPATCHER: register_result: lock acquired
02:21:16 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:21:16 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 94, 'last_n_outputs': 30, 'lr': 0.0012957247483038148, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.14473003747192065}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.006581819943872847, 'info': {'sick_no_sick': 0.006581819943872847, 'config': "{'batch_size': 32, 'hidden_dim': 94, 'last_n_outputs': 30, 'lr': 0.0012957247483038148, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.14473003747192065}"}}
exception: None

02:21:16 job_callback for (0, 0, 8) started
02:21:16 job_callback for (0, 0, 8) got condition
02:21:16 DISPATCHER: Trying to submit another job.
02:21:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:21:16 HBMASTER: Trying to run another job!
02:21:16 job_callback for (0, 0, 8) finished
02:21:16 start sampling a new configuration.
02:21:16 done sampling a new configuration.
02:21:16 HBMASTER: schedule new run for iteration 0
02:21:16 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
02:21:16 HBMASTER: submitting job (0, 0, 9) to dispatcher
02:21:16 DISPATCHER: trying to submit job (0, 0, 9)
02:21:16 DISPATCHER: trying to notify the job_runner thread.
02:21:16 HBMASTER: job (0, 0, 9) submitted to dispatcher
02:21:16 DISPATCHER: Trying to submit another job.
02:21:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:21:16 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:21:16 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:21:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:21:16 WORKER: start processing job (0, 0, 9)
02:21:16 WORKER: args: ()
02:21:16 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 24, 'last_n_outputs': 10, 'lr': 0.002009110084889415, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.026237932250598624}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:21:20 DISPATCHER: Starting worker discovery
02:21:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:21:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-415:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:22:20 DISPATCHER: Starting worker discovery
02:22:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:22:20 DISPATCHER: Finished worker discovery
02:23:01 WORKER: done with job (0, 0, 9), trying to register it.
02:23:01 WORKER: registered result for job (0, 0, 9) with dispatcher
02:23:01 DISPATCHER: job (0, 0, 9) finished
02:23:01 DISPATCHER: register_result: lock acquired
02:23:01 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:23:01 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 24, 'last_n_outputs': 10, 'lr': 0.002009110084889415, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.026237932250598624}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0016694901134758997, 'info': {'sick_no_sick': 0.0016694901134758997, 'config': "{'batch_size': 16, 'hidden_dim': 24, 'last_n_outputs': 10, 'lr': 0.002009110084889415, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.026237932250598624}"}}
exception: None

02:23:01 job_callback for (0, 0, 9) started
02:23:01 DISPATCHER: Trying to submit another job.
02:23:01 job_callback for (0, 0, 9) got condition
02:23:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:23:01 HBMASTER: Trying to run another job!
02:23:01 job_callback for (0, 0, 9) finished
02:23:01 start sampling a new configuration.
02:23:01 done sampling a new configuration.
02:23:01 HBMASTER: schedule new run for iteration 0
02:23:01 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
02:23:01 HBMASTER: submitting job (0, 0, 10) to dispatcher
02:23:01 DISPATCHER: trying to submit job (0, 0, 10)
02:23:01 DISPATCHER: trying to notify the job_runner thread.
02:23:01 HBMASTER: job (0, 0, 10) submitted to dispatcher
02:23:01 DISPATCHER: Trying to submit another job.
02:23:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:23:01 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:23:01 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:23:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:23:01 WORKER: start processing job (0, 0, 10)
02:23:01 WORKER: args: ()
02:23:01 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 30, 'last_n_outputs': 25, 'lr': 0.0025343640096532442, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.013803519329872976}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:23:20 DISPATCHER: Starting worker discovery
02:23:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:23:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-416:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:24:20 DISPATCHER: Starting worker discovery
02:24:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:24:20 DISPATCHER: Finished worker discovery
02:24:46 WORKER: done with job (0, 0, 10), trying to register it.
02:24:46 WORKER: registered result for job (0, 0, 10) with dispatcher
02:24:46 DISPATCHER: job (0, 0, 10) finished
02:24:46 DISPATCHER: register_result: lock acquired
02:24:46 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:24:46 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 30, 'last_n_outputs': 25, 'lr': 0.0025343640096532442, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.013803519329872976}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.015105594572167924, 'info': {'sick_no_sick': 0.015105594572167924, 'config': "{'batch_size': 16, 'hidden_dim': 30, 'last_n_outputs': 25, 'lr': 0.0025343640096532442, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.013803519329872976}"}}
exception: None

02:24:46 DISPATCHER: Trying to submit another job.
02:24:46 job_callback for (0, 0, 10) started
02:24:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:24:46 job_callback for (0, 0, 10) got condition
02:24:46 HBMASTER: Trying to run another job!
02:24:46 job_callback for (0, 0, 10) finished
02:24:46 start sampling a new configuration.
02:24:46 done sampling a new configuration.
02:24:46 HBMASTER: schedule new run for iteration 0
02:24:46 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
02:24:46 HBMASTER: submitting job (0, 0, 11) to dispatcher
02:24:46 DISPATCHER: trying to submit job (0, 0, 11)
02:24:46 DISPATCHER: trying to notify the job_runner thread.
02:24:46 HBMASTER: job (0, 0, 11) submitted to dispatcher
02:24:46 DISPATCHER: Trying to submit another job.
02:24:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:24:46 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:24:46 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:24:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:24:46 WORKER: start processing job (0, 0, 11)
02:24:46 WORKER: args: ()
02:24:46 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 74, 'last_n_outputs': 45, 'lr': 0.0038888933738948, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.061288556778535334}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:25:20 DISPATCHER: Starting worker discovery
02:25:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:25:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-417:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:26:20 DISPATCHER: Starting worker discovery
02:26:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:26:20 DISPATCHER: Finished worker discovery
02:26:32 WORKER: done with job (0, 0, 11), trying to register it.
02:26:32 WORKER: registered result for job (0, 0, 11) with dispatcher
02:26:32 DISPATCHER: job (0, 0, 11) finished
02:26:32 DISPATCHER: register_result: lock acquired
02:26:32 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:26:32 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 74, 'last_n_outputs': 45, 'lr': 0.0038888933738948, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.061288556778535334}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0015590727910244058, 'info': {'sick_no_sick': 0.0015590727910244058, 'config': "{'batch_size': 16, 'hidden_dim': 74, 'last_n_outputs': 45, 'lr': 0.0038888933738948, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.061288556778535334}"}}
exception: None

02:26:32 job_callback for (0, 0, 11) started
02:26:32 DISPATCHER: Trying to submit another job.
02:26:32 job_callback for (0, 0, 11) got condition
02:26:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:26:32 HBMASTER: Trying to run another job!
02:26:32 job_callback for (0, 0, 11) finished
02:26:32 start sampling a new configuration.
02:26:32 done sampling a new configuration.
02:26:32 HBMASTER: schedule new run for iteration 0
02:26:32 HBMASTER: trying submitting job (0, 0, 12) to dispatcher
02:26:32 HBMASTER: submitting job (0, 0, 12) to dispatcher
02:26:32 DISPATCHER: trying to submit job (0, 0, 12)
02:26:32 DISPATCHER: trying to notify the job_runner thread.
02:26:32 HBMASTER: job (0, 0, 12) submitted to dispatcher
02:26:32 DISPATCHER: Trying to submit another job.
02:26:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:26:32 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:26:32 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:26:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:26:32 WORKER: start processing job (0, 0, 12)
02:26:32 WORKER: args: ()
02:26:32 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 89, 'last_n_outputs': 48, 'lr': 0.0014073058041155712, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.015819702543516556}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:27:20 DISPATCHER: Starting worker discovery
02:27:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:27:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-418:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:28:20 DISPATCHER: Starting worker discovery
02:28:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:28:20 DISPATCHER: Finished worker discovery
02:28:20 WORKER: done with job (0, 0, 12), trying to register it.
02:28:20 WORKER: registered result for job (0, 0, 12) with dispatcher
02:28:20 DISPATCHER: job (0, 0, 12) finished
02:28:20 DISPATCHER: register_result: lock acquired
02:28:20 DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:28:20 job_id: (0, 0, 12)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 89, 'last_n_outputs': 48, 'lr': 0.0014073058041155712, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.015819702543516556}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1352074297374128, 'info': {'sick_no_sick': 0.1352074297374128, 'config': "{'batch_size': 32, 'hidden_dim': 89, 'last_n_outputs': 48, 'lr': 0.0014073058041155712, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.015819702543516556}"}}
exception: None

02:28:20 job_callback for (0, 0, 12) started
02:28:20 DISPATCHER: Trying to submit another job.
02:28:20 job_callback for (0, 0, 12) got condition
02:28:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:28:20 HBMASTER: Trying to run another job!
02:28:20 job_callback for (0, 0, 12) finished
02:28:20 start sampling a new configuration.
02:28:20 done sampling a new configuration.
02:28:20 HBMASTER: schedule new run for iteration 0
02:28:20 HBMASTER: trying submitting job (0, 0, 13) to dispatcher
02:28:20 HBMASTER: submitting job (0, 0, 13) to dispatcher
02:28:20 DISPATCHER: trying to submit job (0, 0, 13)
02:28:20 DISPATCHER: trying to notify the job_runner thread.
02:28:20 HBMASTER: job (0, 0, 13) submitted to dispatcher
02:28:20 DISPATCHER: Trying to submit another job.
02:28:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:28:20 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:28:20 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:28:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:28:20 WORKER: start processing job (0, 0, 13)
02:28:20 WORKER: args: ()
02:28:20 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 88, 'last_n_outputs': 8, 'lr': 0.001504287917424112, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.02103006418206001}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:29:20 DISPATCHER: Starting worker discovery
02:29:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:29:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-419:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:30:06 WORKER: done with job (0, 0, 13), trying to register it.
02:30:06 WORKER: registered result for job (0, 0, 13) with dispatcher
02:30:06 DISPATCHER: job (0, 0, 13) finished
02:30:06 DISPATCHER: register_result: lock acquired
02:30:06 DISPATCHER: job (0, 0, 13) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:30:06 job_id: (0, 0, 13)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 88, 'last_n_outputs': 8, 'lr': 0.001504287917424112, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.02103006418206001}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.011468526657734, 'info': {'sick_no_sick': 0.011468526657734, 'config': "{'batch_size': 128, 'hidden_dim': 88, 'last_n_outputs': 8, 'lr': 0.001504287917424112, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.02103006418206001}"}}
exception: None

02:30:06 job_callback for (0, 0, 13) started
02:30:06 DISPATCHER: Trying to submit another job.
02:30:06 job_callback for (0, 0, 13) got condition
02:30:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:30:06 HBMASTER: Trying to run another job!
02:30:06 job_callback for (0, 0, 13) finished
02:30:06 start sampling a new configuration.
02:30:06 done sampling a new configuration.
02:30:06 HBMASTER: schedule new run for iteration 0
02:30:06 HBMASTER: trying submitting job (0, 0, 14) to dispatcher
02:30:06 HBMASTER: submitting job (0, 0, 14) to dispatcher
02:30:06 DISPATCHER: trying to submit job (0, 0, 14)
02:30:06 DISPATCHER: trying to notify the job_runner thread.
02:30:06 HBMASTER: job (0, 0, 14) submitted to dispatcher
02:30:06 DISPATCHER: Trying to submit another job.
02:30:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:30:06 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:30:06 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:30:06 WORKER: start processing job (0, 0, 14)
02:30:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:30:06 WORKER: args: ()
02:30:06 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 90, 'last_n_outputs': 43, 'lr': 0.001626597859984814, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.01952933539755163}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:30:20 DISPATCHER: Starting worker discovery
02:30:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:30:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-420:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:31:20 DISPATCHER: Starting worker discovery
02:31:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:31:20 DISPATCHER: Finished worker discovery
02:31:52 WORKER: done with job (0, 0, 14), trying to register it.
02:31:52 WORKER: registered result for job (0, 0, 14) with dispatcher
02:31:52 DISPATCHER: job (0, 0, 14) finished
02:31:52 DISPATCHER: register_result: lock acquired
02:31:52 DISPATCHER: job (0, 0, 14) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:31:52 job_id: (0, 0, 14)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 90, 'last_n_outputs': 43, 'lr': 0.001626597859984814, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.01952933539755163}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.00015157688143260835, 'info': {'sick_no_sick': 0.00015157688143260835, 'config': "{'batch_size': 128, 'hidden_dim': 90, 'last_n_outputs': 43, 'lr': 0.001626597859984814, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.01952933539755163}"}}
exception: None

02:31:52 job_callback for (0, 0, 14) started
02:31:52 job_callback for (0, 0, 14) got condition
02:31:52 DISPATCHER: Trying to submit another job.
02:31:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:31:52 HBMASTER: Trying to run another job!
02:31:52 job_callback for (0, 0, 14) finished
02:31:52 start sampling a new configuration.
02:31:52 done sampling a new configuration.
02:31:52 HBMASTER: schedule new run for iteration 0
02:31:52 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
02:31:52 HBMASTER: submitting job (0, 0, 15) to dispatcher
02:31:52 DISPATCHER: trying to submit job (0, 0, 15)
02:31:52 DISPATCHER: trying to notify the job_runner thread.
02:31:52 HBMASTER: job (0, 0, 15) submitted to dispatcher
02:31:52 DISPATCHER: Trying to submit another job.
02:31:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:31:52 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:31:52 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:31:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:31:52 WORKER: start processing job (0, 0, 15)
02:31:52 WORKER: args: ()
02:31:52 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 69, 'last_n_outputs': 44, 'lr': 0.0025806442157453465, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.12318090472984858}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:32:20 DISPATCHER: Starting worker discovery
02:32:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:32:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-421:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:33:20 DISPATCHER: Starting worker discovery
02:33:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:33:20 DISPATCHER: Finished worker discovery
02:33:37 WORKER: done with job (0, 0, 15), trying to register it.
02:33:37 WORKER: registered result for job (0, 0, 15) with dispatcher
02:33:37 DISPATCHER: job (0, 0, 15) finished
02:33:37 DISPATCHER: register_result: lock acquired
02:33:37 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:33:37 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 69, 'last_n_outputs': 44, 'lr': 0.0025806442157453465, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.12318090472984858}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.36572680218957854, 'info': {'sick_no_sick': 0.36572680218957854, 'config': "{'batch_size': 128, 'hidden_dim': 69, 'last_n_outputs': 44, 'lr': 0.0025806442157453465, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.12318090472984858}"}}
exception: None

02:33:37 job_callback for (0, 0, 15) started
02:33:37 DISPATCHER: Trying to submit another job.
02:33:37 job_callback for (0, 0, 15) got condition
02:33:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:33:37 HBMASTER: Trying to run another job!
02:33:37 job_callback for (0, 0, 15) finished
02:33:37 start sampling a new configuration.
02:33:37 done sampling a new configuration.
02:33:37 HBMASTER: schedule new run for iteration 0
02:33:37 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
02:33:37 HBMASTER: submitting job (0, 0, 16) to dispatcher
02:33:37 DISPATCHER: trying to submit job (0, 0, 16)
02:33:37 DISPATCHER: trying to notify the job_runner thread.
02:33:37 HBMASTER: job (0, 0, 16) submitted to dispatcher
02:33:37 DISPATCHER: Trying to submit another job.
02:33:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:33:37 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:33:38 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:33:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:33:38 WORKER: start processing job (0, 0, 16)
02:33:38 WORKER: args: ()
02:33:38 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 79, 'last_n_outputs': 10, 'lr': 0.013698269920932137, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.023692814943441828}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:34:20 DISPATCHER: Starting worker discovery
02:34:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:34:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-422:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:35:20 DISPATCHER: Starting worker discovery
02:35:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:35:20 DISPATCHER: Finished worker discovery
02:35:25 WORKER: done with job (0, 0, 16), trying to register it.
02:35:25 WORKER: registered result for job (0, 0, 16) with dispatcher
02:35:25 DISPATCHER: job (0, 0, 16) finished
02:35:25 DISPATCHER: register_result: lock acquired
02:35:25 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:35:25 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 79, 'last_n_outputs': 10, 'lr': 0.013698269920932137, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.023692814943441828}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 79, 'last_n_outputs': 10, 'lr': 0.013698269920932137, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.023692814943441828}"}}
exception: None

02:35:25 job_callback for (0, 0, 16) started
02:35:25 job_callback for (0, 0, 16) got condition
02:35:25 DISPATCHER: Trying to submit another job.
02:35:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:35:25 HBMASTER: Trying to run another job!
02:35:25 job_callback for (0, 0, 16) finished
02:35:25 start sampling a new configuration.
02:35:25 done sampling a new configuration.
02:35:25 HBMASTER: schedule new run for iteration 0
02:35:25 HBMASTER: trying submitting job (0, 0, 17) to dispatcher
02:35:25 HBMASTER: submitting job (0, 0, 17) to dispatcher
02:35:25 DISPATCHER: trying to submit job (0, 0, 17)
02:35:25 DISPATCHER: trying to notify the job_runner thread.
02:35:25 HBMASTER: job (0, 0, 17) submitted to dispatcher
02:35:25 DISPATCHER: Trying to submit another job.
02:35:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:35:25 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:35:25 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:35:25 WORKER: start processing job (0, 0, 17)
02:35:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:35:25 WORKER: args: ()
02:35:25 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 72, 'last_n_outputs': 7, 'lr': 0.012269689309889502, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.11493655356955944}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:36:20 DISPATCHER: Starting worker discovery
02:36:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:36:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-423:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:37:10 WORKER: done with job (0, 0, 17), trying to register it.
02:37:10 WORKER: registered result for job (0, 0, 17) with dispatcher
02:37:10 DISPATCHER: job (0, 0, 17) finished
02:37:10 DISPATCHER: register_result: lock acquired
02:37:10 DISPATCHER: job (0, 0, 17) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:37:10 job_id: (0, 0, 17)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 72, 'last_n_outputs': 7, 'lr': 0.012269689309889502, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.11493655356955944}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.45268643874269343, 'info': {'sick_no_sick': 0.45268643874269343, 'config': "{'batch_size': 128, 'hidden_dim': 72, 'last_n_outputs': 7, 'lr': 0.012269689309889502, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.11493655356955944}"}}
exception: None

02:37:10 job_callback for (0, 0, 17) started
02:37:10 job_callback for (0, 0, 17) got condition
02:37:10 DISPATCHER: Trying to submit another job.
02:37:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:37:10 done building a new model for budget 44.444444 based on 9/15 split
Best loss for this budget:-0.452686





02:37:10 HBMASTER: Trying to run another job!
02:37:10 job_callback for (0, 0, 17) finished
02:37:10 start sampling a new configuration.
02:37:10 best_vector: [1, 0.39213642691570916, 0.8651952601420223, 0.023684521535771746, 0.3573158394483652, 1, 0.567741959428156, 0.9593158580510293], 0.001949827311522624, 0.060384861534537176, 0.00011774005222255253
02:37:10 done sampling a new configuration.
02:37:10 HBMASTER: schedule new run for iteration 0
02:37:10 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
02:37:10 HBMASTER: submitting job (0, 0, 18) to dispatcher
02:37:10 DISPATCHER: trying to submit job (0, 0, 18)
02:37:10 DISPATCHER: trying to notify the job_runner thread.
02:37:10 HBMASTER: job (0, 0, 18) submitted to dispatcher
02:37:10 DISPATCHER: Trying to submit another job.
02:37:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:37:10 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:37:10 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:37:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:37:10 WORKER: start processing job (0, 0, 18)
02:37:10 WORKER: args: ()
02:37:10 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 51, 'last_n_outputs': 44, 'lr': 0.0011152418112173753, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.17705113151808036}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:37:20 DISPATCHER: Starting worker discovery
02:37:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:37:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-424:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:38:20 DISPATCHER: Starting worker discovery
02:38:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:38:20 DISPATCHER: Finished worker discovery
02:38:55 WORKER: done with job (0, 0, 18), trying to register it.
02:38:55 WORKER: registered result for job (0, 0, 18) with dispatcher
02:38:55 DISPATCHER: job (0, 0, 18) finished
02:38:55 DISPATCHER: register_result: lock acquired
02:38:55 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:38:55 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 51, 'last_n_outputs': 44, 'lr': 0.0011152418112173753, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.17705113151808036}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.008234482215001086, 'info': {'sick_no_sick': 0.008234482215001086, 'config': "{'batch_size': 32, 'hidden_dim': 51, 'last_n_outputs': 44, 'lr': 0.0011152418112173753, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.17705113151808036}"}}
exception: None

02:38:55 job_callback for (0, 0, 18) started
02:38:55 job_callback for (0, 0, 18) got condition
02:38:55 DISPATCHER: Trying to submit another job.
02:38:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:38:55 done building a new model for budget 44.444444 based on 9/16 split
Best loss for this budget:-0.452686





02:38:55 HBMASTER: Trying to run another job!
02:38:55 job_callback for (0, 0, 18) finished
02:38:55 start sampling a new configuration.
02:38:55 best_vector: [0, 0.444210563012081, 0.6622420264892765, 0.366533263588544, 0.22616231249632712, 1, 0.648634957868785, 0.9684880421550879], 0.0026174986947738285, 0.33823433832606153, 0.0008853279390961556
02:38:55 done sampling a new configuration.
02:38:55 HBMASTER: schedule new run for iteration 0
02:38:55 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
02:38:55 HBMASTER: submitting job (0, 0, 19) to dispatcher
02:38:55 DISPATCHER: trying to submit job (0, 0, 19)
02:38:55 DISPATCHER: trying to notify the job_runner thread.
02:38:55 HBMASTER: job (0, 0, 19) submitted to dispatcher
02:38:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:38:55 DISPATCHER: Trying to submit another job.
02:38:55 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:38:55 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:38:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:38:55 WORKER: start processing job (0, 0, 19)
02:38:55 WORKER: args: ()
02:38:55 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 55, 'last_n_outputs': 34, 'lr': 0.005408371644635802, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.18198349159287766}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:39:20 DISPATCHER: Starting worker discovery
02:39:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:39:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-425:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:40:20 DISPATCHER: Starting worker discovery
02:40:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:40:20 DISPATCHER: Finished worker discovery
02:40:40 WORKER: done with job (0, 0, 19), trying to register it.
02:40:40 WORKER: registered result for job (0, 0, 19) with dispatcher
02:40:40 DISPATCHER: job (0, 0, 19) finished
02:40:40 DISPATCHER: register_result: lock acquired
02:40:40 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:40:40 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 55, 'last_n_outputs': 34, 'lr': 0.005408371644635802, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.18198349159287766}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 55, 'last_n_outputs': 34, 'lr': 0.005408371644635802, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.18198349159287766}"}}
exception: None

02:40:40 job_callback for (0, 0, 19) started
02:40:40 DISPATCHER: Trying to submit another job.
02:40:40 job_callback for (0, 0, 19) got condition
02:40:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:40:40 done building a new model for budget 44.444444 based on 9/17 split
Best loss for this budget:-0.452686





02:40:40 HBMASTER: Trying to run another job!
02:40:40 job_callback for (0, 0, 19) finished
02:40:40 start sampling a new configuration.
02:40:40 best_vector: [0, 0.4125301667586735, 0.8602870809119286, 0.5346090617889732, 0.034920546663948115, 0, 0.6567737865908793, 0.664455922454603], 1.1506673623239028e-32, 0.8690608882660815, -0.0027916354463756164
02:40:40 done sampling a new configuration.
02:40:40 HBMASTER: schedule new run for iteration 0
02:40:40 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
02:40:40 HBMASTER: submitting job (0, 0, 20) to dispatcher
02:40:40 DISPATCHER: trying to submit job (0, 0, 20)
02:40:40 DISPATCHER: trying to notify the job_runner thread.
02:40:40 HBMASTER: job (0, 0, 20) submitted to dispatcher
02:40:40 DISPATCHER: Trying to submit another job.
02:40:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:40:40 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:40:40 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:40:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:40:40 WORKER: start processing job (0, 0, 20)
02:40:40 WORKER: args: ()
02:40:40 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 53, 'last_n_outputs': 44, 'lr': 0.011727842463118893, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.07319427036820986}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:41:20 DISPATCHER: Starting worker discovery
02:41:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:41:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-426:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:42:20 DISPATCHER: Starting worker discovery
02:42:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:42:20 DISPATCHER: Finished worker discovery
02:42:27 WORKER: done with job (0, 0, 20), trying to register it.
02:42:27 WORKER: registered result for job (0, 0, 20) with dispatcher
02:42:27 DISPATCHER: job (0, 0, 20) finished
02:42:27 DISPATCHER: register_result: lock acquired
02:42:27 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:42:27 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 53, 'last_n_outputs': 44, 'lr': 0.011727842463118893, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.07319427036820986}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.42186365075098864, 'info': {'sick_no_sick': 0.42186365075098864, 'config': "{'batch_size': 16, 'hidden_dim': 53, 'last_n_outputs': 44, 'lr': 0.011727842463118893, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.07319427036820986}"}}
exception: None

02:42:27 job_callback for (0, 0, 20) started
02:42:27 DISPATCHER: Trying to submit another job.
02:42:27 job_callback for (0, 0, 20) got condition
02:42:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:42:27 done building a new model for budget 44.444444 based on 9/17 split
Best loss for this budget:-0.452686





02:42:27 HBMASTER: Trying to run another job!
02:42:27 job_callback for (0, 0, 20) finished
02:42:27 start sampling a new configuration.
02:42:27 best_vector: [3, 0.876426720348337, 0.9176974657874784, 0.3632755883460791, 0.06902281601069468, 1, 0.9069473081632755, 0.19148137672273352], 1.4506507540015627e-32, 0.6893457968718795, -0.03322005927919642
02:42:27 done sampling a new configuration.
02:42:27 HBMASTER: schedule new run for iteration 0
02:42:27 HBMASTER: trying submitting job (0, 0, 21) to dispatcher
02:42:27 HBMASTER: submitting job (0, 0, 21) to dispatcher
02:42:27 DISPATCHER: trying to submit job (0, 0, 21)
02:42:27 DISPATCHER: trying to notify the job_runner thread.
02:42:27 HBMASTER: job (0, 0, 21) submitted to dispatcher
02:42:27 DISPATCHER: Trying to submit another job.
02:42:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:42:27 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:42:27 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:42:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:42:27 WORKER: start processing job (0, 0, 21)
02:42:27 WORKER: args: ()
02:42:27 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 90, 'last_n_outputs': 46, 'lr': 0.005327840031921749, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.01774692094571133}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:43:20 DISPATCHER: Starting worker discovery
02:43:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:43:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-427:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:44:13 WORKER: done with job (0, 0, 21), trying to register it.
02:44:13 WORKER: registered result for job (0, 0, 21) with dispatcher
02:44:13 DISPATCHER: job (0, 0, 21) finished
02:44:13 DISPATCHER: register_result: lock acquired
02:44:13 DISPATCHER: job (0, 0, 21) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:44:13 job_id: (0, 0, 21)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 90, 'last_n_outputs': 46, 'lr': 0.005327840031921749, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.01774692094571133}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.28414752204470967, 'info': {'sick_no_sick': 0.28414752204470967, 'config': "{'batch_size': 128, 'hidden_dim': 90, 'last_n_outputs': 46, 'lr': 0.005327840031921749, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.01774692094571133}"}}
exception: None

02:44:13 job_callback for (0, 0, 21) started
02:44:13 job_callback for (0, 0, 21) got condition
02:44:13 DISPATCHER: Trying to submit another job.
02:44:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:44:13 done building a new model for budget 44.444444 based on 9/18 split
Best loss for this budget:-0.452686





02:44:13 HBMASTER: Trying to run another job!
02:44:13 job_callback for (0, 0, 21) finished
02:44:13 start sampling a new configuration.
02:44:13 done sampling a new configuration.
02:44:13 HBMASTER: schedule new run for iteration 0
02:44:13 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
02:44:13 HBMASTER: submitting job (0, 0, 22) to dispatcher
02:44:13 DISPATCHER: trying to submit job (0, 0, 22)
02:44:13 DISPATCHER: trying to notify the job_runner thread.
02:44:13 HBMASTER: job (0, 0, 22) submitted to dispatcher
02:44:13 DISPATCHER: Trying to submit another job.
02:44:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:44:13 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:44:13 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:44:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:44:13 WORKER: start processing job (0, 0, 22)
02:44:13 WORKER: args: ()
02:44:13 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 99, 'last_n_outputs': 44, 'lr': 0.034893318592644294, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.17035153624203758}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:44:20 DISPATCHER: Starting worker discovery
02:44:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:44:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-428:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:45:20 DISPATCHER: Starting worker discovery
02:45:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:45:20 DISPATCHER: Finished worker discovery
02:45:58 WORKER: done with job (0, 0, 22), trying to register it.
02:45:58 WORKER: registered result for job (0, 0, 22) with dispatcher
02:45:58 DISPATCHER: job (0, 0, 22) finished
02:45:58 DISPATCHER: register_result: lock acquired
02:45:58 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:45:58 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 99, 'last_n_outputs': 44, 'lr': 0.034893318592644294, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.17035153624203758}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 99, 'last_n_outputs': 44, 'lr': 0.034893318592644294, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.17035153624203758}"}}
exception: None

02:45:58 job_callback for (0, 0, 22) started
02:45:58 job_callback for (0, 0, 22) got condition
02:45:58 DISPATCHER: Trying to submit another job.
02:45:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:45:58 done building a new model for budget 44.444444 based on 9/19 split
Best loss for this budget:-0.452686





02:45:58 HBMASTER: Trying to run another job!
02:45:58 job_callback for (0, 0, 22) finished
02:45:58 start sampling a new configuration.
02:45:58 best_vector: [0, 0.3022631254224053, 0.9468036380153502, 0.4750184716666566, 0.07947048569962639, 0, 0.49414268257348065, 0.8728515656352818], 1.2131302758887089e-32, 0.8243137772383309, -0.00432857389309394
02:45:58 done sampling a new configuration.
02:45:58 HBMASTER: schedule new run for iteration 0
02:45:58 HBMASTER: trying submitting job (0, 0, 23) to dispatcher
02:45:58 HBMASTER: submitting job (0, 0, 23) to dispatcher
02:45:58 DISPATCHER: trying to submit job (0, 0, 23)
02:45:58 DISPATCHER: trying to notify the job_runner thread.
02:45:58 HBMASTER: job (0, 0, 23) submitted to dispatcher
02:45:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:45:58 DISPATCHER: Trying to submit another job.
02:45:58 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:45:58 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:45:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:45:58 WORKER: start processing job (0, 0, 23)
02:45:58 WORKER: args: ()
02:45:58 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 44, 'last_n_outputs': 48, 'lr': 0.00891326755769713, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.1366488775363271}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:46:20 DISPATCHER: Starting worker discovery
02:46:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:46:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-429:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:47:20 DISPATCHER: Starting worker discovery
02:47:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:47:20 DISPATCHER: Finished worker discovery
02:47:45 WORKER: done with job (0, 0, 23), trying to register it.
02:47:45 WORKER: registered result for job (0, 0, 23) with dispatcher
02:47:45 DISPATCHER: job (0, 0, 23) finished
02:47:45 DISPATCHER: register_result: lock acquired
02:47:45 DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:47:45 job_id: (0, 0, 23)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 44, 'last_n_outputs': 48, 'lr': 0.00891326755769713, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.1366488775363271}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.11645606632587668, 'info': {'sick_no_sick': 0.11645606632587668, 'config': "{'batch_size': 16, 'hidden_dim': 44, 'last_n_outputs': 48, 'lr': 0.00891326755769713, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.1366488775363271}"}}
exception: None

02:47:45 job_callback for (0, 0, 23) started
02:47:45 job_callback for (0, 0, 23) got condition
02:47:45 DISPATCHER: Trying to submit another job.
02:47:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:47:45 done building a new model for budget 44.444444 based on 9/20 split
Best loss for this budget:-0.452686





02:47:45 HBMASTER: Trying to run another job!
02:47:45 job_callback for (0, 0, 23) finished
02:47:45 start sampling a new configuration.
02:47:45 done sampling a new configuration.
02:47:45 HBMASTER: schedule new run for iteration 0
02:47:45 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
02:47:45 HBMASTER: submitting job (0, 0, 24) to dispatcher
02:47:45 DISPATCHER: trying to submit job (0, 0, 24)
02:47:45 DISPATCHER: trying to notify the job_runner thread.
02:47:45 HBMASTER: job (0, 0, 24) submitted to dispatcher
02:47:45 DISPATCHER: Trying to submit another job.
02:47:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:47:45 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:47:45 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:47:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:47:45 WORKER: start processing job (0, 0, 24)
02:47:45 WORKER: args: ()
02:47:45 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 24, 'last_n_outputs': 9, 'lr': 0.02207138796571652, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.11706084522215461}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:48:20 DISPATCHER: Starting worker discovery
02:48:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:48:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-430:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:49:20 DISPATCHER: Starting worker discovery
02:49:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:49:20 DISPATCHER: Finished worker discovery
02:49:31 WORKER: done with job (0, 0, 24), trying to register it.
02:49:31 WORKER: registered result for job (0, 0, 24) with dispatcher
02:49:31 DISPATCHER: job (0, 0, 24) finished
02:49:31 DISPATCHER: register_result: lock acquired
02:49:31 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:49:31 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 24, 'last_n_outputs': 9, 'lr': 0.02207138796571652, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.11706084522215461}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 24, 'last_n_outputs': 9, 'lr': 0.02207138796571652, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.11706084522215461}"}}
exception: None

02:49:31 job_callback for (0, 0, 24) started
02:49:31 DISPATCHER: Trying to submit another job.
02:49:31 job_callback for (0, 0, 24) got condition
02:49:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:49:31 done building a new model for budget 44.444444 based on 9/21 split
Best loss for this budget:-0.452686





02:49:31 HBMASTER: Trying to run another job!
02:49:31 job_callback for (0, 0, 24) finished
02:49:31 start sampling a new configuration.
02:49:31 done sampling a new configuration.
02:49:31 HBMASTER: schedule new run for iteration 0
02:49:31 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
02:49:31 HBMASTER: submitting job (0, 0, 25) to dispatcher
02:49:31 DISPATCHER: trying to submit job (0, 0, 25)
02:49:31 DISPATCHER: trying to notify the job_runner thread.
02:49:31 HBMASTER: job (0, 0, 25) submitted to dispatcher
02:49:31 DISPATCHER: Trying to submit another job.
02:49:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:49:31 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:49:31 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:49:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:49:31 WORKER: start processing job (0, 0, 25)
02:49:31 WORKER: args: ()
02:49:31 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 68, 'last_n_outputs': 6, 'lr': 0.052965998490779834, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.0113598808040426}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:50:20 DISPATCHER: Starting worker discovery
02:50:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:50:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-431:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:51:20 DISPATCHER: Starting worker discovery
02:51:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:51:20 DISPATCHER: Finished worker discovery
02:51:21 WORKER: done with job (0, 0, 25), trying to register it.
02:51:21 WORKER: registered result for job (0, 0, 25) with dispatcher
02:51:21 DISPATCHER: job (0, 0, 25) finished
02:51:21 DISPATCHER: register_result: lock acquired
02:51:21 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:51:21 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 68, 'last_n_outputs': 6, 'lr': 0.052965998490779834, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.0113598808040426}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 68, 'last_n_outputs': 6, 'lr': 0.052965998490779834, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.0113598808040426}"}}
exception: None

02:51:21 job_callback for (0, 0, 25) started
02:51:21 DISPATCHER: Trying to submit another job.
02:51:21 job_callback for (0, 0, 25) got condition
02:51:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:51:21 done building a new model for budget 44.444444 based on 9/22 split
Best loss for this budget:-0.452686





02:51:21 HBMASTER: Trying to run another job!
02:51:21 job_callback for (0, 0, 25) finished
02:51:21 start sampling a new configuration.
02:51:21 best_vector: [0, 0.18850408318182824, 0.7811701547810733, 0.6424549368478181, 0.02343277558790062, 0, 0.9453956317522134, 0.6077815712148161], 0.0034585496988346065, 0.14479605922849625, 0.0005007843670371536
02:51:21 done sampling a new configuration.
02:51:21 HBMASTER: schedule new run for iteration 0
02:51:21 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
02:51:21 HBMASTER: submitting job (0, 0, 26) to dispatcher
02:51:21 DISPATCHER: trying to submit job (0, 0, 26)
02:51:21 DISPATCHER: trying to notify the job_runner thread.
02:51:21 HBMASTER: job (0, 0, 26) submitted to dispatcher
02:51:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:51:21 DISPATCHER: Trying to submit another job.
02:51:21 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:51:21 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:51:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:51:21 WORKER: start processing job (0, 0, 26)
02:51:21 WORKER: args: ()
02:51:21 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 35, 'last_n_outputs': 40, 'lr': 0.019271249480062116, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.06176494442170675}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:52:20 DISPATCHER: Starting worker discovery
02:52:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:52:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-432:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:53:06 WORKER: done with job (0, 0, 26), trying to register it.
02:53:06 WORKER: registered result for job (0, 0, 26) with dispatcher
02:53:06 DISPATCHER: job (0, 0, 26) finished
02:53:06 DISPATCHER: register_result: lock acquired
02:53:06 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:53:06 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 35, 'last_n_outputs': 40, 'lr': 0.019271249480062116, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.06176494442170675}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.31777175449675976, 'info': {'sick_no_sick': 0.31777175449675976, 'config': "{'batch_size': 16, 'hidden_dim': 35, 'last_n_outputs': 40, 'lr': 0.019271249480062116, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.06176494442170675}"}}
exception: None

02:53:06 job_callback for (0, 0, 26) started
02:53:06 DISPATCHER: Trying to submit another job.
02:53:06 job_callback for (0, 0, 26) got condition
02:53:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:53:06 done building a new model for budget 44.444444 based on 9/22 split
Best loss for this budget:-0.452686





02:53:06 HBMASTER: Trying to run another job!
02:53:06 job_callback for (0, 0, 26) finished
02:53:06 ITERATION: Advancing config (0, 0, 3) to next budget 133.333333
02:53:06 ITERATION: Advancing config (0, 0, 10) to next budget 133.333333
02:53:06 ITERATION: Advancing config (0, 0, 12) to next budget 133.333333
02:53:06 ITERATION: Advancing config (0, 0, 15) to next budget 133.333333
02:53:06 ITERATION: Advancing config (0, 0, 17) to next budget 133.333333
02:53:06 ITERATION: Advancing config (0, 0, 20) to next budget 133.333333
02:53:06 ITERATION: Advancing config (0, 0, 21) to next budget 133.333333
02:53:06 ITERATION: Advancing config (0, 0, 23) to next budget 133.333333
02:53:06 ITERATION: Advancing config (0, 0, 26) to next budget 133.333333
02:53:06 HBMASTER: schedule new run for iteration 0
02:53:06 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
02:53:06 HBMASTER: submitting job (0, 0, 3) to dispatcher
02:53:06 DISPATCHER: trying to submit job (0, 0, 3)
02:53:06 DISPATCHER: trying to notify the job_runner thread.
02:53:06 HBMASTER: job (0, 0, 3) submitted to dispatcher
02:53:06 DISPATCHER: Trying to submit another job.
02:53:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:53:06 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:53:06 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:53:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:53:06 WORKER: start processing job (0, 0, 3)
02:53:06 WORKER: args: ()
02:53:06 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 42, 'last_n_outputs': 44, 'lr': 0.011844108747859704, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.04954518270413494}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:53:20 DISPATCHER: Starting worker discovery
02:53:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:53:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-433:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:54:20 DISPATCHER: Starting worker discovery
02:54:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:54:20 DISPATCHER: Finished worker discovery
02:55:20 DISPATCHER: Starting worker discovery
02:55:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:55:20 DISPATCHER: Finished worker discovery
02:56:20 DISPATCHER: Starting worker discovery
02:56:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:56:20 DISPATCHER: Finished worker discovery
02:56:23 WORKER: done with job (0, 0, 3), trying to register it.
02:56:23 WORKER: registered result for job (0, 0, 3) with dispatcher
02:56:23 DISPATCHER: job (0, 0, 3) finished
02:56:23 DISPATCHER: register_result: lock acquired
02:56:23 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:56:23 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 42, 'last_n_outputs': 44, 'lr': 0.011844108747859704, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.04954518270413494}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3004633248987967, 'info': {'sick_no_sick': 0.3004633248987967, 'config': "{'batch_size': 128, 'hidden_dim': 42, 'last_n_outputs': 44, 'lr': 0.011844108747859704, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.04954518270413494}"}}
exception: None

02:56:23 job_callback for (0, 0, 3) started
02:56:23 DISPATCHER: Trying to submit another job.
02:56:23 job_callback for (0, 0, 3) got condition
02:56:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:56:23 Only 1 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
02:56:23 HBMASTER: Trying to run another job!
02:56:23 job_callback for (0, 0, 3) finished
02:56:23 HBMASTER: schedule new run for iteration 0
02:56:23 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
02:56:23 HBMASTER: submitting job (0, 0, 10) to dispatcher
02:56:23 DISPATCHER: trying to submit job (0, 0, 10)
02:56:23 DISPATCHER: trying to notify the job_runner thread.
02:56:23 HBMASTER: job (0, 0, 10) submitted to dispatcher
02:56:23 DISPATCHER: Trying to submit another job.
02:56:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:56:23 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:56:23 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:56:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:56:23 WORKER: start processing job (0, 0, 10)
02:56:23 WORKER: args: ()
02:56:23 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 30, 'last_n_outputs': 25, 'lr': 0.0025343640096532442, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.013803519329872976}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:57:20 DISPATCHER: Starting worker discovery
02:57:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:57:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-434:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:58:20 DISPATCHER: Starting worker discovery
02:58:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:58:20 DISPATCHER: Finished worker discovery
02:59:20 DISPATCHER: Starting worker discovery
02:59:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:59:20 DISPATCHER: Finished worker discovery
02:59:39 WORKER: done with job (0, 0, 10), trying to register it.
02:59:39 WORKER: registered result for job (0, 0, 10) with dispatcher
02:59:39 DISPATCHER: job (0, 0, 10) finished
02:59:39 DISPATCHER: register_result: lock acquired
02:59:39 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:59:39 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 30, 'last_n_outputs': 25, 'lr': 0.0025343640096532442, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.013803519329872976}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 30, 'last_n_outputs': 25, 'lr': 0.0025343640096532442, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.013803519329872976}"}}
exception: None

02:59:39 job_callback for (0, 0, 10) started
02:59:39 DISPATCHER: Trying to submit another job.
02:59:39 job_callback for (0, 0, 10) got condition
02:59:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:59:39 Only 2 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
02:59:39 HBMASTER: Trying to run another job!
02:59:39 job_callback for (0, 0, 10) finished
02:59:39 HBMASTER: schedule new run for iteration 0
02:59:39 HBMASTER: trying submitting job (0, 0, 12) to dispatcher
02:59:39 HBMASTER: submitting job (0, 0, 12) to dispatcher
02:59:39 DISPATCHER: trying to submit job (0, 0, 12)
02:59:39 DISPATCHER: trying to notify the job_runner thread.
02:59:39 HBMASTER: job (0, 0, 12) submitted to dispatcher
02:59:39 DISPATCHER: Trying to submit another job.
02:59:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:59:39 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:59:39 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:59:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:59:39 WORKER: start processing job (0, 0, 12)
02:59:39 WORKER: args: ()
02:59:39 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 89, 'last_n_outputs': 48, 'lr': 0.0014073058041155712, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.015819702543516556}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:00:20 DISPATCHER: Starting worker discovery
03:00:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:00:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-435:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:01:20 DISPATCHER: Starting worker discovery
03:01:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:01:20 DISPATCHER: Finished worker discovery
03:02:20 DISPATCHER: Starting worker discovery
03:02:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:02:20 DISPATCHER: Finished worker discovery
03:02:54 WORKER: done with job (0, 0, 12), trying to register it.
03:02:54 WORKER: registered result for job (0, 0, 12) with dispatcher
03:02:54 DISPATCHER: job (0, 0, 12) finished
03:02:54 DISPATCHER: register_result: lock acquired
03:02:54 DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
03:02:54 job_id: (0, 0, 12)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 89, 'last_n_outputs': 48, 'lr': 0.0014073058041155712, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.015819702543516556}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.05587968075284758, 'info': {'sick_no_sick': 0.05587968075284758, 'config': "{'batch_size': 32, 'hidden_dim': 89, 'last_n_outputs': 48, 'lr': 0.0014073058041155712, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.015819702543516556}"}}
exception: None

03:02:54 job_callback for (0, 0, 12) started
03:02:54 job_callback for (0, 0, 12) got condition
03:02:54 DISPATCHER: Trying to submit another job.
03:02:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:02:54 Only 3 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
03:02:54 HBMASTER: Trying to run another job!
03:02:54 job_callback for (0, 0, 12) finished
03:02:54 HBMASTER: schedule new run for iteration 0
03:02:54 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
03:02:54 HBMASTER: submitting job (0, 0, 15) to dispatcher
03:02:54 DISPATCHER: trying to submit job (0, 0, 15)
03:02:54 DISPATCHER: trying to notify the job_runner thread.
03:02:54 HBMASTER: job (0, 0, 15) submitted to dispatcher
03:02:54 DISPATCHER: Trying to submit another job.
03:02:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:02:54 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:02:54 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:02:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:02:54 WORKER: start processing job (0, 0, 15)
03:02:54 WORKER: args: ()
03:02:54 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 69, 'last_n_outputs': 44, 'lr': 0.0025806442157453465, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.12318090472984858}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:03:20 DISPATCHER: Starting worker discovery
03:03:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:03:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-436:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:04:20 DISPATCHER: Starting worker discovery
03:04:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:04:20 DISPATCHER: Finished worker discovery
03:05:20 DISPATCHER: Starting worker discovery
03:05:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:05:20 DISPATCHER: Finished worker discovery
03:06:08 WORKER: done with job (0, 0, 15), trying to register it.
03:06:08 WORKER: registered result for job (0, 0, 15) with dispatcher
03:06:08 DISPATCHER: job (0, 0, 15) finished
03:06:08 DISPATCHER: register_result: lock acquired
03:06:08 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
03:06:08 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 69, 'last_n_outputs': 44, 'lr': 0.0025806442157453465, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.12318090472984858}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4080539399932249, 'info': {'sick_no_sick': 0.4080539399932249, 'config': "{'batch_size': 128, 'hidden_dim': 69, 'last_n_outputs': 44, 'lr': 0.0025806442157453465, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.12318090472984858}"}}
exception: None

03:06:08 job_callback for (0, 0, 15) started
03:06:08 DISPATCHER: Trying to submit another job.
03:06:08 job_callback for (0, 0, 15) got condition
03:06:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:06:08 Only 4 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
03:06:08 HBMASTER: Trying to run another job!
03:06:08 job_callback for (0, 0, 15) finished
03:06:08 HBMASTER: schedule new run for iteration 0
03:06:08 HBMASTER: trying submitting job (0, 0, 17) to dispatcher
03:06:08 HBMASTER: submitting job (0, 0, 17) to dispatcher
03:06:08 DISPATCHER: trying to submit job (0, 0, 17)
03:06:08 DISPATCHER: trying to notify the job_runner thread.
03:06:08 HBMASTER: job (0, 0, 17) submitted to dispatcher
03:06:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:06:08 DISPATCHER: Trying to submit another job.
03:06:08 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:06:08 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:06:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:06:08 WORKER: start processing job (0, 0, 17)
03:06:08 WORKER: args: ()
03:06:08 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 72, 'last_n_outputs': 7, 'lr': 0.012269689309889502, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.11493655356955944}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:06:20 DISPATCHER: Starting worker discovery
03:06:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:06:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-437:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:07:20 DISPATCHER: Starting worker discovery
03:07:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:07:20 DISPATCHER: Finished worker discovery
03:08:20 DISPATCHER: Starting worker discovery
03:08:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:08:20 DISPATCHER: Finished worker discovery
03:09:20 DISPATCHER: Starting worker discovery
03:09:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:09:20 DISPATCHER: Finished worker discovery
03:09:22 WORKER: done with job (0, 0, 17), trying to register it.
03:09:22 WORKER: registered result for job (0, 0, 17) with dispatcher
03:09:22 DISPATCHER: job (0, 0, 17) finished
03:09:22 DISPATCHER: register_result: lock acquired
03:09:22 DISPATCHER: job (0, 0, 17) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
03:09:22 job_id: (0, 0, 17)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 72, 'last_n_outputs': 7, 'lr': 0.012269689309889502, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.11493655356955944}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.41317364155262076, 'info': {'sick_no_sick': 0.41317364155262076, 'config': "{'batch_size': 128, 'hidden_dim': 72, 'last_n_outputs': 7, 'lr': 0.012269689309889502, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.11493655356955944}"}}
exception: None

03:09:22 job_callback for (0, 0, 17) started
03:09:22 job_callback for (0, 0, 17) got condition
03:09:22 DISPATCHER: Trying to submit another job.
03:09:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:09:22 Only 5 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
03:09:22 HBMASTER: Trying to run another job!
03:09:22 job_callback for (0, 0, 17) finished
03:09:22 HBMASTER: schedule new run for iteration 0
03:09:22 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
03:09:22 HBMASTER: submitting job (0, 0, 20) to dispatcher
03:09:22 DISPATCHER: trying to submit job (0, 0, 20)
03:09:22 DISPATCHER: trying to notify the job_runner thread.
03:09:22 HBMASTER: job (0, 0, 20) submitted to dispatcher
03:09:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:09:22 DISPATCHER: Trying to submit another job.
03:09:22 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:09:22 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:09:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:09:22 WORKER: start processing job (0, 0, 20)
03:09:22 WORKER: args: ()
03:09:22 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 53, 'last_n_outputs': 44, 'lr': 0.011727842463118893, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.07319427036820986}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:10:20 DISPATCHER: Starting worker discovery
03:10:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:10:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-438:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:11:20 DISPATCHER: Starting worker discovery
03:11:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:11:20 DISPATCHER: Finished worker discovery
03:12:20 DISPATCHER: Starting worker discovery
03:12:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:12:20 DISPATCHER: Finished worker discovery
03:12:36 WORKER: done with job (0, 0, 20), trying to register it.
03:12:36 WORKER: registered result for job (0, 0, 20) with dispatcher
03:12:36 DISPATCHER: job (0, 0, 20) finished
03:12:36 DISPATCHER: register_result: lock acquired
03:12:36 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
03:12:36 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 53, 'last_n_outputs': 44, 'lr': 0.011727842463118893, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.07319427036820986}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1946074309908919, 'info': {'sick_no_sick': 0.1946074309908919, 'config': "{'batch_size': 16, 'hidden_dim': 53, 'last_n_outputs': 44, 'lr': 0.011727842463118893, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.07319427036820986}"}}
exception: None

03:12:36 job_callback for (0, 0, 20) started
03:12:36 job_callback for (0, 0, 20) got condition
03:12:36 DISPATCHER: Trying to submit another job.
03:12:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:12:36 Only 6 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
03:12:36 HBMASTER: Trying to run another job!
03:12:36 job_callback for (0, 0, 20) finished
03:12:36 HBMASTER: schedule new run for iteration 0
03:12:36 HBMASTER: trying submitting job (0, 0, 21) to dispatcher
03:12:36 HBMASTER: submitting job (0, 0, 21) to dispatcher
03:12:36 DISPATCHER: trying to submit job (0, 0, 21)
03:12:36 DISPATCHER: trying to notify the job_runner thread.
03:12:36 HBMASTER: job (0, 0, 21) submitted to dispatcher
03:12:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:12:36 DISPATCHER: Trying to submit another job.
03:12:36 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:12:36 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:12:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:12:36 WORKER: start processing job (0, 0, 21)
03:12:36 WORKER: args: ()
03:12:36 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 90, 'last_n_outputs': 46, 'lr': 0.005327840031921749, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.01774692094571133}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:13:20 DISPATCHER: Starting worker discovery
03:13:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:13:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-439:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:14:20 DISPATCHER: Starting worker discovery
03:14:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:14:20 DISPATCHER: Finished worker discovery
03:15:20 DISPATCHER: Starting worker discovery
03:15:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:15:20 DISPATCHER: Finished worker discovery
03:15:51 WORKER: done with job (0, 0, 21), trying to register it.
03:15:51 WORKER: registered result for job (0, 0, 21) with dispatcher
03:15:51 DISPATCHER: job (0, 0, 21) finished
03:15:51 DISPATCHER: register_result: lock acquired
03:15:51 DISPATCHER: job (0, 0, 21) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
03:15:51 job_id: (0, 0, 21)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 90, 'last_n_outputs': 46, 'lr': 0.005327840031921749, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.01774692094571133}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.21459642890516276, 'info': {'sick_no_sick': 0.21459642890516276, 'config': "{'batch_size': 128, 'hidden_dim': 90, 'last_n_outputs': 46, 'lr': 0.005327840031921749, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.01774692094571133}"}}
exception: None

03:15:51 job_callback for (0, 0, 21) started
03:15:51 job_callback for (0, 0, 21) got condition
03:15:51 DISPATCHER: Trying to submit another job.
03:15:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:15:51 Only 7 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
03:15:51 HBMASTER: Trying to run another job!
03:15:51 job_callback for (0, 0, 21) finished
03:15:51 HBMASTER: schedule new run for iteration 0
03:15:51 HBMASTER: trying submitting job (0, 0, 23) to dispatcher
03:15:51 HBMASTER: submitting job (0, 0, 23) to dispatcher
03:15:51 DISPATCHER: trying to submit job (0, 0, 23)
03:15:51 DISPATCHER: trying to notify the job_runner thread.
03:15:51 HBMASTER: job (0, 0, 23) submitted to dispatcher
03:15:51 DISPATCHER: Trying to submit another job.
03:15:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:15:51 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:15:51 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:15:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:15:51 WORKER: start processing job (0, 0, 23)
03:15:51 WORKER: args: ()
03:15:51 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 44, 'last_n_outputs': 48, 'lr': 0.00891326755769713, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.1366488775363271}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:16:20 DISPATCHER: Starting worker discovery
03:16:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:16:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-440:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:17:20 DISPATCHER: Starting worker discovery
03:17:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:17:20 DISPATCHER: Finished worker discovery
03:18:20 DISPATCHER: Starting worker discovery
03:18:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:18:20 DISPATCHER: Finished worker discovery
03:19:06 WORKER: done with job (0, 0, 23), trying to register it.
03:19:06 WORKER: registered result for job (0, 0, 23) with dispatcher
03:19:06 DISPATCHER: job (0, 0, 23) finished
03:19:06 DISPATCHER: register_result: lock acquired
03:19:06 DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
03:19:06 job_id: (0, 0, 23)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 44, 'last_n_outputs': 48, 'lr': 0.00891326755769713, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.1366488775363271}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.31183382019341355, 'info': {'sick_no_sick': 0.31183382019341355, 'config': "{'batch_size': 16, 'hidden_dim': 44, 'last_n_outputs': 48, 'lr': 0.00891326755769713, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.1366488775363271}"}}
exception: None

03:19:06 job_callback for (0, 0, 23) started
03:19:06 DISPATCHER: Trying to submit another job.
03:19:06 job_callback for (0, 0, 23) got condition
03:19:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:19:06 Only 8 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
03:19:06 HBMASTER: Trying to run another job!
03:19:06 job_callback for (0, 0, 23) finished
03:19:06 HBMASTER: schedule new run for iteration 0
03:19:06 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
03:19:06 HBMASTER: submitting job (0, 0, 26) to dispatcher
03:19:06 DISPATCHER: trying to submit job (0, 0, 26)
03:19:06 DISPATCHER: trying to notify the job_runner thread.
03:19:06 HBMASTER: job (0, 0, 26) submitted to dispatcher
03:19:06 DISPATCHER: Trying to submit another job.
03:19:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:19:06 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:19:06 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:19:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:19:06 WORKER: start processing job (0, 0, 26)
03:19:06 WORKER: args: ()
03:19:06 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 35, 'last_n_outputs': 40, 'lr': 0.019271249480062116, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.06176494442170675}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:19:20 DISPATCHER: Starting worker discovery
03:19:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:19:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-441:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:20:20 DISPATCHER: Starting worker discovery
03:20:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:20:20 DISPATCHER: Finished worker discovery
03:21:20 DISPATCHER: Starting worker discovery
03:21:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:21:20 DISPATCHER: Finished worker discovery
03:22:20 DISPATCHER: Starting worker discovery
03:22:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:22:20 DISPATCHER: Finished worker discovery
03:22:21 WORKER: done with job (0, 0, 26), trying to register it.
03:22:21 WORKER: registered result for job (0, 0, 26) with dispatcher
03:22:21 DISPATCHER: job (0, 0, 26) finished
03:22:21 DISPATCHER: register_result: lock acquired
03:22:21 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
03:22:21 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 35, 'last_n_outputs': 40, 'lr': 0.019271249480062116, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.06176494442170675}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2427086482821196, 'info': {'sick_no_sick': 0.2427086482821196, 'config': "{'batch_size': 16, 'hidden_dim': 35, 'last_n_outputs': 40, 'lr': 0.019271249480062116, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.06176494442170675}"}}
exception: None

03:22:21 job_callback for (0, 0, 26) started
03:22:21 job_callback for (0, 0, 26) got condition
03:22:21 DISPATCHER: Trying to submit another job.
03:22:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:22:21 HBMASTER: Trying to run another job!
03:22:21 job_callback for (0, 0, 26) finished
03:22:21 ITERATION: Advancing config (0, 0, 15) to next budget 400.000000
03:22:21 ITERATION: Advancing config (0, 0, 17) to next budget 400.000000
03:22:21 ITERATION: Advancing config (0, 0, 23) to next budget 400.000000
03:22:21 HBMASTER: schedule new run for iteration 0
03:22:21 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
03:22:21 HBMASTER: submitting job (0, 0, 15) to dispatcher
03:22:21 DISPATCHER: trying to submit job (0, 0, 15)
03:22:21 DISPATCHER: trying to notify the job_runner thread.
03:22:21 HBMASTER: job (0, 0, 15) submitted to dispatcher
03:22:21 DISPATCHER: Trying to submit another job.
03:22:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:22:21 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:22:21 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:22:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:22:21 WORKER: start processing job (0, 0, 15)
03:22:21 WORKER: args: ()
03:22:21 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 69, 'last_n_outputs': 44, 'lr': 0.0025806442157453465, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.12318090472984858}, 'budget': 400.0, 'working_directory': '.'}
03:23:20 DISPATCHER: Starting worker discovery
03:23:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:23:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-442:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:24:20 DISPATCHER: Starting worker discovery
03:24:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:24:20 DISPATCHER: Finished worker discovery
03:25:20 DISPATCHER: Starting worker discovery
03:25:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:25:20 DISPATCHER: Finished worker discovery
03:26:20 DISPATCHER: Starting worker discovery
03:26:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:26:20 DISPATCHER: Finished worker discovery
03:27:20 DISPATCHER: Starting worker discovery
03:27:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:27:20 DISPATCHER: Finished worker discovery
03:28:20 DISPATCHER: Starting worker discovery
03:28:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:28:20 DISPATCHER: Finished worker discovery
03:29:20 DISPATCHER: Starting worker discovery
03:29:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:29:20 DISPATCHER: Finished worker discovery
03:30:03 WORKER: done with job (0, 0, 15), trying to register it.
03:30:03 WORKER: registered result for job (0, 0, 15) with dispatcher
03:30:03 DISPATCHER: job (0, 0, 15) finished
03:30:03 DISPATCHER: register_result: lock acquired
03:30:03 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
03:30:03 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 69, 'last_n_outputs': 44, 'lr': 0.0025806442157453465, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.12318090472984858}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5284371644816704, 'info': {'sick_no_sick': 0.5284371644816704, 'config': "{'batch_size': 128, 'hidden_dim': 69, 'last_n_outputs': 44, 'lr': 0.0025806442157453465, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.12318090472984858}"}}
exception: None

03:30:03 job_callback for (0, 0, 15) started
03:30:03 job_callback for (0, 0, 15) got condition
03:30:03 DISPATCHER: Trying to submit another job.
03:30:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:30:03 Only 1 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
03:30:03 HBMASTER: Trying to run another job!
03:30:03 job_callback for (0, 0, 15) finished
03:30:03 HBMASTER: schedule new run for iteration 0
03:30:03 HBMASTER: trying submitting job (0, 0, 17) to dispatcher
03:30:03 HBMASTER: submitting job (0, 0, 17) to dispatcher
03:30:03 DISPATCHER: trying to submit job (0, 0, 17)
03:30:03 DISPATCHER: trying to notify the job_runner thread.
03:30:03 HBMASTER: job (0, 0, 17) submitted to dispatcher
03:30:03 DISPATCHER: Trying to submit another job.
03:30:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:30:03 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:30:03 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:30:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:30:03 WORKER: start processing job (0, 0, 17)
03:30:03 WORKER: args: ()
03:30:03 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 72, 'last_n_outputs': 7, 'lr': 0.012269689309889502, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.11493655356955944}, 'budget': 400.0, 'working_directory': '.'}
03:30:20 DISPATCHER: Starting worker discovery
03:30:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:30:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-443:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:31:20 DISPATCHER: Starting worker discovery
03:31:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:31:20 DISPATCHER: Finished worker discovery
03:32:20 DISPATCHER: Starting worker discovery
03:32:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:32:20 DISPATCHER: Finished worker discovery
03:33:20 DISPATCHER: Starting worker discovery
03:33:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:33:20 DISPATCHER: Finished worker discovery
03:34:20 DISPATCHER: Starting worker discovery
03:34:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:34:20 DISPATCHER: Finished worker discovery
03:35:20 DISPATCHER: Starting worker discovery
03:35:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:35:20 DISPATCHER: Finished worker discovery
03:36:20 DISPATCHER: Starting worker discovery
03:36:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:36:20 DISPATCHER: Finished worker discovery
03:37:20 DISPATCHER: Starting worker discovery
03:37:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:37:20 DISPATCHER: Finished worker discovery
03:37:44 WORKER: done with job (0, 0, 17), trying to register it.
03:37:44 WORKER: registered result for job (0, 0, 17) with dispatcher
03:37:44 DISPATCHER: job (0, 0, 17) finished
03:37:44 DISPATCHER: register_result: lock acquired
03:37:44 DISPATCHER: job (0, 0, 17) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
03:37:44 job_id: (0, 0, 17)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 72, 'last_n_outputs': 7, 'lr': 0.012269689309889502, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.11493655356955944}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.024336800963726424, 'info': {'sick_no_sick': 0.024336800963726424, 'config': "{'batch_size': 128, 'hidden_dim': 72, 'last_n_outputs': 7, 'lr': 0.012269689309889502, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.11493655356955944}"}}
exception: None

03:37:44 job_callback for (0, 0, 17) started
03:37:44 DISPATCHER: Trying to submit another job.
03:37:44 job_callback for (0, 0, 17) got condition
03:37:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:37:44 Only 2 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
03:37:44 HBMASTER: Trying to run another job!
03:37:44 job_callback for (0, 0, 17) finished
03:37:44 HBMASTER: schedule new run for iteration 0
03:37:44 HBMASTER: trying submitting job (0, 0, 23) to dispatcher
03:37:44 HBMASTER: submitting job (0, 0, 23) to dispatcher
03:37:44 DISPATCHER: trying to submit job (0, 0, 23)
03:37:44 DISPATCHER: trying to notify the job_runner thread.
03:37:44 HBMASTER: job (0, 0, 23) submitted to dispatcher
03:37:44 DISPATCHER: Trying to submit another job.
03:37:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:37:44 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:37:44 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:37:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:37:44 WORKER: start processing job (0, 0, 23)
03:37:44 WORKER: args: ()
03:37:44 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 44, 'last_n_outputs': 48, 'lr': 0.00891326755769713, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.1366488775363271}, 'budget': 400.0, 'working_directory': '.'}
03:38:20 DISPATCHER: Starting worker discovery
03:38:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:38:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-444:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:39:20 DISPATCHER: Starting worker discovery
03:39:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:39:20 DISPATCHER: Finished worker discovery
03:40:20 DISPATCHER: Starting worker discovery
03:40:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:40:20 DISPATCHER: Finished worker discovery
03:41:20 DISPATCHER: Starting worker discovery
03:41:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:41:20 DISPATCHER: Finished worker discovery
03:42:20 DISPATCHER: Starting worker discovery
03:42:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:42:20 DISPATCHER: Finished worker discovery
03:43:20 DISPATCHER: Starting worker discovery
03:43:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:43:20 DISPATCHER: Finished worker discovery
03:44:20 DISPATCHER: Starting worker discovery
03:44:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:44:20 DISPATCHER: Finished worker discovery
03:45:20 DISPATCHER: Starting worker discovery
03:45:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:45:20 DISPATCHER: Finished worker discovery
03:45:26 WORKER: done with job (0, 0, 23), trying to register it.
03:45:26 WORKER: registered result for job (0, 0, 23) with dispatcher
03:45:26 DISPATCHER: job (0, 0, 23) finished
03:45:26 DISPATCHER: register_result: lock acquired
03:45:26 DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
03:45:26 job_id: (0, 0, 23)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 44, 'last_n_outputs': 48, 'lr': 0.00891326755769713, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.1366488775363271}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.11062561276530933, 'info': {'sick_no_sick': 0.11062561276530933, 'config': "{'batch_size': 16, 'hidden_dim': 44, 'last_n_outputs': 48, 'lr': 0.00891326755769713, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.1366488775363271}"}}
exception: None

03:45:26 job_callback for (0, 0, 23) started
03:45:26 job_callback for (0, 0, 23) got condition
03:45:26 DISPATCHER: Trying to submit another job.
03:45:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:45:26 Only 3 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
03:45:26 HBMASTER: Trying to run another job!
03:45:26 job_callback for (0, 0, 23) finished
03:45:26 ITERATION: Advancing config (0, 0, 15) to next budget 1200.000000
03:45:26 HBMASTER: schedule new run for iteration 0
03:45:26 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
03:45:26 HBMASTER: submitting job (0, 0, 15) to dispatcher
03:45:26 DISPATCHER: trying to submit job (0, 0, 15)
03:45:26 DISPATCHER: trying to notify the job_runner thread.
03:45:26 HBMASTER: job (0, 0, 15) submitted to dispatcher
03:45:26 DISPATCHER: Trying to submit another job.
03:45:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:45:26 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:45:26 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:45:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:45:26 WORKER: start processing job (0, 0, 15)
03:45:26 WORKER: args: ()
03:45:26 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 69, 'last_n_outputs': 44, 'lr': 0.0025806442157453465, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.12318090472984858}, 'budget': 1200.0, 'working_directory': '.'}
03:46:20 DISPATCHER: Starting worker discovery
03:46:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:46:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-445:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:47:20 DISPATCHER: Starting worker discovery
03:47:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:47:20 DISPATCHER: Finished worker discovery
03:48:20 DISPATCHER: Starting worker discovery
03:48:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:48:20 DISPATCHER: Finished worker discovery
03:49:20 DISPATCHER: Starting worker discovery
03:49:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:49:20 DISPATCHER: Finished worker discovery
03:50:20 DISPATCHER: Starting worker discovery
03:50:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:50:20 DISPATCHER: Finished worker discovery
03:51:20 DISPATCHER: Starting worker discovery
03:51:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:51:20 DISPATCHER: Finished worker discovery
03:52:20 DISPATCHER: Starting worker discovery
03:52:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:52:20 DISPATCHER: Finished worker discovery
03:53:20 DISPATCHER: Starting worker discovery
03:53:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:53:20 DISPATCHER: Finished worker discovery
03:54:20 DISPATCHER: Starting worker discovery
03:54:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:54:20 DISPATCHER: Finished worker discovery
03:55:20 DISPATCHER: Starting worker discovery
03:55:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:55:20 DISPATCHER: Finished worker discovery
03:56:20 DISPATCHER: Starting worker discovery
03:56:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:56:20 DISPATCHER: Finished worker discovery
03:57:20 DISPATCHER: Starting worker discovery
03:57:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:57:20 DISPATCHER: Finished worker discovery
03:58:20 DISPATCHER: Starting worker discovery
03:58:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:58:20 DISPATCHER: Finished worker discovery
03:59:20 DISPATCHER: Starting worker discovery
03:59:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:59:20 DISPATCHER: Finished worker discovery
04:00:20 DISPATCHER: Starting worker discovery
04:00:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:00:20 DISPATCHER: Finished worker discovery
04:01:20 DISPATCHER: Starting worker discovery
04:01:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:01:20 DISPATCHER: Finished worker discovery
04:02:20 DISPATCHER: Starting worker discovery
04:02:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:02:20 DISPATCHER: Finished worker discovery
04:03:20 DISPATCHER: Starting worker discovery
04:03:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:03:20 DISPATCHER: Finished worker discovery
04:04:20 DISPATCHER: Starting worker discovery
04:04:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:04:20 DISPATCHER: Finished worker discovery
04:05:20 DISPATCHER: Starting worker discovery
04:05:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:05:20 DISPATCHER: Finished worker discovery
04:06:20 DISPATCHER: Starting worker discovery
04:06:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:06:20 DISPATCHER: Finished worker discovery
04:06:27 WORKER: done with job (0, 0, 15), trying to register it.
04:06:27 WORKER: registered result for job (0, 0, 15) with dispatcher
04:06:27 DISPATCHER: job (0, 0, 15) finished
04:06:27 DISPATCHER: register_result: lock acquired
04:06:27 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
04:06:27 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 69, 'last_n_outputs': 44, 'lr': 0.0025806442157453465, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.12318090472984858}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.4008832151816886, 'info': {'sick_no_sick': 0.4008832151816886, 'config': "{'batch_size': 128, 'hidden_dim': 69, 'last_n_outputs': 44, 'lr': 0.0025806442157453465, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.12318090472984858}"}}
exception: None

04:06:27 job_callback for (0, 0, 15) started
04:06:27 job_callback for (0, 0, 15) got condition
04:06:27 DISPATCHER: Trying to submit another job.
04:06:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:06:27 Only 1 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
04:06:27 HBMASTER: Trying to run another job!
04:06:27 job_callback for (0, 0, 15) finished
04:06:27 start sampling a new configuration.
04:06:27 best_vector: [2, 0.4210374186685555, 0.9227597495094348, 0.562182728759399, 0.1017860612095437, 1, 0.5129536875641629, 0.2611952158930114], 0.0045982172654012565, 2.7815451457930944, 0.012790148913878863
04:06:27 done sampling a new configuration.
04:06:27 HBMASTER: schedule new run for iteration 1
04:06:27 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
04:06:27 HBMASTER: submitting job (1, 0, 0) to dispatcher
04:06:27 DISPATCHER: trying to submit job (1, 0, 0)
04:06:27 DISPATCHER: trying to notify the job_runner thread.
04:06:27 HBMASTER: job (1, 0, 0) submitted to dispatcher
04:06:27 DISPATCHER: Trying to submit another job.
04:06:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:06:27 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:06:27 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:06:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:06:27 WORKER: start processing job (1, 0, 0)
04:06:27 WORKER: args: ()
04:06:27 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 54, 'last_n_outputs': 47, 'lr': 0.013315744626169265, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.02186869213118236}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:07:20 DISPATCHER: Starting worker discovery
04:07:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:07:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-446:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:08:20 DISPATCHER: Starting worker discovery
04:08:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:08:20 DISPATCHER: Finished worker discovery
04:09:20 DISPATCHER: Starting worker discovery
04:09:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:09:20 DISPATCHER: Finished worker discovery
04:09:40 WORKER: done with job (1, 0, 0), trying to register it.
04:09:40 WORKER: registered result for job (1, 0, 0) with dispatcher
04:09:40 DISPATCHER: job (1, 0, 0) finished
04:09:40 DISPATCHER: register_result: lock acquired
04:09:40 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
04:09:40 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 54, 'last_n_outputs': 47, 'lr': 0.013315744626169265, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.02186869213118236}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.008656713569898038, 'info': {'sick_no_sick': 0.008656713569898038, 'config': "{'batch_size': 64, 'hidden_dim': 54, 'last_n_outputs': 47, 'lr': 0.013315744626169265, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.02186869213118236}"}}
exception: None

04:09:40 job_callback for (1, 0, 0) started
04:09:40 DISPATCHER: Trying to submit another job.
04:09:40 job_callback for (1, 0, 0) got condition
04:09:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:09:40 HBMASTER: Trying to run another job!
04:09:40 job_callback for (1, 0, 0) finished
04:09:40 start sampling a new configuration.
04:09:40 best_vector: [0, 0.19825267114118794, 0.9177048481234349, 0.7369672872767832, 0.051296566337792095, 1, 0.42572313465982464, 0.6608118746458602], 0.00864732408892916, 0.22681207020875524, 0.001961317478376061
04:09:40 done sampling a new configuration.
04:09:40 HBMASTER: schedule new run for iteration 1
04:09:40 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
04:09:40 HBMASTER: submitting job (1, 0, 1) to dispatcher
04:09:40 DISPATCHER: trying to submit job (1, 0, 1)
04:09:40 DISPATCHER: trying to notify the job_runner thread.
04:09:40 HBMASTER: job (1, 0, 1) submitted to dispatcher
04:09:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:09:40 DISPATCHER: Trying to submit another job.
04:09:40 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:09:40 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:09:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:09:40 WORKER: start processing job (1, 0, 1)
04:09:40 WORKER: args: ()
04:09:40 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 36, 'last_n_outputs': 46, 'lr': 0.02978067756702391, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.07239958393480807}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:10:20 DISPATCHER: Starting worker discovery
04:10:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:10:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-447:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:11:20 DISPATCHER: Starting worker discovery
04:11:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:11:20 DISPATCHER: Finished worker discovery
04:12:20 DISPATCHER: Starting worker discovery
04:12:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:12:20 DISPATCHER: Finished worker discovery
04:12:54 WORKER: done with job (1, 0, 1), trying to register it.
04:12:54 WORKER: registered result for job (1, 0, 1) with dispatcher
04:12:54 DISPATCHER: job (1, 0, 1) finished
04:12:54 DISPATCHER: register_result: lock acquired
04:12:54 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
04:12:54 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 36, 'last_n_outputs': 46, 'lr': 0.02978067756702391, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.07239958393480807}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.02261485297128038, 'info': {'sick_no_sick': 0.02261485297128038, 'config': "{'batch_size': 16, 'hidden_dim': 36, 'last_n_outputs': 46, 'lr': 0.02978067756702391, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.07239958393480807}"}}
exception: None

04:12:54 job_callback for (1, 0, 1) started
04:12:54 DISPATCHER: Trying to submit another job.
04:12:54 job_callback for (1, 0, 1) got condition
04:12:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:12:54 HBMASTER: Trying to run another job!
04:12:54 job_callback for (1, 0, 1) finished
04:12:54 start sampling a new configuration.
04:12:54 best_vector: [3, 0.38567903107985474, 0.881883500455585, 0.15412523579640325, 0.08347167600082298, 1, 0.7488391735647353, 0.044505844304536996], 0.002303895497104489, 0.4291442720651047, 0.0009887035560189783
04:12:54 done sampling a new configuration.
04:12:54 HBMASTER: schedule new run for iteration 1
04:12:54 HBMASTER: trying submitting job (1, 0, 2) to dispatcher
04:12:54 HBMASTER: submitting job (1, 0, 2) to dispatcher
04:12:54 DISPATCHER: trying to submit job (1, 0, 2)
04:12:54 DISPATCHER: trying to notify the job_runner thread.
04:12:54 HBMASTER: job (1, 0, 2) submitted to dispatcher
04:12:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:12:54 DISPATCHER: Trying to submit another job.
04:12:54 DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:12:54 DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:12:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:12:54 WORKER: start processing job (1, 0, 2)
04:12:54 WORKER: args: ()
04:12:54 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 51, 'last_n_outputs': 45, 'lr': 0.0020335294746427865, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.01142624254040969}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:13:20 DISPATCHER: Starting worker discovery
04:13:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:13:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-448:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:14:20 DISPATCHER: Starting worker discovery
04:14:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:14:20 DISPATCHER: Finished worker discovery
04:15:20 DISPATCHER: Starting worker discovery
04:15:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:15:20 DISPATCHER: Finished worker discovery
04:16:09 WORKER: done with job (1, 0, 2), trying to register it.
04:16:09 WORKER: registered result for job (1, 0, 2) with dispatcher
04:16:09 DISPATCHER: job (1, 0, 2) finished
04:16:09 DISPATCHER: register_result: lock acquired
04:16:09 DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
04:16:09 job_id: (1, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 51, 'last_n_outputs': 45, 'lr': 0.0020335294746427865, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.01142624254040969}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.005377701610039826, 'info': {'sick_no_sick': 0.005377701610039826, 'config': "{'batch_size': 128, 'hidden_dim': 51, 'last_n_outputs': 45, 'lr': 0.0020335294746427865, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.01142624254040969}"}}
exception: None

04:16:09 job_callback for (1, 0, 2) started
04:16:09 DISPATCHER: Trying to submit another job.
04:16:09 job_callback for (1, 0, 2) got condition
04:16:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:16:09 HBMASTER: Trying to run another job!
04:16:09 job_callback for (1, 0, 2) finished
04:16:09 start sampling a new configuration.
04:16:09 best_vector: [3, 0.6475103768387247, 0.9821787562440683, 0.019865122235429133, 0.1455089421216184, 0, 0.8429260331150614, 0.29516407701092306], 5.123882347978404e-33, 1.951645123925501, -0.00011630296525216784
04:16:09 done sampling a new configuration.
04:16:09 HBMASTER: schedule new run for iteration 1
04:16:09 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
04:16:09 HBMASTER: submitting job (1, 0, 3) to dispatcher
04:16:09 DISPATCHER: trying to submit job (1, 0, 3)
04:16:09 DISPATCHER: trying to notify the job_runner thread.
04:16:09 HBMASTER: job (1, 0, 3) submitted to dispatcher
04:16:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:16:09 DISPATCHER: Trying to submit another job.
04:16:09 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:16:09 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:16:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:16:09 WORKER: start processing job (1, 0, 3)
04:16:09 WORKER: args: ()
04:16:09 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 72, 'last_n_outputs': 50, 'lr': 0.0010957973465645279, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.024211255890964206}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:16:20 DISPATCHER: Starting worker discovery
04:16:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:16:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-449:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:17:20 DISPATCHER: Starting worker discovery
04:17:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:17:20 DISPATCHER: Finished worker discovery
04:18:20 DISPATCHER: Starting worker discovery
04:18:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:18:20 DISPATCHER: Finished worker discovery
04:19:20 DISPATCHER: Starting worker discovery
04:19:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:19:20 DISPATCHER: Finished worker discovery
04:19:21 WORKER: done with job (1, 0, 3), trying to register it.
04:19:21 WORKER: registered result for job (1, 0, 3) with dispatcher
04:19:21 DISPATCHER: job (1, 0, 3) finished
04:19:21 DISPATCHER: register_result: lock acquired
04:19:21 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
04:19:21 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 72, 'last_n_outputs': 50, 'lr': 0.0010957973465645279, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.024211255890964206}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.45097478913124295, 'info': {'sick_no_sick': 0.45097478913124295, 'config': "{'batch_size': 128, 'hidden_dim': 72, 'last_n_outputs': 50, 'lr': 0.0010957973465645279, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.024211255890964206}"}}
exception: None

04:19:21 job_callback for (1, 0, 3) started
04:19:21 DISPATCHER: Trying to submit another job.
04:19:21 job_callback for (1, 0, 3) got condition
04:19:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:19:21 HBMASTER: Trying to run another job!
04:19:21 job_callback for (1, 0, 3) finished
04:19:21 start sampling a new configuration.
04:19:22 best_vector: [3, 0.6591147778937023, 0.977498555399298, 0.1439421461680438, 0.2146840616940796, 1, 0.891893307299281, 0.2687348149852836], 1.100639482642207e-32, 0.9085627181021976, -0.0012463456418216959
04:19:22 done sampling a new configuration.
04:19:22 HBMASTER: schedule new run for iteration 1
04:19:22 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
04:19:22 HBMASTER: submitting job (1, 0, 4) to dispatcher
04:19:22 DISPATCHER: trying to submit job (1, 0, 4)
04:19:22 DISPATCHER: trying to notify the job_runner thread.
04:19:22 HBMASTER: job (1, 0, 4) submitted to dispatcher
04:19:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:19:22 DISPATCHER: Trying to submit another job.
04:19:22 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:19:22 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:19:22 WORKER: start processing job (1, 0, 4)
04:19:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:19:22 WORKER: args: ()
04:19:22 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 73, 'last_n_outputs': 49, 'lr': 0.001940368842570719, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.02236825242926158}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:20:20 DISPATCHER: Starting worker discovery
04:20:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:20:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-450:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:21:20 DISPATCHER: Starting worker discovery
04:21:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:21:20 DISPATCHER: Finished worker discovery
04:22:20 DISPATCHER: Starting worker discovery
04:22:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:22:20 DISPATCHER: Finished worker discovery
04:22:36 WORKER: done with job (1, 0, 4), trying to register it.
04:22:36 WORKER: registered result for job (1, 0, 4) with dispatcher
04:22:36 DISPATCHER: job (1, 0, 4) finished
04:22:36 DISPATCHER: register_result: lock acquired
04:22:36 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
04:22:36 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 73, 'last_n_outputs': 49, 'lr': 0.001940368842570719, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.02236825242926158}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 73, 'last_n_outputs': 49, 'lr': 0.001940368842570719, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.02236825242926158}"}}
exception: None

04:22:36 job_callback for (1, 0, 4) started
04:22:36 job_callback for (1, 0, 4) got condition
04:22:36 DISPATCHER: Trying to submit another job.
04:22:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:22:36 HBMASTER: Trying to run another job!
04:22:36 job_callback for (1, 0, 4) finished
04:22:36 start sampling a new configuration.
04:22:36 best_vector: [0, 0.022597427451852448, 0.6689649407501004, 0.8548858724388679, 0.22339463464702458, 1, 0.7539896645212176, 0.13232069227787133], 7.790329454728744e-30, 0.001283642759669167, -0.0002537225312778559
04:22:36 done sampling a new configuration.
04:22:36 HBMASTER: schedule new run for iteration 1
04:22:36 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
04:22:36 HBMASTER: submitting job (1, 0, 5) to dispatcher
04:22:36 DISPATCHER: trying to submit job (1, 0, 5)
04:22:36 DISPATCHER: trying to notify the job_runner thread.
04:22:36 HBMASTER: job (1, 0, 5) submitted to dispatcher
04:22:36 DISPATCHER: Trying to submit another job.
04:22:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:22:36 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:22:36 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:22:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:22:36 WORKER: start processing job (1, 0, 5)
04:22:36 WORKER: args: ()
04:22:36 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 21, 'last_n_outputs': 34, 'lr': 0.05125919067465246, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.014864598722657375}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:23:20 DISPATCHER: Starting worker discovery
04:23:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:23:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-451:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:24:20 DISPATCHER: Starting worker discovery
04:24:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:24:20 DISPATCHER: Finished worker discovery
04:25:20 DISPATCHER: Starting worker discovery
04:25:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:25:20 DISPATCHER: Finished worker discovery
04:25:50 WORKER: done with job (1, 0, 5), trying to register it.
04:25:50 WORKER: registered result for job (1, 0, 5) with dispatcher
04:25:50 DISPATCHER: job (1, 0, 5) finished
04:25:50 DISPATCHER: register_result: lock acquired
04:25:50 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
04:25:50 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 21, 'last_n_outputs': 34, 'lr': 0.05125919067465246, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.014864598722657375}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 21, 'last_n_outputs': 34, 'lr': 0.05125919067465246, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.014864598722657375}"}}
exception: None

04:25:50 job_callback for (1, 0, 5) started
04:25:50 DISPATCHER: Trying to submit another job.
04:25:50 job_callback for (1, 0, 5) got condition
04:25:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:25:50 HBMASTER: Trying to run another job!
04:25:50 job_callback for (1, 0, 5) finished
04:25:50 start sampling a new configuration.
04:25:51 best_vector: [0, 0.37136897781145595, 0.7557599706686325, 0.6194279648748444, 0.16482981473676095, 0, 0.6085834664093721, 0.3473670322000514], 0.002009626821554294, 1.801611671733418, 0.003620567137540747
04:25:51 done sampling a new configuration.
04:25:51 HBMASTER: schedule new run for iteration 1
04:25:51 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
04:25:51 HBMASTER: submitting job (1, 0, 6) to dispatcher
04:25:51 DISPATCHER: trying to submit job (1, 0, 6)
04:25:51 DISPATCHER: trying to notify the job_runner thread.
04:25:51 HBMASTER: job (1, 0, 6) submitted to dispatcher
04:25:51 DISPATCHER: Trying to submit another job.
04:25:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:25:51 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:25:51 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:25:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:25:51 WORKER: start processing job (1, 0, 6)
04:25:51 WORKER: args: ()
04:25:51 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 50, 'last_n_outputs': 38, 'lr': 0.017332289313899876, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.02830967791897915}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:26:20 DISPATCHER: Starting worker discovery
04:26:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:26:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-452:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:27:20 DISPATCHER: Starting worker discovery
04:27:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:27:20 DISPATCHER: Finished worker discovery
04:28:20 DISPATCHER: Starting worker discovery
04:28:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:28:20 DISPATCHER: Finished worker discovery
04:29:06 WORKER: done with job (1, 0, 6), trying to register it.
04:29:06 WORKER: registered result for job (1, 0, 6) with dispatcher
04:29:06 DISPATCHER: job (1, 0, 6) finished
04:29:06 DISPATCHER: register_result: lock acquired
04:29:06 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
04:29:06 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 50, 'last_n_outputs': 38, 'lr': 0.017332289313899876, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.02830967791897915}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.34882822297456145, 'info': {'sick_no_sick': 0.34882822297456145, 'config': "{'batch_size': 16, 'hidden_dim': 50, 'last_n_outputs': 38, 'lr': 0.017332289313899876, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.02830967791897915}"}}
exception: None

04:29:06 job_callback for (1, 0, 6) started
04:29:06 DISPATCHER: Trying to submit another job.
04:29:06 job_callback for (1, 0, 6) got condition
04:29:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:29:06 HBMASTER: Trying to run another job!
04:29:06 job_callback for (1, 0, 6) finished
04:29:06 start sampling a new configuration.
04:29:06 best_vector: [1, 0.10273783820211005, 0.9639940649753964, 0.6313220876631478, 0.13983311032644674, 0, 0.48855820514151843, 0.5796402845307658], 0.0017908028923901077, 4.603775143335337, 0.008244453842598604
04:29:06 done sampling a new configuration.
04:29:06 HBMASTER: schedule new run for iteration 1
04:29:06 HBMASTER: trying submitting job (1, 0, 7) to dispatcher
04:29:06 HBMASTER: submitting job (1, 0, 7) to dispatcher
04:29:06 DISPATCHER: trying to submit job (1, 0, 7)
04:29:06 DISPATCHER: trying to notify the job_runner thread.
04:29:06 HBMASTER: job (1, 0, 7) submitted to dispatcher
04:29:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:29:06 DISPATCHER: Trying to submit another job.
04:29:06 DISPATCHER: starting job (1, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:29:06 DISPATCHER: job (1, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:29:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:29:06 WORKER: start processing job (1, 0, 7)
04:29:06 WORKER: args: ()
04:29:06 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 28, 'last_n_outputs': 49, 'lr': 0.01830813791597773, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.056771372898694994}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:29:20 DISPATCHER: Starting worker discovery
04:29:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:29:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-453:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:30:20 DISPATCHER: Starting worker discovery
04:30:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:30:20 DISPATCHER: Finished worker discovery
04:31:20 DISPATCHER: Starting worker discovery
04:31:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:31:20 DISPATCHER: Finished worker discovery
04:32:20 DISPATCHER: Starting worker discovery
04:32:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:32:20 DISPATCHER: Finished worker discovery
04:32:21 WORKER: done with job (1, 0, 7), trying to register it.
04:32:21 WORKER: registered result for job (1, 0, 7) with dispatcher
04:32:21 DISPATCHER: job (1, 0, 7) finished
04:32:21 DISPATCHER: register_result: lock acquired
04:32:21 DISPATCHER: job (1, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
04:32:21 job_id: (1, 0, 7)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 28, 'last_n_outputs': 49, 'lr': 0.01830813791597773, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.056771372898694994}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.20598901731881808, 'info': {'sick_no_sick': 0.20598901731881808, 'config': "{'batch_size': 32, 'hidden_dim': 28, 'last_n_outputs': 49, 'lr': 0.01830813791597773, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.056771372898694994}"}}
exception: None

04:32:21 job_callback for (1, 0, 7) started
04:32:21 job_callback for (1, 0, 7) got condition
04:32:21 DISPATCHER: Trying to submit another job.
04:32:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:32:21 HBMASTER: Trying to run another job!
04:32:21 job_callback for (1, 0, 7) finished
04:32:21 start sampling a new configuration.
04:32:21 best_vector: [2, 0.6736698823349241, 0.9675217304285689, 0.7636621161178775, 0.1067540712353705, 0, 0.7615992227678721, 0.37898738041994506], 0.003933581129689688, 1.0246982882566043, 0.004030733850311503
04:32:21 done sampling a new configuration.
04:32:21 HBMASTER: schedule new run for iteration 1
04:32:21 HBMASTER: trying submitting job (1, 0, 8) to dispatcher
04:32:21 HBMASTER: submitting job (1, 0, 8) to dispatcher
04:32:21 DISPATCHER: trying to submit job (1, 0, 8)
04:32:21 DISPATCHER: trying to notify the job_runner thread.
04:32:21 HBMASTER: job (1, 0, 8) submitted to dispatcher
04:32:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:32:21 DISPATCHER: Trying to submit another job.
04:32:21 DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:32:21 DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:32:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:32:21 WORKER: start processing job (1, 0, 8)
04:32:21 WORKER: args: ()
04:32:21 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 74, 'last_n_outputs': 49, 'lr': 0.033676289340020156, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.031122462326670874}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:33:20 DISPATCHER: Starting worker discovery
04:33:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:33:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-454:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:34:20 DISPATCHER: Starting worker discovery
04:34:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:34:20 DISPATCHER: Finished worker discovery
04:35:20 DISPATCHER: Starting worker discovery
04:35:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:35:20 DISPATCHER: Finished worker discovery
04:35:34 WORKER: done with job (1, 0, 8), trying to register it.
04:35:34 WORKER: registered result for job (1, 0, 8) with dispatcher
04:35:34 DISPATCHER: job (1, 0, 8) finished
04:35:34 DISPATCHER: register_result: lock acquired
04:35:34 DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
04:35:34 job_id: (1, 0, 8)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 74, 'last_n_outputs': 49, 'lr': 0.033676289340020156, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.031122462326670874}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.11215006386700002, 'info': {'sick_no_sick': 0.11215006386700002, 'config': "{'batch_size': 64, 'hidden_dim': 74, 'last_n_outputs': 49, 'lr': 0.033676289340020156, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.031122462326670874}"}}
exception: None

04:35:34 job_callback for (1, 0, 8) started
04:35:34 job_callback for (1, 0, 8) got condition
04:35:34 DISPATCHER: Trying to submit another job.
04:35:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:35:34 done building a new model for budget 133.333333 based on 9/15 split
Best loss for this budget:-0.450975





04:35:34 HBMASTER: Trying to run another job!
04:35:34 job_callback for (1, 0, 8) finished
04:35:34 ITERATION: Advancing config (1, 0, 3) to next budget 400.000000
04:35:34 ITERATION: Advancing config (1, 0, 6) to next budget 400.000000
04:35:34 ITERATION: Advancing config (1, 0, 7) to next budget 400.000000
04:35:34 HBMASTER: schedule new run for iteration 1
04:35:34 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
04:35:34 HBMASTER: submitting job (1, 0, 3) to dispatcher
04:35:34 DISPATCHER: trying to submit job (1, 0, 3)
04:35:34 DISPATCHER: trying to notify the job_runner thread.
04:35:34 HBMASTER: job (1, 0, 3) submitted to dispatcher
04:35:34 DISPATCHER: Trying to submit another job.
04:35:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:35:34 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:35:34 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:35:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:35:34 WORKER: start processing job (1, 0, 3)
04:35:34 WORKER: args: ()
04:35:34 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 72, 'last_n_outputs': 50, 'lr': 0.0010957973465645279, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.024211255890964206}, 'budget': 400.0, 'working_directory': '.'}
04:36:20 DISPATCHER: Starting worker discovery
04:36:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:36:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-455:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:37:20 DISPATCHER: Starting worker discovery
04:37:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:37:20 DISPATCHER: Finished worker discovery
04:38:20 DISPATCHER: Starting worker discovery
04:38:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:38:20 DISPATCHER: Finished worker discovery
04:39:20 DISPATCHER: Starting worker discovery
04:39:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:39:20 DISPATCHER: Finished worker discovery
04:40:20 DISPATCHER: Starting worker discovery
04:40:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:40:20 DISPATCHER: Finished worker discovery
04:41:20 DISPATCHER: Starting worker discovery
04:41:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:41:20 DISPATCHER: Finished worker discovery
04:42:20 DISPATCHER: Starting worker discovery
04:42:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:42:20 DISPATCHER: Finished worker discovery
04:43:14 WORKER: done with job (1, 0, 3), trying to register it.
04:43:14 WORKER: registered result for job (1, 0, 3) with dispatcher
04:43:14 DISPATCHER: job (1, 0, 3) finished
04:43:14 DISPATCHER: register_result: lock acquired
04:43:14 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
04:43:14 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 72, 'last_n_outputs': 50, 'lr': 0.0010957973465645279, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.024211255890964206}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.38970113569402287, 'info': {'sick_no_sick': 0.38970113569402287, 'config': "{'batch_size': 128, 'hidden_dim': 72, 'last_n_outputs': 50, 'lr': 0.0010957973465645279, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.024211255890964206}"}}
exception: None

04:43:14 job_callback for (1, 0, 3) started
04:43:14 job_callback for (1, 0, 3) got condition
04:43:14 DISPATCHER: Trying to submit another job.
04:43:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:43:14 Only 4 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
04:43:14 HBMASTER: Trying to run another job!
04:43:14 job_callback for (1, 0, 3) finished
04:43:14 HBMASTER: schedule new run for iteration 1
04:43:14 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
04:43:14 HBMASTER: submitting job (1, 0, 6) to dispatcher
04:43:14 DISPATCHER: trying to submit job (1, 0, 6)
04:43:14 DISPATCHER: trying to notify the job_runner thread.
04:43:14 HBMASTER: job (1, 0, 6) submitted to dispatcher
04:43:14 DISPATCHER: Trying to submit another job.
04:43:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:43:14 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:43:14 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:43:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:43:14 WORKER: start processing job (1, 0, 6)
04:43:14 WORKER: args: ()
04:43:14 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 50, 'last_n_outputs': 38, 'lr': 0.017332289313899876, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.02830967791897915}, 'budget': 400.0, 'working_directory': '.'}
04:43:20 DISPATCHER: Starting worker discovery
04:43:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:43:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-456:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:44:20 DISPATCHER: Starting worker discovery
04:44:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:44:20 DISPATCHER: Finished worker discovery
04:45:20 DISPATCHER: Starting worker discovery
04:45:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:45:20 DISPATCHER: Finished worker discovery
04:46:20 DISPATCHER: Starting worker discovery
04:46:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:46:20 DISPATCHER: Finished worker discovery
04:47:20 DISPATCHER: Starting worker discovery
04:47:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:47:20 DISPATCHER: Finished worker discovery
04:48:20 DISPATCHER: Starting worker discovery
04:48:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:48:20 DISPATCHER: Finished worker discovery
04:49:20 DISPATCHER: Starting worker discovery
04:49:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:49:20 DISPATCHER: Finished worker discovery
04:50:20 DISPATCHER: Starting worker discovery
04:50:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:50:20 DISPATCHER: Finished worker discovery
04:50:54 WORKER: done with job (1, 0, 6), trying to register it.
04:50:54 WORKER: registered result for job (1, 0, 6) with dispatcher
04:50:54 DISPATCHER: job (1, 0, 6) finished
04:50:54 DISPATCHER: register_result: lock acquired
04:50:54 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
04:50:54 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 50, 'last_n_outputs': 38, 'lr': 0.017332289313899876, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.02830967791897915}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3743935349207289, 'info': {'sick_no_sick': 0.3743935349207289, 'config': "{'batch_size': 16, 'hidden_dim': 50, 'last_n_outputs': 38, 'lr': 0.017332289313899876, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.02830967791897915}"}}
exception: None

04:50:54 job_callback for (1, 0, 6) started
04:50:54 job_callback for (1, 0, 6) got condition
04:50:54 DISPATCHER: Trying to submit another job.
04:50:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:50:54 Only 5 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
04:50:54 HBMASTER: Trying to run another job!
04:50:54 job_callback for (1, 0, 6) finished
04:50:54 HBMASTER: schedule new run for iteration 1
04:50:54 HBMASTER: trying submitting job (1, 0, 7) to dispatcher
04:50:54 HBMASTER: submitting job (1, 0, 7) to dispatcher
04:50:54 DISPATCHER: trying to submit job (1, 0, 7)
04:50:54 DISPATCHER: trying to notify the job_runner thread.
04:50:54 HBMASTER: job (1, 0, 7) submitted to dispatcher
04:50:54 DISPATCHER: Trying to submit another job.
04:50:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:50:54 DISPATCHER: starting job (1, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:50:54 DISPATCHER: job (1, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:50:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:50:54 WORKER: start processing job (1, 0, 7)
04:50:54 WORKER: args: ()
04:50:54 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 28, 'last_n_outputs': 49, 'lr': 0.01830813791597773, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.056771372898694994}, 'budget': 400.0, 'working_directory': '.'}
04:51:20 DISPATCHER: Starting worker discovery
04:51:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:51:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-457:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:52:20 DISPATCHER: Starting worker discovery
04:52:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:52:21 DISPATCHER: Finished worker discovery
04:53:21 DISPATCHER: Starting worker discovery
04:53:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:53:21 DISPATCHER: Finished worker discovery
04:54:21 DISPATCHER: Starting worker discovery
04:54:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:54:21 DISPATCHER: Finished worker discovery
04:55:21 DISPATCHER: Starting worker discovery
04:55:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:55:21 DISPATCHER: Finished worker discovery
04:56:21 DISPATCHER: Starting worker discovery
04:56:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:56:21 DISPATCHER: Finished worker discovery
04:57:21 DISPATCHER: Starting worker discovery
04:57:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:57:21 DISPATCHER: Finished worker discovery
04:58:21 DISPATCHER: Starting worker discovery
04:58:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:58:21 DISPATCHER: Finished worker discovery
04:58:36 WORKER: done with job (1, 0, 7), trying to register it.
04:58:36 WORKER: registered result for job (1, 0, 7) with dispatcher
04:58:36 DISPATCHER: job (1, 0, 7) finished
04:58:36 DISPATCHER: register_result: lock acquired
04:58:36 DISPATCHER: job (1, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
04:58:36 job_id: (1, 0, 7)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 28, 'last_n_outputs': 49, 'lr': 0.01830813791597773, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.056771372898694994}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.2456605535926447, 'info': {'sick_no_sick': 0.2456605535926447, 'config': "{'batch_size': 32, 'hidden_dim': 28, 'last_n_outputs': 49, 'lr': 0.01830813791597773, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.056771372898694994}"}}
exception: None

04:58:36 job_callback for (1, 0, 7) started
04:58:36 DISPATCHER: Trying to submit another job.
04:58:36 job_callback for (1, 0, 7) got condition
04:58:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:58:36 Only 6 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
04:58:36 HBMASTER: Trying to run another job!
04:58:36 job_callback for (1, 0, 7) finished
04:58:36 ITERATION: Advancing config (1, 0, 3) to next budget 1200.000000
04:58:36 HBMASTER: schedule new run for iteration 1
04:58:36 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
04:58:36 HBMASTER: submitting job (1, 0, 3) to dispatcher
04:58:36 DISPATCHER: trying to submit job (1, 0, 3)
04:58:36 DISPATCHER: trying to notify the job_runner thread.
04:58:36 HBMASTER: job (1, 0, 3) submitted to dispatcher
04:58:36 DISPATCHER: Trying to submit another job.
04:58:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:58:36 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:58:36 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:58:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:58:36 WORKER: start processing job (1, 0, 3)
04:58:36 WORKER: args: ()
04:58:36 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 72, 'last_n_outputs': 50, 'lr': 0.0010957973465645279, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.024211255890964206}, 'budget': 1200.0, 'working_directory': '.'}
04:59:21 DISPATCHER: Starting worker discovery
04:59:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:59:21 DISPATCHER: Finished worker discovery
Exception in thread Thread-458:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:00:21 DISPATCHER: Starting worker discovery
05:00:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:00:21 DISPATCHER: Finished worker discovery
05:01:21 DISPATCHER: Starting worker discovery
05:01:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:01:21 DISPATCHER: Finished worker discovery
05:02:21 DISPATCHER: Starting worker discovery
05:02:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:02:21 DISPATCHER: Finished worker discovery
05:03:21 DISPATCHER: Starting worker discovery
05:03:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:03:21 DISPATCHER: Finished worker discovery
05:04:21 DISPATCHER: Starting worker discovery
05:04:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:04:21 DISPATCHER: Finished worker discovery
05:05:21 DISPATCHER: Starting worker discovery
05:05:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:05:21 DISPATCHER: Finished worker discovery
05:06:21 DISPATCHER: Starting worker discovery
05:06:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:06:21 DISPATCHER: Finished worker discovery
05:07:21 DISPATCHER: Starting worker discovery
05:07:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:07:21 DISPATCHER: Finished worker discovery
05:08:21 DISPATCHER: Starting worker discovery
05:08:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:08:21 DISPATCHER: Finished worker discovery
05:09:21 DISPATCHER: Starting worker discovery
05:09:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:09:21 DISPATCHER: Finished worker discovery
05:10:21 DISPATCHER: Starting worker discovery
05:10:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:10:21 DISPATCHER: Finished worker discovery
05:11:21 DISPATCHER: Starting worker discovery
05:11:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:11:21 DISPATCHER: Finished worker discovery
05:12:21 DISPATCHER: Starting worker discovery
05:12:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:12:21 DISPATCHER: Finished worker discovery
05:13:21 DISPATCHER: Starting worker discovery
05:13:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:13:21 DISPATCHER: Finished worker discovery
05:14:21 DISPATCHER: Starting worker discovery
05:14:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:14:21 DISPATCHER: Finished worker discovery
05:15:21 DISPATCHER: Starting worker discovery
05:15:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:15:21 DISPATCHER: Finished worker discovery
05:16:21 DISPATCHER: Starting worker discovery
05:16:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:16:21 DISPATCHER: Finished worker discovery
05:17:21 DISPATCHER: Starting worker discovery
05:17:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:17:21 DISPATCHER: Finished worker discovery
05:18:21 DISPATCHER: Starting worker discovery
05:18:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:18:21 DISPATCHER: Finished worker discovery
05:19:21 DISPATCHER: Starting worker discovery
05:19:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:19:21 DISPATCHER: Finished worker discovery
05:19:37 WORKER: done with job (1, 0, 3), trying to register it.
05:19:37 WORKER: registered result for job (1, 0, 3) with dispatcher
05:19:37 DISPATCHER: job (1, 0, 3) finished
05:19:37 DISPATCHER: register_result: lock acquired
05:19:37 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
05:19:37 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 72, 'last_n_outputs': 50, 'lr': 0.0010957973465645279, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.024211255890964206}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.4638689395257561, 'info': {'sick_no_sick': 0.4638689395257561, 'config': "{'batch_size': 128, 'hidden_dim': 72, 'last_n_outputs': 50, 'lr': 0.0010957973465645279, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.024211255890964206}"}}
exception: None

05:19:37 job_callback for (1, 0, 3) started
05:19:37 job_callback for (1, 0, 3) got condition
05:19:37 DISPATCHER: Trying to submit another job.
05:19:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:19:37 Only 2 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
05:19:37 HBMASTER: Trying to run another job!
05:19:37 job_callback for (1, 0, 3) finished
05:19:37 start sampling a new configuration.
05:19:37 done sampling a new configuration.
05:19:37 HBMASTER: schedule new run for iteration 2
05:19:37 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
05:19:37 HBMASTER: submitting job (2, 0, 0) to dispatcher
05:19:37 DISPATCHER: trying to submit job (2, 0, 0)
05:19:37 DISPATCHER: trying to notify the job_runner thread.
05:19:37 HBMASTER: job (2, 0, 0) submitted to dispatcher
05:19:37 DISPATCHER: Trying to submit another job.
05:19:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:19:37 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
05:19:37 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
05:19:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:19:37 WORKER: start processing job (2, 0, 0)
05:19:37 WORKER: args: ()
05:19:37 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 96, 'last_n_outputs': 18, 'lr': 0.03049460468884283, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.03235490896896981}, 'budget': 400.0, 'working_directory': '.'}
05:20:21 DISPATCHER: Starting worker discovery
05:20:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:20:21 DISPATCHER: Finished worker discovery
Exception in thread Thread-459:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:21:21 DISPATCHER: Starting worker discovery
05:21:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:21:21 DISPATCHER: Finished worker discovery
05:22:21 DISPATCHER: Starting worker discovery
05:22:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:22:21 DISPATCHER: Finished worker discovery
05:23:21 DISPATCHER: Starting worker discovery
05:23:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:23:21 DISPATCHER: Finished worker discovery
05:24:21 DISPATCHER: Starting worker discovery
05:24:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:24:21 DISPATCHER: Finished worker discovery
05:25:21 DISPATCHER: Starting worker discovery
05:25:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:25:21 DISPATCHER: Finished worker discovery
05:26:21 DISPATCHER: Starting worker discovery
05:26:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:26:21 DISPATCHER: Finished worker discovery
05:27:19 WORKER: done with job (2, 0, 0), trying to register it.
05:27:19 WORKER: registered result for job (2, 0, 0) with dispatcher
05:27:19 DISPATCHER: job (2, 0, 0) finished
05:27:19 DISPATCHER: register_result: lock acquired
05:27:19 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
05:27:19 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 96, 'last_n_outputs': 18, 'lr': 0.03049460468884283, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.03235490896896981}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': 0.0004162659024929907, 'info': {'sick_no_sick': -0.0004162659024929907, 'config': "{'batch_size': 64, 'hidden_dim': 96, 'last_n_outputs': 18, 'lr': 0.03049460468884283, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.03235490896896981}"}}
exception: None

05:27:19 job_callback for (2, 0, 0) started
05:27:19 job_callback for (2, 0, 0) got condition
05:27:19 DISPATCHER: Trying to submit another job.
05:27:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:27:19 Only 7 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
05:27:19 HBMASTER: Trying to run another job!
05:27:19 job_callback for (2, 0, 0) finished
05:27:19 start sampling a new configuration.
05:27:19 best_vector: [0, 0.029378533723189854, 0.5732298298789125, 0.9537090440812861, 0.06413843760960783, 0, 0.4676155445674196, 0.816444002530345], 4.7017227162033635e-32, 0.21268799977372954, -0.01437966383171956
05:27:19 done sampling a new configuration.
05:27:19 HBMASTER: schedule new run for iteration 2
05:27:19 HBMASTER: trying submitting job (2, 0, 1) to dispatcher
05:27:19 HBMASTER: submitting job (2, 0, 1) to dispatcher
05:27:19 DISPATCHER: trying to submit job (2, 0, 1)
05:27:19 DISPATCHER: trying to notify the job_runner thread.
05:27:19 HBMASTER: job (2, 0, 1) submitted to dispatcher
05:27:19 DISPATCHER: Trying to submit another job.
05:27:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:27:19 DISPATCHER: starting job (2, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
05:27:19 DISPATCHER: job (2, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
05:27:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:27:19 WORKER: start processing job (2, 0, 1)
05:27:19 WORKER: args: ()
05:27:19 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 22, 'last_n_outputs': 29, 'lr': 0.08080125163266412, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.11540327588896247}, 'budget': 400.0, 'working_directory': '.'}
05:27:21 DISPATCHER: Starting worker discovery
05:27:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:27:21 DISPATCHER: Finished worker discovery
05:28:21 DISPATCHER: Starting worker discovery
05:28:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:28:21 DISPATCHER: Finished worker discovery
Exception in thread Thread-460:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:29:21 DISPATCHER: Starting worker discovery
05:29:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:29:21 DISPATCHER: Finished worker discovery
05:30:21 DISPATCHER: Starting worker discovery
05:30:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:30:21 DISPATCHER: Finished worker discovery
05:31:21 DISPATCHER: Starting worker discovery
05:31:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:31:21 DISPATCHER: Finished worker discovery
05:32:21 DISPATCHER: Starting worker discovery
05:32:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:32:21 DISPATCHER: Finished worker discovery
05:33:21 DISPATCHER: Starting worker discovery
05:33:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:33:21 DISPATCHER: Finished worker discovery
05:34:21 DISPATCHER: Starting worker discovery
05:34:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:34:21 DISPATCHER: Finished worker discovery
05:35:00 WORKER: done with job (2, 0, 1), trying to register it.
05:35:00 WORKER: registered result for job (2, 0, 1) with dispatcher
05:35:00 DISPATCHER: job (2, 0, 1) finished
05:35:00 DISPATCHER: register_result: lock acquired
05:35:00 DISPATCHER: job (2, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
05:35:00 job_id: (2, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 22, 'last_n_outputs': 29, 'lr': 0.08080125163266412, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.11540327588896247}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0314487042520139, 'info': {'sick_no_sick': 0.0314487042520139, 'config': "{'batch_size': 16, 'hidden_dim': 22, 'last_n_outputs': 29, 'lr': 0.08080125163266412, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.11540327588896247}"}}
exception: None

05:35:00 job_callback for (2, 0, 1) started
05:35:00 job_callback for (2, 0, 1) got condition
05:35:00 DISPATCHER: Trying to submit another job.
05:35:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:35:00 Only 8 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
05:35:00 HBMASTER: Trying to run another job!
05:35:00 job_callback for (2, 0, 1) finished
05:35:00 start sampling a new configuration.
05:35:00 best_vector: [0, 0.28310038495977563, 0.39291499089872717, 0.7540075811843391, 0.32721196230817473, 0, 0.5070404458807525, 0.09281668705368346], 7.30002125000095e-30, 0.0013698590260951223, -0.024899015650119746
05:35:00 done sampling a new configuration.
05:35:00 HBMASTER: schedule new run for iteration 2
05:35:00 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
05:35:00 HBMASTER: submitting job (2, 0, 2) to dispatcher
05:35:00 DISPATCHER: trying to submit job (2, 0, 2)
05:35:00 DISPATCHER: trying to notify the job_runner thread.
05:35:00 HBMASTER: job (2, 0, 2) submitted to dispatcher
05:35:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:35:00 DISPATCHER: Trying to submit another job.
05:35:00 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
05:35:00 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
05:35:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:35:00 WORKER: start processing job (2, 0, 2)
05:35:00 WORKER: args: ()
05:35:00 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 42, 'last_n_outputs': 20, 'lr': 0.03221181249274837, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.013205574326673752}, 'budget': 400.0, 'working_directory': '.'}
05:35:21 DISPATCHER: Starting worker discovery
05:35:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:35:21 DISPATCHER: Finished worker discovery
Exception in thread Thread-461:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:36:21 DISPATCHER: Starting worker discovery
05:36:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:36:21 DISPATCHER: Finished worker discovery
05:37:21 DISPATCHER: Starting worker discovery
05:37:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:37:21 DISPATCHER: Finished worker discovery
05:38:21 DISPATCHER: Starting worker discovery
05:38:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:38:21 DISPATCHER: Finished worker discovery
05:39:21 DISPATCHER: Starting worker discovery
05:39:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:39:21 DISPATCHER: Finished worker discovery
05:40:21 DISPATCHER: Starting worker discovery
05:40:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:40:21 DISPATCHER: Finished worker discovery
05:41:21 DISPATCHER: Starting worker discovery
05:41:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:41:21 DISPATCHER: Finished worker discovery
05:42:21 DISPATCHER: Starting worker discovery
05:42:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:42:21 DISPATCHER: Finished worker discovery
05:42:40 WORKER: done with job (2, 0, 2), trying to register it.
05:42:40 WORKER: registered result for job (2, 0, 2) with dispatcher
05:42:40 DISPATCHER: job (2, 0, 2) finished
05:42:40 DISPATCHER: register_result: lock acquired
05:42:40 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
05:42:40 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 42, 'last_n_outputs': 20, 'lr': 0.03221181249274837, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.013205574326673752}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.23079258872222205, 'info': {'sick_no_sick': 0.23079258872222205, 'config': "{'batch_size': 16, 'hidden_dim': 42, 'last_n_outputs': 20, 'lr': 0.03221181249274837, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.013205574326673752}"}}
exception: None

05:42:40 job_callback for (2, 0, 2) started
05:42:40 DISPATCHER: Trying to submit another job.
05:42:40 job_callback for (2, 0, 2) got condition
05:42:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:42:40 HBMASTER: Trying to run another job!
05:42:40 job_callback for (2, 0, 2) finished
05:42:40 start sampling a new configuration.
05:42:40 best_vector: [0, 0.45961676952493546, 0.058731251681804486, 0.7566959939705553, 0.25787487579302026, 0, 0.5257951087031941, 0.8042682415518935], 3.471210380121166e-33, 2.8808395069534622, -9.885388259516012e-08
05:42:40 done sampling a new configuration.
05:42:40 HBMASTER: schedule new run for iteration 2
05:42:40 HBMASTER: trying submitting job (2, 0, 3) to dispatcher
05:42:40 HBMASTER: submitting job (2, 0, 3) to dispatcher
05:42:40 DISPATCHER: trying to submit job (2, 0, 3)
05:42:40 DISPATCHER: trying to notify the job_runner thread.
05:42:40 HBMASTER: job (2, 0, 3) submitted to dispatcher
05:42:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:42:40 DISPATCHER: Trying to submit another job.
05:42:40 DISPATCHER: starting job (2, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
05:42:40 DISPATCHER: job (2, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
05:42:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:42:40 WORKER: start processing job (2, 0, 3)
05:42:40 WORKER: args: ()
05:42:40 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 57, 'last_n_outputs': 3, 'lr': 0.03261309292760981, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.11126974860084733}, 'budget': 400.0, 'working_directory': '.'}
05:43:21 DISPATCHER: Starting worker discovery
05:43:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:43:21 DISPATCHER: Finished worker discovery
Exception in thread Thread-462:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:44:21 DISPATCHER: Starting worker discovery
05:44:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:44:21 DISPATCHER: Finished worker discovery
05:45:21 DISPATCHER: Starting worker discovery
05:45:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:45:21 DISPATCHER: Finished worker discovery
05:46:21 DISPATCHER: Starting worker discovery
05:46:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:46:21 DISPATCHER: Finished worker discovery
05:47:21 DISPATCHER: Starting worker discovery
05:47:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:47:21 DISPATCHER: Finished worker discovery
05:48:21 DISPATCHER: Starting worker discovery
05:48:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:48:21 DISPATCHER: Finished worker discovery
05:49:21 DISPATCHER: Starting worker discovery
05:49:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:49:21 DISPATCHER: Finished worker discovery
05:50:21 DISPATCHER: Starting worker discovery
05:50:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:50:21 DISPATCHER: Finished worker discovery
05:50:22 WORKER: done with job (2, 0, 3), trying to register it.
05:50:22 WORKER: registered result for job (2, 0, 3) with dispatcher
05:50:22 DISPATCHER: job (2, 0, 3) finished
05:50:22 DISPATCHER: register_result: lock acquired
05:50:22 DISPATCHER: job (2, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
05:50:22 job_id: (2, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 57, 'last_n_outputs': 3, 'lr': 0.03261309292760981, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.11126974860084733}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.002125565370820597, 'info': {'sick_no_sick': 0.002125565370820597, 'config': "{'batch_size': 16, 'hidden_dim': 57, 'last_n_outputs': 3, 'lr': 0.03261309292760981, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.11126974860084733}"}}
exception: None

05:50:22 job_callback for (2, 0, 3) started
05:50:22 DISPATCHER: Trying to submit another job.
05:50:22 job_callback for (2, 0, 3) got condition
05:50:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:50:22 HBMASTER: Trying to run another job!
05:50:22 job_callback for (2, 0, 3) finished
05:50:22 start sampling a new configuration.
05:50:22 best_vector: [0, 0.6027571247842869, 0.9057955647519935, 0.10545570961328599, 0.10263064682090431, 0, 0.6676537239648948, 0.6354456911257127], 1.5969197127227885e-33, 6.262055581335237, -0.09674632386199955
05:50:22 done sampling a new configuration.
05:50:22 HBMASTER: schedule new run for iteration 2
05:50:22 HBMASTER: trying submitting job (2, 0, 4) to dispatcher
05:50:22 HBMASTER: submitting job (2, 0, 4) to dispatcher
05:50:22 DISPATCHER: trying to submit job (2, 0, 4)
05:50:22 DISPATCHER: trying to notify the job_runner thread.
05:50:22 HBMASTER: job (2, 0, 4) submitted to dispatcher
05:50:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:50:22 DISPATCHER: Trying to submit another job.
05:50:22 DISPATCHER: starting job (2, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776
05:50:22 DISPATCHER: job (2, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
05:50:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:50:22 WORKER: start processing job (2, 0, 4)
05:50:22 WORKER: args: ()
05:50:22 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 68, 'last_n_outputs': 46, 'lr': 0.001625217234885398, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.06710175898329554}, 'budget': 400.0, 'working_directory': '.'}
05:51:21 DISPATCHER: Starting worker discovery
05:51:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:51:21 DISPATCHER: Finished worker discovery
Exception in thread Thread-463:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:52:21 DISPATCHER: Starting worker discovery
05:52:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:52:21 DISPATCHER: Finished worker discovery
05:53:21 DISPATCHER: Starting worker discovery
05:53:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:53:21 DISPATCHER: Finished worker discovery
05:54:21 DISPATCHER: Starting worker discovery
05:54:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:54:21 DISPATCHER: Finished worker discovery
05:55:21 DISPATCHER: Starting worker discovery
05:55:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:55:21 DISPATCHER: Finished worker discovery
05:56:21 DISPATCHER: Starting worker discovery
05:56:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:56:21 DISPATCHER: Finished worker discovery
05:57:21 DISPATCHER: Starting worker discovery
05:57:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:57:21 DISPATCHER: Finished worker discovery
05:58:03 WORKER: done with job (2, 0, 4), trying to register it.
05:58:03 WORKER: registered result for job (2, 0, 4) with dispatcher
05:58:03 DISPATCHER: job (2, 0, 4) finished
05:58:03 DISPATCHER: register_result: lock acquired
05:58:03 DISPATCHER: job (2, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
05:58:03 job_id: (2, 0, 4)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 68, 'last_n_outputs': 46, 'lr': 0.001625217234885398, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.06710175898329554}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.375686618029856, 'info': {'sick_no_sick': 0.375686618029856, 'config': "{'batch_size': 16, 'hidden_dim': 68, 'last_n_outputs': 46, 'lr': 0.001625217234885398, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.06710175898329554}"}}
exception: None

05:58:03 job_callback for (2, 0, 4) started
05:58:03 DISPATCHER: Trying to submit another job.
05:58:03 job_callback for (2, 0, 4) got condition
05:58:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:58:03 HBMASTER: Trying to run another job!
05:58:03 job_callback for (2, 0, 4) finished
05:58:03 start sampling a new configuration.
05:58:03 best_vector: [0, 0.10930700521808921, 0.4821500863295851, 0.9405153558891117, 0.11819757292934915, 0, 0.38603764060026735, 0.5448875617283852], 5.289952933697945e-32, 0.1890375987335958, -0.0029559333857402496
05:58:03 done sampling a new configuration.
05:58:03 HBMASTER: schedule new run for iteration 2
05:58:03 HBMASTER: trying submitting job (2, 0, 5) to dispatcher
05:58:03 HBMASTER: submitting job (2, 0, 5) to dispatcher
05:58:03 DISPATCHER: trying to submit job (2, 0, 5)
05:58:03 DISPATCHER: trying to notify the job_runner thread.
05:58:03 HBMASTER: job (2, 0, 5) submitted to dispatcher
05:58:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:58:03 DISPATCHER: Trying to submit another job.
05:58:03 DISPATCHER: starting job (2, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776
05:58:03 DISPATCHER: job (2, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
05:58:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:58:03 WORKER: start processing job (2, 0, 5)
05:58:03 WORKER: args: ()
05:58:03 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 28, 'last_n_outputs': 25, 'lr': 0.07603800464413774, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.05115817722271316}, 'budget': 400.0, 'working_directory': '.'}
05:58:21 DISPATCHER: Starting worker discovery
05:58:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:58:21 DISPATCHER: Finished worker discovery
Exception in thread Thread-464:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:59:21 DISPATCHER: Starting worker discovery
05:59:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:59:21 DISPATCHER: Finished worker discovery
06:00:21 DISPATCHER: Starting worker discovery
06:00:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:00:21 DISPATCHER: Finished worker discovery
06:01:21 DISPATCHER: Starting worker discovery
06:01:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:01:21 DISPATCHER: Finished worker discovery
06:02:21 DISPATCHER: Starting worker discovery
06:02:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:02:21 DISPATCHER: Finished worker discovery
06:03:21 DISPATCHER: Starting worker discovery
06:03:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:03:21 DISPATCHER: Finished worker discovery
06:04:21 DISPATCHER: Starting worker discovery
06:04:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:04:21 DISPATCHER: Finished worker discovery
06:05:21 DISPATCHER: Starting worker discovery
06:05:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:05:21 DISPATCHER: Finished worker discovery
06:05:45 WORKER: done with job (2, 0, 5), trying to register it.
06:05:45 WORKER: registered result for job (2, 0, 5) with dispatcher
06:05:45 DISPATCHER: job (2, 0, 5) finished
06:05:45 DISPATCHER: register_result: lock acquired
06:05:45 DISPATCHER: job (2, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
06:05:45 job_id: (2, 0, 5)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 28, 'last_n_outputs': 25, 'lr': 0.07603800464413774, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.05115817722271316}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.09761166943503055, 'info': {'sick_no_sick': 0.09761166943503055, 'config': "{'batch_size': 16, 'hidden_dim': 28, 'last_n_outputs': 25, 'lr': 0.07603800464413774, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.05115817722271316}"}}
exception: None

06:05:45 job_callback for (2, 0, 5) started
06:05:45 job_callback for (2, 0, 5) got condition
06:05:45 DISPATCHER: Trying to submit another job.
06:05:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:05:45 HBMASTER: Trying to run another job!
06:05:45 job_callback for (2, 0, 5) finished
06:05:45 ITERATION: Advancing config (2, 0, 2) to next budget 1200.000000
06:05:45 ITERATION: Advancing config (2, 0, 4) to next budget 1200.000000
06:05:45 HBMASTER: schedule new run for iteration 2
06:05:45 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
06:05:45 HBMASTER: submitting job (2, 0, 2) to dispatcher
06:05:45 DISPATCHER: trying to submit job (2, 0, 2)
06:05:45 DISPATCHER: trying to notify the job_runner thread.
06:05:45 HBMASTER: job (2, 0, 2) submitted to dispatcher
06:05:45 DISPATCHER: Trying to submit another job.
06:05:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:05:45 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:05:45 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:05:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:05:45 WORKER: start processing job (2, 0, 2)
06:05:45 WORKER: args: ()
06:05:45 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 42, 'last_n_outputs': 20, 'lr': 0.03221181249274837, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.013205574326673752}, 'budget': 1200.0, 'working_directory': '.'}
06:06:21 DISPATCHER: Starting worker discovery
06:06:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:06:21 DISPATCHER: Finished worker discovery
Exception in thread Thread-465:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:07:21 DISPATCHER: Starting worker discovery
06:07:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:07:21 DISPATCHER: Finished worker discovery
06:08:21 DISPATCHER: Starting worker discovery
06:08:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:08:21 DISPATCHER: Finished worker discovery
06:09:21 DISPATCHER: Starting worker discovery
06:09:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:09:21 DISPATCHER: Finished worker discovery
06:10:21 DISPATCHER: Starting worker discovery
06:10:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:10:21 DISPATCHER: Finished worker discovery
06:11:21 DISPATCHER: Starting worker discovery
06:11:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:11:21 DISPATCHER: Finished worker discovery
06:12:21 DISPATCHER: Starting worker discovery
06:12:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:12:21 DISPATCHER: Finished worker discovery
06:13:21 DISPATCHER: Starting worker discovery
06:13:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:13:21 DISPATCHER: Finished worker discovery
06:14:21 DISPATCHER: Starting worker discovery
06:14:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:14:21 DISPATCHER: Finished worker discovery
06:15:21 DISPATCHER: Starting worker discovery
06:15:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:15:21 DISPATCHER: Finished worker discovery
06:16:21 DISPATCHER: Starting worker discovery
06:16:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:16:21 DISPATCHER: Finished worker discovery
06:17:21 DISPATCHER: Starting worker discovery
06:17:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:17:21 DISPATCHER: Finished worker discovery
06:18:21 DISPATCHER: Starting worker discovery
06:18:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:18:21 DISPATCHER: Finished worker discovery
06:19:21 DISPATCHER: Starting worker discovery
06:19:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:19:21 DISPATCHER: Finished worker discovery
06:20:21 DISPATCHER: Starting worker discovery
06:20:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:20:21 DISPATCHER: Finished worker discovery
06:21:21 DISPATCHER: Starting worker discovery
06:21:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:21:21 DISPATCHER: Finished worker discovery
06:22:21 DISPATCHER: Starting worker discovery
06:22:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:22:21 DISPATCHER: Finished worker discovery
06:23:21 DISPATCHER: Starting worker discovery
06:23:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:23:21 DISPATCHER: Finished worker discovery
06:24:21 DISPATCHER: Starting worker discovery
06:24:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:24:21 DISPATCHER: Finished worker discovery
06:25:21 DISPATCHER: Starting worker discovery
06:25:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:25:21 DISPATCHER: Finished worker discovery
06:26:21 DISPATCHER: Starting worker discovery
06:26:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:26:21 DISPATCHER: Finished worker discovery
06:26:46 WORKER: done with job (2, 0, 2), trying to register it.
06:26:46 WORKER: registered result for job (2, 0, 2) with dispatcher
06:26:46 DISPATCHER: job (2, 0, 2) finished
06:26:46 DISPATCHER: register_result: lock acquired
06:26:46 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
06:26:46 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 42, 'last_n_outputs': 20, 'lr': 0.03221181249274837, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.013205574326673752}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.23213233967971555, 'info': {'sick_no_sick': 0.23213233967971555, 'config': "{'batch_size': 16, 'hidden_dim': 42, 'last_n_outputs': 20, 'lr': 0.03221181249274837, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.013205574326673752}"}}
exception: None

06:26:46 job_callback for (2, 0, 2) started
06:26:46 DISPATCHER: Trying to submit another job.
06:26:46 job_callback for (2, 0, 2) got condition
06:26:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:26:46 Only 3 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
06:26:46 HBMASTER: Trying to run another job!
06:26:46 job_callback for (2, 0, 2) finished
06:26:46 HBMASTER: schedule new run for iteration 2
06:26:46 HBMASTER: trying submitting job (2, 0, 4) to dispatcher
06:26:46 HBMASTER: submitting job (2, 0, 4) to dispatcher
06:26:46 DISPATCHER: trying to submit job (2, 0, 4)
06:26:46 DISPATCHER: trying to notify the job_runner thread.
06:26:46 HBMASTER: job (2, 0, 4) submitted to dispatcher
06:26:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:26:46 DISPATCHER: Trying to submit another job.
06:26:46 DISPATCHER: starting job (2, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:26:46 DISPATCHER: job (2, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:26:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:26:46 WORKER: start processing job (2, 0, 4)
06:26:46 WORKER: args: ()
06:26:46 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 68, 'last_n_outputs': 46, 'lr': 0.001625217234885398, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.06710175898329554}, 'budget': 1200.0, 'working_directory': '.'}
06:27:21 DISPATCHER: Starting worker discovery
06:27:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:27:21 DISPATCHER: Finished worker discovery
Exception in thread Thread-466:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:28:21 DISPATCHER: Starting worker discovery
06:28:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:28:21 DISPATCHER: Finished worker discovery
06:29:21 DISPATCHER: Starting worker discovery
06:29:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:29:21 DISPATCHER: Finished worker discovery
06:30:21 DISPATCHER: Starting worker discovery
06:30:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:30:21 DISPATCHER: Finished worker discovery
06:31:21 DISPATCHER: Starting worker discovery
06:31:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:31:21 DISPATCHER: Finished worker discovery
06:32:21 DISPATCHER: Starting worker discovery
06:32:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:32:21 DISPATCHER: Finished worker discovery
06:33:21 DISPATCHER: Starting worker discovery
06:33:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:33:21 DISPATCHER: Finished worker discovery
06:34:21 DISPATCHER: Starting worker discovery
06:34:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:34:21 DISPATCHER: Finished worker discovery
06:35:21 DISPATCHER: Starting worker discovery
06:35:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:35:21 DISPATCHER: Finished worker discovery
06:36:21 DISPATCHER: Starting worker discovery
06:36:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:36:21 DISPATCHER: Finished worker discovery
06:37:21 DISPATCHER: Starting worker discovery
06:37:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:37:21 DISPATCHER: Finished worker discovery
06:38:21 DISPATCHER: Starting worker discovery
06:38:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:38:21 DISPATCHER: Finished worker discovery
06:39:21 DISPATCHER: Starting worker discovery
06:39:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:39:21 DISPATCHER: Finished worker discovery
06:40:21 DISPATCHER: Starting worker discovery
06:40:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:40:21 DISPATCHER: Finished worker discovery
06:41:21 DISPATCHER: Starting worker discovery
06:41:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:41:21 DISPATCHER: Finished worker discovery
06:42:21 DISPATCHER: Starting worker discovery
06:42:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:42:21 DISPATCHER: Finished worker discovery
06:43:21 DISPATCHER: Starting worker discovery
06:43:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:43:21 DISPATCHER: Finished worker discovery
06:44:21 DISPATCHER: Starting worker discovery
06:44:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:44:21 DISPATCHER: Finished worker discovery
06:45:21 DISPATCHER: Starting worker discovery
06:45:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:45:21 DISPATCHER: Finished worker discovery
06:46:21 DISPATCHER: Starting worker discovery
06:46:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:46:21 DISPATCHER: Finished worker discovery
06:47:21 DISPATCHER: Starting worker discovery
06:47:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:47:21 DISPATCHER: Finished worker discovery
06:47:48 WORKER: done with job (2, 0, 4), trying to register it.
06:47:48 WORKER: registered result for job (2, 0, 4) with dispatcher
06:47:48 DISPATCHER: job (2, 0, 4) finished
06:47:48 DISPATCHER: register_result: lock acquired
06:47:48 DISPATCHER: job (2, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
06:47:48 job_id: (2, 0, 4)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 68, 'last_n_outputs': 46, 'lr': 0.001625217234885398, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.06710175898329554}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.43045407271869485, 'info': {'sick_no_sick': 0.43045407271869485, 'config': "{'batch_size': 16, 'hidden_dim': 68, 'last_n_outputs': 46, 'lr': 0.001625217234885398, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.06710175898329554}"}}
exception: None

06:47:48 job_callback for (2, 0, 4) started
06:47:48 DISPATCHER: Trying to submit another job.
06:47:48 job_callback for (2, 0, 4) got condition
06:47:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:47:48 Only 4 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
06:47:48 HBMASTER: Trying to run another job!
06:47:48 job_callback for (2, 0, 4) finished
06:47:48 start sampling a new configuration.
06:47:48 done sampling a new configuration.
06:47:48 HBMASTER: schedule new run for iteration 3
06:47:48 HBMASTER: trying submitting job (3, 0, 0) to dispatcher
06:47:48 HBMASTER: submitting job (3, 0, 0) to dispatcher
06:47:48 DISPATCHER: trying to submit job (3, 0, 0)
06:47:48 DISPATCHER: trying to notify the job_runner thread.
06:47:48 HBMASTER: job (3, 0, 0) submitted to dispatcher
06:47:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:47:48 DISPATCHER: Trying to submit another job.
06:47:48 DISPATCHER: starting job (3, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:47:48 DISPATCHER: job (3, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:47:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:47:48 WORKER: start processing job (3, 0, 0)
06:47:48 WORKER: args: ()
06:47:48 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 91, 'last_n_outputs': 1, 'lr': 0.02912031112894439, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.04719714729780494}, 'budget': 1200.0, 'working_directory': '.'}
06:48:21 DISPATCHER: Starting worker discovery
06:48:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:48:21 DISPATCHER: Finished worker discovery
Exception in thread Thread-467:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:49:21 DISPATCHER: Starting worker discovery
06:49:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:49:21 DISPATCHER: Finished worker discovery
06:50:21 DISPATCHER: Starting worker discovery
06:50:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:50:21 DISPATCHER: Finished worker discovery
06:51:21 DISPATCHER: Starting worker discovery
06:51:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:51:21 DISPATCHER: Finished worker discovery
06:52:21 DISPATCHER: Starting worker discovery
06:52:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:52:21 DISPATCHER: Finished worker discovery
06:53:21 DISPATCHER: Starting worker discovery
06:53:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:53:21 DISPATCHER: Finished worker discovery
06:54:21 DISPATCHER: Starting worker discovery
06:54:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:54:21 DISPATCHER: Finished worker discovery
06:55:21 DISPATCHER: Starting worker discovery
06:55:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:55:21 DISPATCHER: Finished worker discovery
06:56:21 DISPATCHER: Starting worker discovery
06:56:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:56:21 DISPATCHER: Finished worker discovery
06:57:21 DISPATCHER: Starting worker discovery
06:57:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:57:21 DISPATCHER: Finished worker discovery
06:58:21 DISPATCHER: Starting worker discovery
06:58:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:58:21 DISPATCHER: Finished worker discovery
06:59:21 DISPATCHER: Starting worker discovery
06:59:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:59:21 DISPATCHER: Finished worker discovery
07:00:21 DISPATCHER: Starting worker discovery
07:00:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:00:21 DISPATCHER: Finished worker discovery
07:01:21 DISPATCHER: Starting worker discovery
07:01:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:01:21 DISPATCHER: Finished worker discovery
07:02:21 DISPATCHER: Starting worker discovery
07:02:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:02:21 DISPATCHER: Finished worker discovery
07:03:21 DISPATCHER: Starting worker discovery
07:03:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:03:21 DISPATCHER: Finished worker discovery
07:04:21 DISPATCHER: Starting worker discovery
07:04:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:04:21 DISPATCHER: Finished worker discovery
07:05:21 DISPATCHER: Starting worker discovery
07:05:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:05:21 DISPATCHER: Finished worker discovery
07:06:21 DISPATCHER: Starting worker discovery
07:06:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:06:21 DISPATCHER: Finished worker discovery
07:07:21 DISPATCHER: Starting worker discovery
07:07:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:07:21 DISPATCHER: Finished worker discovery
07:08:21 DISPATCHER: Starting worker discovery
07:08:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:08:21 DISPATCHER: Finished worker discovery
07:08:47 WORKER: done with job (3, 0, 0), trying to register it.
07:08:47 WORKER: registered result for job (3, 0, 0) with dispatcher
07:08:47 DISPATCHER: job (3, 0, 0) finished
07:08:47 DISPATCHER: register_result: lock acquired
07:08:47 DISPATCHER: job (3, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
07:08:47 job_id: (3, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 91, 'last_n_outputs': 1, 'lr': 0.02912031112894439, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.04719714729780494}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 91, 'last_n_outputs': 1, 'lr': 0.02912031112894439, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.04719714729780494}"}}
exception: None

07:08:47 job_callback for (3, 0, 0) started
07:08:47 job_callback for (3, 0, 0) got condition
07:08:47 DISPATCHER: Trying to submit another job.
07:08:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:08:47 Only 5 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
07:08:47 HBMASTER: Trying to run another job!
07:08:47 job_callback for (3, 0, 0) finished
07:08:47 start sampling a new configuration.
07:08:47 done sampling a new configuration.
07:08:47 HBMASTER: schedule new run for iteration 3
07:08:47 HBMASTER: trying submitting job (3, 0, 1) to dispatcher
07:08:47 HBMASTER: submitting job (3, 0, 1) to dispatcher
07:08:47 DISPATCHER: trying to submit job (3, 0, 1)
07:08:47 DISPATCHER: trying to notify the job_runner thread.
07:08:47 HBMASTER: job (3, 0, 1) submitted to dispatcher
07:08:47 DISPATCHER: Trying to submit another job.
07:08:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:08:47 DISPATCHER: starting job (3, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:08:47 DISPATCHER: job (3, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:08:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:08:47 WORKER: start processing job (3, 0, 1)
07:08:47 WORKER: args: ()
07:08:47 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 62, 'last_n_outputs': 42, 'lr': 0.002474037082201975, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.06660204815900524}, 'budget': 1200.0, 'working_directory': '.'}
07:09:21 DISPATCHER: Starting worker discovery
07:09:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:09:21 DISPATCHER: Finished worker discovery
Exception in thread Thread-468:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:10:21 DISPATCHER: Starting worker discovery
07:10:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:10:21 DISPATCHER: Finished worker discovery
07:11:21 DISPATCHER: Starting worker discovery
07:11:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:11:21 DISPATCHER: Finished worker discovery
07:12:21 DISPATCHER: Starting worker discovery
07:12:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:12:21 DISPATCHER: Finished worker discovery
07:13:21 DISPATCHER: Starting worker discovery
07:13:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:13:21 DISPATCHER: Finished worker discovery
07:14:21 DISPATCHER: Starting worker discovery
07:14:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:14:21 DISPATCHER: Finished worker discovery
07:15:21 DISPATCHER: Starting worker discovery
07:15:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:15:21 DISPATCHER: Finished worker discovery
07:16:21 DISPATCHER: Starting worker discovery
07:16:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:16:21 DISPATCHER: Finished worker discovery
07:17:21 DISPATCHER: Starting worker discovery
07:17:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:17:21 DISPATCHER: Finished worker discovery
07:18:21 DISPATCHER: Starting worker discovery
07:18:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:18:21 DISPATCHER: Finished worker discovery
07:19:21 DISPATCHER: Starting worker discovery
07:19:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:19:21 DISPATCHER: Finished worker discovery
07:20:21 DISPATCHER: Starting worker discovery
07:20:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:20:21 DISPATCHER: Finished worker discovery
07:21:21 DISPATCHER: Starting worker discovery
07:21:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:21:21 DISPATCHER: Finished worker discovery
07:22:21 DISPATCHER: Starting worker discovery
07:22:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:22:21 DISPATCHER: Finished worker discovery
07:23:21 DISPATCHER: Starting worker discovery
07:23:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:23:21 DISPATCHER: Finished worker discovery
07:24:21 DISPATCHER: Starting worker discovery
07:24:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:24:21 DISPATCHER: Finished worker discovery
07:25:21 DISPATCHER: Starting worker discovery
07:25:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:25:21 DISPATCHER: Finished worker discovery
07:26:21 DISPATCHER: Starting worker discovery
07:26:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:26:22 DISPATCHER: Finished worker discovery
07:27:22 DISPATCHER: Starting worker discovery
07:27:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:27:22 DISPATCHER: Finished worker discovery
07:28:22 DISPATCHER: Starting worker discovery
07:28:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:28:22 DISPATCHER: Finished worker discovery
07:29:22 DISPATCHER: Starting worker discovery
07:29:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:29:22 DISPATCHER: Finished worker discovery
07:29:48 WORKER: done with job (3, 0, 1), trying to register it.
07:29:48 WORKER: registered result for job (3, 0, 1) with dispatcher
07:29:48 DISPATCHER: job (3, 0, 1) finished
07:29:48 DISPATCHER: register_result: lock acquired
07:29:48 DISPATCHER: job (3, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
07:29:48 job_id: (3, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 62, 'last_n_outputs': 42, 'lr': 0.002474037082201975, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.06660204815900524}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 62, 'last_n_outputs': 42, 'lr': 0.002474037082201975, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.06660204815900524}"}}
exception: None

07:29:48 job_callback for (3, 0, 1) started
07:29:48 DISPATCHER: Trying to submit another job.
07:29:48 job_callback for (3, 0, 1) got condition
07:29:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:29:48 Only 6 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
07:29:48 HBMASTER: Trying to run another job!
07:29:48 job_callback for (3, 0, 1) finished
07:29:48 start sampling a new configuration.
07:29:48 best_vector: [2, 0.634140787606297, 0.9619620291934069, 0.7149490251617742, 0.11822804429482384, 0, 0.7513386136699401, 0.19213318505619748], 4.40666019494049e-33, 2.2692922888589204, -0.6452368383078579
07:29:48 done sampling a new configuration.
07:29:48 HBMASTER: schedule new run for iteration 3
07:29:48 HBMASTER: trying submitting job (3, 0, 2) to dispatcher
07:29:48 HBMASTER: submitting job (3, 0, 2) to dispatcher
07:29:48 DISPATCHER: trying to submit job (3, 0, 2)
07:29:48 DISPATCHER: trying to notify the job_runner thread.
07:29:48 HBMASTER: job (3, 0, 2) submitted to dispatcher
07:29:48 DISPATCHER: Trying to submit another job.
07:29:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:29:48 DISPATCHER: starting job (3, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:29:48 DISPATCHER: job (3, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:29:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:29:48 WORKER: start processing job (3, 0, 2)
07:29:48 WORKER: args: ()
07:29:48 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 71, 'last_n_outputs': 49, 'lr': 0.02690903046193758, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.017781608206196037}, 'budget': 1200.0, 'working_directory': '.'}
07:30:22 DISPATCHER: Starting worker discovery
07:30:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:30:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-469:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:31:22 DISPATCHER: Starting worker discovery
07:31:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:31:22 DISPATCHER: Finished worker discovery
07:32:22 DISPATCHER: Starting worker discovery
07:32:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:32:22 DISPATCHER: Finished worker discovery
07:33:22 DISPATCHER: Starting worker discovery
07:33:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:33:22 DISPATCHER: Finished worker discovery
07:34:22 DISPATCHER: Starting worker discovery
07:34:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:34:22 DISPATCHER: Finished worker discovery
07:35:22 DISPATCHER: Starting worker discovery
07:35:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:35:22 DISPATCHER: Finished worker discovery
07:36:22 DISPATCHER: Starting worker discovery
07:36:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:36:22 DISPATCHER: Finished worker discovery
07:37:22 DISPATCHER: Starting worker discovery
07:37:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:37:22 DISPATCHER: Finished worker discovery
07:38:22 DISPATCHER: Starting worker discovery
07:38:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:38:22 DISPATCHER: Finished worker discovery
07:39:22 DISPATCHER: Starting worker discovery
07:39:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:39:22 DISPATCHER: Finished worker discovery
07:40:22 DISPATCHER: Starting worker discovery
07:40:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:40:22 DISPATCHER: Finished worker discovery
07:41:22 DISPATCHER: Starting worker discovery
07:41:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:41:22 DISPATCHER: Finished worker discovery
07:42:22 DISPATCHER: Starting worker discovery
07:42:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:42:22 DISPATCHER: Finished worker discovery
07:43:22 DISPATCHER: Starting worker discovery
07:43:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:43:22 DISPATCHER: Finished worker discovery
07:44:22 DISPATCHER: Starting worker discovery
07:44:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:44:22 DISPATCHER: Finished worker discovery
07:45:22 DISPATCHER: Starting worker discovery
07:45:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:45:22 DISPATCHER: Finished worker discovery
07:46:22 DISPATCHER: Starting worker discovery
07:46:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:46:22 DISPATCHER: Finished worker discovery
07:47:22 DISPATCHER: Starting worker discovery
07:47:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:47:22 DISPATCHER: Finished worker discovery
07:48:22 DISPATCHER: Starting worker discovery
07:48:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:48:22 DISPATCHER: Finished worker discovery
07:49:22 DISPATCHER: Starting worker discovery
07:49:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:49:22 DISPATCHER: Finished worker discovery
07:50:22 DISPATCHER: Starting worker discovery
07:50:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:50:22 DISPATCHER: Finished worker discovery
07:50:50 WORKER: done with job (3, 0, 2), trying to register it.
07:50:50 WORKER: registered result for job (3, 0, 2) with dispatcher
07:50:50 DISPATCHER: job (3, 0, 2) finished
07:50:50 DISPATCHER: register_result: lock acquired
07:50:50 DISPATCHER: job (3, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
07:50:50 job_id: (3, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 71, 'last_n_outputs': 49, 'lr': 0.02690903046193758, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.017781608206196037}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.23476029248298097, 'info': {'sick_no_sick': 0.23476029248298097, 'config': "{'batch_size': 64, 'hidden_dim': 71, 'last_n_outputs': 49, 'lr': 0.02690903046193758, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.017781608206196037}"}}
exception: None

07:50:50 job_callback for (3, 0, 2) started
07:50:50 DISPATCHER: Trying to submit another job.
07:50:50 job_callback for (3, 0, 2) got condition
07:50:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:50:50 Only 7 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
07:50:50 HBMASTER: Trying to run another job!
07:50:50 job_callback for (3, 0, 2) finished
07:50:50 start sampling a new configuration.
07:50:50 done sampling a new configuration.
07:50:50 HBMASTER: schedule new run for iteration 3
07:50:50 HBMASTER: trying submitting job (3, 0, 3) to dispatcher
07:50:50 HBMASTER: submitting job (3, 0, 3) to dispatcher
07:50:50 DISPATCHER: trying to submit job (3, 0, 3)
07:50:50 DISPATCHER: trying to notify the job_runner thread.
07:50:50 HBMASTER: job (3, 0, 3) submitted to dispatcher
07:50:50 DISPATCHER: Trying to submit another job.
07:50:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:50:50 DISPATCHER: starting job (3, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:50:50 DISPATCHER: job (3, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:50:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:50:50 WORKER: start processing job (3, 0, 3)
07:50:50 WORKER: args: ()
07:50:50 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 55, 'last_n_outputs': 34, 'lr': 0.02431919860829964, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.10870398208908473}, 'budget': 1200.0, 'working_directory': '.'}
07:51:22 DISPATCHER: Starting worker discovery
07:51:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:51:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-470:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:52:22 DISPATCHER: Starting worker discovery
07:52:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:52:22 DISPATCHER: Finished worker discovery
07:53:22 DISPATCHER: Starting worker discovery
07:53:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:53:22 DISPATCHER: Finished worker discovery
07:54:22 DISPATCHER: Starting worker discovery
07:54:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:54:22 DISPATCHER: Finished worker discovery
07:55:22 DISPATCHER: Starting worker discovery
07:55:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:55:22 DISPATCHER: Finished worker discovery
07:56:22 DISPATCHER: Starting worker discovery
07:56:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:56:22 DISPATCHER: Finished worker discovery
07:57:22 DISPATCHER: Starting worker discovery
07:57:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:57:22 DISPATCHER: Finished worker discovery
07:58:22 DISPATCHER: Starting worker discovery
07:58:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:58:22 DISPATCHER: Finished worker discovery
07:59:22 DISPATCHER: Starting worker discovery
07:59:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:59:22 DISPATCHER: Finished worker discovery
08:00:22 DISPATCHER: Starting worker discovery
08:00:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:00:22 DISPATCHER: Finished worker discovery
08:01:22 DISPATCHER: Starting worker discovery
08:01:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:01:22 DISPATCHER: Finished worker discovery
08:02:22 DISPATCHER: Starting worker discovery
08:02:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:02:22 DISPATCHER: Finished worker discovery
08:03:22 DISPATCHER: Starting worker discovery
08:03:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:03:22 DISPATCHER: Finished worker discovery
08:04:22 DISPATCHER: Starting worker discovery
08:04:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:04:22 DISPATCHER: Finished worker discovery
08:05:22 DISPATCHER: Starting worker discovery
08:05:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:05:22 DISPATCHER: Finished worker discovery
08:06:22 DISPATCHER: Starting worker discovery
08:06:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:06:22 DISPATCHER: Finished worker discovery
08:07:22 DISPATCHER: Starting worker discovery
08:07:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:07:22 DISPATCHER: Finished worker discovery
08:08:22 DISPATCHER: Starting worker discovery
08:08:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:08:22 DISPATCHER: Finished worker discovery
08:09:22 DISPATCHER: Starting worker discovery
08:09:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:09:22 DISPATCHER: Finished worker discovery
08:10:22 DISPATCHER: Starting worker discovery
08:10:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:10:22 DISPATCHER: Finished worker discovery
08:11:22 DISPATCHER: Starting worker discovery
08:11:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:11:22 DISPATCHER: Finished worker discovery
08:11:50 WORKER: done with job (3, 0, 3), trying to register it.
08:11:50 WORKER: registered result for job (3, 0, 3) with dispatcher
08:11:50 DISPATCHER: job (3, 0, 3) finished
08:11:50 DISPATCHER: register_result: lock acquired
08:11:50 DISPATCHER: job (3, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:11:50 job_id: (3, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 55, 'last_n_outputs': 34, 'lr': 0.02431919860829964, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.10870398208908473}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 55, 'last_n_outputs': 34, 'lr': 0.02431919860829964, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.10870398208908473}"}}
exception: None

08:11:50 job_callback for (3, 0, 3) started
08:11:50 DISPATCHER: Trying to submit another job.
08:11:50 job_callback for (3, 0, 3) got condition
08:11:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:11:50 Only 8 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
08:11:50 HBMASTER: Trying to run another job!
08:11:50 job_callback for (3, 0, 3) finished
08:11:50 start sampling a new configuration.
08:11:50 done sampling a new configuration.
08:11:50 HBMASTER: schedule new run for iteration 4
08:11:50 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
08:11:50 HBMASTER: submitting job (4, 0, 0) to dispatcher
08:11:50 DISPATCHER: trying to submit job (4, 0, 0)
08:11:50 DISPATCHER: trying to notify the job_runner thread.
08:11:50 HBMASTER: job (4, 0, 0) submitted to dispatcher
08:11:50 DISPATCHER: Trying to submit another job.
08:11:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:11:50 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:11:50 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:11:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:11:50 WORKER: start processing job (4, 0, 0)
08:11:50 WORKER: args: ()
08:11:50 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 26, 'last_n_outputs': 50, 'lr': 0.0014190057467307019, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.03457203497416801}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:12:22 DISPATCHER: Starting worker discovery
08:12:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:12:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-471:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:13:22 DISPATCHER: Starting worker discovery
08:13:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:13:22 DISPATCHER: Finished worker discovery
08:13:34 WORKER: done with job (4, 0, 0), trying to register it.
08:13:34 WORKER: registered result for job (4, 0, 0) with dispatcher
08:13:34 DISPATCHER: job (4, 0, 0) finished
08:13:34 DISPATCHER: register_result: lock acquired
08:13:34 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:13:34 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 26, 'last_n_outputs': 50, 'lr': 0.0014190057467307019, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.03457203497416801}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4166195701402371, 'info': {'sick_no_sick': 0.4166195701402371, 'config': "{'batch_size': 128, 'hidden_dim': 26, 'last_n_outputs': 50, 'lr': 0.0014190057467307019, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.03457203497416801}"}}
exception: None

08:13:34 job_callback for (4, 0, 0) started
08:13:34 DISPATCHER: Trying to submit another job.
08:13:34 job_callback for (4, 0, 0) got condition
08:13:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:13:34 HBMASTER: Trying to run another job!
08:13:34 job_callback for (4, 0, 0) finished
08:13:34 start sampling a new configuration.
08:13:34 done sampling a new configuration.
08:13:34 HBMASTER: schedule new run for iteration 4
08:13:34 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
08:13:34 HBMASTER: submitting job (4, 0, 1) to dispatcher
08:13:34 DISPATCHER: trying to submit job (4, 0, 1)
08:13:34 DISPATCHER: trying to notify the job_runner thread.
08:13:34 HBMASTER: job (4, 0, 1) submitted to dispatcher
08:13:34 DISPATCHER: Trying to submit another job.
08:13:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:13:34 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:13:34 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:13:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:13:34 WORKER: start processing job (4, 0, 1)
08:13:34 WORKER: args: ()
08:13:34 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 47, 'last_n_outputs': 23, 'lr': 0.0010230921273465244, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 10, 'weight_decay': 0.011767509808525785}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:14:22 DISPATCHER: Starting worker discovery
08:14:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:14:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-472:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:15:21 WORKER: done with job (4, 0, 1), trying to register it.
08:15:21 WORKER: registered result for job (4, 0, 1) with dispatcher
08:15:21 DISPATCHER: job (4, 0, 1) finished
08:15:21 DISPATCHER: register_result: lock acquired
08:15:21 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:15:21 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 47, 'last_n_outputs': 23, 'lr': 0.0010230921273465244, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 10, 'weight_decay': 0.011767509808525785}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 47, 'last_n_outputs': 23, 'lr': 0.0010230921273465244, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 10, 'weight_decay': 0.011767509808525785}"}}
exception: None

08:15:21 job_callback for (4, 0, 1) started
08:15:21 job_callback for (4, 0, 1) got condition
08:15:21 DISPATCHER: Trying to submit another job.
08:15:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:15:21 HBMASTER: Trying to run another job!
08:15:21 job_callback for (4, 0, 1) finished
08:15:21 start sampling a new configuration.
08:15:21 done sampling a new configuration.
08:15:21 HBMASTER: schedule new run for iteration 4
08:15:21 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
08:15:21 HBMASTER: submitting job (4, 0, 2) to dispatcher
08:15:21 DISPATCHER: trying to submit job (4, 0, 2)
08:15:21 DISPATCHER: trying to notify the job_runner thread.
08:15:21 HBMASTER: job (4, 0, 2) submitted to dispatcher
08:15:21 DISPATCHER: Trying to submit another job.
08:15:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:15:21 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:15:21 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:15:21 WORKER: start processing job (4, 0, 2)
08:15:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:15:21 WORKER: args: ()
08:15:21 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 40, 'last_n_outputs': 1, 'lr': 0.004559131246972551, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.02516215404789277}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:15:22 DISPATCHER: Starting worker discovery
08:15:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:15:22 DISPATCHER: Finished worker discovery
08:16:22 DISPATCHER: Starting worker discovery
08:16:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:16:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-473:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:17:07 WORKER: done with job (4, 0, 2), trying to register it.
08:17:07 WORKER: registered result for job (4, 0, 2) with dispatcher
08:17:07 DISPATCHER: job (4, 0, 2) finished
08:17:07 DISPATCHER: register_result: lock acquired
08:17:07 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:17:07 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 40, 'last_n_outputs': 1, 'lr': 0.004559131246972551, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.02516215404789277}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.18547213370138493, 'info': {'sick_no_sick': 0.18547213370138493, 'config': "{'batch_size': 16, 'hidden_dim': 40, 'last_n_outputs': 1, 'lr': 0.004559131246972551, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.02516215404789277}"}}
exception: None

08:17:07 job_callback for (4, 0, 2) started
08:17:07 DISPATCHER: Trying to submit another job.
08:17:07 job_callback for (4, 0, 2) got condition
08:17:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:17:07 HBMASTER: Trying to run another job!
08:17:07 job_callback for (4, 0, 2) finished
08:17:07 start sampling a new configuration.
08:17:07 best_vector: [0, 0.2103308931292045, 0.8560381615166468, 0.39386847571973516, 0.06681406605063814, 0, 0.4569755503541606, 0.7830027316740851], 6.681890509325488e-33, 1.496582439661895, -0.39119055107488215
08:17:07 done sampling a new configuration.
08:17:07 HBMASTER: schedule new run for iteration 4
08:17:07 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
08:17:07 HBMASTER: submitting job (4, 0, 3) to dispatcher
08:17:07 DISPATCHER: trying to submit job (4, 0, 3)
08:17:07 DISPATCHER: trying to notify the job_runner thread.
08:17:07 HBMASTER: job (4, 0, 3) submitted to dispatcher
08:17:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:17:07 DISPATCHER: Trying to submit another job.
08:17:07 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:17:07 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:17:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:17:07 WORKER: start processing job (4, 0, 3)
08:17:07 WORKER: args: ()
08:17:07 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 37, 'last_n_outputs': 43, 'lr': 0.006133903671764282, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.10440229380829961}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:17:22 DISPATCHER: Starting worker discovery
08:17:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:17:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-474:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:18:22 DISPATCHER: Starting worker discovery
08:18:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:18:22 DISPATCHER: Finished worker discovery
08:18:52 WORKER: done with job (4, 0, 3), trying to register it.
08:18:52 WORKER: registered result for job (4, 0, 3) with dispatcher
08:18:52 DISPATCHER: job (4, 0, 3) finished
08:18:52 DISPATCHER: register_result: lock acquired
08:18:52 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:18:52 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 37, 'last_n_outputs': 43, 'lr': 0.006133903671764282, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.10440229380829961}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.007941981233044102, 'info': {'sick_no_sick': 0.007941981233044102, 'config': "{'batch_size': 16, 'hidden_dim': 37, 'last_n_outputs': 43, 'lr': 0.006133903671764282, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.10440229380829961}"}}
exception: None

08:18:52 job_callback for (4, 0, 3) started
08:18:52 job_callback for (4, 0, 3) got condition
08:18:52 DISPATCHER: Trying to submit another job.
08:18:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:18:52 HBMASTER: Trying to run another job!
08:18:52 job_callback for (4, 0, 3) finished
08:18:52 start sampling a new configuration.
08:18:52 done sampling a new configuration.
08:18:52 HBMASTER: schedule new run for iteration 4
08:18:52 HBMASTER: trying submitting job (4, 0, 4) to dispatcher
08:18:52 HBMASTER: submitting job (4, 0, 4) to dispatcher
08:18:52 DISPATCHER: trying to submit job (4, 0, 4)
08:18:52 DISPATCHER: trying to notify the job_runner thread.
08:18:52 HBMASTER: job (4, 0, 4) submitted to dispatcher
08:18:52 DISPATCHER: Trying to submit another job.
08:18:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:18:52 DISPATCHER: starting job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:18:52 DISPATCHER: job (4, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:18:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:18:52 WORKER: start processing job (4, 0, 4)
08:18:52 WORKER: args: ()
08:18:52 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 89, 'last_n_outputs': 39, 'lr': 0.07956461006562186, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.02712529444825603}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:19:22 DISPATCHER: Starting worker discovery
08:19:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:19:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-475:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

08:20:22 DISPATCHER: Starting worker discovery
08:20:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:20:22 DISPATCHER: Finished worker discovery
08:20:38 WORKER: done with job (4, 0, 4), trying to register it.
08:20:38 WORKER: registered result for job (4, 0, 4) with dispatcher
08:20:38 DISPATCHER: job (4, 0, 4) finished
08:20:38 DISPATCHER: register_result: lock acquired
08:20:38 DISPATCHER: job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:20:38 job_id: (4, 0, 4)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 89, 'last_n_outputs': 39, 'lr': 0.07956461006562186, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.02712529444825603}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 89, 'last_n_outputs': 39, 'lr': 0.07956461006562186, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.02712529444825603}"}}
exception: None

08:20:38 job_callback for (4, 0, 4) started
08:20:38 DISPATCHER: Trying to submit another job.
08:20:38 job_callback for (4, 0, 4) got condition
08:20:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:20:38 HBMASTER: Trying to run another job!
08:20:38 job_callback for (4, 0, 4) finished
08:20:38 start sampling a new configuration.
08:20:38 best_vector: [0, 0.3944316121111581, 0.39415009321056926, 0.31284296961017666, 0.3878376138079587, 0, 0.49739667635788104, 0.765115614283963], 2.728189981568497e-32, 0.3665433883842202, -0.0001657630954351274
08:20:38 done sampling a new configuration.
08:20:38 HBMASTER: schedule new run for iteration 4
08:20:38 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
08:20:38 HBMASTER: submitting job (4, 0, 5) to dispatcher
08:20:38 DISPATCHER: trying to submit job (4, 0, 5)
08:20:38 DISPATCHER: trying to notify the job_runner thread.
08:20:38 HBMASTER: job (4, 0, 5) submitted to dispatcher
08:20:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:20:38 DISPATCHER: Trying to submit another job.
08:20:38 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:20:38 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:20:38 WORKER: start processing job (4, 0, 5)
08:20:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:20:38 WORKER: args: ()
08:20:38 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 51, 'last_n_outputs': 20, 'lr': 0.004223630712418371, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.09895514154153896}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:21:22 DISPATCHER: Starting worker discovery
08:21:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:21:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-476:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:22:22 DISPATCHER: Starting worker discovery
08:22:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:22:22 DISPATCHER: Finished worker discovery
08:22:23 WORKER: done with job (4, 0, 5), trying to register it.
08:22:23 WORKER: registered result for job (4, 0, 5) with dispatcher
08:22:23 DISPATCHER: job (4, 0, 5) finished
08:22:23 DISPATCHER: register_result: lock acquired
08:22:23 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:22:23 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 51, 'last_n_outputs': 20, 'lr': 0.004223630712418371, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.09895514154153896}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3569323600683495, 'info': {'sick_no_sick': 0.3569323600683495, 'config': "{'batch_size': 16, 'hidden_dim': 51, 'last_n_outputs': 20, 'lr': 0.004223630712418371, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.09895514154153896}"}}
exception: None

08:22:23 job_callback for (4, 0, 5) started
08:22:23 DISPATCHER: Trying to submit another job.
08:22:23 job_callback for (4, 0, 5) got condition
08:22:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:22:23 HBMASTER: Trying to run another job!
08:22:23 job_callback for (4, 0, 5) finished
08:22:23 start sampling a new configuration.
08:22:23 best_vector: [0, 0.5384669565734248, 0.9210668201227196, 0.3428757785738531, 0.13414308253821064, 0, 0.663932716867923, 0.711901032462837], 1.8647303538807465e-33, 5.362705647596018, -0.534174762882456
08:22:23 done sampling a new configuration.
08:22:23 HBMASTER: schedule new run for iteration 4
08:22:23 HBMASTER: trying submitting job (4, 0, 6) to dispatcher
08:22:23 HBMASTER: submitting job (4, 0, 6) to dispatcher
08:22:23 DISPATCHER: trying to submit job (4, 0, 6)
08:22:23 DISPATCHER: trying to notify the job_runner thread.
08:22:23 HBMASTER: job (4, 0, 6) submitted to dispatcher
08:22:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:22:23 DISPATCHER: Trying to submit another job.
08:22:23 DISPATCHER: starting job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:22:23 DISPATCHER: job (4, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:22:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:22:23 WORKER: start processing job (4, 0, 6)
08:22:23 WORKER: args: ()
08:22:23 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 63, 'last_n_outputs': 47, 'lr': 0.004850109650215882, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.0843732148401986}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:23:22 DISPATCHER: Starting worker discovery
08:23:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:23:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-477:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:24:07 WORKER: done with job (4, 0, 6), trying to register it.
08:24:07 WORKER: registered result for job (4, 0, 6) with dispatcher
08:24:07 DISPATCHER: job (4, 0, 6) finished
08:24:07 DISPATCHER: register_result: lock acquired
08:24:07 DISPATCHER: job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:24:07 job_id: (4, 0, 6)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 63, 'last_n_outputs': 47, 'lr': 0.004850109650215882, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.0843732148401986}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3185864683605783, 'info': {'sick_no_sick': 0.3185864683605783, 'config': "{'batch_size': 16, 'hidden_dim': 63, 'last_n_outputs': 47, 'lr': 0.004850109650215882, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.0843732148401986}"}}
exception: None

08:24:07 job_callback for (4, 0, 6) started
08:24:07 job_callback for (4, 0, 6) got condition
08:24:07 DISPATCHER: Trying to submit another job.
08:24:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:24:07 HBMASTER: Trying to run another job!
08:24:07 job_callback for (4, 0, 6) finished
08:24:07 start sampling a new configuration.
08:24:08 best_vector: [0, 0.12975130548159627, 0.9933624515453291, 0.46846184199951146, 0.015268738838491142, 0, 0.36705710085960347, 0.6731534855063136], 5.506402296836373e-33, 1.8160678172289302, -0.18505865944259012
08:24:08 done sampling a new configuration.
08:24:08 HBMASTER: schedule new run for iteration 4
08:24:08 HBMASTER: trying submitting job (4, 0, 7) to dispatcher
08:24:08 HBMASTER: submitting job (4, 0, 7) to dispatcher
08:24:08 DISPATCHER: trying to submit job (4, 0, 7)
08:24:08 DISPATCHER: trying to notify the job_runner thread.
08:24:08 HBMASTER: job (4, 0, 7) submitted to dispatcher
08:24:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:24:08 DISPATCHER: Trying to submit another job.
08:24:08 DISPATCHER: starting job (4, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:24:08 DISPATCHER: job (4, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:24:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:24:08 WORKER: start processing job (4, 0, 7)
08:24:08 WORKER: args: ()
08:24:08 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 30, 'last_n_outputs': 50, 'lr': 0.008648159364324386, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.07512645155863616}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:24:22 DISPATCHER: Starting worker discovery
08:24:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:24:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-478:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:25:22 DISPATCHER: Starting worker discovery
08:25:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:25:22 DISPATCHER: Finished worker discovery
08:25:52 WORKER: done with job (4, 0, 7), trying to register it.
08:25:52 WORKER: registered result for job (4, 0, 7) with dispatcher
08:25:52 DISPATCHER: job (4, 0, 7) finished
08:25:52 DISPATCHER: register_result: lock acquired
08:25:52 DISPATCHER: job (4, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:25:52 job_id: (4, 0, 7)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 30, 'last_n_outputs': 50, 'lr': 0.008648159364324386, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.07512645155863616}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.284034304392264, 'info': {'sick_no_sick': 0.284034304392264, 'config': "{'batch_size': 16, 'hidden_dim': 30, 'last_n_outputs': 50, 'lr': 0.008648159364324386, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.07512645155863616}"}}
exception: None

08:25:52 job_callback for (4, 0, 7) started
08:25:52 DISPATCHER: Trying to submit another job.
08:25:52 job_callback for (4, 0, 7) got condition
08:25:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:25:52 HBMASTER: Trying to run another job!
08:25:52 job_callback for (4, 0, 7) finished
08:25:52 start sampling a new configuration.
08:25:53 best_vector: [0, 0.7133753148959708, 0.608330579096001, 0.7179478962920709, 0.1823707680919045, 0, 0.7205420870419049, 0.6868604304397492], 1.877725987546044e-31, 0.05325590669951139, -0.010664205974643966
08:25:53 done sampling a new configuration.
08:25:53 HBMASTER: schedule new run for iteration 4
08:25:53 HBMASTER: trying submitting job (4, 0, 8) to dispatcher
08:25:53 HBMASTER: submitting job (4, 0, 8) to dispatcher
08:25:53 DISPATCHER: trying to submit job (4, 0, 8)
08:25:53 DISPATCHER: trying to notify the job_runner thread.
08:25:53 HBMASTER: job (4, 0, 8) submitted to dispatcher
08:25:53 DISPATCHER: Trying to submit another job.
08:25:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:25:53 DISPATCHER: starting job (4, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:25:53 DISPATCHER: job (4, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:25:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:25:53 WORKER: start processing job (4, 0, 8)
08:25:53 WORKER: args: ()
08:25:53 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 77, 'last_n_outputs': 31, 'lr': 0.02728323052851051, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.07827553107240305}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:26:22 DISPATCHER: Starting worker discovery
08:26:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:26:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-479:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:27:22 DISPATCHER: Starting worker discovery
08:27:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:27:22 DISPATCHER: Finished worker discovery
08:27:37 WORKER: done with job (4, 0, 8), trying to register it.
08:27:37 WORKER: registered result for job (4, 0, 8) with dispatcher
08:27:37 DISPATCHER: job (4, 0, 8) finished
08:27:37 DISPATCHER: register_result: lock acquired
08:27:37 DISPATCHER: job (4, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:27:37 job_id: (4, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 77, 'last_n_outputs': 31, 'lr': 0.02728323052851051, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.07827553107240305}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.16986601450239833, 'info': {'sick_no_sick': 0.16986601450239833, 'config': "{'batch_size': 16, 'hidden_dim': 77, 'last_n_outputs': 31, 'lr': 0.02728323052851051, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.07827553107240305}"}}
exception: None

08:27:37 job_callback for (4, 0, 8) started
08:27:37 DISPATCHER: Trying to submit another job.
08:27:37 job_callback for (4, 0, 8) got condition
08:27:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:27:37 HBMASTER: Trying to run another job!
08:27:37 job_callback for (4, 0, 8) finished
08:27:37 start sampling a new configuration.
08:27:37 best_vector: [0, 0.9881279911966891, 0.1339679001030404, 0.5150020600355373, 0.24915281562926309, 0, 0.44900789839843325, 0.5019161305254403], 1.3392604642970529e-32, 0.7466807440813069, -2.0339871919493303e-07
08:27:37 done sampling a new configuration.
08:27:37 HBMASTER: schedule new run for iteration 4
08:27:37 HBMASTER: trying submitting job (4, 0, 9) to dispatcher
08:27:37 HBMASTER: submitting job (4, 0, 9) to dispatcher
08:27:37 DISPATCHER: trying to submit job (4, 0, 9)
08:27:37 DISPATCHER: trying to notify the job_runner thread.
08:27:37 HBMASTER: job (4, 0, 9) submitted to dispatcher
08:27:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:27:37 DISPATCHER: Trying to submit another job.
08:27:37 DISPATCHER: starting job (4, 0, 9) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:27:37 DISPATCHER: job (4, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:27:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:27:37 WORKER: start processing job (4, 0, 9)
08:27:37 WORKER: args: ()
08:27:37 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 7, 'lr': 0.010715294705904264, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.044978807924138144}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:28:22 DISPATCHER: Starting worker discovery
08:28:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:28:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-480:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:29:22 DISPATCHER: Starting worker discovery
08:29:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:29:22 DISPATCHER: Finished worker discovery
08:29:23 WORKER: done with job (4, 0, 9), trying to register it.
08:29:23 WORKER: registered result for job (4, 0, 9) with dispatcher
08:29:23 DISPATCHER: job (4, 0, 9) finished
08:29:23 DISPATCHER: register_result: lock acquired
08:29:23 DISPATCHER: job (4, 0, 9) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:29:23 job_id: (4, 0, 9)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 7, 'lr': 0.010715294705904264, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.044978807924138144}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0966854592816456, 'info': {'sick_no_sick': 0.0966854592816456, 'config': "{'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 7, 'lr': 0.010715294705904264, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.044978807924138144}"}}
exception: None

08:29:23 job_callback for (4, 0, 9) started
08:29:23 job_callback for (4, 0, 9) got condition
08:29:23 DISPATCHER: Trying to submit another job.
08:29:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:29:23 HBMASTER: Trying to run another job!
08:29:23 job_callback for (4, 0, 9) finished
08:29:23 start sampling a new configuration.
08:29:23 best_vector: [0, 0.6972806226331248, 0.6571993672785573, 0.28774249644507494, 0.16054139645771623, 0, 0.887701848861629, 0.7076231293672766], 3.504219199393247e-33, 2.8537027597279, -0.002495835588555097
08:29:23 done sampling a new configuration.
08:29:23 HBMASTER: schedule new run for iteration 4
08:29:23 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
08:29:23 HBMASTER: submitting job (4, 0, 10) to dispatcher
08:29:23 DISPATCHER: trying to submit job (4, 0, 10)
08:29:23 DISPATCHER: trying to notify the job_runner thread.
08:29:23 HBMASTER: job (4, 0, 10) submitted to dispatcher
08:29:23 DISPATCHER: Trying to submit another job.
08:29:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:29:23 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:29:23 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:29:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:29:23 WORKER: start processing job (4, 0, 10)
08:29:23 WORKER: args: ()
08:29:23 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 76, 'last_n_outputs': 33, 'lr': 0.0037625735041491117, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.08329883297351488}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:30:22 DISPATCHER: Starting worker discovery
08:30:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:30:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-481:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:31:07 WORKER: done with job (4, 0, 10), trying to register it.
08:31:07 WORKER: registered result for job (4, 0, 10) with dispatcher
08:31:07 DISPATCHER: job (4, 0, 10) finished
08:31:07 DISPATCHER: register_result: lock acquired
08:31:07 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:31:07 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 76, 'last_n_outputs': 33, 'lr': 0.0037625735041491117, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.08329883297351488}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.40956367083539647, 'info': {'sick_no_sick': 0.40956367083539647, 'config': "{'batch_size': 16, 'hidden_dim': 76, 'last_n_outputs': 33, 'lr': 0.0037625735041491117, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.08329883297351488}"}}
exception: None

08:31:07 job_callback for (4, 0, 10) started
08:31:07 job_callback for (4, 0, 10) got condition
08:31:07 DISPATCHER: Trying to submit another job.
08:31:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:31:07 HBMASTER: Trying to run another job!
08:31:07 job_callback for (4, 0, 10) finished
08:31:07 start sampling a new configuration.
08:31:07 done sampling a new configuration.
08:31:07 HBMASTER: schedule new run for iteration 4
08:31:07 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
08:31:07 HBMASTER: submitting job (4, 0, 11) to dispatcher
08:31:07 DISPATCHER: trying to submit job (4, 0, 11)
08:31:07 DISPATCHER: trying to notify the job_runner thread.
08:31:07 HBMASTER: job (4, 0, 11) submitted to dispatcher
08:31:07 DISPATCHER: Trying to submit another job.
08:31:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:31:07 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:31:07 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:31:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:31:07 WORKER: start processing job (4, 0, 11)
08:31:07 WORKER: args: ()
08:31:07 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 98, 'last_n_outputs': 46, 'lr': 0.016123468968969806, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.032366728835571665}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:31:22 DISPATCHER: Starting worker discovery
08:31:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:31:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-482:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:32:22 DISPATCHER: Starting worker discovery
08:32:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:32:22 DISPATCHER: Finished worker discovery
08:32:54 WORKER: done with job (4, 0, 11), trying to register it.
08:32:54 WORKER: registered result for job (4, 0, 11) with dispatcher
08:32:54 DISPATCHER: job (4, 0, 11) finished
08:32:54 DISPATCHER: register_result: lock acquired
08:32:54 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:32:54 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 98, 'last_n_outputs': 46, 'lr': 0.016123468968969806, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.032366728835571665}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 98, 'last_n_outputs': 46, 'lr': 0.016123468968969806, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.032366728835571665}"}}
exception: None

08:32:54 job_callback for (4, 0, 11) started
08:32:54 job_callback for (4, 0, 11) got condition
08:32:54 DISPATCHER: Trying to submit another job.
08:32:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:32:54 HBMASTER: Trying to run another job!
08:32:54 job_callback for (4, 0, 11) finished
08:32:54 start sampling a new configuration.
08:32:54 best_vector: [0, 0.7509634409647004, 0.35712526710347714, 0.4143973854210441, 0.18028298815805127, 0, 0.6782315721869927, 0.7807582973659567], 3.3571789502306095e-32, 0.2978691379949551, -0.0001811103501310645
08:32:54 done sampling a new configuration.
08:32:54 HBMASTER: schedule new run for iteration 4
08:32:54 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
08:32:54 HBMASTER: submitting job (4, 0, 12) to dispatcher
08:32:54 DISPATCHER: trying to submit job (4, 0, 12)
08:32:54 DISPATCHER: trying to notify the job_runner thread.
08:32:54 HBMASTER: job (4, 0, 12) submitted to dispatcher
08:32:54 DISPATCHER: Trying to submit another job.
08:32:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:32:54 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:32:54 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:32:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:32:54 WORKER: start processing job (4, 0, 12)
08:32:54 WORKER: args: ()
08:32:54 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 80, 'last_n_outputs': 18, 'lr': 0.006742093496550488, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.1037026762227994}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:33:22 DISPATCHER: Starting worker discovery
08:33:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:33:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-483:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:34:22 DISPATCHER: Starting worker discovery
08:34:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:34:22 DISPATCHER: Finished worker discovery
08:34:40 WORKER: done with job (4, 0, 12), trying to register it.
08:34:40 WORKER: registered result for job (4, 0, 12) with dispatcher
08:34:40 DISPATCHER: job (4, 0, 12) finished
08:34:40 DISPATCHER: register_result: lock acquired
08:34:40 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:34:40 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 80, 'last_n_outputs': 18, 'lr': 0.006742093496550488, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.1037026762227994}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.23690252221581626, 'info': {'sick_no_sick': 0.23690252221581626, 'config': "{'batch_size': 16, 'hidden_dim': 80, 'last_n_outputs': 18, 'lr': 0.006742093496550488, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.1037026762227994}"}}
exception: None

08:34:40 job_callback for (4, 0, 12) started
08:34:40 job_callback for (4, 0, 12) got condition
08:34:40 DISPATCHER: Trying to submit another job.
08:34:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:34:40 HBMASTER: Trying to run another job!
08:34:40 job_callback for (4, 0, 12) finished
08:34:40 start sampling a new configuration.
08:34:40 best_vector: [0, 0.7871038209889446, 0.5883604040448147, 0.4269548581701548, 0.19623486013156646, 0, 0.7563204588117816, 0.8980972946280386], 2.3999460458435444e-32, 0.4166760339183022, -0.006637863913783017
08:34:40 done sampling a new configuration.
08:34:40 HBMASTER: schedule new run for iteration 4
08:34:40 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
08:34:40 HBMASTER: submitting job (4, 0, 13) to dispatcher
08:34:40 DISPATCHER: trying to submit job (4, 0, 13)
08:34:40 DISPATCHER: trying to notify the job_runner thread.
08:34:40 HBMASTER: job (4, 0, 13) submitted to dispatcher
08:34:40 DISPATCHER: Trying to submit another job.
08:34:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:34:40 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:34:40 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:34:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:34:40 WORKER: start processing job (4, 0, 13)
08:34:40 WORKER: args: ()
08:34:40 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 83, 'last_n_outputs': 30, 'lr': 0.007143478078667286, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.14738440053241983}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:35:22 DISPATCHER: Starting worker discovery
08:35:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:35:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-484:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:36:22 DISPATCHER: Starting worker discovery
08:36:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:36:22 DISPATCHER: Finished worker discovery
08:36:27 WORKER: done with job (4, 0, 13), trying to register it.
08:36:27 WORKER: registered result for job (4, 0, 13) with dispatcher
08:36:27 DISPATCHER: job (4, 0, 13) finished
08:36:27 DISPATCHER: register_result: lock acquired
08:36:27 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:36:27 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 83, 'last_n_outputs': 30, 'lr': 0.007143478078667286, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.14738440053241983}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.009906898756375291, 'info': {'sick_no_sick': 0.009906898756375291, 'config': "{'batch_size': 16, 'hidden_dim': 83, 'last_n_outputs': 30, 'lr': 0.007143478078667286, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.14738440053241983}"}}
exception: None

08:36:27 job_callback for (4, 0, 13) started
08:36:27 DISPATCHER: Trying to submit another job.
08:36:27 job_callback for (4, 0, 13) got condition
08:36:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:36:27 HBMASTER: Trying to run another job!
08:36:27 job_callback for (4, 0, 13) finished
08:36:27 start sampling a new configuration.
08:36:27 best_vector: [0, 0.4232813672944389, 0.6767791587297324, 0.5222056027060947, 0.020962466707951183, 0, 0.3959395709433146, 0.7528196422997566], 3.3964513341531724e-32, 0.29442494580871925, -0.07694930918409366
08:36:27 done sampling a new configuration.
08:36:27 HBMASTER: schedule new run for iteration 4
08:36:27 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
08:36:27 HBMASTER: submitting job (4, 0, 14) to dispatcher
08:36:27 DISPATCHER: trying to submit job (4, 0, 14)
08:36:27 DISPATCHER: trying to notify the job_runner thread.
08:36:27 HBMASTER: job (4, 0, 14) submitted to dispatcher
08:36:27 DISPATCHER: Trying to submit another job.
08:36:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:36:27 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:36:27 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:36:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:36:27 WORKER: start processing job (4, 0, 14)
08:36:27 WORKER: args: ()
08:36:27 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 54, 'last_n_outputs': 34, 'lr': 0.011076720708079097, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.0953764022128115}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:37:22 DISPATCHER: Starting worker discovery
08:37:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:37:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-485:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:38:11 WORKER: done with job (4, 0, 14), trying to register it.
08:38:11 WORKER: registered result for job (4, 0, 14) with dispatcher
08:38:11 DISPATCHER: job (4, 0, 14) finished
08:38:11 DISPATCHER: register_result: lock acquired
08:38:11 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:38:11 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 54, 'last_n_outputs': 34, 'lr': 0.011076720708079097, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.0953764022128115}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.03979384675536081, 'info': {'sick_no_sick': 0.03979384675536081, 'config': "{'batch_size': 16, 'hidden_dim': 54, 'last_n_outputs': 34, 'lr': 0.011076720708079097, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.0953764022128115}"}}
exception: None

08:38:11 DISPATCHER: Trying to submit another job.
08:38:11 job_callback for (4, 0, 14) started
08:38:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:38:11 job_callback for (4, 0, 14) got condition
08:38:11 HBMASTER: Trying to run another job!
08:38:11 job_callback for (4, 0, 14) finished
08:38:11 start sampling a new configuration.
08:38:11 done sampling a new configuration.
08:38:11 HBMASTER: schedule new run for iteration 4
08:38:11 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
08:38:11 HBMASTER: submitting job (4, 0, 15) to dispatcher
08:38:11 DISPATCHER: trying to submit job (4, 0, 15)
08:38:11 DISPATCHER: trying to notify the job_runner thread.
08:38:11 HBMASTER: job (4, 0, 15) submitted to dispatcher
08:38:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:38:11 DISPATCHER: Trying to submit another job.
08:38:11 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:38:11 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:38:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:38:11 WORKER: start processing job (4, 0, 15)
08:38:11 WORKER: args: ()
08:38:11 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 55, 'last_n_outputs': 11, 'lr': 0.016688829631297555, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.04837243995867513}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:38:22 DISPATCHER: Starting worker discovery
08:38:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:38:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-486:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:39:22 DISPATCHER: Starting worker discovery
08:39:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:39:22 DISPATCHER: Finished worker discovery
08:39:56 WORKER: done with job (4, 0, 15), trying to register it.
08:39:56 WORKER: registered result for job (4, 0, 15) with dispatcher
08:39:56 DISPATCHER: job (4, 0, 15) finished
08:39:56 DISPATCHER: register_result: lock acquired
08:39:56 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:39:56 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 55, 'last_n_outputs': 11, 'lr': 0.016688829631297555, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.04837243995867513}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 55, 'last_n_outputs': 11, 'lr': 0.016688829631297555, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.04837243995867513}"}}
exception: None

08:39:56 job_callback for (4, 0, 15) started
08:39:56 DISPATCHER: Trying to submit another job.
08:39:56 job_callback for (4, 0, 15) got condition
08:39:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:39:56 HBMASTER: Trying to run another job!
08:39:56 job_callback for (4, 0, 15) finished
08:39:56 start sampling a new configuration.
08:39:56 done sampling a new configuration.
08:39:56 HBMASTER: schedule new run for iteration 4
08:39:56 HBMASTER: trying submitting job (4, 0, 16) to dispatcher
08:39:56 HBMASTER: submitting job (4, 0, 16) to dispatcher
08:39:56 DISPATCHER: trying to submit job (4, 0, 16)
08:39:56 DISPATCHER: trying to notify the job_runner thread.
08:39:56 HBMASTER: job (4, 0, 16) submitted to dispatcher
08:39:56 DISPATCHER: Trying to submit another job.
08:39:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:39:56 DISPATCHER: starting job (4, 0, 16) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:39:56 DISPATCHER: job (4, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:39:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:39:56 WORKER: start processing job (4, 0, 16)
08:39:56 WORKER: args: ()
08:39:56 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 59, 'last_n_outputs': 20, 'lr': 0.0020865492244510698, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.1884920429476151}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:40:22 DISPATCHER: Starting worker discovery
08:40:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:40:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-487:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:41:22 DISPATCHER: Starting worker discovery
08:41:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:41:22 DISPATCHER: Finished worker discovery
08:41:43 WORKER: done with job (4, 0, 16), trying to register it.
08:41:43 WORKER: registered result for job (4, 0, 16) with dispatcher
08:41:43 DISPATCHER: job (4, 0, 16) finished
08:41:43 DISPATCHER: register_result: lock acquired
08:41:43 DISPATCHER: job (4, 0, 16) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:41:43 job_id: (4, 0, 16)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 59, 'last_n_outputs': 20, 'lr': 0.0020865492244510698, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.1884920429476151}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0044004217852042634, 'info': {'sick_no_sick': 0.0044004217852042634, 'config': "{'batch_size': 32, 'hidden_dim': 59, 'last_n_outputs': 20, 'lr': 0.0020865492244510698, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.1884920429476151}"}}
exception: None

08:41:43 job_callback for (4, 0, 16) started
08:41:43 job_callback for (4, 0, 16) got condition
08:41:43 DISPATCHER: Trying to submit another job.
08:41:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:41:43 HBMASTER: Trying to run another job!
08:41:43 job_callback for (4, 0, 16) finished
08:41:43 start sampling a new configuration.
08:41:43 done sampling a new configuration.
08:41:43 HBMASTER: schedule new run for iteration 4
08:41:43 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
08:41:43 HBMASTER: submitting job (4, 0, 17) to dispatcher
08:41:43 DISPATCHER: trying to submit job (4, 0, 17)
08:41:43 DISPATCHER: trying to notify the job_runner thread.
08:41:43 HBMASTER: job (4, 0, 17) submitted to dispatcher
08:41:43 DISPATCHER: Trying to submit another job.
08:41:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:41:43 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:41:43 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:41:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:41:43 WORKER: start processing job (4, 0, 17)
08:41:43 WORKER: args: ()
08:41:43 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 63, 'last_n_outputs': 49, 'lr': 0.006017745364756507, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.05027028883780859}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:42:22 DISPATCHER: Starting worker discovery
08:42:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:42:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-488:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:43:22 DISPATCHER: Starting worker discovery
08:43:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:43:22 DISPATCHER: Finished worker discovery
08:43:26 WORKER: done with job (4, 0, 17), trying to register it.
08:43:26 WORKER: registered result for job (4, 0, 17) with dispatcher
08:43:26 DISPATCHER: job (4, 0, 17) finished
08:43:26 DISPATCHER: register_result: lock acquired
08:43:26 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:43:26 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 63, 'last_n_outputs': 49, 'lr': 0.006017745364756507, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.05027028883780859}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3780509953003692, 'info': {'sick_no_sick': 0.3780509953003692, 'config': "{'batch_size': 16, 'hidden_dim': 63, 'last_n_outputs': 49, 'lr': 0.006017745364756507, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.05027028883780859}"}}
exception: None

08:43:26 job_callback for (4, 0, 17) started
08:43:26 job_callback for (4, 0, 17) got condition
08:43:26 DISPATCHER: Trying to submit another job.
08:43:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:43:26 HBMASTER: Trying to run another job!
08:43:26 job_callback for (4, 0, 17) finished
08:43:26 start sampling a new configuration.
08:43:27 best_vector: [0, 0.5854106240594599, 0.3474872106401243, 0.3081382846227967, 0.32109429907285536, 0, 0.2931712941763065, 0.5176329876861584], 1.7180315954401392e-32, 0.5820614723583195, -5.3168714847482156e-05
08:43:27 done sampling a new configuration.
08:43:27 HBMASTER: schedule new run for iteration 4
08:43:27 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
08:43:27 HBMASTER: submitting job (4, 0, 18) to dispatcher
08:43:27 DISPATCHER: trying to submit job (4, 0, 18)
08:43:27 DISPATCHER: trying to notify the job_runner thread.
08:43:27 HBMASTER: job (4, 0, 18) submitted to dispatcher
08:43:27 DISPATCHER: Trying to submit another job.
08:43:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:43:27 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:43:27 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:43:27 WORKER: start processing job (4, 0, 18)
08:43:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:43:27 WORKER: args: ()
08:43:27 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 67, 'last_n_outputs': 18, 'lr': 0.004133106244167753, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.047147214978064844}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:44:22 DISPATCHER: Starting worker discovery
08:44:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:44:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-489:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:45:12 WORKER: done with job (4, 0, 18), trying to register it.
08:45:12 WORKER: registered result for job (4, 0, 18) with dispatcher
08:45:12 DISPATCHER: job (4, 0, 18) finished
08:45:12 DISPATCHER: register_result: lock acquired
08:45:12 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:45:12 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 67, 'last_n_outputs': 18, 'lr': 0.004133106244167753, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.047147214978064844}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.21893009302295524, 'info': {'sick_no_sick': 0.21893009302295524, 'config': "{'batch_size': 16, 'hidden_dim': 67, 'last_n_outputs': 18, 'lr': 0.004133106244167753, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.047147214978064844}"}}
exception: None

08:45:12 job_callback for (4, 0, 18) started
08:45:12 DISPATCHER: Trying to submit another job.
08:45:12 job_callback for (4, 0, 18) got condition
08:45:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:45:12 HBMASTER: Trying to run another job!
08:45:12 job_callback for (4, 0, 18) finished
08:45:12 start sampling a new configuration.
08:45:12 done sampling a new configuration.
08:45:12 HBMASTER: schedule new run for iteration 4
08:45:12 HBMASTER: trying submitting job (4, 0, 19) to dispatcher
08:45:12 HBMASTER: submitting job (4, 0, 19) to dispatcher
08:45:12 DISPATCHER: trying to submit job (4, 0, 19)
08:45:12 DISPATCHER: trying to notify the job_runner thread.
08:45:12 HBMASTER: job (4, 0, 19) submitted to dispatcher
08:45:12 DISPATCHER: Trying to submit another job.
08:45:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:45:12 DISPATCHER: starting job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:45:12 DISPATCHER: job (4, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:45:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:45:12 WORKER: start processing job (4, 0, 19)
08:45:12 WORKER: args: ()
08:45:12 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 92, 'last_n_outputs': 38, 'lr': 0.0029417977325305136, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.12928870568827183}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:45:22 DISPATCHER: Starting worker discovery
08:45:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:45:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-490:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:46:22 DISPATCHER: Starting worker discovery
08:46:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:46:22 DISPATCHER: Finished worker discovery
08:46:58 WORKER: done with job (4, 0, 19), trying to register it.
08:46:58 WORKER: registered result for job (4, 0, 19) with dispatcher
08:46:58 DISPATCHER: job (4, 0, 19) finished
08:46:58 DISPATCHER: register_result: lock acquired
08:46:58 DISPATCHER: job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:46:58 job_id: (4, 0, 19)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 92, 'last_n_outputs': 38, 'lr': 0.0029417977325305136, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.12928870568827183}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 92, 'last_n_outputs': 38, 'lr': 0.0029417977325305136, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.12928870568827183}"}}
exception: None

08:46:58 job_callback for (4, 0, 19) started
08:46:58 DISPATCHER: Trying to submit another job.
08:46:58 job_callback for (4, 0, 19) got condition
08:46:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:46:58 HBMASTER: Trying to run another job!
08:46:58 job_callback for (4, 0, 19) finished
08:46:58 start sampling a new configuration.
08:46:58 best_vector: [0, 0.1308589349534593, 0.8625186299303335, 0.7877095580370628, 0.1476373196184234, 0, 0.4165751433276735, 0.7989571621048014], 3.53205767809817e-33, 2.8312108440382215, -0.5225359557276329
08:46:58 done sampling a new configuration.
08:46:58 HBMASTER: schedule new run for iteration 4
08:46:58 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
08:46:58 HBMASTER: submitting job (4, 0, 20) to dispatcher
08:46:58 DISPATCHER: trying to submit job (4, 0, 20)
08:46:58 DISPATCHER: trying to notify the job_runner thread.
08:46:58 HBMASTER: job (4, 0, 20) submitted to dispatcher
08:46:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:46:58 DISPATCHER: Trying to submit another job.
08:46:58 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:46:58 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:46:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:46:58 WORKER: start processing job (4, 0, 20)
08:46:58 WORKER: args: ()
08:46:58 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 30, 'last_n_outputs': 44, 'lr': 0.03762002814041962, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.1095133926078312}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:47:22 DISPATCHER: Starting worker discovery
08:47:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:47:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-491:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:48:22 DISPATCHER: Starting worker discovery
08:48:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:48:22 DISPATCHER: Finished worker discovery
08:48:44 WORKER: done with job (4, 0, 20), trying to register it.
08:48:44 WORKER: registered result for job (4, 0, 20) with dispatcher
08:48:44 DISPATCHER: job (4, 0, 20) finished
08:48:44 DISPATCHER: register_result: lock acquired
08:48:44 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:48:44 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 30, 'last_n_outputs': 44, 'lr': 0.03762002814041962, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.1095133926078312}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4012090416079644, 'info': {'sick_no_sick': 0.4012090416079644, 'config': "{'batch_size': 16, 'hidden_dim': 30, 'last_n_outputs': 44, 'lr': 0.03762002814041962, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.1095133926078312}"}}
exception: None

08:48:44 job_callback for (4, 0, 20) started
08:48:44 DISPATCHER: Trying to submit another job.
08:48:44 job_callback for (4, 0, 20) got condition
08:48:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:48:44 HBMASTER: Trying to run another job!
08:48:44 job_callback for (4, 0, 20) finished
08:48:44 start sampling a new configuration.
08:48:44 best_vector: [2, 0.4679066595527793, 0.7034800805905148, 0.34287932149145706, 0.09425275325322921, 0, 0.14390975209070955, 0.15481847360263928], 2.254345515582666e-31, 0.044358772561158916, -0.00145140157299411
08:48:44 done sampling a new configuration.
08:48:44 HBMASTER: schedule new run for iteration 4
08:48:44 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
08:48:44 HBMASTER: submitting job (4, 0, 21) to dispatcher
08:48:44 DISPATCHER: trying to submit job (4, 0, 21)
08:48:44 DISPATCHER: trying to notify the job_runner thread.
08:48:44 HBMASTER: job (4, 0, 21) submitted to dispatcher
08:48:44 DISPATCHER: Trying to submit another job.
08:48:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:48:44 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:48:44 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:48:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:48:44 WORKER: start processing job (4, 0, 21)
08:48:44 WORKER: args: ()
08:48:44 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 57, 'last_n_outputs': 36, 'lr': 0.004850188783982295, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.015900964868012905}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:49:22 DISPATCHER: Starting worker discovery
08:49:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:49:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-492:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:50:22 DISPATCHER: Starting worker discovery
08:50:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:50:22 DISPATCHER: Finished worker discovery
08:50:28 WORKER: done with job (4, 0, 21), trying to register it.
08:50:28 WORKER: registered result for job (4, 0, 21) with dispatcher
08:50:28 DISPATCHER: job (4, 0, 21) finished
08:50:28 DISPATCHER: register_result: lock acquired
08:50:28 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:50:28 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 57, 'last_n_outputs': 36, 'lr': 0.004850188783982295, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.015900964868012905}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3193749281298482, 'info': {'sick_no_sick': 0.3193749281298482, 'config': "{'batch_size': 64, 'hidden_dim': 57, 'last_n_outputs': 36, 'lr': 0.004850188783982295, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.015900964868012905}"}}
exception: None

08:50:28 job_callback for (4, 0, 21) started
08:50:28 DISPATCHER: Trying to submit another job.
08:50:28 job_callback for (4, 0, 21) got condition
08:50:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:50:28 HBMASTER: Trying to run another job!
08:50:28 job_callback for (4, 0, 21) finished
08:50:28 start sampling a new configuration.
08:50:28 best_vector: [0, 0.684677305964475, 0.5992165450515068, 0.4075487216958196, 0.11580702605339366, 0, 0.7491650869104455, 0.993813755060817], 4.895371493030825e-33, 2.042745890528687, -0.01455120997639277
08:50:28 done sampling a new configuration.
08:50:28 HBMASTER: schedule new run for iteration 4
08:50:28 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
08:50:28 HBMASTER: submitting job (4, 0, 22) to dispatcher
08:50:28 DISPATCHER: trying to submit job (4, 0, 22)
08:50:28 DISPATCHER: trying to notify the job_runner thread.
08:50:28 HBMASTER: job (4, 0, 22) submitted to dispatcher
08:50:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:50:28 DISPATCHER: Trying to submit another job.
08:50:28 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:50:28 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:50:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:50:28 WORKER: start processing job (4, 0, 22)
08:50:28 WORKER: args: ()
08:50:28 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 75, 'last_n_outputs': 30, 'lr': 0.00653277113101939, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.1963276668322585}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:51:22 DISPATCHER: Starting worker discovery
08:51:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:51:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-493:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:52:12 WORKER: done with job (4, 0, 22), trying to register it.
08:52:12 WORKER: registered result for job (4, 0, 22) with dispatcher
08:52:12 DISPATCHER: job (4, 0, 22) finished
08:52:12 DISPATCHER: register_result: lock acquired
08:52:12 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:52:12 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 75, 'last_n_outputs': 30, 'lr': 0.00653277113101939, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.1963276668322585}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3535119540542267, 'info': {'sick_no_sick': 0.3535119540542267, 'config': "{'batch_size': 16, 'hidden_dim': 75, 'last_n_outputs': 30, 'lr': 0.00653277113101939, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.1963276668322585}"}}
exception: None

08:52:12 job_callback for (4, 0, 22) started
08:52:12 DISPATCHER: Trying to submit another job.
08:52:12 job_callback for (4, 0, 22) got condition
08:52:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:52:12 HBMASTER: Trying to run another job!
08:52:12 job_callback for (4, 0, 22) finished
08:52:12 start sampling a new configuration.
08:52:12 best_vector: [3, 0.3221237129556841, 0.9137933194940364, 0.4709070202829927, 0.08894148829366519, 0, 0.8828479687652074, 0.03873390406830013], 2.014705123843959e-32, 0.4963505518326418, -0.010229053397323655
08:52:12 done sampling a new configuration.
08:52:12 HBMASTER: schedule new run for iteration 4
08:52:12 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
08:52:12 HBMASTER: submitting job (4, 0, 23) to dispatcher
08:52:12 DISPATCHER: trying to submit job (4, 0, 23)
08:52:12 DISPATCHER: trying to notify the job_runner thread.
08:52:12 HBMASTER: job (4, 0, 23) submitted to dispatcher
08:52:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:52:12 DISPATCHER: Trying to submit another job.
08:52:12 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:52:12 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:52:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:52:12 WORKER: start processing job (4, 0, 23)
08:52:12 WORKER: args: ()
08:52:12 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 46, 'last_n_outputs': 46, 'lr': 0.008746091983818687, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.011230367572246346}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:52:22 DISPATCHER: Starting worker discovery
08:52:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:52:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-494:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:53:22 DISPATCHER: Starting worker discovery
08:53:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:53:22 DISPATCHER: Finished worker discovery
08:53:58 WORKER: done with job (4, 0, 23), trying to register it.
08:53:58 WORKER: registered result for job (4, 0, 23) with dispatcher
08:53:58 DISPATCHER: job (4, 0, 23) finished
08:53:58 DISPATCHER: register_result: lock acquired
08:53:58 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:53:58 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 46, 'last_n_outputs': 46, 'lr': 0.008746091983818687, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.011230367572246346}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2994619966277349, 'info': {'sick_no_sick': 0.2994619966277349, 'config': "{'batch_size': 128, 'hidden_dim': 46, 'last_n_outputs': 46, 'lr': 0.008746091983818687, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.011230367572246346}"}}
exception: None

08:53:58 job_callback for (4, 0, 23) started
08:53:58 DISPATCHER: Trying to submit another job.
08:53:58 job_callback for (4, 0, 23) got condition
08:53:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:53:58 HBMASTER: Trying to run another job!
08:53:58 job_callback for (4, 0, 23) finished
08:53:58 start sampling a new configuration.
08:53:58 best_vector: [0, 0.7024604852610723, 0.894132297609704, 0.2835073924560543, 0.1517487332409429, 0, 0.8401000859405277, 0.9485572415892328], 1.6878780060746235e-33, 5.924598794468731, -0.029256588723793678
08:53:58 done sampling a new configuration.
08:53:58 HBMASTER: schedule new run for iteration 4
08:53:58 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
08:53:58 HBMASTER: submitting job (4, 0, 24) to dispatcher
08:53:58 DISPATCHER: trying to submit job (4, 0, 24)
08:53:58 DISPATCHER: trying to notify the job_runner thread.
08:53:58 HBMASTER: job (4, 0, 24) submitted to dispatcher
08:53:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:53:58 DISPATCHER: Trying to submit another job.
08:53:58 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:53:58 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:53:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:53:58 WORKER: start processing job (4, 0, 24)
08:53:58 WORKER: args: ()
08:53:58 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 76, 'last_n_outputs': 45, 'lr': 0.0036899016007956886, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.17143576270205493}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:54:22 DISPATCHER: Starting worker discovery
08:54:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:54:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-495:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:55:22 DISPATCHER: Starting worker discovery
08:55:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:55:22 DISPATCHER: Finished worker discovery
08:55:43 WORKER: done with job (4, 0, 24), trying to register it.
08:55:43 WORKER: registered result for job (4, 0, 24) with dispatcher
08:55:43 DISPATCHER: job (4, 0, 24) finished
08:55:43 DISPATCHER: register_result: lock acquired
08:55:43 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:55:43 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 76, 'last_n_outputs': 45, 'lr': 0.0036899016007956886, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.17143576270205493}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.17600887935358783, 'info': {'sick_no_sick': 0.17600887935358783, 'config': "{'batch_size': 16, 'hidden_dim': 76, 'last_n_outputs': 45, 'lr': 0.0036899016007956886, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.17143576270205493}"}}
exception: None

08:55:43 job_callback for (4, 0, 24) started
08:55:43 DISPATCHER: Trying to submit another job.
08:55:43 job_callback for (4, 0, 24) got condition
08:55:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:55:43 HBMASTER: Trying to run another job!
08:55:43 job_callback for (4, 0, 24) finished
08:55:43 start sampling a new configuration.
08:55:43 best_vector: [0, 0.32179899727714234, 0.0029742650345061517, 0.6340026284284616, 0.3340249337985375, 0, 0.2968419684230126, 0.8244807640078654], 7.11022602829534e-33, 1.4064250503717781, -1.8087874273157167e-09
08:55:43 done sampling a new configuration.
08:55:43 HBMASTER: schedule new run for iteration 4
08:55:43 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
08:55:43 HBMASTER: submitting job (4, 0, 25) to dispatcher
08:55:43 DISPATCHER: trying to submit job (4, 0, 25)
08:55:43 DISPATCHER: trying to notify the job_runner thread.
08:55:43 HBMASTER: job (4, 0, 25) submitted to dispatcher
08:55:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:55:43 DISPATCHER: Trying to submit another job.
08:55:43 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:55:43 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:55:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:55:43 WORKER: start processing job (4, 0, 25)
08:55:43 WORKER: args: ()
08:55:43 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 46, 'last_n_outputs': 1, 'lr': 0.018535540593653574, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.11821544049156027}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:56:22 DISPATCHER: Starting worker discovery
08:56:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:56:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-496:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:57:22 DISPATCHER: Starting worker discovery
08:57:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:57:22 DISPATCHER: Finished worker discovery
08:57:28 WORKER: done with job (4, 0, 25), trying to register it.
08:57:28 WORKER: registered result for job (4, 0, 25) with dispatcher
08:57:28 DISPATCHER: job (4, 0, 25) finished
08:57:28 DISPATCHER: register_result: lock acquired
08:57:28 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:57:28 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 46, 'last_n_outputs': 1, 'lr': 0.018535540593653574, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.11821544049156027}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 46, 'last_n_outputs': 1, 'lr': 0.018535540593653574, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.11821544049156027}"}}
exception: None

08:57:28 job_callback for (4, 0, 25) started
08:57:28 job_callback for (4, 0, 25) got condition
08:57:28 DISPATCHER: Trying to submit another job.
08:57:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:57:28 HBMASTER: Trying to run another job!
08:57:28 job_callback for (4, 0, 25) finished
08:57:28 start sampling a new configuration.
08:57:28 best_vector: [0, 0.14777564158115564, 0.6303643748752443, 0.05873331402020693, 0.12636587889458895, 0, 0.6848890101539392, 0.9299071973066655], 3.5912772644654065e-32, 0.2784524631096282, -0.009759866510290356
08:57:28 done sampling a new configuration.
08:57:28 HBMASTER: schedule new run for iteration 4
08:57:28 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
08:57:28 HBMASTER: submitting job (4, 0, 26) to dispatcher
08:57:28 DISPATCHER: trying to submit job (4, 0, 26)
08:57:28 DISPATCHER: trying to notify the job_runner thread.
08:57:28 HBMASTER: job (4, 0, 26) submitted to dispatcher
08:57:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:57:28 DISPATCHER: Trying to submit another job.
08:57:28 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:57:28 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:57:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:57:28 WORKER: start processing job (4, 0, 26)
08:57:28 WORKER: args: ()
08:57:28 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 31, 'last_n_outputs': 32, 'lr': 0.0013105893304840512, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 72, 'weight_decay': 0.16212020972110558}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:58:22 DISPATCHER: Starting worker discovery
08:58:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:58:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-497:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:59:13 WORKER: done with job (4, 0, 26), trying to register it.
08:59:13 WORKER: registered result for job (4, 0, 26) with dispatcher
08:59:13 DISPATCHER: job (4, 0, 26) finished
08:59:13 DISPATCHER: register_result: lock acquired
08:59:13 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:59:13 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 31, 'last_n_outputs': 32, 'lr': 0.0013105893304840512, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 72, 'weight_decay': 0.16212020972110558}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3063850974107539, 'info': {'sick_no_sick': 0.3063850974107539, 'config': "{'batch_size': 16, 'hidden_dim': 31, 'last_n_outputs': 32, 'lr': 0.0013105893304840512, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 72, 'weight_decay': 0.16212020972110558}"}}
exception: None

08:59:13 job_callback for (4, 0, 26) started
08:59:13 DISPATCHER: Trying to submit another job.
08:59:13 job_callback for (4, 0, 26) got condition
08:59:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:59:13 HBMASTER: Trying to run another job!
08:59:13 job_callback for (4, 0, 26) finished
08:59:13 ITERATION: Advancing config (4, 0, 0) to next budget 133.333333
08:59:13 ITERATION: Advancing config (4, 0, 5) to next budget 133.333333
08:59:13 ITERATION: Advancing config (4, 0, 6) to next budget 133.333333
08:59:13 ITERATION: Advancing config (4, 0, 10) to next budget 133.333333
08:59:13 ITERATION: Advancing config (4, 0, 17) to next budget 133.333333
08:59:13 ITERATION: Advancing config (4, 0, 20) to next budget 133.333333
08:59:13 ITERATION: Advancing config (4, 0, 21) to next budget 133.333333
08:59:13 ITERATION: Advancing config (4, 0, 22) to next budget 133.333333
08:59:13 ITERATION: Advancing config (4, 0, 26) to next budget 133.333333
08:59:13 HBMASTER: schedule new run for iteration 4
08:59:13 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
08:59:13 HBMASTER: submitting job (4, 0, 0) to dispatcher
08:59:13 DISPATCHER: trying to submit job (4, 0, 0)
08:59:13 DISPATCHER: trying to notify the job_runner thread.
08:59:13 HBMASTER: job (4, 0, 0) submitted to dispatcher
08:59:13 DISPATCHER: Trying to submit another job.
08:59:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:59:13 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:59:13 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:59:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:59:13 WORKER: start processing job (4, 0, 0)
08:59:13 WORKER: args: ()
08:59:13 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 26, 'last_n_outputs': 50, 'lr': 0.0014190057467307019, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.03457203497416801}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:59:22 DISPATCHER: Starting worker discovery
08:59:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:59:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-498:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:00:22 DISPATCHER: Starting worker discovery
09:00:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:00:22 DISPATCHER: Finished worker discovery
09:01:22 DISPATCHER: Starting worker discovery
09:01:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:01:22 DISPATCHER: Finished worker discovery
09:02:22 DISPATCHER: Starting worker discovery
09:02:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:02:22 DISPATCHER: Finished worker discovery
09:02:27 WORKER: done with job (4, 0, 0), trying to register it.
09:02:27 WORKER: registered result for job (4, 0, 0) with dispatcher
09:02:27 DISPATCHER: job (4, 0, 0) finished
09:02:27 DISPATCHER: register_result: lock acquired
09:02:27 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
09:02:27 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 26, 'last_n_outputs': 50, 'lr': 0.0014190057467307019, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.03457203497416801}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2776971322579213, 'info': {'sick_no_sick': 0.2776971322579213, 'config': "{'batch_size': 128, 'hidden_dim': 26, 'last_n_outputs': 50, 'lr': 0.0014190057467307019, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.03457203497416801}"}}
exception: None

09:02:27 job_callback for (4, 0, 0) started
09:02:27 job_callback for (4, 0, 0) got condition
09:02:27 DISPATCHER: Trying to submit another job.
09:02:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:02:27 done building a new model for budget 133.333333 based on 9/16 split
Best loss for this budget:-0.450975





09:02:27 HBMASTER: Trying to run another job!
09:02:27 job_callback for (4, 0, 0) finished
09:02:27 HBMASTER: schedule new run for iteration 4
09:02:27 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
09:02:27 HBMASTER: submitting job (4, 0, 5) to dispatcher
09:02:27 DISPATCHER: trying to submit job (4, 0, 5)
09:02:27 DISPATCHER: trying to notify the job_runner thread.
09:02:27 HBMASTER: job (4, 0, 5) submitted to dispatcher
09:02:27 DISPATCHER: Trying to submit another job.
09:02:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:02:27 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:02:27 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:02:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:02:27 WORKER: start processing job (4, 0, 5)
09:02:27 WORKER: args: ()
09:02:27 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 51, 'last_n_outputs': 20, 'lr': 0.004223630712418371, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.09895514154153896}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:03:22 DISPATCHER: Starting worker discovery
09:03:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:03:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-499:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:04:22 DISPATCHER: Starting worker discovery
09:04:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:04:22 DISPATCHER: Finished worker discovery
09:05:22 DISPATCHER: Starting worker discovery
09:05:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:05:22 DISPATCHER: Finished worker discovery
09:05:40 WORKER: done with job (4, 0, 5), trying to register it.
09:05:40 WORKER: registered result for job (4, 0, 5) with dispatcher
09:05:40 DISPATCHER: job (4, 0, 5) finished
09:05:40 DISPATCHER: register_result: lock acquired
09:05:40 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
09:05:40 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 51, 'last_n_outputs': 20, 'lr': 0.004223630712418371, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.09895514154153896}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 51, 'last_n_outputs': 20, 'lr': 0.004223630712418371, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.09895514154153896}"}}
exception: None

09:05:40 job_callback for (4, 0, 5) started
09:05:40 job_callback for (4, 0, 5) got condition
09:05:40 DISPATCHER: Trying to submit another job.
09:05:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:05:40 done building a new model for budget 133.333333 based on 9/17 split
Best loss for this budget:-0.450975





09:05:40 HBMASTER: Trying to run another job!
09:05:40 job_callback for (4, 0, 5) finished
09:05:40 HBMASTER: schedule new run for iteration 4
09:05:40 HBMASTER: trying submitting job (4, 0, 6) to dispatcher
09:05:40 HBMASTER: submitting job (4, 0, 6) to dispatcher
09:05:40 DISPATCHER: trying to submit job (4, 0, 6)
09:05:40 DISPATCHER: trying to notify the job_runner thread.
09:05:40 HBMASTER: job (4, 0, 6) submitted to dispatcher
09:05:40 DISPATCHER: Trying to submit another job.
09:05:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:05:40 DISPATCHER: starting job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:05:40 DISPATCHER: job (4, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:05:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:05:40 WORKER: start processing job (4, 0, 6)
09:05:40 WORKER: args: ()
09:05:40 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 63, 'last_n_outputs': 47, 'lr': 0.004850109650215882, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.0843732148401986}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:06:22 DISPATCHER: Starting worker discovery
09:06:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:06:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-500:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:07:22 DISPATCHER: Starting worker discovery
09:07:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:07:22 DISPATCHER: Finished worker discovery
09:08:22 DISPATCHER: Starting worker discovery
09:08:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:08:22 DISPATCHER: Finished worker discovery
09:08:54 WORKER: done with job (4, 0, 6), trying to register it.
09:08:54 WORKER: registered result for job (4, 0, 6) with dispatcher
09:08:54 DISPATCHER: job (4, 0, 6) finished
09:08:54 DISPATCHER: register_result: lock acquired
09:08:54 DISPATCHER: job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
09:08:54 job_id: (4, 0, 6)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 63, 'last_n_outputs': 47, 'lr': 0.004850109650215882, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.0843732148401986}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1283699207787296, 'info': {'sick_no_sick': 0.1283699207787296, 'config': "{'batch_size': 16, 'hidden_dim': 63, 'last_n_outputs': 47, 'lr': 0.004850109650215882, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.0843732148401986}"}}
exception: None

09:08:54 job_callback for (4, 0, 6) started
09:08:54 job_callback for (4, 0, 6) got condition
09:08:54 DISPATCHER: Trying to submit another job.
09:08:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:08:54 done building a new model for budget 133.333333 based on 9/17 split
Best loss for this budget:-0.450975





09:08:54 HBMASTER: Trying to run another job!
09:08:54 job_callback for (4, 0, 6) finished
09:08:54 HBMASTER: schedule new run for iteration 4
09:08:54 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
09:08:54 HBMASTER: submitting job (4, 0, 10) to dispatcher
09:08:54 DISPATCHER: trying to submit job (4, 0, 10)
09:08:54 DISPATCHER: trying to notify the job_runner thread.
09:08:54 HBMASTER: job (4, 0, 10) submitted to dispatcher
09:08:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:08:54 DISPATCHER: Trying to submit another job.
09:08:54 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:08:54 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:08:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:08:54 WORKER: start processing job (4, 0, 10)
09:08:54 WORKER: args: ()
09:08:54 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 76, 'last_n_outputs': 33, 'lr': 0.0037625735041491117, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.08329883297351488}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:09:22 DISPATCHER: Starting worker discovery
09:09:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:09:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-501:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:10:22 DISPATCHER: Starting worker discovery
09:10:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:10:22 DISPATCHER: Finished worker discovery
09:11:22 DISPATCHER: Starting worker discovery
09:11:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:11:22 DISPATCHER: Finished worker discovery
09:12:07 WORKER: done with job (4, 0, 10), trying to register it.
09:12:07 WORKER: registered result for job (4, 0, 10) with dispatcher
09:12:07 DISPATCHER: job (4, 0, 10) finished
09:12:07 DISPATCHER: register_result: lock acquired
09:12:07 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
09:12:07 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 76, 'last_n_outputs': 33, 'lr': 0.0037625735041491117, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.08329883297351488}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.41646059171080846, 'info': {'sick_no_sick': 0.41646059171080846, 'config': "{'batch_size': 16, 'hidden_dim': 76, 'last_n_outputs': 33, 'lr': 0.0037625735041491117, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.08329883297351488}"}}
exception: None

09:12:07 job_callback for (4, 0, 10) started
09:12:07 DISPATCHER: Trying to submit another job.
09:12:07 job_callback for (4, 0, 10) got condition
09:12:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:12:07 done building a new model for budget 133.333333 based on 9/18 split
Best loss for this budget:-0.450975





09:12:07 HBMASTER: Trying to run another job!
09:12:07 job_callback for (4, 0, 10) finished
09:12:07 HBMASTER: schedule new run for iteration 4
09:12:07 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
09:12:07 HBMASTER: submitting job (4, 0, 17) to dispatcher
09:12:07 DISPATCHER: trying to submit job (4, 0, 17)
09:12:07 DISPATCHER: trying to notify the job_runner thread.
09:12:07 HBMASTER: job (4, 0, 17) submitted to dispatcher
09:12:07 DISPATCHER: Trying to submit another job.
09:12:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:12:07 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:12:07 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:12:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:12:07 WORKER: start processing job (4, 0, 17)
09:12:07 WORKER: args: ()
09:12:07 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 63, 'last_n_outputs': 49, 'lr': 0.006017745364756507, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.05027028883780859}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:12:22 DISPATCHER: Starting worker discovery
09:12:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:12:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-502:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:13:22 DISPATCHER: Starting worker discovery
09:13:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:13:22 DISPATCHER: Finished worker discovery
09:14:22 DISPATCHER: Starting worker discovery
09:14:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:14:22 DISPATCHER: Finished worker discovery
09:15:20 WORKER: done with job (4, 0, 17), trying to register it.
09:15:20 WORKER: registered result for job (4, 0, 17) with dispatcher
09:15:20 DISPATCHER: job (4, 0, 17) finished
09:15:20 DISPATCHER: register_result: lock acquired
09:15:20 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
09:15:20 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 63, 'last_n_outputs': 49, 'lr': 0.006017745364756507, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.05027028883780859}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.27308490824298587, 'info': {'sick_no_sick': 0.27308490824298587, 'config': "{'batch_size': 16, 'hidden_dim': 63, 'last_n_outputs': 49, 'lr': 0.006017745364756507, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.05027028883780859}"}}
exception: None

09:15:20 job_callback for (4, 0, 17) started
09:15:20 DISPATCHER: Trying to submit another job.
09:15:20 job_callback for (4, 0, 17) got condition
09:15:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:15:20 done building a new model for budget 133.333333 based on 9/19 split
Best loss for this budget:-0.450975





09:15:20 HBMASTER: Trying to run another job!
09:15:20 job_callback for (4, 0, 17) finished
09:15:20 HBMASTER: schedule new run for iteration 4
09:15:20 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
09:15:20 HBMASTER: submitting job (4, 0, 20) to dispatcher
09:15:20 DISPATCHER: trying to submit job (4, 0, 20)
09:15:20 DISPATCHER: trying to notify the job_runner thread.
09:15:20 HBMASTER: job (4, 0, 20) submitted to dispatcher
09:15:20 DISPATCHER: Trying to submit another job.
09:15:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:15:20 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:15:20 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:15:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:15:20 WORKER: start processing job (4, 0, 20)
09:15:20 WORKER: args: ()
09:15:20 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 30, 'last_n_outputs': 44, 'lr': 0.03762002814041962, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.1095133926078312}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:15:22 DISPATCHER: Starting worker discovery
09:15:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:15:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-503:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:16:22 DISPATCHER: Starting worker discovery
09:16:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:16:22 DISPATCHER: Finished worker discovery
09:17:22 DISPATCHER: Starting worker discovery
09:17:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:17:22 DISPATCHER: Finished worker discovery
09:18:22 DISPATCHER: Starting worker discovery
09:18:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:18:22 DISPATCHER: Finished worker discovery
09:18:34 WORKER: done with job (4, 0, 20), trying to register it.
09:18:34 WORKER: registered result for job (4, 0, 20) with dispatcher
09:18:34 DISPATCHER: job (4, 0, 20) finished
09:18:34 DISPATCHER: register_result: lock acquired
09:18:34 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
09:18:34 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 30, 'last_n_outputs': 44, 'lr': 0.03762002814041962, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.1095133926078312}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2466831907690622, 'info': {'sick_no_sick': 0.2466831907690622, 'config': "{'batch_size': 16, 'hidden_dim': 30, 'last_n_outputs': 44, 'lr': 0.03762002814041962, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.1095133926078312}"}}
exception: None

09:18:34 job_callback for (4, 0, 20) started
09:18:34 DISPATCHER: Trying to submit another job.
09:18:34 job_callback for (4, 0, 20) got condition
09:18:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:18:34 done building a new model for budget 133.333333 based on 9/20 split
Best loss for this budget:-0.450975





09:18:34 HBMASTER: Trying to run another job!
09:18:34 job_callback for (4, 0, 20) finished
09:18:34 HBMASTER: schedule new run for iteration 4
09:18:34 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
09:18:34 HBMASTER: submitting job (4, 0, 21) to dispatcher
09:18:34 DISPATCHER: trying to submit job (4, 0, 21)
09:18:34 DISPATCHER: trying to notify the job_runner thread.
09:18:34 HBMASTER: job (4, 0, 21) submitted to dispatcher
09:18:34 DISPATCHER: Trying to submit another job.
09:18:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:18:34 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:18:34 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:18:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:18:34 WORKER: start processing job (4, 0, 21)
09:18:34 WORKER: args: ()
09:18:34 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 57, 'last_n_outputs': 36, 'lr': 0.004850188783982295, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.015900964868012905}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:19:22 DISPATCHER: Starting worker discovery
09:19:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:19:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-504:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:20:22 DISPATCHER: Starting worker discovery
09:20:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:20:22 DISPATCHER: Finished worker discovery
09:21:22 DISPATCHER: Starting worker discovery
09:21:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:21:22 DISPATCHER: Finished worker discovery
09:21:48 WORKER: done with job (4, 0, 21), trying to register it.
09:21:48 WORKER: registered result for job (4, 0, 21) with dispatcher
09:21:48 DISPATCHER: job (4, 0, 21) finished
09:21:48 DISPATCHER: register_result: lock acquired
09:21:48 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
09:21:48 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 57, 'last_n_outputs': 36, 'lr': 0.004850188783982295, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.015900964868012905}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3754389541215556, 'info': {'sick_no_sick': 0.3754389541215556, 'config': "{'batch_size': 64, 'hidden_dim': 57, 'last_n_outputs': 36, 'lr': 0.004850188783982295, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.015900964868012905}"}}
exception: None

09:21:48 job_callback for (4, 0, 21) started
09:21:48 job_callback for (4, 0, 21) got condition
09:21:48 DISPATCHER: Trying to submit another job.
09:21:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:21:48 done building a new model for budget 133.333333 based on 9/21 split
Best loss for this budget:-0.450975





09:21:48 HBMASTER: Trying to run another job!
09:21:48 job_callback for (4, 0, 21) finished
09:21:48 HBMASTER: schedule new run for iteration 4
09:21:48 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
09:21:48 HBMASTER: submitting job (4, 0, 22) to dispatcher
09:21:48 DISPATCHER: trying to submit job (4, 0, 22)
09:21:48 DISPATCHER: trying to notify the job_runner thread.
09:21:48 HBMASTER: job (4, 0, 22) submitted to dispatcher
09:21:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:21:48 DISPATCHER: Trying to submit another job.
09:21:48 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:21:48 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:21:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:21:48 WORKER: start processing job (4, 0, 22)
09:21:48 WORKER: args: ()
09:21:48 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 75, 'last_n_outputs': 30, 'lr': 0.00653277113101939, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.1963276668322585}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:22:22 DISPATCHER: Starting worker discovery
09:22:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:22:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-505:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:23:22 DISPATCHER: Starting worker discovery
09:23:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:23:22 DISPATCHER: Finished worker discovery
09:24:22 DISPATCHER: Starting worker discovery
09:24:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:24:22 DISPATCHER: Finished worker discovery
09:25:03 WORKER: done with job (4, 0, 22), trying to register it.
09:25:03 WORKER: registered result for job (4, 0, 22) with dispatcher
09:25:03 DISPATCHER: job (4, 0, 22) finished
09:25:03 DISPATCHER: register_result: lock acquired
09:25:03 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
09:25:03 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 75, 'last_n_outputs': 30, 'lr': 0.00653277113101939, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.1963276668322585}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.05420456038256608, 'info': {'sick_no_sick': 0.05420456038256608, 'config': "{'batch_size': 16, 'hidden_dim': 75, 'last_n_outputs': 30, 'lr': 0.00653277113101939, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.1963276668322585}"}}
exception: None

09:25:03 job_callback for (4, 0, 22) started
09:25:03 DISPATCHER: Trying to submit another job.
09:25:03 job_callback for (4, 0, 22) got condition
09:25:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:25:03 done building a new model for budget 133.333333 based on 9/22 split
Best loss for this budget:-0.450975





09:25:03 HBMASTER: Trying to run another job!
09:25:03 job_callback for (4, 0, 22) finished
09:25:03 HBMASTER: schedule new run for iteration 4
09:25:03 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
09:25:03 HBMASTER: submitting job (4, 0, 26) to dispatcher
09:25:03 DISPATCHER: trying to submit job (4, 0, 26)
09:25:03 DISPATCHER: trying to notify the job_runner thread.
09:25:03 HBMASTER: job (4, 0, 26) submitted to dispatcher
09:25:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:25:03 DISPATCHER: Trying to submit another job.
09:25:03 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:25:03 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:25:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:25:03 WORKER: start processing job (4, 0, 26)
09:25:03 WORKER: args: ()
09:25:03 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 31, 'last_n_outputs': 32, 'lr': 0.0013105893304840512, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 72, 'weight_decay': 0.16212020972110558}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:25:22 DISPATCHER: Starting worker discovery
09:25:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:25:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-506:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:26:22 DISPATCHER: Starting worker discovery
09:26:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:26:22 DISPATCHER: Finished worker discovery
09:27:22 DISPATCHER: Starting worker discovery
09:27:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:27:22 DISPATCHER: Finished worker discovery
09:28:17 WORKER: done with job (4, 0, 26), trying to register it.
09:28:17 WORKER: registered result for job (4, 0, 26) with dispatcher
09:28:17 DISPATCHER: job (4, 0, 26) finished
09:28:17 DISPATCHER: register_result: lock acquired
09:28:17 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
09:28:17 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 31, 'last_n_outputs': 32, 'lr': 0.0013105893304840512, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 72, 'weight_decay': 0.16212020972110558}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.29694984417895914, 'info': {'sick_no_sick': 0.29694984417895914, 'config': "{'batch_size': 16, 'hidden_dim': 31, 'last_n_outputs': 32, 'lr': 0.0013105893304840512, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 72, 'weight_decay': 0.16212020972110558}"}}
exception: None

09:28:17 job_callback for (4, 0, 26) started
09:28:17 DISPATCHER: Trying to submit another job.
09:28:17 job_callback for (4, 0, 26) got condition
09:28:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:28:17 done building a new model for budget 133.333333 based on 9/22 split
Best loss for this budget:-0.450975





09:28:17 HBMASTER: Trying to run another job!
09:28:17 job_callback for (4, 0, 26) finished
09:28:17 ITERATION: Advancing config (4, 0, 10) to next budget 400.000000
09:28:17 ITERATION: Advancing config (4, 0, 21) to next budget 400.000000
09:28:17 ITERATION: Advancing config (4, 0, 26) to next budget 400.000000
09:28:17 HBMASTER: schedule new run for iteration 4
09:28:17 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
09:28:17 HBMASTER: submitting job (4, 0, 10) to dispatcher
09:28:17 DISPATCHER: trying to submit job (4, 0, 10)
09:28:17 DISPATCHER: trying to notify the job_runner thread.
09:28:17 HBMASTER: job (4, 0, 10) submitted to dispatcher
09:28:17 DISPATCHER: Trying to submit another job.
09:28:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:28:17 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:28:17 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:28:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:28:17 WORKER: start processing job (4, 0, 10)
09:28:17 WORKER: args: ()
09:28:17 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 76, 'last_n_outputs': 33, 'lr': 0.0037625735041491117, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.08329883297351488}, 'budget': 400.0, 'working_directory': '.'}
09:28:22 DISPATCHER: Starting worker discovery
09:28:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:28:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-507:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:29:22 DISPATCHER: Starting worker discovery
09:29:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:29:22 DISPATCHER: Finished worker discovery
09:30:22 DISPATCHER: Starting worker discovery
09:30:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:30:22 DISPATCHER: Finished worker discovery
09:31:22 DISPATCHER: Starting worker discovery
09:31:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:31:22 DISPATCHER: Finished worker discovery
09:32:22 DISPATCHER: Starting worker discovery
09:32:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:32:22 DISPATCHER: Finished worker discovery
09:33:22 DISPATCHER: Starting worker discovery
09:33:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:33:22 DISPATCHER: Finished worker discovery
09:34:22 DISPATCHER: Starting worker discovery
09:34:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:34:22 DISPATCHER: Finished worker discovery
09:35:22 DISPATCHER: Starting worker discovery
09:35:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:35:22 DISPATCHER: Finished worker discovery
09:35:58 WORKER: done with job (4, 0, 10), trying to register it.
09:35:58 WORKER: registered result for job (4, 0, 10) with dispatcher
09:35:58 DISPATCHER: job (4, 0, 10) finished
09:35:58 DISPATCHER: register_result: lock acquired
09:35:58 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
09:35:58 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 76, 'last_n_outputs': 33, 'lr': 0.0037625735041491117, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.08329883297351488}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.34747385425290905, 'info': {'sick_no_sick': 0.34747385425290905, 'config': "{'batch_size': 16, 'hidden_dim': 76, 'last_n_outputs': 33, 'lr': 0.0037625735041491117, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.08329883297351488}"}}
exception: None

09:35:58 job_callback for (4, 0, 10) started
09:35:58 DISPATCHER: Trying to submit another job.
09:35:58 job_callback for (4, 0, 10) got condition
09:35:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:35:58 HBMASTER: Trying to run another job!
09:35:58 job_callback for (4, 0, 10) finished
09:35:58 HBMASTER: schedule new run for iteration 4
09:35:58 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
09:35:58 HBMASTER: submitting job (4, 0, 21) to dispatcher
09:35:58 DISPATCHER: trying to submit job (4, 0, 21)
09:35:58 DISPATCHER: trying to notify the job_runner thread.
09:35:58 HBMASTER: job (4, 0, 21) submitted to dispatcher
09:35:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:35:58 DISPATCHER: Trying to submit another job.
09:35:58 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:35:58 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:35:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:35:58 WORKER: start processing job (4, 0, 21)
09:35:58 WORKER: args: ()
09:35:58 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 57, 'last_n_outputs': 36, 'lr': 0.004850188783982295, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.015900964868012905}, 'budget': 400.0, 'working_directory': '.'}
09:36:22 DISPATCHER: Starting worker discovery
09:36:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:36:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-508:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:37:22 DISPATCHER: Starting worker discovery
09:37:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:37:22 DISPATCHER: Finished worker discovery
09:38:22 DISPATCHER: Starting worker discovery
09:38:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:38:22 DISPATCHER: Finished worker discovery
09:39:22 DISPATCHER: Starting worker discovery
09:39:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:39:22 DISPATCHER: Finished worker discovery
09:40:22 DISPATCHER: Starting worker discovery
09:40:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:40:22 DISPATCHER: Finished worker discovery
09:41:22 DISPATCHER: Starting worker discovery
09:41:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:41:22 DISPATCHER: Finished worker discovery
09:42:22 DISPATCHER: Starting worker discovery
09:42:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:42:22 DISPATCHER: Finished worker discovery
09:43:22 DISPATCHER: Starting worker discovery
09:43:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:43:22 DISPATCHER: Finished worker discovery
09:43:39 WORKER: done with job (4, 0, 21), trying to register it.
09:43:39 WORKER: registered result for job (4, 0, 21) with dispatcher
09:43:39 DISPATCHER: job (4, 0, 21) finished
09:43:39 DISPATCHER: register_result: lock acquired
09:43:39 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
09:43:39 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 57, 'last_n_outputs': 36, 'lr': 0.004850188783982295, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.015900964868012905}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.17628398707743198, 'info': {'sick_no_sick': 0.17628398707743198, 'config': "{'batch_size': 64, 'hidden_dim': 57, 'last_n_outputs': 36, 'lr': 0.004850188783982295, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.015900964868012905}"}}
exception: None

09:43:39 job_callback for (4, 0, 21) started
09:43:39 job_callback for (4, 0, 21) got condition
09:43:39 DISPATCHER: Trying to submit another job.
09:43:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:43:39 HBMASTER: Trying to run another job!
09:43:39 job_callback for (4, 0, 21) finished
09:43:39 HBMASTER: schedule new run for iteration 4
09:43:39 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
09:43:39 HBMASTER: submitting job (4, 0, 26) to dispatcher
09:43:39 DISPATCHER: trying to submit job (4, 0, 26)
09:43:39 DISPATCHER: trying to notify the job_runner thread.
09:43:39 HBMASTER: job (4, 0, 26) submitted to dispatcher
09:43:39 DISPATCHER: Trying to submit another job.
09:43:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:43:39 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:43:39 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:43:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:43:39 WORKER: start processing job (4, 0, 26)
09:43:39 WORKER: args: ()
09:43:39 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 31, 'last_n_outputs': 32, 'lr': 0.0013105893304840512, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 72, 'weight_decay': 0.16212020972110558}, 'budget': 400.0, 'working_directory': '.'}
09:44:22 DISPATCHER: Starting worker discovery
09:44:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:44:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-509:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:45:22 DISPATCHER: Starting worker discovery
09:45:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:45:22 DISPATCHER: Finished worker discovery
09:46:22 DISPATCHER: Starting worker discovery
09:46:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:46:22 DISPATCHER: Finished worker discovery
09:47:22 DISPATCHER: Starting worker discovery
09:47:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:47:22 DISPATCHER: Finished worker discovery
09:48:22 DISPATCHER: Starting worker discovery
09:48:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:48:22 DISPATCHER: Finished worker discovery
09:49:22 DISPATCHER: Starting worker discovery
09:49:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:49:22 DISPATCHER: Finished worker discovery
09:50:22 DISPATCHER: Starting worker discovery
09:50:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:50:22 DISPATCHER: Finished worker discovery
09:51:19 WORKER: done with job (4, 0, 26), trying to register it.
09:51:19 WORKER: registered result for job (4, 0, 26) with dispatcher
09:51:19 DISPATCHER: job (4, 0, 26) finished
09:51:19 DISPATCHER: register_result: lock acquired
09:51:19 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
09:51:19 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 31, 'last_n_outputs': 32, 'lr': 0.0013105893304840512, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 72, 'weight_decay': 0.16212020972110558}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.03824414821429918, 'info': {'sick_no_sick': 0.03824414821429918, 'config': "{'batch_size': 16, 'hidden_dim': 31, 'last_n_outputs': 32, 'lr': 0.0013105893304840512, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 72, 'weight_decay': 0.16212020972110558}"}}
exception: None

09:51:19 job_callback for (4, 0, 26) started
09:51:19 DISPATCHER: Trying to submit another job.
09:51:19 job_callback for (4, 0, 26) got condition
09:51:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:51:19 HBMASTER: Trying to run another job!
09:51:19 job_callback for (4, 0, 26) finished
09:51:19 ITERATION: Advancing config (4, 0, 10) to next budget 1200.000000
09:51:19 HBMASTER: schedule new run for iteration 4
09:51:19 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
09:51:19 HBMASTER: submitting job (4, 0, 10) to dispatcher
09:51:19 DISPATCHER: trying to submit job (4, 0, 10)
09:51:19 DISPATCHER: trying to notify the job_runner thread.
09:51:19 HBMASTER: job (4, 0, 10) submitted to dispatcher
09:51:19 DISPATCHER: Trying to submit another job.
09:51:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:51:19 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:51:19 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
09:51:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:51:19 WORKER: start processing job (4, 0, 10)
09:51:19 WORKER: args: ()
09:51:19 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 76, 'last_n_outputs': 33, 'lr': 0.0037625735041491117, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.08329883297351488}, 'budget': 1200.0, 'working_directory': '.'}
09:51:22 DISPATCHER: Starting worker discovery
09:51:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:51:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-510:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:52:22 DISPATCHER: Starting worker discovery
09:52:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:52:22 DISPATCHER: Finished worker discovery
09:53:22 DISPATCHER: Starting worker discovery
09:53:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:53:22 DISPATCHER: Finished worker discovery
09:54:22 DISPATCHER: Starting worker discovery
09:54:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:54:22 DISPATCHER: Finished worker discovery
09:55:22 DISPATCHER: Starting worker discovery
09:55:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:55:22 DISPATCHER: Finished worker discovery
09:56:22 DISPATCHER: Starting worker discovery
09:56:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:56:22 DISPATCHER: Finished worker discovery
09:57:22 DISPATCHER: Starting worker discovery
09:57:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:57:22 DISPATCHER: Finished worker discovery
09:58:22 DISPATCHER: Starting worker discovery
09:58:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:58:22 DISPATCHER: Finished worker discovery
09:59:22 DISPATCHER: Starting worker discovery
09:59:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:59:22 DISPATCHER: Finished worker discovery
10:00:22 DISPATCHER: Starting worker discovery
10:00:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:00:22 DISPATCHER: Finished worker discovery
10:01:22 DISPATCHER: Starting worker discovery
10:01:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:01:23 DISPATCHER: Finished worker discovery
10:02:23 DISPATCHER: Starting worker discovery
10:02:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:02:23 DISPATCHER: Finished worker discovery
10:03:23 DISPATCHER: Starting worker discovery
10:03:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:03:23 DISPATCHER: Finished worker discovery
10:04:23 DISPATCHER: Starting worker discovery
10:04:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:04:23 DISPATCHER: Finished worker discovery
10:05:23 DISPATCHER: Starting worker discovery
10:05:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:05:23 DISPATCHER: Finished worker discovery
10:06:23 DISPATCHER: Starting worker discovery
10:06:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:06:23 DISPATCHER: Finished worker discovery
10:07:23 DISPATCHER: Starting worker discovery
10:07:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:07:23 DISPATCHER: Finished worker discovery
10:08:23 DISPATCHER: Starting worker discovery
10:08:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:08:23 DISPATCHER: Finished worker discovery
10:09:23 DISPATCHER: Starting worker discovery
10:09:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:09:23 DISPATCHER: Finished worker discovery
10:10:23 DISPATCHER: Starting worker discovery
10:10:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:10:23 DISPATCHER: Finished worker discovery
10:11:23 DISPATCHER: Starting worker discovery
10:11:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:11:23 DISPATCHER: Finished worker discovery
10:12:18 WORKER: done with job (4, 0, 10), trying to register it.
10:12:18 WORKER: registered result for job (4, 0, 10) with dispatcher
10:12:18 DISPATCHER: job (4, 0, 10) finished
10:12:18 DISPATCHER: register_result: lock acquired
10:12:18 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
10:12:18 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 76, 'last_n_outputs': 33, 'lr': 0.0037625735041491117, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.08329883297351488}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.2664018975747135, 'info': {'sick_no_sick': 0.2664018975747135, 'config': "{'batch_size': 16, 'hidden_dim': 76, 'last_n_outputs': 33, 'lr': 0.0037625735041491117, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.08329883297351488}"}}
exception: None

10:12:18 job_callback for (4, 0, 10) started
10:12:18 DISPATCHER: Trying to submit another job.
10:12:18 job_callback for (4, 0, 10) got condition
10:12:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:12:18 HBMASTER: Trying to run another job!
10:12:18 job_callback for (4, 0, 10) finished
10:12:18 start sampling a new configuration.
10:12:18 done sampling a new configuration.
10:12:18 HBMASTER: schedule new run for iteration 5
10:12:18 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
10:12:18 HBMASTER: submitting job (5, 0, 0) to dispatcher
10:12:18 DISPATCHER: trying to submit job (5, 0, 0)
10:12:18 DISPATCHER: trying to notify the job_runner thread.
10:12:18 HBMASTER: job (5, 0, 0) submitted to dispatcher
10:12:18 DISPATCHER: Trying to submit another job.
10:12:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:12:18 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:12:18 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:12:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:12:18 WORKER: start processing job (5, 0, 0)
10:12:18 WORKER: args: ()
10:12:18 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 27, 'last_n_outputs': 26, 'lr': 0.002342280911137, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.09531620438008442}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:12:23 DISPATCHER: Starting worker discovery
10:12:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:12:23 DISPATCHER: Finished worker discovery
10:13:23 DISPATCHER: Starting worker discovery
10:13:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:13:23 DISPATCHER: Finished worker discovery
Exception in thread Thread-511:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:14:23 DISPATCHER: Starting worker discovery
10:14:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:14:23 DISPATCHER: Finished worker discovery
10:15:23 DISPATCHER: Starting worker discovery
10:15:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:15:23 DISPATCHER: Finished worker discovery
10:15:33 WORKER: done with job (5, 0, 0), trying to register it.
10:15:33 WORKER: registered result for job (5, 0, 0) with dispatcher
10:15:33 DISPATCHER: job (5, 0, 0) finished
10:15:33 DISPATCHER: register_result: lock acquired
10:15:33 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
10:15:33 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 27, 'last_n_outputs': 26, 'lr': 0.002342280911137, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.09531620438008442}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 27, 'last_n_outputs': 26, 'lr': 0.002342280911137, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.09531620438008442}"}}
exception: None

10:15:33 job_callback for (5, 0, 0) started
10:15:33 DISPATCHER: Trying to submit another job.
10:15:33 job_callback for (5, 0, 0) got condition
10:15:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:15:33 done building a new model for budget 133.333333 based on 9/23 split
Best loss for this budget:-0.450975





10:15:33 HBMASTER: Trying to run another job!
10:15:33 job_callback for (5, 0, 0) finished
10:15:33 start sampling a new configuration.
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/statsmodels/nonparametric/kernels.py:62: RuntimeWarning: divide by zero encountered in true_divide
  kernel_value = np.ones(Xi.size) * h / (num_levels - 1)
10:15:33 best_vector: [0, 0.630041072589145, 0.6302760054466905, 0.31528154691556437, 0.14226665597639854, 0, 0.5581737451472133, 0.8467634398706477], 6.783468176389438e-33, 1.474172169747333, -0.03747190069358564
10:15:33 done sampling a new configuration.
10:15:33 HBMASTER: schedule new run for iteration 5
10:15:33 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
10:15:33 HBMASTER: submitting job (5, 0, 1) to dispatcher
10:15:33 DISPATCHER: trying to submit job (5, 0, 1)
10:15:33 DISPATCHER: trying to notify the job_runner thread.
10:15:33 HBMASTER: job (5, 0, 1) submitted to dispatcher
10:15:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:15:33 DISPATCHER: Trying to submit another job.
10:15:33 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:15:33 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:15:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:15:33 WORKER: start processing job (5, 0, 1)
10:15:33 WORKER: args: ()
10:15:33 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 71, 'last_n_outputs': 32, 'lr': 0.004271329683476471, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.12637600854470418}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:16:23 DISPATCHER: Starting worker discovery
10:16:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:16:23 DISPATCHER: Finished worker discovery
Exception in thread Thread-512:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:17:23 DISPATCHER: Starting worker discovery
10:17:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:17:23 DISPATCHER: Finished worker discovery
10:18:23 DISPATCHER: Starting worker discovery
10:18:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:18:23 DISPATCHER: Finished worker discovery
10:18:47 WORKER: done with job (5, 0, 1), trying to register it.
10:18:47 WORKER: registered result for job (5, 0, 1) with dispatcher
10:18:47 DISPATCHER: job (5, 0, 1) finished
10:18:47 DISPATCHER: register_result: lock acquired
10:18:47 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
10:18:47 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 71, 'last_n_outputs': 32, 'lr': 0.004271329683476471, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.12637600854470418}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3492773861549222, 'info': {'sick_no_sick': 0.3492773861549222, 'config': "{'batch_size': 16, 'hidden_dim': 71, 'last_n_outputs': 32, 'lr': 0.004271329683476471, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.12637600854470418}"}}
exception: None

10:18:47 job_callback for (5, 0, 1) started
10:18:47 DISPATCHER: Trying to submit another job.
10:18:47 job_callback for (5, 0, 1) got condition
10:18:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:18:47 done building a new model for budget 133.333333 based on 9/24 split
Best loss for this budget:-0.450975





10:18:47 HBMASTER: Trying to run another job!
10:18:47 job_callback for (5, 0, 1) finished
10:18:47 start sampling a new configuration.
10:18:47 best_vector: [0, 0.6376160810650641, 0.16859701546605632, 0.3752292608485807, 0.33155107842867704, 0, 0.6435162769230098, 0.7350857707075403], 1.3880258594308983e-33, 7.20447672646393, -0.0026649528075955936
10:18:47 done sampling a new configuration.
10:18:47 HBMASTER: schedule new run for iteration 5
10:18:47 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
10:18:47 HBMASTER: submitting job (5, 0, 2) to dispatcher
10:18:47 DISPATCHER: trying to submit job (5, 0, 2)
10:18:47 DISPATCHER: trying to notify the job_runner thread.
10:18:47 HBMASTER: job (5, 0, 2) submitted to dispatcher
10:18:47 DISPATCHER: Trying to submit another job.
10:18:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:18:47 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:18:47 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:18:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:18:47 WORKER: start processing job (5, 0, 2)
10:18:47 WORKER: args: ()
10:18:47 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 71, 'last_n_outputs': 9, 'lr': 0.005629353503790522, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.09044168335034877}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:19:23 DISPATCHER: Starting worker discovery
10:19:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:19:23 DISPATCHER: Finished worker discovery
Exception in thread Thread-513:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:20:23 DISPATCHER: Starting worker discovery
10:20:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:20:23 DISPATCHER: Finished worker discovery
10:21:23 DISPATCHER: Starting worker discovery
10:21:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:21:23 DISPATCHER: Finished worker discovery
10:22:01 WORKER: done with job (5, 0, 2), trying to register it.
10:22:01 WORKER: registered result for job (5, 0, 2) with dispatcher
10:22:01 DISPATCHER: job (5, 0, 2) finished
10:22:01 DISPATCHER: register_result: lock acquired
10:22:01 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
10:22:01 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 71, 'last_n_outputs': 9, 'lr': 0.005629353503790522, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.09044168335034877}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.34892587483413784, 'info': {'sick_no_sick': 0.34892587483413784, 'config': "{'batch_size': 16, 'hidden_dim': 71, 'last_n_outputs': 9, 'lr': 0.005629353503790522, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.09044168335034877}"}}
exception: None

10:22:01 job_callback for (5, 0, 2) started
10:22:01 job_callback for (5, 0, 2) got condition
10:22:01 DISPATCHER: Trying to submit another job.
10:22:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:22:01 done building a new model for budget 133.333333 based on 9/25 split
Best loss for this budget:-0.450975





10:22:01 HBMASTER: Trying to run another job!
10:22:01 job_callback for (5, 0, 2) finished
10:22:01 start sampling a new configuration.
10:22:01 done sampling a new configuration.
10:22:01 HBMASTER: schedule new run for iteration 5
10:22:01 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
10:22:01 HBMASTER: submitting job (5, 0, 3) to dispatcher
10:22:01 DISPATCHER: trying to submit job (5, 0, 3)
10:22:01 DISPATCHER: trying to notify the job_runner thread.
10:22:01 HBMASTER: job (5, 0, 3) submitted to dispatcher
10:22:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:22:01 DISPATCHER: Trying to submit another job.
10:22:01 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:22:01 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:22:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:22:01 WORKER: start processing job (5, 0, 3)
10:22:01 WORKER: args: ()
10:22:01 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 72, 'last_n_outputs': 27, 'lr': 0.08370108552854078, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.011305717294279587}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:22:23 DISPATCHER: Starting worker discovery
10:22:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:22:23 DISPATCHER: Finished worker discovery
Exception in thread Thread-514:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:23:23 DISPATCHER: Starting worker discovery
10:23:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:23:23 DISPATCHER: Finished worker discovery
10:24:23 DISPATCHER: Starting worker discovery
10:24:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:24:23 DISPATCHER: Finished worker discovery
10:25:17 WORKER: done with job (5, 0, 3), trying to register it.
10:25:17 WORKER: registered result for job (5, 0, 3) with dispatcher
10:25:17 DISPATCHER: job (5, 0, 3) finished
10:25:17 DISPATCHER: register_result: lock acquired
10:25:17 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
10:25:17 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 72, 'last_n_outputs': 27, 'lr': 0.08370108552854078, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.011305717294279587}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 72, 'last_n_outputs': 27, 'lr': 0.08370108552854078, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.011305717294279587}"}}
exception: None

10:25:17 job_callback for (5, 0, 3) started
10:25:17 DISPATCHER: Trying to submit another job.
10:25:17 job_callback for (5, 0, 3) got condition
10:25:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:25:17 done building a new model for budget 133.333333 based on 9/26 split
Best loss for this budget:-0.450975





10:25:17 HBMASTER: Trying to run another job!
10:25:17 job_callback for (5, 0, 3) finished
10:25:17 start sampling a new configuration.
10:25:17 best_vector: [0, 0.6248056188874669, 0.008987978494574334, 0.5791428944197523, 0.19454355592036424, 0, 0.6523463439297338, 0.918281598264618], 3.860012795617137e-33, 2.590664987264946, -0.000213785280562637
10:25:17 done sampling a new configuration.
10:25:17 HBMASTER: schedule new run for iteration 5
10:25:17 HBMASTER: trying submitting job (5, 0, 4) to dispatcher
10:25:17 HBMASTER: submitting job (5, 0, 4) to dispatcher
10:25:17 DISPATCHER: trying to submit job (5, 0, 4)
10:25:17 DISPATCHER: trying to notify the job_runner thread.
10:25:17 HBMASTER: job (5, 0, 4) submitted to dispatcher
10:25:17 DISPATCHER: Trying to submit another job.
10:25:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:25:17 DISPATCHER: starting job (5, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:25:17 DISPATCHER: job (5, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:25:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:25:17 WORKER: start processing job (5, 0, 4)
10:25:17 WORKER: args: ()
10:25:17 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 70, 'last_n_outputs': 1, 'lr': 0.014397456957442349, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.15657120853759837}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:25:23 DISPATCHER: Starting worker discovery
10:25:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:25:23 DISPATCHER: Finished worker discovery
Exception in thread Thread-515:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:26:23 DISPATCHER: Starting worker discovery
10:26:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:26:23 DISPATCHER: Finished worker discovery
10:27:23 DISPATCHER: Starting worker discovery
10:27:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:27:23 DISPATCHER: Finished worker discovery
10:28:23 DISPATCHER: Starting worker discovery
10:28:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:28:23 DISPATCHER: Finished worker discovery
10:28:31 WORKER: done with job (5, 0, 4), trying to register it.
10:28:31 WORKER: registered result for job (5, 0, 4) with dispatcher
10:28:31 DISPATCHER: job (5, 0, 4) finished
10:28:31 DISPATCHER: register_result: lock acquired
10:28:31 DISPATCHER: job (5, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
10:28:31 job_id: (5, 0, 4)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 70, 'last_n_outputs': 1, 'lr': 0.014397456957442349, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.15657120853759837}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': 0.003073895602050046, 'info': {'sick_no_sick': -0.003073895602050046, 'config': "{'batch_size': 16, 'hidden_dim': 70, 'last_n_outputs': 1, 'lr': 0.014397456957442349, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.15657120853759837}"}}
exception: None

10:28:31 job_callback for (5, 0, 4) started
10:28:31 job_callback for (5, 0, 4) got condition
10:28:31 DISPATCHER: Trying to submit another job.
10:28:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:28:31 done building a new model for budget 133.333333 based on 9/27 split
Best loss for this budget:-0.450975





10:28:31 HBMASTER: Trying to run another job!
10:28:31 job_callback for (5, 0, 4) finished
10:28:31 start sampling a new configuration.
10:28:31 done sampling a new configuration.
10:28:31 HBMASTER: schedule new run for iteration 5
10:28:31 HBMASTER: trying submitting job (5, 0, 5) to dispatcher
10:28:31 HBMASTER: submitting job (5, 0, 5) to dispatcher
10:28:31 DISPATCHER: trying to submit job (5, 0, 5)
10:28:31 DISPATCHER: trying to notify the job_runner thread.
10:28:31 HBMASTER: job (5, 0, 5) submitted to dispatcher
10:28:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:28:31 DISPATCHER: Trying to submit another job.
10:28:31 DISPATCHER: starting job (5, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:28:31 DISPATCHER: job (5, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:28:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:28:31 WORKER: start processing job (5, 0, 5)
10:28:31 WORKER: args: ()
10:28:31 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 99, 'last_n_outputs': 29, 'lr': 0.006954506936252278, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.06682587428693071}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:29:23 DISPATCHER: Starting worker discovery
10:29:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:29:23 DISPATCHER: Finished worker discovery
Exception in thread Thread-516:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:30:23 DISPATCHER: Starting worker discovery
10:30:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:30:23 DISPATCHER: Finished worker discovery
10:31:23 DISPATCHER: Starting worker discovery
10:31:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:31:23 DISPATCHER: Finished worker discovery
10:31:46 WORKER: done with job (5, 0, 5), trying to register it.
10:31:46 WORKER: registered result for job (5, 0, 5) with dispatcher
10:31:46 DISPATCHER: job (5, 0, 5) finished
10:31:46 DISPATCHER: register_result: lock acquired
10:31:46 DISPATCHER: job (5, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
10:31:46 job_id: (5, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 99, 'last_n_outputs': 29, 'lr': 0.006954506936252278, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.06682587428693071}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': 0.0009832713395137558, 'info': {'sick_no_sick': -0.0009832713395137558, 'config': "{'batch_size': 128, 'hidden_dim': 99, 'last_n_outputs': 29, 'lr': 0.006954506936252278, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.06682587428693071}"}}
exception: None

10:31:46 job_callback for (5, 0, 5) started
10:31:46 job_callback for (5, 0, 5) got condition
10:31:46 DISPATCHER: Trying to submit another job.
10:31:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:31:46 done building a new model for budget 133.333333 based on 9/28 split
Best loss for this budget:-0.450975





10:31:46 HBMASTER: Trying to run another job!
10:31:46 job_callback for (5, 0, 5) finished
10:31:46 start sampling a new configuration.
10:31:46 done sampling a new configuration.
10:31:46 HBMASTER: schedule new run for iteration 5
10:31:46 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
10:31:46 HBMASTER: submitting job (5, 0, 6) to dispatcher
10:31:46 DISPATCHER: trying to submit job (5, 0, 6)
10:31:46 DISPATCHER: trying to notify the job_runner thread.
10:31:46 HBMASTER: job (5, 0, 6) submitted to dispatcher
10:31:46 DISPATCHER: Trying to submit another job.
10:31:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:31:46 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:31:46 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:31:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:31:46 WORKER: start processing job (5, 0, 6)
10:31:46 WORKER: args: ()
10:31:46 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 28, 'last_n_outputs': 49, 'lr': 0.08178409432548772, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.045273806089550554}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:32:23 DISPATCHER: Starting worker discovery
10:32:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:32:23 DISPATCHER: Finished worker discovery
Exception in thread Thread-517:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:33:23 DISPATCHER: Starting worker discovery
10:33:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:33:23 DISPATCHER: Finished worker discovery
10:34:23 DISPATCHER: Starting worker discovery
10:34:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:34:23 DISPATCHER: Finished worker discovery
10:35:01 WORKER: done with job (5, 0, 6), trying to register it.
10:35:01 WORKER: registered result for job (5, 0, 6) with dispatcher
10:35:01 DISPATCHER: job (5, 0, 6) finished
10:35:01 DISPATCHER: register_result: lock acquired
10:35:01 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
10:35:01 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 28, 'last_n_outputs': 49, 'lr': 0.08178409432548772, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.045273806089550554}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.12796885788821588, 'info': {'sick_no_sick': 0.12796885788821588, 'config': "{'batch_size': 16, 'hidden_dim': 28, 'last_n_outputs': 49, 'lr': 0.08178409432548772, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.045273806089550554}"}}
exception: None

10:35:01 job_callback for (5, 0, 6) started
10:35:01 DISPATCHER: Trying to submit another job.
10:35:01 job_callback for (5, 0, 6) got condition
10:35:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:35:01 done building a new model for budget 133.333333 based on 9/28 split
Best loss for this budget:-0.450975





10:35:01 HBMASTER: Trying to run another job!
10:35:01 job_callback for (5, 0, 6) finished
10:35:01 start sampling a new configuration.
10:35:01 best_vector: [0, 0.25909876187937436, 0.05376311342317626, 0.409909420805055, 0.08940393296401089, 0, 0.16367510485424275, 0.3967751917132782], 1.2431086134198185e-31, 0.08044349377074772, -8.317747594841152e-05
10:35:01 done sampling a new configuration.
10:35:01 HBMASTER: schedule new run for iteration 5
10:35:01 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
10:35:01 HBMASTER: submitting job (5, 0, 7) to dispatcher
10:35:01 DISPATCHER: trying to submit job (5, 0, 7)
10:35:01 DISPATCHER: trying to notify the job_runner thread.
10:35:01 HBMASTER: job (5, 0, 7) submitted to dispatcher
10:35:01 DISPATCHER: Trying to submit another job.
10:35:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:35:01 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:35:01 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:35:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:35:01 WORKER: start processing job (5, 0, 7)
10:35:01 WORKER: args: ()
10:35:01 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 40, 'last_n_outputs': 3, 'lr': 0.006604179086987299, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.032825883659785345}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:35:23 DISPATCHER: Starting worker discovery
10:35:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:35:23 DISPATCHER: Finished worker discovery
Exception in thread Thread-518:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:36:23 DISPATCHER: Starting worker discovery
10:36:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:36:23 DISPATCHER: Finished worker discovery
10:37:23 DISPATCHER: Starting worker discovery
10:37:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:37:23 DISPATCHER: Finished worker discovery
10:38:15 WORKER: done with job (5, 0, 7), trying to register it.
10:38:15 WORKER: registered result for job (5, 0, 7) with dispatcher
10:38:15 DISPATCHER: job (5, 0, 7) finished
10:38:15 DISPATCHER: register_result: lock acquired
10:38:15 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
10:38:15 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 40, 'last_n_outputs': 3, 'lr': 0.006604179086987299, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.032825883659785345}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0807286340596476, 'info': {'sick_no_sick': 0.0807286340596476, 'config': "{'batch_size': 16, 'hidden_dim': 40, 'last_n_outputs': 3, 'lr': 0.006604179086987299, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.032825883659785345}"}}
exception: None

10:38:15 job_callback for (5, 0, 7) started
10:38:15 job_callback for (5, 0, 7) got condition
10:38:15 DISPATCHER: Trying to submit another job.
10:38:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:38:15 done building a new model for budget 133.333333 based on 9/29 split
Best loss for this budget:-0.450975





10:38:15 HBMASTER: Trying to run another job!
10:38:15 job_callback for (5, 0, 7) finished
10:38:15 start sampling a new configuration.
10:38:15 done sampling a new configuration.
10:38:15 HBMASTER: schedule new run for iteration 5
10:38:15 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
10:38:15 HBMASTER: submitting job (5, 0, 8) to dispatcher
10:38:15 DISPATCHER: trying to submit job (5, 0, 8)
10:38:15 DISPATCHER: trying to notify the job_runner thread.
10:38:15 HBMASTER: job (5, 0, 8) submitted to dispatcher
10:38:15 DISPATCHER: Trying to submit another job.
10:38:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:38:15 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:38:15 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:38:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:38:15 WORKER: start processing job (5, 0, 8)
10:38:15 WORKER: args: ()
10:38:15 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 87, 'last_n_outputs': 41, 'lr': 0.05274643390703165, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.026887423523412012}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:38:23 DISPATCHER: Starting worker discovery
10:38:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:38:23 DISPATCHER: Finished worker discovery
Exception in thread Thread-519:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:39:23 DISPATCHER: Starting worker discovery
10:39:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:39:23 DISPATCHER: Finished worker discovery
10:40:23 DISPATCHER: Starting worker discovery
10:40:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:40:23 DISPATCHER: Finished worker discovery
10:41:23 DISPATCHER: Starting worker discovery
10:41:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:41:23 DISPATCHER: Finished worker discovery
10:41:28 WORKER: done with job (5, 0, 8), trying to register it.
10:41:28 WORKER: registered result for job (5, 0, 8) with dispatcher
10:41:28 DISPATCHER: job (5, 0, 8) finished
10:41:28 DISPATCHER: register_result: lock acquired
10:41:28 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
10:41:28 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 87, 'last_n_outputs': 41, 'lr': 0.05274643390703165, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.026887423523412012}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 87, 'last_n_outputs': 41, 'lr': 0.05274643390703165, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.026887423523412012}"}}
exception: None

10:41:28 job_callback for (5, 0, 8) started
10:41:28 DISPATCHER: Trying to submit another job.
10:41:28 job_callback for (5, 0, 8) got condition
10:41:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:41:28 done building a new model for budget 133.333333 based on 9/30 split
Best loss for this budget:-0.450975





10:41:28 HBMASTER: Trying to run another job!
10:41:28 job_callback for (5, 0, 8) finished
10:41:28 ITERATION: Advancing config (5, 0, 1) to next budget 400.000000
10:41:28 ITERATION: Advancing config (5, 0, 2) to next budget 400.000000
10:41:28 ITERATION: Advancing config (5, 0, 6) to next budget 400.000000
10:41:28 HBMASTER: schedule new run for iteration 5
10:41:28 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
10:41:28 HBMASTER: submitting job (5, 0, 1) to dispatcher
10:41:28 DISPATCHER: trying to submit job (5, 0, 1)
10:41:28 DISPATCHER: trying to notify the job_runner thread.
10:41:28 HBMASTER: job (5, 0, 1) submitted to dispatcher
10:41:28 DISPATCHER: Trying to submit another job.
10:41:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:41:28 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:41:28 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:41:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:41:28 WORKER: start processing job (5, 0, 1)
10:41:28 WORKER: args: ()
10:41:28 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 71, 'last_n_outputs': 32, 'lr': 0.004271329683476471, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.12637600854470418}, 'budget': 400.0, 'working_directory': '.'}
10:42:23 DISPATCHER: Starting worker discovery
10:42:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:42:23 DISPATCHER: Finished worker discovery
Exception in thread Thread-520:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:43:23 DISPATCHER: Starting worker discovery
10:43:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:43:23 DISPATCHER: Finished worker discovery
10:44:23 DISPATCHER: Starting worker discovery
10:44:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:44:23 DISPATCHER: Finished worker discovery
10:45:23 DISPATCHER: Starting worker discovery
10:45:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:45:23 DISPATCHER: Finished worker discovery
10:46:23 DISPATCHER: Starting worker discovery
10:46:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:46:23 DISPATCHER: Finished worker discovery
10:47:23 DISPATCHER: Starting worker discovery
10:47:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:47:23 DISPATCHER: Finished worker discovery
10:48:23 DISPATCHER: Starting worker discovery
10:48:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:48:23 DISPATCHER: Finished worker discovery
10:49:10 WORKER: done with job (5, 0, 1), trying to register it.
10:49:10 WORKER: registered result for job (5, 0, 1) with dispatcher
10:49:10 DISPATCHER: job (5, 0, 1) finished
10:49:10 DISPATCHER: register_result: lock acquired
10:49:10 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
10:49:10 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 71, 'last_n_outputs': 32, 'lr': 0.004271329683476471, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.12637600854470418}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.39790390332877446, 'info': {'sick_no_sick': 0.39790390332877446, 'config': "{'batch_size': 16, 'hidden_dim': 71, 'last_n_outputs': 32, 'lr': 0.004271329683476471, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.12637600854470418}"}}
exception: None

10:49:10 job_callback for (5, 0, 1) started
10:49:10 DISPATCHER: Trying to submit another job.
10:49:10 job_callback for (5, 0, 1) got condition
10:49:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:49:10 HBMASTER: Trying to run another job!
10:49:10 job_callback for (5, 0, 1) finished
10:49:10 HBMASTER: schedule new run for iteration 5
10:49:10 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
10:49:10 HBMASTER: submitting job (5, 0, 2) to dispatcher
10:49:10 DISPATCHER: trying to submit job (5, 0, 2)
10:49:10 DISPATCHER: trying to notify the job_runner thread.
10:49:10 HBMASTER: job (5, 0, 2) submitted to dispatcher
10:49:10 DISPATCHER: Trying to submit another job.
10:49:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:49:10 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:49:10 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:49:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:49:10 WORKER: start processing job (5, 0, 2)
10:49:10 WORKER: args: ()
10:49:10 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 71, 'last_n_outputs': 9, 'lr': 0.005629353503790522, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.09044168335034877}, 'budget': 400.0, 'working_directory': '.'}
10:49:23 DISPATCHER: Starting worker discovery
10:49:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:49:23 DISPATCHER: Finished worker discovery
Exception in thread Thread-521:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:50:23 DISPATCHER: Starting worker discovery
10:50:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:50:23 DISPATCHER: Finished worker discovery
10:51:23 DISPATCHER: Starting worker discovery
10:51:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:51:23 DISPATCHER: Finished worker discovery
10:52:23 DISPATCHER: Starting worker discovery
10:52:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:52:23 DISPATCHER: Finished worker discovery
10:53:23 DISPATCHER: Starting worker discovery
10:53:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:53:23 DISPATCHER: Finished worker discovery
10:54:23 DISPATCHER: Starting worker discovery
10:54:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:54:23 DISPATCHER: Finished worker discovery
10:55:23 DISPATCHER: Starting worker discovery
10:55:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:55:23 DISPATCHER: Finished worker discovery
10:56:23 DISPATCHER: Starting worker discovery
10:56:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:56:23 DISPATCHER: Finished worker discovery
10:56:51 WORKER: done with job (5, 0, 2), trying to register it.
10:56:51 WORKER: registered result for job (5, 0, 2) with dispatcher
10:56:51 DISPATCHER: job (5, 0, 2) finished
10:56:51 DISPATCHER: register_result: lock acquired
10:56:51 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
10:56:51 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 71, 'last_n_outputs': 9, 'lr': 0.005629353503790522, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.09044168335034877}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.4155588618487816, 'info': {'sick_no_sick': 0.4155588618487816, 'config': "{'batch_size': 16, 'hidden_dim': 71, 'last_n_outputs': 9, 'lr': 0.005629353503790522, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.09044168335034877}"}}
exception: None

10:56:51 job_callback for (5, 0, 2) started
10:56:51 DISPATCHER: Trying to submit another job.
10:56:51 job_callback for (5, 0, 2) got condition
10:56:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:56:51 HBMASTER: Trying to run another job!
10:56:51 job_callback for (5, 0, 2) finished
10:56:51 HBMASTER: schedule new run for iteration 5
10:56:51 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
10:56:51 HBMASTER: submitting job (5, 0, 6) to dispatcher
10:56:51 DISPATCHER: trying to submit job (5, 0, 6)
10:56:51 DISPATCHER: trying to notify the job_runner thread.
10:56:51 HBMASTER: job (5, 0, 6) submitted to dispatcher
10:56:51 DISPATCHER: Trying to submit another job.
10:56:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:56:51 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:56:51 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
10:56:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:56:51 WORKER: start processing job (5, 0, 6)
10:56:51 WORKER: args: ()
10:56:51 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 28, 'last_n_outputs': 49, 'lr': 0.08178409432548772, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.045273806089550554}, 'budget': 400.0, 'working_directory': '.'}
10:57:23 DISPATCHER: Starting worker discovery
10:57:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:57:23 DISPATCHER: Finished worker discovery
Exception in thread Thread-522:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:58:23 DISPATCHER: Starting worker discovery
10:58:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:58:23 DISPATCHER: Finished worker discovery
10:59:23 DISPATCHER: Starting worker discovery
10:59:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:59:23 DISPATCHER: Finished worker discovery
11:00:23 DISPATCHER: Starting worker discovery
11:00:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:00:23 DISPATCHER: Finished worker discovery
11:01:23 DISPATCHER: Starting worker discovery
11:01:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:01:23 DISPATCHER: Finished worker discovery
11:02:23 DISPATCHER: Starting worker discovery
11:02:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:02:23 DISPATCHER: Finished worker discovery
11:03:23 DISPATCHER: Starting worker discovery
11:03:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:03:23 DISPATCHER: Finished worker discovery
11:04:23 DISPATCHER: Starting worker discovery
11:04:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:04:23 DISPATCHER: Finished worker discovery
11:04:32 WORKER: done with job (5, 0, 6), trying to register it.
11:04:32 WORKER: registered result for job (5, 0, 6) with dispatcher
11:04:32 DISPATCHER: job (5, 0, 6) finished
11:04:32 DISPATCHER: register_result: lock acquired
11:04:32 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
11:04:32 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 28, 'last_n_outputs': 49, 'lr': 0.08178409432548772, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.045273806089550554}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.19004381059206438, 'info': {'sick_no_sick': 0.19004381059206438, 'config': "{'batch_size': 16, 'hidden_dim': 28, 'last_n_outputs': 49, 'lr': 0.08178409432548772, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.045273806089550554}"}}
exception: None

11:04:32 job_callback for (5, 0, 6) started
11:04:32 DISPATCHER: Trying to submit another job.
11:04:32 job_callback for (5, 0, 6) got condition
11:04:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:04:32 done building a new model for budget 400.000000 based on 9/15 split
Best loss for this budget:-0.528437





11:04:32 HBMASTER: Trying to run another job!
11:04:32 job_callback for (5, 0, 6) finished
11:04:32 ITERATION: Advancing config (5, 0, 2) to next budget 1200.000000
11:04:32 HBMASTER: schedule new run for iteration 5
11:04:32 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
11:04:32 HBMASTER: submitting job (5, 0, 2) to dispatcher
11:04:32 DISPATCHER: trying to submit job (5, 0, 2)
11:04:32 DISPATCHER: trying to notify the job_runner thread.
11:04:32 HBMASTER: job (5, 0, 2) submitted to dispatcher
11:04:32 DISPATCHER: Trying to submit another job.
11:04:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:04:32 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
11:04:32 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
11:04:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:04:32 WORKER: start processing job (5, 0, 2)
11:04:32 WORKER: args: ()
11:04:32 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 71, 'last_n_outputs': 9, 'lr': 0.005629353503790522, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.09044168335034877}, 'budget': 1200.0, 'working_directory': '.'}
11:05:23 DISPATCHER: Starting worker discovery
11:05:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:05:23 DISPATCHER: Finished worker discovery
Exception in thread Thread-523:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:06:23 DISPATCHER: Starting worker discovery
11:06:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:06:23 DISPATCHER: Finished worker discovery
11:07:23 DISPATCHER: Starting worker discovery
11:07:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:07:23 DISPATCHER: Finished worker discovery
11:08:23 DISPATCHER: Starting worker discovery
11:08:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:08:23 DISPATCHER: Finished worker discovery
11:09:23 DISPATCHER: Starting worker discovery
11:09:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:09:23 DISPATCHER: Finished worker discovery
11:10:23 DISPATCHER: Starting worker discovery
11:10:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:10:23 DISPATCHER: Finished worker discovery
11:11:23 DISPATCHER: Starting worker discovery
11:11:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:11:23 DISPATCHER: Finished worker discovery
11:12:23 DISPATCHER: Starting worker discovery
11:12:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:12:23 DISPATCHER: Finished worker discovery
11:13:23 DISPATCHER: Starting worker discovery
11:13:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:13:23 DISPATCHER: Finished worker discovery
11:14:23 DISPATCHER: Starting worker discovery
11:14:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:14:23 DISPATCHER: Finished worker discovery
11:15:23 DISPATCHER: Starting worker discovery
11:15:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:15:23 DISPATCHER: Finished worker discovery
11:16:23 DISPATCHER: Starting worker discovery
11:16:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:16:23 DISPATCHER: Finished worker discovery
11:17:23 DISPATCHER: Starting worker discovery
11:17:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:17:23 DISPATCHER: Finished worker discovery
11:18:23 DISPATCHER: Starting worker discovery
11:18:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:18:23 DISPATCHER: Finished worker discovery
11:19:23 DISPATCHER: Starting worker discovery
11:19:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:19:23 DISPATCHER: Finished worker discovery
11:20:23 DISPATCHER: Starting worker discovery
11:20:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:20:23 DISPATCHER: Finished worker discovery
11:21:23 DISPATCHER: Starting worker discovery
11:21:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:21:23 DISPATCHER: Finished worker discovery
11:22:23 DISPATCHER: Starting worker discovery
11:22:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:22:23 DISPATCHER: Finished worker discovery
11:23:23 DISPATCHER: Starting worker discovery
11:23:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:23:23 DISPATCHER: Finished worker discovery
11:24:23 DISPATCHER: Starting worker discovery
11:24:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:24:23 DISPATCHER: Finished worker discovery
11:25:23 DISPATCHER: Starting worker discovery
11:25:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:25:23 DISPATCHER: Finished worker discovery
11:25:34 WORKER: done with job (5, 0, 2), trying to register it.
11:25:34 WORKER: registered result for job (5, 0, 2) with dispatcher
11:25:34 DISPATCHER: job (5, 0, 2) finished
11:25:34 DISPATCHER: register_result: lock acquired
11:25:34 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
11:25:34 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 71, 'last_n_outputs': 9, 'lr': 0.005629353503790522, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.09044168335034877}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.3926604623668384, 'info': {'sick_no_sick': 0.3926604623668384, 'config': "{'batch_size': 16, 'hidden_dim': 71, 'last_n_outputs': 9, 'lr': 0.005629353503790522, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.09044168335034877}"}}
exception: None

11:25:34 job_callback for (5, 0, 2) started
11:25:34 DISPATCHER: Trying to submit another job.
11:25:34 job_callback for (5, 0, 2) got condition
11:25:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:25:34 HBMASTER: Trying to run another job!
11:25:34 job_callback for (5, 0, 2) finished
11:25:34 start sampling a new configuration.
11:25:34 best_vector: [3, 0.646431503703885, 0.4949784549142214, 0.31113708265534584, 0.07360389962284795, 0, 0.9696042826773686, 0.7132234130825283], 0.003880297168636658, 8.268799085794655, 0.032085397680634384
11:25:34 done sampling a new configuration.
11:25:34 HBMASTER: schedule new run for iteration 6
11:25:34 HBMASTER: trying submitting job (6, 0, 0) to dispatcher
11:25:34 HBMASTER: submitting job (6, 0, 0) to dispatcher
11:25:34 DISPATCHER: trying to submit job (6, 0, 0)
11:25:34 DISPATCHER: trying to notify the job_runner thread.
11:25:34 HBMASTER: job (6, 0, 0) submitted to dispatcher
11:25:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:25:34 DISPATCHER: Trying to submit another job.
11:25:34 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
11:25:34 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
11:25:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:25:34 WORKER: start processing job (6, 0, 0)
11:25:34 WORKER: args: ()
11:25:34 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 72, 'last_n_outputs': 25, 'lr': 0.004190580283385862, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.08470812211669693}, 'budget': 400.0, 'working_directory': '.'}
11:26:23 DISPATCHER: Starting worker discovery
11:26:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:26:23 DISPATCHER: Finished worker discovery
Exception in thread Thread-524:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:27:23 DISPATCHER: Starting worker discovery
11:27:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:27:23 DISPATCHER: Finished worker discovery
11:28:23 DISPATCHER: Starting worker discovery
11:28:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:28:23 DISPATCHER: Finished worker discovery
11:29:23 DISPATCHER: Starting worker discovery
11:29:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:29:23 DISPATCHER: Finished worker discovery
11:30:23 DISPATCHER: Starting worker discovery
11:30:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:30:23 DISPATCHER: Finished worker discovery
11:31:23 DISPATCHER: Starting worker discovery
11:31:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:31:23 DISPATCHER: Finished worker discovery
11:32:23 DISPATCHER: Starting worker discovery
11:32:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:32:23 DISPATCHER: Finished worker discovery
11:33:14 WORKER: done with job (6, 0, 0), trying to register it.
11:33:14 WORKER: registered result for job (6, 0, 0) with dispatcher
11:33:14 DISPATCHER: job (6, 0, 0) finished
11:33:14 DISPATCHER: register_result: lock acquired
11:33:14 DISPATCHER: job (6, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
11:33:14 job_id: (6, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 72, 'last_n_outputs': 25, 'lr': 0.004190580283385862, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.08470812211669693}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.4202348571854575, 'info': {'sick_no_sick': 0.4202348571854575, 'config': "{'batch_size': 128, 'hidden_dim': 72, 'last_n_outputs': 25, 'lr': 0.004190580283385862, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.08470812211669693}"}}
exception: None

11:33:14 job_callback for (6, 0, 0) started
11:33:14 DISPATCHER: Trying to submit another job.
11:33:14 job_callback for (6, 0, 0) got condition
11:33:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:33:14 done building a new model for budget 400.000000 based on 9/16 split
Best loss for this budget:-0.528437





11:33:14 HBMASTER: Trying to run another job!
11:33:14 job_callback for (6, 0, 0) finished
11:33:14 start sampling a new configuration.
11:33:14 done sampling a new configuration.
11:33:14 HBMASTER: schedule new run for iteration 6
11:33:14 HBMASTER: trying submitting job (6, 0, 1) to dispatcher
11:33:14 HBMASTER: submitting job (6, 0, 1) to dispatcher
11:33:14 DISPATCHER: trying to submit job (6, 0, 1)
11:33:14 DISPATCHER: trying to notify the job_runner thread.
11:33:14 HBMASTER: job (6, 0, 1) submitted to dispatcher
11:33:14 DISPATCHER: Trying to submit another job.
11:33:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:33:14 DISPATCHER: starting job (6, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
11:33:14 DISPATCHER: job (6, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
11:33:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:33:14 WORKER: start processing job (6, 0, 1)
11:33:14 WORKER: args: ()
11:33:14 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 56, 'last_n_outputs': 45, 'lr': 0.004612316936120741, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.08851036564518275}, 'budget': 400.0, 'working_directory': '.'}
11:33:23 DISPATCHER: Starting worker discovery
11:33:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:33:23 DISPATCHER: Finished worker discovery
Exception in thread Thread-525:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:34:23 DISPATCHER: Starting worker discovery
11:34:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:34:23 DISPATCHER: Finished worker discovery
11:35:23 DISPATCHER: Starting worker discovery
11:35:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:35:23 DISPATCHER: Finished worker discovery
11:36:23 DISPATCHER: Starting worker discovery
11:36:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:36:23 DISPATCHER: Finished worker discovery
11:37:23 DISPATCHER: Starting worker discovery
11:37:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:37:23 DISPATCHER: Finished worker discovery
11:38:23 DISPATCHER: Starting worker discovery
11:38:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:38:23 DISPATCHER: Finished worker discovery
11:39:23 DISPATCHER: Starting worker discovery
11:39:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:39:23 DISPATCHER: Finished worker discovery
11:40:23 DISPATCHER: Starting worker discovery
11:40:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:40:23 DISPATCHER: Finished worker discovery
11:40:55 WORKER: done with job (6, 0, 1), trying to register it.
11:40:55 WORKER: registered result for job (6, 0, 1) with dispatcher
11:40:55 DISPATCHER: job (6, 0, 1) finished
11:40:55 DISPATCHER: register_result: lock acquired
11:40:55 DISPATCHER: job (6, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
11:40:55 job_id: (6, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 56, 'last_n_outputs': 45, 'lr': 0.004612316936120741, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.08851036564518275}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 56, 'last_n_outputs': 45, 'lr': 0.004612316936120741, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.08851036564518275}"}}
exception: None

11:40:55 job_callback for (6, 0, 1) started
11:40:55 DISPATCHER: Trying to submit another job.
11:40:55 job_callback for (6, 0, 1) got condition
11:40:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:40:55 done building a new model for budget 400.000000 based on 9/17 split
Best loss for this budget:-0.528437





11:40:55 HBMASTER: Trying to run another job!
11:40:55 job_callback for (6, 0, 1) finished
11:40:55 start sampling a new configuration.
11:40:55 best_vector: [0, 0.5840388224667308, 0.6392418723670159, 0.31861189377575355, 0.10974202168987812, 0, 0.8879405615174802, 0.956318282428744], 6.979244352641072e-34, 14.328198719988677, -0.004850077033848202
11:40:55 done sampling a new configuration.
11:40:55 HBMASTER: schedule new run for iteration 6
11:40:55 HBMASTER: trying submitting job (6, 0, 2) to dispatcher
11:40:55 HBMASTER: submitting job (6, 0, 2) to dispatcher
11:40:55 DISPATCHER: trying to submit job (6, 0, 2)
11:40:55 DISPATCHER: trying to notify the job_runner thread.
11:40:55 HBMASTER: job (6, 0, 2) submitted to dispatcher
11:40:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:40:55 DISPATCHER: Trying to submit another job.
11:40:55 DISPATCHER: starting job (6, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
11:40:55 DISPATCHER: job (6, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
11:40:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:40:55 WORKER: start processing job (6, 0, 2)
11:40:55 WORKER: args: ()
11:40:55 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 67, 'last_n_outputs': 32, 'lr': 0.004337343197196588, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.17546834134827496}, 'budget': 400.0, 'working_directory': '.'}
11:41:23 DISPATCHER: Starting worker discovery
11:41:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:41:23 DISPATCHER: Finished worker discovery
Exception in thread Thread-526:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:42:23 DISPATCHER: Starting worker discovery
11:42:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:42:23 DISPATCHER: Finished worker discovery
11:43:23 DISPATCHER: Starting worker discovery
11:43:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:43:23 DISPATCHER: Finished worker discovery
11:44:23 DISPATCHER: Starting worker discovery
11:44:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:44:23 DISPATCHER: Finished worker discovery
11:45:23 DISPATCHER: Starting worker discovery
11:45:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:45:23 DISPATCHER: Finished worker discovery
11:46:23 DISPATCHER: Starting worker discovery
11:46:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:46:23 DISPATCHER: Finished worker discovery
11:47:23 DISPATCHER: Starting worker discovery
11:47:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:47:23 DISPATCHER: Finished worker discovery
11:48:23 DISPATCHER: Starting worker discovery
11:48:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:48:23 DISPATCHER: Finished worker discovery
11:48:35 WORKER: done with job (6, 0, 2), trying to register it.
11:48:35 WORKER: registered result for job (6, 0, 2) with dispatcher
11:48:35 DISPATCHER: job (6, 0, 2) finished
11:48:35 DISPATCHER: register_result: lock acquired
11:48:35 DISPATCHER: job (6, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
11:48:35 job_id: (6, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 67, 'last_n_outputs': 32, 'lr': 0.004337343197196588, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.17546834134827496}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.07986029145140758, 'info': {'sick_no_sick': 0.07986029145140758, 'config': "{'batch_size': 16, 'hidden_dim': 67, 'last_n_outputs': 32, 'lr': 0.004337343197196588, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.17546834134827496}"}}
exception: None

11:48:35 job_callback for (6, 0, 2) started
11:48:35 job_callback for (6, 0, 2) got condition
11:48:35 DISPATCHER: Trying to submit another job.
11:48:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:48:35 done building a new model for budget 400.000000 based on 9/17 split
Best loss for this budget:-0.528437





11:48:35 HBMASTER: Trying to run another job!
11:48:35 job_callback for (6, 0, 2) finished
11:48:35 start sampling a new configuration.
11:48:35 best_vector: [0, 0.6310929114072986, 0.491412932561315, 0.08244619555390992, 0.1584804939802828, 0, 0.8541711719689173, 0.4643525746818602], 5.2642863076089235e-33, 1.8995927302711755, -0.0008509218975106363
11:48:35 done sampling a new configuration.
11:48:35 HBMASTER: schedule new run for iteration 6
11:48:35 HBMASTER: trying submitting job (6, 0, 3) to dispatcher
11:48:35 HBMASTER: submitting job (6, 0, 3) to dispatcher
11:48:35 DISPATCHER: trying to submit job (6, 0, 3)
11:48:35 DISPATCHER: trying to notify the job_runner thread.
11:48:35 HBMASTER: job (6, 0, 3) submitted to dispatcher
11:48:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:48:35 DISPATCHER: Trying to submit another job.
11:48:35 DISPATCHER: starting job (6, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
11:48:35 DISPATCHER: job (6, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
11:48:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:48:35 WORKER: start processing job (6, 0, 3)
11:48:35 WORKER: args: ()
11:48:35 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 71, 'last_n_outputs': 25, 'lr': 0.00146181492307907, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.04019172333653293}, 'budget': 400.0, 'working_directory': '.'}
11:49:23 DISPATCHER: Starting worker discovery
11:49:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:49:23 DISPATCHER: Finished worker discovery
Exception in thread Thread-527:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:50:23 DISPATCHER: Starting worker discovery
11:50:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:50:23 DISPATCHER: Finished worker discovery
11:51:23 DISPATCHER: Starting worker discovery
11:51:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:51:23 DISPATCHER: Finished worker discovery
11:52:23 DISPATCHER: Starting worker discovery
11:52:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:52:23 DISPATCHER: Finished worker discovery
11:53:23 DISPATCHER: Starting worker discovery
11:53:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:53:23 DISPATCHER: Finished worker discovery
11:54:23 DISPATCHER: Starting worker discovery
11:54:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:54:23 DISPATCHER: Finished worker discovery
11:55:23 DISPATCHER: Starting worker discovery
11:55:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:55:23 DISPATCHER: Finished worker discovery
11:56:16 WORKER: done with job (6, 0, 3), trying to register it.
11:56:16 WORKER: registered result for job (6, 0, 3) with dispatcher
11:56:16 DISPATCHER: job (6, 0, 3) finished
11:56:16 DISPATCHER: register_result: lock acquired
11:56:16 DISPATCHER: job (6, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
11:56:16 job_id: (6, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 71, 'last_n_outputs': 25, 'lr': 0.00146181492307907, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.04019172333653293}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.2216465622385548, 'info': {'sick_no_sick': 0.2216465622385548, 'config': "{'batch_size': 16, 'hidden_dim': 71, 'last_n_outputs': 25, 'lr': 0.00146181492307907, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.04019172333653293}"}}
exception: None

11:56:16 job_callback for (6, 0, 3) started
11:56:16 DISPATCHER: Trying to submit another job.
11:56:16 job_callback for (6, 0, 3) got condition
11:56:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:56:16 done building a new model for budget 400.000000 based on 9/18 split
Best loss for this budget:-0.528437





11:56:16 HBMASTER: Trying to run another job!
11:56:16 job_callback for (6, 0, 3) finished
11:56:16 start sampling a new configuration.
11:56:16 best_vector: [0, 0.5826069292281633, 0.8657149170369192, 0.2242220990851933, 0.05724740532291991, 0, 0.9182588486763066, 0.7089020291857919], 7.263930082564502e-34, 13.766652330537768, -0.012448808396068382
11:56:16 done sampling a new configuration.
11:56:16 HBMASTER: schedule new run for iteration 6
11:56:16 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
11:56:16 HBMASTER: submitting job (6, 0, 4) to dispatcher
11:56:16 DISPATCHER: trying to submit job (6, 0, 4)
11:56:16 DISPATCHER: trying to notify the job_runner thread.
11:56:16 HBMASTER: job (6, 0, 4) submitted to dispatcher
11:56:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:56:16 DISPATCHER: Trying to submit another job.
11:56:16 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776
11:56:16 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
11:56:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:56:16 WORKER: start processing job (6, 0, 4)
11:56:16 WORKER: args: ()
11:56:16 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 67, 'last_n_outputs': 44, 'lr': 0.0028083045148601577, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.08361858304479998}, 'budget': 400.0, 'working_directory': '.'}
11:56:23 DISPATCHER: Starting worker discovery
11:56:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:56:23 DISPATCHER: Finished worker discovery
Exception in thread Thread-528:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:57:23 DISPATCHER: Starting worker discovery
11:57:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:57:23 DISPATCHER: Finished worker discovery
11:58:23 DISPATCHER: Starting worker discovery
11:58:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:58:23 DISPATCHER: Finished worker discovery
11:59:23 DISPATCHER: Starting worker discovery
11:59:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:59:23 DISPATCHER: Finished worker discovery
12:00:23 DISPATCHER: Starting worker discovery
12:00:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:00:23 DISPATCHER: Finished worker discovery
12:01:23 DISPATCHER: Starting worker discovery
12:01:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:01:23 DISPATCHER: Finished worker discovery
12:02:23 DISPATCHER: Starting worker discovery
12:02:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:02:23 DISPATCHER: Finished worker discovery
12:03:23 DISPATCHER: Starting worker discovery
12:03:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:03:23 DISPATCHER: Finished worker discovery
12:03:56 WORKER: done with job (6, 0, 4), trying to register it.
12:03:56 WORKER: registered result for job (6, 0, 4) with dispatcher
12:03:56 DISPATCHER: job (6, 0, 4) finished
12:03:56 DISPATCHER: register_result: lock acquired
12:03:56 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
12:03:56 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 67, 'last_n_outputs': 44, 'lr': 0.0028083045148601577, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.08361858304479998}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3834620782985019, 'info': {'sick_no_sick': 0.3834620782985019, 'config': "{'batch_size': 16, 'hidden_dim': 67, 'last_n_outputs': 44, 'lr': 0.0028083045148601577, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.08361858304479998}"}}
exception: None

12:03:56 job_callback for (6, 0, 4) started
12:03:56 job_callback for (6, 0, 4) got condition
12:03:56 DISPATCHER: Trying to submit another job.
12:03:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:03:56 done building a new model for budget 400.000000 based on 9/19 split
Best loss for this budget:-0.528437





12:03:56 HBMASTER: Trying to run another job!
12:03:56 job_callback for (6, 0, 4) finished
12:03:56 start sampling a new configuration.
12:03:56 best_vector: [3, 0.4176033236418595, 0.7250606580337617, 0.745469222615476, 0.07543590471090135, 0, 0.7880536989370582, 0.49835297210449014], 0.003431406088952724, 26.725326503230676, 0.09170544809243535
12:03:56 done sampling a new configuration.
12:03:56 HBMASTER: schedule new run for iteration 6
12:03:56 HBMASTER: trying submitting job (6, 0, 5) to dispatcher
12:03:56 HBMASTER: submitting job (6, 0, 5) to dispatcher
12:03:56 DISPATCHER: trying to submit job (6, 0, 5)
12:03:56 DISPATCHER: trying to notify the job_runner thread.
12:03:56 HBMASTER: job (6, 0, 5) submitted to dispatcher
12:03:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:03:56 DISPATCHER: Trying to submit another job.
12:03:56 DISPATCHER: starting job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776
12:03:56 DISPATCHER: job (6, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
12:03:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:03:56 WORKER: start processing job (6, 0, 5)
12:03:56 WORKER: args: ()
12:03:56 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 53, 'last_n_outputs': 37, 'lr': 0.03096980317312556, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.04450124539339536}, 'budget': 400.0, 'working_directory': '.'}
12:04:23 DISPATCHER: Starting worker discovery
12:04:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:04:23 DISPATCHER: Finished worker discovery
Exception in thread Thread-529:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

12:05:23 DISPATCHER: Starting worker discovery
12:05:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:05:23 DISPATCHER: Finished worker discovery
12:06:23 DISPATCHER: Starting worker discovery
12:06:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:06:23 DISPATCHER: Finished worker discovery
12:07:23 DISPATCHER: Starting worker discovery
12:07:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:07:23 DISPATCHER: Finished worker discovery
12:08:23 DISPATCHER: Starting worker discovery
12:08:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:08:23 DISPATCHER: Finished worker discovery
12:09:23 DISPATCHER: Starting worker discovery
12:09:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:09:23 DISPATCHER: Finished worker discovery
12:10:23 DISPATCHER: Starting worker discovery
12:10:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:10:23 DISPATCHER: Finished worker discovery
12:11:23 DISPATCHER: Starting worker discovery
12:11:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:11:23 DISPATCHER: Finished worker discovery
12:11:37 WORKER: done with job (6, 0, 5), trying to register it.
12:11:37 WORKER: registered result for job (6, 0, 5) with dispatcher
12:11:37 DISPATCHER: job (6, 0, 5) finished
12:11:37 DISPATCHER: register_result: lock acquired
12:11:37 DISPATCHER: job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
12:11:37 job_id: (6, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 53, 'last_n_outputs': 37, 'lr': 0.03096980317312556, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.04450124539339536}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.2577377655035384, 'info': {'sick_no_sick': 0.2577377655035384, 'config': "{'batch_size': 128, 'hidden_dim': 53, 'last_n_outputs': 37, 'lr': 0.03096980317312556, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.04450124539339536}"}}
exception: None

12:11:37 job_callback for (6, 0, 5) started
12:11:37 DISPATCHER: Trying to submit another job.
12:11:37 job_callback for (6, 0, 5) got condition
12:11:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:11:37 done building a new model for budget 400.000000 based on 9/20 split
Best loss for this budget:-0.528437





12:11:37 HBMASTER: Trying to run another job!
12:11:37 job_callback for (6, 0, 5) finished
12:11:37 ITERATION: Advancing config (6, 0, 0) to next budget 1200.000000
12:11:37 ITERATION: Advancing config (6, 0, 4) to next budget 1200.000000
12:11:37 HBMASTER: schedule new run for iteration 6
12:11:37 HBMASTER: trying submitting job (6, 0, 0) to dispatcher
12:11:37 HBMASTER: submitting job (6, 0, 0) to dispatcher
12:11:37 DISPATCHER: trying to submit job (6, 0, 0)
12:11:37 DISPATCHER: trying to notify the job_runner thread.
12:11:37 HBMASTER: job (6, 0, 0) submitted to dispatcher
12:11:37 DISPATCHER: Trying to submit another job.
12:11:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:11:37 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
12:11:37 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
12:11:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:11:37 WORKER: start processing job (6, 0, 0)
12:11:37 WORKER: args: ()
12:11:37 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 72, 'last_n_outputs': 25, 'lr': 0.004190580283385862, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.08470812211669693}, 'budget': 1200.0, 'working_directory': '.'}
12:12:23 DISPATCHER: Starting worker discovery
12:12:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:12:23 DISPATCHER: Finished worker discovery
Exception in thread Thread-530:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

12:13:23 DISPATCHER: Starting worker discovery
12:13:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:13:23 DISPATCHER: Finished worker discovery
12:14:23 DISPATCHER: Starting worker discovery
12:14:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:14:23 DISPATCHER: Finished worker discovery
12:15:23 DISPATCHER: Starting worker discovery
12:15:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:15:23 DISPATCHER: Finished worker discovery
12:16:23 DISPATCHER: Starting worker discovery
12:16:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:16:23 DISPATCHER: Finished worker discovery
12:17:23 DISPATCHER: Starting worker discovery
12:17:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:17:23 DISPATCHER: Finished worker discovery
12:18:23 DISPATCHER: Starting worker discovery
12:18:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:18:23 DISPATCHER: Finished worker discovery
12:19:23 DISPATCHER: Starting worker discovery
12:19:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:19:23 DISPATCHER: Finished worker discovery
12:20:23 DISPATCHER: Starting worker discovery
12:20:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:20:23 DISPATCHER: Finished worker discovery
12:21:23 DISPATCHER: Starting worker discovery
12:21:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:21:23 DISPATCHER: Finished worker discovery
12:22:23 DISPATCHER: Starting worker discovery
12:22:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:22:23 DISPATCHER: Finished worker discovery
12:23:23 DISPATCHER: Starting worker discovery
12:23:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:23:23 DISPATCHER: Finished worker discovery
12:24:23 DISPATCHER: Starting worker discovery
12:24:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:24:23 DISPATCHER: Finished worker discovery
12:25:23 DISPATCHER: Starting worker discovery
12:25:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:25:23 DISPATCHER: Finished worker discovery
12:26:23 DISPATCHER: Starting worker discovery
12:26:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:26:23 DISPATCHER: Finished worker discovery
12:27:23 DISPATCHER: Starting worker discovery
12:27:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:27:23 DISPATCHER: Finished worker discovery
12:28:23 DISPATCHER: Starting worker discovery
12:28:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:28:23 DISPATCHER: Finished worker discovery
12:29:23 DISPATCHER: Starting worker discovery
12:29:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:29:23 DISPATCHER: Finished worker discovery
12:30:23 DISPATCHER: Starting worker discovery
12:30:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:30:23 DISPATCHER: Finished worker discovery
12:31:23 DISPATCHER: Starting worker discovery
12:31:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:31:23 DISPATCHER: Finished worker discovery
12:32:23 DISPATCHER: Starting worker discovery
12:32:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:32:23 DISPATCHER: Finished worker discovery
12:32:39 WORKER: done with job (6, 0, 0), trying to register it.
12:32:39 WORKER: registered result for job (6, 0, 0) with dispatcher
12:32:39 DISPATCHER: job (6, 0, 0) finished
12:32:39 DISPATCHER: register_result: lock acquired
12:32:39 DISPATCHER: job (6, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
12:32:39 job_id: (6, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 72, 'last_n_outputs': 25, 'lr': 0.004190580283385862, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.08470812211669693}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.4335971643060711, 'info': {'sick_no_sick': 0.4335971643060711, 'config': "{'batch_size': 128, 'hidden_dim': 72, 'last_n_outputs': 25, 'lr': 0.004190580283385862, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.08470812211669693}"}}
exception: None

12:32:39 job_callback for (6, 0, 0) started
12:32:39 DISPATCHER: Trying to submit another job.
12:32:39 job_callback for (6, 0, 0) got condition
12:32:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:32:39 HBMASTER: Trying to run another job!
12:32:39 job_callback for (6, 0, 0) finished
12:32:39 HBMASTER: schedule new run for iteration 6
12:32:39 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
12:32:39 HBMASTER: submitting job (6, 0, 4) to dispatcher
12:32:39 DISPATCHER: trying to submit job (6, 0, 4)
12:32:39 DISPATCHER: trying to notify the job_runner thread.
12:32:39 HBMASTER: job (6, 0, 4) submitted to dispatcher
12:32:39 DISPATCHER: Trying to submit another job.
12:32:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:32:39 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776
12:32:39 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
12:32:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:32:39 WORKER: start processing job (6, 0, 4)
12:32:39 WORKER: args: ()
12:32:39 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 67, 'last_n_outputs': 44, 'lr': 0.0028083045148601577, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.08361858304479998}, 'budget': 1200.0, 'working_directory': '.'}
12:33:23 DISPATCHER: Starting worker discovery
12:33:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:33:23 DISPATCHER: Finished worker discovery
Exception in thread Thread-531:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

12:34:23 DISPATCHER: Starting worker discovery
12:34:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:34:23 DISPATCHER: Finished worker discovery
12:35:23 DISPATCHER: Starting worker discovery
12:35:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:35:23 DISPATCHER: Finished worker discovery
12:36:23 DISPATCHER: Starting worker discovery
12:36:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:36:24 DISPATCHER: Finished worker discovery
12:37:24 DISPATCHER: Starting worker discovery
12:37:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:37:24 DISPATCHER: Finished worker discovery
12:38:24 DISPATCHER: Starting worker discovery
12:38:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:38:24 DISPATCHER: Finished worker discovery
12:39:24 DISPATCHER: Starting worker discovery
12:39:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:39:24 DISPATCHER: Finished worker discovery
12:40:24 DISPATCHER: Starting worker discovery
12:40:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:40:24 DISPATCHER: Finished worker discovery
12:41:24 DISPATCHER: Starting worker discovery
12:41:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:41:24 DISPATCHER: Finished worker discovery
12:42:24 DISPATCHER: Starting worker discovery
12:42:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:42:24 DISPATCHER: Finished worker discovery
12:43:24 DISPATCHER: Starting worker discovery
12:43:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:43:24 DISPATCHER: Finished worker discovery
12:44:24 DISPATCHER: Starting worker discovery
12:44:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:44:24 DISPATCHER: Finished worker discovery
12:45:24 DISPATCHER: Starting worker discovery
12:45:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:45:24 DISPATCHER: Finished worker discovery
12:46:24 DISPATCHER: Starting worker discovery
12:46:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:46:24 DISPATCHER: Finished worker discovery
12:47:24 DISPATCHER: Starting worker discovery
12:47:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:47:24 DISPATCHER: Finished worker discovery
12:48:24 DISPATCHER: Starting worker discovery
12:48:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:48:24 DISPATCHER: Finished worker discovery
12:49:24 DISPATCHER: Starting worker discovery
12:49:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:49:24 DISPATCHER: Finished worker discovery
12:50:24 DISPATCHER: Starting worker discovery
12:50:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:50:24 DISPATCHER: Finished worker discovery
12:51:24 DISPATCHER: Starting worker discovery
12:51:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:51:24 DISPATCHER: Finished worker discovery
12:52:24 DISPATCHER: Starting worker discovery
12:52:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:52:24 DISPATCHER: Finished worker discovery
12:53:24 DISPATCHER: Starting worker discovery
12:53:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:53:24 DISPATCHER: Finished worker discovery
12:53:40 WORKER: done with job (6, 0, 4), trying to register it.
12:53:40 WORKER: registered result for job (6, 0, 4) with dispatcher
12:53:40 DISPATCHER: job (6, 0, 4) finished
12:53:40 DISPATCHER: register_result: lock acquired
12:53:40 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
12:53:40 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 67, 'last_n_outputs': 44, 'lr': 0.0028083045148601577, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.08361858304479998}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.28632976644859587, 'info': {'sick_no_sick': 0.28632976644859587, 'config': "{'batch_size': 16, 'hidden_dim': 67, 'last_n_outputs': 44, 'lr': 0.0028083045148601577, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.08361858304479998}"}}
exception: None

12:53:40 job_callback for (6, 0, 4) started
12:53:40 DISPATCHER: Trying to submit another job.
12:53:40 job_callback for (6, 0, 4) got condition
12:53:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:53:40 HBMASTER: Trying to run another job!
12:53:40 job_callback for (6, 0, 4) finished
12:53:40 start sampling a new configuration.
12:53:40 best_vector: [1, 0.6670479063811443, 0.4290198957930371, 0.2691864051651603, 0.10004574943638683, 0, 0.996585448645631, 0.74389968935583], 0.0014937747343269539, 274.24923239903757, 0.40966657426624337
12:53:40 done sampling a new configuration.
12:53:40 HBMASTER: schedule new run for iteration 7
12:53:40 HBMASTER: trying submitting job (7, 0, 0) to dispatcher
12:53:40 HBMASTER: submitting job (7, 0, 0) to dispatcher
12:53:40 DISPATCHER: trying to submit job (7, 0, 0)
12:53:40 DISPATCHER: trying to notify the job_runner thread.
12:53:40 HBMASTER: job (7, 0, 0) submitted to dispatcher
12:53:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:53:40 DISPATCHER: Trying to submit another job.
12:53:40 DISPATCHER: starting job (7, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
12:53:40 DISPATCHER: job (7, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
12:53:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:53:40 WORKER: start processing job (7, 0, 0)
12:53:40 WORKER: args: ()
12:53:40 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 74, 'last_n_outputs': 22, 'lr': 0.003454401474205245, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.09286152459656813}, 'budget': 1200.0, 'working_directory': '.'}
12:54:24 DISPATCHER: Starting worker discovery
12:54:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:54:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-532:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

12:55:24 DISPATCHER: Starting worker discovery
12:55:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:55:24 DISPATCHER: Finished worker discovery
12:56:24 DISPATCHER: Starting worker discovery
12:56:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:56:24 DISPATCHER: Finished worker discovery
12:57:24 DISPATCHER: Starting worker discovery
12:57:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:57:24 DISPATCHER: Finished worker discovery
12:58:24 DISPATCHER: Starting worker discovery
12:58:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:58:24 DISPATCHER: Finished worker discovery
12:59:24 DISPATCHER: Starting worker discovery
12:59:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:59:24 DISPATCHER: Finished worker discovery
13:00:24 DISPATCHER: Starting worker discovery
13:00:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:00:24 DISPATCHER: Finished worker discovery
13:01:24 DISPATCHER: Starting worker discovery
13:01:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:01:24 DISPATCHER: Finished worker discovery
13:02:24 DISPATCHER: Starting worker discovery
13:02:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:02:24 DISPATCHER: Finished worker discovery
13:03:24 DISPATCHER: Starting worker discovery
13:03:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:03:24 DISPATCHER: Finished worker discovery
13:04:24 DISPATCHER: Starting worker discovery
13:04:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:04:24 DISPATCHER: Finished worker discovery
13:05:24 DISPATCHER: Starting worker discovery
13:05:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:05:24 DISPATCHER: Finished worker discovery
13:06:24 DISPATCHER: Starting worker discovery
13:06:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:06:24 DISPATCHER: Finished worker discovery
13:07:24 DISPATCHER: Starting worker discovery
13:07:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:07:24 DISPATCHER: Finished worker discovery
13:08:24 DISPATCHER: Starting worker discovery
13:08:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:08:24 DISPATCHER: Finished worker discovery
13:09:24 DISPATCHER: Starting worker discovery
13:09:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:09:24 DISPATCHER: Finished worker discovery
13:10:24 DISPATCHER: Starting worker discovery
13:10:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:10:24 DISPATCHER: Finished worker discovery
13:11:24 DISPATCHER: Starting worker discovery
13:11:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:11:24 DISPATCHER: Finished worker discovery
13:12:24 DISPATCHER: Starting worker discovery
13:12:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:12:24 DISPATCHER: Finished worker discovery
13:13:24 DISPATCHER: Starting worker discovery
13:13:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:13:24 DISPATCHER: Finished worker discovery
13:14:24 DISPATCHER: Starting worker discovery
13:14:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:14:24 DISPATCHER: Finished worker discovery
13:14:41 WORKER: done with job (7, 0, 0), trying to register it.
13:14:41 WORKER: registered result for job (7, 0, 0) with dispatcher
13:14:41 DISPATCHER: job (7, 0, 0) finished
13:14:41 DISPATCHER: register_result: lock acquired
13:14:41 DISPATCHER: job (7, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
13:14:41 job_id: (7, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 74, 'last_n_outputs': 22, 'lr': 0.003454401474205245, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.09286152459656813}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.2958377484770878, 'info': {'sick_no_sick': 0.2958377484770878, 'config': "{'batch_size': 32, 'hidden_dim': 74, 'last_n_outputs': 22, 'lr': 0.003454401474205245, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.09286152459656813}"}}
exception: None

13:14:41 job_callback for (7, 0, 0) started
13:14:41 DISPATCHER: Trying to submit another job.
13:14:41 job_callback for (7, 0, 0) got condition
13:14:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:14:41 HBMASTER: Trying to run another job!
13:14:41 job_callback for (7, 0, 0) finished
13:14:41 start sampling a new configuration.
13:14:41 done sampling a new configuration.
13:14:41 HBMASTER: schedule new run for iteration 7
13:14:41 HBMASTER: trying submitting job (7, 0, 1) to dispatcher
13:14:41 HBMASTER: submitting job (7, 0, 1) to dispatcher
13:14:41 DISPATCHER: trying to submit job (7, 0, 1)
13:14:41 DISPATCHER: trying to notify the job_runner thread.
13:14:41 HBMASTER: job (7, 0, 1) submitted to dispatcher
13:14:41 DISPATCHER: Trying to submit another job.
13:14:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:14:41 DISPATCHER: starting job (7, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
13:14:41 DISPATCHER: job (7, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
13:14:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:14:41 WORKER: start processing job (7, 0, 1)
13:14:41 WORKER: args: ()
13:14:41 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 94, 'last_n_outputs': 8, 'lr': 0.07668340496317362, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.09825380594238009}, 'budget': 1200.0, 'working_directory': '.'}
13:15:24 DISPATCHER: Starting worker discovery
13:15:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:15:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-533:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:16:24 DISPATCHER: Starting worker discovery
13:16:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:16:24 DISPATCHER: Finished worker discovery
13:17:24 DISPATCHER: Starting worker discovery
13:17:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:17:24 DISPATCHER: Finished worker discovery
13:18:24 DISPATCHER: Starting worker discovery
13:18:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:18:24 DISPATCHER: Finished worker discovery
13:19:24 DISPATCHER: Starting worker discovery
13:19:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:19:24 DISPATCHER: Finished worker discovery
13:20:24 DISPATCHER: Starting worker discovery
13:20:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:20:24 DISPATCHER: Finished worker discovery
13:21:24 DISPATCHER: Starting worker discovery
13:21:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:21:24 DISPATCHER: Finished worker discovery
13:22:24 DISPATCHER: Starting worker discovery
13:22:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:22:24 DISPATCHER: Finished worker discovery
13:23:24 DISPATCHER: Starting worker discovery
13:23:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:23:24 DISPATCHER: Finished worker discovery
13:24:24 DISPATCHER: Starting worker discovery
13:24:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:24:24 DISPATCHER: Finished worker discovery
13:25:24 DISPATCHER: Starting worker discovery
13:25:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:25:24 DISPATCHER: Finished worker discovery
13:26:24 DISPATCHER: Starting worker discovery
13:26:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:26:24 DISPATCHER: Finished worker discovery
13:27:24 DISPATCHER: Starting worker discovery
13:27:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:27:24 DISPATCHER: Finished worker discovery
13:28:24 DISPATCHER: Starting worker discovery
13:28:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:28:24 DISPATCHER: Finished worker discovery
13:29:24 DISPATCHER: Starting worker discovery
13:29:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:29:24 DISPATCHER: Finished worker discovery
13:30:24 DISPATCHER: Starting worker discovery
13:30:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:30:24 DISPATCHER: Finished worker discovery
13:31:24 DISPATCHER: Starting worker discovery
13:31:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:31:24 DISPATCHER: Finished worker discovery
13:32:24 DISPATCHER: Starting worker discovery
13:32:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:32:24 DISPATCHER: Finished worker discovery
13:33:24 DISPATCHER: Starting worker discovery
13:33:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:33:24 DISPATCHER: Finished worker discovery
13:34:24 DISPATCHER: Starting worker discovery
13:34:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:34:24 DISPATCHER: Finished worker discovery
13:35:24 DISPATCHER: Starting worker discovery
13:35:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:35:24 DISPATCHER: Finished worker discovery
13:35:42 WORKER: done with job (7, 0, 1), trying to register it.
13:35:42 WORKER: registered result for job (7, 0, 1) with dispatcher
13:35:42 DISPATCHER: job (7, 0, 1) finished
13:35:42 DISPATCHER: register_result: lock acquired
13:35:42 DISPATCHER: job (7, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
13:35:42 job_id: (7, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 94, 'last_n_outputs': 8, 'lr': 0.07668340496317362, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.09825380594238009}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.18210051551354056, 'info': {'sick_no_sick': 0.18210051551354056, 'config': "{'batch_size': 32, 'hidden_dim': 94, 'last_n_outputs': 8, 'lr': 0.07668340496317362, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.09825380594238009}"}}
exception: None

13:35:42 job_callback for (7, 0, 1) started
13:35:42 DISPATCHER: Trying to submit another job.
13:35:42 job_callback for (7, 0, 1) got condition
13:35:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:35:42 HBMASTER: Trying to run another job!
13:35:42 job_callback for (7, 0, 1) finished
13:35:42 start sampling a new configuration.
13:35:42 best_vector: [0, 0.7746138722309909, 0.5981145524761751, 0.11711958861699215, 0.14734672645076788, 0, 0.8440847272629861, 0.7176993161896876], 3.230102237697524e-33, 3.0958772398263728, -0.04940946098374608
13:35:42 done sampling a new configuration.
13:35:42 HBMASTER: schedule new run for iteration 7
13:35:42 HBMASTER: trying submitting job (7, 0, 2) to dispatcher
13:35:42 HBMASTER: submitting job (7, 0, 2) to dispatcher
13:35:42 DISPATCHER: trying to submit job (7, 0, 2)
13:35:42 DISPATCHER: trying to notify the job_runner thread.
13:35:42 HBMASTER: job (7, 0, 2) submitted to dispatcher
13:35:42 DISPATCHER: Trying to submit another job.
13:35:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:35:42 DISPATCHER: starting job (7, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
13:35:42 DISPATCHER: job (7, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
13:35:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:35:42 WORKER: start processing job (7, 0, 2)
13:35:42 WORKER: args: ()
13:35:42 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 82, 'last_n_outputs': 30, 'lr': 0.0017149014882152152, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.08585158908684365}, 'budget': 1200.0, 'working_directory': '.'}
13:36:24 DISPATCHER: Starting worker discovery
13:36:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:36:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-534:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:37:24 DISPATCHER: Starting worker discovery
13:37:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:37:24 DISPATCHER: Finished worker discovery
13:38:24 DISPATCHER: Starting worker discovery
13:38:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:38:24 DISPATCHER: Finished worker discovery
13:39:24 DISPATCHER: Starting worker discovery
13:39:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:39:24 DISPATCHER: Finished worker discovery
13:40:24 DISPATCHER: Starting worker discovery
13:40:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:40:24 DISPATCHER: Finished worker discovery
13:41:24 DISPATCHER: Starting worker discovery
13:41:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:41:24 DISPATCHER: Finished worker discovery
13:42:24 DISPATCHER: Starting worker discovery
13:42:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:42:24 DISPATCHER: Finished worker discovery
13:43:24 DISPATCHER: Starting worker discovery
13:43:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:43:24 DISPATCHER: Finished worker discovery
13:44:24 DISPATCHER: Starting worker discovery
13:44:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:44:24 DISPATCHER: Finished worker discovery
13:45:24 DISPATCHER: Starting worker discovery
13:45:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:45:24 DISPATCHER: Finished worker discovery
13:46:24 DISPATCHER: Starting worker discovery
13:46:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:46:24 DISPATCHER: Finished worker discovery
13:47:24 DISPATCHER: Starting worker discovery
13:47:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:47:24 DISPATCHER: Finished worker discovery
13:48:24 DISPATCHER: Starting worker discovery
13:48:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:48:24 DISPATCHER: Finished worker discovery
13:49:24 DISPATCHER: Starting worker discovery
13:49:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:49:24 DISPATCHER: Finished worker discovery
13:50:24 DISPATCHER: Starting worker discovery
13:50:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:50:24 DISPATCHER: Finished worker discovery
13:51:24 DISPATCHER: Starting worker discovery
13:51:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:51:24 DISPATCHER: Finished worker discovery
13:52:24 DISPATCHER: Starting worker discovery
13:52:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:52:24 DISPATCHER: Finished worker discovery
13:53:24 DISPATCHER: Starting worker discovery
13:53:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:53:24 DISPATCHER: Finished worker discovery
13:54:24 DISPATCHER: Starting worker discovery
13:54:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:54:24 DISPATCHER: Finished worker discovery
13:55:24 DISPATCHER: Starting worker discovery
13:55:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:55:24 DISPATCHER: Finished worker discovery
13:56:24 DISPATCHER: Starting worker discovery
13:56:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:56:24 DISPATCHER: Finished worker discovery
13:56:44 WORKER: done with job (7, 0, 2), trying to register it.
13:56:44 WORKER: registered result for job (7, 0, 2) with dispatcher
13:56:44 DISPATCHER: job (7, 0, 2) finished
13:56:44 DISPATCHER: register_result: lock acquired
13:56:44 DISPATCHER: job (7, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
13:56:44 job_id: (7, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 82, 'last_n_outputs': 30, 'lr': 0.0017149014882152152, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.08585158908684365}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.3563318430479044, 'info': {'sick_no_sick': 0.3563318430479044, 'config': "{'batch_size': 16, 'hidden_dim': 82, 'last_n_outputs': 30, 'lr': 0.0017149014882152152, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.08585158908684365}"}}
exception: None

13:56:44 job_callback for (7, 0, 2) started
13:56:44 DISPATCHER: Trying to submit another job.
13:56:44 job_callback for (7, 0, 2) got condition
13:56:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:56:44 HBMASTER: Trying to run another job!
13:56:44 job_callback for (7, 0, 2) finished
13:56:44 start sampling a new configuration.
13:56:44 best_vector: [0, 0.6148816779827073, 0.932989758895117, 0.1573522748418561, 0.17041506550450097, 0, 0.9715945965053969, 0.49730033149346486], 7.638413683630433e-34, 13.09172350985727, -0.004270705097661986
13:56:44 done sampling a new configuration.
13:56:44 HBMASTER: schedule new run for iteration 7
13:56:44 HBMASTER: trying submitting job (7, 0, 3) to dispatcher
13:56:44 HBMASTER: submitting job (7, 0, 3) to dispatcher
13:56:44 DISPATCHER: trying to submit job (7, 0, 3)
13:56:44 DISPATCHER: trying to notify the job_runner thread.
13:56:44 HBMASTER: job (7, 0, 3) submitted to dispatcher
13:56:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:56:44 DISPATCHER: Trying to submit another job.
13:56:44 DISPATCHER: starting job (7, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
13:56:44 DISPATCHER: job (7, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
13:56:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:56:44 WORKER: start processing job (7, 0, 3)
13:56:44 WORKER: args: ()
13:56:44 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 69, 'last_n_outputs': 47, 'lr': 0.002063975556563854, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.04436113488597652}, 'budget': 1200.0, 'working_directory': '.'}
13:57:24 DISPATCHER: Starting worker discovery
13:57:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:57:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-535:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:58:24 DISPATCHER: Starting worker discovery
13:58:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:58:24 DISPATCHER: Finished worker discovery
13:59:24 DISPATCHER: Starting worker discovery
13:59:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:59:24 DISPATCHER: Finished worker discovery
14:00:24 DISPATCHER: Starting worker discovery
14:00:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:00:24 DISPATCHER: Finished worker discovery
14:01:24 DISPATCHER: Starting worker discovery
14:01:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:01:24 DISPATCHER: Finished worker discovery
14:02:24 DISPATCHER: Starting worker discovery
14:02:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:02:24 DISPATCHER: Finished worker discovery
14:03:24 DISPATCHER: Starting worker discovery
14:03:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:03:24 DISPATCHER: Finished worker discovery
14:04:24 DISPATCHER: Starting worker discovery
14:04:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:04:24 DISPATCHER: Finished worker discovery
14:05:24 DISPATCHER: Starting worker discovery
14:05:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:05:24 DISPATCHER: Finished worker discovery
14:06:24 DISPATCHER: Starting worker discovery
14:06:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:06:24 DISPATCHER: Finished worker discovery
14:07:24 DISPATCHER: Starting worker discovery
14:07:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:07:24 DISPATCHER: Finished worker discovery
14:08:24 DISPATCHER: Starting worker discovery
14:08:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:08:24 DISPATCHER: Finished worker discovery
14:09:24 DISPATCHER: Starting worker discovery
14:09:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:09:24 DISPATCHER: Finished worker discovery
14:10:24 DISPATCHER: Starting worker discovery
14:10:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:10:24 DISPATCHER: Finished worker discovery
14:11:24 DISPATCHER: Starting worker discovery
14:11:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:11:24 DISPATCHER: Finished worker discovery
14:12:24 DISPATCHER: Starting worker discovery
14:12:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:12:24 DISPATCHER: Finished worker discovery
14:13:24 DISPATCHER: Starting worker discovery
14:13:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:13:24 DISPATCHER: Finished worker discovery
14:14:24 DISPATCHER: Starting worker discovery
14:14:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:14:24 DISPATCHER: Finished worker discovery
14:15:24 DISPATCHER: Starting worker discovery
14:15:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:15:24 DISPATCHER: Finished worker discovery
14:16:24 DISPATCHER: Starting worker discovery
14:16:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:16:24 DISPATCHER: Finished worker discovery
14:17:24 DISPATCHER: Starting worker discovery
14:17:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:17:24 DISPATCHER: Finished worker discovery
14:17:45 WORKER: done with job (7, 0, 3), trying to register it.
14:17:45 WORKER: registered result for job (7, 0, 3) with dispatcher
14:17:45 DISPATCHER: job (7, 0, 3) finished
14:17:45 DISPATCHER: register_result: lock acquired
14:17:45 DISPATCHER: job (7, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
14:17:45 job_id: (7, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 69, 'last_n_outputs': 47, 'lr': 0.002063975556563854, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.04436113488597652}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.4215561890447956, 'info': {'sick_no_sick': 0.4215561890447956, 'config': "{'batch_size': 16, 'hidden_dim': 69, 'last_n_outputs': 47, 'lr': 0.002063975556563854, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.04436113488597652}"}}
exception: None

14:17:45 job_callback for (7, 0, 3) started
14:17:45 DISPATCHER: Trying to submit another job.
14:17:45 job_callback for (7, 0, 3) got condition
14:17:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:17:45 HBMASTER: Trying to run another job!
14:17:45 job_callback for (7, 0, 3) finished
14:17:45 start sampling a new configuration.
14:17:45 done sampling a new configuration.
14:17:45 HBMASTER: schedule new run for iteration 8
14:17:45 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
14:17:45 HBMASTER: submitting job (8, 0, 0) to dispatcher
14:17:45 DISPATCHER: trying to submit job (8, 0, 0)
14:17:45 DISPATCHER: trying to notify the job_runner thread.
14:17:45 HBMASTER: job (8, 0, 0) submitted to dispatcher
14:17:45 DISPATCHER: Trying to submit another job.
14:17:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:17:45 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:17:45 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:17:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:17:45 WORKER: start processing job (8, 0, 0)
14:17:45 WORKER: args: ()
14:17:45 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 87, 'last_n_outputs': 23, 'lr': 0.003689683779516607, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.016762532303606904}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:18:24 DISPATCHER: Starting worker discovery
14:18:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:18:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-536:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:19:24 DISPATCHER: Starting worker discovery
14:19:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:19:24 DISPATCHER: Finished worker discovery
14:19:32 WORKER: done with job (8, 0, 0), trying to register it.
14:19:32 WORKER: registered result for job (8, 0, 0) with dispatcher
14:19:32 DISPATCHER: job (8, 0, 0) finished
14:19:32 DISPATCHER: register_result: lock acquired
14:19:32 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
14:19:32 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 87, 'last_n_outputs': 23, 'lr': 0.003689683779516607, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.016762532303606904}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.00809411035149321, 'info': {'sick_no_sick': 0.00809411035149321, 'config': "{'batch_size': 32, 'hidden_dim': 87, 'last_n_outputs': 23, 'lr': 0.003689683779516607, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.016762532303606904}"}}
exception: None

14:19:32 job_callback for (8, 0, 0) started
14:19:32 job_callback for (8, 0, 0) got condition
14:19:32 DISPATCHER: Trying to submit another job.
14:19:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:19:32 HBMASTER: Trying to run another job!
14:19:32 job_callback for (8, 0, 0) finished
14:19:32 start sampling a new configuration.
14:19:32 best_vector: [0, 0.4836450605953559, 0.5671989449022989, 0.3124944916021628, 0.0951347199413448, 0, 0.780712485419592, 0.7425217416574476], 7.809617129768008e-34, 12.804725038162095, -0.0037292358311081155
14:19:32 done sampling a new configuration.
14:19:32 HBMASTER: schedule new run for iteration 8
14:19:32 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
14:19:32 HBMASTER: submitting job (8, 0, 1) to dispatcher
14:19:32 DISPATCHER: trying to submit job (8, 0, 1)
14:19:32 DISPATCHER: trying to notify the job_runner thread.
14:19:32 HBMASTER: job (8, 0, 1) submitted to dispatcher
14:19:32 DISPATCHER: Trying to submit another job.
14:19:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:19:32 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:19:32 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:19:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:19:32 WORKER: start processing job (8, 0, 1)
14:19:32 WORKER: args: ()
14:19:32 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 59, 'last_n_outputs': 29, 'lr': 0.0042168580634288485, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.0924789858114997}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:20:24 DISPATCHER: Starting worker discovery
14:20:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:20:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-537:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:21:18 WORKER: done with job (8, 0, 1), trying to register it.
14:21:18 WORKER: registered result for job (8, 0, 1) with dispatcher
14:21:18 DISPATCHER: job (8, 0, 1) finished
14:21:18 DISPATCHER: register_result: lock acquired
14:21:18 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
14:21:18 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 59, 'last_n_outputs': 29, 'lr': 0.0042168580634288485, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.0924789858114997}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2893097225096257, 'info': {'sick_no_sick': 0.2893097225096257, 'config': "{'batch_size': 16, 'hidden_dim': 59, 'last_n_outputs': 29, 'lr': 0.0042168580634288485, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.0924789858114997}"}}
exception: None

14:21:18 job_callback for (8, 0, 1) started
14:21:18 DISPATCHER: Trying to submit another job.
14:21:18 job_callback for (8, 0, 1) got condition
14:21:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:21:18 HBMASTER: Trying to run another job!
14:21:18 job_callback for (8, 0, 1) finished
14:21:18 start sampling a new configuration.
14:21:18 best_vector: [2, 0.8510324693270599, 0.6678361348267774, 0.11404995124116968, 0.2424699461329657, 0, 0.13273016997403475, 0.13564063595640663], 2.1720229691456518e-25, 4.604002877526393e-08, -0.007471378632028819
14:21:18 done sampling a new configuration.
14:21:18 HBMASTER: schedule new run for iteration 8
14:21:18 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
14:21:18 HBMASTER: submitting job (8, 0, 2) to dispatcher
14:21:18 DISPATCHER: trying to submit job (8, 0, 2)
14:21:18 DISPATCHER: trying to notify the job_runner thread.
14:21:18 HBMASTER: job (8, 0, 2) submitted to dispatcher
14:21:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:21:18 DISPATCHER: Trying to submit another job.
14:21:18 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:21:18 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:21:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:21:18 WORKER: start processing job (8, 0, 2)
14:21:18 WORKER: args: ()
14:21:18 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 88, 'last_n_outputs': 34, 'lr': 0.0016908298352048526, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.015013174621780588}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:21:24 DISPATCHER: Starting worker discovery
14:21:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:21:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-538:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:22:24 DISPATCHER: Starting worker discovery
14:22:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:22:24 DISPATCHER: Finished worker discovery
14:23:03 WORKER: done with job (8, 0, 2), trying to register it.
14:23:03 WORKER: registered result for job (8, 0, 2) with dispatcher
14:23:03 DISPATCHER: job (8, 0, 2) finished
14:23:03 DISPATCHER: register_result: lock acquired
14:23:03 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
14:23:03 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 88, 'last_n_outputs': 34, 'lr': 0.0016908298352048526, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.015013174621780588}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3887402194170233, 'info': {'sick_no_sick': 0.3887402194170233, 'config': "{'batch_size': 64, 'hidden_dim': 88, 'last_n_outputs': 34, 'lr': 0.0016908298352048526, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.015013174621780588}"}}
exception: None

14:23:03 job_callback for (8, 0, 2) started
14:23:03 DISPATCHER: Trying to submit another job.
14:23:03 job_callback for (8, 0, 2) got condition
14:23:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:23:03 HBMASTER: Trying to run another job!
14:23:03 job_callback for (8, 0, 2) finished
14:23:03 start sampling a new configuration.
14:23:03 best_vector: [0, 0.4068853935598058, 0.9857923244278091, 0.11767545670990406, 0.008321838250997138, 0, 0.9261805492523815, 0.8166336657521568], 3.334775965633986e-32, 0.2998702192607072, -0.013420284632796533
14:23:03 done sampling a new configuration.
14:23:03 HBMASTER: schedule new run for iteration 8
14:23:03 HBMASTER: trying submitting job (8, 0, 3) to dispatcher
14:23:03 HBMASTER: submitting job (8, 0, 3) to dispatcher
14:23:03 DISPATCHER: trying to submit job (8, 0, 3)
14:23:03 DISPATCHER: trying to notify the job_runner thread.
14:23:03 HBMASTER: job (8, 0, 3) submitted to dispatcher
14:23:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:23:03 DISPATCHER: Trying to submit another job.
14:23:03 DISPATCHER: starting job (8, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:23:03 DISPATCHER: job (8, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:23:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:23:03 WORKER: start processing job (8, 0, 3)
14:23:03 WORKER: args: ()
14:23:03 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 52, 'last_n_outputs': 50, 'lr': 0.0017192970318362568, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.11546886438061858}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:23:24 DISPATCHER: Starting worker discovery
14:23:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:23:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-539:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:24:24 DISPATCHER: Starting worker discovery
14:24:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:24:24 DISPATCHER: Finished worker discovery
14:24:48 WORKER: done with job (8, 0, 3), trying to register it.
14:24:48 WORKER: registered result for job (8, 0, 3) with dispatcher
14:24:48 DISPATCHER: job (8, 0, 3) finished
14:24:48 DISPATCHER: register_result: lock acquired
14:24:48 DISPATCHER: job (8, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
14:24:48 job_id: (8, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 52, 'last_n_outputs': 50, 'lr': 0.0017192970318362568, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.11546886438061858}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3697975322745819, 'info': {'sick_no_sick': 0.3697975322745819, 'config': "{'batch_size': 16, 'hidden_dim': 52, 'last_n_outputs': 50, 'lr': 0.0017192970318362568, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.11546886438061858}"}}
exception: None

14:24:48 job_callback for (8, 0, 3) started
14:24:48 DISPATCHER: Trying to submit another job.
14:24:48 job_callback for (8, 0, 3) got condition
14:24:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:24:48 HBMASTER: Trying to run another job!
14:24:48 job_callback for (8, 0, 3) finished
14:24:48 start sampling a new configuration.
14:24:48 best_vector: [0, 0.6947884607376644, 0.8165496603162946, 0.24717370303747122, 0.01463007183047177, 0, 0.8946007075377906, 0.48838652252920234], 1.5499555430092393e-33, 6.451797953239999, -0.0020958237477200882
14:24:48 done sampling a new configuration.
14:24:48 HBMASTER: schedule new run for iteration 8
14:24:48 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
14:24:48 HBMASTER: submitting job (8, 0, 4) to dispatcher
14:24:48 DISPATCHER: trying to submit job (8, 0, 4)
14:24:48 DISPATCHER: trying to notify the job_runner thread.
14:24:48 HBMASTER: job (8, 0, 4) submitted to dispatcher
14:24:48 DISPATCHER: Trying to submit another job.
14:24:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:24:48 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:24:48 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:24:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:24:48 WORKER: start processing job (8, 0, 4)
14:24:48 WORKER: args: ()
14:24:48 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 76, 'last_n_outputs': 41, 'lr': 0.0031213854819719853, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.04319221887979799}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:25:24 DISPATCHER: Starting worker discovery
14:25:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:25:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-540:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:26:24 DISPATCHER: Starting worker discovery
14:26:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:26:24 DISPATCHER: Finished worker discovery
14:26:34 WORKER: done with job (8, 0, 4), trying to register it.
14:26:34 WORKER: registered result for job (8, 0, 4) with dispatcher
14:26:34 DISPATCHER: job (8, 0, 4) finished
14:26:34 DISPATCHER: register_result: lock acquired
14:26:34 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
14:26:34 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 76, 'last_n_outputs': 41, 'lr': 0.0031213854819719853, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.04319221887979799}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3874587299777502, 'info': {'sick_no_sick': 0.3874587299777502, 'config': "{'batch_size': 16, 'hidden_dim': 76, 'last_n_outputs': 41, 'lr': 0.0031213854819719853, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.04319221887979799}"}}
exception: None

14:26:34 job_callback for (8, 0, 4) started
14:26:34 job_callback for (8, 0, 4) got condition
14:26:34 DISPATCHER: Trying to submit another job.
14:26:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:26:34 HBMASTER: Trying to run another job!
14:26:34 job_callback for (8, 0, 4) finished
14:26:34 start sampling a new configuration.
14:26:35 best_vector: [0, 0.5763499645113271, 0.6869621546345269, 0.11627156802282891, 0.24313747998610022, 0, 0.9899432532518571, 0.28543953077500944], 1.4177637989152702e-32, 0.7053361080069185, -0.019320804857410015
14:26:35 done sampling a new configuration.
14:26:35 HBMASTER: schedule new run for iteration 8
14:26:35 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
14:26:35 HBMASTER: submitting job (8, 0, 5) to dispatcher
14:26:35 DISPATCHER: trying to submit job (8, 0, 5)
14:26:35 DISPATCHER: trying to notify the job_runner thread.
14:26:35 HBMASTER: job (8, 0, 5) submitted to dispatcher
14:26:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:26:35 DISPATCHER: Trying to submit another job.
14:26:35 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:26:35 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:26:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:26:35 WORKER: start processing job (8, 0, 5)
14:26:35 WORKER: args: ()
14:26:35 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 66, 'last_n_outputs': 35, 'lr': 0.0017082173793270094, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.023516105044909492}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:27:24 DISPATCHER: Starting worker discovery
14:27:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:27:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-541:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:28:20 WORKER: done with job (8, 0, 5), trying to register it.
14:28:20 WORKER: registered result for job (8, 0, 5) with dispatcher
14:28:20 DISPATCHER: job (8, 0, 5) finished
14:28:20 DISPATCHER: register_result: lock acquired
14:28:20 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
14:28:20 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 66, 'last_n_outputs': 35, 'lr': 0.0017082173793270094, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.023516105044909492}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3928645597503796, 'info': {'sick_no_sick': 0.3928645597503796, 'config': "{'batch_size': 16, 'hidden_dim': 66, 'last_n_outputs': 35, 'lr': 0.0017082173793270094, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.023516105044909492}"}}
exception: None

14:28:20 job_callback for (8, 0, 5) started
14:28:20 DISPATCHER: Trying to submit another job.
14:28:20 job_callback for (8, 0, 5) got condition
14:28:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:28:20 HBMASTER: Trying to run another job!
14:28:20 job_callback for (8, 0, 5) finished
14:28:20 start sampling a new configuration.
14:28:20 done sampling a new configuration.
14:28:20 HBMASTER: schedule new run for iteration 8
14:28:20 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
14:28:20 HBMASTER: submitting job (8, 0, 6) to dispatcher
14:28:20 DISPATCHER: trying to submit job (8, 0, 6)
14:28:20 DISPATCHER: trying to notify the job_runner thread.
14:28:20 HBMASTER: job (8, 0, 6) submitted to dispatcher
14:28:20 DISPATCHER: Trying to submit another job.
14:28:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:28:20 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:28:20 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:28:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:28:20 WORKER: start processing job (8, 0, 6)
14:28:20 WORKER: args: ()
14:28:20 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 75, 'last_n_outputs': 16, 'lr': 0.001310446577940673, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.010852355512984376}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:28:24 DISPATCHER: Starting worker discovery
14:28:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:28:24 DISPATCHER: Finished worker discovery
14:29:24 DISPATCHER: Starting worker discovery
14:29:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:29:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-542:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:30:05 WORKER: done with job (8, 0, 6), trying to register it.
14:30:05 WORKER: registered result for job (8, 0, 6) with dispatcher
14:30:05 DISPATCHER: job (8, 0, 6) finished
14:30:05 DISPATCHER: register_result: lock acquired
14:30:05 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
14:30:05 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 75, 'last_n_outputs': 16, 'lr': 0.001310446577940673, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.010852355512984376}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4854520725226054, 'info': {'sick_no_sick': 0.4854520725226054, 'config': "{'batch_size': 128, 'hidden_dim': 75, 'last_n_outputs': 16, 'lr': 0.001310446577940673, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.010852355512984376}"}}
exception: None

14:30:05 job_callback for (8, 0, 6) started
14:30:05 job_callback for (8, 0, 6) got condition
14:30:05 DISPATCHER: Trying to submit another job.
14:30:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:30:05 HBMASTER: Trying to run another job!
14:30:05 job_callback for (8, 0, 6) finished
14:30:05 start sampling a new configuration.
14:30:05 best_vector: [3, 0.44149429102687965, 0.9050028032633791, 0.5619881237226411, 0.16622540535321167, 0, 0.9635195269372098, 0.32572172674041133], 9.895929298220907e-33, 1.0105165163010819, -0.004701119726850707
14:30:05 done sampling a new configuration.
14:30:05 HBMASTER: schedule new run for iteration 8
14:30:05 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
14:30:05 HBMASTER: submitting job (8, 0, 7) to dispatcher
14:30:05 DISPATCHER: trying to submit job (8, 0, 7)
14:30:05 DISPATCHER: trying to notify the job_runner thread.
14:30:05 HBMASTER: job (8, 0, 7) submitted to dispatcher
14:30:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:30:05 DISPATCHER: Trying to submit another job.
14:30:05 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:30:05 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:30:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:30:05 WORKER: start processing job (8, 0, 7)
14:30:05 WORKER: args: ()
14:30:05 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 55, 'last_n_outputs': 46, 'lr': 0.013303816543844682, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.02653222898076358}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:30:24 DISPATCHER: Starting worker discovery
14:30:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:30:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-543:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:31:24 DISPATCHER: Starting worker discovery
14:31:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:31:24 DISPATCHER: Finished worker discovery
14:31:51 WORKER: done with job (8, 0, 7), trying to register it.
14:31:51 WORKER: registered result for job (8, 0, 7) with dispatcher
14:31:51 DISPATCHER: job (8, 0, 7) finished
14:31:51 DISPATCHER: register_result: lock acquired
14:31:51 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
14:31:51 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 55, 'last_n_outputs': 46, 'lr': 0.013303816543844682, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.02653222898076358}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.411231270461276, 'info': {'sick_no_sick': 0.411231270461276, 'config': "{'batch_size': 128, 'hidden_dim': 55, 'last_n_outputs': 46, 'lr': 0.013303816543844682, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.02653222898076358}"}}
exception: None

14:31:51 job_callback for (8, 0, 7) started
14:31:51 job_callback for (8, 0, 7) got condition
14:31:51 DISPATCHER: Trying to submit another job.
14:31:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:31:51 HBMASTER: Trying to run another job!
14:31:51 job_callback for (8, 0, 7) finished
14:31:51 start sampling a new configuration.
14:31:52 best_vector: [2, 0.6406920051338282, 0.7432918905936603, 0.149312356176838, 0.05006493780375305, 0, 0.2660770744912163, 0.41760414292006554], 2.729272784767998e-32, 0.3663979670998716, -0.008714908075371616
14:31:52 done sampling a new configuration.
14:31:52 HBMASTER: schedule new run for iteration 8
14:31:52 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
14:31:52 HBMASTER: submitting job (8, 0, 8) to dispatcher
14:31:52 DISPATCHER: trying to submit job (8, 0, 8)
14:31:52 DISPATCHER: trying to notify the job_runner thread.
14:31:52 HBMASTER: job (8, 0, 8) submitted to dispatcher
14:31:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:31:52 DISPATCHER: Trying to submit another job.
14:31:52 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:31:52 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:31:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:31:52 WORKER: start processing job (8, 0, 8)
14:31:52 WORKER: args: ()
14:31:52 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 71, 'last_n_outputs': 38, 'lr': 0.0019889538779983796, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.0349394059133695}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:32:24 DISPATCHER: Starting worker discovery
14:32:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:32:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-544:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:33:24 DISPATCHER: Starting worker discovery
14:33:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:33:24 DISPATCHER: Finished worker discovery
14:33:36 WORKER: done with job (8, 0, 8), trying to register it.
14:33:36 WORKER: registered result for job (8, 0, 8) with dispatcher
14:33:36 DISPATCHER: job (8, 0, 8) finished
14:33:36 DISPATCHER: register_result: lock acquired
14:33:36 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
14:33:36 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 71, 'last_n_outputs': 38, 'lr': 0.0019889538779983796, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.0349394059133695}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.42687300350050356, 'info': {'sick_no_sick': 0.42687300350050356, 'config': "{'batch_size': 64, 'hidden_dim': 71, 'last_n_outputs': 38, 'lr': 0.0019889538779983796, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.0349394059133695}"}}
exception: None

14:33:36 job_callback for (8, 0, 8) started
14:33:36 DISPATCHER: Trying to submit another job.
14:33:36 job_callback for (8, 0, 8) got condition
14:33:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:33:36 HBMASTER: Trying to run another job!
14:33:36 job_callback for (8, 0, 8) finished
14:33:36 start sampling a new configuration.
14:33:36 done sampling a new configuration.
14:33:36 HBMASTER: schedule new run for iteration 8
14:33:36 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
14:33:36 HBMASTER: submitting job (8, 0, 9) to dispatcher
14:33:36 DISPATCHER: trying to submit job (8, 0, 9)
14:33:36 DISPATCHER: trying to notify the job_runner thread.
14:33:36 HBMASTER: job (8, 0, 9) submitted to dispatcher
14:33:36 DISPATCHER: Trying to submit another job.
14:33:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:33:36 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:33:36 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:33:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:33:36 WORKER: start processing job (8, 0, 9)
14:33:36 WORKER: args: ()
14:33:36 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 92, 'last_n_outputs': 44, 'lr': 0.012168829944195278, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.03689676779951965}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:34:24 DISPATCHER: Starting worker discovery
14:34:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:34:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-545:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:35:22 WORKER: done with job (8, 0, 9), trying to register it.
14:35:22 WORKER: registered result for job (8, 0, 9) with dispatcher
14:35:22 DISPATCHER: job (8, 0, 9) finished
14:35:22 DISPATCHER: register_result: lock acquired
14:35:22 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
14:35:22 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 92, 'last_n_outputs': 44, 'lr': 0.012168829944195278, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.03689676779951965}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4162944023529468, 'info': {'sick_no_sick': 0.4162944023529468, 'config': "{'batch_size': 64, 'hidden_dim': 92, 'last_n_outputs': 44, 'lr': 0.012168829944195278, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.03689676779951965}"}}
exception: None

14:35:22 job_callback for (8, 0, 9) started
14:35:22 DISPATCHER: Trying to submit another job.
14:35:22 job_callback for (8, 0, 9) got condition
14:35:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:35:22 HBMASTER: Trying to run another job!
14:35:22 job_callback for (8, 0, 9) finished
14:35:22 start sampling a new configuration.
14:35:22 done sampling a new configuration.
14:35:22 HBMASTER: schedule new run for iteration 8
14:35:22 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
14:35:22 HBMASTER: submitting job (8, 0, 10) to dispatcher
14:35:22 DISPATCHER: trying to submit job (8, 0, 10)
14:35:22 DISPATCHER: trying to notify the job_runner thread.
14:35:22 HBMASTER: job (8, 0, 10) submitted to dispatcher
14:35:22 DISPATCHER: Trying to submit another job.
14:35:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:35:22 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:35:22 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:35:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:35:22 WORKER: start processing job (8, 0, 10)
14:35:22 WORKER: args: ()
14:35:22 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 62, 'last_n_outputs': 33, 'lr': 0.04473923536933063, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.01858389384649549}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:35:24 DISPATCHER: Starting worker discovery
14:35:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:35:24 DISPATCHER: Finished worker discovery
14:36:24 DISPATCHER: Starting worker discovery
14:36:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:36:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-546:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:37:08 WORKER: done with job (8, 0, 10), trying to register it.
14:37:08 WORKER: registered result for job (8, 0, 10) with dispatcher
14:37:08 DISPATCHER: job (8, 0, 10) finished
14:37:08 DISPATCHER: register_result: lock acquired
14:37:08 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
14:37:08 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 62, 'last_n_outputs': 33, 'lr': 0.04473923536933063, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.01858389384649549}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4443921809312433, 'info': {'sick_no_sick': 0.4443921809312433, 'config': "{'batch_size': 128, 'hidden_dim': 62, 'last_n_outputs': 33, 'lr': 0.04473923536933063, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.01858389384649549}"}}
exception: None

14:37:08 job_callback for (8, 0, 10) started
14:37:08 DISPATCHER: Trying to submit another job.
14:37:08 job_callback for (8, 0, 10) got condition
14:37:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:37:08 HBMASTER: Trying to run another job!
14:37:08 job_callback for (8, 0, 10) finished
14:37:08 start sampling a new configuration.
14:37:08 best_vector: [0, 0.6994957806814536, 0.8100212228727158, 0.09503495400939782, 0.057282006244233435, 0, 0.6980683409023962, 0.7786414486032789], 4.152028373863771e-34, 24.0846138310328, -0.02562202062615892
14:37:08 done sampling a new configuration.
14:37:08 HBMASTER: schedule new run for iteration 8
14:37:08 HBMASTER: trying submitting job (8, 0, 11) to dispatcher
14:37:08 HBMASTER: submitting job (8, 0, 11) to dispatcher
14:37:08 DISPATCHER: trying to submit job (8, 0, 11)
14:37:08 DISPATCHER: trying to notify the job_runner thread.
14:37:08 HBMASTER: job (8, 0, 11) submitted to dispatcher
14:37:08 DISPATCHER: Trying to submit another job.
14:37:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:37:08 DISPATCHER: starting job (8, 0, 11) on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:37:08 DISPATCHER: job (8, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:37:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:37:08 WORKER: start processing job (8, 0, 11)
14:37:08 WORKER: args: ()
14:37:08 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 76, 'last_n_outputs': 41, 'lr': 0.0015490659506924827, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.10304712523005842}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:37:24 DISPATCHER: Starting worker discovery
14:37:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:37:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-547:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:38:24 DISPATCHER: Starting worker discovery
14:38:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:38:24 DISPATCHER: Finished worker discovery
14:38:55 WORKER: done with job (8, 0, 11), trying to register it.
14:38:55 WORKER: registered result for job (8, 0, 11) with dispatcher
14:38:55 DISPATCHER: job (8, 0, 11) finished
14:38:55 DISPATCHER: register_result: lock acquired
14:38:55 DISPATCHER: job (8, 0, 11) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
14:38:55 job_id: (8, 0, 11)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 76, 'last_n_outputs': 41, 'lr': 0.0015490659506924827, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.10304712523005842}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3362086699609842, 'info': {'sick_no_sick': 0.3362086699609842, 'config': "{'batch_size': 16, 'hidden_dim': 76, 'last_n_outputs': 41, 'lr': 0.0015490659506924827, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.10304712523005842}"}}
exception: None

14:38:55 job_callback for (8, 0, 11) started
14:38:55 DISPATCHER: Trying to submit another job.
14:38:55 job_callback for (8, 0, 11) got condition
14:38:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:38:55 HBMASTER: Trying to run another job!
14:38:55 job_callback for (8, 0, 11) finished
14:38:55 start sampling a new configuration.
14:38:55 done sampling a new configuration.
14:38:55 HBMASTER: schedule new run for iteration 8
14:38:55 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
14:38:55 HBMASTER: submitting job (8, 0, 12) to dispatcher
14:38:55 DISPATCHER: trying to submit job (8, 0, 12)
14:38:55 DISPATCHER: trying to notify the job_runner thread.
14:38:55 HBMASTER: job (8, 0, 12) submitted to dispatcher
14:38:55 DISPATCHER: Trying to submit another job.
14:38:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:38:55 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:38:55 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:38:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:38:55 WORKER: start processing job (8, 0, 12)
14:38:55 WORKER: args: ()
14:38:55 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 28, 'last_n_outputs': 20, 'lr': 0.0011681469265514216, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.03454468524353542}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:39:24 DISPATCHER: Starting worker discovery
14:39:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:39:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-548:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:40:24 DISPATCHER: Starting worker discovery
14:40:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:40:24 DISPATCHER: Finished worker discovery
14:40:39 WORKER: done with job (8, 0, 12), trying to register it.
14:40:39 WORKER: registered result for job (8, 0, 12) with dispatcher
14:40:39 DISPATCHER: job (8, 0, 12) finished
14:40:39 DISPATCHER: register_result: lock acquired
14:40:39 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
14:40:39 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 28, 'last_n_outputs': 20, 'lr': 0.0011681469265514216, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.03454468524353542}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 28, 'last_n_outputs': 20, 'lr': 0.0011681469265514216, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.03454468524353542}"}}
exception: None

14:40:39 job_callback for (8, 0, 12) started
14:40:39 job_callback for (8, 0, 12) got condition
14:40:39 DISPATCHER: Trying to submit another job.
14:40:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:40:39 HBMASTER: Trying to run another job!
14:40:39 job_callback for (8, 0, 12) finished
14:40:39 start sampling a new configuration.
14:40:39 best_vector: [0, 0.6928382247582383, 0.7258149591481706, 0.2975082024376682, 0.04769910464005493, 0, 0.9208024766299947, 0.6325859027823116], 2.680798374984147e-34, 37.30232043302822, -0.01249248362521341
14:40:39 done sampling a new configuration.
14:40:39 HBMASTER: schedule new run for iteration 8
14:40:39 HBMASTER: trying submitting job (8, 0, 13) to dispatcher
14:40:39 HBMASTER: submitting job (8, 0, 13) to dispatcher
14:40:39 DISPATCHER: trying to submit job (8, 0, 13)
14:40:39 DISPATCHER: trying to notify the job_runner thread.
14:40:39 HBMASTER: job (8, 0, 13) submitted to dispatcher
14:40:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:40:39 DISPATCHER: Trying to submit another job.
14:40:39 DISPATCHER: starting job (8, 0, 13) on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:40:39 DISPATCHER: job (8, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:40:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:40:39 WORKER: start processing job (8, 0, 13)
14:40:39 WORKER: args: ()
14:40:39 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 76, 'last_n_outputs': 37, 'lr': 0.003935649415481019, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.06652934295299831}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:41:24 DISPATCHER: Starting worker discovery
14:41:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:41:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-549:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:42:24 DISPATCHER: Starting worker discovery
14:42:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:42:24 DISPATCHER: Finished worker discovery
14:42:26 WORKER: done with job (8, 0, 13), trying to register it.
14:42:26 WORKER: registered result for job (8, 0, 13) with dispatcher
14:42:26 DISPATCHER: job (8, 0, 13) finished
14:42:26 DISPATCHER: register_result: lock acquired
14:42:26 DISPATCHER: job (8, 0, 13) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
14:42:26 job_id: (8, 0, 13)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 76, 'last_n_outputs': 37, 'lr': 0.003935649415481019, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.06652934295299831}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3779526740869888, 'info': {'sick_no_sick': 0.3779526740869888, 'config': "{'batch_size': 16, 'hidden_dim': 76, 'last_n_outputs': 37, 'lr': 0.003935649415481019, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.06652934295299831}"}}
exception: None

14:42:26 job_callback for (8, 0, 13) started
14:42:26 DISPATCHER: Trying to submit another job.
14:42:26 job_callback for (8, 0, 13) got condition
14:42:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:42:26 HBMASTER: Trying to run another job!
14:42:26 job_callback for (8, 0, 13) finished
14:42:26 start sampling a new configuration.
14:42:27 best_vector: [3, 0.9048653233692798, 0.21636133692512927, 0.4795527025702595, 0.09254086331826933, 0, 0.38477029816929775, 0.9494176672762512], 9.799164441419717e-31, 0.010204951717854002, -0.0026479880447479328
14:42:27 done sampling a new configuration.
14:42:27 HBMASTER: schedule new run for iteration 8
14:42:27 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
14:42:27 HBMASTER: submitting job (8, 0, 14) to dispatcher
14:42:27 DISPATCHER: trying to submit job (8, 0, 14)
14:42:27 DISPATCHER: trying to notify the job_runner thread.
14:42:27 HBMASTER: job (8, 0, 14) submitted to dispatcher
14:42:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:42:27 DISPATCHER: Trying to submit another job.
14:42:27 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:42:27 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:42:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:42:27 WORKER: start processing job (8, 0, 14)
14:42:27 WORKER: args: ()
14:42:27 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 11, 'lr': 0.009101341393025167, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.17187822638442615}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:43:24 DISPATCHER: Starting worker discovery
14:43:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:43:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-550:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:44:13 WORKER: done with job (8, 0, 14), trying to register it.
14:44:13 WORKER: registered result for job (8, 0, 14) with dispatcher
14:44:13 DISPATCHER: job (8, 0, 14) finished
14:44:13 DISPATCHER: register_result: lock acquired
14:44:13 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
14:44:13 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 11, 'lr': 0.009101341393025167, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.17187822638442615}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4319917959938685, 'info': {'sick_no_sick': 0.4319917959938685, 'config': "{'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 11, 'lr': 0.009101341393025167, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.17187822638442615}"}}
exception: None

14:44:13 job_callback for (8, 0, 14) started
14:44:13 job_callback for (8, 0, 14) got condition
14:44:13 DISPATCHER: Trying to submit another job.
14:44:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:44:13 HBMASTER: Trying to run another job!
14:44:13 job_callback for (8, 0, 14) finished
14:44:13 start sampling a new configuration.
14:44:13 done sampling a new configuration.
14:44:13 HBMASTER: schedule new run for iteration 8
14:44:13 HBMASTER: trying submitting job (8, 0, 15) to dispatcher
14:44:13 HBMASTER: submitting job (8, 0, 15) to dispatcher
14:44:13 DISPATCHER: trying to submit job (8, 0, 15)
14:44:13 DISPATCHER: trying to notify the job_runner thread.
14:44:13 HBMASTER: job (8, 0, 15) submitted to dispatcher
14:44:13 DISPATCHER: Trying to submit another job.
14:44:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:44:13 DISPATCHER: starting job (8, 0, 15) on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:44:13 DISPATCHER: job (8, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:44:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:44:13 WORKER: start processing job (8, 0, 15)
14:44:13 WORKER: args: ()
14:44:13 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 24, 'last_n_outputs': 40, 'lr': 0.006848225521785932, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.04418645828876516}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:44:24 DISPATCHER: Starting worker discovery
14:44:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:44:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-551:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:45:24 DISPATCHER: Starting worker discovery
14:45:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:45:24 DISPATCHER: Finished worker discovery
14:45:59 WORKER: done with job (8, 0, 15), trying to register it.
14:45:59 WORKER: registered result for job (8, 0, 15) with dispatcher
14:45:59 DISPATCHER: job (8, 0, 15) finished
14:45:59 DISPATCHER: register_result: lock acquired
14:45:59 DISPATCHER: job (8, 0, 15) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
14:45:59 job_id: (8, 0, 15)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 24, 'last_n_outputs': 40, 'lr': 0.006848225521785932, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.04418645828876516}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 24, 'last_n_outputs': 40, 'lr': 0.006848225521785932, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.04418645828876516}"}}
exception: None

14:45:59 job_callback for (8, 0, 15) started
14:45:59 job_callback for (8, 0, 15) got condition
14:45:59 DISPATCHER: Trying to submit another job.
14:45:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:45:59 HBMASTER: Trying to run another job!
14:45:59 job_callback for (8, 0, 15) finished
14:45:59 start sampling a new configuration.
14:45:59 best_vector: [0, 0.5627049036333204, 0.6816203160459252, 0.12864502443159104, 0.013501640566375664, 0, 0.7600812178587041, 0.2620515504789675], 1.502492536636651e-33, 6.6556071036366875, -0.018060105647658236
14:45:59 done sampling a new configuration.
14:45:59 HBMASTER: schedule new run for iteration 8
14:45:59 HBMASTER: trying submitting job (8, 0, 16) to dispatcher
14:45:59 HBMASTER: submitting job (8, 0, 16) to dispatcher
14:45:59 DISPATCHER: trying to submit job (8, 0, 16)
14:45:59 DISPATCHER: trying to notify the job_runner thread.
14:45:59 HBMASTER: job (8, 0, 16) submitted to dispatcher
14:45:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:45:59 DISPATCHER: Trying to submit another job.
14:45:59 DISPATCHER: starting job (8, 0, 16) on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:45:59 DISPATCHER: job (8, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:45:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:45:59 WORKER: start processing job (8, 0, 16)
14:45:59 WORKER: args: ()
14:45:59 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 65, 'last_n_outputs': 35, 'lr': 0.0018083814724035368, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.021924864982768803}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:46:24 DISPATCHER: Starting worker discovery
14:46:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:46:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-552:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:47:24 DISPATCHER: Starting worker discovery
14:47:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:47:24 DISPATCHER: Finished worker discovery
14:47:44 WORKER: done with job (8, 0, 16), trying to register it.
14:47:44 WORKER: registered result for job (8, 0, 16) with dispatcher
14:47:44 DISPATCHER: job (8, 0, 16) finished
14:47:44 DISPATCHER: register_result: lock acquired
14:47:44 DISPATCHER: job (8, 0, 16) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
14:47:44 job_id: (8, 0, 16)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 65, 'last_n_outputs': 35, 'lr': 0.0018083814724035368, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.021924864982768803}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.35988108540465447, 'info': {'sick_no_sick': 0.35988108540465447, 'config': "{'batch_size': 16, 'hidden_dim': 65, 'last_n_outputs': 35, 'lr': 0.0018083814724035368, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.021924864982768803}"}}
exception: None

14:47:44 job_callback for (8, 0, 16) started
14:47:44 DISPATCHER: Trying to submit another job.
14:47:44 job_callback for (8, 0, 16) got condition
14:47:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:47:44 HBMASTER: Trying to run another job!
14:47:44 job_callback for (8, 0, 16) finished
14:47:44 start sampling a new configuration.
14:47:44 best_vector: [0, 0.34251733722735617, 0.11813916647641454, 0.12202266331539163, 0.13096067782875673, 0, 0.9965948320670004, 0.44736794614595976], 7.941483457608717e-30, 0.0012592105811690666, -0.0070049428715376096
14:47:44 done sampling a new configuration.
14:47:44 HBMASTER: schedule new run for iteration 8
14:47:44 HBMASTER: trying submitting job (8, 0, 17) to dispatcher
14:47:44 HBMASTER: submitting job (8, 0, 17) to dispatcher
14:47:44 DISPATCHER: trying to submit job (8, 0, 17)
14:47:44 DISPATCHER: trying to notify the job_runner thread.
14:47:44 HBMASTER: job (8, 0, 17) submitted to dispatcher
14:47:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:47:44 DISPATCHER: Trying to submit another job.
14:47:44 DISPATCHER: starting job (8, 0, 17) on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:47:44 DISPATCHER: job (8, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:47:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:47:44 WORKER: start processing job (8, 0, 17)
14:47:44 WORKER: args: ()
14:47:44 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 47, 'last_n_outputs': 6, 'lr': 0.001754063561138888, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.038197867422462645}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:48:24 DISPATCHER: Starting worker discovery
14:48:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:48:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-553:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:49:24 DISPATCHER: Starting worker discovery
14:49:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:49:24 DISPATCHER: Finished worker discovery
14:49:30 WORKER: done with job (8, 0, 17), trying to register it.
14:49:30 WORKER: registered result for job (8, 0, 17) with dispatcher
14:49:30 DISPATCHER: job (8, 0, 17) finished
14:49:30 DISPATCHER: register_result: lock acquired
14:49:30 DISPATCHER: job (8, 0, 17) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
14:49:30 job_id: (8, 0, 17)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 47, 'last_n_outputs': 6, 'lr': 0.001754063561138888, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.038197867422462645}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.14079008549903022, 'info': {'sick_no_sick': 0.14079008549903022, 'config': "{'batch_size': 16, 'hidden_dim': 47, 'last_n_outputs': 6, 'lr': 0.001754063561138888, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.038197867422462645}"}}
exception: None

14:49:30 job_callback for (8, 0, 17) started
14:49:30 DISPATCHER: Trying to submit another job.
14:49:30 job_callback for (8, 0, 17) got condition
14:49:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:49:30 HBMASTER: Trying to run another job!
14:49:30 job_callback for (8, 0, 17) finished
14:49:30 start sampling a new configuration.
14:49:30 best_vector: [0, 0.539522534028004, 0.7029963931902108, 0.10255620051135422, 0.10039050253714145, 0, 0.9887188212027541, 0.6370530666063916], 7.963419228859932e-34, 12.55742001345273, -0.04124408634693087
14:49:30 done sampling a new configuration.
14:49:30 HBMASTER: schedule new run for iteration 8
14:49:30 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
14:49:30 HBMASTER: submitting job (8, 0, 18) to dispatcher
14:49:30 DISPATCHER: trying to submit job (8, 0, 18)
14:49:30 DISPATCHER: trying to notify the job_runner thread.
14:49:30 HBMASTER: job (8, 0, 18) submitted to dispatcher
14:49:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:49:30 DISPATCHER: Trying to submit another job.
14:49:30 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:49:30 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:49:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:49:30 WORKER: start processing job (8, 0, 18)
14:49:30 WORKER: args: ()
14:49:30 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 63, 'last_n_outputs': 36, 'lr': 0.0016036603850106317, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.06742565102978573}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:50:24 DISPATCHER: Starting worker discovery
14:50:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:50:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-554:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:51:16 WORKER: done with job (8, 0, 18), trying to register it.
14:51:16 WORKER: registered result for job (8, 0, 18) with dispatcher
14:51:16 DISPATCHER: job (8, 0, 18) finished
14:51:16 DISPATCHER: register_result: lock acquired
14:51:16 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
14:51:16 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 63, 'last_n_outputs': 36, 'lr': 0.0016036603850106317, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.06742565102978573}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3464610553458493, 'info': {'sick_no_sick': 0.3464610553458493, 'config': "{'batch_size': 16, 'hidden_dim': 63, 'last_n_outputs': 36, 'lr': 0.0016036603850106317, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.06742565102978573}"}}
exception: None

14:51:16 job_callback for (8, 0, 18) started
14:51:16 job_callback for (8, 0, 18) got condition
14:51:16 DISPATCHER: Trying to submit another job.
14:51:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:51:16 HBMASTER: Trying to run another job!
14:51:16 job_callback for (8, 0, 18) finished
14:51:16 start sampling a new configuration.
14:51:16 done sampling a new configuration.
14:51:16 HBMASTER: schedule new run for iteration 8
14:51:16 HBMASTER: trying submitting job (8, 0, 19) to dispatcher
14:51:16 HBMASTER: submitting job (8, 0, 19) to dispatcher
14:51:16 DISPATCHER: trying to submit job (8, 0, 19)
14:51:16 DISPATCHER: trying to notify the job_runner thread.
14:51:16 HBMASTER: job (8, 0, 19) submitted to dispatcher
14:51:16 DISPATCHER: Trying to submit another job.
14:51:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:51:16 DISPATCHER: starting job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:51:16 DISPATCHER: job (8, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:51:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:51:16 WORKER: start processing job (8, 0, 19)
14:51:16 WORKER: args: ()
14:51:16 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 33, 'last_n_outputs': 6, 'lr': 0.002207647559838456, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.018539360785323013}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:51:24 DISPATCHER: Starting worker discovery
14:51:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:51:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-555:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:52:24 DISPATCHER: Starting worker discovery
14:52:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:52:24 DISPATCHER: Finished worker discovery
14:53:01 WORKER: done with job (8, 0, 19), trying to register it.
14:53:01 WORKER: registered result for job (8, 0, 19) with dispatcher
14:53:01 DISPATCHER: job (8, 0, 19) finished
14:53:01 DISPATCHER: register_result: lock acquired
14:53:01 DISPATCHER: job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
14:53:01 job_id: (8, 0, 19)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 33, 'last_n_outputs': 6, 'lr': 0.002207647559838456, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.018539360785323013}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 33, 'last_n_outputs': 6, 'lr': 0.002207647559838456, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.018539360785323013}"}}
exception: None

14:53:01 job_callback for (8, 0, 19) started
14:53:01 job_callback for (8, 0, 19) got condition
14:53:01 DISPATCHER: Trying to submit another job.
14:53:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:53:01 HBMASTER: Trying to run another job!
14:53:01 job_callback for (8, 0, 19) finished
14:53:01 start sampling a new configuration.
14:53:01 best_vector: [3, 0.691319660779188, 0.22866952723535416, 0.0274129890575113, 0.21804738369904442, 0, 0.23977861122242905, 0.7078542758348493], 3.8971847653572906e-31, 0.025659548115069184, -0.0004392775291546822
14:53:01 done sampling a new configuration.
14:53:01 HBMASTER: schedule new run for iteration 8
14:53:01 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
14:53:01 HBMASTER: submitting job (8, 0, 20) to dispatcher
14:53:01 DISPATCHER: trying to submit job (8, 0, 20)
14:53:01 DISPATCHER: trying to notify the job_runner thread.
14:53:01 HBMASTER: job (8, 0, 20) submitted to dispatcher
14:53:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:53:01 DISPATCHER: Trying to submit another job.
14:53:01 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:53:01 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:53:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:53:01 WORKER: start processing job (8, 0, 20)
14:53:01 WORKER: args: ()
14:53:01 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 75, 'last_n_outputs': 12, 'lr': 0.0011345561077203792, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.08335653346984175}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:53:24 DISPATCHER: Starting worker discovery
14:53:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:53:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-556:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:54:24 DISPATCHER: Starting worker discovery
14:54:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:54:24 DISPATCHER: Finished worker discovery
14:54:48 WORKER: done with job (8, 0, 20), trying to register it.
14:54:48 WORKER: registered result for job (8, 0, 20) with dispatcher
14:54:48 DISPATCHER: job (8, 0, 20) finished
14:54:48 DISPATCHER: register_result: lock acquired
14:54:48 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
14:54:48 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 75, 'last_n_outputs': 12, 'lr': 0.0011345561077203792, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.08335653346984175}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 75, 'last_n_outputs': 12, 'lr': 0.0011345561077203792, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.08335653346984175}"}}
exception: None

14:54:48 job_callback for (8, 0, 20) started
14:54:48 job_callback for (8, 0, 20) got condition
14:54:48 DISPATCHER: Trying to submit another job.
14:54:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:54:48 HBMASTER: Trying to run another job!
14:54:48 job_callback for (8, 0, 20) finished
14:54:48 start sampling a new configuration.
14:54:48 done sampling a new configuration.
14:54:48 HBMASTER: schedule new run for iteration 8
14:54:48 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
14:54:48 HBMASTER: submitting job (8, 0, 21) to dispatcher
14:54:48 DISPATCHER: trying to submit job (8, 0, 21)
14:54:48 DISPATCHER: trying to notify the job_runner thread.
14:54:48 HBMASTER: job (8, 0, 21) submitted to dispatcher
14:54:48 DISPATCHER: Trying to submit another job.
14:54:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:54:48 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:54:48 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:54:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:54:48 WORKER: start processing job (8, 0, 21)
14:54:48 WORKER: args: ()
14:54:48 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 48, 'last_n_outputs': 13, 'lr': 0.0032752047892734143, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.017268526782189667}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:55:24 DISPATCHER: Starting worker discovery
14:55:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:55:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-557:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:56:24 DISPATCHER: Starting worker discovery
14:56:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:56:24 DISPATCHER: Finished worker discovery
14:56:34 WORKER: done with job (8, 0, 21), trying to register it.
14:56:34 WORKER: registered result for job (8, 0, 21) with dispatcher
14:56:34 DISPATCHER: job (8, 0, 21) finished
14:56:34 DISPATCHER: register_result: lock acquired
14:56:34 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
14:56:34 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 48, 'last_n_outputs': 13, 'lr': 0.0032752047892734143, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.017268526782189667}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 48, 'last_n_outputs': 13, 'lr': 0.0032752047892734143, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.017268526782189667}"}}
exception: None

14:56:34 job_callback for (8, 0, 21) started
14:56:34 job_callback for (8, 0, 21) got condition
14:56:34 DISPATCHER: Trying to submit another job.
14:56:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:56:34 HBMASTER: Trying to run another job!
14:56:34 job_callback for (8, 0, 21) finished
14:56:34 start sampling a new configuration.
14:56:34 best_vector: [2, 0.7546441334773087, 0.7379674930018951, 0.0024102326835531984, 0.12253632348351173, 0, 0.32797249119023497, 0.1922345580252851], 6.096273025502832e-31, 0.016403464802456386, -0.0042697656702365295
14:56:34 done sampling a new configuration.
14:56:34 HBMASTER: schedule new run for iteration 8
14:56:34 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
14:56:34 HBMASTER: submitting job (8, 0, 22) to dispatcher
14:56:34 DISPATCHER: trying to submit job (8, 0, 22)
14:56:34 DISPATCHER: trying to notify the job_runner thread.
14:56:34 HBMASTER: job (8, 0, 22) submitted to dispatcher
14:56:34 DISPATCHER: Trying to submit another job.
14:56:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:56:34 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:56:34 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:56:34 WORKER: start processing job (8, 0, 22)
14:56:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:56:34 WORKER: args: ()
14:56:34 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 81, 'last_n_outputs': 37, 'lr': 0.0010111613600410044, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.017787009056599128}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:57:24 DISPATCHER: Starting worker discovery
14:57:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:57:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-558:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:58:20 WORKER: done with job (8, 0, 22), trying to register it.
14:58:20 WORKER: registered result for job (8, 0, 22) with dispatcher
14:58:20 DISPATCHER: job (8, 0, 22) finished
14:58:20 DISPATCHER: register_result: lock acquired
14:58:20 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
14:58:20 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 81, 'last_n_outputs': 37, 'lr': 0.0010111613600410044, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.017787009056599128}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3371416577550184, 'info': {'sick_no_sick': 0.3371416577550184, 'config': "{'batch_size': 64, 'hidden_dim': 81, 'last_n_outputs': 37, 'lr': 0.0010111613600410044, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.017787009056599128}"}}
exception: None

14:58:20 job_callback for (8, 0, 22) started
14:58:20 job_callback for (8, 0, 22) got condition
14:58:20 DISPATCHER: Trying to submit another job.
14:58:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:58:20 HBMASTER: Trying to run another job!
14:58:20 job_callback for (8, 0, 22) finished
14:58:20 start sampling a new configuration.
14:58:20 best_vector: [2, 0.6480210013905863, 0.48136556712478606, 0.3354599175973312, 0.06084412422814753, 0, 0.6725982965409774, 0.751947776685017], 0.0033197068054066064, 114.95010538701857, 0.38160064713549213
14:58:20 done sampling a new configuration.
14:58:20 HBMASTER: schedule new run for iteration 8
14:58:20 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
14:58:20 HBMASTER: submitting job (8, 0, 23) to dispatcher
14:58:20 DISPATCHER: trying to submit job (8, 0, 23)
14:58:20 DISPATCHER: trying to notify the job_runner thread.
14:58:20 HBMASTER: job (8, 0, 23) submitted to dispatcher
14:58:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:58:20 DISPATCHER: Trying to submit another job.
14:58:20 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:58:20 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
14:58:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:58:20 WORKER: start processing job (8, 0, 23)
14:58:20 WORKER: args: ()
14:58:20 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 72, 'last_n_outputs': 25, 'lr': 0.0046872685361057966, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.09512761592159358}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:58:24 DISPATCHER: Starting worker discovery
14:58:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:58:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-559:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:59:24 DISPATCHER: Starting worker discovery
14:59:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:59:24 DISPATCHER: Finished worker discovery
15:00:06 WORKER: done with job (8, 0, 23), trying to register it.
15:00:06 WORKER: registered result for job (8, 0, 23) with dispatcher
15:00:06 DISPATCHER: job (8, 0, 23) finished
15:00:06 DISPATCHER: register_result: lock acquired
15:00:06 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
15:00:06 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 72, 'last_n_outputs': 25, 'lr': 0.0046872685361057966, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.09512761592159358}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.45931726064095235, 'info': {'sick_no_sick': 0.45931726064095235, 'config': "{'batch_size': 64, 'hidden_dim': 72, 'last_n_outputs': 25, 'lr': 0.0046872685361057966, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.09512761592159358}"}}
exception: None

15:00:06 job_callback for (8, 0, 23) started
15:00:06 DISPATCHER: Trying to submit another job.
15:00:06 job_callback for (8, 0, 23) got condition
15:00:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:00:06 HBMASTER: Trying to run another job!
15:00:06 job_callback for (8, 0, 23) finished
15:00:06 start sampling a new configuration.
15:00:06 best_vector: [0, 0.572813102576862, 0.8612788783402335, 0.25093103539604045, 0.12168642179869789, 0, 0.6979314067034152, 0.9389911512523376], 1.2391575761767688e-34, 80.69998676724772, -0.04370205067997354
15:00:06 done sampling a new configuration.
15:00:06 HBMASTER: schedule new run for iteration 8
15:00:06 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
15:00:06 HBMASTER: submitting job (8, 0, 24) to dispatcher
15:00:06 DISPATCHER: trying to submit job (8, 0, 24)
15:00:06 DISPATCHER: trying to notify the job_runner thread.
15:00:06 HBMASTER: job (8, 0, 24) submitted to dispatcher
15:00:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:00:06 DISPATCHER: Trying to submit another job.
15:00:06 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpuj.30598140416580691776
15:00:06 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
15:00:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:00:06 WORKER: start processing job (8, 0, 24)
15:00:06 WORKER: args: ()
15:00:06 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 66, 'last_n_outputs': 44, 'lr': 0.003175865275540368, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.16659257974286631}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:00:24 DISPATCHER: Starting worker discovery
15:00:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:00:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-560:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:01:24 DISPATCHER: Starting worker discovery
15:01:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:01:24 DISPATCHER: Finished worker discovery
15:01:51 WORKER: done with job (8, 0, 24), trying to register it.
15:01:51 WORKER: registered result for job (8, 0, 24) with dispatcher
15:01:51 DISPATCHER: job (8, 0, 24) finished
15:01:51 DISPATCHER: register_result: lock acquired
15:01:51 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
15:01:51 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 66, 'last_n_outputs': 44, 'lr': 0.003175865275540368, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.16659257974286631}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3602955567345779, 'info': {'sick_no_sick': 0.3602955567345779, 'config': "{'batch_size': 16, 'hidden_dim': 66, 'last_n_outputs': 44, 'lr': 0.003175865275540368, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.16659257974286631}"}}
exception: None

15:01:51 job_callback for (8, 0, 24) started
15:01:51 job_callback for (8, 0, 24) got condition
15:01:51 DISPATCHER: Trying to submit another job.
15:01:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:01:51 HBMASTER: Trying to run another job!
15:01:51 job_callback for (8, 0, 24) finished
15:01:51 start sampling a new configuration.
15:01:51 done sampling a new configuration.
15:01:51 HBMASTER: schedule new run for iteration 8
15:01:51 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
15:01:51 HBMASTER: submitting job (8, 0, 25) to dispatcher
15:01:51 DISPATCHER: trying to submit job (8, 0, 25)
15:01:51 DISPATCHER: trying to notify the job_runner thread.
15:01:51 HBMASTER: job (8, 0, 25) submitted to dispatcher
15:01:51 DISPATCHER: Trying to submit another job.
15:01:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:01:51 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpuj.30598140416580691776
15:01:51 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
15:01:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:01:51 WORKER: start processing job (8, 0, 25)
15:01:51 WORKER: args: ()
15:01:51 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 58, 'last_n_outputs': 22, 'lr': 0.04780788326542332, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.015672723632753894}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:02:24 DISPATCHER: Starting worker discovery
15:02:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:02:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-561:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:03:24 DISPATCHER: Starting worker discovery
15:03:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:03:24 DISPATCHER: Finished worker discovery
15:03:36 WORKER: done with job (8, 0, 25), trying to register it.
15:03:36 WORKER: registered result for job (8, 0, 25) with dispatcher
15:03:36 DISPATCHER: job (8, 0, 25) finished
15:03:36 DISPATCHER: register_result: lock acquired
15:03:36 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
15:03:36 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 58, 'last_n_outputs': 22, 'lr': 0.04780788326542332, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.015672723632753894}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 58, 'last_n_outputs': 22, 'lr': 0.04780788326542332, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.015672723632753894}"}}
exception: None

15:03:36 job_callback for (8, 0, 25) started
15:03:36 DISPATCHER: Trying to submit another job.
15:03:36 job_callback for (8, 0, 25) got condition
15:03:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:03:36 HBMASTER: Trying to run another job!
15:03:36 job_callback for (8, 0, 25) finished
15:03:36 start sampling a new configuration.
15:03:36 best_vector: [0, 0.6669880720275116, 0.21086216611986575, 0.36695244058397847, 0.03650566316760376, 0, 0.9585681362167092, 0.8346929443681991], 3.269324575030287e-34, 30.58735763458836, -0.008236083004783767
15:03:36 done sampling a new configuration.
15:03:36 HBMASTER: schedule new run for iteration 8
15:03:36 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
15:03:36 HBMASTER: submitting job (8, 0, 26) to dispatcher
15:03:36 DISPATCHER: trying to submit job (8, 0, 26)
15:03:36 DISPATCHER: trying to notify the job_runner thread.
15:03:36 HBMASTER: job (8, 0, 26) submitted to dispatcher
15:03:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:03:36 DISPATCHER: Trying to submit another job.
15:03:36 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.30598140416580691776
15:03:36 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
15:03:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:03:36 WORKER: start processing job (8, 0, 26)
15:03:36 WORKER: args: ()
15:03:36 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 74, 'last_n_outputs': 11, 'lr': 0.005418821947964309, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.1218878896486848}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:04:24 DISPATCHER: Starting worker discovery
15:04:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:04:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-562:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:05:24 WORKER: done with job (8, 0, 26), trying to register it.
15:05:24 WORKER: registered result for job (8, 0, 26) with dispatcher
15:05:24 DISPATCHER: job (8, 0, 26) finished
15:05:24 DISPATCHER: register_result: lock acquired
15:05:24 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
15:05:24 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 74, 'last_n_outputs': 11, 'lr': 0.005418821947964309, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.1218878896486848}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3682946808164705, 'info': {'sick_no_sick': 0.3682946808164705, 'config': "{'batch_size': 16, 'hidden_dim': 74, 'last_n_outputs': 11, 'lr': 0.005418821947964309, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.1218878896486848}"}}
exception: None

15:05:24 job_callback for (8, 0, 26) started
15:05:24 job_callback for (8, 0, 26) got condition
15:05:24 DISPATCHER: Trying to submit another job.
15:05:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:05:24 HBMASTER: Trying to run another job!
15:05:24 job_callback for (8, 0, 26) finished
15:05:24 ITERATION: Advancing config (8, 0, 2) to next budget 133.333333
15:05:24 ITERATION: Advancing config (8, 0, 5) to next budget 133.333333
15:05:24 ITERATION: Advancing config (8, 0, 6) to next budget 133.333333
15:05:24 ITERATION: Advancing config (8, 0, 7) to next budget 133.333333
15:05:24 ITERATION: Advancing config (8, 0, 8) to next budget 133.333333
15:05:24 ITERATION: Advancing config (8, 0, 9) to next budget 133.333333
15:05:24 ITERATION: Advancing config (8, 0, 10) to next budget 133.333333
15:05:24 ITERATION: Advancing config (8, 0, 14) to next budget 133.333333
15:05:24 ITERATION: Advancing config (8, 0, 23) to next budget 133.333333
15:05:24 HBMASTER: schedule new run for iteration 8
15:05:24 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
15:05:24 HBMASTER: submitting job (8, 0, 2) to dispatcher
15:05:24 DISPATCHER: trying to submit job (8, 0, 2)
15:05:24 DISPATCHER: trying to notify the job_runner thread.
15:05:24 HBMASTER: job (8, 0, 2) submitted to dispatcher
15:05:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:05:24 DISPATCHER: Trying to submit another job.
15:05:24 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
15:05:24 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
15:05:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:05:24 WORKER: start processing job (8, 0, 2)
15:05:24 WORKER: args: ()
15:05:24 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 88, 'last_n_outputs': 34, 'lr': 0.0016908298352048526, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.015013174621780588}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:05:24 DISPATCHER: Starting worker discovery
15:05:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:05:24 DISPATCHER: Finished worker discovery
15:06:24 DISPATCHER: Starting worker discovery
15:06:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:06:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-563:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:07:24 DISPATCHER: Starting worker discovery
15:07:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:07:24 DISPATCHER: Finished worker discovery
15:08:24 DISPATCHER: Starting worker discovery
15:08:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:08:24 DISPATCHER: Finished worker discovery
15:08:38 WORKER: done with job (8, 0, 2), trying to register it.
15:08:38 WORKER: registered result for job (8, 0, 2) with dispatcher
15:08:38 DISPATCHER: job (8, 0, 2) finished
15:08:38 DISPATCHER: register_result: lock acquired
15:08:38 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
15:08:38 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 88, 'last_n_outputs': 34, 'lr': 0.0016908298352048526, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.015013174621780588}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.299606598359815, 'info': {'sick_no_sick': 0.299606598359815, 'config': "{'batch_size': 64, 'hidden_dim': 88, 'last_n_outputs': 34, 'lr': 0.0016908298352048526, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.015013174621780588}"}}
exception: None

15:08:38 job_callback for (8, 0, 2) started
15:08:38 DISPATCHER: Trying to submit another job.
15:08:38 job_callback for (8, 0, 2) got condition
15:08:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:08:38 HBMASTER: Trying to run another job!
15:08:38 job_callback for (8, 0, 2) finished
15:08:38 HBMASTER: schedule new run for iteration 8
15:08:38 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
15:08:38 HBMASTER: submitting job (8, 0, 5) to dispatcher
15:08:38 DISPATCHER: trying to submit job (8, 0, 5)
15:08:38 DISPATCHER: trying to notify the job_runner thread.
15:08:38 HBMASTER: job (8, 0, 5) submitted to dispatcher
15:08:38 DISPATCHER: Trying to submit another job.
15:08:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:08:38 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776
15:08:38 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
15:08:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:08:38 WORKER: start processing job (8, 0, 5)
15:08:38 WORKER: args: ()
15:08:38 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 66, 'last_n_outputs': 35, 'lr': 0.0017082173793270094, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.023516105044909492}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:09:24 DISPATCHER: Starting worker discovery
15:09:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:09:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-564:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:10:24 DISPATCHER: Starting worker discovery
15:10:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:10:24 DISPATCHER: Finished worker discovery
15:11:24 DISPATCHER: Starting worker discovery
15:11:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:11:24 DISPATCHER: Finished worker discovery
15:11:53 WORKER: done with job (8, 0, 5), trying to register it.
15:11:53 WORKER: registered result for job (8, 0, 5) with dispatcher
15:11:53 DISPATCHER: job (8, 0, 5) finished
15:11:53 DISPATCHER: register_result: lock acquired
15:11:53 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
15:11:53 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 66, 'last_n_outputs': 35, 'lr': 0.0017082173793270094, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.023516105044909492}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.42658574757448336, 'info': {'sick_no_sick': 0.42658574757448336, 'config': "{'batch_size': 16, 'hidden_dim': 66, 'last_n_outputs': 35, 'lr': 0.0017082173793270094, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.023516105044909492}"}}
exception: None

15:11:53 job_callback for (8, 0, 5) started
15:11:53 DISPATCHER: Trying to submit another job.
15:11:53 job_callback for (8, 0, 5) got condition
15:11:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:11:53 HBMASTER: Trying to run another job!
15:11:53 job_callback for (8, 0, 5) finished
15:11:53 HBMASTER: schedule new run for iteration 8
15:11:53 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
15:11:53 HBMASTER: submitting job (8, 0, 6) to dispatcher
15:11:53 DISPATCHER: trying to submit job (8, 0, 6)
15:11:53 DISPATCHER: trying to notify the job_runner thread.
15:11:53 HBMASTER: job (8, 0, 6) submitted to dispatcher
15:11:53 DISPATCHER: Trying to submit another job.
15:11:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:11:53 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776
15:11:53 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
15:11:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:11:53 WORKER: start processing job (8, 0, 6)
15:11:53 WORKER: args: ()
15:11:53 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 75, 'last_n_outputs': 16, 'lr': 0.001310446577940673, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.010852355512984376}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:12:24 DISPATCHER: Starting worker discovery
15:12:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:12:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-565:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:13:24 DISPATCHER: Starting worker discovery
15:13:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:13:24 DISPATCHER: Finished worker discovery
15:14:24 DISPATCHER: Starting worker discovery
15:14:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:14:24 DISPATCHER: Finished worker discovery
15:15:07 WORKER: done with job (8, 0, 6), trying to register it.
15:15:07 WORKER: registered result for job (8, 0, 6) with dispatcher
15:15:07 DISPATCHER: job (8, 0, 6) finished
15:15:07 DISPATCHER: register_result: lock acquired
15:15:07 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
15:15:07 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 75, 'last_n_outputs': 16, 'lr': 0.001310446577940673, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.010852355512984376}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3797480016804904, 'info': {'sick_no_sick': 0.3797480016804904, 'config': "{'batch_size': 128, 'hidden_dim': 75, 'last_n_outputs': 16, 'lr': 0.001310446577940673, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.010852355512984376}"}}
exception: None

15:15:07 job_callback for (8, 0, 6) started
15:15:07 DISPATCHER: Trying to submit another job.
15:15:07 job_callback for (8, 0, 6) got condition
15:15:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:15:07 HBMASTER: Trying to run another job!
15:15:07 job_callback for (8, 0, 6) finished
15:15:07 HBMASTER: schedule new run for iteration 8
15:15:07 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
15:15:07 HBMASTER: submitting job (8, 0, 7) to dispatcher
15:15:07 DISPATCHER: trying to submit job (8, 0, 7)
15:15:07 DISPATCHER: trying to notify the job_runner thread.
15:15:07 HBMASTER: job (8, 0, 7) submitted to dispatcher
15:15:07 DISPATCHER: Trying to submit another job.
15:15:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:15:07 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776
15:15:07 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
15:15:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:15:07 WORKER: start processing job (8, 0, 7)
15:15:07 WORKER: args: ()
15:15:07 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 55, 'last_n_outputs': 46, 'lr': 0.013303816543844682, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.02653222898076358}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:15:24 DISPATCHER: Starting worker discovery
15:15:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:15:25 DISPATCHER: Finished worker discovery
Exception in thread Thread-566:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:16:25 DISPATCHER: Starting worker discovery
15:16:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:16:25 DISPATCHER: Finished worker discovery
15:17:25 DISPATCHER: Starting worker discovery
15:17:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:17:25 DISPATCHER: Finished worker discovery
15:18:22 WORKER: done with job (8, 0, 7), trying to register it.
15:18:22 WORKER: registered result for job (8, 0, 7) with dispatcher
15:18:22 DISPATCHER: job (8, 0, 7) finished
15:18:22 DISPATCHER: register_result: lock acquired
15:18:22 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
15:18:22 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 55, 'last_n_outputs': 46, 'lr': 0.013303816543844682, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.02653222898076358}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4733561352663818, 'info': {'sick_no_sick': 0.4733561352663818, 'config': "{'batch_size': 128, 'hidden_dim': 55, 'last_n_outputs': 46, 'lr': 0.013303816543844682, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.02653222898076358}"}}
exception: None

15:18:22 job_callback for (8, 0, 7) started
15:18:22 DISPATCHER: Trying to submit another job.
15:18:22 job_callback for (8, 0, 7) got condition
15:18:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:18:22 HBMASTER: Trying to run another job!
15:18:22 job_callback for (8, 0, 7) finished
15:18:22 HBMASTER: schedule new run for iteration 8
15:18:22 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
15:18:22 HBMASTER: submitting job (8, 0, 8) to dispatcher
15:18:22 DISPATCHER: trying to submit job (8, 0, 8)
15:18:22 DISPATCHER: trying to notify the job_runner thread.
15:18:22 HBMASTER: job (8, 0, 8) submitted to dispatcher
15:18:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:18:22 DISPATCHER: Trying to submit another job.
15:18:22 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776
15:18:22 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
15:18:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:18:22 WORKER: start processing job (8, 0, 8)
15:18:22 WORKER: args: ()
15:18:22 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 71, 'last_n_outputs': 38, 'lr': 0.0019889538779983796, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.0349394059133695}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:18:25 DISPATCHER: Starting worker discovery
15:18:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:18:25 DISPATCHER: Finished worker discovery
Exception in thread Thread-567:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:19:25 DISPATCHER: Starting worker discovery
15:19:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:19:25 DISPATCHER: Finished worker discovery
15:20:25 DISPATCHER: Starting worker discovery
15:20:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:20:25 DISPATCHER: Finished worker discovery
15:21:25 DISPATCHER: Starting worker discovery
15:21:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:21:25 DISPATCHER: Finished worker discovery
15:21:36 WORKER: done with job (8, 0, 8), trying to register it.
15:21:36 WORKER: registered result for job (8, 0, 8) with dispatcher
15:21:36 DISPATCHER: job (8, 0, 8) finished
15:21:36 DISPATCHER: register_result: lock acquired
15:21:36 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
15:21:36 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 71, 'last_n_outputs': 38, 'lr': 0.0019889538779983796, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.0349394059133695}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.24373619390736126, 'info': {'sick_no_sick': 0.24373619390736126, 'config': "{'batch_size': 64, 'hidden_dim': 71, 'last_n_outputs': 38, 'lr': 0.0019889538779983796, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.0349394059133695}"}}
exception: None

15:21:36 job_callback for (8, 0, 8) started
15:21:36 DISPATCHER: Trying to submit another job.
15:21:36 job_callback for (8, 0, 8) got condition
15:21:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:21:36 HBMASTER: Trying to run another job!
15:21:36 job_callback for (8, 0, 8) finished
15:21:36 HBMASTER: schedule new run for iteration 8
15:21:36 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
15:21:36 HBMASTER: submitting job (8, 0, 9) to dispatcher
15:21:36 DISPATCHER: trying to submit job (8, 0, 9)
15:21:36 DISPATCHER: trying to notify the job_runner thread.
15:21:36 HBMASTER: job (8, 0, 9) submitted to dispatcher
15:21:36 DISPATCHER: Trying to submit another job.
15:21:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:21:36 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.30598140416580691776
15:21:36 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
15:21:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:21:36 WORKER: start processing job (8, 0, 9)
15:21:36 WORKER: args: ()
15:21:36 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 92, 'last_n_outputs': 44, 'lr': 0.012168829944195278, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.03689676779951965}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:22:25 DISPATCHER: Starting worker discovery
15:22:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:22:25 DISPATCHER: Finished worker discovery
Exception in thread Thread-568:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:23:25 DISPATCHER: Starting worker discovery
15:23:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:23:25 DISPATCHER: Finished worker discovery
15:24:25 DISPATCHER: Starting worker discovery
15:24:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:24:25 DISPATCHER: Finished worker discovery
15:24:51 WORKER: done with job (8, 0, 9), trying to register it.
15:24:51 WORKER: registered result for job (8, 0, 9) with dispatcher
15:24:51 DISPATCHER: job (8, 0, 9) finished
15:24:51 DISPATCHER: register_result: lock acquired
15:24:51 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
15:24:51 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 92, 'last_n_outputs': 44, 'lr': 0.012168829944195278, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.03689676779951965}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3269167318604004, 'info': {'sick_no_sick': 0.3269167318604004, 'config': "{'batch_size': 64, 'hidden_dim': 92, 'last_n_outputs': 44, 'lr': 0.012168829944195278, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.03689676779951965}"}}
exception: None

15:24:51 job_callback for (8, 0, 9) started
15:24:51 DISPATCHER: Trying to submit another job.
15:24:51 job_callback for (8, 0, 9) got condition
15:24:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:24:51 HBMASTER: Trying to run another job!
15:24:51 job_callback for (8, 0, 9) finished
15:24:51 HBMASTER: schedule new run for iteration 8
15:24:51 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
15:24:51 HBMASTER: submitting job (8, 0, 10) to dispatcher
15:24:51 DISPATCHER: trying to submit job (8, 0, 10)
15:24:51 DISPATCHER: trying to notify the job_runner thread.
15:24:51 HBMASTER: job (8, 0, 10) submitted to dispatcher
15:24:51 DISPATCHER: Trying to submit another job.
15:24:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:24:51 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.30598140416580691776
15:24:51 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
15:24:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:24:51 WORKER: start processing job (8, 0, 10)
15:24:51 WORKER: args: ()
15:24:51 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 62, 'last_n_outputs': 33, 'lr': 0.04473923536933063, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.01858389384649549}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:25:25 DISPATCHER: Starting worker discovery
15:25:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:25:25 DISPATCHER: Finished worker discovery
Exception in thread Thread-569:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:26:25 DISPATCHER: Starting worker discovery
15:26:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:26:25 DISPATCHER: Finished worker discovery
15:27:25 DISPATCHER: Starting worker discovery
15:27:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:27:25 DISPATCHER: Finished worker discovery
15:28:06 WORKER: done with job (8, 0, 10), trying to register it.
15:28:06 WORKER: registered result for job (8, 0, 10) with dispatcher
15:28:06 DISPATCHER: job (8, 0, 10) finished
15:28:06 DISPATCHER: register_result: lock acquired
15:28:06 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
15:28:06 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 62, 'last_n_outputs': 33, 'lr': 0.04473923536933063, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.01858389384649549}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3265125467424782, 'info': {'sick_no_sick': 0.3265125467424782, 'config': "{'batch_size': 128, 'hidden_dim': 62, 'last_n_outputs': 33, 'lr': 0.04473923536933063, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.01858389384649549}"}}
exception: None

15:28:06 job_callback for (8, 0, 10) started
15:28:06 DISPATCHER: Trying to submit another job.
15:28:06 job_callback for (8, 0, 10) got condition
15:28:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:28:06 HBMASTER: Trying to run another job!
15:28:06 job_callback for (8, 0, 10) finished
15:28:06 HBMASTER: schedule new run for iteration 8
15:28:06 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
15:28:06 HBMASTER: submitting job (8, 0, 14) to dispatcher
15:28:06 DISPATCHER: trying to submit job (8, 0, 14)
15:28:06 DISPATCHER: trying to notify the job_runner thread.
15:28:06 HBMASTER: job (8, 0, 14) submitted to dispatcher
15:28:06 DISPATCHER: Trying to submit another job.
15:28:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:28:06 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.30598140416580691776
15:28:06 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
15:28:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:28:06 WORKER: start processing job (8, 0, 14)
15:28:06 WORKER: args: ()
15:28:06 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 11, 'lr': 0.009101341393025167, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.17187822638442615}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:28:25 DISPATCHER: Starting worker discovery
15:28:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:28:25 DISPATCHER: Finished worker discovery
Exception in thread Thread-570:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:29:25 DISPATCHER: Starting worker discovery
15:29:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:29:25 DISPATCHER: Finished worker discovery
15:30:25 DISPATCHER: Starting worker discovery
15:30:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:30:25 DISPATCHER: Finished worker discovery
15:31:21 WORKER: done with job (8, 0, 14), trying to register it.
15:31:21 WORKER: registered result for job (8, 0, 14) with dispatcher
15:31:21 DISPATCHER: job (8, 0, 14) finished
15:31:21 DISPATCHER: register_result: lock acquired
15:31:21 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
15:31:21 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 11, 'lr': 0.009101341393025167, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.17187822638442615}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.43161720696200245, 'info': {'sick_no_sick': 0.43161720696200245, 'config': "{'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 11, 'lr': 0.009101341393025167, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.17187822638442615}"}}
exception: None

15:31:21 job_callback for (8, 0, 14) started
15:31:21 job_callback for (8, 0, 14) got condition
15:31:21 DISPATCHER: Trying to submit another job.
15:31:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:31:21 HBMASTER: Trying to run another job!
15:31:21 job_callback for (8, 0, 14) finished
15:31:21 HBMASTER: schedule new run for iteration 8
15:31:21 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
15:31:21 HBMASTER: submitting job (8, 0, 23) to dispatcher
15:31:21 DISPATCHER: trying to submit job (8, 0, 23)
15:31:21 DISPATCHER: trying to notify the job_runner thread.
15:31:21 HBMASTER: job (8, 0, 23) submitted to dispatcher
15:31:21 DISPATCHER: Trying to submit another job.
15:31:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:31:21 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.30598140416580691776
15:31:21 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
15:31:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:31:21 WORKER: start processing job (8, 0, 23)
15:31:21 WORKER: args: ()
15:31:21 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 72, 'last_n_outputs': 25, 'lr': 0.0046872685361057966, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.09512761592159358}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:31:25 DISPATCHER: Starting worker discovery
15:31:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:31:25 DISPATCHER: Finished worker discovery
Exception in thread Thread-571:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:32:25 DISPATCHER: Starting worker discovery
15:32:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:32:25 DISPATCHER: Finished worker discovery
15:33:25 DISPATCHER: Starting worker discovery
15:33:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:33:25 DISPATCHER: Finished worker discovery
15:34:25 DISPATCHER: Starting worker discovery
15:34:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:34:25 DISPATCHER: Finished worker discovery
15:34:34 WORKER: done with job (8, 0, 23), trying to register it.
15:34:34 WORKER: registered result for job (8, 0, 23) with dispatcher
15:34:34 DISPATCHER: job (8, 0, 23) finished
15:34:34 DISPATCHER: register_result: lock acquired
15:34:34 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
15:34:34 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 72, 'last_n_outputs': 25, 'lr': 0.0046872685361057966, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.09512761592159358}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.447359431174264, 'info': {'sick_no_sick': 0.447359431174264, 'config': "{'batch_size': 64, 'hidden_dim': 72, 'last_n_outputs': 25, 'lr': 0.0046872685361057966, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.09512761592159358}"}}
exception: None

15:34:34 job_callback for (8, 0, 23) started
15:34:34 job_callback for (8, 0, 23) got condition
15:34:34 DISPATCHER: Trying to submit another job.
15:34:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:34:34 HBMASTER: Trying to run another job!
15:34:34 job_callback for (8, 0, 23) finished
15:34:34 ITERATION: Advancing config (8, 0, 7) to next budget 400.000000
15:34:34 ITERATION: Advancing config (8, 0, 14) to next budget 400.000000
15:34:34 ITERATION: Advancing config (8, 0, 23) to next budget 400.000000
15:34:34 HBMASTER: schedule new run for iteration 8
15:34:34 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
15:34:34 HBMASTER: submitting job (8, 0, 7) to dispatcher
15:34:34 DISPATCHER: trying to submit job (8, 0, 7)
15:34:34 DISPATCHER: trying to notify the job_runner thread.
15:34:34 HBMASTER: job (8, 0, 7) submitted to dispatcher
15:34:34 DISPATCHER: Trying to submit another job.
15:34:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:34:34 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776
15:34:34 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
15:34:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:34:34 WORKER: start processing job (8, 0, 7)
15:34:34 WORKER: args: ()
15:34:34 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 55, 'last_n_outputs': 46, 'lr': 0.013303816543844682, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.02653222898076358}, 'budget': 400.0, 'working_directory': '.'}
15:35:25 DISPATCHER: Starting worker discovery
15:35:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:35:25 DISPATCHER: Finished worker discovery
Exception in thread Thread-572:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:36:25 DISPATCHER: Starting worker discovery
15:36:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:36:25 DISPATCHER: Finished worker discovery
15:37:25 DISPATCHER: Starting worker discovery
15:37:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:37:25 DISPATCHER: Finished worker discovery
15:38:25 DISPATCHER: Starting worker discovery
15:38:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:38:25 DISPATCHER: Finished worker discovery
15:39:25 DISPATCHER: Starting worker discovery
15:39:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:39:25 DISPATCHER: Finished worker discovery
15:40:25 DISPATCHER: Starting worker discovery
15:40:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:40:25 DISPATCHER: Finished worker discovery
15:41:25 DISPATCHER: Starting worker discovery
15:41:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:41:25 DISPATCHER: Finished worker discovery
15:42:17 WORKER: done with job (8, 0, 7), trying to register it.
15:42:17 WORKER: registered result for job (8, 0, 7) with dispatcher
15:42:17 DISPATCHER: job (8, 0, 7) finished
15:42:17 DISPATCHER: register_result: lock acquired
15:42:17 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
15:42:17 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 55, 'last_n_outputs': 46, 'lr': 0.013303816543844682, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.02653222898076358}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.4535154248837528, 'info': {'sick_no_sick': 0.4535154248837528, 'config': "{'batch_size': 128, 'hidden_dim': 55, 'last_n_outputs': 46, 'lr': 0.013303816543844682, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.02653222898076358}"}}
exception: None

15:42:17 job_callback for (8, 0, 7) started
15:42:17 job_callback for (8, 0, 7) got condition
15:42:17 DISPATCHER: Trying to submit another job.
15:42:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:42:17 done building a new model for budget 400.000000 based on 9/21 split
Best loss for this budget:-0.528437





15:42:17 HBMASTER: Trying to run another job!
15:42:17 job_callback for (8, 0, 7) finished
15:42:17 HBMASTER: schedule new run for iteration 8
15:42:17 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
15:42:17 HBMASTER: submitting job (8, 0, 14) to dispatcher
15:42:17 DISPATCHER: trying to submit job (8, 0, 14)
15:42:17 DISPATCHER: trying to notify the job_runner thread.
15:42:17 HBMASTER: job (8, 0, 14) submitted to dispatcher
15:42:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:42:17 DISPATCHER: Trying to submit another job.
15:42:17 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.30598140416580691776
15:42:17 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
15:42:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:42:17 WORKER: start processing job (8, 0, 14)
15:42:17 WORKER: args: ()
15:42:17 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 11, 'lr': 0.009101341393025167, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.17187822638442615}, 'budget': 400.0, 'working_directory': '.'}
15:42:25 DISPATCHER: Starting worker discovery
15:42:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:42:25 DISPATCHER: Finished worker discovery
Exception in thread Thread-573:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:43:25 DISPATCHER: Starting worker discovery
15:43:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:43:25 DISPATCHER: Finished worker discovery
15:44:25 DISPATCHER: Starting worker discovery
15:44:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:44:25 DISPATCHER: Finished worker discovery
15:45:25 DISPATCHER: Starting worker discovery
15:45:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:45:25 DISPATCHER: Finished worker discovery
15:46:25 DISPATCHER: Starting worker discovery
15:46:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:46:25 DISPATCHER: Finished worker discovery
15:47:25 DISPATCHER: Starting worker discovery
15:47:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:47:25 DISPATCHER: Finished worker discovery
15:48:25 DISPATCHER: Starting worker discovery
15:48:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:48:25 DISPATCHER: Finished worker discovery
15:49:25 DISPATCHER: Starting worker discovery
15:49:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:49:25 DISPATCHER: Finished worker discovery
15:50:00 WORKER: done with job (8, 0, 14), trying to register it.
15:50:00 WORKER: registered result for job (8, 0, 14) with dispatcher
15:50:00 DISPATCHER: job (8, 0, 14) finished
15:50:00 DISPATCHER: register_result: lock acquired
15:50:00 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
15:50:00 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 11, 'lr': 0.009101341393025167, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.17187822638442615}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.45344607489369376, 'info': {'sick_no_sick': 0.45344607489369376, 'config': "{'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 11, 'lr': 0.009101341393025167, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.17187822638442615}"}}
exception: None

15:50:00 job_callback for (8, 0, 14) started
15:50:00 DISPATCHER: Trying to submit another job.
15:50:00 job_callback for (8, 0, 14) got condition
15:50:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:50:00 done building a new model for budget 400.000000 based on 9/22 split
Best loss for this budget:-0.528437





15:50:00 HBMASTER: Trying to run another job!
15:50:00 job_callback for (8, 0, 14) finished
15:50:00 HBMASTER: schedule new run for iteration 8
15:50:00 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
15:50:00 HBMASTER: submitting job (8, 0, 23) to dispatcher
15:50:00 DISPATCHER: trying to submit job (8, 0, 23)
15:50:00 DISPATCHER: trying to notify the job_runner thread.
15:50:00 HBMASTER: job (8, 0, 23) submitted to dispatcher
15:50:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:50:00 DISPATCHER: Trying to submit another job.
15:50:00 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.30598140416580691776
15:50:00 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
15:50:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:50:00 WORKER: start processing job (8, 0, 23)
15:50:00 WORKER: args: ()
15:50:00 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 72, 'last_n_outputs': 25, 'lr': 0.0046872685361057966, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.09512761592159358}, 'budget': 400.0, 'working_directory': '.'}
15:50:25 DISPATCHER: Starting worker discovery
15:50:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:50:25 DISPATCHER: Finished worker discovery
Exception in thread Thread-574:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:51:25 DISPATCHER: Starting worker discovery
15:51:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:51:25 DISPATCHER: Finished worker discovery
15:52:25 DISPATCHER: Starting worker discovery
15:52:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:52:25 DISPATCHER: Finished worker discovery
15:53:25 DISPATCHER: Starting worker discovery
15:53:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:53:25 DISPATCHER: Finished worker discovery
15:54:25 DISPATCHER: Starting worker discovery
15:54:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:54:25 DISPATCHER: Finished worker discovery
15:55:25 DISPATCHER: Starting worker discovery
15:55:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:55:25 DISPATCHER: Finished worker discovery
15:56:25 DISPATCHER: Starting worker discovery
15:56:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:56:25 DISPATCHER: Finished worker discovery
15:57:25 DISPATCHER: Starting worker discovery
15:57:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:57:25 DISPATCHER: Finished worker discovery
15:57:40 WORKER: done with job (8, 0, 23), trying to register it.
15:57:40 WORKER: registered result for job (8, 0, 23) with dispatcher
15:57:40 DISPATCHER: job (8, 0, 23) finished
15:57:40 DISPATCHER: register_result: lock acquired
15:57:40 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
15:57:40 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 72, 'last_n_outputs': 25, 'lr': 0.0046872685361057966, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.09512761592159358}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3043527105971984, 'info': {'sick_no_sick': 0.3043527105971984, 'config': "{'batch_size': 64, 'hidden_dim': 72, 'last_n_outputs': 25, 'lr': 0.0046872685361057966, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.09512761592159358}"}}
exception: None

15:57:40 job_callback for (8, 0, 23) started
15:57:40 job_callback for (8, 0, 23) got condition
15:57:40 DISPATCHER: Trying to submit another job.
15:57:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:57:40 done building a new model for budget 400.000000 based on 9/22 split
Best loss for this budget:-0.528437





15:57:40 HBMASTER: Trying to run another job!
15:57:40 job_callback for (8, 0, 23) finished
15:57:40 ITERATION: Advancing config (8, 0, 7) to next budget 1200.000000
15:57:40 HBMASTER: schedule new run for iteration 8
15:57:40 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
15:57:40 HBMASTER: submitting job (8, 0, 7) to dispatcher
15:57:40 DISPATCHER: trying to submit job (8, 0, 7)
15:57:40 DISPATCHER: trying to notify the job_runner thread.
15:57:40 HBMASTER: job (8, 0, 7) submitted to dispatcher
15:57:40 DISPATCHER: Trying to submit another job.
15:57:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:57:40 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776
15:57:40 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
15:57:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:57:40 WORKER: start processing job (8, 0, 7)
15:57:40 WORKER: args: ()
15:57:40 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 55, 'last_n_outputs': 46, 'lr': 0.013303816543844682, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.02653222898076358}, 'budget': 1200.0, 'working_directory': '.'}
15:58:25 DISPATCHER: Starting worker discovery
15:58:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:58:25 DISPATCHER: Finished worker discovery
Exception in thread Thread-575:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:59:25 DISPATCHER: Starting worker discovery
15:59:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:59:25 DISPATCHER: Finished worker discovery
16:00:25 DISPATCHER: Starting worker discovery
16:00:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:00:25 DISPATCHER: Finished worker discovery
16:01:25 DISPATCHER: Starting worker discovery
16:01:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:01:25 DISPATCHER: Finished worker discovery
16:02:25 DISPATCHER: Starting worker discovery
16:02:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:02:25 DISPATCHER: Finished worker discovery
16:03:25 DISPATCHER: Starting worker discovery
16:03:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:03:25 DISPATCHER: Finished worker discovery
16:04:25 DISPATCHER: Starting worker discovery
16:04:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:04:25 DISPATCHER: Finished worker discovery
16:05:25 DISPATCHER: Starting worker discovery
16:05:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:05:25 DISPATCHER: Finished worker discovery
16:06:25 DISPATCHER: Starting worker discovery
16:06:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:06:25 DISPATCHER: Finished worker discovery
16:07:25 DISPATCHER: Starting worker discovery
16:07:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:07:25 DISPATCHER: Finished worker discovery
16:08:25 DISPATCHER: Starting worker discovery
16:08:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:08:25 DISPATCHER: Finished worker discovery
16:09:25 DISPATCHER: Starting worker discovery
16:09:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:09:25 DISPATCHER: Finished worker discovery
16:10:25 DISPATCHER: Starting worker discovery
16:10:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:10:25 DISPATCHER: Finished worker discovery
16:11:25 DISPATCHER: Starting worker discovery
16:11:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:11:25 DISPATCHER: Finished worker discovery
16:12:25 DISPATCHER: Starting worker discovery
16:12:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:12:25 DISPATCHER: Finished worker discovery
16:13:25 DISPATCHER: Starting worker discovery
16:13:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:13:25 DISPATCHER: Finished worker discovery
16:14:25 DISPATCHER: Starting worker discovery
16:14:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:14:25 DISPATCHER: Finished worker discovery
16:15:25 DISPATCHER: Starting worker discovery
16:15:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:15:25 DISPATCHER: Finished worker discovery
16:16:25 DISPATCHER: Starting worker discovery
16:16:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:16:25 DISPATCHER: Finished worker discovery
16:17:25 DISPATCHER: Starting worker discovery
16:17:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:17:25 DISPATCHER: Finished worker discovery
16:18:25 DISPATCHER: Starting worker discovery
16:18:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:18:25 DISPATCHER: Finished worker discovery
16:18:41 WORKER: done with job (8, 0, 7), trying to register it.
16:18:41 WORKER: registered result for job (8, 0, 7) with dispatcher
16:18:41 DISPATCHER: job (8, 0, 7) finished
16:18:41 DISPATCHER: register_result: lock acquired
16:18:41 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
16:18:41 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 55, 'last_n_outputs': 46, 'lr': 0.013303816543844682, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.02653222898076358}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.4128394042624231, 'info': {'sick_no_sick': 0.4128394042624231, 'config': "{'batch_size': 128, 'hidden_dim': 55, 'last_n_outputs': 46, 'lr': 0.013303816543844682, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.02653222898076358}"}}
exception: None

16:18:41 job_callback for (8, 0, 7) started
16:18:41 job_callback for (8, 0, 7) got condition
16:18:41 DISPATCHER: Trying to submit another job.
16:18:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:18:41 HBMASTER: Trying to run another job!
16:18:41 job_callback for (8, 0, 7) finished
16:18:41 start sampling a new configuration.
16:18:41 best_vector: [0, 0.8152078782415282, 0.5438947925056972, 0.021062212902005932, 0.16991191631517932, 0, 0.9381234279219336, 0.1166483094919277], 0.0015524379399687205, 1.301015399672309, 0.002019745666934861
16:18:41 done sampling a new configuration.
16:18:41 HBMASTER: schedule new run for iteration 9
16:18:41 HBMASTER: trying submitting job (9, 0, 0) to dispatcher
16:18:41 HBMASTER: submitting job (9, 0, 0) to dispatcher
16:18:41 DISPATCHER: trying to submit job (9, 0, 0)
16:18:41 DISPATCHER: trying to notify the job_runner thread.
16:18:41 HBMASTER: job (9, 0, 0) submitted to dispatcher
16:18:41 DISPATCHER: Trying to submit another job.
16:18:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:18:41 DISPATCHER: starting job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:18:41 DISPATCHER: job (9, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:18:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:18:41 WORKER: start processing job (9, 0, 0)
16:18:41 WORKER: args: ()
16:18:41 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 86, 'last_n_outputs': 28, 'lr': 0.0011018549468698388, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.0141828317066843}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:19:25 DISPATCHER: Starting worker discovery
16:19:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:19:25 DISPATCHER: Finished worker discovery
Exception in thread Thread-576:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

16:20:25 DISPATCHER: Starting worker discovery
16:20:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:20:25 DISPATCHER: Finished worker discovery
16:21:25 DISPATCHER: Starting worker discovery
16:21:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:21:25 DISPATCHER: Finished worker discovery
16:21:55 WORKER: done with job (9, 0, 0), trying to register it.
16:21:55 WORKER: registered result for job (9, 0, 0) with dispatcher
16:21:55 DISPATCHER: job (9, 0, 0) finished
16:21:55 DISPATCHER: register_result: lock acquired
16:21:55 DISPATCHER: job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
16:21:55 job_id: (9, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 86, 'last_n_outputs': 28, 'lr': 0.0011018549468698388, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.0141828317066843}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.36596172324542914, 'info': {'sick_no_sick': 0.36596172324542914, 'config': "{'batch_size': 16, 'hidden_dim': 86, 'last_n_outputs': 28, 'lr': 0.0011018549468698388, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.0141828317066843}"}}
exception: None

16:21:55 job_callback for (9, 0, 0) started
16:21:55 job_callback for (9, 0, 0) got condition
16:21:55 DISPATCHER: Trying to submit another job.
16:21:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:21:55 HBMASTER: Trying to run another job!
16:21:55 job_callback for (9, 0, 0) finished
16:21:55 start sampling a new configuration.
16:21:55 best_vector: [2, 0.6451664884450795, 0.9532433815366077, 0.28837082552863114, 0.04190719680694317, 0, 0.4719377491690352, 0.7284417165966127], 0.005308307382733705, 31.987931464408103, 0.1698017727508973
16:21:55 done sampling a new configuration.
16:21:55 HBMASTER: schedule new run for iteration 9
16:21:55 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
16:21:55 HBMASTER: submitting job (9, 0, 1) to dispatcher
16:21:55 DISPATCHER: trying to submit job (9, 0, 1)
16:21:55 DISPATCHER: trying to notify the job_runner thread.
16:21:55 HBMASTER: job (9, 0, 1) submitted to dispatcher
16:21:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:21:55 DISPATCHER: Trying to submit another job.
16:21:55 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:21:55 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:21:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:21:55 WORKER: start processing job (9, 0, 1)
16:21:55 WORKER: args: ()
16:21:55 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 72, 'last_n_outputs': 48, 'lr': 0.003773476511886275, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.08865934600091857}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:22:25 DISPATCHER: Starting worker discovery
16:22:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:22:25 DISPATCHER: Finished worker discovery
Exception in thread Thread-577:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

16:23:25 DISPATCHER: Starting worker discovery
16:23:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:23:25 DISPATCHER: Finished worker discovery
16:24:25 DISPATCHER: Starting worker discovery
16:24:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:24:25 DISPATCHER: Finished worker discovery
16:25:10 WORKER: done with job (9, 0, 1), trying to register it.
16:25:10 WORKER: registered result for job (9, 0, 1) with dispatcher
16:25:10 DISPATCHER: job (9, 0, 1) finished
16:25:10 DISPATCHER: register_result: lock acquired
16:25:10 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
16:25:10 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 72, 'last_n_outputs': 48, 'lr': 0.003773476511886275, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.08865934600091857}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4465093529075885, 'info': {'sick_no_sick': 0.4465093529075885, 'config': "{'batch_size': 64, 'hidden_dim': 72, 'last_n_outputs': 48, 'lr': 0.003773476511886275, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.08865934600091857}"}}
exception: None

16:25:10 job_callback for (9, 0, 1) started
16:25:10 DISPATCHER: Trying to submit another job.
16:25:10 job_callback for (9, 0, 1) got condition
16:25:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:25:10 HBMASTER: Trying to run another job!
16:25:10 job_callback for (9, 0, 1) finished
16:25:10 start sampling a new configuration.
16:25:10 done sampling a new configuration.
16:25:10 HBMASTER: schedule new run for iteration 9
16:25:10 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
16:25:10 HBMASTER: submitting job (9, 0, 2) to dispatcher
16:25:10 DISPATCHER: trying to submit job (9, 0, 2)
16:25:10 DISPATCHER: trying to notify the job_runner thread.
16:25:10 HBMASTER: job (9, 0, 2) submitted to dispatcher
16:25:10 DISPATCHER: Trying to submit another job.
16:25:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:25:10 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:25:10 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:25:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:25:10 WORKER: start processing job (9, 0, 2)
16:25:10 WORKER: args: ()
16:25:10 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 57, 'last_n_outputs': 16, 'lr': 0.08361812169466128, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.09908636219718481}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:25:25 DISPATCHER: Starting worker discovery
16:25:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:25:25 DISPATCHER: Finished worker discovery
Exception in thread Thread-578:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

16:26:25 DISPATCHER: Starting worker discovery
16:26:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:26:25 DISPATCHER: Finished worker discovery
16:27:25 DISPATCHER: Starting worker discovery
16:27:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:27:25 DISPATCHER: Finished worker discovery
16:28:25 WORKER: done with job (9, 0, 2), trying to register it.
16:28:25 WORKER: registered result for job (9, 0, 2) with dispatcher
16:28:25 DISPATCHER: job (9, 0, 2) finished
16:28:25 DISPATCHER: register_result: lock acquired
16:28:25 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
16:28:25 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 57, 'last_n_outputs': 16, 'lr': 0.08361812169466128, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.09908636219718481}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 57, 'last_n_outputs': 16, 'lr': 0.08361812169466128, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.09908636219718481}"}}
exception: None

16:28:25 job_callback for (9, 0, 2) started
16:28:25 DISPATCHER: Trying to submit another job.
16:28:25 job_callback for (9, 0, 2) got condition
16:28:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:28:25 HBMASTER: Trying to run another job!
16:28:25 job_callback for (9, 0, 2) finished
16:28:25 start sampling a new configuration.
16:28:25 best_vector: [0, 0.6637749771103909, 0.5803044899572205, 0.24291137110490546, 0.11906739001981231, 0, 0.8675034590810663, 0.2136631309554008], 0.003554917099829255, 8.134013967173678, 0.028915745342155703
16:28:25 done sampling a new configuration.
16:28:25 HBMASTER: schedule new run for iteration 9
16:28:25 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
16:28:25 HBMASTER: submitting job (9, 0, 3) to dispatcher
16:28:25 DISPATCHER: trying to submit job (9, 0, 3)
16:28:25 DISPATCHER: trying to notify the job_runner thread.
16:28:25 HBMASTER: job (9, 0, 3) submitted to dispatcher
16:28:25 DISPATCHER: Trying to submit another job.
16:28:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:28:25 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:28:25 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:28:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:28:25 WORKER: start processing job (9, 0, 3)
16:28:25 WORKER: args: ()
16:28:25 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 73, 'last_n_outputs': 30, 'lr': 0.0030607139448158337, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.018966279325798103}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:28:25 DISPATCHER: Starting worker discovery
16:28:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:28:25 DISPATCHER: Finished worker discovery
16:29:25 DISPATCHER: Starting worker discovery
16:29:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:29:25 DISPATCHER: Finished worker discovery
Exception in thread Thread-579:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

16:30:25 DISPATCHER: Starting worker discovery
16:30:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:30:25 DISPATCHER: Finished worker discovery
16:31:25 DISPATCHER: Starting worker discovery
16:31:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:31:25 DISPATCHER: Finished worker discovery
16:31:40 WORKER: done with job (9, 0, 3), trying to register it.
16:31:40 WORKER: registered result for job (9, 0, 3) with dispatcher
16:31:40 DISPATCHER: job (9, 0, 3) finished
16:31:40 DISPATCHER: register_result: lock acquired
16:31:40 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
16:31:40 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 73, 'last_n_outputs': 30, 'lr': 0.0030607139448158337, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.018966279325798103}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4164513576388063, 'info': {'sick_no_sick': 0.4164513576388063, 'config': "{'batch_size': 16, 'hidden_dim': 73, 'last_n_outputs': 30, 'lr': 0.0030607139448158337, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.018966279325798103}"}}
exception: None

16:31:40 job_callback for (9, 0, 3) started
16:31:40 DISPATCHER: Trying to submit another job.
16:31:40 job_callback for (9, 0, 3) got condition
16:31:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:31:40 HBMASTER: Trying to run another job!
16:31:40 job_callback for (9, 0, 3) finished
16:31:40 start sampling a new configuration.
16:31:40 done sampling a new configuration.
16:31:40 HBMASTER: schedule new run for iteration 9
16:31:40 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
16:31:40 HBMASTER: submitting job (9, 0, 4) to dispatcher
16:31:40 DISPATCHER: trying to submit job (9, 0, 4)
16:31:40 DISPATCHER: trying to notify the job_runner thread.
16:31:40 HBMASTER: job (9, 0, 4) submitted to dispatcher
16:31:40 DISPATCHER: Trying to submit another job.
16:31:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:31:40 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:31:40 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:31:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:31:40 WORKER: start processing job (9, 0, 4)
16:31:40 WORKER: args: ()
16:31:40 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 38, 'last_n_outputs': 26, 'lr': 0.010286356689448517, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.03630701803185133}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:32:25 DISPATCHER: Starting worker discovery
16:32:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:32:25 DISPATCHER: Finished worker discovery
Exception in thread Thread-580:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

16:33:25 DISPATCHER: Starting worker discovery
16:33:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:33:25 DISPATCHER: Finished worker discovery
16:34:25 DISPATCHER: Starting worker discovery
16:34:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:34:25 DISPATCHER: Finished worker discovery
16:34:55 WORKER: done with job (9, 0, 4), trying to register it.
16:34:55 WORKER: registered result for job (9, 0, 4) with dispatcher
16:34:55 DISPATCHER: job (9, 0, 4) finished
16:34:55 DISPATCHER: register_result: lock acquired
16:34:55 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
16:34:55 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 38, 'last_n_outputs': 26, 'lr': 0.010286356689448517, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.03630701803185133}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 38, 'last_n_outputs': 26, 'lr': 0.010286356689448517, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.03630701803185133}"}}
exception: None

16:34:55 job_callback for (9, 0, 4) started
16:34:55 job_callback for (9, 0, 4) got condition
16:34:55 DISPATCHER: Trying to submit another job.
16:34:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:34:55 HBMASTER: Trying to run another job!
16:34:55 job_callback for (9, 0, 4) finished
16:34:55 start sampling a new configuration.
16:34:55 done sampling a new configuration.
16:34:55 HBMASTER: schedule new run for iteration 9
16:34:55 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
16:34:55 HBMASTER: submitting job (9, 0, 5) to dispatcher
16:34:55 DISPATCHER: trying to submit job (9, 0, 5)
16:34:55 DISPATCHER: trying to notify the job_runner thread.
16:34:55 HBMASTER: job (9, 0, 5) submitted to dispatcher
16:34:55 DISPATCHER: Trying to submit another job.
16:34:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:34:55 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:34:55 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:34:55 WORKER: start processing job (9, 0, 5)
16:34:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:34:55 WORKER: args: ()
16:34:55 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 72, 'last_n_outputs': 43, 'lr': 0.00308518933463677, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.026264002621339853}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:35:25 DISPATCHER: Starting worker discovery
16:35:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:35:25 DISPATCHER: Finished worker discovery
Exception in thread Thread-581:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

16:36:25 DISPATCHER: Starting worker discovery
16:36:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:36:25 DISPATCHER: Finished worker discovery
16:37:25 DISPATCHER: Starting worker discovery
16:37:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:37:25 DISPATCHER: Finished worker discovery
16:38:09 WORKER: done with job (9, 0, 5), trying to register it.
16:38:09 WORKER: registered result for job (9, 0, 5) with dispatcher
16:38:09 DISPATCHER: job (9, 0, 5) finished
16:38:09 DISPATCHER: register_result: lock acquired
16:38:09 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
16:38:09 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 72, 'last_n_outputs': 43, 'lr': 0.00308518933463677, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.026264002621339853}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 72, 'last_n_outputs': 43, 'lr': 0.00308518933463677, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.026264002621339853}"}}
exception: None

16:38:09 DISPATCHER: Trying to submit another job.
16:38:09 job_callback for (9, 0, 5) started
16:38:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:38:09 job_callback for (9, 0, 5) got condition
16:38:09 HBMASTER: Trying to run another job!
16:38:09 job_callback for (9, 0, 5) finished
16:38:09 start sampling a new configuration.
16:38:09 best_vector: [2, 0.9719656349180157, 0.03470808212626997, 0.5951470200691115, 0.02186006891975152, 0, 0.04422789525153248, 0.9789131354163954], 0.0016508505470720942, 1.790125437302476, 0.0029552295574984642
16:38:09 done sampling a new configuration.
16:38:09 HBMASTER: schedule new run for iteration 9
16:38:09 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
16:38:09 HBMASTER: submitting job (9, 0, 6) to dispatcher
16:38:09 DISPATCHER: trying to submit job (9, 0, 6)
16:38:09 DISPATCHER: trying to notify the job_runner thread.
16:38:09 HBMASTER: job (9, 0, 6) submitted to dispatcher
16:38:09 DISPATCHER: Trying to submit another job.
16:38:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:38:09 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:38:09 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:38:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:38:09 WORKER: start processing job (9, 0, 6)
16:38:09 WORKER: args: ()
16:38:09 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 98, 'last_n_outputs': 2, 'lr': 0.015498656040508034, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.18775666057241455}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:38:25 DISPATCHER: Starting worker discovery
16:38:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:38:25 DISPATCHER: Finished worker discovery
Exception in thread Thread-582:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

16:39:25 DISPATCHER: Starting worker discovery
16:39:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:39:25 DISPATCHER: Finished worker discovery
16:40:25 DISPATCHER: Starting worker discovery
16:40:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:40:25 DISPATCHER: Finished worker discovery
16:41:23 WORKER: done with job (9, 0, 6), trying to register it.
16:41:23 WORKER: registered result for job (9, 0, 6) with dispatcher
16:41:23 DISPATCHER: job (9, 0, 6) finished
16:41:23 DISPATCHER: register_result: lock acquired
16:41:23 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
16:41:23 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 98, 'last_n_outputs': 2, 'lr': 0.015498656040508034, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.18775666057241455}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1326354798735182, 'info': {'sick_no_sick': 0.1326354798735182, 'config': "{'batch_size': 64, 'hidden_dim': 98, 'last_n_outputs': 2, 'lr': 0.015498656040508034, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.18775666057241455}"}}
exception: None

16:41:23 job_callback for (9, 0, 6) started
16:41:23 job_callback for (9, 0, 6) got condition
16:41:23 DISPATCHER: Trying to submit another job.
16:41:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:41:23 HBMASTER: Trying to run another job!
16:41:23 job_callback for (9, 0, 6) finished
16:41:23 start sampling a new configuration.
16:41:23 best_vector: [1, 0.8739147176909037, 0.7660084651163225, 0.33351385809079526, 0.11947660055182091, 0, 0.11035640274695913, 0.8269642883919535], 0.004060556743106649, 1.1139219083079726, 0.0045231431160741645
16:41:23 done sampling a new configuration.
16:41:23 HBMASTER: schedule new run for iteration 9
16:41:23 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
16:41:23 HBMASTER: submitting job (9, 0, 7) to dispatcher
16:41:23 DISPATCHER: trying to submit job (9, 0, 7)
16:41:23 DISPATCHER: trying to notify the job_runner thread.
16:41:23 HBMASTER: job (9, 0, 7) submitted to dispatcher
16:41:23 DISPATCHER: Trying to submit another job.
16:41:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:41:23 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:41:23 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:41:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:41:23 WORKER: start processing job (9, 0, 7)
16:41:23 WORKER: args: ()
16:41:23 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 90, 'last_n_outputs': 39, 'lr': 0.0046454492100708655, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.11909824024442119}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:41:25 DISPATCHER: Starting worker discovery
16:41:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:41:25 DISPATCHER: Finished worker discovery
16:42:25 DISPATCHER: Starting worker discovery
16:42:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:42:25 DISPATCHER: Finished worker discovery
Exception in thread Thread-583:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

16:43:25 DISPATCHER: Starting worker discovery
16:43:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:43:25 DISPATCHER: Finished worker discovery
16:44:25 DISPATCHER: Starting worker discovery
16:44:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:44:25 DISPATCHER: Finished worker discovery
16:44:39 WORKER: done with job (9, 0, 7), trying to register it.
16:44:39 WORKER: registered result for job (9, 0, 7) with dispatcher
16:44:39 DISPATCHER: job (9, 0, 7) finished
16:44:39 DISPATCHER: register_result: lock acquired
16:44:39 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
16:44:39 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 90, 'last_n_outputs': 39, 'lr': 0.0046454492100708655, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.11909824024442119}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.35666167312247127, 'info': {'sick_no_sick': 0.35666167312247127, 'config': "{'batch_size': 32, 'hidden_dim': 90, 'last_n_outputs': 39, 'lr': 0.0046454492100708655, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.11909824024442119}"}}
exception: None

16:44:39 job_callback for (9, 0, 7) started
16:44:39 DISPATCHER: Trying to submit another job.
16:44:39 job_callback for (9, 0, 7) got condition
16:44:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:44:39 HBMASTER: Trying to run another job!
16:44:39 job_callback for (9, 0, 7) finished
16:44:39 start sampling a new configuration.
16:44:39 best_vector: [0, 0.9045458158762001, 0.5627221467695962, 0.6120440583645489, 0.08655169837052387, 0, 0.3026550921704756, 0.8901807223247411], 0.001711491921199592, 19.032947365146384, 0.0325747356520651
16:44:39 done sampling a new configuration.
16:44:39 HBMASTER: schedule new run for iteration 9
16:44:39 HBMASTER: trying submitting job (9, 0, 8) to dispatcher
16:44:39 HBMASTER: submitting job (9, 0, 8) to dispatcher
16:44:39 DISPATCHER: trying to submit job (9, 0, 8)
16:44:39 DISPATCHER: trying to notify the job_runner thread.
16:44:39 HBMASTER: job (9, 0, 8) submitted to dispatcher
16:44:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:44:39 DISPATCHER: Trying to submit another job.
16:44:39 DISPATCHER: starting job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:44:39 DISPATCHER: job (9, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:44:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:44:39 WORKER: start processing job (9, 0, 8)
16:44:39 WORKER: args: ()
16:44:39 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 93, 'last_n_outputs': 29, 'lr': 0.01675282750161625, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.14393016435135678}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:45:25 DISPATCHER: Starting worker discovery
16:45:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:45:25 DISPATCHER: Finished worker discovery
Exception in thread Thread-584:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

16:46:25 DISPATCHER: Starting worker discovery
16:46:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:46:25 DISPATCHER: Finished worker discovery
16:47:25 DISPATCHER: Starting worker discovery
16:47:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:47:25 DISPATCHER: Finished worker discovery
16:47:53 WORKER: done with job (9, 0, 8), trying to register it.
16:47:53 WORKER: registered result for job (9, 0, 8) with dispatcher
16:47:53 DISPATCHER: job (9, 0, 8) finished
16:47:53 DISPATCHER: register_result: lock acquired
16:47:53 DISPATCHER: job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
16:47:53 job_id: (9, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 93, 'last_n_outputs': 29, 'lr': 0.01675282750161625, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.14393016435135678}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3364828934489365, 'info': {'sick_no_sick': 0.3364828934489365, 'config': "{'batch_size': 16, 'hidden_dim': 93, 'last_n_outputs': 29, 'lr': 0.01675282750161625, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.14393016435135678}"}}
exception: None

16:47:53 job_callback for (9, 0, 8) started
16:47:53 job_callback for (9, 0, 8) got condition
16:47:53 DISPATCHER: Trying to submit another job.
16:47:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:47:53 HBMASTER: Trying to run another job!
16:47:53 job_callback for (9, 0, 8) finished
16:47:53 ITERATION: Advancing config (9, 0, 0) to next budget 400.000000
16:47:53 ITERATION: Advancing config (9, 0, 1) to next budget 400.000000
16:47:53 ITERATION: Advancing config (9, 0, 3) to next budget 400.000000
16:47:53 HBMASTER: schedule new run for iteration 9
16:47:53 HBMASTER: trying submitting job (9, 0, 0) to dispatcher
16:47:53 HBMASTER: submitting job (9, 0, 0) to dispatcher
16:47:53 DISPATCHER: trying to submit job (9, 0, 0)
16:47:53 DISPATCHER: trying to notify the job_runner thread.
16:47:53 HBMASTER: job (9, 0, 0) submitted to dispatcher
16:47:53 DISPATCHER: Trying to submit another job.
16:47:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:47:53 DISPATCHER: starting job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:47:53 DISPATCHER: job (9, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:47:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:47:53 WORKER: start processing job (9, 0, 0)
16:47:53 WORKER: args: ()
16:47:53 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 86, 'last_n_outputs': 28, 'lr': 0.0011018549468698388, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.0141828317066843}, 'budget': 400.0, 'working_directory': '.'}
16:48:25 DISPATCHER: Starting worker discovery
16:48:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:48:25 DISPATCHER: Finished worker discovery
Exception in thread Thread-585:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

16:49:25 DISPATCHER: Starting worker discovery
16:49:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:49:25 DISPATCHER: Finished worker discovery
16:50:25 DISPATCHER: Starting worker discovery
16:50:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:50:25 DISPATCHER: Finished worker discovery
16:51:25 DISPATCHER: Starting worker discovery
16:51:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:51:25 DISPATCHER: Finished worker discovery
16:52:25 DISPATCHER: Starting worker discovery
16:52:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:52:25 DISPATCHER: Finished worker discovery
16:53:25 DISPATCHER: Starting worker discovery
16:53:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:53:25 DISPATCHER: Finished worker discovery
16:54:25 DISPATCHER: Starting worker discovery
16:54:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:54:25 DISPATCHER: Finished worker discovery
16:55:25 DISPATCHER: Starting worker discovery
16:55:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:55:25 DISPATCHER: Finished worker discovery
16:55:36 WORKER: done with job (9, 0, 0), trying to register it.
16:55:36 WORKER: registered result for job (9, 0, 0) with dispatcher
16:55:36 DISPATCHER: job (9, 0, 0) finished
16:55:36 DISPATCHER: register_result: lock acquired
16:55:36 DISPATCHER: job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
16:55:36 job_id: (9, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 86, 'last_n_outputs': 28, 'lr': 0.0011018549468698388, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.0141828317066843}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.4174835745695343, 'info': {'sick_no_sick': 0.4174835745695343, 'config': "{'batch_size': 16, 'hidden_dim': 86, 'last_n_outputs': 28, 'lr': 0.0011018549468698388, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.0141828317066843}"}}
exception: None

16:55:36 job_callback for (9, 0, 0) started
16:55:36 job_callback for (9, 0, 0) got condition
16:55:36 DISPATCHER: Trying to submit another job.
16:55:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:55:36 done building a new model for budget 400.000000 based on 9/23 split
Best loss for this budget:-0.528437





16:55:36 HBMASTER: Trying to run another job!
16:55:36 job_callback for (9, 0, 0) finished
16:55:36 HBMASTER: schedule new run for iteration 9
16:55:36 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
16:55:36 HBMASTER: submitting job (9, 0, 1) to dispatcher
16:55:36 DISPATCHER: trying to submit job (9, 0, 1)
16:55:36 DISPATCHER: trying to notify the job_runner thread.
16:55:36 HBMASTER: job (9, 0, 1) submitted to dispatcher
16:55:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:55:36 DISPATCHER: Trying to submit another job.
16:55:36 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:55:36 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
16:55:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:55:36 WORKER: start processing job (9, 0, 1)
16:55:36 WORKER: args: ()
16:55:36 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 72, 'last_n_outputs': 48, 'lr': 0.003773476511886275, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.08865934600091857}, 'budget': 400.0, 'working_directory': '.'}
16:56:25 DISPATCHER: Starting worker discovery
16:56:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:56:25 DISPATCHER: Finished worker discovery
Exception in thread Thread-586:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

16:57:25 DISPATCHER: Starting worker discovery
16:57:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:57:25 DISPATCHER: Finished worker discovery
16:58:25 DISPATCHER: Starting worker discovery
16:58:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:58:25 DISPATCHER: Finished worker discovery
16:59:25 DISPATCHER: Starting worker discovery
16:59:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:59:25 DISPATCHER: Finished worker discovery
17:00:25 DISPATCHER: Starting worker discovery
17:00:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:00:25 DISPATCHER: Finished worker discovery
17:01:25 DISPATCHER: Starting worker discovery
17:01:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:01:25 DISPATCHER: Finished worker discovery
17:02:25 DISPATCHER: Starting worker discovery
17:02:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:02:25 DISPATCHER: Finished worker discovery
17:03:19 WORKER: done with job (9, 0, 1), trying to register it.
17:03:19 WORKER: registered result for job (9, 0, 1) with dispatcher
17:03:19 DISPATCHER: job (9, 0, 1) finished
17:03:19 DISPATCHER: register_result: lock acquired
17:03:19 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
17:03:19 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 72, 'last_n_outputs': 48, 'lr': 0.003773476511886275, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.08865934600091857}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.4021878548294906, 'info': {'sick_no_sick': 0.4021878548294906, 'config': "{'batch_size': 64, 'hidden_dim': 72, 'last_n_outputs': 48, 'lr': 0.003773476511886275, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.08865934600091857}"}}
exception: None

17:03:19 job_callback for (9, 0, 1) started
17:03:19 job_callback for (9, 0, 1) got condition
17:03:19 DISPATCHER: Trying to submit another job.
17:03:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:03:19 done building a new model for budget 400.000000 based on 9/24 split
Best loss for this budget:-0.528437





17:03:19 HBMASTER: Trying to run another job!
17:03:19 job_callback for (9, 0, 1) finished
17:03:19 HBMASTER: schedule new run for iteration 9
17:03:19 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
17:03:19 HBMASTER: submitting job (9, 0, 3) to dispatcher
17:03:19 DISPATCHER: trying to submit job (9, 0, 3)
17:03:19 DISPATCHER: trying to notify the job_runner thread.
17:03:19 HBMASTER: job (9, 0, 3) submitted to dispatcher
17:03:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:03:19 DISPATCHER: Trying to submit another job.
17:03:19 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:03:19 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:03:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:03:19 WORKER: start processing job (9, 0, 3)
17:03:19 WORKER: args: ()
17:03:19 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 73, 'last_n_outputs': 30, 'lr': 0.0030607139448158337, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.018966279325798103}, 'budget': 400.0, 'working_directory': '.'}
17:03:25 DISPATCHER: Starting worker discovery
17:03:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:03:25 DISPATCHER: Finished worker discovery
Exception in thread Thread-587:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

17:04:25 DISPATCHER: Starting worker discovery
17:04:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:04:25 DISPATCHER: Finished worker discovery
17:05:25 DISPATCHER: Starting worker discovery
17:05:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:05:25 DISPATCHER: Finished worker discovery
17:06:25 DISPATCHER: Starting worker discovery
17:06:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:06:25 DISPATCHER: Finished worker discovery
17:07:25 DISPATCHER: Starting worker discovery
17:07:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:07:25 DISPATCHER: Finished worker discovery
17:08:25 DISPATCHER: Starting worker discovery
17:08:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:08:25 DISPATCHER: Finished worker discovery
17:09:25 DISPATCHER: Starting worker discovery
17:09:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:09:25 DISPATCHER: Finished worker discovery
17:10:25 DISPATCHER: Starting worker discovery
17:10:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:10:25 DISPATCHER: Finished worker discovery
17:11:01 WORKER: done with job (9, 0, 3), trying to register it.
17:11:01 WORKER: registered result for job (9, 0, 3) with dispatcher
17:11:01 DISPATCHER: job (9, 0, 3) finished
17:11:01 DISPATCHER: register_result: lock acquired
17:11:01 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
17:11:01 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 73, 'last_n_outputs': 30, 'lr': 0.0030607139448158337, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.018966279325798103}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.4363519134773178, 'info': {'sick_no_sick': 0.4363519134773178, 'config': "{'batch_size': 16, 'hidden_dim': 73, 'last_n_outputs': 30, 'lr': 0.0030607139448158337, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.018966279325798103}"}}
exception: None

17:11:01 job_callback for (9, 0, 3) started
17:11:01 DISPATCHER: Trying to submit another job.
17:11:01 job_callback for (9, 0, 3) got condition
17:11:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:11:01 done building a new model for budget 400.000000 based on 9/25 split
Best loss for this budget:-0.528437





17:11:01 HBMASTER: Trying to run another job!
17:11:01 job_callback for (9, 0, 3) finished
17:11:01 ITERATION: Advancing config (9, 0, 3) to next budget 1200.000000
17:11:01 HBMASTER: schedule new run for iteration 9
17:11:01 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
17:11:01 HBMASTER: submitting job (9, 0, 3) to dispatcher
17:11:01 DISPATCHER: trying to submit job (9, 0, 3)
17:11:01 DISPATCHER: trying to notify the job_runner thread.
17:11:01 HBMASTER: job (9, 0, 3) submitted to dispatcher
17:11:01 DISPATCHER: Trying to submit another job.
17:11:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:11:01 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:11:01 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:11:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:11:01 WORKER: start processing job (9, 0, 3)
17:11:01 WORKER: args: ()
17:11:01 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 73, 'last_n_outputs': 30, 'lr': 0.0030607139448158337, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.018966279325798103}, 'budget': 1200.0, 'working_directory': '.'}
17:11:25 DISPATCHER: Starting worker discovery
17:11:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:11:25 DISPATCHER: Finished worker discovery
Exception in thread Thread-588:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

17:12:25 DISPATCHER: Starting worker discovery
17:12:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:12:25 DISPATCHER: Finished worker discovery
17:13:25 DISPATCHER: Starting worker discovery
17:13:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:13:25 DISPATCHER: Finished worker discovery
17:14:25 DISPATCHER: Starting worker discovery
17:14:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:14:25 DISPATCHER: Finished worker discovery
17:15:25 DISPATCHER: Starting worker discovery
17:15:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:15:25 DISPATCHER: Finished worker discovery
17:16:25 DISPATCHER: Starting worker discovery
17:16:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:16:25 DISPATCHER: Finished worker discovery
17:17:25 DISPATCHER: Starting worker discovery
17:17:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:17:25 DISPATCHER: Finished worker discovery
17:18:25 DISPATCHER: Starting worker discovery
17:18:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:18:25 DISPATCHER: Finished worker discovery
17:19:25 DISPATCHER: Starting worker discovery
17:19:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:19:25 DISPATCHER: Finished worker discovery
17:20:25 DISPATCHER: Starting worker discovery
17:20:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:20:25 DISPATCHER: Finished worker discovery
17:21:25 DISPATCHER: Starting worker discovery
17:21:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:21:25 DISPATCHER: Finished worker discovery
17:22:25 DISPATCHER: Starting worker discovery
17:22:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:22:25 DISPATCHER: Finished worker discovery
17:23:25 DISPATCHER: Starting worker discovery
17:23:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:23:25 DISPATCHER: Finished worker discovery
17:24:25 DISPATCHER: Starting worker discovery
17:24:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:24:25 DISPATCHER: Finished worker discovery
17:25:25 DISPATCHER: Starting worker discovery
17:25:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:25:25 DISPATCHER: Finished worker discovery
17:26:25 DISPATCHER: Starting worker discovery
17:26:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:26:25 DISPATCHER: Finished worker discovery
17:27:25 DISPATCHER: Starting worker discovery
17:27:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:27:25 DISPATCHER: Finished worker discovery
17:28:25 DISPATCHER: Starting worker discovery
17:28:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:28:25 DISPATCHER: Finished worker discovery
17:29:25 DISPATCHER: Starting worker discovery
17:29:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:29:25 DISPATCHER: Finished worker discovery
17:30:25 DISPATCHER: Starting worker discovery
17:30:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:30:25 DISPATCHER: Finished worker discovery
17:31:25 DISPATCHER: Starting worker discovery
17:31:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:31:25 DISPATCHER: Finished worker discovery
17:32:04 WORKER: done with job (9, 0, 3), trying to register it.
17:32:04 WORKER: registered result for job (9, 0, 3) with dispatcher
17:32:04 DISPATCHER: job (9, 0, 3) finished
17:32:04 DISPATCHER: register_result: lock acquired
17:32:04 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
17:32:04 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 73, 'last_n_outputs': 30, 'lr': 0.0030607139448158337, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.018966279325798103}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.4324361786656231, 'info': {'sick_no_sick': 0.4324361786656231, 'config': "{'batch_size': 16, 'hidden_dim': 73, 'last_n_outputs': 30, 'lr': 0.0030607139448158337, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.018966279325798103}"}}
exception: None

17:32:04 job_callback for (9, 0, 3) started
17:32:04 job_callback for (9, 0, 3) got condition
17:32:04 DISPATCHER: Trying to submit another job.
17:32:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:32:04 done building a new model for budget 1200.000000 based on 9/15 split
Best loss for this budget:-0.463869





17:32:04 HBMASTER: Trying to run another job!
17:32:04 job_callback for (9, 0, 3) finished
17:32:04 HBMASTER: shutdown initiated, shutdown_workers = True
17:32:04 WORKER: shutting down now!
17:32:04 DISPATCHER: Dispatcher shutting down
17:32:04 DISPATCHER: discover_workers shutting down
17:32:04 DISPATCHER: Trying to submit another job.
17:32:04 DISPATCHER: 'discover_worker' thread exited
17:32:04 DISPATCHER: job_runner shutting down
17:32:04 DISPATCHER: 'job_runner' thread exited
17:32:04 DISPATCHER: shut down complete
17:32:04 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7fb47c099748; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:30482>
17:32:04 WORKER: No dispatcher found. Waiting for one to initiate contact.
17:32:04 WORKER: start listening for jobs
17:32:04 wait_for_workers trying to get the condition
17:32:04 DISPATCHER: started the 'discover_worker' thread
17:32:04 DISPATCHER: started the 'job_runner' thread
17:32:04 DISPATCHER: Pyro daemon running on localhost:37701
17:32:04 HBMASTER: only 0 worker(s) available, waiting for at least 1.
17:32:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:32:04 DISPATCHER: Starting worker discovery
17:32:04 DISPATCHER: Found 1 potential workers, 0 currently in the pool.
17:32:04 DISPATCHER: discovered new worker, hpbandster.run_0.worker.metagpuj.30598140416580691776
17:32:04 HBMASTER: number of workers changed to 1
17:32:04 adjust_queue_size: lock accquired
17:32:04 HBMASTER: adjusted queue size to (0, 1)
17:32:04 DISPATCHER: Finished worker discovery
17:32:04 DISPATCHER: A new worker triggered discover_worker
17:32:04 DISPATCHER: Trying to submit another job.
17:32:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:32:04 Enough workers to start this run!
17:32:04 HBMASTER: starting run at 1583944324.9385679
17:32:04 start sampling a new configuration.
17:32:04 done sampling a new configuration.
17:32:04 DISPATCHER: Starting worker discovery
17:32:04 HBMASTER: schedule new run for iteration 0
17:32:04 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
17:32:04 HBMASTER: submitting job (0, 0, 0) to dispatcher
17:32:04 DISPATCHER: trying to submit job (0, 0, 0)
17:32:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:32:04 DISPATCHER: Finished worker discovery
17:32:04 DISPATCHER: trying to notify the job_runner thread.
17:32:04 HBMASTER: job (0, 0, 0) submitted to dispatcher
17:32:04 DISPATCHER: Trying to submit another job.
17:32:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:32:04 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:32:04 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:32:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:32:04 WORKER: start processing job (0, 0, 0)
17:32:04 WORKER: args: ()
17:32:04 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.06075351783534571, 'num_filters_1': 59, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.02160305132332481, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 17, 'num_filters_3': 106, 'num_filters_4': 88, 'num_filters_5': 44}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:33:04 DISPATCHER: Starting worker discovery
17:33:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:33:04 DISPATCHER: Finished worker discovery
Exception in thread Thread-602:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

17:33:53 WORKER: done with job (0, 0, 0), trying to register it.
17:33:53 WORKER: registered result for job (0, 0, 0) with dispatcher
17:33:53 DISPATCHER: job (0, 0, 0) finished
17:33:53 DISPATCHER: register_result: lock acquired
17:33:53 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
17:33:53 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.06075351783534571, 'num_filters_1': 59, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.02160305132332481, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 17, 'num_filters_3': 106, 'num_filters_4': 88, 'num_filters_5': 44}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.014054876093627279, 'info': {'sick_no_sick': -0.014054876093627279, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.06075351783534571, 'num_filters_1': 59, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.02160305132332481, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 17, 'num_filters_3': 106, 'num_filters_4': 88, 'num_filters_5': 44}"}}
exception: None

17:33:53 job_callback for (0, 0, 0) started
17:33:53 DISPATCHER: Trying to submit another job.
17:33:53 job_callback for (0, 0, 0) got condition
17:33:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:33:53 Only 1 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
17:33:53 HBMASTER: Trying to run another job!
17:33:53 job_callback for (0, 0, 0) finished
17:33:53 start sampling a new configuration.
17:33:53 done sampling a new configuration.
17:33:53 HBMASTER: schedule new run for iteration 0
17:33:53 HBMASTER: trying submitting job (0, 0, 1) to dispatcher
17:33:53 HBMASTER: submitting job (0, 0, 1) to dispatcher
17:33:53 DISPATCHER: trying to submit job (0, 0, 1)
17:33:53 DISPATCHER: trying to notify the job_runner thread.
17:33:53 HBMASTER: job (0, 0, 1) submitted to dispatcher
17:33:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:33:53 DISPATCHER: Trying to submit another job.
17:33:53 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:33:53 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:33:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:33:53 WORKER: start processing job (0, 0, 1)
17:33:53 WORKER: args: ()
17:33:53 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.008398227439932408, 'num_filters_1': 32, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.042740311062951834, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 35, 'num_filters_3': 68}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:34:04 DISPATCHER: Starting worker discovery
17:34:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:34:04 DISPATCHER: Finished worker discovery
17:35:04 DISPATCHER: Starting worker discovery
17:35:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:35:04 DISPATCHER: Finished worker discovery
17:35:41 WORKER: done with job (0, 0, 1), trying to register it.
17:35:41 WORKER: registered result for job (0, 0, 1) with dispatcher
17:35:41 DISPATCHER: job (0, 0, 1) finished
17:35:41 DISPATCHER: register_result: lock acquired
17:35:41 DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
17:35:41 job_id: (0, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.008398227439932408, 'num_filters_1': 32, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.042740311062951834, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 35, 'num_filters_3': 68}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3988276706955752, 'info': {'sick_no_sick': 0.3988276706955752, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.008398227439932408, 'num_filters_1': 32, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.042740311062951834, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 35, 'num_filters_3': 68}"}}
exception: None

17:35:41 job_callback for (0, 0, 1) started
17:35:41 DISPATCHER: Trying to submit another job.
17:35:41 job_callback for (0, 0, 1) got condition
17:35:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:35:41 Only 2 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
17:35:41 HBMASTER: Trying to run another job!
17:35:41 job_callback for (0, 0, 1) finished
17:35:41 start sampling a new configuration.
17:35:41 done sampling a new configuration.
17:35:41 HBMASTER: schedule new run for iteration 0
17:35:41 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
17:35:41 HBMASTER: submitting job (0, 0, 2) to dispatcher
17:35:41 DISPATCHER: trying to submit job (0, 0, 2)
17:35:41 DISPATCHER: trying to notify the job_runner thread.
17:35:41 HBMASTER: job (0, 0, 2) submitted to dispatcher
17:35:41 DISPATCHER: Trying to submit another job.
17:35:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:35:41 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:35:41 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:35:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:35:41 WORKER: start processing job (0, 0, 2)
17:35:41 WORKER: args: ()
17:35:41 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0019002255148213424, 'num_filters_1': 109, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.011380435879682948, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 25, 'num_filters_3': 24}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:36:04 DISPATCHER: Starting worker discovery
17:36:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:36:04 DISPATCHER: Finished worker discovery
17:37:04 DISPATCHER: Starting worker discovery
17:37:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:37:04 DISPATCHER: Finished worker discovery
17:37:32 WORKER: done with job (0, 0, 2), trying to register it.
17:37:32 WORKER: registered result for job (0, 0, 2) with dispatcher
17:37:32 DISPATCHER: job (0, 0, 2) finished
17:37:32 DISPATCHER: register_result: lock acquired
17:37:32 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
17:37:32 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0019002255148213424, 'num_filters_1': 109, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.011380435879682948, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 25, 'num_filters_3': 24}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4918438630849866, 'info': {'sick_no_sick': 0.4918438630849866, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0019002255148213424, 'num_filters_1': 109, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.011380435879682948, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 25, 'num_filters_3': 24}"}}
exception: None

17:37:32 job_callback for (0, 0, 2) started
17:37:32 DISPATCHER: Trying to submit another job.
17:37:32 job_callback for (0, 0, 2) got condition
17:37:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:37:32 Only 3 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
17:37:32 HBMASTER: Trying to run another job!
17:37:32 job_callback for (0, 0, 2) finished
17:37:32 start sampling a new configuration.
17:37:32 done sampling a new configuration.
17:37:32 HBMASTER: schedule new run for iteration 0
17:37:32 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
17:37:32 HBMASTER: submitting job (0, 0, 3) to dispatcher
17:37:32 DISPATCHER: trying to submit job (0, 0, 3)
17:37:32 DISPATCHER: trying to notify the job_runner thread.
17:37:32 HBMASTER: job (0, 0, 3) submitted to dispatcher
17:37:32 DISPATCHER: Trying to submit another job.
17:37:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:37:32 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:37:32 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:37:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:37:32 WORKER: start processing job (0, 0, 3)
17:37:32 WORKER: args: ()
17:37:32 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.003044148819746077, 'num_filters_1': 60, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.05919131217276223, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 71, 'num_filters_3': 118, 'num_filters_4': 107, 'num_filters_5': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:38:04 DISPATCHER: Starting worker discovery
17:38:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:38:04 DISPATCHER: Finished worker discovery
17:39:04 DISPATCHER: Starting worker discovery
17:39:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:39:04 DISPATCHER: Finished worker discovery
17:39:23 WORKER: done with job (0, 0, 3), trying to register it.
17:39:23 WORKER: registered result for job (0, 0, 3) with dispatcher
17:39:23 DISPATCHER: job (0, 0, 3) finished
17:39:23 DISPATCHER: register_result: lock acquired
17:39:23 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
17:39:23 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.003044148819746077, 'num_filters_1': 60, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.05919131217276223, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 71, 'num_filters_3': 118, 'num_filters_4': 107, 'num_filters_5': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.003044148819746077, 'num_filters_1': 60, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.05919131217276223, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 71, 'num_filters_3': 118, 'num_filters_4': 107, 'num_filters_5': 16}"}}
exception: None

17:39:23 job_callback for (0, 0, 3) started
17:39:23 DISPATCHER: Trying to submit another job.
17:39:23 job_callback for (0, 0, 3) got condition
17:39:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:39:23 Only 4 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
17:39:23 HBMASTER: Trying to run another job!
17:39:23 job_callback for (0, 0, 3) finished
17:39:23 start sampling a new configuration.
17:39:23 done sampling a new configuration.
17:39:23 HBMASTER: schedule new run for iteration 0
17:39:23 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
17:39:23 HBMASTER: submitting job (0, 0, 4) to dispatcher
17:39:23 DISPATCHER: trying to submit job (0, 0, 4)
17:39:23 DISPATCHER: trying to notify the job_runner thread.
17:39:23 HBMASTER: job (0, 0, 4) submitted to dispatcher
17:39:23 DISPATCHER: Trying to submit another job.
17:39:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:39:23 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:39:23 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:39:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:39:23 WORKER: start processing job (0, 0, 4)
17:39:23 WORKER: args: ()
17:39:23 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0616008169646752, 'num_filters_1': 38, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.15279387251132603, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 76, 'num_filters_3': 40}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:40:04 DISPATCHER: Starting worker discovery
17:40:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:40:04 DISPATCHER: Finished worker discovery
17:41:04 DISPATCHER: Starting worker discovery
17:41:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:41:05 DISPATCHER: Finished worker discovery
17:41:12 WORKER: done with job (0, 0, 4), trying to register it.
17:41:12 WORKER: registered result for job (0, 0, 4) with dispatcher
17:41:12 DISPATCHER: job (0, 0, 4) finished
17:41:12 DISPATCHER: register_result: lock acquired
17:41:12 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
17:41:12 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0616008169646752, 'num_filters_1': 38, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.15279387251132603, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 76, 'num_filters_3': 40}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0028223198417011907, 'info': {'sick_no_sick': 0.0028223198417011907, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0616008169646752, 'num_filters_1': 38, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.15279387251132603, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 76, 'num_filters_3': 40}"}}
exception: None

17:41:12 job_callback for (0, 0, 4) started
17:41:12 DISPATCHER: Trying to submit another job.
17:41:12 job_callback for (0, 0, 4) got condition
17:41:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:41:12 Only 5 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
17:41:12 HBMASTER: Trying to run another job!
17:41:12 job_callback for (0, 0, 4) finished
17:41:12 start sampling a new configuration.
17:41:12 done sampling a new configuration.
17:41:12 HBMASTER: schedule new run for iteration 0
17:41:12 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
17:41:12 HBMASTER: submitting job (0, 0, 5) to dispatcher
17:41:12 DISPATCHER: trying to submit job (0, 0, 5)
17:41:12 DISPATCHER: trying to notify the job_runner thread.
17:41:12 HBMASTER: job (0, 0, 5) submitted to dispatcher
17:41:12 DISPATCHER: Trying to submit another job.
17:41:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:41:12 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:41:12 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:41:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:41:12 WORKER: start processing job (0, 0, 5)
17:41:12 WORKER: args: ()
17:41:12 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.013315917792472102, 'num_filters_1': 48, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.13802778020808995, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 85, 'num_filters_3': 36}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:42:05 DISPATCHER: Starting worker discovery
17:42:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:42:05 DISPATCHER: Finished worker discovery
17:42:59 WORKER: done with job (0, 0, 5), trying to register it.
17:42:59 WORKER: registered result for job (0, 0, 5) with dispatcher
17:42:59 DISPATCHER: job (0, 0, 5) finished
17:42:59 DISPATCHER: register_result: lock acquired
17:42:59 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
17:42:59 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.013315917792472102, 'num_filters_1': 48, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.13802778020808995, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 85, 'num_filters_3': 36}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.013315917792472102, 'num_filters_1': 48, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.13802778020808995, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 85, 'num_filters_3': 36}"}}
exception: None

17:42:59 job_callback for (0, 0, 5) started
17:42:59 job_callback for (0, 0, 5) got condition
17:42:59 DISPATCHER: Trying to submit another job.
17:42:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:42:59 Only 6 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
17:42:59 HBMASTER: Trying to run another job!
17:42:59 job_callback for (0, 0, 5) finished
17:42:59 start sampling a new configuration.
17:42:59 done sampling a new configuration.
17:42:59 HBMASTER: schedule new run for iteration 0
17:42:59 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
17:42:59 HBMASTER: submitting job (0, 0, 6) to dispatcher
17:42:59 DISPATCHER: trying to submit job (0, 0, 6)
17:42:59 DISPATCHER: trying to notify the job_runner thread.
17:42:59 HBMASTER: job (0, 0, 6) submitted to dispatcher
17:42:59 DISPATCHER: Trying to submit another job.
17:42:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:42:59 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:42:59 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:42:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:42:59 WORKER: start processing job (0, 0, 6)
17:42:59 WORKER: args: ()
17:42:59 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.006275742740936441, 'num_filters_1': 25, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.02615892919833975, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 46, 'num_filters_3': 85, 'num_filters_4': 40, 'num_filters_5': 101}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:43:05 DISPATCHER: Starting worker discovery
17:43:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:43:05 DISPATCHER: Finished worker discovery
17:44:05 DISPATCHER: Starting worker discovery
17:44:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:44:05 DISPATCHER: Finished worker discovery
17:44:48 WORKER: done with job (0, 0, 6), trying to register it.
17:44:48 WORKER: registered result for job (0, 0, 6) with dispatcher
17:44:48 DISPATCHER: job (0, 0, 6) finished
17:44:48 DISPATCHER: register_result: lock acquired
17:44:48 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
17:44:48 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.006275742740936441, 'num_filters_1': 25, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.02615892919833975, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 46, 'num_filters_3': 85, 'num_filters_4': 40, 'num_filters_5': 101}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.006275742740936441, 'num_filters_1': 25, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.02615892919833975, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 46, 'num_filters_3': 85, 'num_filters_4': 40, 'num_filters_5': 101}"}}
exception: None

17:44:48 job_callback for (0, 0, 6) started
17:44:48 job_callback for (0, 0, 6) got condition
17:44:48 DISPATCHER: Trying to submit another job.
17:44:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:44:48 Only 7 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
17:44:48 HBMASTER: Trying to run another job!
17:44:48 job_callback for (0, 0, 6) finished
17:44:48 start sampling a new configuration.
17:44:48 done sampling a new configuration.
17:44:48 HBMASTER: schedule new run for iteration 0
17:44:48 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
17:44:48 HBMASTER: submitting job (0, 0, 7) to dispatcher
17:44:48 DISPATCHER: trying to submit job (0, 0, 7)
17:44:48 DISPATCHER: trying to notify the job_runner thread.
17:44:48 HBMASTER: job (0, 0, 7) submitted to dispatcher
17:44:48 DISPATCHER: Trying to submit another job.
17:44:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:44:48 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:44:48 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:44:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:44:48 WORKER: start processing job (0, 0, 7)
17:44:48 WORKER: args: ()
17:44:48 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0058745517412776135, 'num_filters_1': 32, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.01970352841938794, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 30, 'num_filters_3': 33}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:45:05 DISPATCHER: Starting worker discovery
17:45:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:45:05 DISPATCHER: Finished worker discovery
17:46:05 DISPATCHER: Starting worker discovery
17:46:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:46:05 DISPATCHER: Finished worker discovery
17:46:36 WORKER: done with job (0, 0, 7), trying to register it.
17:46:36 WORKER: registered result for job (0, 0, 7) with dispatcher
17:46:36 DISPATCHER: job (0, 0, 7) finished
17:46:36 DISPATCHER: register_result: lock acquired
17:46:36 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
17:46:36 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0058745517412776135, 'num_filters_1': 32, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.01970352841938794, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 30, 'num_filters_3': 33}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5352005437247106, 'info': {'sick_no_sick': 0.5352005437247106, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0058745517412776135, 'num_filters_1': 32, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.01970352841938794, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 30, 'num_filters_3': 33}"}}
exception: None

17:46:36 job_callback for (0, 0, 7) started
17:46:36 DISPATCHER: Trying to submit another job.
17:46:36 job_callback for (0, 0, 7) got condition
17:46:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:46:36 Only 8 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
17:46:36 HBMASTER: Trying to run another job!
17:46:36 job_callback for (0, 0, 7) finished
17:46:36 start sampling a new configuration.
17:46:36 done sampling a new configuration.
17:46:36 HBMASTER: schedule new run for iteration 0
17:46:36 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
17:46:36 HBMASTER: submitting job (0, 0, 8) to dispatcher
17:46:36 DISPATCHER: trying to submit job (0, 0, 8)
17:46:36 DISPATCHER: trying to notify the job_runner thread.
17:46:36 HBMASTER: job (0, 0, 8) submitted to dispatcher
17:46:36 DISPATCHER: Trying to submit another job.
17:46:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:46:36 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:46:36 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:46:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:46:36 WORKER: start processing job (0, 0, 8)
17:46:36 WORKER: args: ()
17:46:36 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001607311099321854, 'num_filters_1': 22, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.06055884364364364, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 18, 'num_filters_3': 120}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:47:05 DISPATCHER: Starting worker discovery
17:47:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:47:05 DISPATCHER: Finished worker discovery
17:48:05 DISPATCHER: Starting worker discovery
17:48:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:48:05 DISPATCHER: Finished worker discovery
17:48:24 WORKER: done with job (0, 0, 8), trying to register it.
17:48:24 WORKER: registered result for job (0, 0, 8) with dispatcher
17:48:24 DISPATCHER: job (0, 0, 8) finished
17:48:24 DISPATCHER: register_result: lock acquired
17:48:24 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
17:48:24 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001607311099321854, 'num_filters_1': 22, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.06055884364364364, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 18, 'num_filters_3': 120}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.44798399438397957, 'info': {'sick_no_sick': 0.44798399438397957, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001607311099321854, 'num_filters_1': 22, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.06055884364364364, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 18, 'num_filters_3': 120}"}}
exception: None

17:48:24 job_callback for (0, 0, 8) started
17:48:24 DISPATCHER: Trying to submit another job.
17:48:24 job_callback for (0, 0, 8) got condition
17:48:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:48:24 Only 9 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
17:48:24 HBMASTER: Trying to run another job!
17:48:24 job_callback for (0, 0, 8) finished
17:48:24 start sampling a new configuration.
17:48:24 done sampling a new configuration.
17:48:24 HBMASTER: schedule new run for iteration 0
17:48:24 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
17:48:24 HBMASTER: submitting job (0, 0, 9) to dispatcher
17:48:24 DISPATCHER: trying to submit job (0, 0, 9)
17:48:24 DISPATCHER: trying to notify the job_runner thread.
17:48:24 HBMASTER: job (0, 0, 9) submitted to dispatcher
17:48:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:48:24 DISPATCHER: Trying to submit another job.
17:48:24 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:48:24 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:48:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:48:24 WORKER: start processing job (0, 0, 9)
17:48:24 WORKER: args: ()
17:48:24 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.037708620137109454, 'num_filters_1': 16, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.01856523696043172, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 46, 'num_filters_3': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:49:05 DISPATCHER: Starting worker discovery
17:49:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:49:05 DISPATCHER: Finished worker discovery
17:50:05 DISPATCHER: Starting worker discovery
17:50:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:50:05 DISPATCHER: Finished worker discovery
17:50:12 WORKER: done with job (0, 0, 9), trying to register it.
17:50:12 WORKER: registered result for job (0, 0, 9) with dispatcher
17:50:12 DISPATCHER: job (0, 0, 9) finished
17:50:12 DISPATCHER: register_result: lock acquired
17:50:12 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
17:50:12 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.037708620137109454, 'num_filters_1': 16, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.01856523696043172, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 46, 'num_filters_3': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5590725049527496, 'info': {'sick_no_sick': 0.5590725049527496, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.037708620137109454, 'num_filters_1': 16, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.01856523696043172, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 46, 'num_filters_3': 16}"}}
exception: None

17:50:12 job_callback for (0, 0, 9) started
17:50:12 DISPATCHER: Trying to submit another job.
17:50:12 job_callback for (0, 0, 9) got condition
17:50:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:50:12 Only 10 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
17:50:12 HBMASTER: Trying to run another job!
17:50:12 job_callback for (0, 0, 9) finished
17:50:12 start sampling a new configuration.
17:50:12 done sampling a new configuration.
17:50:12 HBMASTER: schedule new run for iteration 0
17:50:12 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
17:50:12 HBMASTER: submitting job (0, 0, 10) to dispatcher
17:50:12 DISPATCHER: trying to submit job (0, 0, 10)
17:50:12 DISPATCHER: trying to notify the job_runner thread.
17:50:12 HBMASTER: job (0, 0, 10) submitted to dispatcher
17:50:12 DISPATCHER: Trying to submit another job.
17:50:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:50:12 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:50:12 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:50:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:50:12 WORKER: start processing job (0, 0, 10)
17:50:12 WORKER: args: ()
17:50:12 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0022890799024759285, 'num_filters_1': 72, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.01933789386636864}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:51:05 DISPATCHER: Starting worker discovery
17:51:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:51:05 DISPATCHER: Finished worker discovery
17:52:00 WORKER: done with job (0, 0, 10), trying to register it.
17:52:00 WORKER: registered result for job (0, 0, 10) with dispatcher
17:52:00 DISPATCHER: job (0, 0, 10) finished
17:52:00 DISPATCHER: register_result: lock acquired
17:52:00 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
17:52:00 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0022890799024759285, 'num_filters_1': 72, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.01933789386636864}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.42660221624707123, 'info': {'sick_no_sick': 0.42660221624707123, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0022890799024759285, 'num_filters_1': 72, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.01933789386636864}"}}
exception: None

17:52:00 job_callback for (0, 0, 10) started
17:52:00 job_callback for (0, 0, 10) got condition
17:52:00 DISPATCHER: Trying to submit another job.
17:52:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:52:00 Only 11 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
17:52:00 HBMASTER: Trying to run another job!
17:52:00 job_callback for (0, 0, 10) finished
17:52:00 start sampling a new configuration.
17:52:00 done sampling a new configuration.
17:52:00 HBMASTER: schedule new run for iteration 0
17:52:00 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
17:52:00 HBMASTER: submitting job (0, 0, 11) to dispatcher
17:52:00 DISPATCHER: trying to submit job (0, 0, 11)
17:52:00 DISPATCHER: trying to notify the job_runner thread.
17:52:00 HBMASTER: job (0, 0, 11) submitted to dispatcher
17:52:00 DISPATCHER: Trying to submit another job.
17:52:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:52:00 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:52:00 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:52:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:52:00 WORKER: start processing job (0, 0, 11)
17:52:00 WORKER: args: ()
17:52:00 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.007765103313545947, 'num_filters_1': 30, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.010321936146450874, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 23, 'num_filters_3': 46, 'num_filters_4': 45}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:52:05 DISPATCHER: Starting worker discovery
17:52:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:52:05 DISPATCHER: Finished worker discovery
17:53:05 DISPATCHER: Starting worker discovery
17:53:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:53:05 DISPATCHER: Finished worker discovery
17:53:49 WORKER: done with job (0, 0, 11), trying to register it.
17:53:49 WORKER: registered result for job (0, 0, 11) with dispatcher
17:53:49 DISPATCHER: job (0, 0, 11) finished
17:53:49 DISPATCHER: register_result: lock acquired
17:53:49 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
17:53:49 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.007765103313545947, 'num_filters_1': 30, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.010321936146450874, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 23, 'num_filters_3': 46, 'num_filters_4': 45}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.525968277481839, 'info': {'sick_no_sick': 0.525968277481839, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.007765103313545947, 'num_filters_1': 30, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.010321936146450874, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 23, 'num_filters_3': 46, 'num_filters_4': 45}"}}
exception: None

17:53:49 job_callback for (0, 0, 11) started
17:53:49 job_callback for (0, 0, 11) got condition
17:53:49 DISPATCHER: Trying to submit another job.
17:53:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:53:49 Only 12 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
17:53:49 HBMASTER: Trying to run another job!
17:53:49 job_callback for (0, 0, 11) finished
17:53:49 start sampling a new configuration.
17:53:49 done sampling a new configuration.
17:53:49 HBMASTER: schedule new run for iteration 0
17:53:49 HBMASTER: trying submitting job (0, 0, 12) to dispatcher
17:53:49 HBMASTER: submitting job (0, 0, 12) to dispatcher
17:53:49 DISPATCHER: trying to submit job (0, 0, 12)
17:53:49 DISPATCHER: trying to notify the job_runner thread.
17:53:49 HBMASTER: job (0, 0, 12) submitted to dispatcher
17:53:49 DISPATCHER: Trying to submit another job.
17:53:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:53:49 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:53:49 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:53:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:53:49 WORKER: start processing job (0, 0, 12)
17:53:49 WORKER: args: ()
17:53:49 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.02019044210334421, 'num_filters_1': 41, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.11405427748756015, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 24, 'num_filters_3': 66, 'num_filters_4': 69, 'num_filters_5': 28}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:54:05 DISPATCHER: Starting worker discovery
17:54:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:54:05 DISPATCHER: Finished worker discovery
17:55:05 DISPATCHER: Starting worker discovery
17:55:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:55:05 DISPATCHER: Finished worker discovery
17:55:35 WORKER: done with job (0, 0, 12), trying to register it.
17:55:35 WORKER: registered result for job (0, 0, 12) with dispatcher
17:55:35 DISPATCHER: job (0, 0, 12) finished
17:55:35 DISPATCHER: register_result: lock acquired
17:55:35 DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
17:55:35 job_id: (0, 0, 12)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.02019044210334421, 'num_filters_1': 41, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.11405427748756015, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 24, 'num_filters_3': 66, 'num_filters_4': 69, 'num_filters_5': 28}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.02019044210334421, 'num_filters_1': 41, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.11405427748756015, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 24, 'num_filters_3': 66, 'num_filters_4': 69, 'num_filters_5': 28}"}}
exception: None

17:55:35 job_callback for (0, 0, 12) started
17:55:35 DISPATCHER: Trying to submit another job.
17:55:35 job_callback for (0, 0, 12) got condition
17:55:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:55:35 Only 13 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
17:55:35 HBMASTER: Trying to run another job!
17:55:35 job_callback for (0, 0, 12) finished
17:55:35 start sampling a new configuration.
17:55:35 done sampling a new configuration.
17:55:35 HBMASTER: schedule new run for iteration 0
17:55:35 HBMASTER: trying submitting job (0, 0, 13) to dispatcher
17:55:35 HBMASTER: submitting job (0, 0, 13) to dispatcher
17:55:35 DISPATCHER: trying to submit job (0, 0, 13)
17:55:35 DISPATCHER: trying to notify the job_runner thread.
17:55:35 HBMASTER: job (0, 0, 13) submitted to dispatcher
17:55:35 DISPATCHER: Trying to submit another job.
17:55:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:55:35 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:55:35 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:55:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:55:35 WORKER: start processing job (0, 0, 13)
17:55:35 WORKER: args: ()
17:55:35 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0609045500037502, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.0675972292737178, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 83, 'num_filters_3': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:56:05 DISPATCHER: Starting worker discovery
17:56:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:56:05 DISPATCHER: Finished worker discovery
17:57:05 DISPATCHER: Starting worker discovery
17:57:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:57:05 DISPATCHER: Finished worker discovery
17:57:22 WORKER: done with job (0, 0, 13), trying to register it.
17:57:22 WORKER: registered result for job (0, 0, 13) with dispatcher
17:57:22 DISPATCHER: job (0, 0, 13) finished
17:57:22 DISPATCHER: register_result: lock acquired
17:57:22 DISPATCHER: job (0, 0, 13) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
17:57:22 job_id: (0, 0, 13)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0609045500037502, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.0675972292737178, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 83, 'num_filters_3': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0070021233424673104, 'info': {'sick_no_sick': 0.0070021233424673104, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0609045500037502, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.0675972292737178, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 83, 'num_filters_3': 16}"}}
exception: None

17:57:22 job_callback for (0, 0, 13) started
17:57:22 job_callback for (0, 0, 13) got condition
17:57:22 DISPATCHER: Trying to submit another job.
17:57:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:57:22 Only 14 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
17:57:22 HBMASTER: Trying to run another job!
17:57:22 job_callback for (0, 0, 13) finished
17:57:22 start sampling a new configuration.
17:57:22 done sampling a new configuration.
17:57:22 HBMASTER: schedule new run for iteration 0
17:57:22 HBMASTER: trying submitting job (0, 0, 14) to dispatcher
17:57:22 HBMASTER: submitting job (0, 0, 14) to dispatcher
17:57:22 DISPATCHER: trying to submit job (0, 0, 14)
17:57:22 DISPATCHER: trying to notify the job_runner thread.
17:57:22 HBMASTER: job (0, 0, 14) submitted to dispatcher
17:57:22 DISPATCHER: Trying to submit another job.
17:57:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:57:22 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:57:22 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:57:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:57:22 WORKER: start processing job (0, 0, 14)
17:57:22 WORKER: args: ()
17:57:22 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.007008866304912582, 'num_filters_1': 111, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.011551256323413809, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 43, 'num_filters_3': 42, 'num_filters_4': 53}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:58:05 DISPATCHER: Starting worker discovery
17:58:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:58:05 DISPATCHER: Finished worker discovery
17:59:05 DISPATCHER: Starting worker discovery
17:59:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:59:05 DISPATCHER: Finished worker discovery
17:59:09 WORKER: done with job (0, 0, 14), trying to register it.
17:59:09 WORKER: registered result for job (0, 0, 14) with dispatcher
17:59:09 DISPATCHER: job (0, 0, 14) finished
17:59:09 DISPATCHER: register_result: lock acquired
17:59:09 DISPATCHER: job (0, 0, 14) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
17:59:09 job_id: (0, 0, 14)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.007008866304912582, 'num_filters_1': 111, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.011551256323413809, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 43, 'num_filters_3': 42, 'num_filters_4': 53}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5373898378358838, 'info': {'sick_no_sick': 0.5373898378358838, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.007008866304912582, 'num_filters_1': 111, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.011551256323413809, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 43, 'num_filters_3': 42, 'num_filters_4': 53}"}}
exception: None

17:59:09 job_callback for (0, 0, 14) started
17:59:09 DISPATCHER: Trying to submit another job.
17:59:09 job_callback for (0, 0, 14) got condition
17:59:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:59:09 Only 15 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
17:59:09 HBMASTER: Trying to run another job!
17:59:09 job_callback for (0, 0, 14) finished
17:59:09 start sampling a new configuration.
17:59:09 done sampling a new configuration.
17:59:09 HBMASTER: schedule new run for iteration 0
17:59:09 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
17:59:09 HBMASTER: submitting job (0, 0, 15) to dispatcher
17:59:09 DISPATCHER: trying to submit job (0, 0, 15)
17:59:09 DISPATCHER: trying to notify the job_runner thread.
17:59:09 HBMASTER: job (0, 0, 15) submitted to dispatcher
17:59:09 DISPATCHER: Trying to submit another job.
17:59:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:59:09 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:59:09 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
17:59:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:59:09 WORKER: start processing job (0, 0, 15)
17:59:09 WORKER: args: ()
17:59:09 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.012652394176480692, 'num_filters_1': 34, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.16187878501678868, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 33, 'num_filters_3': 17, 'num_filters_4': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:00:05 DISPATCHER: Starting worker discovery
18:00:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:00:05 DISPATCHER: Finished worker discovery
18:00:57 WORKER: done with job (0, 0, 15), trying to register it.
18:00:57 WORKER: registered result for job (0, 0, 15) with dispatcher
18:00:57 DISPATCHER: job (0, 0, 15) finished
18:00:57 DISPATCHER: register_result: lock acquired
18:00:57 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
18:00:57 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.012652394176480692, 'num_filters_1': 34, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.16187878501678868, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 33, 'num_filters_3': 17, 'num_filters_4': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.012652394176480692, 'num_filters_1': 34, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.16187878501678868, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 33, 'num_filters_3': 17, 'num_filters_4': 19}"}}
exception: None

18:00:57 job_callback for (0, 0, 15) started
18:00:57 DISPATCHER: Trying to submit another job.
18:00:57 job_callback for (0, 0, 15) got condition
18:00:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:00:57 Only 16 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
18:00:57 HBMASTER: Trying to run another job!
18:00:57 job_callback for (0, 0, 15) finished
18:00:57 start sampling a new configuration.
18:00:57 done sampling a new configuration.
18:00:57 HBMASTER: schedule new run for iteration 0
18:00:57 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
18:00:57 HBMASTER: submitting job (0, 0, 16) to dispatcher
18:00:57 DISPATCHER: trying to submit job (0, 0, 16)
18:00:57 DISPATCHER: trying to notify the job_runner thread.
18:00:57 HBMASTER: job (0, 0, 16) submitted to dispatcher
18:00:57 DISPATCHER: Trying to submit another job.
18:00:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:00:57 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:00:57 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:00:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:00:57 WORKER: start processing job (0, 0, 16)
18:00:57 WORKER: args: ()
18:00:57 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.06145667065604968, 'num_filters_1': 77, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.026518270398072717, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 27, 'num_filters_3': 62, 'num_filters_4': 34}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:01:05 DISPATCHER: Starting worker discovery
18:01:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:01:05 DISPATCHER: Finished worker discovery
18:02:05 DISPATCHER: Starting worker discovery
18:02:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:02:05 DISPATCHER: Finished worker discovery
18:02:44 WORKER: done with job (0, 0, 16), trying to register it.
18:02:44 WORKER: registered result for job (0, 0, 16) with dispatcher
18:02:44 DISPATCHER: job (0, 0, 16) finished
18:02:44 DISPATCHER: register_result: lock acquired
18:02:44 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
18:02:44 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.06145667065604968, 'num_filters_1': 77, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.026518270398072717, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 27, 'num_filters_3': 62, 'num_filters_4': 34}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.09025062345262011, 'info': {'sick_no_sick': 0.09025062345262011, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.06145667065604968, 'num_filters_1': 77, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.026518270398072717, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 27, 'num_filters_3': 62, 'num_filters_4': 34}"}}
exception: None

18:02:44 job_callback for (0, 0, 16) started
18:02:44 job_callback for (0, 0, 16) got condition
18:02:44 DISPATCHER: Trying to submit another job.
18:02:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:02:44 HBMASTER: Trying to run another job!
18:02:44 job_callback for (0, 0, 16) finished
18:02:44 start sampling a new configuration.
18:02:44 done sampling a new configuration.
18:02:44 HBMASTER: schedule new run for iteration 0
18:02:44 HBMASTER: trying submitting job (0, 0, 17) to dispatcher
18:02:44 HBMASTER: submitting job (0, 0, 17) to dispatcher
18:02:44 DISPATCHER: trying to submit job (0, 0, 17)
18:02:44 DISPATCHER: trying to notify the job_runner thread.
18:02:44 HBMASTER: job (0, 0, 17) submitted to dispatcher
18:02:44 DISPATCHER: Trying to submit another job.
18:02:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:02:44 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:02:44 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:02:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:02:44 WORKER: start processing job (0, 0, 17)
18:02:44 WORKER: args: ()
18:02:44 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0010603876905106253, 'num_filters_1': 53, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.0674182119746825}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:03:05 DISPATCHER: Starting worker discovery
18:03:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:03:05 DISPATCHER: Finished worker discovery
18:04:05 DISPATCHER: Starting worker discovery
18:04:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:04:05 DISPATCHER: Finished worker discovery
18:04:31 WORKER: done with job (0, 0, 17), trying to register it.
18:04:31 WORKER: registered result for job (0, 0, 17) with dispatcher
18:04:31 DISPATCHER: job (0, 0, 17) finished
18:04:31 DISPATCHER: register_result: lock acquired
18:04:31 DISPATCHER: job (0, 0, 17) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
18:04:31 job_id: (0, 0, 17)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0010603876905106253, 'num_filters_1': 53, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.0674182119746825}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.24775551692484796, 'info': {'sick_no_sick': 0.24775551692484796, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0010603876905106253, 'num_filters_1': 53, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.0674182119746825}"}}
exception: None

18:04:31 job_callback for (0, 0, 17) started
18:04:31 job_callback for (0, 0, 17) got condition
18:04:31 DISPATCHER: Trying to submit another job.
18:04:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:04:31 HBMASTER: Trying to run another job!
18:04:31 job_callback for (0, 0, 17) finished
18:04:31 start sampling a new configuration.
18:04:31 done sampling a new configuration.
18:04:31 HBMASTER: schedule new run for iteration 0
18:04:31 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
18:04:31 HBMASTER: submitting job (0, 0, 18) to dispatcher
18:04:31 DISPATCHER: trying to submit job (0, 0, 18)
18:04:31 DISPATCHER: trying to notify the job_runner thread.
18:04:31 HBMASTER: job (0, 0, 18) submitted to dispatcher
18:04:31 DISPATCHER: Trying to submit another job.
18:04:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:04:31 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:04:31 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:04:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:04:31 WORKER: start processing job (0, 0, 18)
18:04:31 WORKER: args: ()
18:04:31 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.016984447453920585, 'num_filters_1': 20, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.010430676660475563, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 67, 'num_filters_3': 29, 'num_filters_4': 48, 'num_filters_5': 35}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:05:05 DISPATCHER: Starting worker discovery
18:05:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:05:05 DISPATCHER: Finished worker discovery
Exception in thread Thread-620:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

18:06:05 DISPATCHER: Starting worker discovery
18:06:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:06:05 DISPATCHER: Finished worker discovery
18:06:16 WORKER: done with job (0, 0, 18), trying to register it.
18:06:16 WORKER: registered result for job (0, 0, 18) with dispatcher
18:06:16 DISPATCHER: job (0, 0, 18) finished
18:06:16 DISPATCHER: register_result: lock acquired
18:06:16 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
18:06:16 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.016984447453920585, 'num_filters_1': 20, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.010430676660475563, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 67, 'num_filters_3': 29, 'num_filters_4': 48, 'num_filters_5': 35}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.40568537708792185, 'info': {'sick_no_sick': 0.40568537708792185, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.016984447453920585, 'num_filters_1': 20, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.010430676660475563, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 67, 'num_filters_3': 29, 'num_filters_4': 48, 'num_filters_5': 35}"}}
exception: None

18:06:16 job_callback for (0, 0, 18) started
18:06:16 job_callback for (0, 0, 18) got condition
18:06:16 DISPATCHER: Trying to submit another job.
18:06:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:06:16 HBMASTER: Trying to run another job!
18:06:16 job_callback for (0, 0, 18) finished
18:06:16 start sampling a new configuration.
18:06:16 done sampling a new configuration.
18:06:16 HBMASTER: schedule new run for iteration 0
18:06:16 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
18:06:16 HBMASTER: submitting job (0, 0, 19) to dispatcher
18:06:16 DISPATCHER: trying to submit job (0, 0, 19)
18:06:16 DISPATCHER: trying to notify the job_runner thread.
18:06:16 HBMASTER: job (0, 0, 19) submitted to dispatcher
18:06:16 DISPATCHER: Trying to submit another job.
18:06:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:06:16 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:06:16 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:06:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:06:16 WORKER: start processing job (0, 0, 19)
18:06:16 WORKER: args: ()
18:06:16 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.052382418270773466, 'num_filters_1': 17, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.01014811170850769, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 18, 'num_filters_3': 92, 'num_filters_4': 115}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:07:05 DISPATCHER: Starting worker discovery
18:07:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:07:05 DISPATCHER: Finished worker discovery
18:08:04 WORKER: done with job (0, 0, 19), trying to register it.
18:08:04 WORKER: registered result for job (0, 0, 19) with dispatcher
18:08:04 DISPATCHER: job (0, 0, 19) finished
18:08:04 DISPATCHER: register_result: lock acquired
18:08:04 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
18:08:04 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.052382418270773466, 'num_filters_1': 17, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.01014811170850769, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 18, 'num_filters_3': 92, 'num_filters_4': 115}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.052382418270773466, 'num_filters_1': 17, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.01014811170850769, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 18, 'num_filters_3': 92, 'num_filters_4': 115}"}}
exception: None

18:08:04 job_callback for (0, 0, 19) started
18:08:04 job_callback for (0, 0, 19) got condition
18:08:04 DISPATCHER: Trying to submit another job.
18:08:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:08:04 HBMASTER: Trying to run another job!
18:08:04 job_callback for (0, 0, 19) finished
18:08:04 start sampling a new configuration.
18:08:04 done sampling a new configuration.
18:08:04 HBMASTER: schedule new run for iteration 0
18:08:04 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
18:08:04 HBMASTER: submitting job (0, 0, 20) to dispatcher
18:08:04 DISPATCHER: trying to submit job (0, 0, 20)
18:08:04 DISPATCHER: trying to notify the job_runner thread.
18:08:04 HBMASTER: job (0, 0, 20) submitted to dispatcher
18:08:04 DISPATCHER: Trying to submit another job.
18:08:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:08:04 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:08:04 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:08:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:08:04 WORKER: start processing job (0, 0, 20)
18:08:04 WORKER: args: ()
18:08:04 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.016645083947358003, 'num_filters_1': 69, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.012169424071045112, 'kernel_size_2': 7, 'num_filters_2': 71}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:08:05 DISPATCHER: Starting worker discovery
18:08:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:08:05 DISPATCHER: Finished worker discovery
18:09:05 DISPATCHER: Starting worker discovery
18:09:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:09:05 DISPATCHER: Finished worker discovery
Exception in thread Thread-622:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

18:09:51 WORKER: done with job (0, 0, 20), trying to register it.
18:09:51 WORKER: registered result for job (0, 0, 20) with dispatcher
18:09:51 DISPATCHER: job (0, 0, 20) finished
18:09:51 DISPATCHER: register_result: lock acquired
18:09:51 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
18:09:51 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.016645083947358003, 'num_filters_1': 69, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.012169424071045112, 'kernel_size_2': 7, 'num_filters_2': 71}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1988900103931179, 'info': {'sick_no_sick': 0.1988900103931179, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.016645083947358003, 'num_filters_1': 69, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.012169424071045112, 'kernel_size_2': 7, 'num_filters_2': 71}"}}
exception: None

18:09:51 DISPATCHER: Trying to submit another job.
18:09:51 job_callback for (0, 0, 20) started
18:09:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:09:51 job_callback for (0, 0, 20) got condition
18:09:51 HBMASTER: Trying to run another job!
18:09:51 job_callback for (0, 0, 20) finished
18:09:51 start sampling a new configuration.
18:09:51 done sampling a new configuration.
18:09:51 HBMASTER: schedule new run for iteration 0
18:09:51 HBMASTER: trying submitting job (0, 0, 21) to dispatcher
18:09:51 HBMASTER: submitting job (0, 0, 21) to dispatcher
18:09:51 DISPATCHER: trying to submit job (0, 0, 21)
18:09:51 DISPATCHER: trying to notify the job_runner thread.
18:09:51 HBMASTER: job (0, 0, 21) submitted to dispatcher
18:09:51 DISPATCHER: Trying to submit another job.
18:09:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:09:51 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:09:51 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:09:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:09:51 WORKER: start processing job (0, 0, 21)
18:09:51 WORKER: args: ()
18:09:51 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.009917632004977058, 'num_filters_1': 28, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.012280830685230136, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 105, 'num_filters_3': 52, 'num_filters_4': 111, 'num_filters_5': 56}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:10:05 DISPATCHER: Starting worker discovery
18:10:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:10:05 DISPATCHER: Finished worker discovery
18:11:05 DISPATCHER: Starting worker discovery
18:11:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:11:05 DISPATCHER: Finished worker discovery
18:11:39 WORKER: done with job (0, 0, 21), trying to register it.
18:11:39 WORKER: registered result for job (0, 0, 21) with dispatcher
18:11:39 DISPATCHER: job (0, 0, 21) finished
18:11:39 DISPATCHER: register_result: lock acquired
18:11:39 DISPATCHER: job (0, 0, 21) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
18:11:39 job_id: (0, 0, 21)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.009917632004977058, 'num_filters_1': 28, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.012280830685230136, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 105, 'num_filters_3': 52, 'num_filters_4': 111, 'num_filters_5': 56}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.009917632004977058, 'num_filters_1': 28, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.012280830685230136, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 105, 'num_filters_3': 52, 'num_filters_4': 111, 'num_filters_5': 56}"}}
exception: None

18:11:39 job_callback for (0, 0, 21) started
18:11:39 job_callback for (0, 0, 21) got condition
18:11:39 DISPATCHER: Trying to submit another job.
18:11:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:11:39 HBMASTER: Trying to run another job!
18:11:39 job_callback for (0, 0, 21) finished
18:11:39 start sampling a new configuration.
18:11:39 done sampling a new configuration.
18:11:39 HBMASTER: schedule new run for iteration 0
18:11:39 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
18:11:39 HBMASTER: submitting job (0, 0, 22) to dispatcher
18:11:39 DISPATCHER: trying to submit job (0, 0, 22)
18:11:39 DISPATCHER: trying to notify the job_runner thread.
18:11:39 HBMASTER: job (0, 0, 22) submitted to dispatcher
18:11:39 DISPATCHER: Trying to submit another job.
18:11:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:11:39 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:11:39 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:11:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:11:39 WORKER: start processing job (0, 0, 22)
18:11:39 WORKER: args: ()
18:11:39 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.013771477753374319, 'num_filters_1': 83, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.19555219734356047}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:12:05 DISPATCHER: Starting worker discovery
18:12:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:12:05 DISPATCHER: Finished worker discovery
18:13:05 DISPATCHER: Starting worker discovery
18:13:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:13:05 DISPATCHER: Finished worker discovery
18:13:29 WORKER: done with job (0, 0, 22), trying to register it.
18:13:29 WORKER: registered result for job (0, 0, 22) with dispatcher
18:13:29 DISPATCHER: job (0, 0, 22) finished
18:13:29 DISPATCHER: register_result: lock acquired
18:13:29 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
18:13:29 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.013771477753374319, 'num_filters_1': 83, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.19555219734356047}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.09590242403179605, 'info': {'sick_no_sick': 0.09590242403179605, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.013771477753374319, 'num_filters_1': 83, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.19555219734356047}"}}
exception: None

18:13:29 job_callback for (0, 0, 22) started
18:13:29 DISPATCHER: Trying to submit another job.
18:13:29 job_callback for (0, 0, 22) got condition
18:13:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:13:29 HBMASTER: Trying to run another job!
18:13:29 job_callback for (0, 0, 22) finished
18:13:29 start sampling a new configuration.
18:13:29 done sampling a new configuration.
18:13:29 HBMASTER: schedule new run for iteration 0
18:13:29 HBMASTER: trying submitting job (0, 0, 23) to dispatcher
18:13:29 HBMASTER: submitting job (0, 0, 23) to dispatcher
18:13:29 DISPATCHER: trying to submit job (0, 0, 23)
18:13:29 DISPATCHER: trying to notify the job_runner thread.
18:13:29 HBMASTER: job (0, 0, 23) submitted to dispatcher
18:13:29 DISPATCHER: Trying to submit another job.
18:13:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:13:29 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:13:29 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:13:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:13:29 WORKER: start processing job (0, 0, 23)
18:13:29 WORKER: args: ()
18:13:29 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001342867224397917, 'num_filters_1': 81, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.029629416959860117}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:14:05 DISPATCHER: Starting worker discovery
18:14:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:14:05 DISPATCHER: Finished worker discovery
18:15:05 DISPATCHER: Starting worker discovery
18:15:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:15:05 DISPATCHER: Finished worker discovery
18:15:17 WORKER: done with job (0, 0, 23), trying to register it.
18:15:17 WORKER: registered result for job (0, 0, 23) with dispatcher
18:15:17 DISPATCHER: job (0, 0, 23) finished
18:15:17 DISPATCHER: register_result: lock acquired
18:15:17 DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
18:15:17 job_id: (0, 0, 23)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001342867224397917, 'num_filters_1': 81, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.029629416959860117}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.48239764125910173, 'info': {'sick_no_sick': 0.48239764125910173, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001342867224397917, 'num_filters_1': 81, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.029629416959860117}"}}
exception: None

18:15:17 job_callback for (0, 0, 23) started
18:15:17 job_callback for (0, 0, 23) got condition
18:15:17 DISPATCHER: Trying to submit another job.
18:15:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:15:17 HBMASTER: Trying to run another job!
18:15:17 job_callback for (0, 0, 23) finished
18:15:17 start sampling a new configuration.
18:15:17 done sampling a new configuration.
18:15:17 HBMASTER: schedule new run for iteration 0
18:15:17 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
18:15:17 HBMASTER: submitting job (0, 0, 24) to dispatcher
18:15:17 DISPATCHER: trying to submit job (0, 0, 24)
18:15:17 DISPATCHER: trying to notify the job_runner thread.
18:15:17 HBMASTER: job (0, 0, 24) submitted to dispatcher
18:15:17 DISPATCHER: Trying to submit another job.
18:15:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:15:17 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:15:17 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:15:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:15:17 WORKER: start processing job (0, 0, 24)
18:15:17 WORKER: args: ()
18:15:17 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.04756023909992903, 'num_filters_1': 37, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.1286623065375981, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 36, 'num_filters_3': 52, 'num_filters_4': 23, 'num_filters_5': 33}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:16:05 DISPATCHER: Starting worker discovery
18:16:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:16:05 DISPATCHER: Finished worker discovery
18:17:05 DISPATCHER: Starting worker discovery
18:17:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:17:05 DISPATCHER: Finished worker discovery
18:17:06 WORKER: done with job (0, 0, 24), trying to register it.
18:17:06 WORKER: registered result for job (0, 0, 24) with dispatcher
18:17:06 DISPATCHER: job (0, 0, 24) finished
18:17:06 DISPATCHER: register_result: lock acquired
18:17:06 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
18:17:06 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.04756023909992903, 'num_filters_1': 37, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.1286623065375981, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 36, 'num_filters_3': 52, 'num_filters_4': 23, 'num_filters_5': 33}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.04756023909992903, 'num_filters_1': 37, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.1286623065375981, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 36, 'num_filters_3': 52, 'num_filters_4': 23, 'num_filters_5': 33}"}}
exception: None

18:17:06 job_callback for (0, 0, 24) started
18:17:06 DISPATCHER: Trying to submit another job.
18:17:06 job_callback for (0, 0, 24) got condition
18:17:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:17:06 HBMASTER: Trying to run another job!
18:17:06 job_callback for (0, 0, 24) finished
18:17:06 start sampling a new configuration.
18:17:06 done sampling a new configuration.
18:17:06 HBMASTER: schedule new run for iteration 0
18:17:06 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
18:17:06 HBMASTER: submitting job (0, 0, 25) to dispatcher
18:17:06 DISPATCHER: trying to submit job (0, 0, 25)
18:17:06 DISPATCHER: trying to notify the job_runner thread.
18:17:06 HBMASTER: job (0, 0, 25) submitted to dispatcher
18:17:06 DISPATCHER: Trying to submit another job.
18:17:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:17:06 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:17:06 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:17:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:17:06 WORKER: start processing job (0, 0, 25)
18:17:06 WORKER: args: ()
18:17:06 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.05254977819673121, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.041864083787991044, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 17, 'num_filters_3': 22, 'num_filters_4': 31}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:18:05 DISPATCHER: Starting worker discovery
18:18:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:18:05 DISPATCHER: Finished worker discovery
18:18:54 WORKER: done with job (0, 0, 25), trying to register it.
18:18:54 WORKER: registered result for job (0, 0, 25) with dispatcher
18:18:54 DISPATCHER: job (0, 0, 25) finished
18:18:54 DISPATCHER: register_result: lock acquired
18:18:54 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
18:18:54 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.05254977819673121, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.041864083787991044, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 17, 'num_filters_3': 22, 'num_filters_4': 31}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.05254977819673121, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.041864083787991044, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 17, 'num_filters_3': 22, 'num_filters_4': 31}"}}
exception: None

18:18:54 job_callback for (0, 0, 25) started
18:18:54 job_callback for (0, 0, 25) got condition
18:18:54 DISPATCHER: Trying to submit another job.
18:18:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:18:54 HBMASTER: Trying to run another job!
18:18:54 job_callback for (0, 0, 25) finished
18:18:54 start sampling a new configuration.
18:18:54 done sampling a new configuration.
18:18:54 HBMASTER: schedule new run for iteration 0
18:18:54 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
18:18:54 HBMASTER: submitting job (0, 0, 26) to dispatcher
18:18:54 DISPATCHER: trying to submit job (0, 0, 26)
18:18:54 DISPATCHER: trying to notify the job_runner thread.
18:18:54 HBMASTER: job (0, 0, 26) submitted to dispatcher
18:18:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:18:54 DISPATCHER: Trying to submit another job.
18:18:54 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:18:54 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:18:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:18:54 WORKER: start processing job (0, 0, 26)
18:18:54 WORKER: args: ()
18:18:54 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.017575894043924425, 'num_filters_1': 18, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.0771458088395184, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 125, 'num_filters_3': 25}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:19:05 DISPATCHER: Starting worker discovery
18:19:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:19:05 DISPATCHER: Finished worker discovery
18:20:05 DISPATCHER: Starting worker discovery
18:20:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:20:05 DISPATCHER: Finished worker discovery
18:20:41 WORKER: done with job (0, 0, 26), trying to register it.
18:20:41 WORKER: registered result for job (0, 0, 26) with dispatcher
18:20:41 DISPATCHER: job (0, 0, 26) finished
18:20:41 DISPATCHER: register_result: lock acquired
18:20:41 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
18:20:41 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.017575894043924425, 'num_filters_1': 18, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.0771458088395184, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 125, 'num_filters_3': 25}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.28021759914383965, 'info': {'sick_no_sick': 0.28021759914383965, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.017575894043924425, 'num_filters_1': 18, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.0771458088395184, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 125, 'num_filters_3': 25}"}}
exception: None

18:20:41 job_callback for (0, 0, 26) started
18:20:41 job_callback for (0, 0, 26) got condition
18:20:41 DISPATCHER: Trying to submit another job.
18:20:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:20:41 HBMASTER: Trying to run another job!
18:20:41 job_callback for (0, 0, 26) finished
18:20:41 ITERATION: Advancing config (0, 0, 2) to next budget 133.333333
18:20:41 ITERATION: Advancing config (0, 0, 7) to next budget 133.333333
18:20:41 ITERATION: Advancing config (0, 0, 8) to next budget 133.333333
18:20:41 ITERATION: Advancing config (0, 0, 9) to next budget 133.333333
18:20:41 ITERATION: Advancing config (0, 0, 10) to next budget 133.333333
18:20:41 ITERATION: Advancing config (0, 0, 11) to next budget 133.333333
18:20:41 ITERATION: Advancing config (0, 0, 14) to next budget 133.333333
18:20:41 ITERATION: Advancing config (0, 0, 18) to next budget 133.333333
18:20:41 ITERATION: Advancing config (0, 0, 23) to next budget 133.333333
18:20:41 HBMASTER: schedule new run for iteration 0
18:20:41 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
18:20:41 HBMASTER: submitting job (0, 0, 2) to dispatcher
18:20:41 DISPATCHER: trying to submit job (0, 0, 2)
18:20:41 DISPATCHER: trying to notify the job_runner thread.
18:20:41 HBMASTER: job (0, 0, 2) submitted to dispatcher
18:20:41 DISPATCHER: Trying to submit another job.
18:20:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:20:41 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:20:41 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:20:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:20:41 WORKER: start processing job (0, 0, 2)
18:20:41 WORKER: args: ()
18:20:41 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0019002255148213424, 'num_filters_1': 109, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.011380435879682948, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 25, 'num_filters_3': 24}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:21:05 DISPATCHER: Starting worker discovery
18:21:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:21:05 DISPATCHER: Finished worker discovery
18:22:05 DISPATCHER: Starting worker discovery
18:22:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:22:05 DISPATCHER: Finished worker discovery
18:23:05 DISPATCHER: Starting worker discovery
18:23:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:23:05 DISPATCHER: Finished worker discovery
18:23:58 WORKER: done with job (0, 0, 2), trying to register it.
18:23:58 WORKER: registered result for job (0, 0, 2) with dispatcher
18:23:58 DISPATCHER: job (0, 0, 2) finished
18:23:58 DISPATCHER: register_result: lock acquired
18:23:58 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
18:23:58 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0019002255148213424, 'num_filters_1': 109, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.011380435879682948, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 25, 'num_filters_3': 24}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4774525996476565, 'info': {'sick_no_sick': 0.4774525996476565, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0019002255148213424, 'num_filters_1': 109, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.011380435879682948, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 25, 'num_filters_3': 24}"}}
exception: None

18:23:58 job_callback for (0, 0, 2) started
18:23:58 DISPATCHER: Trying to submit another job.
18:23:58 job_callback for (0, 0, 2) got condition
18:23:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:23:58 Only 1 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
18:23:58 HBMASTER: Trying to run another job!
18:23:58 job_callback for (0, 0, 2) finished
18:23:58 HBMASTER: schedule new run for iteration 0
18:23:58 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
18:23:58 HBMASTER: submitting job (0, 0, 7) to dispatcher
18:23:58 DISPATCHER: trying to submit job (0, 0, 7)
18:23:58 DISPATCHER: trying to notify the job_runner thread.
18:23:58 HBMASTER: job (0, 0, 7) submitted to dispatcher
18:23:58 DISPATCHER: Trying to submit another job.
18:23:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:23:58 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:23:58 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:23:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:23:58 WORKER: start processing job (0, 0, 7)
18:23:58 WORKER: args: ()
18:23:58 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0058745517412776135, 'num_filters_1': 32, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.01970352841938794, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 30, 'num_filters_3': 33}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:24:05 DISPATCHER: Starting worker discovery
18:24:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:24:05 DISPATCHER: Finished worker discovery
18:25:05 DISPATCHER: Starting worker discovery
18:25:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:25:05 DISPATCHER: Finished worker discovery
18:26:05 DISPATCHER: Starting worker discovery
18:26:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:26:05 DISPATCHER: Finished worker discovery
18:27:05 DISPATCHER: Starting worker discovery
18:27:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:27:05 DISPATCHER: Finished worker discovery
18:27:13 WORKER: done with job (0, 0, 7), trying to register it.
18:27:13 WORKER: registered result for job (0, 0, 7) with dispatcher
18:27:13 DISPATCHER: job (0, 0, 7) finished
18:27:13 DISPATCHER: register_result: lock acquired
18:27:13 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
18:27:13 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0058745517412776135, 'num_filters_1': 32, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.01970352841938794, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 30, 'num_filters_3': 33}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.49958255090176434, 'info': {'sick_no_sick': 0.49958255090176434, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0058745517412776135, 'num_filters_1': 32, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.01970352841938794, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 30, 'num_filters_3': 33}"}}
exception: None

18:27:13 job_callback for (0, 0, 7) started
18:27:13 job_callback for (0, 0, 7) got condition
18:27:13 DISPATCHER: Trying to submit another job.
18:27:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:27:13 Only 2 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
18:27:13 HBMASTER: Trying to run another job!
18:27:13 job_callback for (0, 0, 7) finished
18:27:13 HBMASTER: schedule new run for iteration 0
18:27:13 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
18:27:13 HBMASTER: submitting job (0, 0, 8) to dispatcher
18:27:13 DISPATCHER: trying to submit job (0, 0, 8)
18:27:13 DISPATCHER: trying to notify the job_runner thread.
18:27:13 HBMASTER: job (0, 0, 8) submitted to dispatcher
18:27:13 DISPATCHER: Trying to submit another job.
18:27:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:27:13 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:27:13 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:27:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:27:13 WORKER: start processing job (0, 0, 8)
18:27:13 WORKER: args: ()
18:27:13 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001607311099321854, 'num_filters_1': 22, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.06055884364364364, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 18, 'num_filters_3': 120}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:28:05 DISPATCHER: Starting worker discovery
18:28:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:28:05 DISPATCHER: Finished worker discovery
18:29:05 DISPATCHER: Starting worker discovery
18:29:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:29:05 DISPATCHER: Finished worker discovery
18:30:05 DISPATCHER: Starting worker discovery
18:30:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:30:05 DISPATCHER: Finished worker discovery
18:30:34 WORKER: done with job (0, 0, 8), trying to register it.
18:30:34 WORKER: registered result for job (0, 0, 8) with dispatcher
18:30:34 DISPATCHER: job (0, 0, 8) finished
18:30:34 DISPATCHER: register_result: lock acquired
18:30:34 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
18:30:34 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001607311099321854, 'num_filters_1': 22, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.06055884364364364, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 18, 'num_filters_3': 120}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.46391929189606707, 'info': {'sick_no_sick': 0.46391929189606707, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001607311099321854, 'num_filters_1': 22, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.06055884364364364, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 18, 'num_filters_3': 120}"}}
exception: None

18:30:34 job_callback for (0, 0, 8) started
18:30:34 DISPATCHER: Trying to submit another job.
18:30:34 job_callback for (0, 0, 8) got condition
18:30:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:30:34 Only 3 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
18:30:34 HBMASTER: Trying to run another job!
18:30:34 job_callback for (0, 0, 8) finished
18:30:34 HBMASTER: schedule new run for iteration 0
18:30:34 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
18:30:34 HBMASTER: submitting job (0, 0, 9) to dispatcher
18:30:34 DISPATCHER: trying to submit job (0, 0, 9)
18:30:34 DISPATCHER: trying to notify the job_runner thread.
18:30:34 HBMASTER: job (0, 0, 9) submitted to dispatcher
18:30:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:30:34 DISPATCHER: Trying to submit another job.
18:30:34 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:30:34 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:30:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:30:34 WORKER: start processing job (0, 0, 9)
18:30:34 WORKER: args: ()
18:30:34 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.037708620137109454, 'num_filters_1': 16, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.01856523696043172, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 46, 'num_filters_3': 16}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:31:05 DISPATCHER: Starting worker discovery
18:31:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:31:05 DISPATCHER: Finished worker discovery
Exception in thread Thread-632:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

18:32:05 DISPATCHER: Starting worker discovery
18:32:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:32:05 DISPATCHER: Finished worker discovery
18:33:05 DISPATCHER: Starting worker discovery
18:33:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:33:05 DISPATCHER: Finished worker discovery
18:33:49 WORKER: done with job (0, 0, 9), trying to register it.
18:33:49 WORKER: registered result for job (0, 0, 9) with dispatcher
18:33:49 DISPATCHER: job (0, 0, 9) finished
18:33:49 DISPATCHER: register_result: lock acquired
18:33:49 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
18:33:49 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.037708620137109454, 'num_filters_1': 16, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.01856523696043172, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 46, 'num_filters_3': 16}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4956371047134935, 'info': {'sick_no_sick': 0.4956371047134935, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.037708620137109454, 'num_filters_1': 16, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.01856523696043172, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 46, 'num_filters_3': 16}"}}
exception: None

18:33:49 job_callback for (0, 0, 9) started
18:33:49 job_callback for (0, 0, 9) got condition
18:33:49 DISPATCHER: Trying to submit another job.
18:33:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:33:49 Only 4 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
18:33:49 HBMASTER: Trying to run another job!
18:33:49 job_callback for (0, 0, 9) finished
18:33:49 HBMASTER: schedule new run for iteration 0
18:33:49 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
18:33:49 HBMASTER: submitting job (0, 0, 10) to dispatcher
18:33:49 DISPATCHER: trying to submit job (0, 0, 10)
18:33:49 DISPATCHER: trying to notify the job_runner thread.
18:33:49 HBMASTER: job (0, 0, 10) submitted to dispatcher
18:33:49 DISPATCHER: Trying to submit another job.
18:33:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:33:49 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:33:49 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:33:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:33:49 WORKER: start processing job (0, 0, 10)
18:33:49 WORKER: args: ()
18:33:49 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0022890799024759285, 'num_filters_1': 72, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.01933789386636864}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:34:05 DISPATCHER: Starting worker discovery
18:34:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:34:05 DISPATCHER: Finished worker discovery
18:35:05 DISPATCHER: Starting worker discovery
18:35:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:35:05 DISPATCHER: Finished worker discovery
18:36:05 DISPATCHER: Starting worker discovery
18:36:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:36:05 DISPATCHER: Finished worker discovery
18:37:05 DISPATCHER: Starting worker discovery
18:37:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:37:05 DISPATCHER: Finished worker discovery
18:37:08 WORKER: done with job (0, 0, 10), trying to register it.
18:37:08 WORKER: registered result for job (0, 0, 10) with dispatcher
18:37:08 DISPATCHER: job (0, 0, 10) finished
18:37:08 DISPATCHER: register_result: lock acquired
18:37:08 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
18:37:08 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0022890799024759285, 'num_filters_1': 72, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.01933789386636864}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4372099897901014, 'info': {'sick_no_sick': 0.4372099897901014, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0022890799024759285, 'num_filters_1': 72, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.01933789386636864}"}}
exception: None

18:37:08 job_callback for (0, 0, 10) started
18:37:08 DISPATCHER: Trying to submit another job.
18:37:08 job_callback for (0, 0, 10) got condition
18:37:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:37:08 Only 5 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
18:37:08 HBMASTER: Trying to run another job!
18:37:08 job_callback for (0, 0, 10) finished
18:37:08 HBMASTER: schedule new run for iteration 0
18:37:08 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
18:37:08 HBMASTER: submitting job (0, 0, 11) to dispatcher
18:37:08 DISPATCHER: trying to submit job (0, 0, 11)
18:37:08 DISPATCHER: trying to notify the job_runner thread.
18:37:08 HBMASTER: job (0, 0, 11) submitted to dispatcher
18:37:08 DISPATCHER: Trying to submit another job.
18:37:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:37:08 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:37:08 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:37:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:37:08 WORKER: start processing job (0, 0, 11)
18:37:08 WORKER: args: ()
18:37:08 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.007765103313545947, 'num_filters_1': 30, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.010321936146450874, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 23, 'num_filters_3': 46, 'num_filters_4': 45}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:38:05 DISPATCHER: Starting worker discovery
18:38:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:38:05 DISPATCHER: Finished worker discovery
18:39:05 DISPATCHER: Starting worker discovery
18:39:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:39:05 DISPATCHER: Finished worker discovery
18:40:05 DISPATCHER: Starting worker discovery
18:40:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:40:05 DISPATCHER: Finished worker discovery
18:40:24 WORKER: done with job (0, 0, 11), trying to register it.
18:40:24 WORKER: registered result for job (0, 0, 11) with dispatcher
18:40:24 DISPATCHER: job (0, 0, 11) finished
18:40:24 DISPATCHER: register_result: lock acquired
18:40:24 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
18:40:24 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.007765103313545947, 'num_filters_1': 30, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.010321936146450874, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 23, 'num_filters_3': 46, 'num_filters_4': 45}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5037023991881849, 'info': {'sick_no_sick': 0.5037023991881849, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.007765103313545947, 'num_filters_1': 30, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.010321936146450874, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 23, 'num_filters_3': 46, 'num_filters_4': 45}"}}
exception: None

18:40:24 job_callback for (0, 0, 11) started
18:40:24 job_callback for (0, 0, 11) got condition
18:40:24 DISPATCHER: Trying to submit another job.
18:40:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:40:24 Only 6 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
18:40:24 HBMASTER: Trying to run another job!
18:40:24 job_callback for (0, 0, 11) finished
18:40:24 HBMASTER: schedule new run for iteration 0
18:40:24 HBMASTER: trying submitting job (0, 0, 14) to dispatcher
18:40:24 HBMASTER: submitting job (0, 0, 14) to dispatcher
18:40:24 DISPATCHER: trying to submit job (0, 0, 14)
18:40:24 DISPATCHER: trying to notify the job_runner thread.
18:40:24 HBMASTER: job (0, 0, 14) submitted to dispatcher
18:40:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:40:24 DISPATCHER: Trying to submit another job.
18:40:24 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:40:24 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:40:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:40:24 WORKER: start processing job (0, 0, 14)
18:40:24 WORKER: args: ()
18:40:24 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.007008866304912582, 'num_filters_1': 111, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.011551256323413809, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 43, 'num_filters_3': 42, 'num_filters_4': 53}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:41:05 DISPATCHER: Starting worker discovery
18:41:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:41:05 DISPATCHER: Finished worker discovery
18:42:05 DISPATCHER: Starting worker discovery
18:42:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:42:05 DISPATCHER: Finished worker discovery
18:43:05 DISPATCHER: Starting worker discovery
18:43:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:43:05 DISPATCHER: Finished worker discovery
18:43:40 WORKER: done with job (0, 0, 14), trying to register it.
18:43:40 WORKER: registered result for job (0, 0, 14) with dispatcher
18:43:40 DISPATCHER: job (0, 0, 14) finished
18:43:40 DISPATCHER: register_result: lock acquired
18:43:40 DISPATCHER: job (0, 0, 14) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
18:43:40 job_id: (0, 0, 14)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.007008866304912582, 'num_filters_1': 111, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.011551256323413809, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 43, 'num_filters_3': 42, 'num_filters_4': 53}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5302093897116477, 'info': {'sick_no_sick': 0.5302093897116477, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.007008866304912582, 'num_filters_1': 111, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.011551256323413809, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 43, 'num_filters_3': 42, 'num_filters_4': 53}"}}
exception: None

18:43:40 job_callback for (0, 0, 14) started
18:43:40 DISPATCHER: Trying to submit another job.
18:43:40 job_callback for (0, 0, 14) got condition
18:43:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:43:40 Only 7 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
18:43:40 HBMASTER: Trying to run another job!
18:43:40 job_callback for (0, 0, 14) finished
18:43:40 HBMASTER: schedule new run for iteration 0
18:43:40 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
18:43:40 HBMASTER: submitting job (0, 0, 18) to dispatcher
18:43:40 DISPATCHER: trying to submit job (0, 0, 18)
18:43:40 DISPATCHER: trying to notify the job_runner thread.
18:43:40 HBMASTER: job (0, 0, 18) submitted to dispatcher
18:43:40 DISPATCHER: Trying to submit another job.
18:43:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:43:40 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:43:40 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:43:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:43:40 WORKER: start processing job (0, 0, 18)
18:43:40 WORKER: args: ()
18:43:40 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.016984447453920585, 'num_filters_1': 20, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.010430676660475563, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 67, 'num_filters_3': 29, 'num_filters_4': 48, 'num_filters_5': 35}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:44:05 DISPATCHER: Starting worker discovery
18:44:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:44:05 DISPATCHER: Finished worker discovery
Exception in thread Thread-636:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

18:45:05 DISPATCHER: Starting worker discovery
18:45:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:45:05 DISPATCHER: Finished worker discovery
18:46:05 DISPATCHER: Starting worker discovery
18:46:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:46:05 DISPATCHER: Finished worker discovery
18:46:55 WORKER: done with job (0, 0, 18), trying to register it.
18:46:55 WORKER: registered result for job (0, 0, 18) with dispatcher
18:46:55 DISPATCHER: job (0, 0, 18) finished
18:46:55 DISPATCHER: register_result: lock acquired
18:46:55 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
18:46:55 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.016984447453920585, 'num_filters_1': 20, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.010430676660475563, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 67, 'num_filters_3': 29, 'num_filters_4': 48, 'num_filters_5': 35}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.45802954542042545, 'info': {'sick_no_sick': 0.45802954542042545, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.016984447453920585, 'num_filters_1': 20, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.010430676660475563, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 67, 'num_filters_3': 29, 'num_filters_4': 48, 'num_filters_5': 35}"}}
exception: None

18:46:55 job_callback for (0, 0, 18) started
18:46:55 DISPATCHER: Trying to submit another job.
18:46:55 job_callback for (0, 0, 18) got condition
18:46:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:46:55 Only 8 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
18:46:55 HBMASTER: Trying to run another job!
18:46:55 job_callback for (0, 0, 18) finished
18:46:55 HBMASTER: schedule new run for iteration 0
18:46:55 HBMASTER: trying submitting job (0, 0, 23) to dispatcher
18:46:55 HBMASTER: submitting job (0, 0, 23) to dispatcher
18:46:55 DISPATCHER: trying to submit job (0, 0, 23)
18:46:55 DISPATCHER: trying to notify the job_runner thread.
18:46:55 HBMASTER: job (0, 0, 23) submitted to dispatcher
18:46:55 DISPATCHER: Trying to submit another job.
18:46:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:46:55 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:46:55 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:46:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:46:55 WORKER: start processing job (0, 0, 23)
18:46:55 WORKER: args: ()
18:46:55 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001342867224397917, 'num_filters_1': 81, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.029629416959860117}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:47:05 DISPATCHER: Starting worker discovery
18:47:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:47:05 DISPATCHER: Finished worker discovery
18:48:05 DISPATCHER: Starting worker discovery
18:48:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:48:05 DISPATCHER: Finished worker discovery
18:49:05 DISPATCHER: Starting worker discovery
18:49:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:49:05 DISPATCHER: Finished worker discovery
18:50:05 DISPATCHER: Starting worker discovery
18:50:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:50:05 DISPATCHER: Finished worker discovery
18:50:15 WORKER: done with job (0, 0, 23), trying to register it.
18:50:15 WORKER: registered result for job (0, 0, 23) with dispatcher
18:50:15 DISPATCHER: job (0, 0, 23) finished
18:50:15 DISPATCHER: register_result: lock acquired
18:50:15 DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
18:50:15 job_id: (0, 0, 23)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001342867224397917, 'num_filters_1': 81, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.029629416959860117}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5058803376987967, 'info': {'sick_no_sick': 0.5058803376987967, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001342867224397917, 'num_filters_1': 81, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.029629416959860117}"}}
exception: None

18:50:15 job_callback for (0, 0, 23) started
18:50:15 DISPATCHER: Trying to submit another job.
18:50:15 job_callback for (0, 0, 23) got condition
18:50:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:50:15 Only 9 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
18:50:15 HBMASTER: Trying to run another job!
18:50:15 job_callback for (0, 0, 23) finished
18:50:15 ITERATION: Advancing config (0, 0, 11) to next budget 400.000000
18:50:15 ITERATION: Advancing config (0, 0, 14) to next budget 400.000000
18:50:15 ITERATION: Advancing config (0, 0, 23) to next budget 400.000000
18:50:15 HBMASTER: schedule new run for iteration 0
18:50:15 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
18:50:15 HBMASTER: submitting job (0, 0, 11) to dispatcher
18:50:15 DISPATCHER: trying to submit job (0, 0, 11)
18:50:15 DISPATCHER: trying to notify the job_runner thread.
18:50:15 HBMASTER: job (0, 0, 11) submitted to dispatcher
18:50:15 DISPATCHER: Trying to submit another job.
18:50:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:50:15 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:50:15 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:50:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:50:15 WORKER: start processing job (0, 0, 11)
18:50:15 WORKER: args: ()
18:50:15 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.007765103313545947, 'num_filters_1': 30, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.010321936146450874, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 23, 'num_filters_3': 46, 'num_filters_4': 45}, 'budget': 400.0, 'working_directory': '.'}
18:51:05 DISPATCHER: Starting worker discovery
18:51:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:51:05 DISPATCHER: Finished worker discovery
Exception in thread Thread-638:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

18:52:05 DISPATCHER: Starting worker discovery
18:52:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:52:05 DISPATCHER: Finished worker discovery
18:53:05 DISPATCHER: Starting worker discovery
18:53:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:53:05 DISPATCHER: Finished worker discovery
18:54:05 DISPATCHER: Starting worker discovery
18:54:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:54:05 DISPATCHER: Finished worker discovery
18:55:05 DISPATCHER: Starting worker discovery
18:55:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:55:05 DISPATCHER: Finished worker discovery
18:56:05 DISPATCHER: Starting worker discovery
18:56:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:56:05 DISPATCHER: Finished worker discovery
18:57:05 DISPATCHER: Starting worker discovery
18:57:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:57:05 DISPATCHER: Finished worker discovery
18:57:56 WORKER: done with job (0, 0, 11), trying to register it.
18:57:56 WORKER: registered result for job (0, 0, 11) with dispatcher
18:57:56 DISPATCHER: job (0, 0, 11) finished
18:57:56 DISPATCHER: register_result: lock acquired
18:57:56 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
18:57:56 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.007765103313545947, 'num_filters_1': 30, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.010321936146450874, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 23, 'num_filters_3': 46, 'num_filters_4': 45}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.4632433998579326, 'info': {'sick_no_sick': 0.4632433998579326, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.007765103313545947, 'num_filters_1': 30, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.010321936146450874, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 23, 'num_filters_3': 46, 'num_filters_4': 45}"}}
exception: None

18:57:56 job_callback for (0, 0, 11) started
18:57:56 DISPATCHER: Trying to submit another job.
18:57:56 job_callback for (0, 0, 11) got condition
18:57:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:57:56 Only 1 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
18:57:56 HBMASTER: Trying to run another job!
18:57:56 job_callback for (0, 0, 11) finished
18:57:56 HBMASTER: schedule new run for iteration 0
18:57:56 HBMASTER: trying submitting job (0, 0, 14) to dispatcher
18:57:56 HBMASTER: submitting job (0, 0, 14) to dispatcher
18:57:56 DISPATCHER: trying to submit job (0, 0, 14)
18:57:56 DISPATCHER: trying to notify the job_runner thread.
18:57:56 HBMASTER: job (0, 0, 14) submitted to dispatcher
18:57:56 DISPATCHER: Trying to submit another job.
18:57:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:57:56 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:57:56 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
18:57:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:57:56 WORKER: start processing job (0, 0, 14)
18:57:56 WORKER: args: ()
18:57:56 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.007008866304912582, 'num_filters_1': 111, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.011551256323413809, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 43, 'num_filters_3': 42, 'num_filters_4': 53}, 'budget': 400.0, 'working_directory': '.'}
18:58:05 DISPATCHER: Starting worker discovery
18:58:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:58:05 DISPATCHER: Finished worker discovery
18:59:05 DISPATCHER: Starting worker discovery
18:59:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:59:05 DISPATCHER: Finished worker discovery
19:00:05 DISPATCHER: Starting worker discovery
19:00:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:00:05 DISPATCHER: Finished worker discovery
19:01:05 DISPATCHER: Starting worker discovery
19:01:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:01:05 DISPATCHER: Finished worker discovery
19:02:05 DISPATCHER: Starting worker discovery
19:02:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:02:05 DISPATCHER: Finished worker discovery
19:03:05 DISPATCHER: Starting worker discovery
19:03:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:03:05 DISPATCHER: Finished worker discovery
19:04:05 DISPATCHER: Starting worker discovery
19:04:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:04:05 DISPATCHER: Finished worker discovery
19:05:05 DISPATCHER: Starting worker discovery
19:05:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:05:05 DISPATCHER: Finished worker discovery
19:05:41 WORKER: done with job (0, 0, 14), trying to register it.
19:05:41 WORKER: registered result for job (0, 0, 14) with dispatcher
19:05:41 DISPATCHER: job (0, 0, 14) finished
19:05:41 DISPATCHER: register_result: lock acquired
19:05:41 DISPATCHER: job (0, 0, 14) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
19:05:41 job_id: (0, 0, 14)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.007008866304912582, 'num_filters_1': 111, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.011551256323413809, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 43, 'num_filters_3': 42, 'num_filters_4': 53}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.495021480023726, 'info': {'sick_no_sick': 0.495021480023726, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.007008866304912582, 'num_filters_1': 111, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.011551256323413809, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 43, 'num_filters_3': 42, 'num_filters_4': 53}"}}
exception: None

19:05:41 job_callback for (0, 0, 14) started
19:05:41 job_callback for (0, 0, 14) got condition
19:05:41 DISPATCHER: Trying to submit another job.
19:05:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:05:41 Only 2 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
19:05:41 HBMASTER: Trying to run another job!
19:05:41 job_callback for (0, 0, 14) finished
19:05:41 HBMASTER: schedule new run for iteration 0
19:05:41 HBMASTER: trying submitting job (0, 0, 23) to dispatcher
19:05:41 HBMASTER: submitting job (0, 0, 23) to dispatcher
19:05:41 DISPATCHER: trying to submit job (0, 0, 23)
19:05:41 DISPATCHER: trying to notify the job_runner thread.
19:05:41 HBMASTER: job (0, 0, 23) submitted to dispatcher
19:05:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:05:41 DISPATCHER: Trying to submit another job.
19:05:41 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:05:41 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:05:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:05:41 WORKER: start processing job (0, 0, 23)
19:05:41 WORKER: args: ()
19:05:41 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001342867224397917, 'num_filters_1': 81, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.029629416959860117}, 'budget': 400.0, 'working_directory': '.'}
19:06:05 DISPATCHER: Starting worker discovery
19:06:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:06:05 DISPATCHER: Finished worker discovery
19:07:05 DISPATCHER: Starting worker discovery
19:07:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:07:05 DISPATCHER: Finished worker discovery
19:08:05 DISPATCHER: Starting worker discovery
19:08:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:08:05 DISPATCHER: Finished worker discovery
19:09:05 DISPATCHER: Starting worker discovery
19:09:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:09:05 DISPATCHER: Finished worker discovery
19:10:05 DISPATCHER: Starting worker discovery
19:10:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:10:05 DISPATCHER: Finished worker discovery
19:11:05 DISPATCHER: Starting worker discovery
19:11:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:11:05 DISPATCHER: Finished worker discovery
19:12:05 DISPATCHER: Starting worker discovery
19:12:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:12:05 DISPATCHER: Finished worker discovery
19:13:05 DISPATCHER: Starting worker discovery
19:13:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:13:05 DISPATCHER: Finished worker discovery
19:13:35 WORKER: done with job (0, 0, 23), trying to register it.
19:13:35 WORKER: registered result for job (0, 0, 23) with dispatcher
19:13:35 DISPATCHER: job (0, 0, 23) finished
19:13:35 DISPATCHER: register_result: lock acquired
19:13:35 DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
19:13:35 job_id: (0, 0, 23)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001342867224397917, 'num_filters_1': 81, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.029629416959860117}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.547990241007478, 'info': {'sick_no_sick': 0.547990241007478, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001342867224397917, 'num_filters_1': 81, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.029629416959860117}"}}
exception: None

19:13:35 job_callback for (0, 0, 23) started
19:13:35 DISPATCHER: Trying to submit another job.
19:13:35 job_callback for (0, 0, 23) got condition
19:13:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:13:35 Only 3 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
19:13:35 HBMASTER: Trying to run another job!
19:13:35 job_callback for (0, 0, 23) finished
19:13:35 ITERATION: Advancing config (0, 0, 23) to next budget 1200.000000
19:13:35 HBMASTER: schedule new run for iteration 0
19:13:35 HBMASTER: trying submitting job (0, 0, 23) to dispatcher
19:13:35 HBMASTER: submitting job (0, 0, 23) to dispatcher
19:13:35 DISPATCHER: trying to submit job (0, 0, 23)
19:13:35 DISPATCHER: trying to notify the job_runner thread.
19:13:35 HBMASTER: job (0, 0, 23) submitted to dispatcher
19:13:35 DISPATCHER: Trying to submit another job.
19:13:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:13:35 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:13:35 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:13:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:13:35 WORKER: start processing job (0, 0, 23)
19:13:35 WORKER: args: ()
19:13:35 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001342867224397917, 'num_filters_1': 81, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.029629416959860117}, 'budget': 1200.0, 'working_directory': '.'}
19:14:05 DISPATCHER: Starting worker discovery
19:14:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:14:05 DISPATCHER: Finished worker discovery
19:15:05 DISPATCHER: Starting worker discovery
19:15:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:15:05 DISPATCHER: Finished worker discovery
19:16:05 DISPATCHER: Starting worker discovery
19:16:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:16:06 DISPATCHER: Finished worker discovery
19:17:06 DISPATCHER: Starting worker discovery
19:17:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:17:06 DISPATCHER: Finished worker discovery
19:18:06 DISPATCHER: Starting worker discovery
19:18:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:18:06 DISPATCHER: Finished worker discovery
19:19:06 DISPATCHER: Starting worker discovery
19:19:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:19:06 DISPATCHER: Finished worker discovery
19:20:06 DISPATCHER: Starting worker discovery
19:20:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:20:06 DISPATCHER: Finished worker discovery
19:21:06 DISPATCHER: Starting worker discovery
19:21:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:21:06 DISPATCHER: Finished worker discovery
19:22:06 DISPATCHER: Starting worker discovery
19:22:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:22:06 DISPATCHER: Finished worker discovery
19:23:06 DISPATCHER: Starting worker discovery
19:23:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:23:06 DISPATCHER: Finished worker discovery
19:24:06 DISPATCHER: Starting worker discovery
19:24:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:24:06 DISPATCHER: Finished worker discovery
19:25:06 DISPATCHER: Starting worker discovery
19:25:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:25:06 DISPATCHER: Finished worker discovery
19:26:06 DISPATCHER: Starting worker discovery
19:26:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:26:06 DISPATCHER: Finished worker discovery
19:27:06 DISPATCHER: Starting worker discovery
19:27:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:27:06 DISPATCHER: Finished worker discovery
19:28:06 DISPATCHER: Starting worker discovery
19:28:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:28:06 DISPATCHER: Finished worker discovery
19:29:06 DISPATCHER: Starting worker discovery
19:29:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:29:06 DISPATCHER: Finished worker discovery
19:30:06 DISPATCHER: Starting worker discovery
19:30:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:30:06 DISPATCHER: Finished worker discovery
19:31:06 DISPATCHER: Starting worker discovery
19:31:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:31:06 DISPATCHER: Finished worker discovery
19:32:06 DISPATCHER: Starting worker discovery
19:32:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:32:06 DISPATCHER: Finished worker discovery
19:33:06 DISPATCHER: Starting worker discovery
19:33:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:33:06 DISPATCHER: Finished worker discovery
19:34:06 DISPATCHER: Starting worker discovery
19:34:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:34:06 DISPATCHER: Finished worker discovery
19:35:06 DISPATCHER: Starting worker discovery
19:35:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:35:06 DISPATCHER: Finished worker discovery
19:35:12 WORKER: done with job (0, 0, 23), trying to register it.
19:35:12 WORKER: registered result for job (0, 0, 23) with dispatcher
19:35:12 DISPATCHER: job (0, 0, 23) finished
19:35:12 DISPATCHER: register_result: lock acquired
19:35:12 DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
19:35:12 job_id: (0, 0, 23)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001342867224397917, 'num_filters_1': 81, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.029629416959860117}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5230056502790351, 'info': {'sick_no_sick': 0.5230056502790351, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001342867224397917, 'num_filters_1': 81, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.029629416959860117}"}}
exception: None

19:35:12 job_callback for (0, 0, 23) started
19:35:12 DISPATCHER: Trying to submit another job.
19:35:12 job_callback for (0, 0, 23) got condition
19:35:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:35:12 Only 1 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
19:35:12 HBMASTER: Trying to run another job!
19:35:12 job_callback for (0, 0, 23) finished
19:35:12 start sampling a new configuration.
19:35:12 done sampling a new configuration.
19:35:12 HBMASTER: schedule new run for iteration 1
19:35:12 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
19:35:12 HBMASTER: submitting job (1, 0, 0) to dispatcher
19:35:12 DISPATCHER: trying to submit job (1, 0, 0)
19:35:12 DISPATCHER: trying to notify the job_runner thread.
19:35:12 HBMASTER: job (1, 0, 0) submitted to dispatcher
19:35:12 DISPATCHER: Trying to submit another job.
19:35:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:35:12 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:35:12 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:35:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:35:12 WORKER: start processing job (1, 0, 0)
19:35:12 WORKER: args: ()
19:35:12 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.09841951461239384, 'num_filters_1': 70, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.012243115933122677, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 97, 'num_filters_3': 28, 'num_filters_4': 98, 'num_filters_5': 74}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:36:06 DISPATCHER: Starting worker discovery
19:36:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:36:06 DISPATCHER: Finished worker discovery
19:37:06 DISPATCHER: Starting worker discovery
19:37:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:37:06 DISPATCHER: Finished worker discovery
19:38:06 DISPATCHER: Starting worker discovery
19:38:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:38:06 DISPATCHER: Finished worker discovery
19:38:30 WORKER: done with job (1, 0, 0), trying to register it.
19:38:30 WORKER: registered result for job (1, 0, 0) with dispatcher
19:38:30 DISPATCHER: job (1, 0, 0) finished
19:38:30 DISPATCHER: register_result: lock acquired
19:38:30 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
19:38:30 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.09841951461239384, 'num_filters_1': 70, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.012243115933122677, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 97, 'num_filters_3': 28, 'num_filters_4': 98, 'num_filters_5': 74}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.000469269929470698, 'info': {'sick_no_sick': 0.000469269929470698, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.09841951461239384, 'num_filters_1': 70, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.012243115933122677, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 97, 'num_filters_3': 28, 'num_filters_4': 98, 'num_filters_5': 74}"}}
exception: None

19:38:30 job_callback for (1, 0, 0) started
19:38:30 DISPATCHER: Trying to submit another job.
19:38:30 job_callback for (1, 0, 0) got condition
19:38:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:38:30 Only 10 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
19:38:30 HBMASTER: Trying to run another job!
19:38:30 job_callback for (1, 0, 0) finished
19:38:30 start sampling a new configuration.
19:38:30 done sampling a new configuration.
19:38:30 HBMASTER: schedule new run for iteration 1
19:38:30 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
19:38:30 HBMASTER: submitting job (1, 0, 1) to dispatcher
19:38:30 DISPATCHER: trying to submit job (1, 0, 1)
19:38:30 DISPATCHER: trying to notify the job_runner thread.
19:38:30 HBMASTER: job (1, 0, 1) submitted to dispatcher
19:38:30 DISPATCHER: Trying to submit another job.
19:38:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:38:30 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:38:30 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:38:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:38:30 WORKER: start processing job (1, 0, 1)
19:38:30 WORKER: args: ()
19:38:30 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0011526764525709335, 'num_filters_1': 78, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.0673775210900583}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:39:06 DISPATCHER: Starting worker discovery
19:39:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:39:06 DISPATCHER: Finished worker discovery
19:40:06 DISPATCHER: Starting worker discovery
19:40:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:40:06 DISPATCHER: Finished worker discovery
19:41:06 DISPATCHER: Starting worker discovery
19:41:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:41:06 DISPATCHER: Finished worker discovery
19:41:47 WORKER: done with job (1, 0, 1), trying to register it.
19:41:47 WORKER: registered result for job (1, 0, 1) with dispatcher
19:41:47 DISPATCHER: job (1, 0, 1) finished
19:41:47 DISPATCHER: register_result: lock acquired
19:41:47 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
19:41:47 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0011526764525709335, 'num_filters_1': 78, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.0673775210900583}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.518361012654585, 'info': {'sick_no_sick': 0.518361012654585, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0011526764525709335, 'num_filters_1': 78, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.0673775210900583}"}}
exception: None

19:41:47 job_callback for (1, 0, 1) started
19:41:47 job_callback for (1, 0, 1) got condition
19:41:47 DISPATCHER: Trying to submit another job.
19:41:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:41:47 Only 11 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
19:41:47 HBMASTER: Trying to run another job!
19:41:47 job_callback for (1, 0, 1) finished
19:41:47 start sampling a new configuration.
19:41:47 done sampling a new configuration.
19:41:47 HBMASTER: schedule new run for iteration 1
19:41:47 HBMASTER: trying submitting job (1, 0, 2) to dispatcher
19:41:47 HBMASTER: submitting job (1, 0, 2) to dispatcher
19:41:47 DISPATCHER: trying to submit job (1, 0, 2)
19:41:47 DISPATCHER: trying to notify the job_runner thread.
19:41:47 HBMASTER: job (1, 0, 2) submitted to dispatcher
19:41:47 DISPATCHER: Trying to submit another job.
19:41:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:41:47 DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:41:47 DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:41:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:41:47 WORKER: start processing job (1, 0, 2)
19:41:47 WORKER: args: ()
19:41:47 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001190533617106509, 'num_filters_1': 120, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.02422290607184328}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:42:06 DISPATCHER: Starting worker discovery
19:42:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:42:06 DISPATCHER: Finished worker discovery
19:43:06 DISPATCHER: Starting worker discovery
19:43:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:43:06 DISPATCHER: Finished worker discovery
19:44:06 DISPATCHER: Starting worker discovery
19:44:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:44:06 DISPATCHER: Finished worker discovery
19:45:06 DISPATCHER: Starting worker discovery
19:45:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:45:06 DISPATCHER: Finished worker discovery
19:45:07 WORKER: done with job (1, 0, 2), trying to register it.
19:45:07 WORKER: registered result for job (1, 0, 2) with dispatcher
19:45:07 DISPATCHER: job (1, 0, 2) finished
19:45:07 DISPATCHER: register_result: lock acquired
19:45:07 DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
19:45:07 job_id: (1, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001190533617106509, 'num_filters_1': 120, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.02422290607184328}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5321049735714843, 'info': {'sick_no_sick': 0.5321049735714843, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001190533617106509, 'num_filters_1': 120, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.02422290607184328}"}}
exception: None

19:45:07 job_callback for (1, 0, 2) started
19:45:07 DISPATCHER: Trying to submit another job.
19:45:07 job_callback for (1, 0, 2) got condition
19:45:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:45:07 Only 12 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
19:45:07 HBMASTER: Trying to run another job!
19:45:07 job_callback for (1, 0, 2) finished
19:45:07 start sampling a new configuration.
19:45:07 done sampling a new configuration.
19:45:07 HBMASTER: schedule new run for iteration 1
19:45:07 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
19:45:07 HBMASTER: submitting job (1, 0, 3) to dispatcher
19:45:07 DISPATCHER: trying to submit job (1, 0, 3)
19:45:07 DISPATCHER: trying to notify the job_runner thread.
19:45:07 HBMASTER: job (1, 0, 3) submitted to dispatcher
19:45:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:45:07 DISPATCHER: Trying to submit another job.
19:45:07 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:45:07 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:45:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:45:07 WORKER: start processing job (1, 0, 3)
19:45:07 WORKER: args: ()
19:45:07 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.008223911002527413, 'num_filters_1': 25, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.08812579389338061, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 39, 'num_filters_3': 36, 'num_filters_4': 51, 'num_filters_5': 99}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:46:06 DISPATCHER: Starting worker discovery
19:46:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:46:06 DISPATCHER: Finished worker discovery
19:47:06 DISPATCHER: Starting worker discovery
19:47:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:47:06 DISPATCHER: Finished worker discovery
19:48:06 DISPATCHER: Starting worker discovery
19:48:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:48:06 DISPATCHER: Finished worker discovery
19:48:25 WORKER: done with job (1, 0, 3), trying to register it.
19:48:25 WORKER: registered result for job (1, 0, 3) with dispatcher
19:48:25 DISPATCHER: job (1, 0, 3) finished
19:48:25 DISPATCHER: register_result: lock acquired
19:48:25 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
19:48:25 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.008223911002527413, 'num_filters_1': 25, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.08812579389338061, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 39, 'num_filters_3': 36, 'num_filters_4': 51, 'num_filters_5': 99}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.008223911002527413, 'num_filters_1': 25, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.08812579389338061, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 39, 'num_filters_3': 36, 'num_filters_4': 51, 'num_filters_5': 99}"}}
exception: None

19:48:25 job_callback for (1, 0, 3) started
19:48:25 job_callback for (1, 0, 3) got condition
19:48:25 DISPATCHER: Trying to submit another job.
19:48:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:48:25 Only 13 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
19:48:25 HBMASTER: Trying to run another job!
19:48:25 job_callback for (1, 0, 3) finished
19:48:25 start sampling a new configuration.
19:48:25 done sampling a new configuration.
19:48:25 HBMASTER: schedule new run for iteration 1
19:48:25 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
19:48:25 HBMASTER: submitting job (1, 0, 4) to dispatcher
19:48:25 DISPATCHER: trying to submit job (1, 0, 4)
19:48:25 DISPATCHER: trying to notify the job_runner thread.
19:48:25 HBMASTER: job (1, 0, 4) submitted to dispatcher
19:48:25 DISPATCHER: Trying to submit another job.
19:48:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:48:25 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:48:25 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:48:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:48:25 WORKER: start processing job (1, 0, 4)
19:48:25 WORKER: args: ()
19:48:25 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.009555887854423586, 'num_filters_1': 44, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.12481247894310142, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 21, 'num_filters_3': 43, 'num_filters_4': 74, 'num_filters_5': 35}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:49:06 DISPATCHER: Starting worker discovery
19:49:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:49:06 DISPATCHER: Finished worker discovery
19:50:06 DISPATCHER: Starting worker discovery
19:50:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:50:06 DISPATCHER: Finished worker discovery
19:51:06 DISPATCHER: Starting worker discovery
19:51:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:51:06 DISPATCHER: Finished worker discovery
19:51:41 WORKER: done with job (1, 0, 4), trying to register it.
19:51:41 WORKER: registered result for job (1, 0, 4) with dispatcher
19:51:41 DISPATCHER: job (1, 0, 4) finished
19:51:41 DISPATCHER: register_result: lock acquired
19:51:41 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
19:51:41 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.009555887854423586, 'num_filters_1': 44, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.12481247894310142, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 21, 'num_filters_3': 43, 'num_filters_4': 74, 'num_filters_5': 35}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.009555887854423586, 'num_filters_1': 44, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.12481247894310142, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 21, 'num_filters_3': 43, 'num_filters_4': 74, 'num_filters_5': 35}"}}
exception: None

19:51:41 job_callback for (1, 0, 4) started
19:51:41 job_callback for (1, 0, 4) got condition
19:51:41 DISPATCHER: Trying to submit another job.
19:51:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:51:41 Only 14 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
19:51:41 HBMASTER: Trying to run another job!
19:51:41 job_callback for (1, 0, 4) finished
19:51:41 start sampling a new configuration.
19:51:41 done sampling a new configuration.
19:51:41 HBMASTER: schedule new run for iteration 1
19:51:41 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
19:51:41 HBMASTER: submitting job (1, 0, 5) to dispatcher
19:51:41 DISPATCHER: trying to submit job (1, 0, 5)
19:51:41 DISPATCHER: trying to notify the job_runner thread.
19:51:41 HBMASTER: job (1, 0, 5) submitted to dispatcher
19:51:41 DISPATCHER: Trying to submit another job.
19:51:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:51:41 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:51:41 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:51:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:51:41 WORKER: start processing job (1, 0, 5)
19:51:41 WORKER: args: ()
19:51:41 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.05962165902617458, 'num_filters_1': 92, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.1818832405232028, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 67, 'num_filters_3': 18, 'num_filters_4': 34, 'num_filters_5': 20}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:52:06 DISPATCHER: Starting worker discovery
19:52:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:52:06 DISPATCHER: Finished worker discovery
19:53:06 DISPATCHER: Starting worker discovery
19:53:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:53:06 DISPATCHER: Finished worker discovery
19:54:06 DISPATCHER: Starting worker discovery
19:54:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:54:06 DISPATCHER: Finished worker discovery
19:55:00 WORKER: done with job (1, 0, 5), trying to register it.
19:55:00 WORKER: registered result for job (1, 0, 5) with dispatcher
19:55:00 DISPATCHER: job (1, 0, 5) finished
19:55:00 DISPATCHER: register_result: lock acquired
19:55:00 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
19:55:00 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.05962165902617458, 'num_filters_1': 92, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.1818832405232028, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 67, 'num_filters_3': 18, 'num_filters_4': 34, 'num_filters_5': 20}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.05962165902617458, 'num_filters_1': 92, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.1818832405232028, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 67, 'num_filters_3': 18, 'num_filters_4': 34, 'num_filters_5': 20}"}}
exception: None

19:55:00 job_callback for (1, 0, 5) started
19:55:00 DISPATCHER: Trying to submit another job.
19:55:00 job_callback for (1, 0, 5) got condition
19:55:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:55:00 Only 15 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
19:55:00 HBMASTER: Trying to run another job!
19:55:00 job_callback for (1, 0, 5) finished
19:55:00 start sampling a new configuration.
19:55:00 done sampling a new configuration.
19:55:00 HBMASTER: schedule new run for iteration 1
19:55:00 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
19:55:00 HBMASTER: submitting job (1, 0, 6) to dispatcher
19:55:00 DISPATCHER: trying to submit job (1, 0, 6)
19:55:00 DISPATCHER: trying to notify the job_runner thread.
19:55:00 HBMASTER: job (1, 0, 6) submitted to dispatcher
19:55:00 DISPATCHER: Trying to submit another job.
19:55:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:55:00 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:55:00 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:55:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:55:00 WORKER: start processing job (1, 0, 6)
19:55:00 WORKER: args: ()
19:55:00 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.007680943314499339, 'num_filters_1': 45, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.0319709671919347, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 107, 'num_filters_3': 26, 'num_filters_4': 32, 'num_filters_5': 87}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:55:06 DISPATCHER: Starting worker discovery
19:55:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:55:06 DISPATCHER: Finished worker discovery
19:56:06 DISPATCHER: Starting worker discovery
19:56:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:56:06 DISPATCHER: Finished worker discovery
19:57:06 DISPATCHER: Starting worker discovery
19:57:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:57:06 DISPATCHER: Finished worker discovery
19:58:06 DISPATCHER: Starting worker discovery
19:58:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:58:06 DISPATCHER: Finished worker discovery
19:58:21 WORKER: done with job (1, 0, 6), trying to register it.
19:58:21 WORKER: registered result for job (1, 0, 6) with dispatcher
19:58:21 DISPATCHER: job (1, 0, 6) finished
19:58:21 DISPATCHER: register_result: lock acquired
19:58:21 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
19:58:21 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.007680943314499339, 'num_filters_1': 45, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.0319709671919347, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 107, 'num_filters_3': 26, 'num_filters_4': 32, 'num_filters_5': 87}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.47491539600691224, 'info': {'sick_no_sick': 0.47491539600691224, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.007680943314499339, 'num_filters_1': 45, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.0319709671919347, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 107, 'num_filters_3': 26, 'num_filters_4': 32, 'num_filters_5': 87}"}}
exception: None

19:58:21 job_callback for (1, 0, 6) started
19:58:21 job_callback for (1, 0, 6) got condition
19:58:21 DISPATCHER: Trying to submit another job.
19:58:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:58:21 Only 16 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
19:58:21 HBMASTER: Trying to run another job!
19:58:21 job_callback for (1, 0, 6) finished
19:58:21 start sampling a new configuration.
19:58:21 done sampling a new configuration.
19:58:21 HBMASTER: schedule new run for iteration 1
19:58:21 HBMASTER: trying submitting job (1, 0, 7) to dispatcher
19:58:21 HBMASTER: submitting job (1, 0, 7) to dispatcher
19:58:21 DISPATCHER: trying to submit job (1, 0, 7)
19:58:21 DISPATCHER: trying to notify the job_runner thread.
19:58:21 HBMASTER: job (1, 0, 7) submitted to dispatcher
19:58:21 DISPATCHER: Trying to submit another job.
19:58:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:58:21 DISPATCHER: starting job (1, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:58:21 DISPATCHER: job (1, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
19:58:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:58:21 WORKER: start processing job (1, 0, 7)
19:58:21 WORKER: args: ()
19:58:21 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0032021395986981845, 'num_filters_1': 98, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.010158642990158222, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 27, 'num_filters_3': 120}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:59:06 DISPATCHER: Starting worker discovery
19:59:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:59:06 DISPATCHER: Finished worker discovery
20:00:06 DISPATCHER: Starting worker discovery
20:00:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:00:06 DISPATCHER: Finished worker discovery
20:01:06 DISPATCHER: Starting worker discovery
20:01:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:01:06 DISPATCHER: Finished worker discovery
20:01:41 WORKER: done with job (1, 0, 7), trying to register it.
20:01:41 WORKER: registered result for job (1, 0, 7) with dispatcher
20:01:41 DISPATCHER: job (1, 0, 7) finished
20:01:41 DISPATCHER: register_result: lock acquired
20:01:41 DISPATCHER: job (1, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
20:01:41 job_id: (1, 0, 7)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0032021395986981845, 'num_filters_1': 98, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.010158642990158222, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 27, 'num_filters_3': 120}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.40686893767566135, 'info': {'sick_no_sick': 0.40686893767566135, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0032021395986981845, 'num_filters_1': 98, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.010158642990158222, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 27, 'num_filters_3': 120}"}}
exception: None

20:01:41 job_callback for (1, 0, 7) started
20:01:41 DISPATCHER: Trying to submit another job.
20:01:41 job_callback for (1, 0, 7) got condition
20:01:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:01:41 HBMASTER: Trying to run another job!
20:01:41 job_callback for (1, 0, 7) finished
20:01:41 start sampling a new configuration.
20:01:41 done sampling a new configuration.
20:01:41 HBMASTER: schedule new run for iteration 1
20:01:41 HBMASTER: trying submitting job (1, 0, 8) to dispatcher
20:01:41 HBMASTER: submitting job (1, 0, 8) to dispatcher
20:01:41 DISPATCHER: trying to submit job (1, 0, 8)
20:01:41 DISPATCHER: trying to notify the job_runner thread.
20:01:41 HBMASTER: job (1, 0, 8) submitted to dispatcher
20:01:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:01:41 DISPATCHER: Trying to submit another job.
20:01:41 DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776
20:01:41 DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
20:01:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:01:41 WORKER: start processing job (1, 0, 8)
20:01:41 WORKER: args: ()
20:01:41 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.004104288814554196, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.021669370216625402}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:02:06 DISPATCHER: Starting worker discovery
20:02:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:02:06 DISPATCHER: Finished worker discovery
20:03:06 DISPATCHER: Starting worker discovery
20:03:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:03:06 DISPATCHER: Finished worker discovery
20:04:06 DISPATCHER: Starting worker discovery
20:04:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:04:06 DISPATCHER: Finished worker discovery
20:05:00 WORKER: done with job (1, 0, 8), trying to register it.
20:05:00 WORKER: registered result for job (1, 0, 8) with dispatcher
20:05:00 DISPATCHER: job (1, 0, 8) finished
20:05:00 DISPATCHER: register_result: lock acquired
20:05:00 DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
20:05:00 job_id: (1, 0, 8)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.004104288814554196, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.021669370216625402}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3727071833825368, 'info': {'sick_no_sick': 0.3727071833825368, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.004104288814554196, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.021669370216625402}"}}
exception: None

20:05:00 job_callback for (1, 0, 8) started
20:05:00 DISPATCHER: Trying to submit another job.
20:05:00 job_callback for (1, 0, 8) got condition
20:05:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:05:00 HBMASTER: Trying to run another job!
20:05:00 job_callback for (1, 0, 8) finished
20:05:00 ITERATION: Advancing config (1, 0, 1) to next budget 400.000000
20:05:00 ITERATION: Advancing config (1, 0, 2) to next budget 400.000000
20:05:00 ITERATION: Advancing config (1, 0, 6) to next budget 400.000000
20:05:00 HBMASTER: schedule new run for iteration 1
20:05:00 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
20:05:00 HBMASTER: submitting job (1, 0, 1) to dispatcher
20:05:00 DISPATCHER: trying to submit job (1, 0, 1)
20:05:00 DISPATCHER: trying to notify the job_runner thread.
20:05:00 HBMASTER: job (1, 0, 1) submitted to dispatcher
20:05:00 DISPATCHER: Trying to submit another job.
20:05:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:05:00 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
20:05:00 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
20:05:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:05:00 WORKER: start processing job (1, 0, 1)
20:05:00 WORKER: args: ()
20:05:00 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0011526764525709335, 'num_filters_1': 78, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.0673775210900583}, 'budget': 400.0, 'working_directory': '.'}
20:05:06 DISPATCHER: Starting worker discovery
20:05:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:05:06 DISPATCHER: Finished worker discovery
20:06:06 DISPATCHER: Starting worker discovery
20:06:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:06:06 DISPATCHER: Finished worker discovery
20:07:06 DISPATCHER: Starting worker discovery
20:07:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:07:06 DISPATCHER: Finished worker discovery
20:08:06 DISPATCHER: Starting worker discovery
20:08:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:08:06 DISPATCHER: Finished worker discovery
20:09:06 DISPATCHER: Starting worker discovery
20:09:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:09:06 DISPATCHER: Finished worker discovery
20:10:06 DISPATCHER: Starting worker discovery
20:10:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:10:06 DISPATCHER: Finished worker discovery
20:11:06 DISPATCHER: Starting worker discovery
20:11:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:11:06 DISPATCHER: Finished worker discovery
20:12:06 DISPATCHER: Starting worker discovery
20:12:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:12:06 DISPATCHER: Finished worker discovery
20:12:46 WORKER: done with job (1, 0, 1), trying to register it.
20:12:46 WORKER: registered result for job (1, 0, 1) with dispatcher
20:12:46 DISPATCHER: job (1, 0, 1) finished
20:12:46 DISPATCHER: register_result: lock acquired
20:12:46 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
20:12:46 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0011526764525709335, 'num_filters_1': 78, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.0673775210900583}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5137237151391594, 'info': {'sick_no_sick': 0.5137237151391594, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0011526764525709335, 'num_filters_1': 78, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.0673775210900583}"}}
exception: None

20:12:46 job_callback for (1, 0, 1) started
20:12:46 job_callback for (1, 0, 1) got condition
20:12:46 DISPATCHER: Trying to submit another job.
20:12:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:12:46 Only 4 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
20:12:46 HBMASTER: Trying to run another job!
20:12:46 job_callback for (1, 0, 1) finished
20:12:46 HBMASTER: schedule new run for iteration 1
20:12:46 HBMASTER: trying submitting job (1, 0, 2) to dispatcher
20:12:46 HBMASTER: submitting job (1, 0, 2) to dispatcher
20:12:46 DISPATCHER: trying to submit job (1, 0, 2)
20:12:46 DISPATCHER: trying to notify the job_runner thread.
20:12:46 HBMASTER: job (1, 0, 2) submitted to dispatcher
20:12:46 DISPATCHER: Trying to submit another job.
20:12:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:12:46 DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
20:12:46 DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
20:12:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:12:46 WORKER: start processing job (1, 0, 2)
20:12:46 WORKER: args: ()
20:12:46 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001190533617106509, 'num_filters_1': 120, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.02422290607184328}, 'budget': 400.0, 'working_directory': '.'}
20:13:06 DISPATCHER: Starting worker discovery
20:13:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:13:06 DISPATCHER: Finished worker discovery
20:14:06 DISPATCHER: Starting worker discovery
20:14:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:14:06 DISPATCHER: Finished worker discovery
20:15:06 DISPATCHER: Starting worker discovery
20:15:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:15:06 DISPATCHER: Finished worker discovery
20:16:06 DISPATCHER: Starting worker discovery
20:16:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:16:06 DISPATCHER: Finished worker discovery
20:17:06 DISPATCHER: Starting worker discovery
20:17:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:17:06 DISPATCHER: Finished worker discovery
20:18:06 DISPATCHER: Starting worker discovery
20:18:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:18:06 DISPATCHER: Finished worker discovery
20:19:06 DISPATCHER: Starting worker discovery
20:19:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:19:06 DISPATCHER: Finished worker discovery
20:20:06 DISPATCHER: Starting worker discovery
20:20:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:20:06 DISPATCHER: Finished worker discovery
20:20:38 WORKER: done with job (1, 0, 2), trying to register it.
20:20:38 WORKER: registered result for job (1, 0, 2) with dispatcher
20:20:38 DISPATCHER: job (1, 0, 2) finished
20:20:38 DISPATCHER: register_result: lock acquired
20:20:38 DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
20:20:38 job_id: (1, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001190533617106509, 'num_filters_1': 120, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.02422290607184328}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5285220153145219, 'info': {'sick_no_sick': 0.5285220153145219, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001190533617106509, 'num_filters_1': 120, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.02422290607184328}"}}
exception: None

20:20:38 job_callback for (1, 0, 2) started
20:20:38 DISPATCHER: Trying to submit another job.
20:20:38 job_callback for (1, 0, 2) got condition
20:20:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:20:38 Only 5 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
20:20:38 HBMASTER: Trying to run another job!
20:20:38 job_callback for (1, 0, 2) finished
20:20:38 HBMASTER: schedule new run for iteration 1
20:20:38 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
20:20:38 HBMASTER: submitting job (1, 0, 6) to dispatcher
20:20:38 DISPATCHER: trying to submit job (1, 0, 6)
20:20:38 DISPATCHER: trying to notify the job_runner thread.
20:20:38 HBMASTER: job (1, 0, 6) submitted to dispatcher
20:20:38 DISPATCHER: Trying to submit another job.
20:20:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:20:38 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776
20:20:38 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
20:20:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:20:38 WORKER: start processing job (1, 0, 6)
20:20:38 WORKER: args: ()
20:20:38 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.007680943314499339, 'num_filters_1': 45, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.0319709671919347, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 107, 'num_filters_3': 26, 'num_filters_4': 32, 'num_filters_5': 87}, 'budget': 400.0, 'working_directory': '.'}
20:21:06 DISPATCHER: Starting worker discovery
20:21:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:21:06 DISPATCHER: Finished worker discovery
20:22:06 DISPATCHER: Starting worker discovery
20:22:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:22:07 DISPATCHER: Finished worker discovery
20:23:07 DISPATCHER: Starting worker discovery
20:23:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:23:07 DISPATCHER: Finished worker discovery
20:24:07 DISPATCHER: Starting worker discovery
20:24:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:24:07 DISPATCHER: Finished worker discovery
20:25:07 DISPATCHER: Starting worker discovery
20:25:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:25:07 DISPATCHER: Finished worker discovery
20:26:07 DISPATCHER: Starting worker discovery
20:26:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:26:07 DISPATCHER: Finished worker discovery
20:27:07 DISPATCHER: Starting worker discovery
20:27:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:27:07 DISPATCHER: Finished worker discovery
20:28:07 DISPATCHER: Starting worker discovery
20:28:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:28:07 DISPATCHER: Finished worker discovery
20:28:31 WORKER: done with job (1, 0, 6), trying to register it.
20:28:31 WORKER: registered result for job (1, 0, 6) with dispatcher
20:28:31 DISPATCHER: job (1, 0, 6) finished
20:28:31 DISPATCHER: register_result: lock acquired
20:28:31 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
20:28:31 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.007680943314499339, 'num_filters_1': 45, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.0319709671919347, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 107, 'num_filters_3': 26, 'num_filters_4': 32, 'num_filters_5': 87}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5867241819001279, 'info': {'sick_no_sick': 0.5867241819001279, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.007680943314499339, 'num_filters_1': 45, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.0319709671919347, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 107, 'num_filters_3': 26, 'num_filters_4': 32, 'num_filters_5': 87}"}}
exception: None

20:28:31 job_callback for (1, 0, 6) started
20:28:31 DISPATCHER: Trying to submit another job.
20:28:31 job_callback for (1, 0, 6) got condition
20:28:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:28:31 Only 6 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
20:28:31 HBMASTER: Trying to run another job!
20:28:31 job_callback for (1, 0, 6) finished
20:28:31 ITERATION: Advancing config (1, 0, 6) to next budget 1200.000000
20:28:31 HBMASTER: schedule new run for iteration 1
20:28:31 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
20:28:31 HBMASTER: submitting job (1, 0, 6) to dispatcher
20:28:31 DISPATCHER: trying to submit job (1, 0, 6)
20:28:31 DISPATCHER: trying to notify the job_runner thread.
20:28:31 HBMASTER: job (1, 0, 6) submitted to dispatcher
20:28:31 DISPATCHER: Trying to submit another job.
20:28:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:28:31 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776
20:28:31 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
20:28:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:28:31 WORKER: start processing job (1, 0, 6)
20:28:31 WORKER: args: ()
20:28:31 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.007680943314499339, 'num_filters_1': 45, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.0319709671919347, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 107, 'num_filters_3': 26, 'num_filters_4': 32, 'num_filters_5': 87}, 'budget': 1200.0, 'working_directory': '.'}
20:29:07 DISPATCHER: Starting worker discovery
20:29:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:29:07 DISPATCHER: Finished worker discovery
20:30:07 DISPATCHER: Starting worker discovery
20:30:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:30:07 DISPATCHER: Finished worker discovery
20:31:07 DISPATCHER: Starting worker discovery
20:31:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:31:07 DISPATCHER: Finished worker discovery
20:32:07 DISPATCHER: Starting worker discovery
20:32:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:32:07 DISPATCHER: Finished worker discovery
20:33:07 DISPATCHER: Starting worker discovery
20:33:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:33:07 DISPATCHER: Finished worker discovery
20:34:07 DISPATCHER: Starting worker discovery
20:34:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:34:07 DISPATCHER: Finished worker discovery
20:35:07 DISPATCHER: Starting worker discovery
20:35:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:35:07 DISPATCHER: Finished worker discovery
20:36:07 DISPATCHER: Starting worker discovery
20:36:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:36:07 DISPATCHER: Finished worker discovery
20:37:07 DISPATCHER: Starting worker discovery
20:37:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:37:07 DISPATCHER: Finished worker discovery
20:38:07 DISPATCHER: Starting worker discovery
20:38:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:38:07 DISPATCHER: Finished worker discovery
20:39:07 DISPATCHER: Starting worker discovery
20:39:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:39:07 DISPATCHER: Finished worker discovery
20:40:07 DISPATCHER: Starting worker discovery
20:40:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:40:07 DISPATCHER: Finished worker discovery
20:41:07 DISPATCHER: Starting worker discovery
20:41:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:41:07 DISPATCHER: Finished worker discovery
20:42:07 DISPATCHER: Starting worker discovery
20:42:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:42:07 DISPATCHER: Finished worker discovery
20:43:07 DISPATCHER: Starting worker discovery
20:43:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:43:07 DISPATCHER: Finished worker discovery
20:44:07 DISPATCHER: Starting worker discovery
20:44:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:44:07 DISPATCHER: Finished worker discovery
20:45:07 DISPATCHER: Starting worker discovery
20:45:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:45:07 DISPATCHER: Finished worker discovery
20:46:07 DISPATCHER: Starting worker discovery
20:46:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:46:07 DISPATCHER: Finished worker discovery
20:47:07 DISPATCHER: Starting worker discovery
20:47:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:47:07 DISPATCHER: Finished worker discovery
20:48:07 DISPATCHER: Starting worker discovery
20:48:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:48:07 DISPATCHER: Finished worker discovery
20:49:07 DISPATCHER: Starting worker discovery
20:49:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:49:07 DISPATCHER: Finished worker discovery
20:50:04 WORKER: done with job (1, 0, 6), trying to register it.
20:50:04 WORKER: registered result for job (1, 0, 6) with dispatcher
20:50:04 DISPATCHER: job (1, 0, 6) finished
20:50:04 DISPATCHER: register_result: lock acquired
20:50:04 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
20:50:04 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.007680943314499339, 'num_filters_1': 45, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.0319709671919347, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 107, 'num_filters_3': 26, 'num_filters_4': 32, 'num_filters_5': 87}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.21271284067507984, 'info': {'sick_no_sick': 0.21271284067507984, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.007680943314499339, 'num_filters_1': 45, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.0319709671919347, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 107, 'num_filters_3': 26, 'num_filters_4': 32, 'num_filters_5': 87}"}}
exception: None

20:50:04 job_callback for (1, 0, 6) started
20:50:04 DISPATCHER: Trying to submit another job.
20:50:04 job_callback for (1, 0, 6) got condition
20:50:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:50:04 Only 2 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
20:50:04 HBMASTER: Trying to run another job!
20:50:04 job_callback for (1, 0, 6) finished
20:50:04 start sampling a new configuration.
20:50:04 done sampling a new configuration.
20:50:04 HBMASTER: schedule new run for iteration 2
20:50:04 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
20:50:04 HBMASTER: submitting job (2, 0, 0) to dispatcher
20:50:04 DISPATCHER: trying to submit job (2, 0, 0)
20:50:04 DISPATCHER: trying to notify the job_runner thread.
20:50:04 HBMASTER: job (2, 0, 0) submitted to dispatcher
20:50:04 DISPATCHER: Trying to submit another job.
20:50:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:50:04 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
20:50:04 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
20:50:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:50:04 WORKER: start processing job (2, 0, 0)
20:50:04 WORKER: args: ()
20:50:04 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.02722644405971422, 'num_filters_1': 66, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.19176075407294813, 'kernel_size_2': 3, 'num_filters_2': 36}, 'budget': 400.0, 'working_directory': '.'}
20:50:07 DISPATCHER: Starting worker discovery
20:50:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:50:07 DISPATCHER: Finished worker discovery
Exception in thread Thread-655:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

20:51:07 DISPATCHER: Starting worker discovery
20:51:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:51:07 DISPATCHER: Finished worker discovery
20:52:07 DISPATCHER: Starting worker discovery
20:52:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:52:07 DISPATCHER: Finished worker discovery
20:53:07 DISPATCHER: Starting worker discovery
20:53:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:53:07 DISPATCHER: Finished worker discovery
20:54:07 DISPATCHER: Starting worker discovery
20:54:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:54:07 DISPATCHER: Finished worker discovery
20:55:07 DISPATCHER: Starting worker discovery
20:55:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:55:07 DISPATCHER: Finished worker discovery
20:56:07 DISPATCHER: Starting worker discovery
20:56:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:56:07 DISPATCHER: Finished worker discovery
20:57:07 DISPATCHER: Starting worker discovery
20:57:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:57:07 DISPATCHER: Finished worker discovery
20:57:44 WORKER: done with job (2, 0, 0), trying to register it.
20:57:44 WORKER: registered result for job (2, 0, 0) with dispatcher
20:57:44 DISPATCHER: job (2, 0, 0) finished
20:57:44 DISPATCHER: register_result: lock acquired
20:57:44 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
20:57:44 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.02722644405971422, 'num_filters_1': 66, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.19176075407294813, 'kernel_size_2': 3, 'num_filters_2': 36}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.2675693662673921, 'info': {'sick_no_sick': 0.2675693662673921, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.02722644405971422, 'num_filters_1': 66, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.19176075407294813, 'kernel_size_2': 3, 'num_filters_2': 36}"}}
exception: None

20:57:44 job_callback for (2, 0, 0) started
20:57:44 DISPATCHER: Trying to submit another job.
20:57:44 job_callback for (2, 0, 0) got condition
20:57:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:57:44 Only 7 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
20:57:44 HBMASTER: Trying to run another job!
20:57:44 job_callback for (2, 0, 0) finished
20:57:44 start sampling a new configuration.
20:57:44 done sampling a new configuration.
20:57:44 HBMASTER: schedule new run for iteration 2
20:57:44 HBMASTER: trying submitting job (2, 0, 1) to dispatcher
20:57:44 HBMASTER: submitting job (2, 0, 1) to dispatcher
20:57:44 DISPATCHER: trying to submit job (2, 0, 1)
20:57:44 DISPATCHER: trying to notify the job_runner thread.
20:57:44 HBMASTER: job (2, 0, 1) submitted to dispatcher
20:57:44 DISPATCHER: Trying to submit another job.
20:57:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:57:44 DISPATCHER: starting job (2, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
20:57:44 DISPATCHER: job (2, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
20:57:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:57:44 WORKER: start processing job (2, 0, 1)
20:57:44 WORKER: args: ()
20:57:44 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.015456669769087597, 'num_filters_1': 34, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.02024271212032921, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 119, 'num_filters_3': 20}, 'budget': 400.0, 'working_directory': '.'}
20:58:07 DISPATCHER: Starting worker discovery
20:58:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:58:07 DISPATCHER: Finished worker discovery
20:59:07 DISPATCHER: Starting worker discovery
20:59:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:59:07 DISPATCHER: Finished worker discovery
21:00:07 DISPATCHER: Starting worker discovery
21:00:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:00:07 DISPATCHER: Finished worker discovery
21:01:07 DISPATCHER: Starting worker discovery
21:01:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:01:07 DISPATCHER: Finished worker discovery
21:02:07 DISPATCHER: Starting worker discovery
21:02:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:02:07 DISPATCHER: Finished worker discovery
21:03:07 DISPATCHER: Starting worker discovery
21:03:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:03:07 DISPATCHER: Finished worker discovery
21:04:07 DISPATCHER: Starting worker discovery
21:04:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:04:07 DISPATCHER: Finished worker discovery
21:05:07 DISPATCHER: Starting worker discovery
21:05:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:05:07 DISPATCHER: Finished worker discovery
21:05:30 WORKER: done with job (2, 0, 1), trying to register it.
21:05:30 WORKER: registered result for job (2, 0, 1) with dispatcher
21:05:30 DISPATCHER: job (2, 0, 1) finished
21:05:30 DISPATCHER: register_result: lock acquired
21:05:30 DISPATCHER: job (2, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
21:05:30 job_id: (2, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.015456669769087597, 'num_filters_1': 34, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.02024271212032921, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 119, 'num_filters_3': 20}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.015456669769087597, 'num_filters_1': 34, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.02024271212032921, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 119, 'num_filters_3': 20}"}}
exception: None

21:05:30 job_callback for (2, 0, 1) started
21:05:30 DISPATCHER: Trying to submit another job.
21:05:30 job_callback for (2, 0, 1) got condition
21:05:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:05:30 Only 8 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
21:05:30 HBMASTER: Trying to run another job!
21:05:30 job_callback for (2, 0, 1) finished
21:05:30 start sampling a new configuration.
21:05:30 done sampling a new configuration.
21:05:30 HBMASTER: schedule new run for iteration 2
21:05:30 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
21:05:30 HBMASTER: submitting job (2, 0, 2) to dispatcher
21:05:30 DISPATCHER: trying to submit job (2, 0, 2)
21:05:30 DISPATCHER: trying to notify the job_runner thread.
21:05:30 HBMASTER: job (2, 0, 2) submitted to dispatcher
21:05:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:05:30 DISPATCHER: Trying to submit another job.
21:05:30 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
21:05:30 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
21:05:30 WORKER: start processing job (2, 0, 2)
21:05:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:05:30 WORKER: args: ()
21:05:30 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.010007753809815882, 'num_filters_1': 51, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.0810928975793626}, 'budget': 400.0, 'working_directory': '.'}
21:06:07 DISPATCHER: Starting worker discovery
21:06:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:06:07 DISPATCHER: Finished worker discovery
21:07:07 DISPATCHER: Starting worker discovery
21:07:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:07:07 DISPATCHER: Finished worker discovery
21:08:07 DISPATCHER: Starting worker discovery
21:08:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:08:07 DISPATCHER: Finished worker discovery
21:09:07 DISPATCHER: Starting worker discovery
21:09:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:09:07 DISPATCHER: Finished worker discovery
21:10:07 DISPATCHER: Starting worker discovery
21:10:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:10:07 DISPATCHER: Finished worker discovery
21:11:07 DISPATCHER: Starting worker discovery
21:11:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:11:07 DISPATCHER: Finished worker discovery
21:12:07 DISPATCHER: Starting worker discovery
21:12:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:12:07 DISPATCHER: Finished worker discovery
21:13:07 DISPATCHER: Starting worker discovery
21:13:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:13:07 DISPATCHER: Finished worker discovery
21:13:15 WORKER: done with job (2, 0, 2), trying to register it.
21:13:15 WORKER: registered result for job (2, 0, 2) with dispatcher
21:13:15 DISPATCHER: job (2, 0, 2) finished
21:13:15 DISPATCHER: register_result: lock acquired
21:13:15 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
21:13:15 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.010007753809815882, 'num_filters_1': 51, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.0810928975793626}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3241734014726091, 'info': {'sick_no_sick': 0.3241734014726091, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.010007753809815882, 'num_filters_1': 51, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.0810928975793626}"}}
exception: None

21:13:15 job_callback for (2, 0, 2) started
21:13:15 job_callback for (2, 0, 2) got condition
21:13:15 DISPATCHER: Trying to submit another job.
21:13:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:13:15 Only 9 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
21:13:15 HBMASTER: Trying to run another job!
21:13:15 job_callback for (2, 0, 2) finished
21:13:15 start sampling a new configuration.
21:13:15 done sampling a new configuration.
21:13:15 HBMASTER: schedule new run for iteration 2
21:13:15 HBMASTER: trying submitting job (2, 0, 3) to dispatcher
21:13:15 HBMASTER: submitting job (2, 0, 3) to dispatcher
21:13:15 DISPATCHER: trying to submit job (2, 0, 3)
21:13:15 DISPATCHER: trying to notify the job_runner thread.
21:13:15 HBMASTER: job (2, 0, 3) submitted to dispatcher
21:13:15 DISPATCHER: Trying to submit another job.
21:13:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:13:15 DISPATCHER: starting job (2, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
21:13:15 DISPATCHER: job (2, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
21:13:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:13:15 WORKER: start processing job (2, 0, 3)
21:13:15 WORKER: args: ()
21:13:15 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0037818234995289773, 'num_filters_1': 38, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.055324345359262055, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 78, 'num_filters_3': 48, 'num_filters_4': 40}, 'budget': 400.0, 'working_directory': '.'}
21:14:07 DISPATCHER: Starting worker discovery
21:14:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:14:07 DISPATCHER: Finished worker discovery
21:15:07 DISPATCHER: Starting worker discovery
21:15:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:15:07 DISPATCHER: Finished worker discovery
21:16:07 DISPATCHER: Starting worker discovery
21:16:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:16:07 DISPATCHER: Finished worker discovery
21:17:07 DISPATCHER: Starting worker discovery
21:17:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:17:07 DISPATCHER: Finished worker discovery
21:18:07 DISPATCHER: Starting worker discovery
21:18:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:18:07 DISPATCHER: Finished worker discovery
21:19:07 DISPATCHER: Starting worker discovery
21:19:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:19:07 DISPATCHER: Finished worker discovery
21:20:07 DISPATCHER: Starting worker discovery
21:20:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:20:07 DISPATCHER: Finished worker discovery
21:21:03 WORKER: done with job (2, 0, 3), trying to register it.
21:21:03 WORKER: registered result for job (2, 0, 3) with dispatcher
21:21:03 DISPATCHER: job (2, 0, 3) finished
21:21:03 DISPATCHER: register_result: lock acquired
21:21:03 DISPATCHER: job (2, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
21:21:03 job_id: (2, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0037818234995289773, 'num_filters_1': 38, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.055324345359262055, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 78, 'num_filters_3': 48, 'num_filters_4': 40}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0037818234995289773, 'num_filters_1': 38, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.055324345359262055, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 78, 'num_filters_3': 48, 'num_filters_4': 40}"}}
exception: None

21:21:03 job_callback for (2, 0, 3) started
21:21:03 job_callback for (2, 0, 3) got condition
21:21:03 DISPATCHER: Trying to submit another job.
21:21:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:21:03 Only 10 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
21:21:03 HBMASTER: Trying to run another job!
21:21:03 job_callback for (2, 0, 3) finished
21:21:03 start sampling a new configuration.
21:21:03 done sampling a new configuration.
21:21:03 HBMASTER: schedule new run for iteration 2
21:21:03 HBMASTER: trying submitting job (2, 0, 4) to dispatcher
21:21:03 HBMASTER: submitting job (2, 0, 4) to dispatcher
21:21:03 DISPATCHER: trying to submit job (2, 0, 4)
21:21:03 DISPATCHER: trying to notify the job_runner thread.
21:21:03 HBMASTER: job (2, 0, 4) submitted to dispatcher
21:21:03 DISPATCHER: Trying to submit another job.
21:21:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:21:03 DISPATCHER: starting job (2, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776
21:21:03 DISPATCHER: job (2, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
21:21:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:21:03 WORKER: start processing job (2, 0, 4)
21:21:03 WORKER: args: ()
21:21:03 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.06206267732622469, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.010200631091985156, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 40, 'num_filters_3': 17, 'num_filters_4': 25, 'num_filters_5': 19}, 'budget': 400.0, 'working_directory': '.'}
21:21:07 DISPATCHER: Starting worker discovery
21:21:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:21:07 DISPATCHER: Finished worker discovery
21:22:07 DISPATCHER: Starting worker discovery
21:22:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:22:07 DISPATCHER: Finished worker discovery
21:23:07 DISPATCHER: Starting worker discovery
21:23:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:23:07 DISPATCHER: Finished worker discovery
21:24:07 DISPATCHER: Starting worker discovery
21:24:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:24:07 DISPATCHER: Finished worker discovery
21:25:07 DISPATCHER: Starting worker discovery
21:25:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:25:07 DISPATCHER: Finished worker discovery
21:26:07 DISPATCHER: Starting worker discovery
21:26:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:26:07 DISPATCHER: Finished worker discovery
21:27:07 DISPATCHER: Starting worker discovery
21:27:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:27:07 DISPATCHER: Finished worker discovery
21:28:07 DISPATCHER: Starting worker discovery
21:28:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:28:07 DISPATCHER: Finished worker discovery
21:28:48 WORKER: done with job (2, 0, 4), trying to register it.
21:28:48 WORKER: registered result for job (2, 0, 4) with dispatcher
21:28:48 DISPATCHER: job (2, 0, 4) finished
21:28:48 DISPATCHER: register_result: lock acquired
21:28:48 DISPATCHER: job (2, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
21:28:48 job_id: (2, 0, 4)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.06206267732622469, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.010200631091985156, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 40, 'num_filters_3': 17, 'num_filters_4': 25, 'num_filters_5': 19}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.06206267732622469, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.010200631091985156, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 40, 'num_filters_3': 17, 'num_filters_4': 25, 'num_filters_5': 19}"}}
exception: None

21:28:48 job_callback for (2, 0, 4) started
21:28:48 DISPATCHER: Trying to submit another job.
21:28:48 job_callback for (2, 0, 4) got condition
21:28:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:28:48 Only 11 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
21:28:48 HBMASTER: Trying to run another job!
21:28:48 job_callback for (2, 0, 4) finished
21:28:48 start sampling a new configuration.
21:28:48 done sampling a new configuration.
21:28:48 HBMASTER: schedule new run for iteration 2
21:28:48 HBMASTER: trying submitting job (2, 0, 5) to dispatcher
21:28:48 HBMASTER: submitting job (2, 0, 5) to dispatcher
21:28:48 DISPATCHER: trying to submit job (2, 0, 5)
21:28:48 DISPATCHER: trying to notify the job_runner thread.
21:28:48 HBMASTER: job (2, 0, 5) submitted to dispatcher
21:28:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:28:48 DISPATCHER: Trying to submit another job.
21:28:48 DISPATCHER: starting job (2, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776
21:28:48 DISPATCHER: job (2, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
21:28:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:28:48 WORKER: start processing job (2, 0, 5)
21:28:48 WORKER: args: ()
21:28:48 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0026142692480385877, 'num_filters_1': 50, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.019542552701449275}, 'budget': 400.0, 'working_directory': '.'}
21:29:07 DISPATCHER: Starting worker discovery
21:29:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:29:07 DISPATCHER: Finished worker discovery
21:30:07 DISPATCHER: Starting worker discovery
21:30:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:30:07 DISPATCHER: Finished worker discovery
21:31:07 DISPATCHER: Starting worker discovery
21:31:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:31:07 DISPATCHER: Finished worker discovery
21:32:07 DISPATCHER: Starting worker discovery
21:32:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:32:08 DISPATCHER: Finished worker discovery
21:33:08 DISPATCHER: Starting worker discovery
21:33:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:33:08 DISPATCHER: Finished worker discovery
21:34:08 DISPATCHER: Starting worker discovery
21:34:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:34:08 DISPATCHER: Finished worker discovery
21:35:08 DISPATCHER: Starting worker discovery
21:35:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:35:08 DISPATCHER: Finished worker discovery
21:36:08 DISPATCHER: Starting worker discovery
21:36:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:36:08 DISPATCHER: Finished worker discovery
21:36:37 WORKER: done with job (2, 0, 5), trying to register it.
21:36:37 WORKER: registered result for job (2, 0, 5) with dispatcher
21:36:37 DISPATCHER: job (2, 0, 5) finished
21:36:37 DISPATCHER: register_result: lock acquired
21:36:37 DISPATCHER: job (2, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
21:36:37 job_id: (2, 0, 5)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0026142692480385877, 'num_filters_1': 50, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.019542552701449275}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.4909668508620726, 'info': {'sick_no_sick': 0.4909668508620726, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0026142692480385877, 'num_filters_1': 50, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.019542552701449275}"}}
exception: None

21:36:37 job_callback for (2, 0, 5) started
21:36:37 DISPATCHER: Trying to submit another job.
21:36:37 job_callback for (2, 0, 5) got condition
21:36:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:36:38 Only 12 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
21:36:38 HBMASTER: Trying to run another job!
21:36:38 job_callback for (2, 0, 5) finished
21:36:38 ITERATION: Advancing config (2, 0, 2) to next budget 1200.000000
21:36:38 ITERATION: Advancing config (2, 0, 5) to next budget 1200.000000
21:36:38 HBMASTER: schedule new run for iteration 2
21:36:38 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
21:36:38 HBMASTER: submitting job (2, 0, 2) to dispatcher
21:36:38 DISPATCHER: trying to submit job (2, 0, 2)
21:36:38 DISPATCHER: trying to notify the job_runner thread.
21:36:38 HBMASTER: job (2, 0, 2) submitted to dispatcher
21:36:38 DISPATCHER: Trying to submit another job.
21:36:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:36:38 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
21:36:38 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
21:36:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:36:38 WORKER: start processing job (2, 0, 2)
21:36:38 WORKER: args: ()
21:36:38 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.010007753809815882, 'num_filters_1': 51, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.0810928975793626}, 'budget': 1200.0, 'working_directory': '.'}
21:37:08 DISPATCHER: Starting worker discovery
21:37:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:37:08 DISPATCHER: Finished worker discovery
21:38:08 DISPATCHER: Starting worker discovery
21:38:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:38:08 DISPATCHER: Finished worker discovery
21:39:08 DISPATCHER: Starting worker discovery
21:39:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:39:08 DISPATCHER: Finished worker discovery
21:40:08 DISPATCHER: Starting worker discovery
21:40:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:40:08 DISPATCHER: Finished worker discovery
21:41:08 DISPATCHER: Starting worker discovery
21:41:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:41:08 DISPATCHER: Finished worker discovery
21:42:08 DISPATCHER: Starting worker discovery
21:42:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:42:08 DISPATCHER: Finished worker discovery
21:43:08 DISPATCHER: Starting worker discovery
21:43:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:43:08 DISPATCHER: Finished worker discovery
21:44:08 DISPATCHER: Starting worker discovery
21:44:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:44:08 DISPATCHER: Finished worker discovery
21:45:08 DISPATCHER: Starting worker discovery
21:45:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:45:08 DISPATCHER: Finished worker discovery
21:46:08 DISPATCHER: Starting worker discovery
21:46:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:46:08 DISPATCHER: Finished worker discovery
21:47:08 DISPATCHER: Starting worker discovery
21:47:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:47:08 DISPATCHER: Finished worker discovery
21:48:08 DISPATCHER: Starting worker discovery
21:48:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:48:08 DISPATCHER: Finished worker discovery
21:49:08 DISPATCHER: Starting worker discovery
21:49:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:49:08 DISPATCHER: Finished worker discovery
21:50:08 DISPATCHER: Starting worker discovery
21:50:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:50:08 DISPATCHER: Finished worker discovery
21:51:08 DISPATCHER: Starting worker discovery
21:51:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:51:08 DISPATCHER: Finished worker discovery
21:52:08 DISPATCHER: Starting worker discovery
21:52:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:52:08 DISPATCHER: Finished worker discovery
21:53:08 DISPATCHER: Starting worker discovery
21:53:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:53:08 DISPATCHER: Finished worker discovery
21:54:08 DISPATCHER: Starting worker discovery
21:54:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:54:08 DISPATCHER: Finished worker discovery
21:55:08 DISPATCHER: Starting worker discovery
21:55:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:55:08 DISPATCHER: Finished worker discovery
21:56:08 DISPATCHER: Starting worker discovery
21:56:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:56:08 DISPATCHER: Finished worker discovery
21:57:08 DISPATCHER: Starting worker discovery
21:57:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:57:08 DISPATCHER: Finished worker discovery
21:57:53 WORKER: done with job (2, 0, 2), trying to register it.
21:57:53 WORKER: registered result for job (2, 0, 2) with dispatcher
21:57:53 DISPATCHER: job (2, 0, 2) finished
21:57:53 DISPATCHER: register_result: lock acquired
21:57:53 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
21:57:53 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.010007753809815882, 'num_filters_1': 51, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.0810928975793626}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.29524511008895693, 'info': {'sick_no_sick': 0.29524511008895693, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.010007753809815882, 'num_filters_1': 51, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.0810928975793626}"}}
exception: None

21:57:53 job_callback for (2, 0, 2) started
21:57:53 DISPATCHER: Trying to submit another job.
21:57:53 job_callback for (2, 0, 2) got condition
21:57:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:57:53 Only 3 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
21:57:53 HBMASTER: Trying to run another job!
21:57:53 job_callback for (2, 0, 2) finished
21:57:53 HBMASTER: schedule new run for iteration 2
21:57:53 HBMASTER: trying submitting job (2, 0, 5) to dispatcher
21:57:53 HBMASTER: submitting job (2, 0, 5) to dispatcher
21:57:53 DISPATCHER: trying to submit job (2, 0, 5)
21:57:53 DISPATCHER: trying to notify the job_runner thread.
21:57:53 HBMASTER: job (2, 0, 5) submitted to dispatcher
21:57:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:57:53 DISPATCHER: Trying to submit another job.
21:57:53 DISPATCHER: starting job (2, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776
21:57:53 DISPATCHER: job (2, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
21:57:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:57:53 WORKER: start processing job (2, 0, 5)
21:57:53 WORKER: args: ()
21:57:53 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0026142692480385877, 'num_filters_1': 50, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.019542552701449275}, 'budget': 1200.0, 'working_directory': '.'}
21:58:08 DISPATCHER: Starting worker discovery
21:58:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:58:08 DISPATCHER: Finished worker discovery
21:59:08 DISPATCHER: Starting worker discovery
21:59:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:59:08 DISPATCHER: Finished worker discovery
22:00:08 DISPATCHER: Starting worker discovery
22:00:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:00:08 DISPATCHER: Finished worker discovery
22:01:08 DISPATCHER: Starting worker discovery
22:01:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:01:08 DISPATCHER: Finished worker discovery
22:02:08 DISPATCHER: Starting worker discovery
22:02:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:02:08 DISPATCHER: Finished worker discovery
22:03:08 DISPATCHER: Starting worker discovery
22:03:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:03:08 DISPATCHER: Finished worker discovery
22:04:08 DISPATCHER: Starting worker discovery
22:04:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:04:08 DISPATCHER: Finished worker discovery
22:05:08 DISPATCHER: Starting worker discovery
22:05:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:05:08 DISPATCHER: Finished worker discovery
22:06:08 DISPATCHER: Starting worker discovery
22:06:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:06:08 DISPATCHER: Finished worker discovery
22:07:08 DISPATCHER: Starting worker discovery
22:07:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:07:08 DISPATCHER: Finished worker discovery
22:08:08 DISPATCHER: Starting worker discovery
22:08:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:08:08 DISPATCHER: Finished worker discovery
22:09:08 DISPATCHER: Starting worker discovery
22:09:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:09:08 DISPATCHER: Finished worker discovery
22:10:08 DISPATCHER: Starting worker discovery
22:10:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:10:08 DISPATCHER: Finished worker discovery
22:11:08 DISPATCHER: Starting worker discovery
22:11:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:11:08 DISPATCHER: Finished worker discovery
22:12:08 DISPATCHER: Starting worker discovery
22:12:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:12:08 DISPATCHER: Finished worker discovery
22:13:08 DISPATCHER: Starting worker discovery
22:13:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:13:08 DISPATCHER: Finished worker discovery
22:14:08 DISPATCHER: Starting worker discovery
22:14:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:14:08 DISPATCHER: Finished worker discovery
22:15:08 DISPATCHER: Starting worker discovery
22:15:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:15:08 DISPATCHER: Finished worker discovery
22:16:08 DISPATCHER: Starting worker discovery
22:16:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:16:08 DISPATCHER: Finished worker discovery
22:17:08 DISPATCHER: Starting worker discovery
22:17:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:17:08 DISPATCHER: Finished worker discovery
22:18:08 DISPATCHER: Starting worker discovery
22:18:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:18:08 DISPATCHER: Finished worker discovery
22:19:08 DISPATCHER: Starting worker discovery
22:19:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:19:08 DISPATCHER: Finished worker discovery
22:19:18 WORKER: done with job (2, 0, 5), trying to register it.
22:19:18 WORKER: registered result for job (2, 0, 5) with dispatcher
22:19:18 DISPATCHER: job (2, 0, 5) finished
22:19:18 DISPATCHER: register_result: lock acquired
22:19:18 DISPATCHER: job (2, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
22:19:18 job_id: (2, 0, 5)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0026142692480385877, 'num_filters_1': 50, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.019542552701449275}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.45527805199349114, 'info': {'sick_no_sick': 0.45527805199349114, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0026142692480385877, 'num_filters_1': 50, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.019542552701449275}"}}
exception: None

22:19:18 job_callback for (2, 0, 5) started
22:19:18 job_callback for (2, 0, 5) got condition
22:19:18 DISPATCHER: Trying to submit another job.
22:19:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:19:18 Only 4 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
22:19:18 HBMASTER: Trying to run another job!
22:19:18 job_callback for (2, 0, 5) finished
22:19:18 start sampling a new configuration.
22:19:18 done sampling a new configuration.
22:19:18 HBMASTER: schedule new run for iteration 3
22:19:18 HBMASTER: trying submitting job (3, 0, 0) to dispatcher
22:19:18 HBMASTER: submitting job (3, 0, 0) to dispatcher
22:19:18 DISPATCHER: trying to submit job (3, 0, 0)
22:19:18 DISPATCHER: trying to notify the job_runner thread.
22:19:18 HBMASTER: job (3, 0, 0) submitted to dispatcher
22:19:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:19:18 DISPATCHER: Trying to submit another job.
22:19:18 DISPATCHER: starting job (3, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
22:19:18 DISPATCHER: job (3, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
22:19:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:19:18 WORKER: start processing job (3, 0, 0)
22:19:18 WORKER: args: ()
22:19:18 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.011822252808517208, 'num_filters_1': 30, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.010676006468752173, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 54, 'num_filters_3': 25}, 'budget': 1200.0, 'working_directory': '.'}
22:20:08 DISPATCHER: Starting worker discovery
22:20:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:20:08 DISPATCHER: Finished worker discovery
22:21:08 DISPATCHER: Starting worker discovery
22:21:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:21:08 DISPATCHER: Finished worker discovery
22:22:08 DISPATCHER: Starting worker discovery
22:22:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:22:08 DISPATCHER: Finished worker discovery
22:23:08 DISPATCHER: Starting worker discovery
22:23:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:23:08 DISPATCHER: Finished worker discovery
22:24:08 DISPATCHER: Starting worker discovery
22:24:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:24:08 DISPATCHER: Finished worker discovery
22:25:08 DISPATCHER: Starting worker discovery
22:25:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:25:08 DISPATCHER: Finished worker discovery
22:26:08 DISPATCHER: Starting worker discovery
22:26:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:26:08 DISPATCHER: Finished worker discovery
22:27:08 DISPATCHER: Starting worker discovery
22:27:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:27:08 DISPATCHER: Finished worker discovery
22:28:08 DISPATCHER: Starting worker discovery
22:28:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:28:08 DISPATCHER: Finished worker discovery
22:29:08 DISPATCHER: Starting worker discovery
22:29:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:29:08 DISPATCHER: Finished worker discovery
22:30:08 DISPATCHER: Starting worker discovery
22:30:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:30:08 DISPATCHER: Finished worker discovery
22:31:08 DISPATCHER: Starting worker discovery
22:31:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:31:08 DISPATCHER: Finished worker discovery
22:32:08 DISPATCHER: Starting worker discovery
22:32:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:32:08 DISPATCHER: Finished worker discovery
22:33:08 DISPATCHER: Starting worker discovery
22:33:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:33:08 DISPATCHER: Finished worker discovery
22:34:08 DISPATCHER: Starting worker discovery
22:34:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:34:08 DISPATCHER: Finished worker discovery
22:35:08 DISPATCHER: Starting worker discovery
22:35:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:35:08 DISPATCHER: Finished worker discovery
22:36:08 DISPATCHER: Starting worker discovery
22:36:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:36:08 DISPATCHER: Finished worker discovery
22:37:08 DISPATCHER: Starting worker discovery
22:37:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:37:08 DISPATCHER: Finished worker discovery
22:38:08 DISPATCHER: Starting worker discovery
22:38:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:38:08 DISPATCHER: Finished worker discovery
22:39:08 DISPATCHER: Starting worker discovery
22:39:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:39:08 DISPATCHER: Finished worker discovery
22:40:08 DISPATCHER: Starting worker discovery
22:40:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:40:09 DISPATCHER: Finished worker discovery
22:40:55 WORKER: done with job (3, 0, 0), trying to register it.
22:40:55 WORKER: registered result for job (3, 0, 0) with dispatcher
22:40:55 DISPATCHER: job (3, 0, 0) finished
22:40:55 DISPATCHER: register_result: lock acquired
22:40:55 DISPATCHER: job (3, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
22:40:55 job_id: (3, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.011822252808517208, 'num_filters_1': 30, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.010676006468752173, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 54, 'num_filters_3': 25}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5250026900558207, 'info': {'sick_no_sick': 0.5250026900558207, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.011822252808517208, 'num_filters_1': 30, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.010676006468752173, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 54, 'num_filters_3': 25}"}}
exception: None

22:40:55 job_callback for (3, 0, 0) started
22:40:55 DISPATCHER: Trying to submit another job.
22:40:55 job_callback for (3, 0, 0) got condition
22:40:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:40:55 Only 5 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
22:40:55 HBMASTER: Trying to run another job!
22:40:55 job_callback for (3, 0, 0) finished
22:40:55 start sampling a new configuration.
22:40:55 done sampling a new configuration.
22:40:55 HBMASTER: schedule new run for iteration 3
22:40:55 HBMASTER: trying submitting job (3, 0, 1) to dispatcher
22:40:55 HBMASTER: submitting job (3, 0, 1) to dispatcher
22:40:55 DISPATCHER: trying to submit job (3, 0, 1)
22:40:55 DISPATCHER: trying to notify the job_runner thread.
22:40:55 HBMASTER: job (3, 0, 1) submitted to dispatcher
22:40:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:40:55 DISPATCHER: Trying to submit another job.
22:40:55 DISPATCHER: starting job (3, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
22:40:55 DISPATCHER: job (3, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
22:40:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:40:55 WORKER: start processing job (3, 0, 1)
22:40:55 WORKER: args: ()
22:40:55 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0012842935812833163, 'num_filters_1': 66, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.042113225376845746, 'kernel_size_2': 3, 'num_filters_2': 26}, 'budget': 1200.0, 'working_directory': '.'}
22:41:09 DISPATCHER: Starting worker discovery
22:41:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:41:09 DISPATCHER: Finished worker discovery
22:42:09 DISPATCHER: Starting worker discovery
22:42:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:42:09 DISPATCHER: Finished worker discovery
22:43:09 DISPATCHER: Starting worker discovery
22:43:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:43:09 DISPATCHER: Finished worker discovery
22:44:09 DISPATCHER: Starting worker discovery
22:44:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:44:09 DISPATCHER: Finished worker discovery
22:45:09 DISPATCHER: Starting worker discovery
22:45:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:45:09 DISPATCHER: Finished worker discovery
22:46:09 DISPATCHER: Starting worker discovery
22:46:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:46:09 DISPATCHER: Finished worker discovery
22:47:09 DISPATCHER: Starting worker discovery
22:47:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:47:09 DISPATCHER: Finished worker discovery
22:48:09 DISPATCHER: Starting worker discovery
22:48:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:48:09 DISPATCHER: Finished worker discovery
22:49:09 DISPATCHER: Starting worker discovery
22:49:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:49:09 DISPATCHER: Finished worker discovery
22:50:09 DISPATCHER: Starting worker discovery
22:50:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:50:09 DISPATCHER: Finished worker discovery
22:51:09 DISPATCHER: Starting worker discovery
22:51:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:51:09 DISPATCHER: Finished worker discovery
22:52:09 DISPATCHER: Starting worker discovery
22:52:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:52:09 DISPATCHER: Finished worker discovery
22:53:09 DISPATCHER: Starting worker discovery
22:53:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:53:09 DISPATCHER: Finished worker discovery
22:54:09 DISPATCHER: Starting worker discovery
22:54:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:54:09 DISPATCHER: Finished worker discovery
22:55:09 DISPATCHER: Starting worker discovery
22:55:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:55:09 DISPATCHER: Finished worker discovery
22:56:09 DISPATCHER: Starting worker discovery
22:56:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:56:09 DISPATCHER: Finished worker discovery
22:57:09 DISPATCHER: Starting worker discovery
22:57:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:57:09 DISPATCHER: Finished worker discovery
22:58:09 DISPATCHER: Starting worker discovery
22:58:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:58:09 DISPATCHER: Finished worker discovery
22:59:09 DISPATCHER: Starting worker discovery
22:59:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:59:09 DISPATCHER: Finished worker discovery
23:00:09 DISPATCHER: Starting worker discovery
23:00:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:00:09 DISPATCHER: Finished worker discovery
23:01:09 DISPATCHER: Starting worker discovery
23:01:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:01:09 DISPATCHER: Finished worker discovery
23:02:09 DISPATCHER: Starting worker discovery
23:02:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:02:09 DISPATCHER: Finished worker discovery
23:02:54 WORKER: done with job (3, 0, 1), trying to register it.
23:02:54 WORKER: registered result for job (3, 0, 1) with dispatcher
23:02:54 DISPATCHER: job (3, 0, 1) finished
23:02:54 DISPATCHER: register_result: lock acquired
23:02:54 DISPATCHER: job (3, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
23:02:54 job_id: (3, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0012842935812833163, 'num_filters_1': 66, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.042113225376845746, 'kernel_size_2': 3, 'num_filters_2': 26}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.457505082737535, 'info': {'sick_no_sick': 0.457505082737535, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0012842935812833163, 'num_filters_1': 66, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.042113225376845746, 'kernel_size_2': 3, 'num_filters_2': 26}"}}
exception: None

23:02:54 job_callback for (3, 0, 1) started
23:02:54 job_callback for (3, 0, 1) got condition
23:02:54 DISPATCHER: Trying to submit another job.
23:02:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:02:54 Only 6 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
23:02:54 HBMASTER: Trying to run another job!
23:02:54 job_callback for (3, 0, 1) finished
23:02:54 start sampling a new configuration.
23:02:54 done sampling a new configuration.
23:02:54 HBMASTER: schedule new run for iteration 3
23:02:54 HBMASTER: trying submitting job (3, 0, 2) to dispatcher
23:02:54 HBMASTER: submitting job (3, 0, 2) to dispatcher
23:02:54 DISPATCHER: trying to submit job (3, 0, 2)
23:02:54 DISPATCHER: trying to notify the job_runner thread.
23:02:54 HBMASTER: job (3, 0, 2) submitted to dispatcher
23:02:54 DISPATCHER: Trying to submit another job.
23:02:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:02:54 DISPATCHER: starting job (3, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:02:54 DISPATCHER: job (3, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:02:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:02:54 WORKER: start processing job (3, 0, 2)
23:02:54 WORKER: args: ()
23:02:54 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.03431276244037616, 'num_filters_1': 99, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.15367049795030202, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 36, 'num_filters_3': 44}, 'budget': 1200.0, 'working_directory': '.'}
23:03:09 DISPATCHER: Starting worker discovery
23:03:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:03:09 DISPATCHER: Finished worker discovery
23:04:09 DISPATCHER: Starting worker discovery
23:04:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:04:09 DISPATCHER: Finished worker discovery
23:05:09 DISPATCHER: Starting worker discovery
23:05:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:05:09 DISPATCHER: Finished worker discovery
23:06:09 DISPATCHER: Starting worker discovery
23:06:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:06:09 DISPATCHER: Finished worker discovery
23:07:09 DISPATCHER: Starting worker discovery
23:07:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:07:09 DISPATCHER: Finished worker discovery
23:08:09 DISPATCHER: Starting worker discovery
23:08:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:08:09 DISPATCHER: Finished worker discovery
23:09:09 DISPATCHER: Starting worker discovery
23:09:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:09:09 DISPATCHER: Finished worker discovery
23:10:09 DISPATCHER: Starting worker discovery
23:10:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:10:09 DISPATCHER: Finished worker discovery
23:11:09 DISPATCHER: Starting worker discovery
23:11:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:11:09 DISPATCHER: Finished worker discovery
23:12:09 DISPATCHER: Starting worker discovery
23:12:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:12:09 DISPATCHER: Finished worker discovery
23:13:09 DISPATCHER: Starting worker discovery
23:13:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:13:09 DISPATCHER: Finished worker discovery
23:14:09 DISPATCHER: Starting worker discovery
23:14:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:14:09 DISPATCHER: Finished worker discovery
23:15:09 DISPATCHER: Starting worker discovery
23:15:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:15:09 DISPATCHER: Finished worker discovery
23:16:09 DISPATCHER: Starting worker discovery
23:16:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:16:09 DISPATCHER: Finished worker discovery
23:17:09 DISPATCHER: Starting worker discovery
23:17:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:17:09 DISPATCHER: Finished worker discovery
23:18:09 DISPATCHER: Starting worker discovery
23:18:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:18:09 DISPATCHER: Finished worker discovery
23:19:09 DISPATCHER: Starting worker discovery
23:19:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:19:09 DISPATCHER: Finished worker discovery
23:20:09 DISPATCHER: Starting worker discovery
23:20:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:20:09 DISPATCHER: Finished worker discovery
23:21:09 DISPATCHER: Starting worker discovery
23:21:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:21:09 DISPATCHER: Finished worker discovery
23:22:09 DISPATCHER: Starting worker discovery
23:22:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:22:09 DISPATCHER: Finished worker discovery
23:23:09 DISPATCHER: Starting worker discovery
23:23:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:23:09 DISPATCHER: Finished worker discovery
23:24:01 WORKER: done with job (3, 0, 2), trying to register it.
23:24:01 WORKER: registered result for job (3, 0, 2) with dispatcher
23:24:01 DISPATCHER: job (3, 0, 2) finished
23:24:01 DISPATCHER: register_result: lock acquired
23:24:01 DISPATCHER: job (3, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
23:24:01 job_id: (3, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.03431276244037616, 'num_filters_1': 99, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.15367049795030202, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 36, 'num_filters_3': 44}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.005268067566133945, 'info': {'sick_no_sick': 0.005268067566133945, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.03431276244037616, 'num_filters_1': 99, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.15367049795030202, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 36, 'num_filters_3': 44}"}}
exception: None

23:24:01 job_callback for (3, 0, 2) started
23:24:01 job_callback for (3, 0, 2) got condition
23:24:01 DISPATCHER: Trying to submit another job.
23:24:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:24:01 Only 7 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
23:24:01 HBMASTER: Trying to run another job!
23:24:01 job_callback for (3, 0, 2) finished
23:24:01 start sampling a new configuration.
23:24:01 done sampling a new configuration.
23:24:01 HBMASTER: schedule new run for iteration 3
23:24:01 HBMASTER: trying submitting job (3, 0, 3) to dispatcher
23:24:01 HBMASTER: submitting job (3, 0, 3) to dispatcher
23:24:01 DISPATCHER: trying to submit job (3, 0, 3)
23:24:01 DISPATCHER: trying to notify the job_runner thread.
23:24:01 HBMASTER: job (3, 0, 3) submitted to dispatcher
23:24:01 DISPATCHER: Trying to submit another job.
23:24:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:24:01 DISPATCHER: starting job (3, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:24:01 DISPATCHER: job (3, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:24:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:24:01 WORKER: start processing job (3, 0, 3)
23:24:01 WORKER: args: ()
23:24:01 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.001112089653172874, 'num_filters_1': 92, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.08071774708769573, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 34, 'num_filters_3': 25}, 'budget': 1200.0, 'working_directory': '.'}
23:24:09 DISPATCHER: Starting worker discovery
23:24:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:24:09 DISPATCHER: Finished worker discovery
23:25:09 DISPATCHER: Starting worker discovery
23:25:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:25:09 DISPATCHER: Finished worker discovery
23:26:09 DISPATCHER: Starting worker discovery
23:26:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:26:09 DISPATCHER: Finished worker discovery
23:27:09 DISPATCHER: Starting worker discovery
23:27:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:27:09 DISPATCHER: Finished worker discovery
23:28:09 DISPATCHER: Starting worker discovery
23:28:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:28:09 DISPATCHER: Finished worker discovery
23:29:09 DISPATCHER: Starting worker discovery
23:29:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:29:09 DISPATCHER: Finished worker discovery
23:30:09 DISPATCHER: Starting worker discovery
23:30:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:30:09 DISPATCHER: Finished worker discovery
23:31:09 DISPATCHER: Starting worker discovery
23:31:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:31:09 DISPATCHER: Finished worker discovery
23:32:09 DISPATCHER: Starting worker discovery
23:32:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:32:09 DISPATCHER: Finished worker discovery
23:33:09 DISPATCHER: Starting worker discovery
23:33:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:33:09 DISPATCHER: Finished worker discovery
23:34:09 DISPATCHER: Starting worker discovery
23:34:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:34:09 DISPATCHER: Finished worker discovery
23:35:09 DISPATCHER: Starting worker discovery
23:35:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:35:09 DISPATCHER: Finished worker discovery
23:36:09 DISPATCHER: Starting worker discovery
23:36:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:36:09 DISPATCHER: Finished worker discovery
23:37:09 DISPATCHER: Starting worker discovery
23:37:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:37:09 DISPATCHER: Finished worker discovery
23:38:09 DISPATCHER: Starting worker discovery
23:38:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:38:09 DISPATCHER: Finished worker discovery
23:39:09 DISPATCHER: Starting worker discovery
23:39:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:39:09 DISPATCHER: Finished worker discovery
23:40:09 DISPATCHER: Starting worker discovery
23:40:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:40:09 DISPATCHER: Finished worker discovery
23:41:09 DISPATCHER: Starting worker discovery
23:41:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:41:09 DISPATCHER: Finished worker discovery
23:42:09 DISPATCHER: Starting worker discovery
23:42:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:42:09 DISPATCHER: Finished worker discovery
23:43:09 DISPATCHER: Starting worker discovery
23:43:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:43:09 DISPATCHER: Finished worker discovery
23:44:09 DISPATCHER: Starting worker discovery
23:44:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:44:09 DISPATCHER: Finished worker discovery
23:45:09 DISPATCHER: Starting worker discovery
23:45:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:45:09 DISPATCHER: Finished worker discovery
23:45:14 WORKER: done with job (3, 0, 3), trying to register it.
23:45:14 WORKER: registered result for job (3, 0, 3) with dispatcher
23:45:14 DISPATCHER: job (3, 0, 3) finished
23:45:14 DISPATCHER: register_result: lock acquired
23:45:14 DISPATCHER: job (3, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
23:45:14 job_id: (3, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.001112089653172874, 'num_filters_1': 92, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.08071774708769573, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 34, 'num_filters_3': 25}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.4792093641176068, 'info': {'sick_no_sick': 0.4792093641176068, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.001112089653172874, 'num_filters_1': 92, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.08071774708769573, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 34, 'num_filters_3': 25}"}}
exception: None

23:45:14 job_callback for (3, 0, 3) started
23:45:14 DISPATCHER: Trying to submit another job.
23:45:14 job_callback for (3, 0, 3) got condition
23:45:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:45:14 Only 8 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
23:45:14 HBMASTER: Trying to run another job!
23:45:14 job_callback for (3, 0, 3) finished
23:45:14 start sampling a new configuration.
23:45:14 done sampling a new configuration.
23:45:14 HBMASTER: schedule new run for iteration 4
23:45:14 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
23:45:14 HBMASTER: submitting job (4, 0, 0) to dispatcher
23:45:14 DISPATCHER: trying to submit job (4, 0, 0)
23:45:14 DISPATCHER: trying to notify the job_runner thread.
23:45:14 HBMASTER: job (4, 0, 0) submitted to dispatcher
23:45:14 DISPATCHER: Trying to submit another job.
23:45:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:45:14 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:45:14 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:45:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:45:14 WORKER: start processing job (4, 0, 0)
23:45:14 WORKER: args: ()
23:45:14 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001184286997691667, 'num_filters_1': 43, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.01512361074205936, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 53, 'num_filters_3': 102}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:46:09 DISPATCHER: Starting worker discovery
23:46:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:46:09 DISPATCHER: Finished worker discovery
23:47:04 WORKER: done with job (4, 0, 0), trying to register it.
23:47:04 WORKER: registered result for job (4, 0, 0) with dispatcher
23:47:04 DISPATCHER: job (4, 0, 0) finished
23:47:04 DISPATCHER: register_result: lock acquired
23:47:04 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
23:47:04 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001184286997691667, 'num_filters_1': 43, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.01512361074205936, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 53, 'num_filters_3': 102}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5223364999452406, 'info': {'sick_no_sick': 0.5223364999452406, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001184286997691667, 'num_filters_1': 43, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.01512361074205936, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 53, 'num_filters_3': 102}"}}
exception: None

23:47:04 job_callback for (4, 0, 0) started
23:47:04 job_callback for (4, 0, 0) got condition
23:47:04 DISPATCHER: Trying to submit another job.
23:47:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:47:04 HBMASTER: Trying to run another job!
23:47:04 job_callback for (4, 0, 0) finished
23:47:04 start sampling a new configuration.
23:47:04 done sampling a new configuration.
23:47:04 HBMASTER: schedule new run for iteration 4
23:47:04 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
23:47:04 HBMASTER: submitting job (4, 0, 1) to dispatcher
23:47:04 DISPATCHER: trying to submit job (4, 0, 1)
23:47:04 DISPATCHER: trying to notify the job_runner thread.
23:47:04 HBMASTER: job (4, 0, 1) submitted to dispatcher
23:47:04 DISPATCHER: Trying to submit another job.
23:47:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:47:04 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:47:04 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:47:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:47:04 WORKER: start processing job (4, 0, 1)
23:47:04 WORKER: args: ()
23:47:04 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.011826964625336903, 'num_filters_1': 98, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.16920296768638488, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 33, 'num_filters_3': 34, 'num_filters_4': 46}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:47:09 DISPATCHER: Starting worker discovery
23:47:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:47:09 DISPATCHER: Finished worker discovery
23:48:09 DISPATCHER: Starting worker discovery
23:48:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:48:09 DISPATCHER: Finished worker discovery
23:48:51 WORKER: done with job (4, 0, 1), trying to register it.
23:48:51 WORKER: registered result for job (4, 0, 1) with dispatcher
23:48:51 DISPATCHER: job (4, 0, 1) finished
23:48:51 DISPATCHER: register_result: lock acquired
23:48:51 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
23:48:51 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.011826964625336903, 'num_filters_1': 98, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.16920296768638488, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 33, 'num_filters_3': 34, 'num_filters_4': 46}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.011826964625336903, 'num_filters_1': 98, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.16920296768638488, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 33, 'num_filters_3': 34, 'num_filters_4': 46}"}}
exception: None

23:48:51 job_callback for (4, 0, 1) started
23:48:51 job_callback for (4, 0, 1) got condition
23:48:51 DISPATCHER: Trying to submit another job.
23:48:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:48:51 HBMASTER: Trying to run another job!
23:48:51 job_callback for (4, 0, 1) finished
23:48:51 start sampling a new configuration.
23:48:51 done sampling a new configuration.
23:48:51 HBMASTER: schedule new run for iteration 4
23:48:51 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
23:48:51 HBMASTER: submitting job (4, 0, 2) to dispatcher
23:48:51 DISPATCHER: trying to submit job (4, 0, 2)
23:48:51 DISPATCHER: trying to notify the job_runner thread.
23:48:51 HBMASTER: job (4, 0, 2) submitted to dispatcher
23:48:51 DISPATCHER: Trying to submit another job.
23:48:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:48:51 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:48:51 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:48:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:48:51 WORKER: start processing job (4, 0, 2)
23:48:51 WORKER: args: ()
23:48:51 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.005404989005825372, 'num_filters_1': 93, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.02295093454253971, 'kernel_size_2': 7, 'num_filters_2': 20}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:49:09 DISPATCHER: Starting worker discovery
23:49:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:49:09 DISPATCHER: Finished worker discovery
23:50:09 DISPATCHER: Starting worker discovery
23:50:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:50:09 DISPATCHER: Finished worker discovery
23:50:38 WORKER: done with job (4, 0, 2), trying to register it.
23:50:38 WORKER: registered result for job (4, 0, 2) with dispatcher
23:50:38 DISPATCHER: job (4, 0, 2) finished
23:50:38 DISPATCHER: register_result: lock acquired
23:50:38 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
23:50:38 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.005404989005825372, 'num_filters_1': 93, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.02295093454253971, 'kernel_size_2': 7, 'num_filters_2': 20}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4903157683772376, 'info': {'sick_no_sick': 0.4903157683772376, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.005404989005825372, 'num_filters_1': 93, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.02295093454253971, 'kernel_size_2': 7, 'num_filters_2': 20}"}}
exception: None

23:50:38 job_callback for (4, 0, 2) started
23:50:38 DISPATCHER: Trying to submit another job.
23:50:38 job_callback for (4, 0, 2) got condition
23:50:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:50:38 HBMASTER: Trying to run another job!
23:50:38 job_callback for (4, 0, 2) finished
23:50:38 start sampling a new configuration.
23:50:38 done sampling a new configuration.
23:50:38 HBMASTER: schedule new run for iteration 4
23:50:38 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
23:50:38 HBMASTER: submitting job (4, 0, 3) to dispatcher
23:50:38 DISPATCHER: trying to submit job (4, 0, 3)
23:50:38 DISPATCHER: trying to notify the job_runner thread.
23:50:38 HBMASTER: job (4, 0, 3) submitted to dispatcher
23:50:38 DISPATCHER: Trying to submit another job.
23:50:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:50:38 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:50:38 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:50:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:50:38 WORKER: start processing job (4, 0, 3)
23:50:38 WORKER: args: ()
23:50:38 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004487946858748581, 'num_filters_1': 31, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.012971204010703003, 'kernel_size_2': 7, 'num_filters_2': 63}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:51:09 DISPATCHER: Starting worker discovery
23:51:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:51:09 DISPATCHER: Finished worker discovery
23:52:09 DISPATCHER: Starting worker discovery
23:52:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:52:09 DISPATCHER: Finished worker discovery
23:52:26 WORKER: done with job (4, 0, 3), trying to register it.
23:52:26 WORKER: registered result for job (4, 0, 3) with dispatcher
23:52:26 DISPATCHER: job (4, 0, 3) finished
23:52:26 DISPATCHER: register_result: lock acquired
23:52:26 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
23:52:26 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004487946858748581, 'num_filters_1': 31, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.012971204010703003, 'kernel_size_2': 7, 'num_filters_2': 63}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5049933508744767, 'info': {'sick_no_sick': 0.5049933508744767, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004487946858748581, 'num_filters_1': 31, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.012971204010703003, 'kernel_size_2': 7, 'num_filters_2': 63}"}}
exception: None

23:52:26 job_callback for (4, 0, 3) started
23:52:26 job_callback for (4, 0, 3) got condition
23:52:26 DISPATCHER: Trying to submit another job.
23:52:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:52:26 HBMASTER: Trying to run another job!
23:52:26 job_callback for (4, 0, 3) finished
23:52:26 start sampling a new configuration.
23:52:26 done sampling a new configuration.
23:52:26 HBMASTER: schedule new run for iteration 4
23:52:26 HBMASTER: trying submitting job (4, 0, 4) to dispatcher
23:52:26 HBMASTER: submitting job (4, 0, 4) to dispatcher
23:52:26 DISPATCHER: trying to submit job (4, 0, 4)
23:52:26 DISPATCHER: trying to notify the job_runner thread.
23:52:26 HBMASTER: job (4, 0, 4) submitted to dispatcher
23:52:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:52:26 DISPATCHER: Trying to submit another job.
23:52:26 DISPATCHER: starting job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:52:26 DISPATCHER: job (4, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:52:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:52:26 WORKER: start processing job (4, 0, 4)
23:52:26 WORKER: args: ()
23:52:26 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.017854487433917394, 'num_filters_1': 44, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.03323705337516027, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 16, 'num_filters_3': 33}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:53:09 DISPATCHER: Starting worker discovery
23:53:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:53:09 DISPATCHER: Finished worker discovery
23:54:09 DISPATCHER: Starting worker discovery
23:54:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:54:10 DISPATCHER: Finished worker discovery
23:54:12 WORKER: done with job (4, 0, 4), trying to register it.
23:54:12 WORKER: registered result for job (4, 0, 4) with dispatcher
23:54:12 DISPATCHER: job (4, 0, 4) finished
23:54:12 DISPATCHER: register_result: lock acquired
23:54:12 DISPATCHER: job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
23:54:12 job_id: (4, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.017854487433917394, 'num_filters_1': 44, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.03323705337516027, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 16, 'num_filters_3': 33}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.438030954820291, 'info': {'sick_no_sick': 0.438030954820291, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.017854487433917394, 'num_filters_1': 44, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.03323705337516027, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 16, 'num_filters_3': 33}"}}
exception: None

23:54:12 job_callback for (4, 0, 4) started
23:54:12 DISPATCHER: Trying to submit another job.
23:54:12 job_callback for (4, 0, 4) got condition
23:54:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:54:12 HBMASTER: Trying to run another job!
23:54:12 job_callback for (4, 0, 4) finished
23:54:12 start sampling a new configuration.
23:54:12 done sampling a new configuration.
23:54:12 HBMASTER: schedule new run for iteration 4
23:54:12 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
23:54:12 HBMASTER: submitting job (4, 0, 5) to dispatcher
23:54:12 DISPATCHER: trying to submit job (4, 0, 5)
23:54:12 DISPATCHER: trying to notify the job_runner thread.
23:54:12 HBMASTER: job (4, 0, 5) submitted to dispatcher
23:54:12 DISPATCHER: Trying to submit another job.
23:54:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:54:12 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:54:12 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:54:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:54:12 WORKER: start processing job (4, 0, 5)
23:54:12 WORKER: args: ()
23:54:12 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.02375865403212819, 'num_filters_1': 30, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.018928088391781308, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 23, 'num_filters_3': 33, 'num_filters_4': 34, 'num_filters_5': 89}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:55:10 DISPATCHER: Starting worker discovery
23:55:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:55:10 DISPATCHER: Finished worker discovery
23:55:57 WORKER: done with job (4, 0, 5), trying to register it.
23:55:57 WORKER: registered result for job (4, 0, 5) with dispatcher
23:55:57 DISPATCHER: job (4, 0, 5) finished
23:55:57 DISPATCHER: register_result: lock acquired
23:55:57 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
23:55:57 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.02375865403212819, 'num_filters_1': 30, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.018928088391781308, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 23, 'num_filters_3': 33, 'num_filters_4': 34, 'num_filters_5': 89}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.02375865403212819, 'num_filters_1': 30, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.018928088391781308, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 23, 'num_filters_3': 33, 'num_filters_4': 34, 'num_filters_5': 89}"}}
exception: None

23:55:57 job_callback for (4, 0, 5) started
23:55:57 job_callback for (4, 0, 5) got condition
23:55:57 DISPATCHER: Trying to submit another job.
23:55:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:55:57 HBMASTER: Trying to run another job!
23:55:57 job_callback for (4, 0, 5) finished
23:55:57 start sampling a new configuration.
23:55:57 done sampling a new configuration.
23:55:57 HBMASTER: schedule new run for iteration 4
23:55:57 HBMASTER: trying submitting job (4, 0, 6) to dispatcher
23:55:57 HBMASTER: submitting job (4, 0, 6) to dispatcher
23:55:57 DISPATCHER: trying to submit job (4, 0, 6)
23:55:57 DISPATCHER: trying to notify the job_runner thread.
23:55:57 HBMASTER: job (4, 0, 6) submitted to dispatcher
23:55:57 DISPATCHER: Trying to submit another job.
23:55:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:55:57 DISPATCHER: starting job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:55:57 DISPATCHER: job (4, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:55:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:55:57 WORKER: start processing job (4, 0, 6)
23:55:57 WORKER: args: ()
23:55:57 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.007565901365910238, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.03669303233286641, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 91, 'num_filters_3': 120, 'num_filters_4': 59}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:56:10 DISPATCHER: Starting worker discovery
23:56:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:56:10 DISPATCHER: Finished worker discovery
23:57:10 DISPATCHER: Starting worker discovery
23:57:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:57:10 DISPATCHER: Finished worker discovery
23:57:47 WORKER: done with job (4, 0, 6), trying to register it.
23:57:47 WORKER: registered result for job (4, 0, 6) with dispatcher
23:57:47 DISPATCHER: job (4, 0, 6) finished
23:57:47 DISPATCHER: register_result: lock acquired
23:57:47 DISPATCHER: job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
23:57:47 job_id: (4, 0, 6)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.007565901365910238, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.03669303233286641, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 91, 'num_filters_3': 120, 'num_filters_4': 59}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5228822937238902, 'info': {'sick_no_sick': 0.5228822937238902, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.007565901365910238, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.03669303233286641, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 91, 'num_filters_3': 120, 'num_filters_4': 59}"}}
exception: None

23:57:47 job_callback for (4, 0, 6) started
23:57:47 job_callback for (4, 0, 6) got condition
23:57:47 DISPATCHER: Trying to submit another job.
23:57:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:57:47 done building a new model for budget 44.444444 based on 17/28 split
Best loss for this budget:-0.559073





23:57:47 HBMASTER: Trying to run another job!
23:57:47 job_callback for (4, 0, 6) finished
23:57:47 start sampling a new configuration.
23:57:47 done sampling a new configuration.
23:57:47 HBMASTER: schedule new run for iteration 4
23:57:47 HBMASTER: trying submitting job (4, 0, 7) to dispatcher
23:57:47 HBMASTER: submitting job (4, 0, 7) to dispatcher
23:57:47 DISPATCHER: trying to submit job (4, 0, 7)
23:57:47 DISPATCHER: trying to notify the job_runner thread.
23:57:47 HBMASTER: job (4, 0, 7) submitted to dispatcher
23:57:47 DISPATCHER: Trying to submit another job.
23:57:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:57:47 DISPATCHER: starting job (4, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:57:47 DISPATCHER: job (4, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:57:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:57:47 WORKER: start processing job (4, 0, 7)
23:57:47 WORKER: args: ()
23:57:47 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0470163210581478, 'num_filters_1': 25, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.11176407518476358, 'kernel_size_2': 5, 'num_filters_2': 26}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:58:10 DISPATCHER: Starting worker discovery
23:58:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:58:10 DISPATCHER: Finished worker discovery
23:59:10 DISPATCHER: Starting worker discovery
23:59:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:59:10 DISPATCHER: Finished worker discovery
23:59:36 WORKER: done with job (4, 0, 7), trying to register it.
23:59:36 WORKER: registered result for job (4, 0, 7) with dispatcher
23:59:36 DISPATCHER: job (4, 0, 7) finished
23:59:36 DISPATCHER: register_result: lock acquired
23:59:36 DISPATCHER: job (4, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
23:59:36 job_id: (4, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0470163210581478, 'num_filters_1': 25, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.11176407518476358, 'kernel_size_2': 5, 'num_filters_2': 26}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 1.4329998090503249e-05, 'info': {'sick_no_sick': -1.4329998090503249e-05, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0470163210581478, 'num_filters_1': 25, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.11176407518476358, 'kernel_size_2': 5, 'num_filters_2': 26}"}}
exception: None

23:59:36 job_callback for (4, 0, 7) started
23:59:36 job_callback for (4, 0, 7) got condition
23:59:36 DISPATCHER: Trying to submit another job.
23:59:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:59:36 done building a new model for budget 44.444444 based on 17/29 split
Best loss for this budget:-0.559073





23:59:36 HBMASTER: Trying to run another job!
23:59:36 job_callback for (4, 0, 7) finished
23:59:36 start sampling a new configuration.
23:59:36 done sampling a new configuration.
23:59:36 HBMASTER: schedule new run for iteration 4
23:59:36 HBMASTER: trying submitting job (4, 0, 8) to dispatcher
23:59:36 HBMASTER: submitting job (4, 0, 8) to dispatcher
23:59:36 DISPATCHER: trying to submit job (4, 0, 8)
23:59:36 DISPATCHER: trying to notify the job_runner thread.
23:59:36 HBMASTER: job (4, 0, 8) submitted to dispatcher
23:59:36 DISPATCHER: Trying to submit another job.
23:59:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:59:36 DISPATCHER: starting job (4, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:59:36 DISPATCHER: job (4, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
23:59:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:59:36 WORKER: start processing job (4, 0, 8)
23:59:36 WORKER: args: ()
23:59:36 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.06646919387405699, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.020987695148838203}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:00:10 DISPATCHER: Starting worker discovery
00:00:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:00:10 DISPATCHER: Finished worker discovery
00:01:10 DISPATCHER: Starting worker discovery
00:01:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:01:10 DISPATCHER: Finished worker discovery
00:01:24 WORKER: done with job (4, 0, 8), trying to register it.
00:01:24 WORKER: registered result for job (4, 0, 8) with dispatcher
00:01:24 DISPATCHER: job (4, 0, 8) finished
00:01:24 DISPATCHER: register_result: lock acquired
00:01:24 DISPATCHER: job (4, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
00:01:24 job_id: (4, 0, 8)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.06646919387405699, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.020987695148838203}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5028681251067544, 'info': {'sick_no_sick': 0.5028681251067544, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.06646919387405699, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.020987695148838203}"}}
exception: None

00:01:24 job_callback for (4, 0, 8) started
00:01:24 job_callback for (4, 0, 8) got condition
00:01:24 DISPATCHER: Trying to submit another job.
00:01:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:01:24 done building a new model for budget 44.444444 based on 17/30 split
Best loss for this budget:-0.559073





00:01:24 HBMASTER: Trying to run another job!
00:01:24 job_callback for (4, 0, 8) finished
00:01:24 start sampling a new configuration.
00:01:24 done sampling a new configuration.
00:01:24 HBMASTER: schedule new run for iteration 4
00:01:24 HBMASTER: trying submitting job (4, 0, 9) to dispatcher
00:01:24 HBMASTER: submitting job (4, 0, 9) to dispatcher
00:01:24 DISPATCHER: trying to submit job (4, 0, 9)
00:01:24 DISPATCHER: trying to notify the job_runner thread.
00:01:24 HBMASTER: job (4, 0, 9) submitted to dispatcher
00:01:24 DISPATCHER: Trying to submit another job.
00:01:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:01:24 DISPATCHER: starting job (4, 0, 9) on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:01:24 DISPATCHER: job (4, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:01:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:01:24 WORKER: start processing job (4, 0, 9)
00:01:24 WORKER: args: ()
00:01:24 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.008124939896139168, 'num_filters_1': 38, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.15141409953609025}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:02:10 DISPATCHER: Starting worker discovery
00:02:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:02:10 DISPATCHER: Finished worker discovery
00:03:10 DISPATCHER: Starting worker discovery
00:03:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:03:10 DISPATCHER: Finished worker discovery
00:03:12 WORKER: done with job (4, 0, 9), trying to register it.
00:03:12 WORKER: registered result for job (4, 0, 9) with dispatcher
00:03:12 DISPATCHER: job (4, 0, 9) finished
00:03:12 DISPATCHER: register_result: lock acquired
00:03:12 DISPATCHER: job (4, 0, 9) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
00:03:12 job_id: (4, 0, 9)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.008124939896139168, 'num_filters_1': 38, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.15141409953609025}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.047014288229609805, 'info': {'sick_no_sick': 0.047014288229609805, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.008124939896139168, 'num_filters_1': 38, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.15141409953609025}"}}
exception: None

00:03:12 job_callback for (4, 0, 9) started
00:03:12 job_callback for (4, 0, 9) got condition
00:03:12 DISPATCHER: Trying to submit another job.
00:03:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:03:12 done building a new model for budget 44.444444 based on 17/31 split
Best loss for this budget:-0.559073





00:03:12 HBMASTER: Trying to run another job!
00:03:12 job_callback for (4, 0, 9) finished
00:03:12 start sampling a new configuration.
00:03:12 done sampling a new configuration.
00:03:12 HBMASTER: schedule new run for iteration 4
00:03:12 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
00:03:12 HBMASTER: submitting job (4, 0, 10) to dispatcher
00:03:12 DISPATCHER: trying to submit job (4, 0, 10)
00:03:12 DISPATCHER: trying to notify the job_runner thread.
00:03:12 HBMASTER: job (4, 0, 10) submitted to dispatcher
00:03:12 DISPATCHER: Trying to submit another job.
00:03:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:03:12 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:03:12 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:03:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:03:12 WORKER: start processing job (4, 0, 10)
00:03:12 WORKER: args: ()
00:03:12 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.00787943344906889, 'num_filters_1': 80, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.050980778497888894, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 27, 'num_filters_3': 65}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:04:10 DISPATCHER: Starting worker discovery
00:04:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:04:10 DISPATCHER: Finished worker discovery
00:05:02 WORKER: done with job (4, 0, 10), trying to register it.
00:05:02 WORKER: registered result for job (4, 0, 10) with dispatcher
00:05:02 DISPATCHER: job (4, 0, 10) finished
00:05:02 DISPATCHER: register_result: lock acquired
00:05:02 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
00:05:02 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.00787943344906889, 'num_filters_1': 80, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.050980778497888894, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 27, 'num_filters_3': 65}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -6.150073793474829e-05, 'info': {'sick_no_sick': 6.150073793474829e-05, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.00787943344906889, 'num_filters_1': 80, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.050980778497888894, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 27, 'num_filters_3': 65}"}}
exception: None

00:05:02 job_callback for (4, 0, 10) started
00:05:02 job_callback for (4, 0, 10) got condition
00:05:02 DISPATCHER: Trying to submit another job.
00:05:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:05:02 done building a new model for budget 44.444444 based on 17/32 split
Best loss for this budget:-0.559073





00:05:02 HBMASTER: Trying to run another job!
00:05:02 job_callback for (4, 0, 10) finished
00:05:02 start sampling a new configuration.
00:05:02 done sampling a new configuration.
00:05:02 HBMASTER: schedule new run for iteration 4
00:05:02 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
00:05:02 HBMASTER: submitting job (4, 0, 11) to dispatcher
00:05:02 DISPATCHER: trying to submit job (4, 0, 11)
00:05:02 DISPATCHER: trying to notify the job_runner thread.
00:05:02 HBMASTER: job (4, 0, 11) submitted to dispatcher
00:05:02 DISPATCHER: Trying to submit another job.
00:05:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:05:02 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:05:02 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:05:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:05:02 WORKER: start processing job (4, 0, 11)
00:05:02 WORKER: args: ()
00:05:02 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.007713420672163019, 'num_filters_1': 40, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.039477805153575234, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 100, 'num_filters_3': 66, 'num_filters_4': 38}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:05:10 DISPATCHER: Starting worker discovery
00:05:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:05:10 DISPATCHER: Finished worker discovery
00:06:10 DISPATCHER: Starting worker discovery
00:06:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:06:10 DISPATCHER: Finished worker discovery
00:06:49 WORKER: done with job (4, 0, 11), trying to register it.
00:06:49 WORKER: registered result for job (4, 0, 11) with dispatcher
00:06:49 DISPATCHER: job (4, 0, 11) finished
00:06:49 DISPATCHER: register_result: lock acquired
00:06:49 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
00:06:49 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.007713420672163019, 'num_filters_1': 40, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.039477805153575234, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 100, 'num_filters_3': 66, 'num_filters_4': 38}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.007713420672163019, 'num_filters_1': 40, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.039477805153575234, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 100, 'num_filters_3': 66, 'num_filters_4': 38}"}}
exception: None

00:06:49 job_callback for (4, 0, 11) started
00:06:49 DISPATCHER: Trying to submit another job.
00:06:49 job_callback for (4, 0, 11) got condition
00:06:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:06:49 done building a new model for budget 44.444444 based on 17/33 split
Best loss for this budget:-0.559073





00:06:49 HBMASTER: Trying to run another job!
00:06:49 job_callback for (4, 0, 11) finished
00:06:49 start sampling a new configuration.
00:06:49 best_vector: [0, 1, 0.638342013174279, 0.64994926385223, 0.439202095700025, 0, 0.9146182883997518, 0.37855755829303056, 0, 2, 1, 2, 0.5425398208696818, 0.37950089979329493, 0.9531535822281996, 0.38860897002799977], 7.910387762084827e-16, 1.2641605317922423e-17, -1.3723474535916308e-06
00:06:49 done sampling a new configuration.
00:06:49 HBMASTER: schedule new run for iteration 4
00:06:49 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
00:06:49 HBMASTER: submitting job (4, 0, 12) to dispatcher
00:06:49 DISPATCHER: trying to submit job (4, 0, 12)
00:06:49 DISPATCHER: trying to notify the job_runner thread.
00:06:49 HBMASTER: job (4, 0, 12) submitted to dispatcher
00:06:49 DISPATCHER: Trying to submit another job.
00:06:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:06:49 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:06:49 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:06:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:06:49 WORKER: start processing job (4, 0, 12)
00:06:49 WORKER: args: ()
00:06:49 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.01890967332998932, 'num_filters_1': 61, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.03108241383710813, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 49, 'num_filters_3': 35}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:07:10 DISPATCHER: Starting worker discovery
00:07:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:07:10 DISPATCHER: Finished worker discovery
00:08:10 DISPATCHER: Starting worker discovery
00:08:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:08:10 DISPATCHER: Finished worker discovery
00:08:37 WORKER: done with job (4, 0, 12), trying to register it.
00:08:37 WORKER: registered result for job (4, 0, 12) with dispatcher
00:08:37 DISPATCHER: job (4, 0, 12) finished
00:08:37 DISPATCHER: register_result: lock acquired
00:08:37 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
00:08:37 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.01890967332998932, 'num_filters_1': 61, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.03108241383710813, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 49, 'num_filters_3': 35}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.01890967332998932, 'num_filters_1': 61, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.03108241383710813, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 49, 'num_filters_3': 35}"}}
exception: None

00:08:37 job_callback for (4, 0, 12) started
00:08:37 job_callback for (4, 0, 12) got condition
00:08:37 DISPATCHER: Trying to submit another job.
00:08:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:08:37 done building a new model for budget 44.444444 based on 17/34 split
Best loss for this budget:-0.559073





00:08:37 HBMASTER: Trying to run another job!
00:08:37 job_callback for (4, 0, 12) finished
00:08:37 start sampling a new configuration.
00:08:37 best_vector: [2, 0, 0.6897245804413418, 0.8947789074413788, 0.08097343158165204, 1, 0.359562587738234, 0.3566308517184307, 2, 1, 2, 2, 0.21369806793371227, 0.9554869999269908, 0.4850236483503278, 0.3844401844498976], 7.683816029313833e-06, 0.16876318621445816, 1.296745275392729e-06
00:08:37 done sampling a new configuration.
00:08:37 HBMASTER: schedule new run for iteration 4
00:08:37 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
00:08:37 HBMASTER: submitting job (4, 0, 13) to dispatcher
00:08:37 DISPATCHER: trying to submit job (4, 0, 13)
00:08:37 DISPATCHER: trying to notify the job_runner thread.
00:08:37 HBMASTER: job (4, 0, 13) submitted to dispatcher
00:08:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:08:37 DISPATCHER: Trying to submit another job.
00:08:37 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:08:37 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:08:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:08:37 WORKER: start processing job (4, 0, 13)
00:08:37 WORKER: args: ()
00:08:37 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.02395792278546633, 'num_filters_1': 103, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.029106329095860025}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:09:10 DISPATCHER: Starting worker discovery
00:09:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:09:10 DISPATCHER: Finished worker discovery
00:10:10 DISPATCHER: Starting worker discovery
00:10:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:10:10 DISPATCHER: Finished worker discovery
00:10:25 WORKER: done with job (4, 0, 13), trying to register it.
00:10:25 WORKER: registered result for job (4, 0, 13) with dispatcher
00:10:25 DISPATCHER: job (4, 0, 13) finished
00:10:25 DISPATCHER: register_result: lock acquired
00:10:25 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
00:10:25 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.02395792278546633, 'num_filters_1': 103, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.029106329095860025}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4562645919981917, 'info': {'sick_no_sick': 0.4562645919981917, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.02395792278546633, 'num_filters_1': 103, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.029106329095860025}"}}
exception: None

00:10:25 job_callback for (4, 0, 13) started
00:10:25 job_callback for (4, 0, 13) got condition
00:10:25 DISPATCHER: Trying to submit another job.
00:10:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:10:25 done building a new model for budget 44.444444 based on 17/34 split
Best loss for this budget:-0.559073





00:10:25 HBMASTER: Trying to run another job!
00:10:25 job_callback for (4, 0, 13) finished
00:10:25 start sampling a new configuration.
00:10:25 done sampling a new configuration.
00:10:25 HBMASTER: schedule new run for iteration 4
00:10:25 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
00:10:25 HBMASTER: submitting job (4, 0, 14) to dispatcher
00:10:25 DISPATCHER: trying to submit job (4, 0, 14)
00:10:25 DISPATCHER: trying to notify the job_runner thread.
00:10:25 HBMASTER: job (4, 0, 14) submitted to dispatcher
00:10:25 DISPATCHER: Trying to submit another job.
00:10:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:10:25 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:10:25 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:10:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:10:25 WORKER: start processing job (4, 0, 14)
00:10:25 WORKER: args: ()
00:10:25 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0018559562533154263, 'num_filters_1': 35, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.07816846971487018, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 29, 'num_filters_3': 18, 'num_filters_4': 94, 'num_filters_5': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:11:10 DISPATCHER: Starting worker discovery
00:11:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:11:10 DISPATCHER: Finished worker discovery
00:12:10 DISPATCHER: Starting worker discovery
00:12:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:12:10 DISPATCHER: Finished worker discovery
00:12:13 WORKER: done with job (4, 0, 14), trying to register it.
00:12:13 WORKER: registered result for job (4, 0, 14) with dispatcher
00:12:13 DISPATCHER: job (4, 0, 14) finished
00:12:13 DISPATCHER: register_result: lock acquired
00:12:13 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
00:12:13 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0018559562533154263, 'num_filters_1': 35, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.07816846971487018, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 29, 'num_filters_3': 18, 'num_filters_4': 94, 'num_filters_5': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3543325281342766, 'info': {'sick_no_sick': 0.3543325281342766, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0018559562533154263, 'num_filters_1': 35, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.07816846971487018, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 29, 'num_filters_3': 18, 'num_filters_4': 94, 'num_filters_5': 16}"}}
exception: None

00:12:13 job_callback for (4, 0, 14) started
00:12:13 job_callback for (4, 0, 14) got condition
00:12:13 DISPATCHER: Trying to submit another job.
00:12:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:12:13 done building a new model for budget 44.444444 based on 17/35 split
Best loss for this budget:-0.559073





00:12:13 HBMASTER: Trying to run another job!
00:12:13 job_callback for (4, 0, 14) finished
00:12:13 start sampling a new configuration.
00:12:13 best_vector: [0, 1, 0.22108683574918284, 0.07700987124924413, 0.08913665903559398, 1, 0.9758655157140118, 0.2211346021718935, 2, 2, 1, 1, 0.29244661277519807, 0.5386279825024454, 0.7883474961819424, 0.3851925613786286], 0.0, inf, 6.210999561176642e-07
00:12:13 done sampling a new configuration.
00:12:13 HBMASTER: schedule new run for iteration 4
00:12:13 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
00:12:13 HBMASTER: submitting job (4, 0, 15) to dispatcher
00:12:13 DISPATCHER: trying to submit job (4, 0, 15)
00:12:13 DISPATCHER: trying to notify the job_runner thread.
00:12:13 HBMASTER: job (4, 0, 15) submitted to dispatcher
00:12:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:12:13 DISPATCHER: Trying to submit another job.
00:12:13 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:12:13 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:12:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:12:13 WORKER: start processing job (4, 0, 15)
00:12:13 WORKER: args: ()
00:12:13 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0027680483483894553, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.019395579077944272}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:13:10 DISPATCHER: Starting worker discovery
00:13:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:13:10 DISPATCHER: Finished worker discovery
00:14:01 WORKER: done with job (4, 0, 15), trying to register it.
00:14:01 WORKER: registered result for job (4, 0, 15) with dispatcher
00:14:01 DISPATCHER: job (4, 0, 15) finished
00:14:01 DISPATCHER: register_result: lock acquired
00:14:01 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
00:14:01 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0027680483483894553, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.019395579077944272}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.473642538115297, 'info': {'sick_no_sick': 0.473642538115297, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0027680483483894553, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.019395579077944272}"}}
exception: None

00:14:01 job_callback for (4, 0, 15) started
00:14:01 job_callback for (4, 0, 15) got condition
00:14:01 DISPATCHER: Trying to submit another job.
00:14:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:14:01 done building a new model for budget 44.444444 based on 17/36 split
Best loss for this budget:-0.559073





00:14:01 HBMASTER: Trying to run another job!
00:14:01 job_callback for (4, 0, 15) finished
00:14:01 start sampling a new configuration.
00:14:01 best_vector: [0, 2, 0.7608585361682585, 0.5970627391553667, 0.009119989949305393, 1, 0.8570718433229754, 0.42785181861201826, 1, 0, 1, 2, 0.463780492930058, 0.31081710821578123, 0.6343204782004388, 0.3848073337840943], 1.3533107924366272e-32, 0.7389285636298715, -6.240718257432943e-06
00:14:01 done sampling a new configuration.
00:14:01 HBMASTER: schedule new run for iteration 4
00:14:01 HBMASTER: trying submitting job (4, 0, 16) to dispatcher
00:14:01 HBMASTER: submitting job (4, 0, 16) to dispatcher
00:14:01 DISPATCHER: trying to submit job (4, 0, 16)
00:14:01 DISPATCHER: trying to notify the job_runner thread.
00:14:01 HBMASTER: job (4, 0, 16) submitted to dispatcher
00:14:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:14:01 DISPATCHER: Trying to submit another job.
00:14:01 DISPATCHER: starting job (4, 0, 16) on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:14:01 DISPATCHER: job (4, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:14:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:14:01 WORKER: start processing job (4, 0, 16)
00:14:01 WORKER: args: ()
00:14:01 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.03324429078074948, 'num_filters_1': 55, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.03602865500894925}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:14:10 DISPATCHER: Starting worker discovery
00:14:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:14:10 DISPATCHER: Finished worker discovery
00:15:10 DISPATCHER: Starting worker discovery
00:15:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:15:10 DISPATCHER: Finished worker discovery
00:15:47 WORKER: done with job (4, 0, 16), trying to register it.
00:15:47 WORKER: registered result for job (4, 0, 16) with dispatcher
00:15:47 DISPATCHER: job (4, 0, 16) finished
00:15:47 DISPATCHER: register_result: lock acquired
00:15:47 DISPATCHER: job (4, 0, 16) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
00:15:47 job_id: (4, 0, 16)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.03324429078074948, 'num_filters_1': 55, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.03602865500894925}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.46386448353374826, 'info': {'sick_no_sick': 0.46386448353374826, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.03324429078074948, 'num_filters_1': 55, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.03602865500894925}"}}
exception: None

00:15:47 job_callback for (4, 0, 16) started
00:15:47 DISPATCHER: Trying to submit another job.
00:15:47 job_callback for (4, 0, 16) got condition
00:15:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:15:47 done building a new model for budget 44.444444 based on 17/37 split
Best loss for this budget:-0.559073





00:15:47 HBMASTER: Trying to run another job!
00:15:47 job_callback for (4, 0, 16) finished
00:15:47 start sampling a new configuration.
00:15:48 best_vector: [0, 1, 0.49765381620671273, 0.701245956678489, 0.599394833126016, 1, 0.9714812104248399, 0.08860951119897525, 1, 1, 0, 2, 0.5622451359596202, 0.6227510920858741, 0.5740899136568302, 0.03485611799459416], 1.2956083842103688e-29, 0.0007718381666767829, -6.557996474105807e-05
00:15:48 done sampling a new configuration.
00:15:48 HBMASTER: schedule new run for iteration 4
00:15:48 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
00:15:48 HBMASTER: submitting job (4, 0, 17) to dispatcher
00:15:48 DISPATCHER: trying to submit job (4, 0, 17)
00:15:48 DISPATCHER: trying to notify the job_runner thread.
00:15:48 HBMASTER: job (4, 0, 17) submitted to dispatcher
00:15:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:15:48 DISPATCHER: Trying to submit another job.
00:15:48 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:15:48 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:15:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:15:48 WORKER: start processing job (4, 0, 17)
00:15:48 WORKER: args: ()
00:15:48 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.009892535841194969, 'num_filters_1': 68, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.013040181373814875, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 51, 'num_filters_3': 58}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:16:10 DISPATCHER: Starting worker discovery
00:16:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:16:10 DISPATCHER: Finished worker discovery
00:17:10 DISPATCHER: Starting worker discovery
00:17:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:17:10 DISPATCHER: Finished worker discovery
00:17:35 WORKER: done with job (4, 0, 17), trying to register it.
00:17:35 WORKER: registered result for job (4, 0, 17) with dispatcher
00:17:35 DISPATCHER: job (4, 0, 17) finished
00:17:35 DISPATCHER: register_result: lock acquired
00:17:35 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
00:17:35 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.009892535841194969, 'num_filters_1': 68, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.013040181373814875, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 51, 'num_filters_3': 58}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5252351071478392, 'info': {'sick_no_sick': 0.5252351071478392, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.009892535841194969, 'num_filters_1': 68, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.013040181373814875, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 51, 'num_filters_3': 58}"}}
exception: None

00:17:35 job_callback for (4, 0, 17) started
00:17:35 job_callback for (4, 0, 17) got condition
00:17:35 DISPATCHER: Trying to submit another job.
00:17:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:17:35 done building a new model for budget 44.444444 based on 17/38 split
Best loss for this budget:-0.559073





00:17:35 HBMASTER: Trying to run another job!
00:17:35 job_callback for (4, 0, 17) finished
00:17:35 start sampling a new configuration.
00:17:35 done sampling a new configuration.
00:17:35 HBMASTER: schedule new run for iteration 4
00:17:35 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
00:17:35 HBMASTER: submitting job (4, 0, 18) to dispatcher
00:17:35 DISPATCHER: trying to submit job (4, 0, 18)
00:17:35 DISPATCHER: trying to notify the job_runner thread.
00:17:35 HBMASTER: job (4, 0, 18) submitted to dispatcher
00:17:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:17:35 DISPATCHER: Trying to submit another job.
00:17:35 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:17:35 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:17:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:17:35 WORKER: start processing job (4, 0, 18)
00:17:35 WORKER: args: ()
00:17:35 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004335908912178131, 'num_filters_1': 46, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.010879309143425804, 'kernel_size_2': 3, 'num_filters_2': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:18:10 DISPATCHER: Starting worker discovery
00:18:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:18:10 DISPATCHER: Finished worker discovery
00:19:10 DISPATCHER: Starting worker discovery
00:19:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:19:10 DISPATCHER: Finished worker discovery
00:19:21 WORKER: done with job (4, 0, 18), trying to register it.
00:19:21 WORKER: registered result for job (4, 0, 18) with dispatcher
00:19:21 DISPATCHER: job (4, 0, 18) finished
00:19:21 DISPATCHER: register_result: lock acquired
00:19:21 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
00:19:21 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004335908912178131, 'num_filters_1': 46, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.010879309143425804, 'kernel_size_2': 3, 'num_filters_2': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4551471183122876, 'info': {'sick_no_sick': 0.4551471183122876, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004335908912178131, 'num_filters_1': 46, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.010879309143425804, 'kernel_size_2': 3, 'num_filters_2': 16}"}}
exception: None

00:19:21 job_callback for (4, 0, 18) started
00:19:21 DISPATCHER: Trying to submit another job.
00:19:21 job_callback for (4, 0, 18) got condition
00:19:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:19:21 done building a new model for budget 44.444444 based on 17/39 split
Best loss for this budget:-0.559073





00:19:21 HBMASTER: Trying to run another job!
00:19:21 job_callback for (4, 0, 18) finished
00:19:21 start sampling a new configuration.
00:19:21 best_vector: [0, 1, 0.8378064041033277, 0.5485704014365352, 0.323151066269475, 1, 0.9328430650377808, 0.15126158212646196, 1, 1, 0, 1, 0.6787558708089205, 0.9735833352533413, 0.6057034858197254, 0.06043144187338245], 1.9354789918475436e-28, 5.1666796912398074e-05, -3.059961873319372e-05
00:19:21 done sampling a new configuration.
00:19:21 HBMASTER: schedule new run for iteration 4
00:19:21 HBMASTER: trying submitting job (4, 0, 19) to dispatcher
00:19:21 HBMASTER: submitting job (4, 0, 19) to dispatcher
00:19:21 DISPATCHER: trying to submit job (4, 0, 19)
00:19:21 DISPATCHER: trying to notify the job_runner thread.
00:19:21 HBMASTER: job (4, 0, 19) submitted to dispatcher
00:19:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:19:21 DISPATCHER: Trying to submit another job.
00:19:21 DISPATCHER: starting job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:19:21 DISPATCHER: job (4, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:19:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:19:21 WORKER: start processing job (4, 0, 19)
00:19:21 WORKER: args: ()
00:19:21 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.04738193670067712, 'num_filters_1': 49, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.01573243171952766, 'kernel_size_2': 5, 'num_filters_2': 65}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:20:10 DISPATCHER: Starting worker discovery
00:20:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:20:10 DISPATCHER: Finished worker discovery
00:21:09 WORKER: done with job (4, 0, 19), trying to register it.
00:21:09 WORKER: registered result for job (4, 0, 19) with dispatcher
00:21:09 DISPATCHER: job (4, 0, 19) finished
00:21:09 DISPATCHER: register_result: lock acquired
00:21:09 DISPATCHER: job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
00:21:09 job_id: (4, 0, 19)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.04738193670067712, 'num_filters_1': 49, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.01573243171952766, 'kernel_size_2': 5, 'num_filters_2': 65}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5242479210644595, 'info': {'sick_no_sick': 0.5242479210644595, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.04738193670067712, 'num_filters_1': 49, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.01573243171952766, 'kernel_size_2': 5, 'num_filters_2': 65}"}}
exception: None

00:21:09 job_callback for (4, 0, 19) started
00:21:09 job_callback for (4, 0, 19) got condition
00:21:09 DISPATCHER: Trying to submit another job.
00:21:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:21:09 done building a new model for budget 44.444444 based on 17/39 split
Best loss for this budget:-0.559073





00:21:09 HBMASTER: Trying to run another job!
00:21:09 job_callback for (4, 0, 19) finished
00:21:09 start sampling a new configuration.
00:21:09 best_vector: [1, 2, 0.3652876563024644, 0.07815687115668221, 0.5727092494811489, 1, 0.7351307151137769, 0.647765286635612, 2, 0, 1, 1, 0.9069825348799105, 0.9666803469082839, 0.6065983705753055, 0.28083338496109533], 0.002099524277847746, 0.0031823112605485243, 6.68133975118989e-06
00:21:09 done sampling a new configuration.
00:21:09 HBMASTER: schedule new run for iteration 4
00:21:09 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
00:21:09 HBMASTER: submitting job (4, 0, 20) to dispatcher
00:21:09 DISPATCHER: trying to submit job (4, 0, 20)
00:21:09 DISPATCHER: trying to notify the job_runner thread.
00:21:09 HBMASTER: job (4, 0, 20) submitted to dispatcher
00:21:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:21:09 DISPATCHER: Trying to submit another job.
00:21:09 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:21:09 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:21:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:21:09 WORKER: start processing job (4, 0, 20)
00:21:09 WORKER: args: ()
00:21:09 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005377436771478425, 'num_filters_1': 18, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.06962449658583628, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 106, 'num_filters_3': 120}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:21:10 DISPATCHER: Starting worker discovery
00:21:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:21:10 DISPATCHER: Finished worker discovery
00:22:10 DISPATCHER: Starting worker discovery
00:22:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:22:10 DISPATCHER: Finished worker discovery
00:22:57 WORKER: done with job (4, 0, 20), trying to register it.
00:22:57 WORKER: registered result for job (4, 0, 20) with dispatcher
00:22:57 DISPATCHER: job (4, 0, 20) finished
00:22:57 DISPATCHER: register_result: lock acquired
00:22:57 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
00:22:57 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005377436771478425, 'num_filters_1': 18, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.06962449658583628, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 106, 'num_filters_3': 120}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5381191974218963, 'info': {'sick_no_sick': 0.5381191974218963, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005377436771478425, 'num_filters_1': 18, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.06962449658583628, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 106, 'num_filters_3': 120}"}}
exception: None

00:22:57 job_callback for (4, 0, 20) started
00:22:57 job_callback for (4, 0, 20) got condition
00:22:57 DISPATCHER: Trying to submit another job.
00:22:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:22:57 done building a new model for budget 44.444444 based on 17/40 split
Best loss for this budget:-0.559073





00:22:57 HBMASTER: Trying to run another job!
00:22:57 job_callback for (4, 0, 20) finished
00:22:57 start sampling a new configuration.
00:22:57 done sampling a new configuration.
00:22:57 HBMASTER: schedule new run for iteration 4
00:22:57 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
00:22:57 HBMASTER: submitting job (4, 0, 21) to dispatcher
00:22:57 DISPATCHER: trying to submit job (4, 0, 21)
00:22:57 DISPATCHER: trying to notify the job_runner thread.
00:22:57 HBMASTER: job (4, 0, 21) submitted to dispatcher
00:22:57 DISPATCHER: Trying to submit another job.
00:22:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:22:57 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:22:57 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:22:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:22:57 WORKER: start processing job (4, 0, 21)
00:22:57 WORKER: args: ()
00:22:57 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.07172952941961049, 'num_filters_1': 66, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.14984625643833938, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 41, 'num_filters_3': 20}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:23:10 DISPATCHER: Starting worker discovery
00:23:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:23:10 DISPATCHER: Finished worker discovery
00:24:10 DISPATCHER: Starting worker discovery
00:24:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:24:10 DISPATCHER: Finished worker discovery
00:24:44 WORKER: done with job (4, 0, 21), trying to register it.
00:24:44 WORKER: registered result for job (4, 0, 21) with dispatcher
00:24:44 DISPATCHER: job (4, 0, 21) finished
00:24:44 DISPATCHER: register_result: lock acquired
00:24:44 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
00:24:44 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.07172952941961049, 'num_filters_1': 66, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.14984625643833938, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 41, 'num_filters_3': 20}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.07172952941961049, 'num_filters_1': 66, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.14984625643833938, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 41, 'num_filters_3': 20}"}}
exception: None

00:24:44 job_callback for (4, 0, 21) started
00:24:44 DISPATCHER: Trying to submit another job.
00:24:44 job_callback for (4, 0, 21) got condition
00:24:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:24:44 done building a new model for budget 44.444444 based on 17/41 split
Best loss for this budget:-0.559073





00:24:44 HBMASTER: Trying to run another job!
00:24:44 job_callback for (4, 0, 21) finished
00:24:44 start sampling a new configuration.
00:24:44 done sampling a new configuration.
00:24:45 HBMASTER: schedule new run for iteration 4
00:24:45 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
00:24:45 HBMASTER: submitting job (4, 0, 22) to dispatcher
00:24:45 DISPATCHER: trying to submit job (4, 0, 22)
00:24:45 DISPATCHER: trying to notify the job_runner thread.
00:24:45 HBMASTER: job (4, 0, 22) submitted to dispatcher
00:24:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:24:45 DISPATCHER: Trying to submit another job.
00:24:45 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:24:45 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:24:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:24:45 WORKER: start processing job (4, 0, 22)
00:24:45 WORKER: args: ()
00:24:45 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0087222890833092, 'num_filters_1': 35, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.12948976450517094, 'kernel_size_2': 5, 'num_filters_2': 83}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:25:10 DISPATCHER: Starting worker discovery
00:25:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:25:10 DISPATCHER: Finished worker discovery
00:26:10 DISPATCHER: Starting worker discovery
00:26:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:26:10 DISPATCHER: Finished worker discovery
00:26:32 WORKER: done with job (4, 0, 22), trying to register it.
00:26:32 WORKER: registered result for job (4, 0, 22) with dispatcher
00:26:32 DISPATCHER: job (4, 0, 22) finished
00:26:32 DISPATCHER: register_result: lock acquired
00:26:32 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
00:26:32 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0087222890833092, 'num_filters_1': 35, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.12948976450517094, 'kernel_size_2': 5, 'num_filters_2': 83}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.379950932812517, 'info': {'sick_no_sick': 0.379950932812517, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0087222890833092, 'num_filters_1': 35, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.12948976450517094, 'kernel_size_2': 5, 'num_filters_2': 83}"}}
exception: None

00:26:32 job_callback for (4, 0, 22) started
00:26:32 job_callback for (4, 0, 22) got condition
00:26:32 DISPATCHER: Trying to submit another job.
00:26:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:26:32 done building a new model for budget 44.444444 based on 17/42 split
Best loss for this budget:-0.559073





00:26:32 HBMASTER: Trying to run another job!
00:26:32 job_callback for (4, 0, 22) finished
00:26:32 start sampling a new configuration.
00:26:32 best_vector: [2, 2, 0.10416895819910382, 0.33784968561833983, 0.5577970199972243, 1, 0.8647075435073874, 0.18022613487148664, 0, 1, 0, 0, 0.019976281245772276, 0.12803509680882877, 0.7258831408269181, 0.7433131567584251], 0.006103152779545965, 0.000950577936284174, 5.8015223740078235e-06
00:26:32 done sampling a new configuration.
00:26:32 HBMASTER: schedule new run for iteration 4
00:26:32 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
00:26:32 HBMASTER: submitting job (4, 0, 23) to dispatcher
00:26:32 DISPATCHER: trying to submit job (4, 0, 23)
00:26:32 DISPATCHER: trying to notify the job_runner thread.
00:26:32 HBMASTER: job (4, 0, 23) submitted to dispatcher
00:26:32 DISPATCHER: Trying to submit another job.
00:26:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:26:32 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:26:32 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:26:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:26:32 WORKER: start processing job (4, 0, 23)
00:26:32 WORKER: args: ()
00:26:32 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001615615147769934, 'num_filters_1': 32, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.01715851139521676, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 16, 'num_filters_3': 20}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:27:10 DISPATCHER: Starting worker discovery
00:27:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:27:10 DISPATCHER: Finished worker discovery
00:28:10 DISPATCHER: Starting worker discovery
00:28:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:28:10 DISPATCHER: Finished worker discovery
00:28:20 WORKER: done with job (4, 0, 23), trying to register it.
00:28:20 WORKER: registered result for job (4, 0, 23) with dispatcher
00:28:20 DISPATCHER: job (4, 0, 23) finished
00:28:20 DISPATCHER: register_result: lock acquired
00:28:20 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
00:28:20 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001615615147769934, 'num_filters_1': 32, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.01715851139521676, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 16, 'num_filters_3': 20}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4172036534554031, 'info': {'sick_no_sick': 0.4172036534554031, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001615615147769934, 'num_filters_1': 32, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.01715851139521676, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 16, 'num_filters_3': 20}"}}
exception: None

00:28:20 job_callback for (4, 0, 23) started
00:28:20 DISPATCHER: Trying to submit another job.
00:28:20 job_callback for (4, 0, 23) got condition
00:28:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:28:20 done building a new model for budget 44.444444 based on 17/43 split
Best loss for this budget:-0.559073





00:28:20 HBMASTER: Trying to run another job!
00:28:20 job_callback for (4, 0, 23) finished
00:28:20 start sampling a new configuration.
00:28:20 done sampling a new configuration.
00:28:20 HBMASTER: schedule new run for iteration 4
00:28:20 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
00:28:20 HBMASTER: submitting job (4, 0, 24) to dispatcher
00:28:20 DISPATCHER: trying to submit job (4, 0, 24)
00:28:20 DISPATCHER: trying to notify the job_runner thread.
00:28:20 HBMASTER: job (4, 0, 24) submitted to dispatcher
00:28:20 DISPATCHER: Trying to submit another job.
00:28:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:28:20 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:28:20 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:28:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:28:20 WORKER: start processing job (4, 0, 24)
00:28:20 WORKER: args: ()
00:28:20 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.04747421405220238, 'num_filters_1': 51, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.10291431235186678}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:29:10 DISPATCHER: Starting worker discovery
00:29:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:29:10 DISPATCHER: Finished worker discovery
Exception in thread Thread-691:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    preds = np.concatenate(preds)
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

00:30:07 WORKER: done with job (4, 0, 24), trying to register it.
00:30:07 WORKER: registered result for job (4, 0, 24) with dispatcher
00:30:07 DISPATCHER: job (4, 0, 24) finished
00:30:07 DISPATCHER: register_result: lock acquired
00:30:07 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
00:30:07 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.04747421405220238, 'num_filters_1': 51, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.10291431235186678}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0895998479040131, 'info': {'sick_no_sick': 0.0895998479040131, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.04747421405220238, 'num_filters_1': 51, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.10291431235186678}"}}
exception: None

00:30:07 job_callback for (4, 0, 24) started
00:30:07 job_callback for (4, 0, 24) got condition
00:30:07 DISPATCHER: Trying to submit another job.
00:30:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:30:07 done building a new model for budget 44.444444 based on 17/44 split
Best loss for this budget:-0.559073





00:30:07 HBMASTER: Trying to run another job!
00:30:07 job_callback for (4, 0, 24) finished
00:30:07 start sampling a new configuration.
00:30:07 done sampling a new configuration.
00:30:07 HBMASTER: schedule new run for iteration 4
00:30:07 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
00:30:07 HBMASTER: submitting job (4, 0, 25) to dispatcher
00:30:07 DISPATCHER: trying to submit job (4, 0, 25)
00:30:07 DISPATCHER: trying to notify the job_runner thread.
00:30:07 HBMASTER: job (4, 0, 25) submitted to dispatcher
00:30:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:30:07 DISPATCHER: Trying to submit another job.
00:30:07 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:30:07 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:30:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:30:07 WORKER: start processing job (4, 0, 25)
00:30:07 WORKER: args: ()
00:30:07 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.029058684212465203, 'num_filters_1': 71, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.017056397446983607, 'kernel_size_2': 3, 'num_filters_2': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:30:10 DISPATCHER: Starting worker discovery
00:30:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:30:10 DISPATCHER: Finished worker discovery
00:31:10 DISPATCHER: Starting worker discovery
00:31:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:31:10 DISPATCHER: Finished worker discovery
00:31:56 WORKER: done with job (4, 0, 25), trying to register it.
00:31:56 WORKER: registered result for job (4, 0, 25) with dispatcher
00:31:56 DISPATCHER: job (4, 0, 25) finished
00:31:56 DISPATCHER: register_result: lock acquired
00:31:56 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
00:31:56 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.029058684212465203, 'num_filters_1': 71, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.017056397446983607, 'kernel_size_2': 3, 'num_filters_2': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.000503717702100657, 'info': {'sick_no_sick': 0.000503717702100657, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.029058684212465203, 'num_filters_1': 71, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.017056397446983607, 'kernel_size_2': 3, 'num_filters_2': 18}"}}
exception: None

00:31:56 job_callback for (4, 0, 25) started
00:31:56 DISPATCHER: Trying to submit another job.
00:31:56 job_callback for (4, 0, 25) got condition
00:31:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:31:57 done building a new model for budget 44.444444 based on 17/45 split
Best loss for this budget:-0.559073





00:31:57 HBMASTER: Trying to run another job!
00:31:57 job_callback for (4, 0, 25) finished
00:31:57 start sampling a new configuration.
00:31:57 best_vector: [1, 2, 0.06398020643479463, 0.7288441522742861, 0.6653379018361987, 1, 0.8516115785405871, 0.1413091532378722, 2, 0, 1, 2, 0.9482414935153541, 0.10168183029985683, 0.5196382767803727, 0.17065105264498776], 0.009089076812224527, 0.00028021113584542057, 2.546860537339709e-06
00:31:57 done sampling a new configuration.
00:31:57 HBMASTER: schedule new run for iteration 4
00:31:57 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
00:31:57 HBMASTER: submitting job (4, 0, 26) to dispatcher
00:31:57 DISPATCHER: trying to submit job (4, 0, 26)
00:31:57 DISPATCHER: trying to notify the job_runner thread.
00:31:57 HBMASTER: job (4, 0, 26) submitted to dispatcher
00:31:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:31:57 DISPATCHER: Trying to submit another job.
00:31:57 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:31:57 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:31:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:31:57 WORKER: start processing job (4, 0, 26)
00:31:57 WORKER: args: ()
00:31:57 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0013426425700155983, 'num_filters_1': 72, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.015270295701324885, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 115, 'num_filters_3': 19, 'num_filters_4': 47}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:32:10 DISPATCHER: Starting worker discovery
00:32:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:32:10 DISPATCHER: Finished worker discovery
00:33:10 DISPATCHER: Starting worker discovery
00:33:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:33:10 DISPATCHER: Finished worker discovery
00:33:43 WORKER: done with job (4, 0, 26), trying to register it.
00:33:43 WORKER: registered result for job (4, 0, 26) with dispatcher
00:33:43 DISPATCHER: job (4, 0, 26) finished
00:33:43 DISPATCHER: register_result: lock acquired
00:33:43 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
00:33:43 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0013426425700155983, 'num_filters_1': 72, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.015270295701324885, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 115, 'num_filters_3': 19, 'num_filters_4': 47}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5050958615748959, 'info': {'sick_no_sick': 0.5050958615748959, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0013426425700155983, 'num_filters_1': 72, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.015270295701324885, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 115, 'num_filters_3': 19, 'num_filters_4': 47}"}}
exception: None

00:33:43 job_callback for (4, 0, 26) started
00:33:43 job_callback for (4, 0, 26) got condition
00:33:43 DISPATCHER: Trying to submit another job.
00:33:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:33:43 done building a new model for budget 44.444444 based on 17/45 split
Best loss for this budget:-0.559073





00:33:43 HBMASTER: Trying to run another job!
00:33:43 job_callback for (4, 0, 26) finished
00:33:43 ITERATION: Advancing config (4, 0, 0) to next budget 133.333333
00:33:43 ITERATION: Advancing config (4, 0, 2) to next budget 133.333333
00:33:43 ITERATION: Advancing config (4, 0, 3) to next budget 133.333333
00:33:43 ITERATION: Advancing config (4, 0, 6) to next budget 133.333333
00:33:43 ITERATION: Advancing config (4, 0, 8) to next budget 133.333333
00:33:43 ITERATION: Advancing config (4, 0, 17) to next budget 133.333333
00:33:43 ITERATION: Advancing config (4, 0, 19) to next budget 133.333333
00:33:43 ITERATION: Advancing config (4, 0, 20) to next budget 133.333333
00:33:43 ITERATION: Advancing config (4, 0, 26) to next budget 133.333333
00:33:43 HBMASTER: schedule new run for iteration 4
00:33:43 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
00:33:43 HBMASTER: submitting job (4, 0, 0) to dispatcher
00:33:43 DISPATCHER: trying to submit job (4, 0, 0)
00:33:43 DISPATCHER: trying to notify the job_runner thread.
00:33:43 HBMASTER: job (4, 0, 0) submitted to dispatcher
00:33:43 DISPATCHER: Trying to submit another job.
00:33:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:33:43 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:33:43 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:33:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:33:43 WORKER: start processing job (4, 0, 0)
00:33:43 WORKER: args: ()
00:33:43 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001184286997691667, 'num_filters_1': 43, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.01512361074205936, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 53, 'num_filters_3': 102}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:34:10 DISPATCHER: Starting worker discovery
00:34:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:34:10 DISPATCHER: Finished worker discovery
00:35:10 DISPATCHER: Starting worker discovery
00:35:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:35:10 DISPATCHER: Finished worker discovery
00:36:10 DISPATCHER: Starting worker discovery
00:36:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:36:10 DISPATCHER: Finished worker discovery
00:37:06 WORKER: done with job (4, 0, 0), trying to register it.
00:37:06 WORKER: registered result for job (4, 0, 0) with dispatcher
00:37:06 DISPATCHER: job (4, 0, 0) finished
00:37:06 DISPATCHER: register_result: lock acquired
00:37:06 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
00:37:06 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001184286997691667, 'num_filters_1': 43, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.01512361074205936, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 53, 'num_filters_3': 102}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5491045140806267, 'info': {'sick_no_sick': 0.5491045140806267, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001184286997691667, 'num_filters_1': 43, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.01512361074205936, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 53, 'num_filters_3': 102}"}}
exception: None

00:37:06 job_callback for (4, 0, 0) started
00:37:06 job_callback for (4, 0, 0) got condition
00:37:06 DISPATCHER: Trying to submit another job.
00:37:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:37:06 HBMASTER: Trying to run another job!
00:37:06 job_callback for (4, 0, 0) finished
00:37:06 HBMASTER: schedule new run for iteration 4
00:37:06 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
00:37:06 HBMASTER: submitting job (4, 0, 2) to dispatcher
00:37:06 DISPATCHER: trying to submit job (4, 0, 2)
00:37:06 DISPATCHER: trying to notify the job_runner thread.
00:37:06 HBMASTER: job (4, 0, 2) submitted to dispatcher
00:37:06 DISPATCHER: Trying to submit another job.
00:37:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:37:06 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:37:06 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:37:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:37:06 WORKER: start processing job (4, 0, 2)
00:37:06 WORKER: args: ()
00:37:06 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.005404989005825372, 'num_filters_1': 93, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.02295093454253971, 'kernel_size_2': 7, 'num_filters_2': 20}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:37:10 DISPATCHER: Starting worker discovery
00:37:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:37:10 DISPATCHER: Finished worker discovery
00:38:10 DISPATCHER: Starting worker discovery
00:38:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:38:10 DISPATCHER: Finished worker discovery
00:39:10 DISPATCHER: Starting worker discovery
00:39:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:39:10 DISPATCHER: Finished worker discovery
00:40:10 DISPATCHER: Starting worker discovery
00:40:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:40:10 DISPATCHER: Finished worker discovery
00:40:24 WORKER: done with job (4, 0, 2), trying to register it.
00:40:24 WORKER: registered result for job (4, 0, 2) with dispatcher
00:40:24 DISPATCHER: job (4, 0, 2) finished
00:40:24 DISPATCHER: register_result: lock acquired
00:40:24 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
00:40:24 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.005404989005825372, 'num_filters_1': 93, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.02295093454253971, 'kernel_size_2': 7, 'num_filters_2': 20}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5287481958784461, 'info': {'sick_no_sick': 0.5287481958784461, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.005404989005825372, 'num_filters_1': 93, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.02295093454253971, 'kernel_size_2': 7, 'num_filters_2': 20}"}}
exception: None

00:40:24 job_callback for (4, 0, 2) started
00:40:24 job_callback for (4, 0, 2) got condition
00:40:24 DISPATCHER: Trying to submit another job.
00:40:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:40:24 HBMASTER: Trying to run another job!
00:40:24 job_callback for (4, 0, 2) finished
00:40:24 HBMASTER: schedule new run for iteration 4
00:40:24 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
00:40:24 HBMASTER: submitting job (4, 0, 3) to dispatcher
00:40:24 DISPATCHER: trying to submit job (4, 0, 3)
00:40:24 DISPATCHER: trying to notify the job_runner thread.
00:40:24 HBMASTER: job (4, 0, 3) submitted to dispatcher
00:40:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:40:24 DISPATCHER: Trying to submit another job.
00:40:24 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:40:24 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:40:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:40:24 WORKER: start processing job (4, 0, 3)
00:40:24 WORKER: args: ()
00:40:24 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004487946858748581, 'num_filters_1': 31, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.012971204010703003, 'kernel_size_2': 7, 'num_filters_2': 63}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:41:10 DISPATCHER: Starting worker discovery
00:41:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:41:10 DISPATCHER: Finished worker discovery
00:42:10 DISPATCHER: Starting worker discovery
00:42:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:42:10 DISPATCHER: Finished worker discovery
00:43:10 DISPATCHER: Starting worker discovery
00:43:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:43:10 DISPATCHER: Finished worker discovery
00:43:42 WORKER: done with job (4, 0, 3), trying to register it.
00:43:42 WORKER: registered result for job (4, 0, 3) with dispatcher
00:43:42 DISPATCHER: job (4, 0, 3) finished
00:43:42 DISPATCHER: register_result: lock acquired
00:43:42 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
00:43:42 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004487946858748581, 'num_filters_1': 31, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.012971204010703003, 'kernel_size_2': 7, 'num_filters_2': 63}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5382088419614085, 'info': {'sick_no_sick': 0.5382088419614085, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004487946858748581, 'num_filters_1': 31, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.012971204010703003, 'kernel_size_2': 7, 'num_filters_2': 63}"}}
exception: None

00:43:42 job_callback for (4, 0, 3) started
00:43:42 job_callback for (4, 0, 3) got condition
00:43:42 DISPATCHER: Trying to submit another job.
00:43:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:43:42 HBMASTER: Trying to run another job!
00:43:42 job_callback for (4, 0, 3) finished
00:43:42 HBMASTER: schedule new run for iteration 4
00:43:42 HBMASTER: trying submitting job (4, 0, 6) to dispatcher
00:43:42 HBMASTER: submitting job (4, 0, 6) to dispatcher
00:43:42 DISPATCHER: trying to submit job (4, 0, 6)
00:43:42 DISPATCHER: trying to notify the job_runner thread.
00:43:42 HBMASTER: job (4, 0, 6) submitted to dispatcher
00:43:42 DISPATCHER: Trying to submit another job.
00:43:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:43:42 DISPATCHER: starting job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:43:42 DISPATCHER: job (4, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:43:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:43:42 WORKER: start processing job (4, 0, 6)
00:43:42 WORKER: args: ()
00:43:42 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.007565901365910238, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.03669303233286641, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 91, 'num_filters_3': 120, 'num_filters_4': 59}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:44:10 DISPATCHER: Starting worker discovery
00:44:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:44:10 DISPATCHER: Finished worker discovery
00:45:10 DISPATCHER: Starting worker discovery
00:45:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:45:10 DISPATCHER: Finished worker discovery
00:46:10 DISPATCHER: Starting worker discovery
00:46:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:46:10 DISPATCHER: Finished worker discovery
00:47:01 WORKER: done with job (4, 0, 6), trying to register it.
00:47:01 WORKER: registered result for job (4, 0, 6) with dispatcher
00:47:01 DISPATCHER: job (4, 0, 6) finished
00:47:01 DISPATCHER: register_result: lock acquired
00:47:01 DISPATCHER: job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
00:47:01 job_id: (4, 0, 6)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.007565901365910238, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.03669303233286641, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 91, 'num_filters_3': 120, 'num_filters_4': 59}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5531503911590139, 'info': {'sick_no_sick': 0.5531503911590139, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.007565901365910238, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.03669303233286641, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 91, 'num_filters_3': 120, 'num_filters_4': 59}"}}
exception: None

00:47:01 job_callback for (4, 0, 6) started
00:47:01 job_callback for (4, 0, 6) got condition
00:47:01 DISPATCHER: Trying to submit another job.
00:47:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:47:01 HBMASTER: Trying to run another job!
00:47:01 job_callback for (4, 0, 6) finished
00:47:01 HBMASTER: schedule new run for iteration 4
00:47:01 HBMASTER: trying submitting job (4, 0, 8) to dispatcher
00:47:01 HBMASTER: submitting job (4, 0, 8) to dispatcher
00:47:01 DISPATCHER: trying to submit job (4, 0, 8)
00:47:01 DISPATCHER: trying to notify the job_runner thread.
00:47:01 HBMASTER: job (4, 0, 8) submitted to dispatcher
00:47:01 DISPATCHER: Trying to submit another job.
00:47:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:47:01 DISPATCHER: starting job (4, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:47:01 DISPATCHER: job (4, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:47:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:47:01 WORKER: start processing job (4, 0, 8)
00:47:01 WORKER: args: ()
00:47:01 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.06646919387405699, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.020987695148838203}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:47:10 DISPATCHER: Starting worker discovery
00:47:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:47:10 DISPATCHER: Finished worker discovery
00:48:10 DISPATCHER: Starting worker discovery
00:48:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:48:10 DISPATCHER: Finished worker discovery
00:49:10 DISPATCHER: Starting worker discovery
00:49:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:49:10 DISPATCHER: Finished worker discovery
00:50:10 DISPATCHER: Starting worker discovery
00:50:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:50:10 DISPATCHER: Finished worker discovery
00:50:18 WORKER: done with job (4, 0, 8), trying to register it.
00:50:18 WORKER: registered result for job (4, 0, 8) with dispatcher
00:50:18 DISPATCHER: job (4, 0, 8) finished
00:50:18 DISPATCHER: register_result: lock acquired
00:50:18 DISPATCHER: job (4, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
00:50:18 job_id: (4, 0, 8)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.06646919387405699, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.020987695148838203}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3798191881136216, 'info': {'sick_no_sick': 0.3798191881136216, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.06646919387405699, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.020987695148838203}"}}
exception: None

00:50:18 job_callback for (4, 0, 8) started
00:50:18 DISPATCHER: Trying to submit another job.
00:50:18 job_callback for (4, 0, 8) got condition
00:50:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:50:18 HBMASTER: Trying to run another job!
00:50:18 job_callback for (4, 0, 8) finished
00:50:18 HBMASTER: schedule new run for iteration 4
00:50:18 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
00:50:18 HBMASTER: submitting job (4, 0, 17) to dispatcher
00:50:18 DISPATCHER: trying to submit job (4, 0, 17)
00:50:18 DISPATCHER: trying to notify the job_runner thread.
00:50:18 HBMASTER: job (4, 0, 17) submitted to dispatcher
00:50:18 DISPATCHER: Trying to submit another job.
00:50:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:50:18 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:50:18 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:50:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:50:18 WORKER: start processing job (4, 0, 17)
00:50:18 WORKER: args: ()
00:50:18 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.009892535841194969, 'num_filters_1': 68, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.013040181373814875, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 51, 'num_filters_3': 58}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:51:10 DISPATCHER: Starting worker discovery
00:51:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:51:10 DISPATCHER: Finished worker discovery
00:52:10 DISPATCHER: Starting worker discovery
00:52:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:52:10 DISPATCHER: Finished worker discovery
00:53:10 DISPATCHER: Starting worker discovery
00:53:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:53:10 DISPATCHER: Finished worker discovery
00:53:36 WORKER: done with job (4, 0, 17), trying to register it.
00:53:36 WORKER: registered result for job (4, 0, 17) with dispatcher
00:53:36 DISPATCHER: job (4, 0, 17) finished
00:53:36 DISPATCHER: register_result: lock acquired
00:53:36 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
00:53:36 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.009892535841194969, 'num_filters_1': 68, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.013040181373814875, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 51, 'num_filters_3': 58}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4934819571486424, 'info': {'sick_no_sick': 0.4934819571486424, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.009892535841194969, 'num_filters_1': 68, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.013040181373814875, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 51, 'num_filters_3': 58}"}}
exception: None

00:53:36 job_callback for (4, 0, 17) started
00:53:36 DISPATCHER: Trying to submit another job.
00:53:36 job_callback for (4, 0, 17) got condition
00:53:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:53:36 HBMASTER: Trying to run another job!
00:53:36 job_callback for (4, 0, 17) finished
00:53:36 HBMASTER: schedule new run for iteration 4
00:53:36 HBMASTER: trying submitting job (4, 0, 19) to dispatcher
00:53:36 HBMASTER: submitting job (4, 0, 19) to dispatcher
00:53:36 DISPATCHER: trying to submit job (4, 0, 19)
00:53:36 DISPATCHER: trying to notify the job_runner thread.
00:53:36 HBMASTER: job (4, 0, 19) submitted to dispatcher
00:53:36 DISPATCHER: Trying to submit another job.
00:53:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:53:36 DISPATCHER: starting job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:53:36 DISPATCHER: job (4, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:53:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:53:36 WORKER: start processing job (4, 0, 19)
00:53:36 WORKER: args: ()
00:53:36 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.04738193670067712, 'num_filters_1': 49, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.01573243171952766, 'kernel_size_2': 5, 'num_filters_2': 65}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:54:10 DISPATCHER: Starting worker discovery
00:54:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:54:10 DISPATCHER: Finished worker discovery
00:55:10 DISPATCHER: Starting worker discovery
00:55:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:55:10 DISPATCHER: Finished worker discovery
00:56:10 DISPATCHER: Starting worker discovery
00:56:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:56:10 DISPATCHER: Finished worker discovery
00:56:55 WORKER: done with job (4, 0, 19), trying to register it.
00:56:55 WORKER: registered result for job (4, 0, 19) with dispatcher
00:56:55 DISPATCHER: job (4, 0, 19) finished
00:56:55 DISPATCHER: register_result: lock acquired
00:56:55 DISPATCHER: job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
00:56:55 job_id: (4, 0, 19)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.04738193670067712, 'num_filters_1': 49, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.01573243171952766, 'kernel_size_2': 5, 'num_filters_2': 65}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4276507019607344, 'info': {'sick_no_sick': 0.4276507019607344, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.04738193670067712, 'num_filters_1': 49, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.01573243171952766, 'kernel_size_2': 5, 'num_filters_2': 65}"}}
exception: None

00:56:55 job_callback for (4, 0, 19) started
00:56:55 job_callback for (4, 0, 19) got condition
00:56:55 DISPATCHER: Trying to submit another job.
00:56:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:56:55 HBMASTER: Trying to run another job!
00:56:55 job_callback for (4, 0, 19) finished
00:56:55 HBMASTER: schedule new run for iteration 4
00:56:55 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
00:56:55 HBMASTER: submitting job (4, 0, 20) to dispatcher
00:56:55 DISPATCHER: trying to submit job (4, 0, 20)
00:56:55 DISPATCHER: trying to notify the job_runner thread.
00:56:55 HBMASTER: job (4, 0, 20) submitted to dispatcher
00:56:55 DISPATCHER: Trying to submit another job.
00:56:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:56:55 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:56:55 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
00:56:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:56:55 WORKER: start processing job (4, 0, 20)
00:56:55 WORKER: args: ()
00:56:55 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005377436771478425, 'num_filters_1': 18, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.06962449658583628, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 106, 'num_filters_3': 120}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:57:10 DISPATCHER: Starting worker discovery
00:57:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:57:10 DISPATCHER: Finished worker discovery
00:58:10 DISPATCHER: Starting worker discovery
00:58:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:58:10 DISPATCHER: Finished worker discovery
00:59:10 DISPATCHER: Starting worker discovery
00:59:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:59:10 DISPATCHER: Finished worker discovery
01:00:10 DISPATCHER: Starting worker discovery
01:00:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:00:10 DISPATCHER: Finished worker discovery
01:00:12 WORKER: done with job (4, 0, 20), trying to register it.
01:00:12 WORKER: registered result for job (4, 0, 20) with dispatcher
01:00:12 DISPATCHER: job (4, 0, 20) finished
01:00:12 DISPATCHER: register_result: lock acquired
01:00:12 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:00:12 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005377436771478425, 'num_filters_1': 18, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.06962449658583628, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 106, 'num_filters_3': 120}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5235426991713842, 'info': {'sick_no_sick': 0.5235426991713842, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005377436771478425, 'num_filters_1': 18, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.06962449658583628, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 106, 'num_filters_3': 120}"}}
exception: None

01:00:12 job_callback for (4, 0, 20) started
01:00:12 job_callback for (4, 0, 20) got condition
01:00:12 DISPATCHER: Trying to submit another job.
01:00:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:00:12 HBMASTER: Trying to run another job!
01:00:12 job_callback for (4, 0, 20) finished
01:00:12 HBMASTER: schedule new run for iteration 4
01:00:12 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
01:00:12 HBMASTER: submitting job (4, 0, 26) to dispatcher
01:00:12 DISPATCHER: trying to submit job (4, 0, 26)
01:00:12 DISPATCHER: trying to notify the job_runner thread.
01:00:12 HBMASTER: job (4, 0, 26) submitted to dispatcher
01:00:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:00:12 DISPATCHER: Trying to submit another job.
01:00:12 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:00:12 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:00:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:00:12 WORKER: start processing job (4, 0, 26)
01:00:12 WORKER: args: ()
01:00:12 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0013426425700155983, 'num_filters_1': 72, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.015270295701324885, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 115, 'num_filters_3': 19, 'num_filters_4': 47}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:01:10 DISPATCHER: Starting worker discovery
01:01:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:01:10 DISPATCHER: Finished worker discovery
01:02:10 DISPATCHER: Starting worker discovery
01:02:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:02:10 DISPATCHER: Finished worker discovery
01:03:10 DISPATCHER: Starting worker discovery
01:03:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:03:10 DISPATCHER: Finished worker discovery
01:03:33 WORKER: done with job (4, 0, 26), trying to register it.
01:03:33 WORKER: registered result for job (4, 0, 26) with dispatcher
01:03:33 DISPATCHER: job (4, 0, 26) finished
01:03:33 DISPATCHER: register_result: lock acquired
01:03:33 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:03:33 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0013426425700155983, 'num_filters_1': 72, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.015270295701324885, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 115, 'num_filters_3': 19, 'num_filters_4': 47}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5295575339039992, 'info': {'sick_no_sick': 0.5295575339039992, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0013426425700155983, 'num_filters_1': 72, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.015270295701324885, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 115, 'num_filters_3': 19, 'num_filters_4': 47}"}}
exception: None

01:03:33 job_callback for (4, 0, 26) started
01:03:33 job_callback for (4, 0, 26) got condition
01:03:33 DISPATCHER: Trying to submit another job.
01:03:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:03:33 HBMASTER: Trying to run another job!
01:03:33 job_callback for (4, 0, 26) finished
01:03:33 ITERATION: Advancing config (4, 0, 0) to next budget 400.000000
01:03:33 ITERATION: Advancing config (4, 0, 3) to next budget 400.000000
01:03:33 ITERATION: Advancing config (4, 0, 6) to next budget 400.000000
01:03:33 HBMASTER: schedule new run for iteration 4
01:03:33 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
01:03:33 HBMASTER: submitting job (4, 0, 0) to dispatcher
01:03:33 DISPATCHER: trying to submit job (4, 0, 0)
01:03:33 DISPATCHER: trying to notify the job_runner thread.
01:03:33 HBMASTER: job (4, 0, 0) submitted to dispatcher
01:03:33 DISPATCHER: Trying to submit another job.
01:03:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:03:33 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:03:33 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:03:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:03:33 WORKER: start processing job (4, 0, 0)
01:03:33 WORKER: args: ()
01:03:33 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001184286997691667, 'num_filters_1': 43, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.01512361074205936, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 53, 'num_filters_3': 102}, 'budget': 400.0, 'working_directory': '.'}
01:04:10 DISPATCHER: Starting worker discovery
01:04:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:04:10 DISPATCHER: Finished worker discovery
01:05:10 DISPATCHER: Starting worker discovery
01:05:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:05:10 DISPATCHER: Finished worker discovery
01:06:10 DISPATCHER: Starting worker discovery
01:06:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:06:10 DISPATCHER: Finished worker discovery
01:07:10 DISPATCHER: Starting worker discovery
01:07:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:07:10 DISPATCHER: Finished worker discovery
01:08:10 DISPATCHER: Starting worker discovery
01:08:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:08:10 DISPATCHER: Finished worker discovery
01:09:10 DISPATCHER: Starting worker discovery
01:09:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:09:10 DISPATCHER: Finished worker discovery
01:10:10 DISPATCHER: Starting worker discovery
01:10:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:10:10 DISPATCHER: Finished worker discovery
01:11:10 DISPATCHER: Starting worker discovery
01:11:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:11:10 DISPATCHER: Finished worker discovery
01:11:36 WORKER: done with job (4, 0, 0), trying to register it.
01:11:36 WORKER: registered result for job (4, 0, 0) with dispatcher
01:11:36 DISPATCHER: job (4, 0, 0) finished
01:11:36 DISPATCHER: register_result: lock acquired
01:11:36 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:11:36 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001184286997691667, 'num_filters_1': 43, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.01512361074205936, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 53, 'num_filters_3': 102}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5282166207625991, 'info': {'sick_no_sick': 0.5282166207625991, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001184286997691667, 'num_filters_1': 43, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.01512361074205936, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 53, 'num_filters_3': 102}"}}
exception: None

01:11:36 job_callback for (4, 0, 0) started
01:11:36 DISPATCHER: Trying to submit another job.
01:11:36 job_callback for (4, 0, 0) got condition
01:11:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:11:36 Only 13 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
01:11:36 HBMASTER: Trying to run another job!
01:11:36 job_callback for (4, 0, 0) finished
01:11:36 HBMASTER: schedule new run for iteration 4
01:11:36 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
01:11:36 HBMASTER: submitting job (4, 0, 3) to dispatcher
01:11:36 DISPATCHER: trying to submit job (4, 0, 3)
01:11:36 DISPATCHER: trying to notify the job_runner thread.
01:11:36 HBMASTER: job (4, 0, 3) submitted to dispatcher
01:11:36 DISPATCHER: Trying to submit another job.
01:11:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:11:36 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:11:36 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:11:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:11:36 WORKER: start processing job (4, 0, 3)
01:11:36 WORKER: args: ()
01:11:36 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004487946858748581, 'num_filters_1': 31, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.012971204010703003, 'kernel_size_2': 7, 'num_filters_2': 63}, 'budget': 400.0, 'working_directory': '.'}
01:12:10 DISPATCHER: Starting worker discovery
01:12:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:12:10 DISPATCHER: Finished worker discovery
01:13:10 DISPATCHER: Starting worker discovery
01:13:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:13:10 DISPATCHER: Finished worker discovery
01:14:10 DISPATCHER: Starting worker discovery
01:14:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:14:10 DISPATCHER: Finished worker discovery
01:15:10 DISPATCHER: Starting worker discovery
01:15:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:15:10 DISPATCHER: Finished worker discovery
01:16:10 DISPATCHER: Starting worker discovery
01:16:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:16:10 DISPATCHER: Finished worker discovery
01:17:10 DISPATCHER: Starting worker discovery
01:17:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:17:10 DISPATCHER: Finished worker discovery
01:18:10 DISPATCHER: Starting worker discovery
01:18:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:18:10 DISPATCHER: Finished worker discovery
01:19:10 DISPATCHER: Starting worker discovery
01:19:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:19:10 DISPATCHER: Finished worker discovery
01:19:21 WORKER: done with job (4, 0, 3), trying to register it.
01:19:21 WORKER: registered result for job (4, 0, 3) with dispatcher
01:19:21 DISPATCHER: job (4, 0, 3) finished
01:19:21 DISPATCHER: register_result: lock acquired
01:19:21 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:19:21 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004487946858748581, 'num_filters_1': 31, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.012971204010703003, 'kernel_size_2': 7, 'num_filters_2': 63}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5381527735858257, 'info': {'sick_no_sick': 0.5381527735858257, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004487946858748581, 'num_filters_1': 31, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.012971204010703003, 'kernel_size_2': 7, 'num_filters_2': 63}"}}
exception: None

01:19:21 job_callback for (4, 0, 3) started
01:19:21 job_callback for (4, 0, 3) got condition
01:19:21 DISPATCHER: Trying to submit another job.
01:19:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:19:21 Only 14 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
01:19:21 HBMASTER: Trying to run another job!
01:19:21 job_callback for (4, 0, 3) finished
01:19:21 HBMASTER: schedule new run for iteration 4
01:19:21 HBMASTER: trying submitting job (4, 0, 6) to dispatcher
01:19:21 HBMASTER: submitting job (4, 0, 6) to dispatcher
01:19:21 DISPATCHER: trying to submit job (4, 0, 6)
01:19:21 DISPATCHER: trying to notify the job_runner thread.
01:19:21 HBMASTER: job (4, 0, 6) submitted to dispatcher
01:19:21 DISPATCHER: Trying to submit another job.
01:19:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:19:21 DISPATCHER: starting job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:19:21 DISPATCHER: job (4, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:19:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:19:21 WORKER: start processing job (4, 0, 6)
01:19:21 WORKER: args: ()
01:19:21 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.007565901365910238, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.03669303233286641, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 91, 'num_filters_3': 120, 'num_filters_4': 59}, 'budget': 400.0, 'working_directory': '.'}
01:20:10 DISPATCHER: Starting worker discovery
01:20:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:20:10 DISPATCHER: Finished worker discovery
01:21:10 DISPATCHER: Starting worker discovery
01:21:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:21:10 DISPATCHER: Finished worker discovery
01:22:10 DISPATCHER: Starting worker discovery
01:22:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:22:10 DISPATCHER: Finished worker discovery
01:23:10 DISPATCHER: Starting worker discovery
01:23:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:23:10 DISPATCHER: Finished worker discovery
01:24:10 DISPATCHER: Starting worker discovery
01:24:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:24:10 DISPATCHER: Finished worker discovery
01:25:10 DISPATCHER: Starting worker discovery
01:25:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:25:10 DISPATCHER: Finished worker discovery
01:26:10 DISPATCHER: Starting worker discovery
01:26:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:26:10 DISPATCHER: Finished worker discovery
01:27:06 WORKER: done with job (4, 0, 6), trying to register it.
01:27:06 WORKER: registered result for job (4, 0, 6) with dispatcher
01:27:06 DISPATCHER: job (4, 0, 6) finished
01:27:06 DISPATCHER: register_result: lock acquired
01:27:06 DISPATCHER: job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:27:06 job_id: (4, 0, 6)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.007565901365910238, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.03669303233286641, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 91, 'num_filters_3': 120, 'num_filters_4': 59}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.43954510395762136, 'info': {'sick_no_sick': 0.43954510395762136, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.007565901365910238, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.03669303233286641, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 91, 'num_filters_3': 120, 'num_filters_4': 59}"}}
exception: None

01:27:06 DISPATCHER: Trying to submit another job.
01:27:06 job_callback for (4, 0, 6) started
01:27:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:27:06 job_callback for (4, 0, 6) got condition
01:27:06 Only 15 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
01:27:06 HBMASTER: Trying to run another job!
01:27:06 job_callback for (4, 0, 6) finished
01:27:06 ITERATION: Advancing config (4, 0, 3) to next budget 1200.000000
01:27:06 HBMASTER: schedule new run for iteration 4
01:27:06 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
01:27:06 HBMASTER: submitting job (4, 0, 3) to dispatcher
01:27:06 DISPATCHER: trying to submit job (4, 0, 3)
01:27:06 DISPATCHER: trying to notify the job_runner thread.
01:27:06 HBMASTER: job (4, 0, 3) submitted to dispatcher
01:27:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:27:06 DISPATCHER: Trying to submit another job.
01:27:06 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:27:06 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:27:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:27:06 WORKER: start processing job (4, 0, 3)
01:27:06 WORKER: args: ()
01:27:06 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004487946858748581, 'num_filters_1': 31, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.012971204010703003, 'kernel_size_2': 7, 'num_filters_2': 63}, 'budget': 1200.0, 'working_directory': '.'}
01:27:10 DISPATCHER: Starting worker discovery
01:27:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:27:10 DISPATCHER: Finished worker discovery
01:28:10 DISPATCHER: Starting worker discovery
01:28:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:28:11 DISPATCHER: Finished worker discovery
01:29:11 DISPATCHER: Starting worker discovery
01:29:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:29:11 DISPATCHER: Finished worker discovery
01:30:11 DISPATCHER: Starting worker discovery
01:30:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:30:11 DISPATCHER: Finished worker discovery
01:31:11 DISPATCHER: Starting worker discovery
01:31:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:31:11 DISPATCHER: Finished worker discovery
01:32:11 DISPATCHER: Starting worker discovery
01:32:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:32:11 DISPATCHER: Finished worker discovery
01:33:11 DISPATCHER: Starting worker discovery
01:33:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:33:11 DISPATCHER: Finished worker discovery
01:34:11 DISPATCHER: Starting worker discovery
01:34:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:34:11 DISPATCHER: Finished worker discovery
01:35:11 DISPATCHER: Starting worker discovery
01:35:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:35:11 DISPATCHER: Finished worker discovery
01:36:11 DISPATCHER: Starting worker discovery
01:36:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:36:11 DISPATCHER: Finished worker discovery
01:37:11 DISPATCHER: Starting worker discovery
01:37:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:37:11 DISPATCHER: Finished worker discovery
01:38:11 DISPATCHER: Starting worker discovery
01:38:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:38:11 DISPATCHER: Finished worker discovery
01:39:11 DISPATCHER: Starting worker discovery
01:39:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:39:11 DISPATCHER: Finished worker discovery
01:40:11 DISPATCHER: Starting worker discovery
01:40:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:40:11 DISPATCHER: Finished worker discovery
01:41:11 DISPATCHER: Starting worker discovery
01:41:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:41:11 DISPATCHER: Finished worker discovery
01:42:11 DISPATCHER: Starting worker discovery
01:42:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:42:11 DISPATCHER: Finished worker discovery
01:43:11 DISPATCHER: Starting worker discovery
01:43:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:43:11 DISPATCHER: Finished worker discovery
01:44:11 DISPATCHER: Starting worker discovery
01:44:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:44:11 DISPATCHER: Finished worker discovery
01:45:11 DISPATCHER: Starting worker discovery
01:45:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:45:11 DISPATCHER: Finished worker discovery
01:46:11 DISPATCHER: Starting worker discovery
01:46:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:46:11 DISPATCHER: Finished worker discovery
01:47:11 DISPATCHER: Starting worker discovery
01:47:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:47:11 DISPATCHER: Finished worker discovery
01:48:11 DISPATCHER: Starting worker discovery
01:48:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:48:11 DISPATCHER: Finished worker discovery
01:48:17 WORKER: done with job (4, 0, 3), trying to register it.
01:48:17 WORKER: registered result for job (4, 0, 3) with dispatcher
01:48:17 DISPATCHER: job (4, 0, 3) finished
01:48:17 DISPATCHER: register_result: lock acquired
01:48:17 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:48:17 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004487946858748581, 'num_filters_1': 31, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.012971204010703003, 'kernel_size_2': 7, 'num_filters_2': 63}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5428465182195795, 'info': {'sick_no_sick': 0.5428465182195795, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004487946858748581, 'num_filters_1': 31, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.012971204010703003, 'kernel_size_2': 7, 'num_filters_2': 63}"}}
exception: None

01:48:17 job_callback for (4, 0, 3) started
01:48:17 DISPATCHER: Trying to submit another job.
01:48:17 job_callback for (4, 0, 3) got condition
01:48:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:48:18 Only 9 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
01:48:18 HBMASTER: Trying to run another job!
01:48:18 job_callback for (4, 0, 3) finished
01:48:18 start sampling a new configuration.
01:48:18 best_vector: [0, 2, 0.933214387615695, 0.06945979200391778, 0.0413952796344329, 1, 0.8208469995433171, 0.3251281400109453, 1, 2, 1, 2, 0.8332182858212874, 0.2636907657046762, 0.5216696610778926, 0.33935864214057126], 0.0010156885102565324, 0.005021427128396052, 5.100205839402323e-06
01:48:18 done sampling a new configuration.
01:48:18 HBMASTER: schedule new run for iteration 5
01:48:18 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
01:48:18 HBMASTER: submitting job (5, 0, 0) to dispatcher
01:48:18 DISPATCHER: trying to submit job (5, 0, 0)
01:48:18 DISPATCHER: trying to notify the job_runner thread.
01:48:18 HBMASTER: job (5, 0, 0) submitted to dispatcher
01:48:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:48:18 DISPATCHER: Trying to submit another job.
01:48:18 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:48:18 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:48:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:48:18 WORKER: start processing job (5, 0, 0)
01:48:18 WORKER: args: ()
01:48:18 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.07352394055229794, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.026485090580680392}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:49:11 DISPATCHER: Starting worker discovery
01:49:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:49:11 DISPATCHER: Finished worker discovery
01:50:11 DISPATCHER: Starting worker discovery
01:50:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:50:11 DISPATCHER: Finished worker discovery
01:51:11 DISPATCHER: Starting worker discovery
01:51:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:51:11 DISPATCHER: Finished worker discovery
01:51:34 WORKER: done with job (5, 0, 0), trying to register it.
01:51:34 WORKER: registered result for job (5, 0, 0) with dispatcher
01:51:34 DISPATCHER: job (5, 0, 0) finished
01:51:34 DISPATCHER: register_result: lock acquired
01:51:34 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:51:34 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.07352394055229794, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.026485090580680392}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.47866676215124426, 'info': {'sick_no_sick': 0.47866676215124426, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.07352394055229794, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.026485090580680392}"}}
exception: None

01:51:34 job_callback for (5, 0, 0) started
01:51:34 job_callback for (5, 0, 0) got condition
01:51:34 DISPATCHER: Trying to submit another job.
01:51:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:51:34 HBMASTER: Trying to run another job!
01:51:34 job_callback for (5, 0, 0) finished
01:51:34 start sampling a new configuration.
01:51:35 best_vector: [1, 2, 0.39119818577264154, 0.052867036313147084, 0.3097468997115678, 0, 0.3182354847472292, 0.07134772714292786, 0, 2, 1, 1, 0.28787609212100923, 0.4564702791532137, 0.47062012740790654, 0.3864778562884325], 0.0060562022208303775, 0.00209777184849538, 1.2704530527653166e-05
01:51:35 done sampling a new configuration.
01:51:35 HBMASTER: schedule new run for iteration 5
01:51:35 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
01:51:35 HBMASTER: submitting job (5, 0, 1) to dispatcher
01:51:35 DISPATCHER: trying to submit job (5, 0, 1)
01:51:35 DISPATCHER: trying to notify the job_runner thread.
01:51:35 HBMASTER: job (5, 0, 1) submitted to dispatcher
01:51:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:51:35 DISPATCHER: Trying to submit another job.
01:51:35 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:51:35 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:51:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:51:35 WORKER: start processing job (5, 0, 1)
01:51:35 WORKER: args: ()
01:51:35 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.006058936089822977, 'num_filters_1': 17, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.012382990311642141, 'kernel_size_2': 3, 'num_filters_2': 28}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:52:11 DISPATCHER: Starting worker discovery
01:52:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:52:11 DISPATCHER: Finished worker discovery
01:53:11 DISPATCHER: Starting worker discovery
01:53:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:53:11 DISPATCHER: Finished worker discovery
01:54:11 DISPATCHER: Starting worker discovery
01:54:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:54:11 DISPATCHER: Finished worker discovery
01:54:53 WORKER: done with job (5, 0, 1), trying to register it.
01:54:53 WORKER: registered result for job (5, 0, 1) with dispatcher
01:54:53 DISPATCHER: job (5, 0, 1) finished
01:54:53 DISPATCHER: register_result: lock acquired
01:54:53 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:54:53 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.006058936089822977, 'num_filters_1': 17, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.012382990311642141, 'kernel_size_2': 3, 'num_filters_2': 28}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5292553377794943, 'info': {'sick_no_sick': 0.5292553377794943, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.006058936089822977, 'num_filters_1': 17, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.012382990311642141, 'kernel_size_2': 3, 'num_filters_2': 28}"}}
exception: None

01:54:53 job_callback for (5, 0, 1) started
01:54:53 job_callback for (5, 0, 1) got condition
01:54:53 DISPATCHER: Trying to submit another job.
01:54:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:54:53 HBMASTER: Trying to run another job!
01:54:53 job_callback for (5, 0, 1) finished
01:54:53 start sampling a new configuration.
01:54:53 done sampling a new configuration.
01:54:53 HBMASTER: schedule new run for iteration 5
01:54:53 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
01:54:53 HBMASTER: submitting job (5, 0, 2) to dispatcher
01:54:53 DISPATCHER: trying to submit job (5, 0, 2)
01:54:53 DISPATCHER: trying to notify the job_runner thread.
01:54:53 HBMASTER: job (5, 0, 2) submitted to dispatcher
01:54:53 DISPATCHER: Trying to submit another job.
01:54:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:54:53 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:54:53 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:54:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:54:53 WORKER: start processing job (5, 0, 2)
01:54:53 WORKER: args: ()
01:54:53 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.004604457945005117, 'num_filters_1': 35, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.015828761229990166, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 51, 'num_filters_3': 56, 'num_filters_4': 25, 'num_filters_5': 113}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:55:11 DISPATCHER: Starting worker discovery
01:55:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:55:11 DISPATCHER: Finished worker discovery
01:56:11 DISPATCHER: Starting worker discovery
01:56:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:56:11 DISPATCHER: Finished worker discovery
01:57:11 DISPATCHER: Starting worker discovery
01:57:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:57:11 DISPATCHER: Finished worker discovery
01:58:10 WORKER: done with job (5, 0, 2), trying to register it.
01:58:10 WORKER: registered result for job (5, 0, 2) with dispatcher
01:58:10 DISPATCHER: job (5, 0, 2) finished
01:58:10 DISPATCHER: register_result: lock acquired
01:58:10 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
01:58:10 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.004604457945005117, 'num_filters_1': 35, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.015828761229990166, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 51, 'num_filters_3': 56, 'num_filters_4': 25, 'num_filters_5': 113}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.004604457945005117, 'num_filters_1': 35, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.015828761229990166, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 51, 'num_filters_3': 56, 'num_filters_4': 25, 'num_filters_5': 113}"}}
exception: None

01:58:10 job_callback for (5, 0, 2) started
01:58:10 job_callback for (5, 0, 2) got condition
01:58:10 DISPATCHER: Trying to submit another job.
01:58:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:58:10 HBMASTER: Trying to run another job!
01:58:10 job_callback for (5, 0, 2) finished
01:58:10 start sampling a new configuration.
01:58:10 best_vector: [2, 1, 0.4541617624147062, 0.15036158421958135, 0.45501693788503406, 1, 0.8730471805494905, 0.523085557419747, 1, 1, 1, 0, 0.8991040929334001, 0.8509298673577855, 0.5445086309782473, 0.6940917956108277], 0.0013246752964975572, 0.02140246786157454, 2.835132046031069e-05
01:58:10 done sampling a new configuration.
01:58:10 HBMASTER: schedule new run for iteration 5
01:58:10 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
01:58:10 HBMASTER: submitting job (5, 0, 3) to dispatcher
01:58:10 DISPATCHER: trying to submit job (5, 0, 3)
01:58:10 DISPATCHER: trying to notify the job_runner thread.
01:58:10 HBMASTER: job (5, 0, 3) submitted to dispatcher
01:58:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:58:10 DISPATCHER: Trying to submit another job.
01:58:10 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:58:10 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
01:58:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:58:10 WORKER: start processing job (5, 0, 3)
01:58:10 WORKER: args: ()
01:58:10 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.00809698854424323, 'num_filters_1': 21, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.04792366244411976, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 104, 'num_filters_3': 94}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:58:11 DISPATCHER: Starting worker discovery
01:58:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:58:11 DISPATCHER: Finished worker discovery
01:59:11 DISPATCHER: Starting worker discovery
01:59:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:59:11 DISPATCHER: Finished worker discovery
02:00:11 DISPATCHER: Starting worker discovery
02:00:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:00:11 DISPATCHER: Finished worker discovery
02:01:11 DISPATCHER: Starting worker discovery
02:01:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:01:11 DISPATCHER: Finished worker discovery
02:01:25 WORKER: done with job (5, 0, 3), trying to register it.
02:01:25 WORKER: registered result for job (5, 0, 3) with dispatcher
02:01:25 DISPATCHER: job (5, 0, 3) finished
02:01:25 DISPATCHER: register_result: lock acquired
02:01:25 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:01:25 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.00809698854424323, 'num_filters_1': 21, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.04792366244411976, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 104, 'num_filters_3': 94}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4909717318087284, 'info': {'sick_no_sick': 0.4909717318087284, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.00809698854424323, 'num_filters_1': 21, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.04792366244411976, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 104, 'num_filters_3': 94}"}}
exception: None

02:01:25 job_callback for (5, 0, 3) started
02:01:25 job_callback for (5, 0, 3) got condition
02:01:25 DISPATCHER: Trying to submit another job.
02:01:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:01:25 HBMASTER: Trying to run another job!
02:01:25 job_callback for (5, 0, 3) finished
02:01:25 start sampling a new configuration.
02:01:25 done sampling a new configuration.
02:01:25 HBMASTER: schedule new run for iteration 5
02:01:25 HBMASTER: trying submitting job (5, 0, 4) to dispatcher
02:01:25 HBMASTER: submitting job (5, 0, 4) to dispatcher
02:01:25 DISPATCHER: trying to submit job (5, 0, 4)
02:01:25 DISPATCHER: trying to notify the job_runner thread.
02:01:25 HBMASTER: job (5, 0, 4) submitted to dispatcher
02:01:25 DISPATCHER: Trying to submit another job.
02:01:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:01:25 DISPATCHER: starting job (5, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:01:25 DISPATCHER: job (5, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:01:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:01:25 WORKER: start processing job (5, 0, 4)
02:01:25 WORKER: args: ()
02:01:25 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.09745229359196765, 'num_filters_1': 63, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.19777981083622845, 'kernel_size_2': 7, 'num_filters_2': 27}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:02:11 DISPATCHER: Starting worker discovery
02:02:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:02:11 DISPATCHER: Finished worker discovery
02:03:11 DISPATCHER: Starting worker discovery
02:03:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:03:11 DISPATCHER: Finished worker discovery
02:04:11 DISPATCHER: Starting worker discovery
02:04:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:04:11 DISPATCHER: Finished worker discovery
02:04:44 WORKER: done with job (5, 0, 4), trying to register it.
02:04:44 WORKER: registered result for job (5, 0, 4) with dispatcher
02:04:44 DISPATCHER: job (5, 0, 4) finished
02:04:44 DISPATCHER: register_result: lock acquired
02:04:44 DISPATCHER: job (5, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:04:44 job_id: (5, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.09745229359196765, 'num_filters_1': 63, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.19777981083622845, 'kernel_size_2': 7, 'num_filters_2': 27}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.00549656647601887, 'info': {'sick_no_sick': 0.00549656647601887, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.09745229359196765, 'num_filters_1': 63, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.19777981083622845, 'kernel_size_2': 7, 'num_filters_2': 27}"}}
exception: None

02:04:44 job_callback for (5, 0, 4) started
02:04:44 DISPATCHER: Trying to submit another job.
02:04:44 job_callback for (5, 0, 4) got condition
02:04:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:04:44 HBMASTER: Trying to run another job!
02:04:44 job_callback for (5, 0, 4) finished
02:04:44 start sampling a new configuration.
02:04:44 best_vector: [2, 0, 0.9827927560464198, 0.05299358435648298, 0.40613080862328155, 1, 0.7957535895754261, 0.19377623592115867, 1, 0, 1, 2, 0.47302286674019717, 0.906286479601629, 0.5879163360793987, 0.46575621894462976], 0.0030405734979853613, 0.0011412227617567797, 3.4699716846953264e-06
02:04:44 done sampling a new configuration.
02:04:44 HBMASTER: schedule new run for iteration 5
02:04:44 HBMASTER: trying submitting job (5, 0, 5) to dispatcher
02:04:44 HBMASTER: submitting job (5, 0, 5) to dispatcher
02:04:44 DISPATCHER: trying to submit job (5, 0, 5)
02:04:44 DISPATCHER: trying to notify the job_runner thread.
02:04:44 HBMASTER: job (5, 0, 5) submitted to dispatcher
02:04:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:04:44 DISPATCHER: Trying to submit another job.
02:04:44 DISPATCHER: starting job (5, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:04:44 DISPATCHER: job (5, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:04:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:04:44 WORKER: start processing job (5, 0, 5)
02:04:44 WORKER: args: ()
02:04:44 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.09238160688532869, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.017869347535672698, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 42, 'num_filters_3': 105}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:05:11 DISPATCHER: Starting worker discovery
02:05:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:05:11 DISPATCHER: Finished worker discovery
02:06:11 DISPATCHER: Starting worker discovery
02:06:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:06:11 DISPATCHER: Finished worker discovery
02:07:11 DISPATCHER: Starting worker discovery
02:07:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:07:11 DISPATCHER: Finished worker discovery
02:08:02 WORKER: done with job (5, 0, 5), trying to register it.
02:08:02 WORKER: registered result for job (5, 0, 5) with dispatcher
02:08:02 DISPATCHER: job (5, 0, 5) finished
02:08:02 DISPATCHER: register_result: lock acquired
02:08:02 DISPATCHER: job (5, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:08:02 job_id: (5, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.09238160688532869, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.017869347535672698, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 42, 'num_filters_3': 105}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.005761533433720038, 'info': {'sick_no_sick': 0.005761533433720038, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.09238160688532869, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.017869347535672698, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 42, 'num_filters_3': 105}"}}
exception: None

02:08:02 job_callback for (5, 0, 5) started
02:08:02 DISPATCHER: Trying to submit another job.
02:08:02 job_callback for (5, 0, 5) got condition
02:08:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:08:02 HBMASTER: Trying to run another job!
02:08:02 job_callback for (5, 0, 5) finished
02:08:02 start sampling a new configuration.
02:08:02 done sampling a new configuration.
02:08:02 HBMASTER: schedule new run for iteration 5
02:08:02 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
02:08:02 HBMASTER: submitting job (5, 0, 6) to dispatcher
02:08:02 DISPATCHER: trying to submit job (5, 0, 6)
02:08:02 DISPATCHER: trying to notify the job_runner thread.
02:08:02 HBMASTER: job (5, 0, 6) submitted to dispatcher
02:08:02 DISPATCHER: Trying to submit another job.
02:08:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:08:02 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:08:02 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:08:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:08:02 WORKER: start processing job (5, 0, 6)
02:08:02 WORKER: args: ()
02:08:02 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.06780662378436794, 'num_filters_1': 112, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.047288520738834876, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 33, 'num_filters_3': 32, 'num_filters_4': 66, 'num_filters_5': 112}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:08:11 DISPATCHER: Starting worker discovery
02:08:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:08:11 DISPATCHER: Finished worker discovery
02:09:11 DISPATCHER: Starting worker discovery
02:09:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:09:11 DISPATCHER: Finished worker discovery
02:10:11 DISPATCHER: Starting worker discovery
02:10:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:10:11 DISPATCHER: Finished worker discovery
02:11:11 DISPATCHER: Starting worker discovery
02:11:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:11:11 DISPATCHER: Finished worker discovery
02:11:19 WORKER: done with job (5, 0, 6), trying to register it.
02:11:19 WORKER: registered result for job (5, 0, 6) with dispatcher
02:11:19 DISPATCHER: job (5, 0, 6) finished
02:11:19 DISPATCHER: register_result: lock acquired
02:11:19 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:11:19 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.06780662378436794, 'num_filters_1': 112, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.047288520738834876, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 33, 'num_filters_3': 32, 'num_filters_4': 66, 'num_filters_5': 112}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.06780662378436794, 'num_filters_1': 112, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.047288520738834876, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 33, 'num_filters_3': 32, 'num_filters_4': 66, 'num_filters_5': 112}"}}
exception: None

02:11:19 job_callback for (5, 0, 6) started
02:11:19 job_callback for (5, 0, 6) got condition
02:11:19 DISPATCHER: Trying to submit another job.
02:11:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:11:19 done building a new model for budget 133.333333 based on 17/28 split
Best loss for this budget:-0.553150





02:11:19 HBMASTER: Trying to run another job!
02:11:19 job_callback for (5, 0, 6) finished
02:11:19 start sampling a new configuration.
02:11:19 best_vector: [0, 0, 0.29189745774530057, 0.05402480915515362, 0.5877930686525167, 1, 0.7552663568033504, 0.5798755669894005, 2, 0, 0, 2, 0.7175156122683659, 0.980831151399487, 0.5442921454834135, 0.21667027932155647], 0.0006767274305811133, 0.014614055279382634, 9.889732079586964e-06
02:11:19 done sampling a new configuration.
02:11:19 HBMASTER: schedule new run for iteration 5
02:11:19 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
02:11:19 HBMASTER: submitting job (5, 0, 7) to dispatcher
02:11:19 DISPATCHER: trying to submit job (5, 0, 7)
02:11:19 DISPATCHER: trying to notify the job_runner thread.
02:11:19 HBMASTER: job (5, 0, 7) submitted to dispatcher
02:11:19 DISPATCHER: Trying to submit another job.
02:11:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:11:19 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:11:19 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:11:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:11:19 WORKER: start processing job (5, 0, 7)
02:11:19 WORKER: args: ()
02:11:19 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.00383526092292887, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.056811401923381376, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 71, 'num_filters_3': 123}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:12:11 DISPATCHER: Starting worker discovery
02:12:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:12:11 DISPATCHER: Finished worker discovery
02:13:11 DISPATCHER: Starting worker discovery
02:13:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:13:11 DISPATCHER: Finished worker discovery
02:14:11 DISPATCHER: Starting worker discovery
02:14:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:14:11 DISPATCHER: Finished worker discovery
02:14:37 WORKER: done with job (5, 0, 7), trying to register it.
02:14:37 WORKER: registered result for job (5, 0, 7) with dispatcher
02:14:37 DISPATCHER: job (5, 0, 7) finished
02:14:37 DISPATCHER: register_result: lock acquired
02:14:37 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:14:37 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.00383526092292887, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.056811401923381376, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 71, 'num_filters_3': 123}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.517182767178703, 'info': {'sick_no_sick': 0.517182767178703, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.00383526092292887, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.056811401923381376, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 71, 'num_filters_3': 123}"}}
exception: None

02:14:37 job_callback for (5, 0, 7) started
02:14:37 DISPATCHER: Trying to submit another job.
02:14:37 job_callback for (5, 0, 7) got condition
02:14:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:14:37 done building a new model for budget 133.333333 based on 17/29 split
Best loss for this budget:-0.553150





02:14:37 HBMASTER: Trying to run another job!
02:14:37 job_callback for (5, 0, 7) finished
02:14:37 start sampling a new configuration.
02:14:37 best_vector: [0, 2, 0.27096530457877965, 0.5438304771628804, 0.4024127706150084, 1, 0.6048593913582332, 0.607529600491802, 2, 0, 1, 0, 0.9679107310890628, 0.7734513841009614, 0.4883284540445175, 0.5132157224045378], 0.010674457279377566, 0.0014503444052977599, 1.54816393947352e-05
02:14:37 done sampling a new configuration.
02:14:37 HBMASTER: schedule new run for iteration 5
02:14:37 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
02:14:37 HBMASTER: submitting job (5, 0, 8) to dispatcher
02:14:37 DISPATCHER: trying to submit job (5, 0, 8)
02:14:37 DISPATCHER: trying to notify the job_runner thread.
02:14:37 HBMASTER: job (5, 0, 8) submitted to dispatcher
02:14:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:14:37 DISPATCHER: Trying to submit another job.
02:14:37 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:14:37 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:14:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:14:37 WORKER: start processing job (5, 0, 8)
02:14:37 WORKER: args: ()
02:14:37 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0034828166273136742, 'num_filters_1': 49, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.06171833955879063, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 120, 'num_filters_3': 80}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:15:11 DISPATCHER: Starting worker discovery
02:15:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:15:11 DISPATCHER: Finished worker discovery
02:16:11 DISPATCHER: Starting worker discovery
02:16:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:16:11 DISPATCHER: Finished worker discovery
02:17:11 DISPATCHER: Starting worker discovery
02:17:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:17:11 DISPATCHER: Finished worker discovery
02:17:55 WORKER: done with job (5, 0, 8), trying to register it.
02:17:55 WORKER: registered result for job (5, 0, 8) with dispatcher
02:17:55 DISPATCHER: job (5, 0, 8) finished
02:17:55 DISPATCHER: register_result: lock acquired
02:17:55 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:17:55 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0034828166273136742, 'num_filters_1': 49, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.06171833955879063, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 120, 'num_filters_3': 80}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5291782068454202, 'info': {'sick_no_sick': 0.5291782068454202, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0034828166273136742, 'num_filters_1': 49, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.06171833955879063, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 120, 'num_filters_3': 80}"}}
exception: None

02:17:55 job_callback for (5, 0, 8) started
02:17:55 DISPATCHER: Trying to submit another job.
02:17:55 job_callback for (5, 0, 8) got condition
02:17:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:17:55 done building a new model for budget 133.333333 based on 17/30 split
Best loss for this budget:-0.553150





02:17:55 HBMASTER: Trying to run another job!
02:17:55 job_callback for (5, 0, 8) finished
02:17:55 ITERATION: Advancing config (5, 0, 1) to next budget 400.000000
02:17:55 ITERATION: Advancing config (5, 0, 7) to next budget 400.000000
02:17:55 ITERATION: Advancing config (5, 0, 8) to next budget 400.000000
02:17:55 HBMASTER: schedule new run for iteration 5
02:17:55 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
02:17:55 HBMASTER: submitting job (5, 0, 1) to dispatcher
02:17:55 DISPATCHER: trying to submit job (5, 0, 1)
02:17:55 DISPATCHER: trying to notify the job_runner thread.
02:17:55 HBMASTER: job (5, 0, 1) submitted to dispatcher
02:17:55 DISPATCHER: Trying to submit another job.
02:17:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:17:55 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:17:55 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:17:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:17:55 WORKER: start processing job (5, 0, 1)
02:17:55 WORKER: args: ()
02:17:55 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.006058936089822977, 'num_filters_1': 17, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.012382990311642141, 'kernel_size_2': 3, 'num_filters_2': 28}, 'budget': 400.0, 'working_directory': '.'}
02:18:11 DISPATCHER: Starting worker discovery
02:18:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:18:11 DISPATCHER: Finished worker discovery
02:19:11 DISPATCHER: Starting worker discovery
02:19:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:19:11 DISPATCHER: Finished worker discovery
02:20:11 DISPATCHER: Starting worker discovery
02:20:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:20:11 DISPATCHER: Finished worker discovery
02:21:11 DISPATCHER: Starting worker discovery
02:21:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:21:11 DISPATCHER: Finished worker discovery
02:22:11 DISPATCHER: Starting worker discovery
02:22:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:22:11 DISPATCHER: Finished worker discovery
02:23:11 DISPATCHER: Starting worker discovery
02:23:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:23:11 DISPATCHER: Finished worker discovery
02:24:11 DISPATCHER: Starting worker discovery
02:24:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:24:11 DISPATCHER: Finished worker discovery
02:25:11 DISPATCHER: Starting worker discovery
02:25:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:25:11 DISPATCHER: Finished worker discovery
02:25:47 WORKER: done with job (5, 0, 1), trying to register it.
02:25:47 WORKER: registered result for job (5, 0, 1) with dispatcher
02:25:47 DISPATCHER: job (5, 0, 1) finished
02:25:47 DISPATCHER: register_result: lock acquired
02:25:47 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:25:47 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.006058936089822977, 'num_filters_1': 17, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.012382990311642141, 'kernel_size_2': 3, 'num_filters_2': 28}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.45695117160221094, 'info': {'sick_no_sick': 0.45695117160221094, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.006058936089822977, 'num_filters_1': 17, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.012382990311642141, 'kernel_size_2': 3, 'num_filters_2': 28}"}}
exception: None

02:25:47 job_callback for (5, 0, 1) started
02:25:47 job_callback for (5, 0, 1) got condition
02:25:47 DISPATCHER: Trying to submit another job.
02:25:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:25:47 Only 16 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
02:25:47 HBMASTER: Trying to run another job!
02:25:47 job_callback for (5, 0, 1) finished
02:25:47 HBMASTER: schedule new run for iteration 5
02:25:47 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
02:25:47 HBMASTER: submitting job (5, 0, 7) to dispatcher
02:25:47 DISPATCHER: trying to submit job (5, 0, 7)
02:25:47 DISPATCHER: trying to notify the job_runner thread.
02:25:47 HBMASTER: job (5, 0, 7) submitted to dispatcher
02:25:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:25:47 DISPATCHER: Trying to submit another job.
02:25:47 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:25:47 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:25:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:25:47 WORKER: start processing job (5, 0, 7)
02:25:47 WORKER: args: ()
02:25:47 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.00383526092292887, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.056811401923381376, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 71, 'num_filters_3': 123}, 'budget': 400.0, 'working_directory': '.'}
02:26:11 DISPATCHER: Starting worker discovery
02:26:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:26:11 DISPATCHER: Finished worker discovery
02:27:11 DISPATCHER: Starting worker discovery
02:27:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:27:11 DISPATCHER: Finished worker discovery
02:28:11 DISPATCHER: Starting worker discovery
02:28:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:28:11 DISPATCHER: Finished worker discovery
02:29:11 DISPATCHER: Starting worker discovery
02:29:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:29:11 DISPATCHER: Finished worker discovery
02:30:11 DISPATCHER: Starting worker discovery
02:30:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:30:11 DISPATCHER: Finished worker discovery
02:31:11 DISPATCHER: Starting worker discovery
02:31:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:31:11 DISPATCHER: Finished worker discovery
02:32:11 DISPATCHER: Starting worker discovery
02:32:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:32:11 DISPATCHER: Finished worker discovery
02:33:11 DISPATCHER: Starting worker discovery
02:33:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:33:11 DISPATCHER: Finished worker discovery
02:33:34 WORKER: done with job (5, 0, 7), trying to register it.
02:33:34 WORKER: registered result for job (5, 0, 7) with dispatcher
02:33:34 DISPATCHER: job (5, 0, 7) finished
02:33:34 DISPATCHER: register_result: lock acquired
02:33:34 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:33:34 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.00383526092292887, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.056811401923381376, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 71, 'num_filters_3': 123}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.47332714304351864, 'info': {'sick_no_sick': 0.47332714304351864, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.00383526092292887, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.056811401923381376, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 71, 'num_filters_3': 123}"}}
exception: None

02:33:34 job_callback for (5, 0, 7) started
02:33:34 DISPATCHER: Trying to submit another job.
02:33:34 job_callback for (5, 0, 7) got condition
02:33:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:33:34 HBMASTER: Trying to run another job!
02:33:34 job_callback for (5, 0, 7) finished
02:33:34 HBMASTER: schedule new run for iteration 5
02:33:34 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
02:33:34 HBMASTER: submitting job (5, 0, 8) to dispatcher
02:33:34 DISPATCHER: trying to submit job (5, 0, 8)
02:33:34 DISPATCHER: trying to notify the job_runner thread.
02:33:34 HBMASTER: job (5, 0, 8) submitted to dispatcher
02:33:34 DISPATCHER: Trying to submit another job.
02:33:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:33:34 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:33:34 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:33:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:33:34 WORKER: start processing job (5, 0, 8)
02:33:34 WORKER: args: ()
02:33:34 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0034828166273136742, 'num_filters_1': 49, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.06171833955879063, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 120, 'num_filters_3': 80}, 'budget': 400.0, 'working_directory': '.'}
02:34:11 DISPATCHER: Starting worker discovery
02:34:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:34:11 DISPATCHER: Finished worker discovery
02:35:11 DISPATCHER: Starting worker discovery
02:35:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:35:11 DISPATCHER: Finished worker discovery
02:36:11 DISPATCHER: Starting worker discovery
02:36:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:36:11 DISPATCHER: Finished worker discovery
02:37:11 DISPATCHER: Starting worker discovery
02:37:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:37:11 DISPATCHER: Finished worker discovery
02:38:11 DISPATCHER: Starting worker discovery
02:38:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:38:11 DISPATCHER: Finished worker discovery
02:39:11 DISPATCHER: Starting worker discovery
02:39:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:39:11 DISPATCHER: Finished worker discovery
02:40:11 DISPATCHER: Starting worker discovery
02:40:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:40:11 DISPATCHER: Finished worker discovery
02:41:11 DISPATCHER: Starting worker discovery
02:41:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:41:11 DISPATCHER: Finished worker discovery
02:41:25 WORKER: done with job (5, 0, 8), trying to register it.
02:41:25 WORKER: registered result for job (5, 0, 8) with dispatcher
02:41:25 DISPATCHER: job (5, 0, 8) finished
02:41:25 DISPATCHER: register_result: lock acquired
02:41:25 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
02:41:25 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0034828166273136742, 'num_filters_1': 49, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.06171833955879063, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 120, 'num_filters_3': 80}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5095123462759348, 'info': {'sick_no_sick': 0.5095123462759348, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0034828166273136742, 'num_filters_1': 49, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.06171833955879063, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 120, 'num_filters_3': 80}"}}
exception: None

02:41:25 job_callback for (5, 0, 8) started
02:41:25 job_callback for (5, 0, 8) got condition
02:41:25 DISPATCHER: Trying to submit another job.
02:41:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:41:25 HBMASTER: Trying to run another job!
02:41:25 job_callback for (5, 0, 8) finished
02:41:25 ITERATION: Advancing config (5, 0, 8) to next budget 1200.000000
02:41:25 HBMASTER: schedule new run for iteration 5
02:41:25 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
02:41:25 HBMASTER: submitting job (5, 0, 8) to dispatcher
02:41:25 DISPATCHER: trying to submit job (5, 0, 8)
02:41:25 DISPATCHER: trying to notify the job_runner thread.
02:41:25 HBMASTER: job (5, 0, 8) submitted to dispatcher
02:41:25 DISPATCHER: Trying to submit another job.
02:41:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:41:25 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:41:25 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
02:41:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:41:25 WORKER: start processing job (5, 0, 8)
02:41:25 WORKER: args: ()
02:41:25 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0034828166273136742, 'num_filters_1': 49, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.06171833955879063, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 120, 'num_filters_3': 80}, 'budget': 1200.0, 'working_directory': '.'}
02:42:11 DISPATCHER: Starting worker discovery
02:42:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:42:11 DISPATCHER: Finished worker discovery
02:43:11 DISPATCHER: Starting worker discovery
02:43:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:43:11 DISPATCHER: Finished worker discovery
02:44:11 DISPATCHER: Starting worker discovery
02:44:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:44:12 DISPATCHER: Finished worker discovery
02:45:12 DISPATCHER: Starting worker discovery
02:45:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:45:12 DISPATCHER: Finished worker discovery
02:46:12 DISPATCHER: Starting worker discovery
02:46:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:46:12 DISPATCHER: Finished worker discovery
02:47:12 DISPATCHER: Starting worker discovery
02:47:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:47:12 DISPATCHER: Finished worker discovery
02:48:12 DISPATCHER: Starting worker discovery
02:48:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:48:12 DISPATCHER: Finished worker discovery
02:49:12 DISPATCHER: Starting worker discovery
02:49:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:49:12 DISPATCHER: Finished worker discovery
02:50:12 DISPATCHER: Starting worker discovery
02:50:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:50:12 DISPATCHER: Finished worker discovery
02:51:12 DISPATCHER: Starting worker discovery
02:51:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:51:12 DISPATCHER: Finished worker discovery
02:52:12 DISPATCHER: Starting worker discovery
02:52:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:52:12 DISPATCHER: Finished worker discovery
02:53:12 DISPATCHER: Starting worker discovery
02:53:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:53:12 DISPATCHER: Finished worker discovery
02:54:12 DISPATCHER: Starting worker discovery
02:54:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:54:12 DISPATCHER: Finished worker discovery
02:55:12 DISPATCHER: Starting worker discovery
02:55:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:55:12 DISPATCHER: Finished worker discovery
02:56:12 DISPATCHER: Starting worker discovery
02:56:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:56:12 DISPATCHER: Finished worker discovery
02:57:12 DISPATCHER: Starting worker discovery
02:57:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:57:12 DISPATCHER: Finished worker discovery
02:58:12 DISPATCHER: Starting worker discovery
02:58:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:58:12 DISPATCHER: Finished worker discovery
02:59:12 DISPATCHER: Starting worker discovery
02:59:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:59:12 DISPATCHER: Finished worker discovery
03:00:12 DISPATCHER: Starting worker discovery
03:00:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:00:12 DISPATCHER: Finished worker discovery
03:01:12 DISPATCHER: Starting worker discovery
03:01:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:01:12 DISPATCHER: Finished worker discovery
03:02:12 DISPATCHER: Starting worker discovery
03:02:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:02:12 DISPATCHER: Finished worker discovery
03:02:47 WORKER: done with job (5, 0, 8), trying to register it.
03:02:47 WORKER: registered result for job (5, 0, 8) with dispatcher
03:02:47 DISPATCHER: job (5, 0, 8) finished
03:02:47 DISPATCHER: register_result: lock acquired
03:02:47 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
03:02:47 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0034828166273136742, 'num_filters_1': 49, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.06171833955879063, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 120, 'num_filters_3': 80}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.46237283964722353, 'info': {'sick_no_sick': 0.46237283964722353, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0034828166273136742, 'num_filters_1': 49, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.06171833955879063, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 120, 'num_filters_3': 80}"}}
exception: None

03:02:47 job_callback for (5, 0, 8) started
03:02:47 job_callback for (5, 0, 8) got condition
03:02:47 DISPATCHER: Trying to submit another job.
03:02:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:02:47 Only 10 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
03:02:47 HBMASTER: Trying to run another job!
03:02:47 job_callback for (5, 0, 8) finished
03:02:47 start sampling a new configuration.
03:02:47 done sampling a new configuration.
03:02:47 HBMASTER: schedule new run for iteration 6
03:02:47 HBMASTER: trying submitting job (6, 0, 0) to dispatcher
03:02:47 HBMASTER: submitting job (6, 0, 0) to dispatcher
03:02:47 DISPATCHER: trying to submit job (6, 0, 0)
03:02:47 DISPATCHER: trying to notify the job_runner thread.
03:02:47 HBMASTER: job (6, 0, 0) submitted to dispatcher
03:02:47 DISPATCHER: Trying to submit another job.
03:02:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:02:47 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:02:47 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:02:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:02:47 WORKER: start processing job (6, 0, 0)
03:02:47 WORKER: args: ()
03:02:47 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002220622954883731, 'num_filters_1': 117, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.025370090287063572, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 102, 'num_filters_3': 18}, 'budget': 400.0, 'working_directory': '.'}
03:03:12 DISPATCHER: Starting worker discovery
03:03:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:03:12 DISPATCHER: Finished worker discovery
03:04:12 DISPATCHER: Starting worker discovery
03:04:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:04:12 DISPATCHER: Finished worker discovery
03:05:12 DISPATCHER: Starting worker discovery
03:05:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:05:12 DISPATCHER: Finished worker discovery
03:06:12 DISPATCHER: Starting worker discovery
03:06:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:06:12 DISPATCHER: Finished worker discovery
03:07:12 DISPATCHER: Starting worker discovery
03:07:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:07:12 DISPATCHER: Finished worker discovery
03:08:12 DISPATCHER: Starting worker discovery
03:08:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:08:12 DISPATCHER: Finished worker discovery
03:09:12 DISPATCHER: Starting worker discovery
03:09:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:09:12 DISPATCHER: Finished worker discovery
03:10:12 DISPATCHER: Starting worker discovery
03:10:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:10:12 DISPATCHER: Finished worker discovery
03:10:39 WORKER: done with job (6, 0, 0), trying to register it.
03:10:39 WORKER: registered result for job (6, 0, 0) with dispatcher
03:10:39 DISPATCHER: job (6, 0, 0) finished
03:10:39 DISPATCHER: register_result: lock acquired
03:10:39 DISPATCHER: job (6, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
03:10:39 job_id: (6, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002220622954883731, 'num_filters_1': 117, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.025370090287063572, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 102, 'num_filters_3': 18}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5471848155548977, 'info': {'sick_no_sick': 0.5471848155548977, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002220622954883731, 'num_filters_1': 117, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.025370090287063572, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 102, 'num_filters_3': 18}"}}
exception: None

03:10:39 job_callback for (6, 0, 0) started
03:10:39 DISPATCHER: Trying to submit another job.
03:10:39 job_callback for (6, 0, 0) got condition
03:10:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:10:39 HBMASTER: Trying to run another job!
03:10:39 job_callback for (6, 0, 0) finished
03:10:39 start sampling a new configuration.
03:10:39 best_vector: [2, 2, 0.2092094876247955, 0.8168334842162005, 0.5969680293649948, 1, 0.6750401708010361, 0.12712695239846425, 2, 1, 0, 1, 0.8995800070546209, 0.7001206104380642, 0.5372450207040327, 0.9542067526099322], 0.0036374234511018675, 0.0032698486943547812, 1.1893824322400904e-05
03:10:39 done sampling a new configuration.
03:10:39 HBMASTER: schedule new run for iteration 6
03:10:39 HBMASTER: trying submitting job (6, 0, 1) to dispatcher
03:10:39 HBMASTER: submitting job (6, 0, 1) to dispatcher
03:10:39 DISPATCHER: trying to submit job (6, 0, 1)
03:10:39 DISPATCHER: trying to notify the job_runner thread.
03:10:39 HBMASTER: job (6, 0, 1) submitted to dispatcher
03:10:39 DISPATCHER: Trying to submit another job.
03:10:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:10:39 DISPATCHER: starting job (6, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:10:39 DISPATCHER: job (6, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:10:39 WORKER: start processing job (6, 0, 1)
03:10:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:10:39 WORKER: args: ()
03:10:39 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0026207100566281298, 'num_filters_1': 87, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.014635109572491829, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 104, 'num_filters_3': 68}, 'budget': 400.0, 'working_directory': '.'}
03:11:12 DISPATCHER: Starting worker discovery
03:11:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:11:12 DISPATCHER: Finished worker discovery
03:12:12 DISPATCHER: Starting worker discovery
03:12:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:12:12 DISPATCHER: Finished worker discovery
03:13:12 DISPATCHER: Starting worker discovery
03:13:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:13:12 DISPATCHER: Finished worker discovery
03:14:12 DISPATCHER: Starting worker discovery
03:14:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:14:12 DISPATCHER: Finished worker discovery
03:15:12 DISPATCHER: Starting worker discovery
03:15:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:15:12 DISPATCHER: Finished worker discovery
03:16:12 DISPATCHER: Starting worker discovery
03:16:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:16:12 DISPATCHER: Finished worker discovery
03:17:12 DISPATCHER: Starting worker discovery
03:17:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:17:12 DISPATCHER: Finished worker discovery
03:18:12 DISPATCHER: Starting worker discovery
03:18:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:18:12 DISPATCHER: Finished worker discovery
03:18:24 WORKER: done with job (6, 0, 1), trying to register it.
03:18:24 WORKER: registered result for job (6, 0, 1) with dispatcher
03:18:24 DISPATCHER: job (6, 0, 1) finished
03:18:24 DISPATCHER: register_result: lock acquired
03:18:24 DISPATCHER: job (6, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
03:18:24 job_id: (6, 0, 1)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0026207100566281298, 'num_filters_1': 87, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.014635109572491829, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 104, 'num_filters_3': 68}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5035936952987039, 'info': {'sick_no_sick': 0.5035936952987039, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0026207100566281298, 'num_filters_1': 87, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.014635109572491829, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 104, 'num_filters_3': 68}"}}
exception: None

03:18:24 job_callback for (6, 0, 1) started
03:18:24 DISPATCHER: Trying to submit another job.
03:18:24 job_callback for (6, 0, 1) got condition
03:18:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:18:24 HBMASTER: Trying to run another job!
03:18:24 job_callback for (6, 0, 1) finished
03:18:24 start sampling a new configuration.
03:18:24 done sampling a new configuration.
03:18:24 HBMASTER: schedule new run for iteration 6
03:18:24 HBMASTER: trying submitting job (6, 0, 2) to dispatcher
03:18:24 HBMASTER: submitting job (6, 0, 2) to dispatcher
03:18:24 DISPATCHER: trying to submit job (6, 0, 2)
03:18:24 DISPATCHER: trying to notify the job_runner thread.
03:18:24 HBMASTER: job (6, 0, 2) submitted to dispatcher
03:18:24 DISPATCHER: Trying to submit another job.
03:18:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:18:24 DISPATCHER: starting job (6, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:18:24 DISPATCHER: job (6, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:18:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:18:24 WORKER: start processing job (6, 0, 2)
03:18:24 WORKER: args: ()
03:18:24 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0017732758507883592, 'num_filters_1': 109, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.09617362201789591, 'kernel_size_2': 5, 'num_filters_2': 16}, 'budget': 400.0, 'working_directory': '.'}
03:19:12 DISPATCHER: Starting worker discovery
03:19:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:19:12 DISPATCHER: Finished worker discovery
03:20:12 DISPATCHER: Starting worker discovery
03:20:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:20:12 DISPATCHER: Finished worker discovery
03:21:12 DISPATCHER: Starting worker discovery
03:21:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:21:12 DISPATCHER: Finished worker discovery
03:22:12 DISPATCHER: Starting worker discovery
03:22:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:22:12 DISPATCHER: Finished worker discovery
03:23:12 DISPATCHER: Starting worker discovery
03:23:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:23:12 DISPATCHER: Finished worker discovery
03:24:12 DISPATCHER: Starting worker discovery
03:24:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:24:12 DISPATCHER: Finished worker discovery
03:25:12 DISPATCHER: Starting worker discovery
03:25:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:25:12 DISPATCHER: Finished worker discovery
03:26:11 WORKER: done with job (6, 0, 2), trying to register it.
03:26:11 WORKER: registered result for job (6, 0, 2) with dispatcher
03:26:11 DISPATCHER: job (6, 0, 2) finished
03:26:11 DISPATCHER: register_result: lock acquired
03:26:11 DISPATCHER: job (6, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
03:26:11 job_id: (6, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0017732758507883592, 'num_filters_1': 109, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.09617362201789591, 'kernel_size_2': 5, 'num_filters_2': 16}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3986224765654912, 'info': {'sick_no_sick': 0.3986224765654912, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0017732758507883592, 'num_filters_1': 109, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.09617362201789591, 'kernel_size_2': 5, 'num_filters_2': 16}"}}
exception: None

03:26:11 job_callback for (6, 0, 2) started
03:26:11 DISPATCHER: Trying to submit another job.
03:26:11 job_callback for (6, 0, 2) got condition
03:26:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:26:11 HBMASTER: Trying to run another job!
03:26:11 job_callback for (6, 0, 2) finished
03:26:11 start sampling a new configuration.
03:26:11 best_vector: [2, 2, 0.3627796687633819, 0.8413353440762483, 0.20662042881168965, 0, 0.06845417712757818, 0.23353005945367855, 1, 1, 1, 2, 0.8866879335489639, 0.8269015972918975, 0.6666723407174827, 0.6959495687594287], 0.0024592166422676216, 0.0004168977655777398, 1.0252419232329634e-06
03:26:11 done sampling a new configuration.
03:26:11 HBMASTER: schedule new run for iteration 6
03:26:11 HBMASTER: trying submitting job (6, 0, 3) to dispatcher
03:26:11 HBMASTER: submitting job (6, 0, 3) to dispatcher
03:26:11 DISPATCHER: trying to submit job (6, 0, 3)
03:26:11 DISPATCHER: trying to notify the job_runner thread.
03:26:11 HBMASTER: job (6, 0, 3) submitted to dispatcher
03:26:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:26:11 DISPATCHER: Trying to submit another job.
03:26:11 DISPATCHER: starting job (6, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:26:11 DISPATCHER: job (6, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:26:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:26:11 WORKER: start processing job (6, 0, 3)
03:26:11 WORKER: args: ()
03:26:11 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.005315686226091706, 'num_filters_1': 92, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.0201293435571659, 'kernel_size_2': 5, 'num_filters_2': 101}, 'budget': 400.0, 'working_directory': '.'}
03:26:12 DISPATCHER: Starting worker discovery
03:26:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:26:12 DISPATCHER: Finished worker discovery
03:27:12 DISPATCHER: Starting worker discovery
03:27:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:27:12 DISPATCHER: Finished worker discovery
03:28:12 DISPATCHER: Starting worker discovery
03:28:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:28:12 DISPATCHER: Finished worker discovery
03:29:12 DISPATCHER: Starting worker discovery
03:29:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:29:12 DISPATCHER: Finished worker discovery
03:30:12 DISPATCHER: Starting worker discovery
03:30:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:30:12 DISPATCHER: Finished worker discovery
03:31:12 DISPATCHER: Starting worker discovery
03:31:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:31:12 DISPATCHER: Finished worker discovery
03:32:12 DISPATCHER: Starting worker discovery
03:32:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:32:12 DISPATCHER: Finished worker discovery
03:33:12 DISPATCHER: Starting worker discovery
03:33:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:33:12 DISPATCHER: Finished worker discovery
03:34:10 WORKER: done with job (6, 0, 3), trying to register it.
03:34:10 WORKER: registered result for job (6, 0, 3) with dispatcher
03:34:10 DISPATCHER: job (6, 0, 3) finished
03:34:10 DISPATCHER: register_result: lock acquired
03:34:10 DISPATCHER: job (6, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
03:34:10 job_id: (6, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.005315686226091706, 'num_filters_1': 92, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.0201293435571659, 'kernel_size_2': 5, 'num_filters_2': 101}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.36875859286298657, 'info': {'sick_no_sick': 0.36875859286298657, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.005315686226091706, 'num_filters_1': 92, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.0201293435571659, 'kernel_size_2': 5, 'num_filters_2': 101}"}}
exception: None

03:34:10 job_callback for (6, 0, 3) started
03:34:10 DISPATCHER: Trying to submit another job.
03:34:10 job_callback for (6, 0, 3) got condition
03:34:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:34:10 HBMASTER: Trying to run another job!
03:34:10 job_callback for (6, 0, 3) finished
03:34:10 start sampling a new configuration.
03:34:10 done sampling a new configuration.
03:34:10 HBMASTER: schedule new run for iteration 6
03:34:10 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
03:34:10 HBMASTER: submitting job (6, 0, 4) to dispatcher
03:34:10 DISPATCHER: trying to submit job (6, 0, 4)
03:34:10 DISPATCHER: trying to notify the job_runner thread.
03:34:10 HBMASTER: job (6, 0, 4) submitted to dispatcher
03:34:10 DISPATCHER: Trying to submit another job.
03:34:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:34:10 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:34:10 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:34:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:34:10 WORKER: start processing job (6, 0, 4)
03:34:10 WORKER: args: ()
03:34:10 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0021835680935176267, 'num_filters_1': 121, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.02503639678026815, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 71, 'num_filters_3': 29}, 'budget': 400.0, 'working_directory': '.'}
03:34:12 DISPATCHER: Starting worker discovery
03:34:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:34:12 DISPATCHER: Finished worker discovery
03:35:12 DISPATCHER: Starting worker discovery
03:35:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:35:12 DISPATCHER: Finished worker discovery
03:36:12 DISPATCHER: Starting worker discovery
03:36:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:36:12 DISPATCHER: Finished worker discovery
03:37:12 DISPATCHER: Starting worker discovery
03:37:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:37:12 DISPATCHER: Finished worker discovery
03:38:12 DISPATCHER: Starting worker discovery
03:38:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:38:12 DISPATCHER: Finished worker discovery
03:39:12 DISPATCHER: Starting worker discovery
03:39:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:39:12 DISPATCHER: Finished worker discovery
03:40:12 DISPATCHER: Starting worker discovery
03:40:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:40:12 DISPATCHER: Finished worker discovery
03:41:12 DISPATCHER: Starting worker discovery
03:41:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:41:12 DISPATCHER: Finished worker discovery
03:42:08 WORKER: done with job (6, 0, 4), trying to register it.
03:42:08 WORKER: registered result for job (6, 0, 4) with dispatcher
03:42:08 DISPATCHER: job (6, 0, 4) finished
03:42:08 DISPATCHER: register_result: lock acquired
03:42:08 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
03:42:08 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0021835680935176267, 'num_filters_1': 121, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.02503639678026815, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 71, 'num_filters_3': 29}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5399925782701595, 'info': {'sick_no_sick': 0.5399925782701595, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0021835680935176267, 'num_filters_1': 121, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.02503639678026815, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 71, 'num_filters_3': 29}"}}
exception: None

03:42:08 job_callback for (6, 0, 4) started
03:42:08 DISPATCHER: Trying to submit another job.
03:42:08 job_callback for (6, 0, 4) got condition
03:42:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:42:08 HBMASTER: Trying to run another job!
03:42:08 job_callback for (6, 0, 4) finished
03:42:08 start sampling a new configuration.
03:42:08 best_vector: [3, 2, 0.4685322612955563, 0.942382297382226, 0.5771345934432787, 1, 0.7802252549359348, 0.36431118696503295, 1, 1, 1, 2, 0.7653181366223833, 0.6276437286962996, 0.49135189285147896, 0.7782866888511402], 0.007506423677016759, 0.002376413763387373, 1.783836853987948e-05
03:42:08 done sampling a new configuration.
03:42:08 HBMASTER: schedule new run for iteration 6
03:42:08 HBMASTER: trying submitting job (6, 0, 5) to dispatcher
03:42:08 HBMASTER: submitting job (6, 0, 5) to dispatcher
03:42:08 DISPATCHER: trying to submit job (6, 0, 5)
03:42:08 DISPATCHER: trying to notify the job_runner thread.
03:42:08 HBMASTER: job (6, 0, 5) submitted to dispatcher
03:42:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:42:08 DISPATCHER: Trying to submit another job.
03:42:08 DISPATCHER: starting job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:42:08 DISPATCHER: job (6, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:42:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:42:08 WORKER: start processing job (6, 0, 5)
03:42:08 WORKER: args: ()
03:42:08 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.008650964355303126, 'num_filters_1': 114, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.029783777717820103, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 78, 'num_filters_3': 58}, 'budget': 400.0, 'working_directory': '.'}
03:42:12 DISPATCHER: Starting worker discovery
03:42:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:42:12 DISPATCHER: Finished worker discovery
03:43:12 DISPATCHER: Starting worker discovery
03:43:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:43:12 DISPATCHER: Finished worker discovery
Exception in thread Thread-725:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    preds = np.concatenate(preds)
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

03:44:12 DISPATCHER: Starting worker discovery
03:44:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:44:12 DISPATCHER: Finished worker discovery
03:45:12 DISPATCHER: Starting worker discovery
03:45:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:45:12 DISPATCHER: Finished worker discovery
03:46:12 DISPATCHER: Starting worker discovery
03:46:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:46:12 DISPATCHER: Finished worker discovery
03:47:12 DISPATCHER: Starting worker discovery
03:47:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:47:12 DISPATCHER: Finished worker discovery
03:48:12 DISPATCHER: Starting worker discovery
03:48:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:48:12 DISPATCHER: Finished worker discovery
03:49:12 DISPATCHER: Starting worker discovery
03:49:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:49:12 DISPATCHER: Finished worker discovery
03:49:50 WORKER: done with job (6, 0, 5), trying to register it.
03:49:50 WORKER: registered result for job (6, 0, 5) with dispatcher
03:49:50 DISPATCHER: job (6, 0, 5) finished
03:49:50 DISPATCHER: register_result: lock acquired
03:49:50 DISPATCHER: job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
03:49:50 job_id: (6, 0, 5)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.008650964355303126, 'num_filters_1': 114, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.029783777717820103, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 78, 'num_filters_3': 58}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3431192092819978, 'info': {'sick_no_sick': 0.3431192092819978, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.008650964355303126, 'num_filters_1': 114, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.029783777717820103, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 78, 'num_filters_3': 58}"}}
exception: None

03:49:50 job_callback for (6, 0, 5) started
03:49:50 job_callback for (6, 0, 5) got condition
03:49:50 DISPATCHER: Trying to submit another job.
03:49:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:49:50 HBMASTER: Trying to run another job!
03:49:50 job_callback for (6, 0, 5) finished
03:49:50 ITERATION: Advancing config (6, 0, 0) to next budget 1200.000000
03:49:50 ITERATION: Advancing config (6, 0, 4) to next budget 1200.000000
03:49:50 HBMASTER: schedule new run for iteration 6
03:49:50 HBMASTER: trying submitting job (6, 0, 0) to dispatcher
03:49:50 HBMASTER: submitting job (6, 0, 0) to dispatcher
03:49:50 DISPATCHER: trying to submit job (6, 0, 0)
03:49:50 DISPATCHER: trying to notify the job_runner thread.
03:49:50 HBMASTER: job (6, 0, 0) submitted to dispatcher
03:49:50 DISPATCHER: Trying to submit another job.
03:49:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:49:50 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:49:50 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
03:49:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:49:50 WORKER: start processing job (6, 0, 0)
03:49:50 WORKER: args: ()
03:49:50 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002220622954883731, 'num_filters_1': 117, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.025370090287063572, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 102, 'num_filters_3': 18}, 'budget': 1200.0, 'working_directory': '.'}
03:50:12 DISPATCHER: Starting worker discovery
03:50:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:50:12 DISPATCHER: Finished worker discovery
03:51:12 DISPATCHER: Starting worker discovery
03:51:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:51:12 DISPATCHER: Finished worker discovery
03:52:12 DISPATCHER: Starting worker discovery
03:52:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:52:12 DISPATCHER: Finished worker discovery
03:53:12 DISPATCHER: Starting worker discovery
03:53:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:53:12 DISPATCHER: Finished worker discovery
03:54:12 DISPATCHER: Starting worker discovery
03:54:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:54:12 DISPATCHER: Finished worker discovery
03:55:12 DISPATCHER: Starting worker discovery
03:55:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:55:12 DISPATCHER: Finished worker discovery
03:56:12 DISPATCHER: Starting worker discovery
03:56:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:56:12 DISPATCHER: Finished worker discovery
03:57:12 DISPATCHER: Starting worker discovery
03:57:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:57:12 DISPATCHER: Finished worker discovery
03:58:12 DISPATCHER: Starting worker discovery
03:58:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:58:12 DISPATCHER: Finished worker discovery
03:59:12 DISPATCHER: Starting worker discovery
03:59:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:59:12 DISPATCHER: Finished worker discovery
04:00:12 DISPATCHER: Starting worker discovery
04:00:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:00:12 DISPATCHER: Finished worker discovery
04:01:12 DISPATCHER: Starting worker discovery
04:01:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:01:12 DISPATCHER: Finished worker discovery
04:02:12 DISPATCHER: Starting worker discovery
04:02:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:02:12 DISPATCHER: Finished worker discovery
04:03:12 DISPATCHER: Starting worker discovery
04:03:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:03:12 DISPATCHER: Finished worker discovery
04:04:12 DISPATCHER: Starting worker discovery
04:04:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:04:12 DISPATCHER: Finished worker discovery
04:05:12 DISPATCHER: Starting worker discovery
04:05:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:05:12 DISPATCHER: Finished worker discovery
04:06:12 DISPATCHER: Starting worker discovery
04:06:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:06:12 DISPATCHER: Finished worker discovery
04:07:12 DISPATCHER: Starting worker discovery
04:07:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:07:12 DISPATCHER: Finished worker discovery
04:08:12 DISPATCHER: Starting worker discovery
04:08:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:08:12 DISPATCHER: Finished worker discovery
04:09:12 DISPATCHER: Starting worker discovery
04:09:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:09:12 DISPATCHER: Finished worker discovery
04:10:12 DISPATCHER: Starting worker discovery
04:10:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:10:12 DISPATCHER: Finished worker discovery
04:11:12 DISPATCHER: Starting worker discovery
04:11:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:11:13 DISPATCHER: Finished worker discovery
04:11:19 WORKER: done with job (6, 0, 0), trying to register it.
04:11:19 WORKER: registered result for job (6, 0, 0) with dispatcher
04:11:19 DISPATCHER: job (6, 0, 0) finished
04:11:19 DISPATCHER: register_result: lock acquired
04:11:19 DISPATCHER: job (6, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
04:11:19 job_id: (6, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002220622954883731, 'num_filters_1': 117, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.025370090287063572, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 102, 'num_filters_3': 18}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5303126110517256, 'info': {'sick_no_sick': 0.5303126110517256, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002220622954883731, 'num_filters_1': 117, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.025370090287063572, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 102, 'num_filters_3': 18}"}}
exception: None

04:11:19 job_callback for (6, 0, 0) started
04:11:19 DISPATCHER: Trying to submit another job.
04:11:19 job_callback for (6, 0, 0) got condition
04:11:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:11:19 Only 11 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
04:11:19 HBMASTER: Trying to run another job!
04:11:19 job_callback for (6, 0, 0) finished
04:11:19 HBMASTER: schedule new run for iteration 6
04:11:19 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
04:11:19 HBMASTER: submitting job (6, 0, 4) to dispatcher
04:11:19 DISPATCHER: trying to submit job (6, 0, 4)
04:11:19 DISPATCHER: trying to notify the job_runner thread.
04:11:19 HBMASTER: job (6, 0, 4) submitted to dispatcher
04:11:19 DISPATCHER: Trying to submit another job.
04:11:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:11:19 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:11:19 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:11:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:11:19 WORKER: start processing job (6, 0, 4)
04:11:19 WORKER: args: ()
04:11:19 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0021835680935176267, 'num_filters_1': 121, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.02503639678026815, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 71, 'num_filters_3': 29}, 'budget': 1200.0, 'working_directory': '.'}
04:12:13 DISPATCHER: Starting worker discovery
04:12:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:12:13 DISPATCHER: Finished worker discovery
04:13:13 DISPATCHER: Starting worker discovery
04:13:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:13:13 DISPATCHER: Finished worker discovery
04:14:13 DISPATCHER: Starting worker discovery
04:14:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:14:13 DISPATCHER: Finished worker discovery
04:15:13 DISPATCHER: Starting worker discovery
04:15:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:15:13 DISPATCHER: Finished worker discovery
04:16:13 DISPATCHER: Starting worker discovery
04:16:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:16:13 DISPATCHER: Finished worker discovery
04:17:13 DISPATCHER: Starting worker discovery
04:17:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:17:13 DISPATCHER: Finished worker discovery
04:18:13 DISPATCHER: Starting worker discovery
04:18:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:18:13 DISPATCHER: Finished worker discovery
04:19:13 DISPATCHER: Starting worker discovery
04:19:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:19:13 DISPATCHER: Finished worker discovery
04:20:13 DISPATCHER: Starting worker discovery
04:20:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:20:13 DISPATCHER: Finished worker discovery
04:21:13 DISPATCHER: Starting worker discovery
04:21:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:21:13 DISPATCHER: Finished worker discovery
04:22:13 DISPATCHER: Starting worker discovery
04:22:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:22:13 DISPATCHER: Finished worker discovery
04:23:13 DISPATCHER: Starting worker discovery
04:23:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:23:13 DISPATCHER: Finished worker discovery
04:24:13 DISPATCHER: Starting worker discovery
04:24:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:24:13 DISPATCHER: Finished worker discovery
04:25:13 DISPATCHER: Starting worker discovery
04:25:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:25:13 DISPATCHER: Finished worker discovery
04:26:13 DISPATCHER: Starting worker discovery
04:26:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:26:13 DISPATCHER: Finished worker discovery
04:27:13 DISPATCHER: Starting worker discovery
04:27:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:27:13 DISPATCHER: Finished worker discovery
04:28:13 DISPATCHER: Starting worker discovery
04:28:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:28:13 DISPATCHER: Finished worker discovery
04:29:13 DISPATCHER: Starting worker discovery
04:29:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:29:13 DISPATCHER: Finished worker discovery
04:30:13 DISPATCHER: Starting worker discovery
04:30:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:30:13 DISPATCHER: Finished worker discovery
04:31:13 DISPATCHER: Starting worker discovery
04:31:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:31:13 DISPATCHER: Finished worker discovery
04:32:13 DISPATCHER: Starting worker discovery
04:32:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:32:13 DISPATCHER: Finished worker discovery
04:33:10 WORKER: done with job (6, 0, 4), trying to register it.
04:33:10 WORKER: registered result for job (6, 0, 4) with dispatcher
04:33:10 DISPATCHER: job (6, 0, 4) finished
04:33:10 DISPATCHER: register_result: lock acquired
04:33:10 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
04:33:10 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0021835680935176267, 'num_filters_1': 121, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.02503639678026815, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 71, 'num_filters_3': 29}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5392833668451472, 'info': {'sick_no_sick': 0.5392833668451472, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0021835680935176267, 'num_filters_1': 121, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.02503639678026815, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 71, 'num_filters_3': 29}"}}
exception: None

04:33:10 job_callback for (6, 0, 4) started
04:33:10 DISPATCHER: Trying to submit another job.
04:33:10 job_callback for (6, 0, 4) got condition
04:33:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:33:10 Only 12 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
04:33:10 HBMASTER: Trying to run another job!
04:33:10 job_callback for (6, 0, 4) finished
04:33:10 start sampling a new configuration.
04:33:10 best_vector: [0, 2, 0.20581002962749212, 0.5974437175436368, 0.47528887055913066, 1, 0.032750282412517366, 0.4656744749233147, 0, 0, 0, 0, 0.7377657052268644, 0.8394202022023487, 0.6151545593752394, 0.36423531848792795], 0.0026989620226237432, 0.0027734376664050285, 7.48540293374139e-06
04:33:10 done sampling a new configuration.
04:33:10 HBMASTER: schedule new run for iteration 7
04:33:10 HBMASTER: trying submitting job (7, 0, 0) to dispatcher
04:33:10 HBMASTER: submitting job (7, 0, 0) to dispatcher
04:33:10 DISPATCHER: trying to submit job (7, 0, 0)
04:33:10 DISPATCHER: trying to notify the job_runner thread.
04:33:10 HBMASTER: job (7, 0, 0) submitted to dispatcher
04:33:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:33:10 DISPATCHER: Trying to submit another job.
04:33:10 DISPATCHER: starting job (7, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:33:10 DISPATCHER: job (7, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:33:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:33:10 WORKER: start processing job (7, 0, 0)
04:33:10 WORKER: args: ()
04:33:10 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0025800020987904165, 'num_filters_1': 55, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.040351200502026945, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 74, 'num_filters_3': 91}, 'budget': 1200.0, 'working_directory': '.'}
04:33:13 DISPATCHER: Starting worker discovery
04:33:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:33:13 DISPATCHER: Finished worker discovery
04:34:13 DISPATCHER: Starting worker discovery
04:34:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:34:13 DISPATCHER: Finished worker discovery
04:35:13 DISPATCHER: Starting worker discovery
04:35:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:35:13 DISPATCHER: Finished worker discovery
04:36:13 DISPATCHER: Starting worker discovery
04:36:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:36:13 DISPATCHER: Finished worker discovery
04:37:13 DISPATCHER: Starting worker discovery
04:37:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:37:13 DISPATCHER: Finished worker discovery
04:38:13 DISPATCHER: Starting worker discovery
04:38:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:38:13 DISPATCHER: Finished worker discovery
04:39:13 DISPATCHER: Starting worker discovery
04:39:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:39:13 DISPATCHER: Finished worker discovery
04:40:13 DISPATCHER: Starting worker discovery
04:40:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:40:13 DISPATCHER: Finished worker discovery
04:41:13 DISPATCHER: Starting worker discovery
04:41:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:41:13 DISPATCHER: Finished worker discovery
04:42:13 DISPATCHER: Starting worker discovery
04:42:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:42:13 DISPATCHER: Finished worker discovery
04:43:13 DISPATCHER: Starting worker discovery
04:43:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:43:13 DISPATCHER: Finished worker discovery
04:44:13 DISPATCHER: Starting worker discovery
04:44:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:44:13 DISPATCHER: Finished worker discovery
04:45:13 DISPATCHER: Starting worker discovery
04:45:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:45:13 DISPATCHER: Finished worker discovery
04:46:13 DISPATCHER: Starting worker discovery
04:46:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:46:13 DISPATCHER: Finished worker discovery
04:47:13 DISPATCHER: Starting worker discovery
04:47:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:47:13 DISPATCHER: Finished worker discovery
04:48:13 DISPATCHER: Starting worker discovery
04:48:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:48:13 DISPATCHER: Finished worker discovery
04:49:13 DISPATCHER: Starting worker discovery
04:49:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:49:13 DISPATCHER: Finished worker discovery
04:50:13 DISPATCHER: Starting worker discovery
04:50:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:50:13 DISPATCHER: Finished worker discovery
04:51:13 DISPATCHER: Starting worker discovery
04:51:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:51:13 DISPATCHER: Finished worker discovery
04:52:13 DISPATCHER: Starting worker discovery
04:52:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:52:13 DISPATCHER: Finished worker discovery
04:53:13 DISPATCHER: Starting worker discovery
04:53:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:53:13 DISPATCHER: Finished worker discovery
04:54:13 DISPATCHER: Starting worker discovery
04:54:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:54:13 DISPATCHER: Finished worker discovery
04:55:13 DISPATCHER: Starting worker discovery
04:55:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:55:13 DISPATCHER: Finished worker discovery
04:55:51 WORKER: done with job (7, 0, 0), trying to register it.
04:55:51 WORKER: registered result for job (7, 0, 0) with dispatcher
04:55:51 DISPATCHER: job (7, 0, 0) finished
04:55:51 DISPATCHER: register_result: lock acquired
04:55:51 DISPATCHER: job (7, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
04:55:51 job_id: (7, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0025800020987904165, 'num_filters_1': 55, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.040351200502026945, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 74, 'num_filters_3': 91}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.4001769598398619, 'info': {'sick_no_sick': 0.4001769598398619, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0025800020987904165, 'num_filters_1': 55, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.040351200502026945, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 74, 'num_filters_3': 91}"}}
exception: None

04:55:51 job_callback for (7, 0, 0) started
04:55:51 job_callback for (7, 0, 0) got condition
04:55:51 DISPATCHER: Trying to submit another job.
04:55:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:55:51 Only 13 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
04:55:51 HBMASTER: Trying to run another job!
04:55:51 job_callback for (7, 0, 0) finished
04:55:51 start sampling a new configuration.
04:55:51 done sampling a new configuration.
04:55:51 HBMASTER: schedule new run for iteration 7
04:55:51 HBMASTER: trying submitting job (7, 0, 1) to dispatcher
04:55:51 HBMASTER: submitting job (7, 0, 1) to dispatcher
04:55:51 DISPATCHER: trying to submit job (7, 0, 1)
04:55:51 DISPATCHER: trying to notify the job_runner thread.
04:55:51 HBMASTER: job (7, 0, 1) submitted to dispatcher
04:55:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:55:51 DISPATCHER: Trying to submit another job.
04:55:51 DISPATCHER: starting job (7, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:55:51 DISPATCHER: job (7, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
04:55:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:55:51 WORKER: start processing job (7, 0, 1)
04:55:51 WORKER: args: ()
04:55:51 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003628009601846165, 'num_filters_1': 25, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.03873151235834806, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 20, 'num_filters_3': 73}, 'budget': 1200.0, 'working_directory': '.'}
04:56:13 DISPATCHER: Starting worker discovery
04:56:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:56:13 DISPATCHER: Finished worker discovery
04:57:13 DISPATCHER: Starting worker discovery
04:57:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:57:13 DISPATCHER: Finished worker discovery
04:58:13 DISPATCHER: Starting worker discovery
04:58:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:58:13 DISPATCHER: Finished worker discovery
04:59:13 DISPATCHER: Starting worker discovery
04:59:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:59:13 DISPATCHER: Finished worker discovery
05:00:13 DISPATCHER: Starting worker discovery
05:00:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:00:13 DISPATCHER: Finished worker discovery
05:01:13 DISPATCHER: Starting worker discovery
05:01:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:01:13 DISPATCHER: Finished worker discovery
05:02:13 DISPATCHER: Starting worker discovery
05:02:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:02:13 DISPATCHER: Finished worker discovery
05:03:13 DISPATCHER: Starting worker discovery
05:03:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:03:13 DISPATCHER: Finished worker discovery
05:04:13 DISPATCHER: Starting worker discovery
05:04:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:04:13 DISPATCHER: Finished worker discovery
05:05:13 DISPATCHER: Starting worker discovery
05:05:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:05:13 DISPATCHER: Finished worker discovery
05:06:13 DISPATCHER: Starting worker discovery
05:06:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:06:13 DISPATCHER: Finished worker discovery
05:07:13 DISPATCHER: Starting worker discovery
05:07:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:07:13 DISPATCHER: Finished worker discovery
05:08:13 DISPATCHER: Starting worker discovery
05:08:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:08:13 DISPATCHER: Finished worker discovery
05:09:13 DISPATCHER: Starting worker discovery
05:09:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:09:13 DISPATCHER: Finished worker discovery
05:10:13 DISPATCHER: Starting worker discovery
05:10:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:10:13 DISPATCHER: Finished worker discovery
05:11:13 DISPATCHER: Starting worker discovery
05:11:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:11:13 DISPATCHER: Finished worker discovery
05:12:13 DISPATCHER: Starting worker discovery
05:12:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:12:13 DISPATCHER: Finished worker discovery
05:13:13 DISPATCHER: Starting worker discovery
05:13:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:13:13 DISPATCHER: Finished worker discovery
05:14:13 DISPATCHER: Starting worker discovery
05:14:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:14:13 DISPATCHER: Finished worker discovery
05:15:13 DISPATCHER: Starting worker discovery
05:15:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:15:13 DISPATCHER: Finished worker discovery
05:16:13 DISPATCHER: Starting worker discovery
05:16:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:16:13 DISPATCHER: Finished worker discovery
05:17:13 DISPATCHER: Starting worker discovery
05:17:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:17:14 DISPATCHER: Finished worker discovery
05:17:14 WORKER: done with job (7, 0, 1), trying to register it.
05:17:14 WORKER: registered result for job (7, 0, 1) with dispatcher
05:17:14 DISPATCHER: job (7, 0, 1) finished
05:17:14 DISPATCHER: register_result: lock acquired
05:17:14 DISPATCHER: job (7, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
05:17:14 job_id: (7, 0, 1)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003628009601846165, 'num_filters_1': 25, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.03873151235834806, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 20, 'num_filters_3': 73}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5116272256104875, 'info': {'sick_no_sick': 0.5116272256104875, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003628009601846165, 'num_filters_1': 25, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.03873151235834806, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 20, 'num_filters_3': 73}"}}
exception: None

05:17:14 job_callback for (7, 0, 1) started
05:17:14 DISPATCHER: Trying to submit another job.
05:17:14 job_callback for (7, 0, 1) got condition
05:17:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:17:14 Only 14 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
05:17:14 HBMASTER: Trying to run another job!
05:17:14 job_callback for (7, 0, 1) finished
05:17:14 start sampling a new configuration.
05:17:14 best_vector: [2, 2, 0.023149337560999406, 0.8829851493784794, 0.14891585133602167, 1, 0.45806847206812684, 0.38551940667531803, 1, 1, 1, 0, 0.9502086196073176, 0.38898451237662457, 0.557551705590495, 0.3924629523570897], 0.0003353568072143663, 0.00811936064850983, 2.722882863706223e-06
05:17:14 done sampling a new configuration.
05:17:14 HBMASTER: schedule new run for iteration 7
05:17:14 HBMASTER: trying submitting job (7, 0, 2) to dispatcher
05:17:14 HBMASTER: submitting job (7, 0, 2) to dispatcher
05:17:14 DISPATCHER: trying to submit job (7, 0, 2)
05:17:14 DISPATCHER: trying to notify the job_runner thread.
05:17:14 HBMASTER: job (7, 0, 2) submitted to dispatcher
05:17:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:17:14 DISPATCHER: Trying to submit another job.
05:17:14 DISPATCHER: starting job (7, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
05:17:14 DISPATCHER: job (7, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
05:17:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:17:14 WORKER: start processing job (7, 0, 2)
05:17:14 WORKER: args: ()
05:17:14 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001112496555819953, 'num_filters_1': 100, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.031737470630825666}, 'budget': 1200.0, 'working_directory': '.'}
05:18:14 DISPATCHER: Starting worker discovery
05:18:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:18:14 DISPATCHER: Finished worker discovery
05:19:14 DISPATCHER: Starting worker discovery
05:19:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:19:14 DISPATCHER: Finished worker discovery
05:20:14 DISPATCHER: Starting worker discovery
05:20:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:20:14 DISPATCHER: Finished worker discovery
05:21:14 DISPATCHER: Starting worker discovery
05:21:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:21:14 DISPATCHER: Finished worker discovery
05:22:14 DISPATCHER: Starting worker discovery
05:22:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:22:14 DISPATCHER: Finished worker discovery
05:23:14 DISPATCHER: Starting worker discovery
05:23:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:23:14 DISPATCHER: Finished worker discovery
05:24:14 DISPATCHER: Starting worker discovery
05:24:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:24:14 DISPATCHER: Finished worker discovery
05:25:14 DISPATCHER: Starting worker discovery
05:25:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:25:14 DISPATCHER: Finished worker discovery
05:26:14 DISPATCHER: Starting worker discovery
05:26:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:26:14 DISPATCHER: Finished worker discovery
05:27:14 DISPATCHER: Starting worker discovery
05:27:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:27:14 DISPATCHER: Finished worker discovery
05:28:14 DISPATCHER: Starting worker discovery
05:28:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:28:14 DISPATCHER: Finished worker discovery
05:29:14 DISPATCHER: Starting worker discovery
05:29:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:29:14 DISPATCHER: Finished worker discovery
05:30:14 DISPATCHER: Starting worker discovery
05:30:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:30:14 DISPATCHER: Finished worker discovery
05:31:14 DISPATCHER: Starting worker discovery
05:31:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:31:14 DISPATCHER: Finished worker discovery
05:32:14 DISPATCHER: Starting worker discovery
05:32:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:32:14 DISPATCHER: Finished worker discovery
05:33:14 DISPATCHER: Starting worker discovery
05:33:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:33:14 DISPATCHER: Finished worker discovery
05:34:14 DISPATCHER: Starting worker discovery
05:34:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:34:14 DISPATCHER: Finished worker discovery
05:35:14 DISPATCHER: Starting worker discovery
05:35:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:35:14 DISPATCHER: Finished worker discovery
05:36:14 DISPATCHER: Starting worker discovery
05:36:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:36:14 DISPATCHER: Finished worker discovery
05:37:14 DISPATCHER: Starting worker discovery
05:37:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:37:14 DISPATCHER: Finished worker discovery
05:38:14 DISPATCHER: Starting worker discovery
05:38:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:38:14 DISPATCHER: Finished worker discovery
05:38:38 WORKER: done with job (7, 0, 2), trying to register it.
05:38:38 WORKER: registered result for job (7, 0, 2) with dispatcher
05:38:38 DISPATCHER: job (7, 0, 2) finished
05:38:38 DISPATCHER: register_result: lock acquired
05:38:38 DISPATCHER: job (7, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
05:38:38 job_id: (7, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001112496555819953, 'num_filters_1': 100, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.031737470630825666}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.4893045664626478, 'info': {'sick_no_sick': 0.4893045664626478, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001112496555819953, 'num_filters_1': 100, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.031737470630825666}"}}
exception: None

05:38:38 job_callback for (7, 0, 2) started
05:38:38 DISPATCHER: Trying to submit another job.
05:38:38 job_callback for (7, 0, 2) got condition
05:38:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:38:39 Only 15 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
05:38:39 HBMASTER: Trying to run another job!
05:38:39 job_callback for (7, 0, 2) finished
05:38:39 start sampling a new configuration.
05:38:39 best_vector: [3, 2, 0.24728381892465762, 0.6801022153752874, 0.08155765898505879, 0, 0.11265542272516038, 0.14652810972588085, 2, 1, 2, 2, 0.9485225342783322, 0.48421789008914845, 0.508089218225814, 0.10296296815085021], 0.00040683739617861884, 0.0038944342468134486, 1.584401488562424e-06
05:38:39 done sampling a new configuration.
05:38:39 HBMASTER: schedule new run for iteration 7
05:38:39 HBMASTER: trying submitting job (7, 0, 3) to dispatcher
05:38:39 HBMASTER: submitting job (7, 0, 3) to dispatcher
05:38:39 DISPATCHER: trying to submit job (7, 0, 3)
05:38:39 DISPATCHER: trying to notify the job_runner thread.
05:38:39 HBMASTER: job (7, 0, 3) submitted to dispatcher
05:38:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:38:39 DISPATCHER: Trying to submit another job.
05:38:39 DISPATCHER: starting job (7, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
05:38:39 DISPATCHER: job (7, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
05:38:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:38:39 WORKER: start processing job (7, 0, 3)
05:38:39 WORKER: args: ()
05:38:39 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.00312296874544775, 'num_filters_1': 65, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.015510916716082396}, 'budget': 1200.0, 'working_directory': '.'}
05:39:14 DISPATCHER: Starting worker discovery
05:39:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:39:14 DISPATCHER: Finished worker discovery
05:40:14 DISPATCHER: Starting worker discovery
05:40:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:40:14 DISPATCHER: Finished worker discovery
05:41:14 DISPATCHER: Starting worker discovery
05:41:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:41:14 DISPATCHER: Finished worker discovery
05:42:14 DISPATCHER: Starting worker discovery
05:42:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:42:14 DISPATCHER: Finished worker discovery
05:43:14 DISPATCHER: Starting worker discovery
05:43:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:43:14 DISPATCHER: Finished worker discovery
05:44:14 DISPATCHER: Starting worker discovery
05:44:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:44:14 DISPATCHER: Finished worker discovery
05:45:14 DISPATCHER: Starting worker discovery
05:45:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:45:14 DISPATCHER: Finished worker discovery
05:46:14 DISPATCHER: Starting worker discovery
05:46:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:46:14 DISPATCHER: Finished worker discovery
05:47:14 DISPATCHER: Starting worker discovery
05:47:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:47:14 DISPATCHER: Finished worker discovery
05:48:14 DISPATCHER: Starting worker discovery
05:48:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:48:14 DISPATCHER: Finished worker discovery
05:49:14 DISPATCHER: Starting worker discovery
05:49:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:49:14 DISPATCHER: Finished worker discovery
05:50:14 DISPATCHER: Starting worker discovery
05:50:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:50:14 DISPATCHER: Finished worker discovery
05:51:14 DISPATCHER: Starting worker discovery
05:51:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:51:14 DISPATCHER: Finished worker discovery
05:52:14 DISPATCHER: Starting worker discovery
05:52:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:52:14 DISPATCHER: Finished worker discovery
05:53:14 DISPATCHER: Starting worker discovery
05:53:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:53:14 DISPATCHER: Finished worker discovery
05:54:14 DISPATCHER: Starting worker discovery
05:54:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:54:14 DISPATCHER: Finished worker discovery
05:55:14 DISPATCHER: Starting worker discovery
05:55:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:55:14 DISPATCHER: Finished worker discovery
05:56:14 DISPATCHER: Starting worker discovery
05:56:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:56:14 DISPATCHER: Finished worker discovery
05:57:14 DISPATCHER: Starting worker discovery
05:57:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:57:14 DISPATCHER: Finished worker discovery
05:58:14 DISPATCHER: Starting worker discovery
05:58:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:58:14 DISPATCHER: Finished worker discovery
05:59:14 DISPATCHER: Starting worker discovery
05:59:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:59:14 DISPATCHER: Finished worker discovery
06:00:11 WORKER: done with job (7, 0, 3), trying to register it.
06:00:11 WORKER: registered result for job (7, 0, 3) with dispatcher
06:00:11 DISPATCHER: job (7, 0, 3) finished
06:00:11 DISPATCHER: register_result: lock acquired
06:00:11 DISPATCHER: job (7, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
06:00:11 job_id: (7, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.00312296874544775, 'num_filters_1': 65, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.015510916716082396}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5329671641289646, 'info': {'sick_no_sick': 0.5329671641289646, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.00312296874544775, 'num_filters_1': 65, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.015510916716082396}"}}
exception: None

06:00:11 job_callback for (7, 0, 3) started
06:00:11 DISPATCHER: Trying to submit another job.
06:00:11 job_callback for (7, 0, 3) got condition
06:00:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:00:11 Only 16 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
06:00:11 HBMASTER: Trying to run another job!
06:00:11 job_callback for (7, 0, 3) finished
06:00:11 start sampling a new configuration.
06:00:11 done sampling a new configuration.
06:00:11 HBMASTER: schedule new run for iteration 8
06:00:11 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
06:00:11 HBMASTER: submitting job (8, 0, 0) to dispatcher
06:00:11 DISPATCHER: trying to submit job (8, 0, 0)
06:00:11 DISPATCHER: trying to notify the job_runner thread.
06:00:11 HBMASTER: job (8, 0, 0) submitted to dispatcher
06:00:11 DISPATCHER: Trying to submit another job.
06:00:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:00:11 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:00:11 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:00:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:00:11 WORKER: start processing job (8, 0, 0)
06:00:11 WORKER: args: ()
06:00:11 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.005099913051303709, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.14336423027470196, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 62, 'num_filters_3': 49, 'num_filters_4': 82}, 'budget': 44.44444444444444, 'working_directory': '.'}
06:00:14 DISPATCHER: Starting worker discovery
06:00:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:00:14 DISPATCHER: Finished worker discovery
06:01:14 DISPATCHER: Starting worker discovery
06:01:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:01:14 DISPATCHER: Finished worker discovery
06:02:00 WORKER: done with job (8, 0, 0), trying to register it.
06:02:00 WORKER: registered result for job (8, 0, 0) with dispatcher
06:02:00 DISPATCHER: job (8, 0, 0) finished
06:02:00 DISPATCHER: register_result: lock acquired
06:02:00 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
06:02:00 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.005099913051303709, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.14336423027470196, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 62, 'num_filters_3': 49, 'num_filters_4': 82}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.005099913051303709, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.14336423027470196, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 62, 'num_filters_3': 49, 'num_filters_4': 82}"}}
exception: None

06:02:00 job_callback for (8, 0, 0) started
06:02:00 DISPATCHER: Trying to submit another job.
06:02:00 job_callback for (8, 0, 0) got condition
06:02:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:02:00 HBMASTER: Trying to run another job!
06:02:00 job_callback for (8, 0, 0) finished
06:02:00 start sampling a new configuration.
06:02:00 done sampling a new configuration.
06:02:00 HBMASTER: schedule new run for iteration 8
06:02:00 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
06:02:00 HBMASTER: submitting job (8, 0, 1) to dispatcher
06:02:00 DISPATCHER: trying to submit job (8, 0, 1)
06:02:00 DISPATCHER: trying to notify the job_runner thread.
06:02:00 HBMASTER: job (8, 0, 1) submitted to dispatcher
06:02:00 DISPATCHER: Trying to submit another job.
06:02:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:02:00 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:02:00 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:02:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:02:00 WORKER: start processing job (8, 0, 1)
06:02:00 WORKER: args: ()
06:02:00 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0037760460738767527, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.07923126446651281}, 'budget': 44.44444444444444, 'working_directory': '.'}
06:02:14 DISPATCHER: Starting worker discovery
06:02:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:02:14 DISPATCHER: Finished worker discovery
06:03:14 DISPATCHER: Starting worker discovery
06:03:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:03:14 DISPATCHER: Finished worker discovery
06:03:48 WORKER: done with job (8, 0, 1), trying to register it.
06:03:48 WORKER: registered result for job (8, 0, 1) with dispatcher
06:03:48 DISPATCHER: job (8, 0, 1) finished
06:03:48 DISPATCHER: register_result: lock acquired
06:03:48 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
06:03:48 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0037760460738767527, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.07923126446651281}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4540586544909315, 'info': {'sick_no_sick': 0.4540586544909315, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0037760460738767527, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.07923126446651281}"}}
exception: None

06:03:48 job_callback for (8, 0, 1) started
06:03:48 DISPATCHER: Trying to submit another job.
06:03:48 job_callback for (8, 0, 1) got condition
06:03:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:03:48 HBMASTER: Trying to run another job!
06:03:48 job_callback for (8, 0, 1) finished
06:03:48 start sampling a new configuration.
06:03:48 done sampling a new configuration.
06:03:48 HBMASTER: schedule new run for iteration 8
06:03:48 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
06:03:48 HBMASTER: submitting job (8, 0, 2) to dispatcher
06:03:48 DISPATCHER: trying to submit job (8, 0, 2)
06:03:48 DISPATCHER: trying to notify the job_runner thread.
06:03:48 HBMASTER: job (8, 0, 2) submitted to dispatcher
06:03:48 DISPATCHER: Trying to submit another job.
06:03:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:03:48 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:03:48 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:03:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:03:48 WORKER: start processing job (8, 0, 2)
06:03:48 WORKER: args: ()
06:03:48 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0011502782652154176, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.06875745054556485, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 88, 'num_filters_3': 102, 'num_filters_4': 63, 'num_filters_5': 37}, 'budget': 44.44444444444444, 'working_directory': '.'}
06:04:14 DISPATCHER: Starting worker discovery
06:04:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:04:14 DISPATCHER: Finished worker discovery
06:05:14 DISPATCHER: Starting worker discovery
06:05:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:05:14 DISPATCHER: Finished worker discovery
06:05:37 WORKER: done with job (8, 0, 2), trying to register it.
06:05:37 WORKER: registered result for job (8, 0, 2) with dispatcher
06:05:37 DISPATCHER: job (8, 0, 2) finished
06:05:37 DISPATCHER: register_result: lock acquired
06:05:37 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
06:05:37 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0011502782652154176, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.06875745054556485, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 88, 'num_filters_3': 102, 'num_filters_4': 63, 'num_filters_5': 37}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3862056702929147, 'info': {'sick_no_sick': 0.3862056702929147, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0011502782652154176, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.06875745054556485, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 88, 'num_filters_3': 102, 'num_filters_4': 63, 'num_filters_5': 37}"}}
exception: None

06:05:37 job_callback for (8, 0, 2) started
06:05:37 job_callback for (8, 0, 2) got condition
06:05:37 DISPATCHER: Trying to submit another job.
06:05:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:05:37 HBMASTER: Trying to run another job!
06:05:37 job_callback for (8, 0, 2) finished
06:05:37 start sampling a new configuration.
06:05:37 best_vector: [3, 2, 0.12640241700878319, 0.4278308546538444, 0.029953920647685428, 1, 0.28652964059741776, 0.14070173818202514, 2, 0, 2, 2, 0.7775770877597916, 0.6921821838140308, 0.4875237853226217, 0.033962031161970954], 0.001056734357518623, 0.003596179404119938, 3.8002063321343874e-06
06:05:37 done sampling a new configuration.
06:05:37 HBMASTER: schedule new run for iteration 8
06:05:37 HBMASTER: trying submitting job (8, 0, 3) to dispatcher
06:05:37 HBMASTER: submitting job (8, 0, 3) to dispatcher
06:05:37 DISPATCHER: trying to submit job (8, 0, 3)
06:05:37 DISPATCHER: trying to notify the job_runner thread.
06:05:37 HBMASTER: job (8, 0, 3) submitted to dispatcher
06:05:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:05:37 DISPATCHER: Trying to submit another job.
06:05:37 DISPATCHER: starting job (8, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:05:37 DISPATCHER: job (8, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:05:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:05:37 WORKER: start processing job (8, 0, 3)
06:05:37 WORKER: args: ()
06:05:37 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0017898013611059428, 'num_filters_1': 38, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.015242534329368614}, 'budget': 44.44444444444444, 'working_directory': '.'}
06:06:14 DISPATCHER: Starting worker discovery
06:06:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:06:14 DISPATCHER: Finished worker discovery
06:07:14 DISPATCHER: Starting worker discovery
06:07:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:07:14 DISPATCHER: Finished worker discovery
06:07:24 WORKER: done with job (8, 0, 3), trying to register it.
06:07:24 WORKER: registered result for job (8, 0, 3) with dispatcher
06:07:24 DISPATCHER: job (8, 0, 3) finished
06:07:24 DISPATCHER: register_result: lock acquired
06:07:24 DISPATCHER: job (8, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
06:07:24 job_id: (8, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0017898013611059428, 'num_filters_1': 38, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.015242534329368614}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.42983263816315703, 'info': {'sick_no_sick': 0.42983263816315703, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0017898013611059428, 'num_filters_1': 38, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.015242534329368614}"}}
exception: None

06:07:24 job_callback for (8, 0, 3) started
06:07:24 job_callback for (8, 0, 3) got condition
06:07:24 DISPATCHER: Trying to submit another job.
06:07:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:07:24 HBMASTER: Trying to run another job!
06:07:24 job_callback for (8, 0, 3) finished
06:07:24 start sampling a new configuration.
06:07:24 done sampling a new configuration.
06:07:24 HBMASTER: schedule new run for iteration 8
06:07:24 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
06:07:24 HBMASTER: submitting job (8, 0, 4) to dispatcher
06:07:24 DISPATCHER: trying to submit job (8, 0, 4)
06:07:24 DISPATCHER: trying to notify the job_runner thread.
06:07:24 HBMASTER: job (8, 0, 4) submitted to dispatcher
06:07:24 DISPATCHER: Trying to submit another job.
06:07:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:07:24 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:07:24 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:07:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:07:24 WORKER: start processing job (8, 0, 4)
06:07:24 WORKER: args: ()
06:07:24 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0909116304927285, 'num_filters_1': 19, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.04653977649405653, 'kernel_size_2': 5, 'num_filters_2': 22}, 'budget': 44.44444444444444, 'working_directory': '.'}
06:08:14 DISPATCHER: Starting worker discovery
06:08:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:08:14 DISPATCHER: Finished worker discovery
06:09:11 WORKER: done with job (8, 0, 4), trying to register it.
06:09:11 WORKER: registered result for job (8, 0, 4) with dispatcher
06:09:11 DISPATCHER: job (8, 0, 4) finished
06:09:11 DISPATCHER: register_result: lock acquired
06:09:11 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
06:09:11 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0909116304927285, 'num_filters_1': 19, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.04653977649405653, 'kernel_size_2': 5, 'num_filters_2': 22}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 1.5072122612776973e-06, 'info': {'sick_no_sick': -1.5072122612776973e-06, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0909116304927285, 'num_filters_1': 19, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.04653977649405653, 'kernel_size_2': 5, 'num_filters_2': 22}"}}
exception: None

06:09:11 job_callback for (8, 0, 4) started
06:09:11 job_callback for (8, 0, 4) got condition
06:09:11 DISPATCHER: Trying to submit another job.
06:09:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:09:11 HBMASTER: Trying to run another job!
06:09:11 job_callback for (8, 0, 4) finished
06:09:11 start sampling a new configuration.
06:09:11 best_vector: [3, 0, 0.5497146457055083, 0.4427449879849377, 0.19091076476166607, 1, 0.026870854647454423, 0.9328666417996583, 2, 0, 0, 1, 0.85503016902686, 0.9218787588853151, 0.5181304942229815, 0.06325013937934215], 0.019874923302810953, 1.776180571102051e-05, 3.530145262259622e-07
06:09:11 done sampling a new configuration.
06:09:11 HBMASTER: schedule new run for iteration 8
06:09:11 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
06:09:11 HBMASTER: submitting job (8, 0, 5) to dispatcher
06:09:11 DISPATCHER: trying to submit job (8, 0, 5)
06:09:11 DISPATCHER: trying to notify the job_runner thread.
06:09:11 HBMASTER: job (8, 0, 5) submitted to dispatcher
06:09:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:09:11 DISPATCHER: Trying to submit another job.
06:09:11 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:09:11 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:09:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:09:11 WORKER: start processing job (8, 0, 5)
06:09:11 WORKER: args: ()
06:09:11 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.012572721380289587, 'num_filters_1': 40, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.16356390966373122}, 'budget': 44.44444444444444, 'working_directory': '.'}
06:09:14 DISPATCHER: Starting worker discovery
06:09:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:09:14 DISPATCHER: Finished worker discovery
06:10:14 DISPATCHER: Starting worker discovery
06:10:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:10:14 DISPATCHER: Finished worker discovery
06:10:59 WORKER: done with job (8, 0, 5), trying to register it.
06:10:59 WORKER: registered result for job (8, 0, 5) with dispatcher
06:10:59 DISPATCHER: job (8, 0, 5) finished
06:10:59 DISPATCHER: register_result: lock acquired
06:10:59 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
06:10:59 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.012572721380289587, 'num_filters_1': 40, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.16356390966373122}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.35117799661238525, 'info': {'sick_no_sick': 0.35117799661238525, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.012572721380289587, 'num_filters_1': 40, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.16356390966373122}"}}
exception: None

06:10:59 job_callback for (8, 0, 5) started
06:10:59 job_callback for (8, 0, 5) got condition
06:10:59 DISPATCHER: Trying to submit another job.
06:10:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:10:59 HBMASTER: Trying to run another job!
06:10:59 job_callback for (8, 0, 5) finished
06:10:59 start sampling a new configuration.
06:10:59 done sampling a new configuration.
06:10:59 HBMASTER: schedule new run for iteration 8
06:10:59 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
06:10:59 HBMASTER: submitting job (8, 0, 6) to dispatcher
06:10:59 DISPATCHER: trying to submit job (8, 0, 6)
06:10:59 DISPATCHER: trying to notify the job_runner thread.
06:10:59 HBMASTER: job (8, 0, 6) submitted to dispatcher
06:10:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:10:59 DISPATCHER: Trying to submit another job.
06:10:59 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:10:59 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:10:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:10:59 WORKER: start processing job (8, 0, 6)
06:10:59 WORKER: args: ()
06:10:59 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.09018809951264799, 'num_filters_1': 34, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.016778518160517064, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 49, 'num_filters_3': 88, 'num_filters_4': 19, 'num_filters_5': 44}, 'budget': 44.44444444444444, 'working_directory': '.'}
06:11:14 DISPATCHER: Starting worker discovery
06:11:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:11:14 DISPATCHER: Finished worker discovery
06:12:14 DISPATCHER: Starting worker discovery
06:12:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:12:14 DISPATCHER: Finished worker discovery
06:12:45 WORKER: done with job (8, 0, 6), trying to register it.
06:12:45 WORKER: registered result for job (8, 0, 6) with dispatcher
06:12:45 DISPATCHER: job (8, 0, 6) finished
06:12:45 DISPATCHER: register_result: lock acquired
06:12:45 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
06:12:45 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.09018809951264799, 'num_filters_1': 34, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.016778518160517064, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 49, 'num_filters_3': 88, 'num_filters_4': 19, 'num_filters_5': 44}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -3.674759610179014e-05, 'info': {'sick_no_sick': 3.674759610179014e-05, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.09018809951264799, 'num_filters_1': 34, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.016778518160517064, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 49, 'num_filters_3': 88, 'num_filters_4': 19, 'num_filters_5': 44}"}}
exception: None

06:12:45 job_callback for (8, 0, 6) started
06:12:45 DISPATCHER: Trying to submit another job.
06:12:45 job_callback for (8, 0, 6) got condition
06:12:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:12:45 HBMASTER: Trying to run another job!
06:12:45 job_callback for (8, 0, 6) finished
06:12:45 start sampling a new configuration.
06:12:45 best_vector: [1, 2, 0.12711474208791612, 0.7427919730464543, 0.10769848897121492, 1, 0.778383606229686, 0.7314174836620722, 1, 2, 1, 2, 0.6812381687860316, 0.3582554523547739, 0.4565294851683339, 0.4542443784144569], 0.005072719061191611, 0.0005708693177953563, 2.8958596698299553e-06
06:12:45 done sampling a new configuration.
06:12:45 HBMASTER: schedule new run for iteration 8
06:12:45 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
06:12:45 HBMASTER: submitting job (8, 0, 7) to dispatcher
06:12:45 DISPATCHER: trying to submit job (8, 0, 7)
06:12:45 DISPATCHER: trying to notify the job_runner thread.
06:12:45 HBMASTER: job (8, 0, 7) submitted to dispatcher
06:12:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:12:45 DISPATCHER: Trying to submit another job.
06:12:45 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:12:45 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:12:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:12:45 WORKER: start processing job (8, 0, 7)
06:12:45 WORKER: args: ()
06:12:45 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001795682226962468, 'num_filters_1': 75, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.0894532421102648}, 'budget': 44.44444444444444, 'working_directory': '.'}
06:13:14 DISPATCHER: Starting worker discovery
06:13:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:13:14 DISPATCHER: Finished worker discovery
06:14:14 DISPATCHER: Starting worker discovery
06:14:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:14:14 DISPATCHER: Finished worker discovery
06:14:33 WORKER: done with job (8, 0, 7), trying to register it.
06:14:33 WORKER: registered result for job (8, 0, 7) with dispatcher
06:14:33 DISPATCHER: job (8, 0, 7) finished
06:14:33 DISPATCHER: register_result: lock acquired
06:14:33 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
06:14:33 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001795682226962468, 'num_filters_1': 75, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.0894532421102648}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.46174417480751695, 'info': {'sick_no_sick': 0.46174417480751695, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001795682226962468, 'num_filters_1': 75, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.0894532421102648}"}}
exception: None

06:14:33 job_callback for (8, 0, 7) started
06:14:33 job_callback for (8, 0, 7) got condition
06:14:33 DISPATCHER: Trying to submit another job.
06:14:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:14:33 HBMASTER: Trying to run another job!
06:14:33 job_callback for (8, 0, 7) finished
06:14:33 start sampling a new configuration.
06:14:33 done sampling a new configuration.
06:14:33 HBMASTER: schedule new run for iteration 8
06:14:33 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
06:14:33 HBMASTER: submitting job (8, 0, 8) to dispatcher
06:14:33 DISPATCHER: trying to submit job (8, 0, 8)
06:14:33 DISPATCHER: trying to notify the job_runner thread.
06:14:33 HBMASTER: job (8, 0, 8) submitted to dispatcher
06:14:33 DISPATCHER: Trying to submit another job.
06:14:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:14:33 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:14:33 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:14:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:14:33 WORKER: start processing job (8, 0, 8)
06:14:33 WORKER: args: ()
06:14:33 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.020070681642402825, 'num_filters_1': 89, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.08847115544997174, 'kernel_size_2': 3, 'num_filters_2': 60}, 'budget': 44.44444444444444, 'working_directory': '.'}
06:15:14 DISPATCHER: Starting worker discovery
06:15:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:15:14 DISPATCHER: Finished worker discovery
06:16:14 DISPATCHER: Starting worker discovery
06:16:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:16:14 DISPATCHER: Finished worker discovery
06:16:18 WORKER: done with job (8, 0, 8), trying to register it.
06:16:18 WORKER: registered result for job (8, 0, 8) with dispatcher
06:16:18 DISPATCHER: job (8, 0, 8) finished
06:16:18 DISPATCHER: register_result: lock acquired
06:16:18 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
06:16:18 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.020070681642402825, 'num_filters_1': 89, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.08847115544997174, 'kernel_size_2': 3, 'num_filters_2': 60}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.020070681642402825, 'num_filters_1': 89, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.08847115544997174, 'kernel_size_2': 3, 'num_filters_2': 60}"}}
exception: None

06:16:18 job_callback for (8, 0, 8) started
06:16:18 DISPATCHER: Trying to submit another job.
06:16:18 job_callback for (8, 0, 8) got condition
06:16:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:16:18 HBMASTER: Trying to run another job!
06:16:18 job_callback for (8, 0, 8) finished
06:16:18 start sampling a new configuration.
06:16:18 best_vector: [2, 2, 0.25610242243906645, 0.7583526403499194, 0.5282515690495873, 0, 0.9393724919240871, 0.544775270141438, 2, 1, 2, 0, 0.763365282732517, 0.7723023723537732, 0.5359366717872697, 0.8954407943962653], 0.002616643534817875, 0.0036764747367040523, 9.620023850717907e-06
06:16:18 done sampling a new configuration.
06:16:18 HBMASTER: schedule new run for iteration 8
06:16:18 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
06:16:18 HBMASTER: submitting job (8, 0, 9) to dispatcher
06:16:18 DISPATCHER: trying to submit job (8, 0, 9)
06:16:18 DISPATCHER: trying to notify the job_runner thread.
06:16:18 HBMASTER: job (8, 0, 9) submitted to dispatcher
06:16:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:16:18 DISPATCHER: Trying to submit another job.
06:16:18 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:16:18 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:16:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:16:18 WORKER: start processing job (8, 0, 9)
06:16:18 WORKER: args: ()
06:16:18 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0032524066837674817, 'num_filters_1': 77, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.051140970734773035, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 78, 'num_filters_3': 79}, 'budget': 44.44444444444444, 'working_directory': '.'}
06:17:14 DISPATCHER: Starting worker discovery
06:17:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:17:14 DISPATCHER: Finished worker discovery
06:18:05 WORKER: done with job (8, 0, 9), trying to register it.
06:18:05 WORKER: registered result for job (8, 0, 9) with dispatcher
06:18:05 DISPATCHER: job (8, 0, 9) finished
06:18:05 DISPATCHER: register_result: lock acquired
06:18:05 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
06:18:05 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0032524066837674817, 'num_filters_1': 77, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.051140970734773035, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 78, 'num_filters_3': 79}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.002578813108747251, 'info': {'sick_no_sick': 0.002578813108747251, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0032524066837674817, 'num_filters_1': 77, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.051140970734773035, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 78, 'num_filters_3': 79}"}}
exception: None

06:18:05 job_callback for (8, 0, 9) started
06:18:05 job_callback for (8, 0, 9) got condition
06:18:05 DISPATCHER: Trying to submit another job.
06:18:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:18:05 HBMASTER: Trying to run another job!
06:18:05 job_callback for (8, 0, 9) finished
06:18:05 start sampling a new configuration.
06:18:05 best_vector: [3, 2, 0.4452373632221742, 0.4459097823946796, 0.4097655912598388, 1, 0.8558023113707202, 0.2515815287714833, 2, 0, 0, 0, 0.16680058873342796, 0.387341906166616, 0.5189967144861449, 0.37357801177471084], 0.0029000692940447824, 0.014887513958918986, 4.317482209692403e-05
06:18:05 done sampling a new configuration.
06:18:05 HBMASTER: schedule new run for iteration 8
06:18:05 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
06:18:05 HBMASTER: submitting job (8, 0, 10) to dispatcher
06:18:05 DISPATCHER: trying to submit job (8, 0, 10)
06:18:05 DISPATCHER: trying to notify the job_runner thread.
06:18:05 HBMASTER: job (8, 0, 10) submitted to dispatcher
06:18:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:18:05 DISPATCHER: Trying to submit another job.
06:18:05 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:18:05 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:18:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:18:05 WORKER: start processing job (8, 0, 10)
06:18:05 WORKER: args: ()
06:18:05 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.007770960947494053, 'num_filters_1': 40, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.021247856042542573, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 22, 'num_filters_3': 35}, 'budget': 44.44444444444444, 'working_directory': '.'}
06:18:14 DISPATCHER: Starting worker discovery
06:18:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:18:14 DISPATCHER: Finished worker discovery
06:19:14 DISPATCHER: Starting worker discovery
06:19:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:19:14 DISPATCHER: Finished worker discovery
06:19:53 WORKER: done with job (8, 0, 10), trying to register it.
06:19:53 WORKER: registered result for job (8, 0, 10) with dispatcher
06:19:53 DISPATCHER: job (8, 0, 10) finished
06:19:53 DISPATCHER: register_result: lock acquired
06:19:53 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
06:19:53 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.007770960947494053, 'num_filters_1': 40, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.021247856042542573, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 22, 'num_filters_3': 35}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5169354947694761, 'info': {'sick_no_sick': 0.5169354947694761, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.007770960947494053, 'num_filters_1': 40, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.021247856042542573, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 22, 'num_filters_3': 35}"}}
exception: None

06:19:53 job_callback for (8, 0, 10) started
06:19:53 DISPATCHER: Trying to submit another job.
06:19:53 job_callback for (8, 0, 10) got condition
06:19:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:19:53 HBMASTER: Trying to run another job!
06:19:53 job_callback for (8, 0, 10) finished
06:19:53 start sampling a new configuration.
06:19:53 done sampling a new configuration.
06:19:53 HBMASTER: schedule new run for iteration 8
06:19:53 HBMASTER: trying submitting job (8, 0, 11) to dispatcher
06:19:53 HBMASTER: submitting job (8, 0, 11) to dispatcher
06:19:53 DISPATCHER: trying to submit job (8, 0, 11)
06:19:53 DISPATCHER: trying to notify the job_runner thread.
06:19:53 HBMASTER: job (8, 0, 11) submitted to dispatcher
06:19:53 DISPATCHER: Trying to submit another job.
06:19:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:19:53 DISPATCHER: starting job (8, 0, 11) on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:19:53 DISPATCHER: job (8, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:19:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:19:53 WORKER: start processing job (8, 0, 11)
06:19:53 WORKER: args: ()
06:19:53 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.016286937095940788, 'num_filters_1': 62, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.04670825999361136, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 23, 'num_filters_3': 21, 'num_filters_4': 24}, 'budget': 44.44444444444444, 'working_directory': '.'}
06:20:14 DISPATCHER: Starting worker discovery
06:20:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:20:14 DISPATCHER: Finished worker discovery
06:21:14 DISPATCHER: Starting worker discovery
06:21:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:21:14 DISPATCHER: Finished worker discovery
06:21:43 WORKER: done with job (8, 0, 11), trying to register it.
06:21:43 WORKER: registered result for job (8, 0, 11) with dispatcher
06:21:43 DISPATCHER: job (8, 0, 11) finished
06:21:43 DISPATCHER: register_result: lock acquired
06:21:43 DISPATCHER: job (8, 0, 11) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
06:21:43 job_id: (8, 0, 11)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.016286937095940788, 'num_filters_1': 62, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.04670825999361136, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 23, 'num_filters_3': 21, 'num_filters_4': 24}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.006092544386810309, 'info': {'sick_no_sick': 0.006092544386810309, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.016286937095940788, 'num_filters_1': 62, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.04670825999361136, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 23, 'num_filters_3': 21, 'num_filters_4': 24}"}}
exception: None

06:21:43 job_callback for (8, 0, 11) started
06:21:43 DISPATCHER: Trying to submit another job.
06:21:43 job_callback for (8, 0, 11) got condition
06:21:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:21:43 HBMASTER: Trying to run another job!
06:21:43 job_callback for (8, 0, 11) finished
06:21:43 start sampling a new configuration.
06:21:43 done sampling a new configuration.
06:21:43 HBMASTER: schedule new run for iteration 8
06:21:43 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
06:21:43 HBMASTER: submitting job (8, 0, 12) to dispatcher
06:21:43 DISPATCHER: trying to submit job (8, 0, 12)
06:21:43 DISPATCHER: trying to notify the job_runner thread.
06:21:43 HBMASTER: job (8, 0, 12) submitted to dispatcher
06:21:43 DISPATCHER: Trying to submit another job.
06:21:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:21:43 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:21:43 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:21:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:21:43 WORKER: start processing job (8, 0, 12)
06:21:43 WORKER: args: ()
06:21:43 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.07950183060394168, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.08306958875444943, 'kernel_size_2': 7, 'num_filters_2': 58}, 'budget': 44.44444444444444, 'working_directory': '.'}
06:22:14 DISPATCHER: Starting worker discovery
06:22:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:22:14 DISPATCHER: Finished worker discovery
Exception in thread Thread-744:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    preds = np.concatenate(preds)
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

06:23:14 DISPATCHER: Starting worker discovery
06:23:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:23:14 DISPATCHER: Finished worker discovery
06:23:27 WORKER: done with job (8, 0, 12), trying to register it.
06:23:27 WORKER: registered result for job (8, 0, 12) with dispatcher
06:23:27 DISPATCHER: job (8, 0, 12) finished
06:23:27 DISPATCHER: register_result: lock acquired
06:23:27 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
06:23:27 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.07950183060394168, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.08306958875444943, 'kernel_size_2': 7, 'num_filters_2': 58}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1272343784890101, 'info': {'sick_no_sick': 0.1272343784890101, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.07950183060394168, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.08306958875444943, 'kernel_size_2': 7, 'num_filters_2': 58}"}}
exception: None

06:23:27 job_callback for (8, 0, 12) started
06:23:27 DISPATCHER: Trying to submit another job.
06:23:27 job_callback for (8, 0, 12) got condition
06:23:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:23:27 HBMASTER: Trying to run another job!
06:23:27 job_callback for (8, 0, 12) finished
06:23:27 start sampling a new configuration.
06:23:28 best_vector: [1, 1, 0.3536025839147243, 0.8022520854440828, 0.7617858935880665, 1, 0.4376488860145977, 0.24464206412774914, 0, 0, 0, 0, 0.13652235408451, 0.46691212332672144, 0.5909496940263754, 0.486457819203018], 0.006694595529171263, 0.0028671089172818093, 1.919413453928186e-05
06:23:28 done sampling a new configuration.
06:23:28 HBMASTER: schedule new run for iteration 8
06:23:28 HBMASTER: trying submitting job (8, 0, 13) to dispatcher
06:23:28 HBMASTER: submitting job (8, 0, 13) to dispatcher
06:23:28 DISPATCHER: trying to submit job (8, 0, 13)
06:23:28 DISPATCHER: trying to notify the job_runner thread.
06:23:28 HBMASTER: job (8, 0, 13) submitted to dispatcher
06:23:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:23:28 DISPATCHER: Trying to submit another job.
06:23:28 DISPATCHER: starting job (8, 0, 13) on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:23:28 DISPATCHER: job (8, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:23:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:23:28 WORKER: start processing job (8, 0, 13)
06:23:28 WORKER: args: ()
06:23:28 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.005095715441508811, 'num_filters_1': 85, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.020810698802477535, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 21, 'num_filters_3': 42, 'num_filters_4': 54}, 'budget': 44.44444444444444, 'working_directory': '.'}
06:24:14 DISPATCHER: Starting worker discovery
06:24:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:24:14 DISPATCHER: Finished worker discovery
06:25:13 WORKER: done with job (8, 0, 13), trying to register it.
06:25:13 WORKER: registered result for job (8, 0, 13) with dispatcher
06:25:13 DISPATCHER: job (8, 0, 13) finished
06:25:13 DISPATCHER: register_result: lock acquired
06:25:13 DISPATCHER: job (8, 0, 13) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
06:25:13 job_id: (8, 0, 13)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.005095715441508811, 'num_filters_1': 85, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.020810698802477535, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 21, 'num_filters_3': 42, 'num_filters_4': 54}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4405990258442337, 'info': {'sick_no_sick': 0.4405990258442337, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.005095715441508811, 'num_filters_1': 85, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.020810698802477535, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 21, 'num_filters_3': 42, 'num_filters_4': 54}"}}
exception: None

06:25:13 job_callback for (8, 0, 13) started
06:25:13 job_callback for (8, 0, 13) got condition
06:25:13 DISPATCHER: Trying to submit another job.
06:25:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:25:13 HBMASTER: Trying to run another job!
06:25:13 job_callback for (8, 0, 13) finished
06:25:13 start sampling a new configuration.
06:25:13 best_vector: [2, 2, 0.2684792655539995, 0.12849410541433484, 0.4941984616500432, 1, 0.6045956335300204, 0.28586325481120406, 2, 0, 2, 2, 0.34349475826167963, 0.7593748811437223, 0.5149743464996072, 0.33996231709009306], 0.0046928767671470945, 0.008982265958194353, 4.2152667231546516e-05
06:25:13 done sampling a new configuration.
06:25:13 HBMASTER: schedule new run for iteration 8
06:25:13 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
06:25:13 HBMASTER: submitting job (8, 0, 14) to dispatcher
06:25:13 DISPATCHER: trying to submit job (8, 0, 14)
06:25:13 DISPATCHER: trying to notify the job_runner thread.
06:25:13 HBMASTER: job (8, 0, 14) submitted to dispatcher
06:25:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:25:13 DISPATCHER: Trying to submit another job.
06:25:13 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:25:13 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:25:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:25:13 WORKER: start processing job (8, 0, 14)
06:25:13 WORKER: args: ()
06:25:13 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003443170518552531, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.023545974490257474, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 32, 'num_filters_3': 77}, 'budget': 44.44444444444444, 'working_directory': '.'}
06:25:14 DISPATCHER: Starting worker discovery
06:25:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:25:14 DISPATCHER: Finished worker discovery
06:26:14 DISPATCHER: Starting worker discovery
06:26:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:26:14 DISPATCHER: Finished worker discovery
06:26:59 WORKER: done with job (8, 0, 14), trying to register it.
06:26:59 WORKER: registered result for job (8, 0, 14) with dispatcher
06:26:59 DISPATCHER: job (8, 0, 14) finished
06:26:59 DISPATCHER: register_result: lock acquired
06:26:59 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
06:26:59 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003443170518552531, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.023545974490257474, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 32, 'num_filters_3': 77}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.46581902762998684, 'info': {'sick_no_sick': 0.46581902762998684, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003443170518552531, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.023545974490257474, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 32, 'num_filters_3': 77}"}}
exception: None

06:26:59 job_callback for (8, 0, 14) started
06:26:59 job_callback for (8, 0, 14) got condition
06:26:59 DISPATCHER: Trying to submit another job.
06:26:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:26:59 HBMASTER: Trying to run another job!
06:26:59 job_callback for (8, 0, 14) finished
06:26:59 start sampling a new configuration.
06:26:59 done sampling a new configuration.
06:26:59 HBMASTER: schedule new run for iteration 8
06:26:59 HBMASTER: trying submitting job (8, 0, 15) to dispatcher
06:26:59 HBMASTER: submitting job (8, 0, 15) to dispatcher
06:26:59 DISPATCHER: trying to submit job (8, 0, 15)
06:26:59 DISPATCHER: trying to notify the job_runner thread.
06:26:59 HBMASTER: job (8, 0, 15) submitted to dispatcher
06:26:59 DISPATCHER: Trying to submit another job.
06:26:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:26:59 DISPATCHER: starting job (8, 0, 15) on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:26:59 DISPATCHER: job (8, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:26:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:26:59 WORKER: start processing job (8, 0, 15)
06:26:59 WORKER: args: ()
06:26:59 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.012053866801423136, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.052102579742391165, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 53, 'num_filters_3': 104}, 'budget': 44.44444444444444, 'working_directory': '.'}
06:27:14 DISPATCHER: Starting worker discovery
06:27:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:27:14 DISPATCHER: Finished worker discovery
06:28:14 DISPATCHER: Starting worker discovery
06:28:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:28:14 DISPATCHER: Finished worker discovery
06:28:47 WORKER: done with job (8, 0, 15), trying to register it.
06:28:47 WORKER: registered result for job (8, 0, 15) with dispatcher
06:28:47 DISPATCHER: job (8, 0, 15) finished
06:28:47 DISPATCHER: register_result: lock acquired
06:28:47 DISPATCHER: job (8, 0, 15) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
06:28:47 job_id: (8, 0, 15)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.012053866801423136, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.052102579742391165, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 53, 'num_filters_3': 104}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.012053866801423136, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.052102579742391165, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 53, 'num_filters_3': 104}"}}
exception: None

06:28:47 job_callback for (8, 0, 15) started
06:28:47 DISPATCHER: Trying to submit another job.
06:28:47 job_callback for (8, 0, 15) got condition
06:28:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:28:47 HBMASTER: Trying to run another job!
06:28:47 job_callback for (8, 0, 15) finished
06:28:47 start sampling a new configuration.
06:28:47 best_vector: [2, 2, 0.2589522077287701, 0.9193131501041231, 0.3185347674075848, 0, 0.6403362950893101, 0.3250974229253759, 1, 0, 0, 2, 0.9084724240785338, 0.42416746611202827, 0.5859182446205337, 0.41995179568968277], 0.0008216776081580811, 0.004770188281972728, 3.919556897995057e-06
06:28:47 done sampling a new configuration.
06:28:47 HBMASTER: schedule new run for iteration 8
06:28:47 HBMASTER: trying submitting job (8, 0, 16) to dispatcher
06:28:47 HBMASTER: submitting job (8, 0, 16) to dispatcher
06:28:47 DISPATCHER: trying to submit job (8, 0, 16)
06:28:47 DISPATCHER: trying to notify the job_runner thread.
06:28:47 HBMASTER: job (8, 0, 16) submitted to dispatcher
06:28:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:28:47 DISPATCHER: Trying to submit another job.
06:28:47 DISPATCHER: starting job (8, 0, 16) on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:28:47 DISPATCHER: job (8, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:28:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:28:47 WORKER: start processing job (8, 0, 16)
06:28:47 WORKER: args: ()
06:28:47 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003295371758500615, 'num_filters_1': 108, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.02648265353041658, 'kernel_size_2': 5, 'num_filters_2': 106}, 'budget': 44.44444444444444, 'working_directory': '.'}
06:29:14 DISPATCHER: Starting worker discovery
06:29:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:29:14 DISPATCHER: Finished worker discovery
06:30:14 DISPATCHER: Starting worker discovery
06:30:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:30:14 DISPATCHER: Finished worker discovery
06:30:32 WORKER: done with job (8, 0, 16), trying to register it.
06:30:32 WORKER: registered result for job (8, 0, 16) with dispatcher
06:30:32 DISPATCHER: job (8, 0, 16) finished
06:30:32 DISPATCHER: register_result: lock acquired
06:30:32 DISPATCHER: job (8, 0, 16) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
06:30:32 job_id: (8, 0, 16)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003295371758500615, 'num_filters_1': 108, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.02648265353041658, 'kernel_size_2': 5, 'num_filters_2': 106}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.42219933168818063, 'info': {'sick_no_sick': 0.42219933168818063, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003295371758500615, 'num_filters_1': 108, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.02648265353041658, 'kernel_size_2': 5, 'num_filters_2': 106}"}}
exception: None

06:30:32 job_callback for (8, 0, 16) started
06:30:32 DISPATCHER: Trying to submit another job.
06:30:32 job_callback for (8, 0, 16) got condition
06:30:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:30:32 HBMASTER: Trying to run another job!
06:30:32 job_callback for (8, 0, 16) finished
06:30:32 start sampling a new configuration.
06:30:32 best_vector: [3, 2, 0.4146409845882766, 0.6365718245835327, 0.4611759374446681, 1, 0.9510264853948645, 0.2524753569832562, 2, 0, 2, 2, 0.15843302663837922, 0.7889885543820696, 0.5005500552378008, 0.2794033917659846], 0.0057264098617276025, 0.006094017249293674, 3.4896840473893416e-05
06:30:32 done sampling a new configuration.
06:30:32 HBMASTER: schedule new run for iteration 8
06:30:32 HBMASTER: trying submitting job (8, 0, 17) to dispatcher
06:30:32 HBMASTER: submitting job (8, 0, 17) to dispatcher
06:30:32 DISPATCHER: trying to submit job (8, 0, 17)
06:30:32 DISPATCHER: trying to notify the job_runner thread.
06:30:32 HBMASTER: job (8, 0, 17) submitted to dispatcher
06:30:32 DISPATCHER: Trying to submit another job.
06:30:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:30:32 DISPATCHER: starting job (8, 0, 17) on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:30:32 DISPATCHER: job (8, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:30:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:30:32 WORKER: start processing job (8, 0, 17)
06:30:32 WORKER: args: ()
06:30:32 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.006749661126310735, 'num_filters_1': 60, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.02130482703039201, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 22, 'num_filters_3': 82}, 'budget': 44.44444444444444, 'working_directory': '.'}
06:31:14 DISPATCHER: Starting worker discovery
06:31:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:31:14 DISPATCHER: Finished worker discovery
06:32:14 DISPATCHER: Starting worker discovery
06:32:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:32:14 DISPATCHER: Finished worker discovery
06:32:21 WORKER: done with job (8, 0, 17), trying to register it.
06:32:21 WORKER: registered result for job (8, 0, 17) with dispatcher
06:32:21 DISPATCHER: job (8, 0, 17) finished
06:32:21 DISPATCHER: register_result: lock acquired
06:32:21 DISPATCHER: job (8, 0, 17) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
06:32:21 job_id: (8, 0, 17)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.006749661126310735, 'num_filters_1': 60, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.02130482703039201, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 22, 'num_filters_3': 82}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.08532840553515558, 'info': {'sick_no_sick': 0.08532840553515558, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.006749661126310735, 'num_filters_1': 60, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.02130482703039201, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 22, 'num_filters_3': 82}"}}
exception: None

06:32:21 job_callback for (8, 0, 17) started
06:32:21 job_callback for (8, 0, 17) got condition
06:32:21 DISPATCHER: Trying to submit another job.
06:32:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:32:21 HBMASTER: Trying to run another job!
06:32:21 job_callback for (8, 0, 17) finished
06:32:21 start sampling a new configuration.
06:32:21 best_vector: [0, 0, 0.16197090601408265, 0.9881776239289641, 0.032007063921794754, 0, 0.6337054992678757, 0.8442559232597632, 2, 0, 2, 0, 0.6465835577421706, 0.9999165589018402, 0.5273356395503137, 0.3389424180058962], 0.0027496017401610813, 0.00019008098256513746, 5.226470004326301e-07
06:32:21 done sampling a new configuration.
06:32:21 HBMASTER: schedule new run for iteration 8
06:32:21 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
06:32:21 HBMASTER: submitting job (8, 0, 18) to dispatcher
06:32:21 DISPATCHER: trying to submit job (8, 0, 18)
06:32:21 DISPATCHER: trying to notify the job_runner thread.
06:32:21 HBMASTER: job (8, 0, 18) submitted to dispatcher
06:32:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:32:21 DISPATCHER: Trying to submit another job.
06:32:21 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:32:21 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:32:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:32:21 WORKER: start processing job (8, 0, 18)
06:32:21 WORKER: args: ()
06:32:21 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0021083456490467952, 'num_filters_1': 125, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.12543024777540132}, 'budget': 44.44444444444444, 'working_directory': '.'}
06:33:14 DISPATCHER: Starting worker discovery
06:33:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:33:14 DISPATCHER: Finished worker discovery
06:34:08 WORKER: done with job (8, 0, 18), trying to register it.
06:34:08 WORKER: registered result for job (8, 0, 18) with dispatcher
06:34:08 DISPATCHER: job (8, 0, 18) finished
06:34:08 DISPATCHER: register_result: lock acquired
06:34:08 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
06:34:08 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0021083456490467952, 'num_filters_1': 125, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.12543024777540132}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2931453049445917, 'info': {'sick_no_sick': 0.2931453049445917, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0021083456490467952, 'num_filters_1': 125, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.12543024777540132}"}}
exception: None

06:34:08 job_callback for (8, 0, 18) started
06:34:08 job_callback for (8, 0, 18) got condition
06:34:08 DISPATCHER: Trying to submit another job.
06:34:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:34:08 HBMASTER: Trying to run another job!
06:34:08 job_callback for (8, 0, 18) finished
06:34:08 start sampling a new configuration.
06:34:08 done sampling a new configuration.
06:34:08 HBMASTER: schedule new run for iteration 8
06:34:08 HBMASTER: trying submitting job (8, 0, 19) to dispatcher
06:34:08 HBMASTER: submitting job (8, 0, 19) to dispatcher
06:34:08 DISPATCHER: trying to submit job (8, 0, 19)
06:34:08 DISPATCHER: trying to notify the job_runner thread.
06:34:08 HBMASTER: job (8, 0, 19) submitted to dispatcher
06:34:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:34:08 DISPATCHER: Trying to submit another job.
06:34:08 DISPATCHER: starting job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:34:08 DISPATCHER: job (8, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:34:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:34:08 WORKER: start processing job (8, 0, 19)
06:34:08 WORKER: args: ()
06:34:08 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.012888148937616657, 'num_filters_1': 58, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.03076474500832118}, 'budget': 44.44444444444444, 'working_directory': '.'}
06:34:14 DISPATCHER: Starting worker discovery
06:34:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:34:14 DISPATCHER: Finished worker discovery
06:35:14 DISPATCHER: Starting worker discovery
06:35:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:35:14 DISPATCHER: Finished worker discovery
06:35:55 WORKER: done with job (8, 0, 19), trying to register it.
06:35:55 WORKER: registered result for job (8, 0, 19) with dispatcher
06:35:55 DISPATCHER: job (8, 0, 19) finished
06:35:55 DISPATCHER: register_result: lock acquired
06:35:55 DISPATCHER: job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
06:35:55 job_id: (8, 0, 19)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.012888148937616657, 'num_filters_1': 58, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.03076474500832118}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5076849760389306, 'info': {'sick_no_sick': 0.5076849760389306, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.012888148937616657, 'num_filters_1': 58, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.03076474500832118}"}}
exception: None

06:35:55 job_callback for (8, 0, 19) started
06:35:55 job_callback for (8, 0, 19) got condition
06:35:55 DISPATCHER: Trying to submit another job.
06:35:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:35:55 HBMASTER: Trying to run another job!
06:35:55 job_callback for (8, 0, 19) finished
06:35:55 start sampling a new configuration.
06:35:55 best_vector: [2, 2, 0.10699058447944909, 0.8067541109759847, 0.2835599826063545, 1, 0.2565955450068905, 0.5563649003071761, 0, 0, 1, 2, 0.8268503025961117, 0.35314681618688104, 0.4702638305833622, 0.4954688599968195], 0.0031694275470456777, 0.002076041397797471, 6.579862794986519e-06
06:35:55 done sampling a new configuration.
06:35:55 HBMASTER: schedule new run for iteration 8
06:35:55 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
06:35:55 HBMASTER: submitting job (8, 0, 20) to dispatcher
06:35:55 DISPATCHER: trying to submit job (8, 0, 20)
06:35:55 DISPATCHER: trying to notify the job_runner thread.
06:35:55 HBMASTER: job (8, 0, 20) submitted to dispatcher
06:35:55 DISPATCHER: Trying to submit another job.
06:35:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:35:55 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:35:55 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:35:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:35:55 WORKER: start processing job (8, 0, 20)
06:35:55 WORKER: args: ()
06:35:55 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0016367455504801176, 'num_filters_1': 85, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.052947739542300636, 'kernel_size_2': 3, 'num_filters_2': 89}, 'budget': 44.44444444444444, 'working_directory': '.'}
06:36:14 DISPATCHER: Starting worker discovery
06:36:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:36:14 DISPATCHER: Finished worker discovery
06:37:14 DISPATCHER: Starting worker discovery
06:37:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:37:14 DISPATCHER: Finished worker discovery
06:37:42 WORKER: done with job (8, 0, 20), trying to register it.
06:37:42 WORKER: registered result for job (8, 0, 20) with dispatcher
06:37:42 DISPATCHER: job (8, 0, 20) finished
06:37:42 DISPATCHER: register_result: lock acquired
06:37:42 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
06:37:42 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0016367455504801176, 'num_filters_1': 85, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.052947739542300636, 'kernel_size_2': 3, 'num_filters_2': 89}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4635802292897388, 'info': {'sick_no_sick': 0.4635802292897388, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0016367455504801176, 'num_filters_1': 85, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.052947739542300636, 'kernel_size_2': 3, 'num_filters_2': 89}"}}
exception: None

06:37:42 job_callback for (8, 0, 20) started
06:37:42 job_callback for (8, 0, 20) got condition
06:37:42 DISPATCHER: Trying to submit another job.
06:37:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:37:42 HBMASTER: Trying to run another job!
06:37:42 job_callback for (8, 0, 20) finished
06:37:42 start sampling a new configuration.
06:37:42 best_vector: [1, 2, 0.14603046850325807, 0.777253363000579, 0.2882260647370053, 1, 0.9784945621795105, 0.9974426325263394, 2, 0, 2, 2, 0.9582167979447677, 0.3258428579683938, 0.5225779285468414, 0.9787488799967323], 0.0009003511580764787, 0.0001591583590812893, 1.4329841291639087e-07
06:37:42 done sampling a new configuration.
06:37:42 HBMASTER: schedule new run for iteration 8
06:37:42 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
06:37:42 HBMASTER: submitting job (8, 0, 21) to dispatcher
06:37:42 DISPATCHER: trying to submit job (8, 0, 21)
06:37:42 DISPATCHER: trying to notify the job_runner thread.
06:37:42 HBMASTER: job (8, 0, 21) submitted to dispatcher
06:37:42 DISPATCHER: Trying to submit another job.
06:37:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:37:42 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:37:42 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:37:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:37:42 WORKER: start processing job (8, 0, 21)
06:37:42 WORKER: args: ()
06:37:42 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.00195911954346241, 'num_filters_1': 80, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.198473616765198, 'kernel_size_2': 7, 'num_filters_2': 118}, 'budget': 44.44444444444444, 'working_directory': '.'}
06:38:14 DISPATCHER: Starting worker discovery
06:38:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:38:14 DISPATCHER: Finished worker discovery
06:39:14 DISPATCHER: Starting worker discovery
06:39:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:39:14 DISPATCHER: Finished worker discovery
06:39:29 WORKER: done with job (8, 0, 21), trying to register it.
06:39:29 WORKER: registered result for job (8, 0, 21) with dispatcher
06:39:29 DISPATCHER: job (8, 0, 21) finished
06:39:29 DISPATCHER: register_result: lock acquired
06:39:29 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
06:39:29 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.00195911954346241, 'num_filters_1': 80, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.198473616765198, 'kernel_size_2': 7, 'num_filters_2': 118}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3973477949268904, 'info': {'sick_no_sick': 0.3973477949268904, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.00195911954346241, 'num_filters_1': 80, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.198473616765198, 'kernel_size_2': 7, 'num_filters_2': 118}"}}
exception: None

06:39:29 job_callback for (8, 0, 21) started
06:39:29 job_callback for (8, 0, 21) got condition
06:39:29 DISPATCHER: Trying to submit another job.
06:39:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:39:29 HBMASTER: Trying to run another job!
06:39:29 job_callback for (8, 0, 21) finished
06:39:29 start sampling a new configuration.
06:39:29 done sampling a new configuration.
06:39:29 HBMASTER: schedule new run for iteration 8
06:39:29 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
06:39:29 HBMASTER: submitting job (8, 0, 22) to dispatcher
06:39:29 DISPATCHER: trying to submit job (8, 0, 22)
06:39:29 DISPATCHER: trying to notify the job_runner thread.
06:39:29 HBMASTER: job (8, 0, 22) submitted to dispatcher
06:39:29 DISPATCHER: Trying to submit another job.
06:39:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:39:29 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:39:29 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:39:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:39:29 WORKER: start processing job (8, 0, 22)
06:39:29 WORKER: args: ()
06:39:29 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.04695226623107558, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.03455146960155718, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 16, 'num_filters_3': 16, 'num_filters_4': 19, 'num_filters_5': 109}, 'budget': 44.44444444444444, 'working_directory': '.'}
06:40:14 DISPATCHER: Starting worker discovery
06:40:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:40:14 DISPATCHER: Finished worker discovery
06:41:14 WORKER: done with job (8, 0, 22), trying to register it.
06:41:14 WORKER: registered result for job (8, 0, 22) with dispatcher
06:41:14 DISPATCHER: job (8, 0, 22) finished
06:41:14 DISPATCHER: register_result: lock acquired
06:41:14 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
06:41:14 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.04695226623107558, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.03455146960155718, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 16, 'num_filters_3': 16, 'num_filters_4': 19, 'num_filters_5': 109}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'sick_no_sick': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.04695226623107558, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.03455146960155718, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 16, 'num_filters_3': 16, 'num_filters_4': 19, 'num_filters_5': 109}"}}
exception: None

06:41:14 job_callback for (8, 0, 22) started
06:41:14 job_callback for (8, 0, 22) got condition
06:41:14 DISPATCHER: Trying to submit another job.
06:41:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:41:14 HBMASTER: Trying to run another job!
06:41:14 job_callback for (8, 0, 22) finished
06:41:14 start sampling a new configuration.
06:41:14 best_vector: [2, 0, 0.14448811223425653, 0.3641404669462635, 0.31665847923291895, 0, 0.44801218441464263, 0.42594707197755644, 2, 1, 1, 0, 0.6386573049647204, 0.9381878941755211, 0.5662823393755206, 0.48400683331484284], 0.008338718883112136, 0.00286231320725309, 2.3868025190702605e-05
06:41:14 done sampling a new configuration.
06:41:14 HBMASTER: schedule new run for iteration 8
06:41:14 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
06:41:14 HBMASTER: submitting job (8, 0, 23) to dispatcher
06:41:14 DISPATCHER: trying to submit job (8, 0, 23)
06:41:14 DISPATCHER: trying to notify the job_runner thread.
06:41:14 HBMASTER: job (8, 0, 23) submitted to dispatcher
06:41:14 DISPATCHER: Trying to submit another job.
06:41:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:41:14 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:41:14 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:41:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:41:14 WORKER: start processing job (8, 0, 23)
06:41:14 WORKER: args: ()
06:41:14 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0019452535854414135, 'num_filters_1': 33, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.035823656932628, 'kernel_size_2': 7, 'num_filters_2': 60}, 'budget': 44.44444444444444, 'working_directory': '.'}
06:41:14 DISPATCHER: Starting worker discovery
06:41:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:41:14 DISPATCHER: Finished worker discovery
06:42:14 DISPATCHER: Starting worker discovery
06:42:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:42:14 DISPATCHER: Finished worker discovery
06:43:01 WORKER: done with job (8, 0, 23), trying to register it.
06:43:01 WORKER: registered result for job (8, 0, 23) with dispatcher
06:43:01 DISPATCHER: job (8, 0, 23) finished
06:43:01 DISPATCHER: register_result: lock acquired
06:43:01 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
06:43:01 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0019452535854414135, 'num_filters_1': 33, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.035823656932628, 'kernel_size_2': 7, 'num_filters_2': 60}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4286768968090088, 'info': {'sick_no_sick': 0.4286768968090088, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0019452535854414135, 'num_filters_1': 33, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.035823656932628, 'kernel_size_2': 7, 'num_filters_2': 60}"}}
exception: None

06:43:01 job_callback for (8, 0, 23) started
06:43:01 job_callback for (8, 0, 23) got condition
06:43:01 DISPATCHER: Trying to submit another job.
06:43:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:43:01 HBMASTER: Trying to run another job!
06:43:01 job_callback for (8, 0, 23) finished
06:43:01 start sampling a new configuration.
06:43:01 best_vector: [1, 2, 0.023828575326307444, 0.8115235678746517, 0.41081898909023257, 1, 0.8878590970482563, 0.33875346166213977, 0, 1, 0, 0, 0.3413178877699093, 0.1519541300479535, 0.5306436479061586, 0.14025247440772382], 0.00851509431790474, 0.0012371429712934713, 1.0534389085296824e-05
06:43:01 done sampling a new configuration.
06:43:01 HBMASTER: schedule new run for iteration 8
06:43:01 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
06:43:01 HBMASTER: submitting job (8, 0, 24) to dispatcher
06:43:01 DISPATCHER: trying to submit job (8, 0, 24)
06:43:01 DISPATCHER: trying to notify the job_runner thread.
06:43:01 HBMASTER: job (8, 0, 24) submitted to dispatcher
06:43:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:43:01 DISPATCHER: Trying to submit another job.
06:43:01 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:43:01 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:43:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:43:01 WORKER: start processing job (8, 0, 24)
06:43:01 WORKER: args: ()
06:43:01 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0011159818994171003, 'num_filters_1': 86, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.027588520736812516, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 32, 'num_filters_3': 21}, 'budget': 44.44444444444444, 'working_directory': '.'}
06:43:14 DISPATCHER: Starting worker discovery
06:43:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:43:14 DISPATCHER: Finished worker discovery
06:44:14 DISPATCHER: Starting worker discovery
06:44:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:44:14 DISPATCHER: Finished worker discovery
06:44:47 WORKER: done with job (8, 0, 24), trying to register it.
06:44:47 WORKER: registered result for job (8, 0, 24) with dispatcher
06:44:47 DISPATCHER: job (8, 0, 24) finished
06:44:47 DISPATCHER: register_result: lock acquired
06:44:47 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
06:44:47 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0011159818994171003, 'num_filters_1': 86, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.027588520736812516, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 32, 'num_filters_3': 21}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4189067976629582, 'info': {'sick_no_sick': 0.4189067976629582, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0011159818994171003, 'num_filters_1': 86, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.027588520736812516, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 32, 'num_filters_3': 21}"}}
exception: None

06:44:47 job_callback for (8, 0, 24) started
06:44:47 DISPATCHER: Trying to submit another job.
06:44:47 job_callback for (8, 0, 24) got condition
06:44:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:44:47 HBMASTER: Trying to run another job!
06:44:47 job_callback for (8, 0, 24) finished
06:44:47 start sampling a new configuration.
06:44:47 best_vector: [1, 2, 0.36796671259182256, 0.8295628741612509, 0.3671751395079128, 1, 0.9228925302674879, 0.5656865164641214, 1, 0, 1, 2, 0.833399159690378, 0.4097992098129845, 0.4684018244740566, 0.7365171683467654], 0.0033140207819805753, 0.0020520288039539876, 6.800466101526258e-06
06:44:47 done sampling a new configuration.
06:44:47 HBMASTER: schedule new run for iteration 8
06:44:47 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
06:44:47 HBMASTER: submitting job (8, 0, 25) to dispatcher
06:44:47 DISPATCHER: trying to submit job (8, 0, 25)
06:44:47 DISPATCHER: trying to notify the job_runner thread.
06:44:47 HBMASTER: job (8, 0, 25) submitted to dispatcher
06:44:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:44:47 DISPATCHER: Trying to submit another job.
06:44:47 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:44:47 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:44:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:44:47 WORKER: start processing job (8, 0, 25)
06:44:47 WORKER: args: ()
06:44:47 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005444191901522411, 'num_filters_1': 90, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.05444714676957671, 'kernel_size_2': 5, 'num_filters_2': 90}, 'budget': 44.44444444444444, 'working_directory': '.'}
06:45:14 DISPATCHER: Starting worker discovery
06:45:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:45:14 DISPATCHER: Finished worker discovery
06:46:14 DISPATCHER: Starting worker discovery
06:46:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:46:14 DISPATCHER: Finished worker discovery
06:46:33 WORKER: done with job (8, 0, 25), trying to register it.
06:46:33 WORKER: registered result for job (8, 0, 25) with dispatcher
06:46:33 DISPATCHER: job (8, 0, 25) finished
06:46:33 DISPATCHER: register_result: lock acquired
06:46:33 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
06:46:33 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005444191901522411, 'num_filters_1': 90, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.05444714676957671, 'kernel_size_2': 5, 'num_filters_2': 90}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5043830974018974, 'info': {'sick_no_sick': 0.5043830974018974, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005444191901522411, 'num_filters_1': 90, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.05444714676957671, 'kernel_size_2': 5, 'num_filters_2': 90}"}}
exception: None

06:46:33 job_callback for (8, 0, 25) started
06:46:33 job_callback for (8, 0, 25) got condition
06:46:33 DISPATCHER: Trying to submit another job.
06:46:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:46:33 HBMASTER: Trying to run another job!
06:46:33 job_callback for (8, 0, 25) finished
06:46:33 start sampling a new configuration.
06:46:33 best_vector: [3, 0, 0.41146156871965345, 0.9100953633987481, 0.21173796192021144, 0, 0.4535567736583938, 0.44917872753334553, 0, 1, 0, 2, 0.5985540524067172, 0.7879346450033992, 0.5590034663931822, 0.42826287602654484], 0.00541944563394286, 0.0014588202892722136, 7.905997247403559e-06
06:46:33 done sampling a new configuration.
06:46:33 HBMASTER: schedule new run for iteration 8
06:46:33 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
06:46:33 HBMASTER: submitting job (8, 0, 26) to dispatcher
06:46:33 DISPATCHER: trying to submit job (8, 0, 26)
06:46:33 DISPATCHER: trying to notify the job_runner thread.
06:46:33 HBMASTER: job (8, 0, 26) submitted to dispatcher
06:46:33 DISPATCHER: Trying to submit another job.
06:46:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:46:33 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:46:33 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:46:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:46:33 WORKER: start processing job (8, 0, 26)
06:46:33 WORKER: args: ()
06:46:33 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0066515542485636, 'num_filters_1': 106, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.03840563922616474, 'kernel_size_2': 3, 'num_filters_2': 55}, 'budget': 44.44444444444444, 'working_directory': '.'}
06:47:14 DISPATCHER: Starting worker discovery
06:47:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:47:14 DISPATCHER: Finished worker discovery
06:48:14 DISPATCHER: Starting worker discovery
06:48:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:48:14 DISPATCHER: Finished worker discovery
06:48:19 WORKER: done with job (8, 0, 26), trying to register it.
06:48:19 WORKER: registered result for job (8, 0, 26) with dispatcher
06:48:19 DISPATCHER: job (8, 0, 26) finished
06:48:19 DISPATCHER: register_result: lock acquired
06:48:19 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
06:48:19 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0066515542485636, 'num_filters_1': 106, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.03840563922616474, 'kernel_size_2': 3, 'num_filters_2': 55}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.44424802454012463, 'info': {'sick_no_sick': 0.44424802454012463, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0066515542485636, 'num_filters_1': 106, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.03840563922616474, 'kernel_size_2': 3, 'num_filters_2': 55}"}}
exception: None

06:48:19 job_callback for (8, 0, 26) started
06:48:19 DISPATCHER: Trying to submit another job.
06:48:19 job_callback for (8, 0, 26) got condition
06:48:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:48:19 HBMASTER: Trying to run another job!
06:48:19 job_callback for (8, 0, 26) finished
06:48:19 ITERATION: Advancing config (8, 0, 1) to next budget 133.333333
06:48:19 ITERATION: Advancing config (8, 0, 7) to next budget 133.333333
06:48:19 ITERATION: Advancing config (8, 0, 10) to next budget 133.333333
06:48:19 ITERATION: Advancing config (8, 0, 13) to next budget 133.333333
06:48:19 ITERATION: Advancing config (8, 0, 14) to next budget 133.333333
06:48:19 ITERATION: Advancing config (8, 0, 19) to next budget 133.333333
06:48:19 ITERATION: Advancing config (8, 0, 20) to next budget 133.333333
06:48:19 ITERATION: Advancing config (8, 0, 25) to next budget 133.333333
06:48:19 ITERATION: Advancing config (8, 0, 26) to next budget 133.333333
06:48:19 HBMASTER: schedule new run for iteration 8
06:48:19 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
06:48:19 HBMASTER: submitting job (8, 0, 1) to dispatcher
06:48:19 DISPATCHER: trying to submit job (8, 0, 1)
06:48:19 DISPATCHER: trying to notify the job_runner thread.
06:48:19 HBMASTER: job (8, 0, 1) submitted to dispatcher
06:48:19 DISPATCHER: Trying to submit another job.
06:48:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:48:19 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:48:19 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:48:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:48:19 WORKER: start processing job (8, 0, 1)
06:48:19 WORKER: args: ()
06:48:19 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0037760460738767527, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.07923126446651281}, 'budget': 133.33333333333331, 'working_directory': '.'}
06:49:14 DISPATCHER: Starting worker discovery
06:49:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:49:14 DISPATCHER: Finished worker discovery
06:50:14 DISPATCHER: Starting worker discovery
06:50:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:50:14 DISPATCHER: Finished worker discovery
06:51:14 DISPATCHER: Starting worker discovery
06:51:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:51:14 DISPATCHER: Finished worker discovery
06:51:40 WORKER: done with job (8, 0, 1), trying to register it.
06:51:40 WORKER: registered result for job (8, 0, 1) with dispatcher
06:51:40 DISPATCHER: job (8, 0, 1) finished
06:51:40 DISPATCHER: register_result: lock acquired
06:51:40 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
06:51:40 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0037760460738767527, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.07923126446651281}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.44254682823128927, 'info': {'sick_no_sick': 0.44254682823128927, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0037760460738767527, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.07923126446651281}"}}
exception: None

06:51:40 job_callback for (8, 0, 1) started
06:51:40 job_callback for (8, 0, 1) got condition
06:51:40 DISPATCHER: Trying to submit another job.
06:51:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:51:40 done building a new model for budget 133.333333 based on 17/31 split
Best loss for this budget:-0.553150





06:51:40 HBMASTER: Trying to run another job!
06:51:40 job_callback for (8, 0, 1) finished
06:51:40 HBMASTER: schedule new run for iteration 8
06:51:40 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
06:51:40 HBMASTER: submitting job (8, 0, 7) to dispatcher
06:51:40 DISPATCHER: trying to submit job (8, 0, 7)
06:51:40 DISPATCHER: trying to notify the job_runner thread.
06:51:40 HBMASTER: job (8, 0, 7) submitted to dispatcher
06:51:40 DISPATCHER: Trying to submit another job.
06:51:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:51:40 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:51:40 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:51:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:51:40 WORKER: start processing job (8, 0, 7)
06:51:40 WORKER: args: ()
06:51:40 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001795682226962468, 'num_filters_1': 75, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.0894532421102648}, 'budget': 133.33333333333331, 'working_directory': '.'}
06:52:14 DISPATCHER: Starting worker discovery
06:52:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:52:14 DISPATCHER: Finished worker discovery
06:53:14 DISPATCHER: Starting worker discovery
06:53:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:53:14 DISPATCHER: Finished worker discovery
06:54:14 DISPATCHER: Starting worker discovery
06:54:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:54:14 DISPATCHER: Finished worker discovery
06:54:57 WORKER: done with job (8, 0, 7), trying to register it.
06:54:57 WORKER: registered result for job (8, 0, 7) with dispatcher
06:54:57 DISPATCHER: job (8, 0, 7) finished
06:54:57 DISPATCHER: register_result: lock acquired
06:54:57 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
06:54:57 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001795682226962468, 'num_filters_1': 75, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.0894532421102648}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.47361657486169273, 'info': {'sick_no_sick': 0.47361657486169273, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001795682226962468, 'num_filters_1': 75, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.0894532421102648}"}}
exception: None

06:54:57 job_callback for (8, 0, 7) started
06:54:57 DISPATCHER: Trying to submit another job.
06:54:57 job_callback for (8, 0, 7) got condition
06:54:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:54:57 done building a new model for budget 133.333333 based on 17/32 split
Best loss for this budget:-0.553150





06:54:57 HBMASTER: Trying to run another job!
06:54:57 job_callback for (8, 0, 7) finished
06:54:57 HBMASTER: schedule new run for iteration 8
06:54:57 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
06:54:57 HBMASTER: submitting job (8, 0, 10) to dispatcher
06:54:57 DISPATCHER: trying to submit job (8, 0, 10)
06:54:57 DISPATCHER: trying to notify the job_runner thread.
06:54:57 HBMASTER: job (8, 0, 10) submitted to dispatcher
06:54:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:54:57 DISPATCHER: Trying to submit another job.
06:54:57 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:54:57 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:54:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:54:57 WORKER: start processing job (8, 0, 10)
06:54:57 WORKER: args: ()
06:54:57 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.007770960947494053, 'num_filters_1': 40, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.021247856042542573, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 22, 'num_filters_3': 35}, 'budget': 133.33333333333331, 'working_directory': '.'}
06:55:14 DISPATCHER: Starting worker discovery
06:55:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:55:14 DISPATCHER: Finished worker discovery
06:56:14 DISPATCHER: Starting worker discovery
06:56:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:56:14 DISPATCHER: Finished worker discovery
06:57:14 DISPATCHER: Starting worker discovery
06:57:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:57:15 DISPATCHER: Finished worker discovery
06:58:12 WORKER: done with job (8, 0, 10), trying to register it.
06:58:12 WORKER: registered result for job (8, 0, 10) with dispatcher
06:58:12 DISPATCHER: job (8, 0, 10) finished
06:58:12 DISPATCHER: register_result: lock acquired
06:58:12 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
06:58:12 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.007770960947494053, 'num_filters_1': 40, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.021247856042542573, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 22, 'num_filters_3': 35}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5355036098479007, 'info': {'sick_no_sick': 0.5355036098479007, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.007770960947494053, 'num_filters_1': 40, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.021247856042542573, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 22, 'num_filters_3': 35}"}}
exception: None

06:58:12 job_callback for (8, 0, 10) started
06:58:12 job_callback for (8, 0, 10) got condition
06:58:12 DISPATCHER: Trying to submit another job.
06:58:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:58:12 done building a new model for budget 133.333333 based on 17/33 split
Best loss for this budget:-0.553150





06:58:12 HBMASTER: Trying to run another job!
06:58:12 job_callback for (8, 0, 10) finished
06:58:12 HBMASTER: schedule new run for iteration 8
06:58:12 HBMASTER: trying submitting job (8, 0, 13) to dispatcher
06:58:12 HBMASTER: submitting job (8, 0, 13) to dispatcher
06:58:12 DISPATCHER: trying to submit job (8, 0, 13)
06:58:12 DISPATCHER: trying to notify the job_runner thread.
06:58:12 HBMASTER: job (8, 0, 13) submitted to dispatcher
06:58:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:58:12 DISPATCHER: Trying to submit another job.
06:58:12 DISPATCHER: starting job (8, 0, 13) on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:58:12 DISPATCHER: job (8, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
06:58:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:58:12 WORKER: start processing job (8, 0, 13)
06:58:12 WORKER: args: ()
06:58:12 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.005095715441508811, 'num_filters_1': 85, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.020810698802477535, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 21, 'num_filters_3': 42, 'num_filters_4': 54}, 'budget': 133.33333333333331, 'working_directory': '.'}
06:58:15 DISPATCHER: Starting worker discovery
06:58:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:58:15 DISPATCHER: Finished worker discovery
06:59:15 DISPATCHER: Starting worker discovery
06:59:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:59:15 DISPATCHER: Finished worker discovery
07:00:15 DISPATCHER: Starting worker discovery
07:00:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:00:15 DISPATCHER: Finished worker discovery
07:01:15 DISPATCHER: Starting worker discovery
07:01:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:01:15 DISPATCHER: Finished worker discovery
07:01:31 WORKER: done with job (8, 0, 13), trying to register it.
07:01:31 WORKER: registered result for job (8, 0, 13) with dispatcher
07:01:31 DISPATCHER: job (8, 0, 13) finished
07:01:31 DISPATCHER: register_result: lock acquired
07:01:31 DISPATCHER: job (8, 0, 13) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
07:01:31 job_id: (8, 0, 13)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.005095715441508811, 'num_filters_1': 85, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.020810698802477535, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 21, 'num_filters_3': 42, 'num_filters_4': 54}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.46162966248439574, 'info': {'sick_no_sick': 0.46162966248439574, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.005095715441508811, 'num_filters_1': 85, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.020810698802477535, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 21, 'num_filters_3': 42, 'num_filters_4': 54}"}}
exception: None

07:01:31 job_callback for (8, 0, 13) started
07:01:31 DISPATCHER: Trying to submit another job.
07:01:31 job_callback for (8, 0, 13) got condition
07:01:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:01:31 done building a new model for budget 133.333333 based on 17/34 split
Best loss for this budget:-0.553150





07:01:31 HBMASTER: Trying to run another job!
07:01:31 job_callback for (8, 0, 13) finished
07:01:31 HBMASTER: schedule new run for iteration 8
07:01:31 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
07:01:31 HBMASTER: submitting job (8, 0, 14) to dispatcher
07:01:31 DISPATCHER: trying to submit job (8, 0, 14)
07:01:31 DISPATCHER: trying to notify the job_runner thread.
07:01:31 HBMASTER: job (8, 0, 14) submitted to dispatcher
07:01:31 DISPATCHER: Trying to submit another job.
07:01:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:01:31 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:01:31 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:01:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:01:31 WORKER: start processing job (8, 0, 14)
07:01:31 WORKER: args: ()
07:01:31 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003443170518552531, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.023545974490257474, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 32, 'num_filters_3': 77}, 'budget': 133.33333333333331, 'working_directory': '.'}
07:02:15 DISPATCHER: Starting worker discovery
07:02:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:02:15 DISPATCHER: Finished worker discovery
07:03:15 DISPATCHER: Starting worker discovery
07:03:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:03:15 DISPATCHER: Finished worker discovery
07:04:15 DISPATCHER: Starting worker discovery
07:04:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:04:15 DISPATCHER: Finished worker discovery
07:04:49 WORKER: done with job (8, 0, 14), trying to register it.
07:04:49 WORKER: registered result for job (8, 0, 14) with dispatcher
07:04:49 DISPATCHER: job (8, 0, 14) finished
07:04:49 DISPATCHER: register_result: lock acquired
07:04:49 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
07:04:49 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003443170518552531, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.023545974490257474, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 32, 'num_filters_3': 77}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.496335090719044, 'info': {'sick_no_sick': 0.496335090719044, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003443170518552531, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.023545974490257474, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 32, 'num_filters_3': 77}"}}
exception: None

07:04:49 job_callback for (8, 0, 14) started
07:04:49 DISPATCHER: Trying to submit another job.
07:04:49 job_callback for (8, 0, 14) got condition
07:04:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:04:49 done building a new model for budget 133.333333 based on 17/34 split
Best loss for this budget:-0.553150





07:04:49 HBMASTER: Trying to run another job!
07:04:49 job_callback for (8, 0, 14) finished
07:04:49 HBMASTER: schedule new run for iteration 8
07:04:49 HBMASTER: trying submitting job (8, 0, 19) to dispatcher
07:04:49 HBMASTER: submitting job (8, 0, 19) to dispatcher
07:04:49 DISPATCHER: trying to submit job (8, 0, 19)
07:04:49 DISPATCHER: trying to notify the job_runner thread.
07:04:49 HBMASTER: job (8, 0, 19) submitted to dispatcher
07:04:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:04:49 DISPATCHER: Trying to submit another job.
07:04:49 DISPATCHER: starting job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:04:49 DISPATCHER: job (8, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:04:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:04:49 WORKER: start processing job (8, 0, 19)
07:04:49 WORKER: args: ()
07:04:49 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.012888148937616657, 'num_filters_1': 58, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.03076474500832118}, 'budget': 133.33333333333331, 'working_directory': '.'}
07:05:15 DISPATCHER: Starting worker discovery
07:05:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:05:15 DISPATCHER: Finished worker discovery
07:06:15 DISPATCHER: Starting worker discovery
07:06:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:06:15 DISPATCHER: Finished worker discovery
07:07:15 DISPATCHER: Starting worker discovery
07:07:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:07:15 DISPATCHER: Finished worker discovery
07:08:08 WORKER: done with job (8, 0, 19), trying to register it.
07:08:08 WORKER: registered result for job (8, 0, 19) with dispatcher
07:08:08 DISPATCHER: job (8, 0, 19) finished
07:08:08 DISPATCHER: register_result: lock acquired
07:08:08 DISPATCHER: job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
07:08:08 job_id: (8, 0, 19)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.012888148937616657, 'num_filters_1': 58, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.03076474500832118}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.48661775358952997, 'info': {'sick_no_sick': 0.48661775358952997, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.012888148937616657, 'num_filters_1': 58, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.03076474500832118}"}}
exception: None

07:08:08 job_callback for (8, 0, 19) started
07:08:08 job_callback for (8, 0, 19) got condition
07:08:08 DISPATCHER: Trying to submit another job.
07:08:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:08:08 done building a new model for budget 133.333333 based on 17/35 split
Best loss for this budget:-0.553150





07:08:08 HBMASTER: Trying to run another job!
07:08:08 job_callback for (8, 0, 19) finished
07:08:08 HBMASTER: schedule new run for iteration 8
07:08:08 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
07:08:08 HBMASTER: submitting job (8, 0, 20) to dispatcher
07:08:08 DISPATCHER: trying to submit job (8, 0, 20)
07:08:08 DISPATCHER: trying to notify the job_runner thread.
07:08:08 HBMASTER: job (8, 0, 20) submitted to dispatcher
07:08:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:08:08 DISPATCHER: Trying to submit another job.
07:08:08 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:08:08 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:08:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:08:08 WORKER: start processing job (8, 0, 20)
07:08:08 WORKER: args: ()
07:08:08 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0016367455504801176, 'num_filters_1': 85, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.052947739542300636, 'kernel_size_2': 3, 'num_filters_2': 89}, 'budget': 133.33333333333331, 'working_directory': '.'}
07:08:15 DISPATCHER: Starting worker discovery
07:08:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:08:15 DISPATCHER: Finished worker discovery
07:09:15 DISPATCHER: Starting worker discovery
07:09:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:09:15 DISPATCHER: Finished worker discovery
07:10:15 DISPATCHER: Starting worker discovery
07:10:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:10:15 DISPATCHER: Finished worker discovery
07:11:15 DISPATCHER: Starting worker discovery
07:11:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:11:15 DISPATCHER: Finished worker discovery
07:11:25 WORKER: done with job (8, 0, 20), trying to register it.
07:11:25 WORKER: registered result for job (8, 0, 20) with dispatcher
07:11:25 DISPATCHER: job (8, 0, 20) finished
07:11:25 DISPATCHER: register_result: lock acquired
07:11:25 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
07:11:25 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0016367455504801176, 'num_filters_1': 85, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.052947739542300636, 'kernel_size_2': 3, 'num_filters_2': 89}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4813404770682727, 'info': {'sick_no_sick': 0.4813404770682727, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0016367455504801176, 'num_filters_1': 85, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.052947739542300636, 'kernel_size_2': 3, 'num_filters_2': 89}"}}
exception: None

07:11:25 job_callback for (8, 0, 20) started
07:11:25 job_callback for (8, 0, 20) got condition
07:11:25 DISPATCHER: Trying to submit another job.
07:11:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:11:25 done building a new model for budget 133.333333 based on 17/36 split
Best loss for this budget:-0.553150





07:11:25 HBMASTER: Trying to run another job!
07:11:25 job_callback for (8, 0, 20) finished
07:11:25 HBMASTER: schedule new run for iteration 8
07:11:25 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
07:11:25 HBMASTER: submitting job (8, 0, 25) to dispatcher
07:11:25 DISPATCHER: trying to submit job (8, 0, 25)
07:11:25 DISPATCHER: trying to notify the job_runner thread.
07:11:25 HBMASTER: job (8, 0, 25) submitted to dispatcher
07:11:25 DISPATCHER: Trying to submit another job.
07:11:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:11:25 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:11:25 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:11:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:11:25 WORKER: start processing job (8, 0, 25)
07:11:25 WORKER: args: ()
07:11:25 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005444191901522411, 'num_filters_1': 90, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.05444714676957671, 'kernel_size_2': 5, 'num_filters_2': 90}, 'budget': 133.33333333333331, 'working_directory': '.'}
07:12:15 DISPATCHER: Starting worker discovery
07:12:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:12:15 DISPATCHER: Finished worker discovery
07:13:15 DISPATCHER: Starting worker discovery
07:13:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:13:15 DISPATCHER: Finished worker discovery
07:14:15 DISPATCHER: Starting worker discovery
07:14:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:14:15 DISPATCHER: Finished worker discovery
07:14:44 WORKER: done with job (8, 0, 25), trying to register it.
07:14:44 WORKER: registered result for job (8, 0, 25) with dispatcher
07:14:44 DISPATCHER: job (8, 0, 25) finished
07:14:44 DISPATCHER: register_result: lock acquired
07:14:44 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
07:14:44 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005444191901522411, 'num_filters_1': 90, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.05444714676957671, 'kernel_size_2': 5, 'num_filters_2': 90}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5195104500510137, 'info': {'sick_no_sick': 0.5195104500510137, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005444191901522411, 'num_filters_1': 90, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.05444714676957671, 'kernel_size_2': 5, 'num_filters_2': 90}"}}
exception: None

07:14:44 job_callback for (8, 0, 25) started
07:14:44 job_callback for (8, 0, 25) got condition
07:14:44 DISPATCHER: Trying to submit another job.
07:14:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:14:44 done building a new model for budget 133.333333 based on 17/37 split
Best loss for this budget:-0.553150





07:14:44 HBMASTER: Trying to run another job!
07:14:44 job_callback for (8, 0, 25) finished
07:14:44 HBMASTER: schedule new run for iteration 8
07:14:44 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
07:14:44 HBMASTER: submitting job (8, 0, 26) to dispatcher
07:14:44 DISPATCHER: trying to submit job (8, 0, 26)
07:14:44 DISPATCHER: trying to notify the job_runner thread.
07:14:44 HBMASTER: job (8, 0, 26) submitted to dispatcher
07:14:44 DISPATCHER: Trying to submit another job.
07:14:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:14:44 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:14:44 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:14:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:14:44 WORKER: start processing job (8, 0, 26)
07:14:44 WORKER: args: ()
07:14:44 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0066515542485636, 'num_filters_1': 106, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.03840563922616474, 'kernel_size_2': 3, 'num_filters_2': 55}, 'budget': 133.33333333333331, 'working_directory': '.'}
07:15:15 DISPATCHER: Starting worker discovery
07:15:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:15:15 DISPATCHER: Finished worker discovery
07:16:15 DISPATCHER: Starting worker discovery
07:16:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:16:15 DISPATCHER: Finished worker discovery
07:17:15 DISPATCHER: Starting worker discovery
07:17:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:17:15 DISPATCHER: Finished worker discovery
07:18:03 WORKER: done with job (8, 0, 26), trying to register it.
07:18:03 WORKER: registered result for job (8, 0, 26) with dispatcher
07:18:03 DISPATCHER: job (8, 0, 26) finished
07:18:03 DISPATCHER: register_result: lock acquired
07:18:03 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
07:18:03 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0066515542485636, 'num_filters_1': 106, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.03840563922616474, 'kernel_size_2': 3, 'num_filters_2': 55}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.37359216139651136, 'info': {'sick_no_sick': 0.37359216139651136, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0066515542485636, 'num_filters_1': 106, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.03840563922616474, 'kernel_size_2': 3, 'num_filters_2': 55}"}}
exception: None

07:18:03 job_callback for (8, 0, 26) started
07:18:03 job_callback for (8, 0, 26) got condition
07:18:03 DISPATCHER: Trying to submit another job.
07:18:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:18:03 done building a new model for budget 133.333333 based on 17/38 split
Best loss for this budget:-0.553150





07:18:03 HBMASTER: Trying to run another job!
07:18:03 job_callback for (8, 0, 26) finished
07:18:03 ITERATION: Advancing config (8, 0, 10) to next budget 400.000000
07:18:03 ITERATION: Advancing config (8, 0, 14) to next budget 400.000000
07:18:03 ITERATION: Advancing config (8, 0, 25) to next budget 400.000000
07:18:03 HBMASTER: schedule new run for iteration 8
07:18:03 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
07:18:03 HBMASTER: submitting job (8, 0, 10) to dispatcher
07:18:03 DISPATCHER: trying to submit job (8, 0, 10)
07:18:03 DISPATCHER: trying to notify the job_runner thread.
07:18:03 HBMASTER: job (8, 0, 10) submitted to dispatcher
07:18:03 DISPATCHER: Trying to submit another job.
07:18:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:18:03 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:18:03 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:18:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:18:03 WORKER: start processing job (8, 0, 10)
07:18:03 WORKER: args: ()
07:18:03 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.007770960947494053, 'num_filters_1': 40, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.021247856042542573, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 22, 'num_filters_3': 35}, 'budget': 400.0, 'working_directory': '.'}
07:18:15 DISPATCHER: Starting worker discovery
07:18:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:18:15 DISPATCHER: Finished worker discovery
07:19:15 DISPATCHER: Starting worker discovery
07:19:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:19:15 DISPATCHER: Finished worker discovery
07:20:15 DISPATCHER: Starting worker discovery
07:20:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:20:15 DISPATCHER: Finished worker discovery
07:21:15 DISPATCHER: Starting worker discovery
07:21:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:21:15 DISPATCHER: Finished worker discovery
07:22:15 DISPATCHER: Starting worker discovery
07:22:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:22:15 DISPATCHER: Finished worker discovery
07:23:15 DISPATCHER: Starting worker discovery
07:23:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:23:15 DISPATCHER: Finished worker discovery
07:24:15 DISPATCHER: Starting worker discovery
07:24:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:24:15 DISPATCHER: Finished worker discovery
07:25:15 DISPATCHER: Starting worker discovery
07:25:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:25:15 DISPATCHER: Finished worker discovery
07:25:48 WORKER: done with job (8, 0, 10), trying to register it.
07:25:48 WORKER: registered result for job (8, 0, 10) with dispatcher
07:25:48 DISPATCHER: job (8, 0, 10) finished
07:25:48 DISPATCHER: register_result: lock acquired
07:25:48 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
07:25:48 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.007770960947494053, 'num_filters_1': 40, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.021247856042542573, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 22, 'num_filters_3': 35}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.4327922437427906, 'info': {'sick_no_sick': 0.4327922437427906, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.007770960947494053, 'num_filters_1': 40, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.021247856042542573, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 22, 'num_filters_3': 35}"}}
exception: None

07:25:48 job_callback for (8, 0, 10) started
07:25:48 job_callback for (8, 0, 10) got condition
07:25:48 DISPATCHER: Trying to submit another job.
07:25:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:25:48 HBMASTER: Trying to run another job!
07:25:48 job_callback for (8, 0, 10) finished
07:25:48 HBMASTER: schedule new run for iteration 8
07:25:48 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
07:25:48 HBMASTER: submitting job (8, 0, 14) to dispatcher
07:25:48 DISPATCHER: trying to submit job (8, 0, 14)
07:25:48 DISPATCHER: trying to notify the job_runner thread.
07:25:48 HBMASTER: job (8, 0, 14) submitted to dispatcher
07:25:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:25:48 DISPATCHER: Trying to submit another job.
07:25:48 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:25:48 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:25:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:25:48 WORKER: start processing job (8, 0, 14)
07:25:48 WORKER: args: ()
07:25:48 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003443170518552531, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.023545974490257474, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 32, 'num_filters_3': 77}, 'budget': 400.0, 'working_directory': '.'}
07:26:15 DISPATCHER: Starting worker discovery
07:26:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:26:15 DISPATCHER: Finished worker discovery
07:27:15 DISPATCHER: Starting worker discovery
07:27:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:27:15 DISPATCHER: Finished worker discovery
07:28:15 DISPATCHER: Starting worker discovery
07:28:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:28:15 DISPATCHER: Finished worker discovery
07:29:15 DISPATCHER: Starting worker discovery
07:29:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:29:15 DISPATCHER: Finished worker discovery
07:30:15 DISPATCHER: Starting worker discovery
07:30:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:30:15 DISPATCHER: Finished worker discovery
07:31:15 DISPATCHER: Starting worker discovery
07:31:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:31:15 DISPATCHER: Finished worker discovery
07:32:15 DISPATCHER: Starting worker discovery
07:32:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:32:15 DISPATCHER: Finished worker discovery
07:33:15 DISPATCHER: Starting worker discovery
07:33:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:33:15 DISPATCHER: Finished worker discovery
07:33:35 WORKER: done with job (8, 0, 14), trying to register it.
07:33:35 WORKER: registered result for job (8, 0, 14) with dispatcher
07:33:35 DISPATCHER: job (8, 0, 14) finished
07:33:35 DISPATCHER: register_result: lock acquired
07:33:35 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
07:33:35 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003443170518552531, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.023545974490257474, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 32, 'num_filters_3': 77}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.45231504823042723, 'info': {'sick_no_sick': 0.45231504823042723, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003443170518552531, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.023545974490257474, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 32, 'num_filters_3': 77}"}}
exception: None

07:33:35 job_callback for (8, 0, 14) started
07:33:35 job_callback for (8, 0, 14) got condition
07:33:35 DISPATCHER: Trying to submit another job.
07:33:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:33:35 HBMASTER: Trying to run another job!
07:33:35 job_callback for (8, 0, 14) finished
07:33:35 HBMASTER: schedule new run for iteration 8
07:33:35 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
07:33:35 HBMASTER: submitting job (8, 0, 25) to dispatcher
07:33:35 DISPATCHER: trying to submit job (8, 0, 25)
07:33:35 DISPATCHER: trying to notify the job_runner thread.
07:33:35 HBMASTER: job (8, 0, 25) submitted to dispatcher
07:33:35 DISPATCHER: Trying to submit another job.
07:33:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:33:35 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:33:35 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:33:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:33:35 WORKER: start processing job (8, 0, 25)
07:33:35 WORKER: args: ()
07:33:35 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005444191901522411, 'num_filters_1': 90, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.05444714676957671, 'kernel_size_2': 5, 'num_filters_2': 90}, 'budget': 400.0, 'working_directory': '.'}
07:34:15 DISPATCHER: Starting worker discovery
07:34:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:34:15 DISPATCHER: Finished worker discovery
07:35:15 DISPATCHER: Starting worker discovery
07:35:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:35:15 DISPATCHER: Finished worker discovery
07:36:15 DISPATCHER: Starting worker discovery
07:36:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:36:15 DISPATCHER: Finished worker discovery
07:37:15 DISPATCHER: Starting worker discovery
07:37:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:37:15 DISPATCHER: Finished worker discovery
07:38:15 DISPATCHER: Starting worker discovery
07:38:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:38:15 DISPATCHER: Finished worker discovery
07:39:15 DISPATCHER: Starting worker discovery
07:39:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:39:15 DISPATCHER: Finished worker discovery
07:40:15 DISPATCHER: Starting worker discovery
07:40:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:40:15 DISPATCHER: Finished worker discovery
07:41:15 DISPATCHER: Starting worker discovery
07:41:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:41:15 DISPATCHER: Finished worker discovery
07:41:21 WORKER: done with job (8, 0, 25), trying to register it.
07:41:21 WORKER: registered result for job (8, 0, 25) with dispatcher
07:41:21 DISPATCHER: job (8, 0, 25) finished
07:41:21 DISPATCHER: register_result: lock acquired
07:41:21 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
07:41:21 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005444191901522411, 'num_filters_1': 90, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.05444714676957671, 'kernel_size_2': 5, 'num_filters_2': 90}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5116096152243127, 'info': {'sick_no_sick': 0.5116096152243127, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005444191901522411, 'num_filters_1': 90, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.05444714676957671, 'kernel_size_2': 5, 'num_filters_2': 90}"}}
exception: None

07:41:21 job_callback for (8, 0, 25) started
07:41:21 DISPATCHER: Trying to submit another job.
07:41:21 job_callback for (8, 0, 25) got condition
07:41:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:41:21 HBMASTER: Trying to run another job!
07:41:21 job_callback for (8, 0, 25) finished
07:41:21 ITERATION: Advancing config (8, 0, 25) to next budget 1200.000000
07:41:21 HBMASTER: schedule new run for iteration 8
07:41:21 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
07:41:21 HBMASTER: submitting job (8, 0, 25) to dispatcher
07:41:21 DISPATCHER: trying to submit job (8, 0, 25)
07:41:21 DISPATCHER: trying to notify the job_runner thread.
07:41:21 HBMASTER: job (8, 0, 25) submitted to dispatcher
07:41:21 DISPATCHER: Trying to submit another job.
07:41:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:41:21 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:41:21 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
07:41:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:41:21 WORKER: start processing job (8, 0, 25)
07:41:21 WORKER: args: ()
07:41:21 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005444191901522411, 'num_filters_1': 90, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.05444714676957671, 'kernel_size_2': 5, 'num_filters_2': 90}, 'budget': 1200.0, 'working_directory': '.'}
07:42:15 DISPATCHER: Starting worker discovery
07:42:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:42:15 DISPATCHER: Finished worker discovery
07:43:15 DISPATCHER: Starting worker discovery
07:43:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:43:15 DISPATCHER: Finished worker discovery
07:44:15 DISPATCHER: Starting worker discovery
07:44:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:44:15 DISPATCHER: Finished worker discovery
07:45:15 DISPATCHER: Starting worker discovery
07:45:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:45:15 DISPATCHER: Finished worker discovery
07:46:15 DISPATCHER: Starting worker discovery
07:46:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:46:15 DISPATCHER: Finished worker discovery
07:47:15 DISPATCHER: Starting worker discovery
07:47:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:47:15 DISPATCHER: Finished worker discovery
07:48:15 DISPATCHER: Starting worker discovery
07:48:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:48:15 DISPATCHER: Finished worker discovery
07:49:15 DISPATCHER: Starting worker discovery
07:49:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:49:15 DISPATCHER: Finished worker discovery
07:50:15 DISPATCHER: Starting worker discovery
07:50:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:50:15 DISPATCHER: Finished worker discovery
07:51:15 DISPATCHER: Starting worker discovery
07:51:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:51:15 DISPATCHER: Finished worker discovery
07:52:15 DISPATCHER: Starting worker discovery
07:52:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:52:15 DISPATCHER: Finished worker discovery
07:53:15 DISPATCHER: Starting worker discovery
07:53:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:53:15 DISPATCHER: Finished worker discovery
07:54:15 DISPATCHER: Starting worker discovery
07:54:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:54:15 DISPATCHER: Finished worker discovery
07:55:15 DISPATCHER: Starting worker discovery
07:55:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:55:15 DISPATCHER: Finished worker discovery
07:56:15 DISPATCHER: Starting worker discovery
07:56:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:56:15 DISPATCHER: Finished worker discovery
07:57:15 DISPATCHER: Starting worker discovery
07:57:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:57:15 DISPATCHER: Finished worker discovery
07:58:15 DISPATCHER: Starting worker discovery
07:58:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:58:15 DISPATCHER: Finished worker discovery
07:59:15 DISPATCHER: Starting worker discovery
07:59:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:59:15 DISPATCHER: Finished worker discovery
08:00:15 DISPATCHER: Starting worker discovery
08:00:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:00:15 DISPATCHER: Finished worker discovery
08:01:15 DISPATCHER: Starting worker discovery
08:01:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:01:15 DISPATCHER: Finished worker discovery
08:02:15 DISPATCHER: Starting worker discovery
08:02:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:02:15 DISPATCHER: Finished worker discovery
08:02:38 WORKER: done with job (8, 0, 25), trying to register it.
08:02:38 WORKER: registered result for job (8, 0, 25) with dispatcher
08:02:38 DISPATCHER: job (8, 0, 25) finished
08:02:38 DISPATCHER: register_result: lock acquired
08:02:38 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:02:38 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005444191901522411, 'num_filters_1': 90, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.05444714676957671, 'kernel_size_2': 5, 'num_filters_2': 90}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5242668607740666, 'info': {'sick_no_sick': 0.5242668607740666, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005444191901522411, 'num_filters_1': 90, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.05444714676957671, 'kernel_size_2': 5, 'num_filters_2': 90}"}}
exception: None

08:02:38 job_callback for (8, 0, 25) started
08:02:38 job_callback for (8, 0, 25) got condition
08:02:38 DISPATCHER: Trying to submit another job.
08:02:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:02:38 HBMASTER: Trying to run another job!
08:02:38 job_callback for (8, 0, 25) finished
08:02:38 start sampling a new configuration.
08:02:38 best_vector: [0, 2, 0.35983904617419493, 0.2239044962788746, 0.2330680552631738, 0, 0.9127957394480564, 0.49538032217250677, 2, 0, 1, 1, 0.860673124952333, 0.8425081483825194, 0.6108763817782166, 0.17718108943267868], 0.0010515090187604714, 0.021971227465514782, 2.3102943833226567e-05
08:02:38 done sampling a new configuration.
08:02:38 HBMASTER: schedule new run for iteration 9
08:02:38 HBMASTER: trying submitting job (9, 0, 0) to dispatcher
08:02:38 HBMASTER: submitting job (9, 0, 0) to dispatcher
08:02:38 DISPATCHER: trying to submit job (9, 0, 0)
08:02:38 DISPATCHER: trying to notify the job_runner thread.
08:02:38 HBMASTER: job (9, 0, 0) submitted to dispatcher
08:02:38 DISPATCHER: Trying to submit another job.
08:02:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:02:38 DISPATCHER: starting job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:02:38 DISPATCHER: job (9, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:02:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:02:38 WORKER: start processing job (9, 0, 0)
08:02:38 WORKER: args: ()
08:02:38 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.005244186067208461, 'num_filters_1': 25, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.04410670941498016, 'kernel_size_2': 7, 'num_filters_2': 96}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:03:15 DISPATCHER: Starting worker discovery
08:03:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:03:15 DISPATCHER: Finished worker discovery
08:04:15 DISPATCHER: Starting worker discovery
08:04:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:04:15 DISPATCHER: Finished worker discovery
08:05:15 DISPATCHER: Starting worker discovery
08:05:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:05:15 DISPATCHER: Finished worker discovery
08:05:56 WORKER: done with job (9, 0, 0), trying to register it.
08:05:56 WORKER: registered result for job (9, 0, 0) with dispatcher
08:05:56 DISPATCHER: job (9, 0, 0) finished
08:05:56 DISPATCHER: register_result: lock acquired
08:05:56 DISPATCHER: job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:05:56 job_id: (9, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.005244186067208461, 'num_filters_1': 25, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.04410670941498016, 'kernel_size_2': 7, 'num_filters_2': 96}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0029553152455725614, 'info': {'sick_no_sick': 0.0029553152455725614, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.005244186067208461, 'num_filters_1': 25, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.04410670941498016, 'kernel_size_2': 7, 'num_filters_2': 96}"}}
exception: None

08:05:56 job_callback for (9, 0, 0) started
08:05:56 job_callback for (9, 0, 0) got condition
08:05:56 DISPATCHER: Trying to submit another job.
08:05:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:05:56 done building a new model for budget 133.333333 based on 17/39 split
Best loss for this budget:-0.553150





08:05:56 HBMASTER: Trying to run another job!
08:05:56 job_callback for (9, 0, 0) finished
08:05:56 start sampling a new configuration.
08:05:56 done sampling a new configuration.
08:05:56 HBMASTER: schedule new run for iteration 9
08:05:56 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
08:05:56 HBMASTER: submitting job (9, 0, 1) to dispatcher
08:05:56 DISPATCHER: trying to submit job (9, 0, 1)
08:05:56 DISPATCHER: trying to notify the job_runner thread.
08:05:56 HBMASTER: job (9, 0, 1) submitted to dispatcher
08:05:56 DISPATCHER: Trying to submit another job.
08:05:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:05:56 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:05:56 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:05:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:05:56 WORKER: start processing job (9, 0, 1)
08:05:56 WORKER: args: ()
08:05:56 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002353719330903579, 'num_filters_1': 91, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.02476914050043296}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:06:15 DISPATCHER: Starting worker discovery
08:06:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:06:15 DISPATCHER: Finished worker discovery
08:07:15 DISPATCHER: Starting worker discovery
08:07:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:07:15 DISPATCHER: Finished worker discovery
08:08:15 DISPATCHER: Starting worker discovery
08:08:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:08:15 DISPATCHER: Finished worker discovery
08:09:14 WORKER: done with job (9, 0, 1), trying to register it.
08:09:14 WORKER: registered result for job (9, 0, 1) with dispatcher
08:09:14 DISPATCHER: job (9, 0, 1) finished
08:09:14 DISPATCHER: register_result: lock acquired
08:09:14 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:09:14 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002353719330903579, 'num_filters_1': 91, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.02476914050043296}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5147400310037886, 'info': {'sick_no_sick': 0.5147400310037886, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002353719330903579, 'num_filters_1': 91, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.02476914050043296}"}}
exception: None

08:09:14 job_callback for (9, 0, 1) started
08:09:14 job_callback for (9, 0, 1) got condition
08:09:14 DISPATCHER: Trying to submit another job.
08:09:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:09:14 done building a new model for budget 133.333333 based on 17/39 split
Best loss for this budget:-0.553150





08:09:14 HBMASTER: Trying to run another job!
08:09:14 job_callback for (9, 0, 1) finished
08:09:14 start sampling a new configuration.
08:09:14 best_vector: [1, 0, 0.2602882662499033, 0.6572883959807747, 0.16283138511117795, 0, 0.10507848179725875, 0.28629313842051113, 1, 0, 1, 0, 0.23962762648080974, 0.0727978017296822, 0.5457092664464837, 0.32184427322896575], 0.0031896507117272458, 0.004061697553687554, 1.295539649294032e-05
08:09:14 done sampling a new configuration.
08:09:14 HBMASTER: schedule new run for iteration 9
08:09:14 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
08:09:14 HBMASTER: submitting job (9, 0, 2) to dispatcher
08:09:14 DISPATCHER: trying to submit job (9, 0, 2)
08:09:14 DISPATCHER: trying to notify the job_runner thread.
08:09:14 HBMASTER: job (9, 0, 2) submitted to dispatcher
08:09:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:09:14 DISPATCHER: Trying to submit another job.
08:09:14 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:09:14 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:09:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:09:14 WORKER: start processing job (9, 0, 2)
08:09:14 WORKER: args: ()
08:09:14 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.003315709949643333, 'num_filters_1': 62, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.023576316911241513}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:09:15 DISPATCHER: Starting worker discovery
08:09:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:09:15 DISPATCHER: Finished worker discovery
08:10:15 DISPATCHER: Starting worker discovery
08:10:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:10:15 DISPATCHER: Finished worker discovery
08:11:15 DISPATCHER: Starting worker discovery
08:11:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:11:15 DISPATCHER: Finished worker discovery
08:12:15 DISPATCHER: Starting worker discovery
08:12:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:12:15 DISPATCHER: Finished worker discovery
08:12:40 WORKER: done with job (9, 0, 2), trying to register it.
08:12:40 WORKER: registered result for job (9, 0, 2) with dispatcher
08:12:40 DISPATCHER: job (9, 0, 2) finished
08:12:40 DISPATCHER: register_result: lock acquired
08:12:40 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:12:40 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.003315709949643333, 'num_filters_1': 62, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.023576316911241513}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5139201644738458, 'info': {'sick_no_sick': 0.5139201644738458, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.003315709949643333, 'num_filters_1': 62, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.023576316911241513}"}}
exception: None

08:12:40 job_callback for (9, 0, 2) started
08:12:40 job_callback for (9, 0, 2) got condition
08:12:40 DISPATCHER: Trying to submit another job.
08:12:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:12:40 done building a new model for budget 133.333333 based on 17/40 split
Best loss for this budget:-0.553150





08:12:40 HBMASTER: Trying to run another job!
08:12:40 job_callback for (9, 0, 2) finished
08:12:40 start sampling a new configuration.
08:12:40 best_vector: [3, 0, 0.17170991247742176, 0.5011406178414127, 0.3371834584819422, 0, 0.19954452418643798, 0.29770552134167116, 0, 0, 0, 0, 0.43166325850619586, 0.8234403445379267, 0.5251691979494872, 0.5394335643813908], 0.0025430083645782086, 0.015580023580337603, 3.962013028512425e-05
08:12:40 done sampling a new configuration.
08:12:40 HBMASTER: schedule new run for iteration 9
08:12:40 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
08:12:40 HBMASTER: submitting job (9, 0, 3) to dispatcher
08:12:40 DISPATCHER: trying to submit job (9, 0, 3)
08:12:40 DISPATCHER: trying to notify the job_runner thread.
08:12:40 HBMASTER: job (9, 0, 3) submitted to dispatcher
08:12:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:12:40 DISPATCHER: Trying to submit another job.
08:12:40 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:12:40 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:12:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:12:40 WORKER: start processing job (9, 0, 3)
08:12:40 WORKER: args: ()
08:12:40 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.002205057023538579, 'num_filters_1': 45, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.024396291457296004, 'kernel_size_2': 3, 'num_filters_2': 39}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:13:15 DISPATCHER: Starting worker discovery
08:13:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:13:15 DISPATCHER: Finished worker discovery
08:14:15 DISPATCHER: Starting worker discovery
08:14:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:14:15 DISPATCHER: Finished worker discovery
08:15:15 DISPATCHER: Starting worker discovery
08:15:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:15:15 DISPATCHER: Finished worker discovery
08:15:57 WORKER: done with job (9, 0, 3), trying to register it.
08:15:57 WORKER: registered result for job (9, 0, 3) with dispatcher
08:15:57 DISPATCHER: job (9, 0, 3) finished
08:15:57 DISPATCHER: register_result: lock acquired
08:15:57 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:15:57 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.002205057023538579, 'num_filters_1': 45, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.024396291457296004, 'kernel_size_2': 3, 'num_filters_2': 39}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4956036262232616, 'info': {'sick_no_sick': 0.4956036262232616, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.002205057023538579, 'num_filters_1': 45, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.024396291457296004, 'kernel_size_2': 3, 'num_filters_2': 39}"}}
exception: None

08:15:57 job_callback for (9, 0, 3) started
08:15:57 job_callback for (9, 0, 3) got condition
08:15:57 DISPATCHER: Trying to submit another job.
08:15:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:15:57 done building a new model for budget 133.333333 based on 17/41 split
Best loss for this budget:-0.553150





08:15:57 HBMASTER: Trying to run another job!
08:15:57 job_callback for (9, 0, 3) finished
08:15:57 start sampling a new configuration.
08:15:57 done sampling a new configuration.
08:15:57 HBMASTER: schedule new run for iteration 9
08:15:57 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
08:15:57 HBMASTER: submitting job (9, 0, 4) to dispatcher
08:15:57 DISPATCHER: trying to submit job (9, 0, 4)
08:15:57 DISPATCHER: trying to notify the job_runner thread.
08:15:57 HBMASTER: job (9, 0, 4) submitted to dispatcher
08:15:57 DISPATCHER: Trying to submit another job.
08:15:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:15:57 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:15:57 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:15:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:15:57 WORKER: start processing job (9, 0, 4)
08:15:57 WORKER: args: ()
08:15:57 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004339310681776714, 'num_filters_1': 87, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.10714863077667765}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:16:15 DISPATCHER: Starting worker discovery
08:16:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:16:15 DISPATCHER: Finished worker discovery
08:17:15 DISPATCHER: Starting worker discovery
08:17:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:17:15 DISPATCHER: Finished worker discovery
08:18:15 DISPATCHER: Starting worker discovery
08:18:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:18:15 DISPATCHER: Finished worker discovery
08:19:14 WORKER: done with job (9, 0, 4), trying to register it.
08:19:14 WORKER: registered result for job (9, 0, 4) with dispatcher
08:19:14 DISPATCHER: job (9, 0, 4) finished
08:19:14 DISPATCHER: register_result: lock acquired
08:19:14 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:19:14 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004339310681776714, 'num_filters_1': 87, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.10714863077667765}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4457533220553339, 'info': {'sick_no_sick': 0.4457533220553339, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004339310681776714, 'num_filters_1': 87, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.10714863077667765}"}}
exception: None

08:19:14 job_callback for (9, 0, 4) started
08:19:14 job_callback for (9, 0, 4) got condition
08:19:14 DISPATCHER: Trying to submit another job.
08:19:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:19:14 done building a new model for budget 133.333333 based on 17/42 split
Best loss for this budget:-0.553150





08:19:14 HBMASTER: Trying to run another job!
08:19:14 job_callback for (9, 0, 4) finished
08:19:14 start sampling a new configuration.
08:19:14 best_vector: [3, 2, 0.483520656023366, 0.045433067826355866, 0.5322623992000755, 0, 0.05830650070231902, 0.05606368810658767, 2, 0, 0, 2, 0.7991534857798355, 0.9714779147339252, 0.5694591189236144, 0.5265903448169524], 0.008611475192382995, 0.00027631102686262096, 2.379445553209332e-06
08:19:14 done sampling a new configuration.
08:19:14 HBMASTER: schedule new run for iteration 9
08:19:14 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
08:19:14 HBMASTER: submitting job (9, 0, 5) to dispatcher
08:19:14 DISPATCHER: trying to submit job (9, 0, 5)
08:19:14 DISPATCHER: trying to notify the job_runner thread.
08:19:14 HBMASTER: job (9, 0, 5) submitted to dispatcher
08:19:14 DISPATCHER: Trying to submit another job.
08:19:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:19:14 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:19:14 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:19:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:19:14 WORKER: start processing job (9, 0, 5)
08:19:14 WORKER: args: ()
08:19:14 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.009269179917990549, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.011828795942825413, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 84, 'num_filters_3': 121}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:19:15 DISPATCHER: Starting worker discovery
08:19:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:19:15 DISPATCHER: Finished worker discovery
08:20:15 DISPATCHER: Starting worker discovery
08:20:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:20:15 DISPATCHER: Finished worker discovery
08:21:15 DISPATCHER: Starting worker discovery
08:21:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:21:15 DISPATCHER: Finished worker discovery
08:22:15 DISPATCHER: Starting worker discovery
08:22:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:22:15 DISPATCHER: Finished worker discovery
08:22:31 WORKER: done with job (9, 0, 5), trying to register it.
08:22:31 WORKER: registered result for job (9, 0, 5) with dispatcher
08:22:31 DISPATCHER: job (9, 0, 5) finished
08:22:31 DISPATCHER: register_result: lock acquired
08:22:31 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:22:31 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.009269179917990549, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.011828795942825413, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 84, 'num_filters_3': 121}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.08127388096381569, 'info': {'sick_no_sick': 0.08127388096381569, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.009269179917990549, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.011828795942825413, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 84, 'num_filters_3': 121}"}}
exception: None

08:22:31 job_callback for (9, 0, 5) started
08:22:31 job_callback for (9, 0, 5) got condition
08:22:31 DISPATCHER: Trying to submit another job.
08:22:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:22:31 done building a new model for budget 133.333333 based on 17/43 split
Best loss for this budget:-0.553150





08:22:31 HBMASTER: Trying to run another job!
08:22:31 job_callback for (9, 0, 5) finished
08:22:31 start sampling a new configuration.
08:22:31 done sampling a new configuration.
08:22:31 HBMASTER: schedule new run for iteration 9
08:22:31 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
08:22:31 HBMASTER: submitting job (9, 0, 6) to dispatcher
08:22:31 DISPATCHER: trying to submit job (9, 0, 6)
08:22:31 DISPATCHER: trying to notify the job_runner thread.
08:22:31 HBMASTER: job (9, 0, 6) submitted to dispatcher
08:22:31 DISPATCHER: Trying to submit another job.
08:22:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:22:31 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:22:31 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:22:31 WORKER: start processing job (9, 0, 6)
08:22:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:22:31 WORKER: args: ()
08:22:31 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.03753344604380489, 'num_filters_1': 22, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.017605219836413315, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 22, 'num_filters_3': 35, 'num_filters_4': 36, 'num_filters_5': 62}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:23:15 DISPATCHER: Starting worker discovery
08:23:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:23:15 DISPATCHER: Finished worker discovery
Exception in thread Thread-778:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    preds = np.concatenate(preds)
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

08:24:15 DISPATCHER: Starting worker discovery
08:24:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:24:15 DISPATCHER: Finished worker discovery
08:25:15 DISPATCHER: Starting worker discovery
08:25:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:25:15 DISPATCHER: Finished worker discovery
08:25:47 WORKER: done with job (9, 0, 6), trying to register it.
08:25:47 WORKER: registered result for job (9, 0, 6) with dispatcher
08:25:47 DISPATCHER: job (9, 0, 6) finished
08:25:47 DISPATCHER: register_result: lock acquired
08:25:47 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:25:47 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.03753344604380489, 'num_filters_1': 22, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.017605219836413315, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 22, 'num_filters_3': 35, 'num_filters_4': 36, 'num_filters_5': 62}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.21492750599773772, 'info': {'sick_no_sick': 0.21492750599773772, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.03753344604380489, 'num_filters_1': 22, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.017605219836413315, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 22, 'num_filters_3': 35, 'num_filters_4': 36, 'num_filters_5': 62}"}}
exception: None

08:25:47 job_callback for (9, 0, 6) started
08:25:47 DISPATCHER: Trying to submit another job.
08:25:47 job_callback for (9, 0, 6) got condition
08:25:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:25:47 done building a new model for budget 133.333333 based on 17/44 split
Best loss for this budget:-0.553150





08:25:47 HBMASTER: Trying to run another job!
08:25:47 job_callback for (9, 0, 6) finished
08:25:47 start sampling a new configuration.
08:25:47 done sampling a new configuration.
08:25:47 HBMASTER: schedule new run for iteration 9
08:25:47 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
08:25:47 HBMASTER: submitting job (9, 0, 7) to dispatcher
08:25:47 DISPATCHER: trying to submit job (9, 0, 7)
08:25:47 DISPATCHER: trying to notify the job_runner thread.
08:25:47 HBMASTER: job (9, 0, 7) submitted to dispatcher
08:25:47 DISPATCHER: Trying to submit another job.
08:25:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:25:47 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:25:47 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:25:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:25:47 WORKER: start processing job (9, 0, 7)
08:25:47 WORKER: args: ()
08:25:47 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.011278556589568155, 'num_filters_1': 102, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.08660399423610281}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:26:15 DISPATCHER: Starting worker discovery
08:26:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:26:15 DISPATCHER: Finished worker discovery
08:27:15 DISPATCHER: Starting worker discovery
08:27:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:27:15 DISPATCHER: Finished worker discovery
08:28:15 DISPATCHER: Starting worker discovery
08:28:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:28:15 DISPATCHER: Finished worker discovery
08:29:07 WORKER: done with job (9, 0, 7), trying to register it.
08:29:07 WORKER: registered result for job (9, 0, 7) with dispatcher
08:29:07 DISPATCHER: job (9, 0, 7) finished
08:29:07 DISPATCHER: register_result: lock acquired
08:29:07 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:29:07 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.011278556589568155, 'num_filters_1': 102, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.08660399423610281}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3331911215932226, 'info': {'sick_no_sick': 0.3331911215932226, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.011278556589568155, 'num_filters_1': 102, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.08660399423610281}"}}
exception: None

08:29:07 job_callback for (9, 0, 7) started
08:29:07 job_callback for (9, 0, 7) got condition
08:29:07 DISPATCHER: Trying to submit another job.
08:29:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:29:07 done building a new model for budget 133.333333 based on 17/45 split
Best loss for this budget:-0.553150





08:29:07 HBMASTER: Trying to run another job!
08:29:07 job_callback for (9, 0, 7) finished
08:29:07 start sampling a new configuration.
08:29:07 best_vector: [2, 1, 0.1392654584377958, 0.7143186289300298, 0.7684790009279853, 0, 0.48492363262032795, 0.32493045610030497, 0, 1, 0, 0, 0.4759068543418984, 0.9577146492718567, 0.5503091500988107, 0.1736086078565492], 0.001998519759759647, 0.002220282460881042, 4.437278370318538e-06
08:29:07 done sampling a new configuration.
08:29:07 HBMASTER: schedule new run for iteration 9
08:29:07 HBMASTER: trying submitting job (9, 0, 8) to dispatcher
08:29:07 HBMASTER: submitting job (9, 0, 8) to dispatcher
08:29:07 DISPATCHER: trying to submit job (9, 0, 8)
08:29:07 DISPATCHER: trying to notify the job_runner thread.
08:29:07 HBMASTER: job (9, 0, 8) submitted to dispatcher
08:29:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:29:07 DISPATCHER: Trying to submit another job.
08:29:07 DISPATCHER: starting job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:29:07 DISPATCHER: job (9, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:29:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:29:07 WORKER: start processing job (9, 0, 8)
08:29:07 WORKER: args: ()
08:29:07 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001899026026553594, 'num_filters_1': 70, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.02646941053965723, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 42, 'num_filters_3': 118, 'num_filters_4': 50}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:29:15 DISPATCHER: Starting worker discovery
08:29:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:29:15 DISPATCHER: Finished worker discovery
08:30:15 DISPATCHER: Starting worker discovery
08:30:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:30:15 DISPATCHER: Finished worker discovery
08:31:15 DISPATCHER: Starting worker discovery
08:31:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:31:15 DISPATCHER: Finished worker discovery
08:32:15 DISPATCHER: Starting worker discovery
08:32:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:32:15 DISPATCHER: Finished worker discovery
08:32:25 WORKER: done with job (9, 0, 8), trying to register it.
08:32:25 WORKER: registered result for job (9, 0, 8) with dispatcher
08:32:25 DISPATCHER: job (9, 0, 8) finished
08:32:25 DISPATCHER: register_result: lock acquired
08:32:25 DISPATCHER: job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:32:25 job_id: (9, 0, 8)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001899026026553594, 'num_filters_1': 70, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.02646941053965723, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 42, 'num_filters_3': 118, 'num_filters_4': 50}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5147675431294343, 'info': {'sick_no_sick': 0.5147675431294343, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001899026026553594, 'num_filters_1': 70, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.02646941053965723, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 42, 'num_filters_3': 118, 'num_filters_4': 50}"}}
exception: None

08:32:25 job_callback for (9, 0, 8) started
08:32:25 job_callback for (9, 0, 8) got condition
08:32:25 DISPATCHER: Trying to submit another job.
08:32:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:32:25 done building a new model for budget 133.333333 based on 17/45 split
Best loss for this budget:-0.553150





08:32:25 HBMASTER: Trying to run another job!
08:32:25 job_callback for (9, 0, 8) finished
08:32:25 ITERATION: Advancing config (9, 0, 1) to next budget 400.000000
08:32:25 ITERATION: Advancing config (9, 0, 2) to next budget 400.000000
08:32:25 ITERATION: Advancing config (9, 0, 8) to next budget 400.000000
08:32:25 HBMASTER: schedule new run for iteration 9
08:32:25 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
08:32:25 HBMASTER: submitting job (9, 0, 1) to dispatcher
08:32:25 DISPATCHER: trying to submit job (9, 0, 1)
08:32:25 DISPATCHER: trying to notify the job_runner thread.
08:32:25 HBMASTER: job (9, 0, 1) submitted to dispatcher
08:32:25 DISPATCHER: Trying to submit another job.
08:32:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:32:25 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:32:25 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:32:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:32:25 WORKER: start processing job (9, 0, 1)
08:32:25 WORKER: args: ()
08:32:25 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002353719330903579, 'num_filters_1': 91, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.02476914050043296}, 'budget': 400.0, 'working_directory': '.'}
08:33:15 DISPATCHER: Starting worker discovery
08:33:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:33:15 DISPATCHER: Finished worker discovery
08:34:15 DISPATCHER: Starting worker discovery
08:34:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:34:15 DISPATCHER: Finished worker discovery
08:35:15 DISPATCHER: Starting worker discovery
08:35:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:35:15 DISPATCHER: Finished worker discovery
08:36:15 DISPATCHER: Starting worker discovery
08:36:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:36:15 DISPATCHER: Finished worker discovery
08:37:15 DISPATCHER: Starting worker discovery
08:37:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:37:15 DISPATCHER: Finished worker discovery
08:38:15 DISPATCHER: Starting worker discovery
08:38:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:38:15 DISPATCHER: Finished worker discovery
08:39:15 DISPATCHER: Starting worker discovery
08:39:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:39:15 DISPATCHER: Finished worker discovery
08:40:15 DISPATCHER: Starting worker discovery
08:40:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:40:15 DISPATCHER: Finished worker discovery
08:40:22 WORKER: done with job (9, 0, 1), trying to register it.
08:40:22 WORKER: registered result for job (9, 0, 1) with dispatcher
08:40:22 DISPATCHER: job (9, 0, 1) finished
08:40:22 DISPATCHER: register_result: lock acquired
08:40:22 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:40:22 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002353719330903579, 'num_filters_1': 91, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.02476914050043296}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.517224898150745, 'info': {'sick_no_sick': 0.517224898150745, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002353719330903579, 'num_filters_1': 91, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.02476914050043296}"}}
exception: None

08:40:22 job_callback for (9, 0, 1) started
08:40:22 DISPATCHER: Trying to submit another job.
08:40:22 job_callback for (9, 0, 1) got condition
08:40:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:40:22 HBMASTER: Trying to run another job!
08:40:22 job_callback for (9, 0, 1) finished
08:40:22 HBMASTER: schedule new run for iteration 9
08:40:22 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
08:40:22 HBMASTER: submitting job (9, 0, 2) to dispatcher
08:40:22 DISPATCHER: trying to submit job (9, 0, 2)
08:40:22 DISPATCHER: trying to notify the job_runner thread.
08:40:22 HBMASTER: job (9, 0, 2) submitted to dispatcher
08:40:22 DISPATCHER: Trying to submit another job.
08:40:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:40:22 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:40:22 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:40:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:40:22 WORKER: start processing job (9, 0, 2)
08:40:22 WORKER: args: ()
08:40:22 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.003315709949643333, 'num_filters_1': 62, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.023576316911241513}, 'budget': 400.0, 'working_directory': '.'}
08:41:15 DISPATCHER: Starting worker discovery
08:41:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:41:15 DISPATCHER: Finished worker discovery
08:42:15 DISPATCHER: Starting worker discovery
08:42:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:42:16 DISPATCHER: Finished worker discovery
08:43:16 DISPATCHER: Starting worker discovery
08:43:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:43:16 DISPATCHER: Finished worker discovery
08:44:16 DISPATCHER: Starting worker discovery
08:44:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:44:16 DISPATCHER: Finished worker discovery
08:45:16 DISPATCHER: Starting worker discovery
08:45:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:45:16 DISPATCHER: Finished worker discovery
08:46:16 DISPATCHER: Starting worker discovery
08:46:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:46:16 DISPATCHER: Finished worker discovery
08:47:16 DISPATCHER: Starting worker discovery
08:47:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:47:16 DISPATCHER: Finished worker discovery
08:48:16 DISPATCHER: Starting worker discovery
08:48:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:48:16 DISPATCHER: Finished worker discovery
08:48:30 WORKER: done with job (9, 0, 2), trying to register it.
08:48:30 WORKER: registered result for job (9, 0, 2) with dispatcher
08:48:30 DISPATCHER: job (9, 0, 2) finished
08:48:30 DISPATCHER: register_result: lock acquired
08:48:30 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:48:30 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.003315709949643333, 'num_filters_1': 62, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.023576316911241513}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5222020521718609, 'info': {'sick_no_sick': 0.5222020521718609, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.003315709949643333, 'num_filters_1': 62, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.023576316911241513}"}}
exception: None

08:48:30 job_callback for (9, 0, 2) started
08:48:30 job_callback for (9, 0, 2) got condition
08:48:30 DISPATCHER: Trying to submit another job.
08:48:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:48:30 HBMASTER: Trying to run another job!
08:48:30 job_callback for (9, 0, 2) finished
08:48:30 HBMASTER: schedule new run for iteration 9
08:48:30 HBMASTER: trying submitting job (9, 0, 8) to dispatcher
08:48:30 HBMASTER: submitting job (9, 0, 8) to dispatcher
08:48:30 DISPATCHER: trying to submit job (9, 0, 8)
08:48:30 DISPATCHER: trying to notify the job_runner thread.
08:48:30 HBMASTER: job (9, 0, 8) submitted to dispatcher
08:48:30 DISPATCHER: Trying to submit another job.
08:48:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:48:30 DISPATCHER: starting job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:48:30 DISPATCHER: job (9, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:48:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:48:30 WORKER: start processing job (9, 0, 8)
08:48:30 WORKER: args: ()
08:48:30 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001899026026553594, 'num_filters_1': 70, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.02646941053965723, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 42, 'num_filters_3': 118, 'num_filters_4': 50}, 'budget': 400.0, 'working_directory': '.'}
08:49:16 DISPATCHER: Starting worker discovery
08:49:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:49:16 DISPATCHER: Finished worker discovery
08:50:16 DISPATCHER: Starting worker discovery
08:50:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:50:16 DISPATCHER: Finished worker discovery
08:51:16 DISPATCHER: Starting worker discovery
08:51:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:51:16 DISPATCHER: Finished worker discovery
08:52:16 DISPATCHER: Starting worker discovery
08:52:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:52:16 DISPATCHER: Finished worker discovery
08:53:16 DISPATCHER: Starting worker discovery
08:53:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:53:16 DISPATCHER: Finished worker discovery
08:54:16 DISPATCHER: Starting worker discovery
08:54:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:54:16 DISPATCHER: Finished worker discovery
08:55:16 DISPATCHER: Starting worker discovery
08:55:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:55:16 DISPATCHER: Finished worker discovery
08:56:16 DISPATCHER: Starting worker discovery
08:56:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:56:16 DISPATCHER: Finished worker discovery
08:56:16 WORKER: done with job (9, 0, 8), trying to register it.
08:56:16 WORKER: registered result for job (9, 0, 8) with dispatcher
08:56:16 DISPATCHER: job (9, 0, 8) finished
08:56:16 DISPATCHER: register_result: lock acquired
08:56:16 DISPATCHER: job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
08:56:16 job_id: (9, 0, 8)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001899026026553594, 'num_filters_1': 70, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.02646941053965723, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 42, 'num_filters_3': 118, 'num_filters_4': 50}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.49289000505385394, 'info': {'sick_no_sick': 0.49289000505385394, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001899026026553594, 'num_filters_1': 70, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.02646941053965723, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 42, 'num_filters_3': 118, 'num_filters_4': 50}"}}
exception: None

08:56:16 job_callback for (9, 0, 8) started
08:56:16 job_callback for (9, 0, 8) got condition
08:56:16 DISPATCHER: Trying to submit another job.
08:56:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:56:16 HBMASTER: Trying to run another job!
08:56:16 job_callback for (9, 0, 8) finished
08:56:16 ITERATION: Advancing config (9, 0, 2) to next budget 1200.000000
08:56:16 HBMASTER: schedule new run for iteration 9
08:56:16 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
08:56:16 HBMASTER: submitting job (9, 0, 2) to dispatcher
08:56:16 DISPATCHER: trying to submit job (9, 0, 2)
08:56:16 DISPATCHER: trying to notify the job_runner thread.
08:56:16 HBMASTER: job (9, 0, 2) submitted to dispatcher
08:56:16 DISPATCHER: Trying to submit another job.
08:56:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:56:16 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:56:16 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.30598140416580691776
08:56:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:56:16 WORKER: start processing job (9, 0, 2)
08:56:16 WORKER: args: ()
08:56:16 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.003315709949643333, 'num_filters_1': 62, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.023576316911241513}, 'budget': 1200.0, 'working_directory': '.'}
08:57:16 DISPATCHER: Starting worker discovery
08:57:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:57:16 DISPATCHER: Finished worker discovery
08:58:16 DISPATCHER: Starting worker discovery
08:58:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:58:16 DISPATCHER: Finished worker discovery
08:59:16 DISPATCHER: Starting worker discovery
08:59:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:59:16 DISPATCHER: Finished worker discovery
09:00:16 DISPATCHER: Starting worker discovery
09:00:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:00:16 DISPATCHER: Finished worker discovery
09:01:16 DISPATCHER: Starting worker discovery
09:01:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:01:16 DISPATCHER: Finished worker discovery
09:02:16 DISPATCHER: Starting worker discovery
09:02:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:02:16 DISPATCHER: Finished worker discovery
09:03:16 DISPATCHER: Starting worker discovery
09:03:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:03:16 DISPATCHER: Finished worker discovery
09:04:16 DISPATCHER: Starting worker discovery
09:04:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:04:16 DISPATCHER: Finished worker discovery
09:05:16 DISPATCHER: Starting worker discovery
09:05:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:05:16 DISPATCHER: Finished worker discovery
09:06:16 DISPATCHER: Starting worker discovery
09:06:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:06:16 DISPATCHER: Finished worker discovery
09:07:16 DISPATCHER: Starting worker discovery
09:07:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:07:16 DISPATCHER: Finished worker discovery
09:08:16 DISPATCHER: Starting worker discovery
09:08:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:08:16 DISPATCHER: Finished worker discovery
09:09:16 DISPATCHER: Starting worker discovery
09:09:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:09:16 DISPATCHER: Finished worker discovery
09:10:16 DISPATCHER: Starting worker discovery
09:10:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:10:16 DISPATCHER: Finished worker discovery
09:11:16 DISPATCHER: Starting worker discovery
09:11:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:11:16 DISPATCHER: Finished worker discovery
09:12:16 DISPATCHER: Starting worker discovery
09:12:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:12:16 DISPATCHER: Finished worker discovery
09:13:16 DISPATCHER: Starting worker discovery
09:13:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:13:16 DISPATCHER: Finished worker discovery
09:14:16 DISPATCHER: Starting worker discovery
09:14:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:14:16 DISPATCHER: Finished worker discovery
09:15:16 DISPATCHER: Starting worker discovery
09:15:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:15:16 DISPATCHER: Finished worker discovery
09:16:16 DISPATCHER: Starting worker discovery
09:16:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:16:16 DISPATCHER: Finished worker discovery
09:17:16 DISPATCHER: Starting worker discovery
09:17:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:17:16 DISPATCHER: Finished worker discovery
09:18:16 DISPATCHER: Starting worker discovery
09:18:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:18:16 DISPATCHER: Finished worker discovery
09:18:40 WORKER: done with job (9, 0, 2), trying to register it.
09:18:40 WORKER: registered result for job (9, 0, 2) with dispatcher
09:18:40 DISPATCHER: job (9, 0, 2) finished
09:18:40 DISPATCHER: register_result: lock acquired
09:18:40 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpuj.30598140416580691776 finished
09:18:40 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.003315709949643333, 'num_filters_1': 62, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.023576316911241513}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.46929166684268975, 'info': {'sick_no_sick': 0.46929166684268975, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.003315709949643333, 'num_filters_1': 62, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.023576316911241513}"}}
exception: None

09:18:40 job_callback for (9, 0, 2) started
09:18:40 job_callback for (9, 0, 2) got condition
09:18:40 DISPATCHER: Trying to submit another job.
09:18:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:18:40 HBMASTER: Trying to run another job!
09:18:40 job_callback for (9, 0, 2) finished
09:18:40 HBMASTER: shutdown initiated, shutdown_workers = True
09:18:40 WORKER: shutting down now!
09:18:40 DISPATCHER: Dispatcher shutting down
09:18:40 DISPATCHER: discover_workers shutting down
09:18:40 DISPATCHER: Trying to submit another job.
09:18:40 DISPATCHER: 'discover_worker' thread exited
09:18:40 DISPATCHER: job_runner shutting down
09:18:40 DISPATCHER: 'job_runner' thread exited
09:18:40 DISPATCHER: shut down complete
