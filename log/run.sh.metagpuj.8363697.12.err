/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Using TensorFlow backend.
WARNING:tensorflow:From /home/ahnj/repo/autodl/AutoDL/model.py:27: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /home/ahnj/repo/autodl/AutoDL/model.py:31: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2020-03-09 22:42:22.251034: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-03-09 22:42:22.254851: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299960000 Hz
2020-03-09 22:42:22.255263: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a3b4d19ff0 executing computations on platform Host. Devices:
2020-03-09 22:42:22.255281: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-03-09 22:42:22.255835: I tensorflow/core/common_runtime/direct_session.cc:296] Device mapping:
/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device

22:42:22 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7f9cb8b90668; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:37875>
22:42:22 WORKER: No dispatcher found. Waiting for one to initiate contact.
22:42:22 WORKER: start listening for jobs
22:42:22 wait_for_workers trying to get the condition
22:42:22 DISPATCHER: started the 'discover_worker' thread
22:42:22 DISPATCHER: started the 'job_runner' thread
22:42:22 DISPATCHER: Pyro daemon running on localhost:40853
22:42:22 DISPATCHER: Starting worker discovery
22:42:22 DISPATCHER: Found 1 potential workers, 0 currently in the pool.
22:42:22 DISPATCHER: discovered new worker, hpbandster.run_0.worker.metagpuj.13101140314513094464
22:42:22 HBMASTER: number of workers changed to 1
22:42:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:42:22 HBMASTER: only 1 worker(s) available, waiting for at least 1.
22:42:22 adjust_queue_size: lock accquired
22:42:22 HBMASTER: adjusted queue size to (0, 1)
22:42:22 DISPATCHER: Finished worker discovery
22:42:22 DISPATCHER: Trying to submit another job.
22:42:22 DISPATCHER: A new worker triggered discover_worker
22:42:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:42:22 Enough workers to start this run!
22:42:22 DISPATCHER: Starting worker discovery
22:42:22 HBMASTER: starting run at 1583790142.3324895
22:42:22 start sampling a new configuration.
22:42:22 done sampling a new configuration.
22:42:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:42:22 HBMASTER: schedule new run for iteration 0
22:42:22 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
22:42:22 HBMASTER: submitting job (0, 0, 0) to dispatcher
22:42:22 DISPATCHER: trying to submit job (0, 0, 0)
22:42:22 DISPATCHER: Finished worker discovery
22:42:22 DISPATCHER: trying to notify the job_runner thread.
22:42:22 HBMASTER: job (0, 0, 0) submitted to dispatcher
22:42:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:42:22 DISPATCHER: Trying to submit another job.
22:42:22 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:42:22 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:42:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:42:22 WORKER: start processing job (0, 0, 0)
22:42:22 WORKER: args: ()
22:42:22 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 790, 'last_n_outputs': 36, 'leak_rate': 0.9988329171720638, 'lr': 0.06656225360432011, 'optimizer': 'Adam', 'sparsity': 0.890444324163778, 'steps_to_train': 83, 'weight_decay': 0.057104120572477365}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:43:22 DISPATCHER: Starting worker discovery
22:43:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:43:22 DISPATCHER: Finished worker discovery
22:43:32 WORKER: done with job (0, 0, 0), trying to register it.
22:43:32 WORKER: registered result for job (0, 0, 0) with dispatcher
22:43:32 DISPATCHER: job (0, 0, 0) finished
22:43:32 DISPATCHER: register_result: lock acquired
22:43:32 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
22:43:32 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 790, 'last_n_outputs': 36, 'leak_rate': 0.9988329171720638, 'lr': 0.06656225360432011, 'optimizer': 'Adam', 'sparsity': 0.890444324163778, 'steps_to_train': 83, 'weight_decay': 0.057104120572477365}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.005269650083397398, 'info': {'data05': 0.005269650083397398, 'config': "{'batch_size': 32, 'hidden_dim': 790, 'last_n_outputs': 36, 'leak_rate': 0.9988329171720638, 'lr': 0.06656225360432011, 'optimizer': 'Adam', 'sparsity': 0.890444324163778, 'steps_to_train': 83, 'weight_decay': 0.057104120572477365}"}}
exception: None

22:43:32 job_callback for (0, 0, 0) started
22:43:32 DISPATCHER: Trying to submit another job.
22:43:32 job_callback for (0, 0, 0) got condition
22:43:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:43:32 Only 1 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
22:43:32 HBMASTER: Trying to run another job!
22:43:32 job_callback for (0, 0, 0) finished
22:43:32 start sampling a new configuration.
22:43:32 done sampling a new configuration.
22:43:32 HBMASTER: schedule new run for iteration 0
22:43:32 HBMASTER: trying submitting job (0, 0, 1) to dispatcher
22:43:32 HBMASTER: submitting job (0, 0, 1) to dispatcher
22:43:32 DISPATCHER: trying to submit job (0, 0, 1)
22:43:32 DISPATCHER: trying to notify the job_runner thread.
22:43:32 HBMASTER: job (0, 0, 1) submitted to dispatcher
22:43:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:43:32 DISPATCHER: Trying to submit another job.
22:43:32 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:43:32 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:43:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:43:32 WORKER: start processing job (0, 0, 1)
22:43:32 WORKER: args: ()
22:43:32 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 480, 'last_n_outputs': 28, 'leak_rate': 0.8046623640296802, 'lr': 0.004295031205414862, 'optimizer': 'Adam', 'sparsity': 0.9565538377135148, 'steps_to_train': 18, 'weight_decay': 0.03343952836514127}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:44:22 DISPATCHER: Starting worker discovery
22:44:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:44:22 DISPATCHER: Finished worker discovery
22:44:29 WORKER: done with job (0, 0, 1), trying to register it.
22:44:29 WORKER: registered result for job (0, 0, 1) with dispatcher
22:44:29 DISPATCHER: job (0, 0, 1) finished
22:44:29 DISPATCHER: register_result: lock acquired
22:44:29 DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
22:44:29 job_id: (0, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 480, 'last_n_outputs': 28, 'leak_rate': 0.8046623640296802, 'lr': 0.004295031205414862, 'optimizer': 'Adam', 'sparsity': 0.9565538377135148, 'steps_to_train': 18, 'weight_decay': 0.03343952836514127}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.37769086426401466, 'info': {'data05': 0.37769086426401466, 'config': "{'batch_size': 16, 'hidden_dim': 480, 'last_n_outputs': 28, 'leak_rate': 0.8046623640296802, 'lr': 0.004295031205414862, 'optimizer': 'Adam', 'sparsity': 0.9565538377135148, 'steps_to_train': 18, 'weight_decay': 0.03343952836514127}"}}
exception: None

22:44:29 job_callback for (0, 0, 1) started
22:44:29 DISPATCHER: Trying to submit another job.
22:44:29 job_callback for (0, 0, 1) got condition
22:44:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:44:29 Only 2 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
22:44:29 HBMASTER: Trying to run another job!
22:44:29 job_callback for (0, 0, 1) finished
22:44:29 start sampling a new configuration.
22:44:29 done sampling a new configuration.
22:44:29 HBMASTER: schedule new run for iteration 0
22:44:29 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
22:44:29 HBMASTER: submitting job (0, 0, 2) to dispatcher
22:44:29 DISPATCHER: trying to submit job (0, 0, 2)
22:44:29 DISPATCHER: trying to notify the job_runner thread.
22:44:29 HBMASTER: job (0, 0, 2) submitted to dispatcher
22:44:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:44:29 DISPATCHER: Trying to submit another job.
22:44:29 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:44:29 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:44:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:44:29 WORKER: start processing job (0, 0, 2)
22:44:29 WORKER: args: ()
22:44:29 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 221, 'last_n_outputs': 32, 'leak_rate': 0.810620510883254, 'lr': 0.05646729433901187, 'optimizer': 'Adam', 'sparsity': 0.9433450810077502, 'steps_to_train': 47, 'weight_decay': 0.10689682716426636}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:45:22 DISPATCHER: Starting worker discovery
22:45:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:45:22 DISPATCHER: Finished worker discovery
22:45:26 WORKER: done with job (0, 0, 2), trying to register it.
22:45:26 WORKER: registered result for job (0, 0, 2) with dispatcher
22:45:26 DISPATCHER: job (0, 0, 2) finished
22:45:26 DISPATCHER: register_result: lock acquired
22:45:26 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
22:45:26 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 221, 'last_n_outputs': 32, 'leak_rate': 0.810620510883254, 'lr': 0.05646729433901187, 'optimizer': 'Adam', 'sparsity': 0.9433450810077502, 'steps_to_train': 47, 'weight_decay': 0.10689682716426636}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.02509555744415349, 'info': {'data05': 0.02509555744415349, 'config': "{'batch_size': 128, 'hidden_dim': 221, 'last_n_outputs': 32, 'leak_rate': 0.810620510883254, 'lr': 0.05646729433901187, 'optimizer': 'Adam', 'sparsity': 0.9433450810077502, 'steps_to_train': 47, 'weight_decay': 0.10689682716426636}"}}
exception: None

22:45:26 job_callback for (0, 0, 2) started
22:45:26 job_callback for (0, 0, 2) got condition
22:45:26 DISPATCHER: Trying to submit another job.
22:45:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:45:26 Only 3 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
22:45:26 HBMASTER: Trying to run another job!
22:45:26 job_callback for (0, 0, 2) finished
22:45:26 start sampling a new configuration.
22:45:26 done sampling a new configuration.
22:45:26 HBMASTER: schedule new run for iteration 0
22:45:26 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
22:45:26 HBMASTER: submitting job (0, 0, 3) to dispatcher
22:45:26 DISPATCHER: trying to submit job (0, 0, 3)
22:45:26 DISPATCHER: trying to notify the job_runner thread.
22:45:26 HBMASTER: job (0, 0, 3) submitted to dispatcher
22:45:26 DISPATCHER: Trying to submit another job.
22:45:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:45:26 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:45:26 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:45:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:45:26 WORKER: start processing job (0, 0, 3)
22:45:26 WORKER: args: ()
22:45:26 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 881, 'last_n_outputs': 23, 'leak_rate': 0.9857757681051131, 'lr': 0.001608434397366311, 'optimizer': 'Adam', 'sparsity': 0.8675971749259547, 'steps_to_train': 20, 'weight_decay': 0.02377807449380557}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:46:22 DISPATCHER: Starting worker discovery
22:46:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:46:22 DISPATCHER: Finished worker discovery
22:46:23 WORKER: done with job (0, 0, 3), trying to register it.
22:46:23 WORKER: registered result for job (0, 0, 3) with dispatcher
22:46:23 DISPATCHER: job (0, 0, 3) finished
22:46:23 DISPATCHER: register_result: lock acquired
22:46:23 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
22:46:23 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 881, 'last_n_outputs': 23, 'leak_rate': 0.9857757681051131, 'lr': 0.001608434397366311, 'optimizer': 'Adam', 'sparsity': 0.8675971749259547, 'steps_to_train': 20, 'weight_decay': 0.02377807449380557}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.47042964837459117, 'info': {'data05': 0.47042964837459117, 'config': "{'batch_size': 64, 'hidden_dim': 881, 'last_n_outputs': 23, 'leak_rate': 0.9857757681051131, 'lr': 0.001608434397366311, 'optimizer': 'Adam', 'sparsity': 0.8675971749259547, 'steps_to_train': 20, 'weight_decay': 0.02377807449380557}"}}
exception: None

22:46:23 DISPATCHER: Trying to submit another job.
22:46:23 job_callback for (0, 0, 3) started
22:46:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:46:23 job_callback for (0, 0, 3) got condition
22:46:23 Only 4 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
22:46:23 HBMASTER: Trying to run another job!
22:46:23 job_callback for (0, 0, 3) finished
22:46:23 start sampling a new configuration.
22:46:23 done sampling a new configuration.
22:46:23 HBMASTER: schedule new run for iteration 0
22:46:23 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
22:46:23 HBMASTER: submitting job (0, 0, 4) to dispatcher
22:46:23 DISPATCHER: trying to submit job (0, 0, 4)
22:46:23 DISPATCHER: trying to notify the job_runner thread.
22:46:23 HBMASTER: job (0, 0, 4) submitted to dispatcher
22:46:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:46:23 DISPATCHER: Trying to submit another job.
22:46:23 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:46:23 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:46:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:46:23 WORKER: start processing job (0, 0, 4)
22:46:23 WORKER: args: ()
22:46:23 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 205, 'last_n_outputs': 17, 'leak_rate': 0.7718366233498665, 'lr': 0.001825476717884993, 'optimizer': 'Adam', 'sparsity': 0.9877830410584818, 'steps_to_train': 47, 'weight_decay': 0.02415992413449215}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:47:20 WORKER: done with job (0, 0, 4), trying to register it.
22:47:20 WORKER: registered result for job (0, 0, 4) with dispatcher
22:47:20 DISPATCHER: job (0, 0, 4) finished
22:47:20 DISPATCHER: register_result: lock acquired
22:47:20 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
22:47:20 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 205, 'last_n_outputs': 17, 'leak_rate': 0.7718366233498665, 'lr': 0.001825476717884993, 'optimizer': 'Adam', 'sparsity': 0.9877830410584818, 'steps_to_train': 47, 'weight_decay': 0.02415992413449215}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4524511201885878, 'info': {'data05': 0.4524511201885878, 'config': "{'batch_size': 64, 'hidden_dim': 205, 'last_n_outputs': 17, 'leak_rate': 0.7718366233498665, 'lr': 0.001825476717884993, 'optimizer': 'Adam', 'sparsity': 0.9877830410584818, 'steps_to_train': 47, 'weight_decay': 0.02415992413449215}"}}
exception: None

22:47:20 job_callback for (0, 0, 4) started
22:47:20 DISPATCHER: Trying to submit another job.
22:47:20 job_callback for (0, 0, 4) got condition
22:47:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:47:20 Only 5 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
22:47:20 HBMASTER: Trying to run another job!
22:47:20 job_callback for (0, 0, 4) finished
22:47:20 start sampling a new configuration.
22:47:20 done sampling a new configuration.
22:47:20 HBMASTER: schedule new run for iteration 0
22:47:20 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
22:47:20 HBMASTER: submitting job (0, 0, 5) to dispatcher
22:47:20 DISPATCHER: trying to submit job (0, 0, 5)
22:47:20 DISPATCHER: trying to notify the job_runner thread.
22:47:20 HBMASTER: job (0, 0, 5) submitted to dispatcher
22:47:20 DISPATCHER: Trying to submit another job.
22:47:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:47:20 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:47:20 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:47:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:47:20 WORKER: start processing job (0, 0, 5)
22:47:20 WORKER: args: ()
22:47:20 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 993, 'last_n_outputs': 38, 'leak_rate': 0.8370780530009059, 'lr': 0.04269315588254884, 'optimizer': 'SGD', 'sparsity': 0.9401581960445465, 'steps_to_train': 100, 'weight_decay': 0.010702851945979875}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:47:22 DISPATCHER: Starting worker discovery
22:47:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:47:22 DISPATCHER: Finished worker discovery
22:48:16 WORKER: done with job (0, 0, 5), trying to register it.
22:48:16 WORKER: registered result for job (0, 0, 5) with dispatcher
22:48:16 DISPATCHER: job (0, 0, 5) finished
22:48:16 DISPATCHER: register_result: lock acquired
22:48:16 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
22:48:16 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 993, 'last_n_outputs': 38, 'leak_rate': 0.8370780530009059, 'lr': 0.04269315588254884, 'optimizer': 'SGD', 'sparsity': 0.9401581960445465, 'steps_to_train': 100, 'weight_decay': 0.010702851945979875}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.756786967976469, 'info': {'data05': 0.756786967976469, 'config': "{'batch_size': 128, 'hidden_dim': 993, 'last_n_outputs': 38, 'leak_rate': 0.8370780530009059, 'lr': 0.04269315588254884, 'optimizer': 'SGD', 'sparsity': 0.9401581960445465, 'steps_to_train': 100, 'weight_decay': 0.010702851945979875}"}}
exception: None

22:48:16 job_callback for (0, 0, 5) started
22:48:16 DISPATCHER: Trying to submit another job.
22:48:16 job_callback for (0, 0, 5) got condition
22:48:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:48:16 Only 6 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
22:48:16 HBMASTER: Trying to run another job!
22:48:16 job_callback for (0, 0, 5) finished
22:48:16 start sampling a new configuration.
22:48:16 done sampling a new configuration.
22:48:16 HBMASTER: schedule new run for iteration 0
22:48:16 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
22:48:16 HBMASTER: submitting job (0, 0, 6) to dispatcher
22:48:16 DISPATCHER: trying to submit job (0, 0, 6)
22:48:16 DISPATCHER: trying to notify the job_runner thread.
22:48:16 HBMASTER: job (0, 0, 6) submitted to dispatcher
22:48:16 DISPATCHER: Trying to submit another job.
22:48:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:48:16 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:48:16 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:48:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:48:16 WORKER: start processing job (0, 0, 6)
22:48:16 WORKER: args: ()
22:48:16 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 953, 'last_n_outputs': 24, 'leak_rate': 0.8017882451724827, 'lr': 0.041164016228981117, 'optimizer': 'SGD', 'sparsity': 0.8567655246411849, 'steps_to_train': 74, 'weight_decay': 0.059971588024208704}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:48:22 DISPATCHER: Starting worker discovery
22:48:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:48:22 DISPATCHER: Finished worker discovery
22:49:19 WORKER: done with job (0, 0, 6), trying to register it.
22:49:19 WORKER: registered result for job (0, 0, 6) with dispatcher
22:49:19 DISPATCHER: job (0, 0, 6) finished
22:49:19 DISPATCHER: register_result: lock acquired
22:49:19 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
22:49:19 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 953, 'last_n_outputs': 24, 'leak_rate': 0.8017882451724827, 'lr': 0.041164016228981117, 'optimizer': 'SGD', 'sparsity': 0.8567655246411849, 'steps_to_train': 74, 'weight_decay': 0.059971588024208704}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5394766508239797, 'info': {'data05': 0.5394766508239797, 'config': "{'batch_size': 16, 'hidden_dim': 953, 'last_n_outputs': 24, 'leak_rate': 0.8017882451724827, 'lr': 0.041164016228981117, 'optimizer': 'SGD', 'sparsity': 0.8567655246411849, 'steps_to_train': 74, 'weight_decay': 0.059971588024208704}"}}
exception: None

22:49:19 job_callback for (0, 0, 6) started
22:49:19 DISPATCHER: Trying to submit another job.
22:49:19 job_callback for (0, 0, 6) got condition
22:49:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:49:19 Only 7 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
22:49:19 HBMASTER: Trying to run another job!
22:49:19 job_callback for (0, 0, 6) finished
22:49:19 start sampling a new configuration.
22:49:19 done sampling a new configuration.
22:49:19 HBMASTER: schedule new run for iteration 0
22:49:19 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
22:49:19 HBMASTER: submitting job (0, 0, 7) to dispatcher
22:49:19 DISPATCHER: trying to submit job (0, 0, 7)
22:49:19 DISPATCHER: trying to notify the job_runner thread.
22:49:19 HBMASTER: job (0, 0, 7) submitted to dispatcher
22:49:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:49:19 DISPATCHER: Trying to submit another job.
22:49:19 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:49:19 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:49:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:49:19 WORKER: start processing job (0, 0, 7)
22:49:19 WORKER: args: ()
22:49:19 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 304, 'last_n_outputs': 44, 'leak_rate': 0.8454013769665221, 'lr': 0.03283994206507779, 'optimizer': 'SGD', 'sparsity': 0.9416829915152293, 'steps_to_train': 50, 'weight_decay': 0.016065976288656286}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:49:22 DISPATCHER: Starting worker discovery
22:49:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:49:22 DISPATCHER: Finished worker discovery
22:50:18 WORKER: done with job (0, 0, 7), trying to register it.
22:50:18 WORKER: registered result for job (0, 0, 7) with dispatcher
22:50:18 DISPATCHER: job (0, 0, 7) finished
22:50:18 DISPATCHER: register_result: lock acquired
22:50:18 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
22:50:18 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 304, 'last_n_outputs': 44, 'leak_rate': 0.8454013769665221, 'lr': 0.03283994206507779, 'optimizer': 'SGD', 'sparsity': 0.9416829915152293, 'steps_to_train': 50, 'weight_decay': 0.016065976288656286}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7315174441021149, 'info': {'data05': 0.7315174441021149, 'config': "{'batch_size': 64, 'hidden_dim': 304, 'last_n_outputs': 44, 'leak_rate': 0.8454013769665221, 'lr': 0.03283994206507779, 'optimizer': 'SGD', 'sparsity': 0.9416829915152293, 'steps_to_train': 50, 'weight_decay': 0.016065976288656286}"}}
exception: None

22:50:18 job_callback for (0, 0, 7) started
22:50:18 DISPATCHER: Trying to submit another job.
22:50:18 job_callback for (0, 0, 7) got condition
22:50:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:50:18 Only 8 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
22:50:18 HBMASTER: Trying to run another job!
22:50:18 job_callback for (0, 0, 7) finished
22:50:18 start sampling a new configuration.
22:50:18 done sampling a new configuration.
22:50:18 HBMASTER: schedule new run for iteration 0
22:50:18 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
22:50:18 HBMASTER: submitting job (0, 0, 8) to dispatcher
22:50:18 DISPATCHER: trying to submit job (0, 0, 8)
22:50:18 DISPATCHER: trying to notify the job_runner thread.
22:50:18 HBMASTER: job (0, 0, 8) submitted to dispatcher
22:50:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:50:18 DISPATCHER: Trying to submit another job.
22:50:18 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:50:18 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:50:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:50:18 WORKER: start processing job (0, 0, 8)
22:50:18 WORKER: args: ()
22:50:18 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 855, 'last_n_outputs': 44, 'leak_rate': 0.8927030492189386, 'lr': 0.0019568121476006813, 'optimizer': 'SGD', 'sparsity': 0.9489950724201204, 'steps_to_train': 23, 'weight_decay': 0.027098171454306475}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:50:22 DISPATCHER: Starting worker discovery
22:50:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:50:22 DISPATCHER: Finished worker discovery
22:51:17 WORKER: done with job (0, 0, 8), trying to register it.
22:51:17 WORKER: registered result for job (0, 0, 8) with dispatcher
22:51:17 DISPATCHER: job (0, 0, 8) finished
22:51:17 DISPATCHER: register_result: lock acquired
22:51:17 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
22:51:17 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 855, 'last_n_outputs': 44, 'leak_rate': 0.8927030492189386, 'lr': 0.0019568121476006813, 'optimizer': 'SGD', 'sparsity': 0.9489950724201204, 'steps_to_train': 23, 'weight_decay': 0.027098171454306475}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6780536020243589, 'info': {'data05': 0.6780536020243589, 'config': "{'batch_size': 128, 'hidden_dim': 855, 'last_n_outputs': 44, 'leak_rate': 0.8927030492189386, 'lr': 0.0019568121476006813, 'optimizer': 'SGD', 'sparsity': 0.9489950724201204, 'steps_to_train': 23, 'weight_decay': 0.027098171454306475}"}}
exception: None

22:51:17 job_callback for (0, 0, 8) started
22:51:17 job_callback for (0, 0, 8) got condition
22:51:17 DISPATCHER: Trying to submit another job.
22:51:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:51:17 Only 9 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
22:51:17 HBMASTER: Trying to run another job!
22:51:17 job_callback for (0, 0, 8) finished
22:51:17 start sampling a new configuration.
22:51:17 done sampling a new configuration.
22:51:17 HBMASTER: schedule new run for iteration 0
22:51:17 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
22:51:17 HBMASTER: submitting job (0, 0, 9) to dispatcher
22:51:17 DISPATCHER: trying to submit job (0, 0, 9)
22:51:17 DISPATCHER: trying to notify the job_runner thread.
22:51:17 HBMASTER: job (0, 0, 9) submitted to dispatcher
22:51:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:51:17 DISPATCHER: Trying to submit another job.
22:51:17 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:51:17 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:51:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:51:17 WORKER: start processing job (0, 0, 9)
22:51:17 WORKER: args: ()
22:51:17 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 278, 'last_n_outputs': 31, 'leak_rate': 0.7744909174207821, 'lr': 0.09213256649038883, 'optimizer': 'SGD', 'sparsity': 0.8463861482867197, 'steps_to_train': 54, 'weight_decay': 0.0885565035191771}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:51:22 DISPATCHER: Starting worker discovery
22:51:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:51:22 DISPATCHER: Finished worker discovery
22:52:15 WORKER: done with job (0, 0, 9), trying to register it.
22:52:15 WORKER: registered result for job (0, 0, 9) with dispatcher
22:52:15 DISPATCHER: job (0, 0, 9) finished
22:52:15 DISPATCHER: register_result: lock acquired
22:52:15 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
22:52:15 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 278, 'last_n_outputs': 31, 'leak_rate': 0.7744909174207821, 'lr': 0.09213256649038883, 'optimizer': 'SGD', 'sparsity': 0.8463861482867197, 'steps_to_train': 54, 'weight_decay': 0.0885565035191771}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.27987660008764875, 'info': {'data05': 0.27987660008764875, 'config': "{'batch_size': 128, 'hidden_dim': 278, 'last_n_outputs': 31, 'leak_rate': 0.7744909174207821, 'lr': 0.09213256649038883, 'optimizer': 'SGD', 'sparsity': 0.8463861482867197, 'steps_to_train': 54, 'weight_decay': 0.0885565035191771}"}}
exception: None

22:52:15 job_callback for (0, 0, 9) started
22:52:15 job_callback for (0, 0, 9) got condition
22:52:15 DISPATCHER: Trying to submit another job.
22:52:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:52:15 HBMASTER: Trying to run another job!
22:52:15 job_callback for (0, 0, 9) finished
22:52:15 start sampling a new configuration.
22:52:15 done sampling a new configuration.
22:52:15 HBMASTER: schedule new run for iteration 0
22:52:15 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
22:52:15 HBMASTER: submitting job (0, 0, 10) to dispatcher
22:52:15 DISPATCHER: trying to submit job (0, 0, 10)
22:52:15 DISPATCHER: trying to notify the job_runner thread.
22:52:15 HBMASTER: job (0, 0, 10) submitted to dispatcher
22:52:15 DISPATCHER: Trying to submit another job.
22:52:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:52:15 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:52:15 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:52:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:52:15 WORKER: start processing job (0, 0, 10)
22:52:15 WORKER: args: ()
22:52:15 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 348, 'last_n_outputs': 31, 'leak_rate': 0.8557125652004375, 'lr': 0.01587596346660864, 'optimizer': 'Adam', 'sparsity': 0.9824387794453681, 'steps_to_train': 19, 'weight_decay': 0.01372142795613634}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:52:22 DISPATCHER: Starting worker discovery
22:52:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:52:22 DISPATCHER: Finished worker discovery
22:53:13 WORKER: done with job (0, 0, 10), trying to register it.
22:53:13 WORKER: registered result for job (0, 0, 10) with dispatcher
22:53:13 DISPATCHER: job (0, 0, 10) finished
22:53:13 DISPATCHER: register_result: lock acquired
22:53:13 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
22:53:13 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 348, 'last_n_outputs': 31, 'leak_rate': 0.8557125652004375, 'lr': 0.01587596346660864, 'optimizer': 'Adam', 'sparsity': 0.9824387794453681, 'steps_to_train': 19, 'weight_decay': 0.01372142795613634}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.31999633942819866, 'info': {'data05': 0.31999633942819866, 'config': "{'batch_size': 64, 'hidden_dim': 348, 'last_n_outputs': 31, 'leak_rate': 0.8557125652004375, 'lr': 0.01587596346660864, 'optimizer': 'Adam', 'sparsity': 0.9824387794453681, 'steps_to_train': 19, 'weight_decay': 0.01372142795613634}"}}
exception: None

22:53:13 job_callback for (0, 0, 10) started
22:53:13 job_callback for (0, 0, 10) got condition
22:53:13 DISPATCHER: Trying to submit another job.
22:53:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:53:13 HBMASTER: Trying to run another job!
22:53:13 job_callback for (0, 0, 10) finished
22:53:13 start sampling a new configuration.
22:53:13 done sampling a new configuration.
22:53:13 HBMASTER: schedule new run for iteration 0
22:53:13 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
22:53:13 HBMASTER: submitting job (0, 0, 11) to dispatcher
22:53:13 DISPATCHER: trying to submit job (0, 0, 11)
22:53:13 DISPATCHER: trying to notify the job_runner thread.
22:53:13 HBMASTER: job (0, 0, 11) submitted to dispatcher
22:53:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:53:13 DISPATCHER: Trying to submit another job.
22:53:13 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:53:13 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:53:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:53:13 WORKER: start processing job (0, 0, 11)
22:53:13 WORKER: args: ()
22:53:13 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 987, 'last_n_outputs': 49, 'leak_rate': 0.9925223501264618, 'lr': 0.011866833529571635, 'optimizer': 'SGD', 'sparsity': 0.8128538944226172, 'steps_to_train': 93, 'weight_decay': 0.04240512958885776}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:53:22 DISPATCHER: Starting worker discovery
22:53:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:53:22 DISPATCHER: Finished worker discovery
22:54:15 WORKER: done with job (0, 0, 11), trying to register it.
22:54:15 WORKER: registered result for job (0, 0, 11) with dispatcher
22:54:15 DISPATCHER: job (0, 0, 11) finished
22:54:15 DISPATCHER: register_result: lock acquired
22:54:15 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
22:54:15 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 987, 'last_n_outputs': 49, 'leak_rate': 0.9925223501264618, 'lr': 0.011866833529571635, 'optimizer': 'SGD', 'sparsity': 0.8128538944226172, 'steps_to_train': 93, 'weight_decay': 0.04240512958885776}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7316000412819926, 'info': {'data05': 0.7316000412819926, 'config': "{'batch_size': 64, 'hidden_dim': 987, 'last_n_outputs': 49, 'leak_rate': 0.9925223501264618, 'lr': 0.011866833529571635, 'optimizer': 'SGD', 'sparsity': 0.8128538944226172, 'steps_to_train': 93, 'weight_decay': 0.04240512958885776}"}}
exception: None

22:54:15 job_callback for (0, 0, 11) started
22:54:15 DISPATCHER: Trying to submit another job.
22:54:15 job_callback for (0, 0, 11) got condition
22:54:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:54:15 HBMASTER: Trying to run another job!
22:54:15 job_callback for (0, 0, 11) finished
22:54:15 start sampling a new configuration.
22:54:15 done sampling a new configuration.
22:54:15 HBMASTER: schedule new run for iteration 0
22:54:15 HBMASTER: trying submitting job (0, 0, 12) to dispatcher
22:54:15 HBMASTER: submitting job (0, 0, 12) to dispatcher
22:54:15 DISPATCHER: trying to submit job (0, 0, 12)
22:54:15 DISPATCHER: trying to notify the job_runner thread.
22:54:15 HBMASTER: job (0, 0, 12) submitted to dispatcher
22:54:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:54:15 DISPATCHER: Trying to submit another job.
22:54:15 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:54:15 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:54:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:54:15 WORKER: start processing job (0, 0, 12)
22:54:15 WORKER: args: ()
22:54:15 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 482, 'last_n_outputs': 12, 'leak_rate': 0.8770472116549696, 'lr': 0.010890808531951577, 'optimizer': 'Adam', 'sparsity': 0.9249076778443868, 'steps_to_train': 91, 'weight_decay': 0.18039985042827758}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:54:22 DISPATCHER: Starting worker discovery
22:54:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:54:22 DISPATCHER: Finished worker discovery
22:55:11 WORKER: done with job (0, 0, 12), trying to register it.
22:55:11 WORKER: registered result for job (0, 0, 12) with dispatcher
22:55:11 DISPATCHER: job (0, 0, 12) finished
22:55:11 DISPATCHER: register_result: lock acquired
22:55:11 DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
22:55:11 job_id: (0, 0, 12)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 482, 'last_n_outputs': 12, 'leak_rate': 0.8770472116549696, 'lr': 0.010890808531951577, 'optimizer': 'Adam', 'sparsity': 0.9249076778443868, 'steps_to_train': 91, 'weight_decay': 0.18039985042827758}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.14426306274794573, 'info': {'data05': 0.14426306274794573, 'config': "{'batch_size': 64, 'hidden_dim': 482, 'last_n_outputs': 12, 'leak_rate': 0.8770472116549696, 'lr': 0.010890808531951577, 'optimizer': 'Adam', 'sparsity': 0.9249076778443868, 'steps_to_train': 91, 'weight_decay': 0.18039985042827758}"}}
exception: None

22:55:11 job_callback for (0, 0, 12) started
22:55:11 job_callback for (0, 0, 12) got condition
22:55:11 DISPATCHER: Trying to submit another job.
22:55:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:55:11 HBMASTER: Trying to run another job!
22:55:11 job_callback for (0, 0, 12) finished
22:55:11 start sampling a new configuration.
22:55:11 done sampling a new configuration.
22:55:11 HBMASTER: schedule new run for iteration 0
22:55:11 HBMASTER: trying submitting job (0, 0, 13) to dispatcher
22:55:11 HBMASTER: submitting job (0, 0, 13) to dispatcher
22:55:11 DISPATCHER: trying to submit job (0, 0, 13)
22:55:11 DISPATCHER: trying to notify the job_runner thread.
22:55:11 HBMASTER: job (0, 0, 13) submitted to dispatcher
22:55:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:55:11 DISPATCHER: Trying to submit another job.
22:55:11 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:55:11 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:55:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:55:11 WORKER: start processing job (0, 0, 13)
22:55:11 WORKER: args: ()
22:55:11 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 569, 'last_n_outputs': 41, 'leak_rate': 0.862020197254004, 'lr': 0.0867702463269228, 'optimizer': 'Adam', 'sparsity': 0.9648761887052218, 'steps_to_train': 30, 'weight_decay': 0.015836302539853297}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:55:22 DISPATCHER: Starting worker discovery
22:55:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:55:22 DISPATCHER: Finished worker discovery
22:56:08 WORKER: done with job (0, 0, 13), trying to register it.
22:56:08 WORKER: registered result for job (0, 0, 13) with dispatcher
22:56:08 DISPATCHER: job (0, 0, 13) finished
22:56:08 DISPATCHER: register_result: lock acquired
22:56:08 DISPATCHER: job (0, 0, 13) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
22:56:08 job_id: (0, 0, 13)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 569, 'last_n_outputs': 41, 'leak_rate': 0.862020197254004, 'lr': 0.0867702463269228, 'optimizer': 'Adam', 'sparsity': 0.9648761887052218, 'steps_to_train': 30, 'weight_decay': 0.015836302539853297}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.12251787074085813, 'info': {'data05': 0.12251787074085813, 'config': "{'batch_size': 32, 'hidden_dim': 569, 'last_n_outputs': 41, 'leak_rate': 0.862020197254004, 'lr': 0.0867702463269228, 'optimizer': 'Adam', 'sparsity': 0.9648761887052218, 'steps_to_train': 30, 'weight_decay': 0.015836302539853297}"}}
exception: None

22:56:08 job_callback for (0, 0, 13) started
22:56:08 DISPATCHER: Trying to submit another job.
22:56:08 job_callback for (0, 0, 13) got condition
22:56:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:56:08 HBMASTER: Trying to run another job!
22:56:08 job_callback for (0, 0, 13) finished
22:56:08 start sampling a new configuration.
22:56:08 done sampling a new configuration.
22:56:08 HBMASTER: schedule new run for iteration 0
22:56:08 HBMASTER: trying submitting job (0, 0, 14) to dispatcher
22:56:08 HBMASTER: submitting job (0, 0, 14) to dispatcher
22:56:08 DISPATCHER: trying to submit job (0, 0, 14)
22:56:08 DISPATCHER: trying to notify the job_runner thread.
22:56:08 HBMASTER: job (0, 0, 14) submitted to dispatcher
22:56:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:56:08 DISPATCHER: Trying to submit another job.
22:56:08 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:56:08 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:56:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:56:08 WORKER: start processing job (0, 0, 14)
22:56:08 WORKER: args: ()
22:56:08 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 240, 'last_n_outputs': 19, 'leak_rate': 0.9196147374172924, 'lr': 0.0041164313898890996, 'optimizer': 'SGD', 'sparsity': 0.8827471333119505, 'steps_to_train': 39, 'weight_decay': 0.012826413729936724}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:56:22 DISPATCHER: Starting worker discovery
22:56:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:56:22 DISPATCHER: Finished worker discovery
22:57:04 WORKER: done with job (0, 0, 14), trying to register it.
22:57:04 WORKER: registered result for job (0, 0, 14) with dispatcher
22:57:04 DISPATCHER: job (0, 0, 14) finished
22:57:04 DISPATCHER: register_result: lock acquired
22:57:04 DISPATCHER: job (0, 0, 14) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
22:57:04 job_id: (0, 0, 14)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 240, 'last_n_outputs': 19, 'leak_rate': 0.9196147374172924, 'lr': 0.0041164313898890996, 'optimizer': 'SGD', 'sparsity': 0.8827471333119505, 'steps_to_train': 39, 'weight_decay': 0.012826413729936724}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4160798708040744, 'info': {'data05': 0.4160798708040744, 'config': "{'batch_size': 64, 'hidden_dim': 240, 'last_n_outputs': 19, 'leak_rate': 0.9196147374172924, 'lr': 0.0041164313898890996, 'optimizer': 'SGD', 'sparsity': 0.8827471333119505, 'steps_to_train': 39, 'weight_decay': 0.012826413729936724}"}}
exception: None

22:57:04 job_callback for (0, 0, 14) started
22:57:04 job_callback for (0, 0, 14) got condition
22:57:04 DISPATCHER: Trying to submit another job.
22:57:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:57:04 HBMASTER: Trying to run another job!
22:57:04 job_callback for (0, 0, 14) finished
22:57:04 start sampling a new configuration.
22:57:04 done sampling a new configuration.
22:57:04 HBMASTER: schedule new run for iteration 0
22:57:04 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
22:57:04 HBMASTER: submitting job (0, 0, 15) to dispatcher
22:57:04 DISPATCHER: trying to submit job (0, 0, 15)
22:57:04 DISPATCHER: trying to notify the job_runner thread.
22:57:04 HBMASTER: job (0, 0, 15) submitted to dispatcher
22:57:04 DISPATCHER: Trying to submit another job.
22:57:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:57:04 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:57:04 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:57:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:57:04 WORKER: start processing job (0, 0, 15)
22:57:04 WORKER: args: ()
22:57:04 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 375, 'last_n_outputs': 15, 'leak_rate': 0.7836795707651639, 'lr': 0.0035827676256598292, 'optimizer': 'Adam', 'sparsity': 0.8347254157484141, 'steps_to_train': 87, 'weight_decay': 0.1328407501123276}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:57:22 DISPATCHER: Starting worker discovery
22:57:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:57:22 DISPATCHER: Finished worker discovery
22:58:01 WORKER: done with job (0, 0, 15), trying to register it.
22:58:01 WORKER: registered result for job (0, 0, 15) with dispatcher
22:58:01 DISPATCHER: job (0, 0, 15) finished
22:58:01 DISPATCHER: register_result: lock acquired
22:58:01 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
22:58:01 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 375, 'last_n_outputs': 15, 'leak_rate': 0.7836795707651639, 'lr': 0.0035827676256598292, 'optimizer': 'Adam', 'sparsity': 0.8347254157484141, 'steps_to_train': 87, 'weight_decay': 0.1328407501123276}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2355458069799879, 'info': {'data05': 0.2355458069799879, 'config': "{'batch_size': 64, 'hidden_dim': 375, 'last_n_outputs': 15, 'leak_rate': 0.7836795707651639, 'lr': 0.0035827676256598292, 'optimizer': 'Adam', 'sparsity': 0.8347254157484141, 'steps_to_train': 87, 'weight_decay': 0.1328407501123276}"}}
exception: None

22:58:01 job_callback for (0, 0, 15) started
22:58:01 DISPATCHER: Trying to submit another job.
22:58:01 job_callback for (0, 0, 15) got condition
22:58:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:58:01 HBMASTER: Trying to run another job!
22:58:01 job_callback for (0, 0, 15) finished
22:58:01 start sampling a new configuration.
22:58:01 done sampling a new configuration.
22:58:01 HBMASTER: schedule new run for iteration 0
22:58:01 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
22:58:01 HBMASTER: submitting job (0, 0, 16) to dispatcher
22:58:01 DISPATCHER: trying to submit job (0, 0, 16)
22:58:01 DISPATCHER: trying to notify the job_runner thread.
22:58:01 HBMASTER: job (0, 0, 16) submitted to dispatcher
22:58:01 DISPATCHER: Trying to submit another job.
22:58:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:58:01 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:58:01 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:58:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:58:01 WORKER: start processing job (0, 0, 16)
22:58:01 WORKER: args: ()
22:58:01 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 765, 'last_n_outputs': 13, 'leak_rate': 0.8458726495870965, 'lr': 0.001105503894109968, 'optimizer': 'Adam', 'sparsity': 0.8177539394066717, 'steps_to_train': 36, 'weight_decay': 0.08301077031399796}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:58:22 DISPATCHER: Starting worker discovery
22:58:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:58:22 DISPATCHER: Finished worker discovery
22:58:58 WORKER: done with job (0, 0, 16), trying to register it.
22:58:58 WORKER: registered result for job (0, 0, 16) with dispatcher
22:58:58 DISPATCHER: job (0, 0, 16) finished
22:58:58 DISPATCHER: register_result: lock acquired
22:58:58 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
22:58:58 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 765, 'last_n_outputs': 13, 'leak_rate': 0.8458726495870965, 'lr': 0.001105503894109968, 'optimizer': 'Adam', 'sparsity': 0.8177539394066717, 'steps_to_train': 36, 'weight_decay': 0.08301077031399796}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.468959218712293, 'info': {'data05': 0.468959218712293, 'config': "{'batch_size': 128, 'hidden_dim': 765, 'last_n_outputs': 13, 'leak_rate': 0.8458726495870965, 'lr': 0.001105503894109968, 'optimizer': 'Adam', 'sparsity': 0.8177539394066717, 'steps_to_train': 36, 'weight_decay': 0.08301077031399796}"}}
exception: None

22:58:58 job_callback for (0, 0, 16) started
22:58:58 DISPATCHER: Trying to submit another job.
22:58:58 job_callback for (0, 0, 16) got condition
22:58:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:58:58 HBMASTER: Trying to run another job!
22:58:58 job_callback for (0, 0, 16) finished
22:58:58 start sampling a new configuration.
22:58:58 done sampling a new configuration.
22:58:58 HBMASTER: schedule new run for iteration 0
22:58:58 HBMASTER: trying submitting job (0, 0, 17) to dispatcher
22:58:58 HBMASTER: submitting job (0, 0, 17) to dispatcher
22:58:58 DISPATCHER: trying to submit job (0, 0, 17)
22:58:58 DISPATCHER: trying to notify the job_runner thread.
22:58:58 HBMASTER: job (0, 0, 17) submitted to dispatcher
22:58:58 DISPATCHER: Trying to submit another job.
22:58:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:58:58 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:58:58 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:58:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:58:58 WORKER: start processing job (0, 0, 17)
22:58:58 WORKER: args: ()
22:58:58 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 293, 'last_n_outputs': 28, 'leak_rate': 0.9341418322412067, 'lr': 0.0041296039004358725, 'optimizer': 'SGD', 'sparsity': 0.8651052907016354, 'steps_to_train': 33, 'weight_decay': 0.09695994833902857}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:59:22 DISPATCHER: Starting worker discovery
22:59:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:59:22 DISPATCHER: Finished worker discovery
22:59:55 WORKER: done with job (0, 0, 17), trying to register it.
22:59:55 WORKER: registered result for job (0, 0, 17) with dispatcher
22:59:55 DISPATCHER: job (0, 0, 17) finished
22:59:55 DISPATCHER: register_result: lock acquired
22:59:55 DISPATCHER: job (0, 0, 17) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
22:59:55 job_id: (0, 0, 17)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 293, 'last_n_outputs': 28, 'leak_rate': 0.9341418322412067, 'lr': 0.0041296039004358725, 'optimizer': 'SGD', 'sparsity': 0.8651052907016354, 'steps_to_train': 33, 'weight_decay': 0.09695994833902857}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5506177440590955, 'info': {'data05': 0.5506177440590955, 'config': "{'batch_size': 16, 'hidden_dim': 293, 'last_n_outputs': 28, 'leak_rate': 0.9341418322412067, 'lr': 0.0041296039004358725, 'optimizer': 'SGD', 'sparsity': 0.8651052907016354, 'steps_to_train': 33, 'weight_decay': 0.09695994833902857}"}}
exception: None

22:59:55 job_callback for (0, 0, 17) started
22:59:55 DISPATCHER: Trying to submit another job.
22:59:55 job_callback for (0, 0, 17) got condition
22:59:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:59:55 HBMASTER: Trying to run another job!
22:59:55 job_callback for (0, 0, 17) finished
22:59:55 start sampling a new configuration.
22:59:55 done sampling a new configuration.
22:59:55 HBMASTER: schedule new run for iteration 0
22:59:55 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
22:59:55 HBMASTER: submitting job (0, 0, 18) to dispatcher
22:59:55 DISPATCHER: trying to submit job (0, 0, 18)
22:59:55 DISPATCHER: trying to notify the job_runner thread.
22:59:55 HBMASTER: job (0, 0, 18) submitted to dispatcher
22:59:55 DISPATCHER: Trying to submit another job.
22:59:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:59:55 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:59:55 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:59:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:59:55 WORKER: start processing job (0, 0, 18)
22:59:55 WORKER: args: ()
22:59:55 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 664, 'last_n_outputs': 27, 'leak_rate': 0.8589217368154246, 'lr': 0.07478047560509206, 'optimizer': 'Adam', 'sparsity': 0.7786874111459591, 'steps_to_train': 43, 'weight_decay': 0.02889715135046347}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:00:22 DISPATCHER: Starting worker discovery
23:00:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:00:22 DISPATCHER: Finished worker discovery
23:00:53 WORKER: done with job (0, 0, 18), trying to register it.
23:00:53 WORKER: registered result for job (0, 0, 18) with dispatcher
23:00:53 DISPATCHER: job (0, 0, 18) finished
23:00:53 DISPATCHER: register_result: lock acquired
23:00:53 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:00:53 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 664, 'last_n_outputs': 27, 'leak_rate': 0.8589217368154246, 'lr': 0.07478047560509206, 'optimizer': 'Adam', 'sparsity': 0.7786874111459591, 'steps_to_train': 43, 'weight_decay': 0.02889715135046347}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0754249421288646, 'info': {'data05': 0.0754249421288646, 'config': "{'batch_size': 16, 'hidden_dim': 664, 'last_n_outputs': 27, 'leak_rate': 0.8589217368154246, 'lr': 0.07478047560509206, 'optimizer': 'Adam', 'sparsity': 0.7786874111459591, 'steps_to_train': 43, 'weight_decay': 0.02889715135046347}"}}
exception: None

23:00:53 job_callback for (0, 0, 18) started
23:00:53 job_callback for (0, 0, 18) got condition
23:00:53 DISPATCHER: Trying to submit another job.
23:00:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:00:53 HBMASTER: Trying to run another job!
23:00:53 job_callback for (0, 0, 18) finished
23:00:53 start sampling a new configuration.
23:00:53 done sampling a new configuration.
23:00:53 HBMASTER: schedule new run for iteration 0
23:00:53 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
23:00:53 HBMASTER: submitting job (0, 0, 19) to dispatcher
23:00:53 DISPATCHER: trying to submit job (0, 0, 19)
23:00:53 DISPATCHER: trying to notify the job_runner thread.
23:00:53 HBMASTER: job (0, 0, 19) submitted to dispatcher
23:00:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:00:53 DISPATCHER: Trying to submit another job.
23:00:53 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:00:53 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:00:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:00:53 WORKER: start processing job (0, 0, 19)
23:00:53 WORKER: args: ()
23:00:53 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 693, 'last_n_outputs': 41, 'leak_rate': 0.9420026048978825, 'lr': 0.0011472292777285505, 'optimizer': 'SGD', 'sparsity': 0.832154359044843, 'steps_to_train': 10, 'weight_decay': 0.024056600439953585}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:01:22 DISPATCHER: Starting worker discovery
23:01:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:01:22 DISPATCHER: Finished worker discovery
23:01:51 WORKER: done with job (0, 0, 19), trying to register it.
23:01:51 WORKER: registered result for job (0, 0, 19) with dispatcher
23:01:51 DISPATCHER: job (0, 0, 19) finished
23:01:51 DISPATCHER: register_result: lock acquired
23:01:51 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:01:51 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 693, 'last_n_outputs': 41, 'leak_rate': 0.9420026048978825, 'lr': 0.0011472292777285505, 'optimizer': 'SGD', 'sparsity': 0.832154359044843, 'steps_to_train': 10, 'weight_decay': 0.024056600439953585}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5803071592256591, 'info': {'data05': 0.5803071592256591, 'config': "{'batch_size': 64, 'hidden_dim': 693, 'last_n_outputs': 41, 'leak_rate': 0.9420026048978825, 'lr': 0.0011472292777285505, 'optimizer': 'SGD', 'sparsity': 0.832154359044843, 'steps_to_train': 10, 'weight_decay': 0.024056600439953585}"}}
exception: None

23:01:51 job_callback for (0, 0, 19) started
23:01:51 DISPATCHER: Trying to submit another job.
23:01:51 job_callback for (0, 0, 19) got condition
23:01:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:01:51 done building a new model for budget 44.444444 based on 10/17 split
Best loss for this budget:-0.756787





23:01:51 HBMASTER: Trying to run another job!
23:01:51 job_callback for (0, 0, 19) finished
23:01:51 start sampling a new configuration.
23:01:51 best_vector: [3, 0.5704832739245244, 0.9200448790176933, 0.8955954209810175, 0.21238568886142017, 1, 0.14083048713804924, 0.00163834866129009, 0.5513405916816233], 0.00012929667411405322, 0.10518547255964347, 1.360013176707691e-05
23:01:51 done sampling a new configuration.
23:01:51 HBMASTER: schedule new run for iteration 0
23:01:51 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
23:01:51 HBMASTER: submitting job (0, 0, 20) to dispatcher
23:01:51 DISPATCHER: trying to submit job (0, 0, 20)
23:01:51 DISPATCHER: trying to notify the job_runner thread.
23:01:51 HBMASTER: job (0, 0, 20) submitted to dispatcher
23:01:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:01:51 DISPATCHER: Trying to submit another job.
23:01:51 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:01:51 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:01:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:01:51 WORKER: start processing job (0, 0, 20)
23:01:51 WORKER: args: ()
23:01:51 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 656, 'last_n_outputs': 47, 'leak_rate': 0.9738988552452543, 'lr': 0.002659324763539236, 'optimizer': 'SGD', 'sparsity': 0.7837993169131319, 'steps_to_train': 10, 'weight_decay': 0.05215676511607621}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:02:22 DISPATCHER: Starting worker discovery
23:02:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:02:22 DISPATCHER: Finished worker discovery
23:02:48 WORKER: done with job (0, 0, 20), trying to register it.
23:02:48 WORKER: registered result for job (0, 0, 20) with dispatcher
23:02:48 DISPATCHER: job (0, 0, 20) finished
23:02:48 DISPATCHER: register_result: lock acquired
23:02:48 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:02:48 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 656, 'last_n_outputs': 47, 'leak_rate': 0.9738988552452543, 'lr': 0.002659324763539236, 'optimizer': 'SGD', 'sparsity': 0.7837993169131319, 'steps_to_train': 10, 'weight_decay': 0.05215676511607621}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.649355796349875, 'info': {'data05': 0.649355796349875, 'config': "{'batch_size': 128, 'hidden_dim': 656, 'last_n_outputs': 47, 'leak_rate': 0.9738988552452543, 'lr': 0.002659324763539236, 'optimizer': 'SGD', 'sparsity': 0.7837993169131319, 'steps_to_train': 10, 'weight_decay': 0.05215676511607621}"}}
exception: None

23:02:48 job_callback for (0, 0, 20) started
23:02:48 job_callback for (0, 0, 20) got condition
23:02:48 DISPATCHER: Trying to submit another job.
23:02:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:02:48 done building a new model for budget 44.444444 based on 10/17 split
Best loss for this budget:-0.756787





23:02:48 HBMASTER: Trying to run another job!
23:02:48 job_callback for (0, 0, 20) finished
23:02:48 start sampling a new configuration.
23:02:48 best_vector: [1, 0.792607837115317, 0.009640040248717396, 0.7791972060653712, 0.07016460563491252, 1, 0.1856639433994976, 0.4292767527524671, 0.2846424553351603], 0.002249118050270279, 0.04558324548193271, 0.00010252210020331599
23:02:48 done sampling a new configuration.
23:02:48 HBMASTER: schedule new run for iteration 0
23:02:48 HBMASTER: trying submitting job (0, 0, 21) to dispatcher
23:02:48 HBMASTER: submitting job (0, 0, 21) to dispatcher
23:02:48 DISPATCHER: trying to submit job (0, 0, 21)
23:02:48 DISPATCHER: trying to notify the job_runner thread.
23:02:48 HBMASTER: job (0, 0, 21) submitted to dispatcher
23:02:48 DISPATCHER: Trying to submit another job.
23:02:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:02:48 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:02:48 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:02:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:02:48 WORKER: start processing job (0, 0, 21)
23:02:48 WORKER: args: ()
23:02:48 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 834, 'last_n_outputs': 10, 'leak_rate': 0.9447993015163428, 'lr': 0.0013814310435961528, 'optimizer': 'SGD', 'sparsity': 0.7945593464158794, 'steps_to_train': 49, 'weight_decay': 0.023460019697960483}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:03:22 DISPATCHER: Starting worker discovery
23:03:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:03:22 DISPATCHER: Finished worker discovery
23:03:45 WORKER: done with job (0, 0, 21), trying to register it.
23:03:45 WORKER: registered result for job (0, 0, 21) with dispatcher
23:03:45 DISPATCHER: job (0, 0, 21) finished
23:03:45 DISPATCHER: register_result: lock acquired
23:03:45 DISPATCHER: job (0, 0, 21) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:03:45 job_id: (0, 0, 21)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 834, 'last_n_outputs': 10, 'leak_rate': 0.9447993015163428, 'lr': 0.0013814310435961528, 'optimizer': 'SGD', 'sparsity': 0.7945593464158794, 'steps_to_train': 49, 'weight_decay': 0.023460019697960483}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.364994681034381, 'info': {'data05': 0.364994681034381, 'config': "{'batch_size': 32, 'hidden_dim': 834, 'last_n_outputs': 10, 'leak_rate': 0.9447993015163428, 'lr': 0.0013814310435961528, 'optimizer': 'SGD', 'sparsity': 0.7945593464158794, 'steps_to_train': 49, 'weight_decay': 0.023460019697960483}"}}
exception: None

23:03:45 job_callback for (0, 0, 21) started
23:03:45 job_callback for (0, 0, 21) got condition
23:03:45 DISPATCHER: Trying to submit another job.
23:03:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:03:45 done building a new model for budget 44.444444 based on 10/18 split
Best loss for this budget:-0.756787





23:03:45 HBMASTER: Trying to run another job!
23:03:45 job_callback for (0, 0, 21) finished
23:03:45 start sampling a new configuration.
23:03:46 best_vector: [0, 0.8525473785355138, 0.8622573208869421, 0.3216152940203056, 0.806845860651943, 1, 0.5058673184302855, 0.9807617379350211, 0.031835604533587324], 0.0011556930192663855, 0.24061299065324065, 0.0002780747536427583
23:03:46 done sampling a new configuration.
23:03:46 HBMASTER: schedule new run for iteration 0
23:03:46 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
23:03:46 HBMASTER: submitting job (0, 0, 22) to dispatcher
23:03:46 DISPATCHER: trying to submit job (0, 0, 22)
23:03:46 DISPATCHER: trying to notify the job_runner thread.
23:03:46 HBMASTER: job (0, 0, 22) submitted to dispatcher
23:03:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:03:46 DISPATCHER: Trying to submit another job.
23:03:46 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:03:46 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:03:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:03:46 WORKER: start processing job (0, 0, 22)
23:03:46 WORKER: args: ()
23:03:46 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 882, 'last_n_outputs': 45, 'leak_rate': 0.8304038235050764, 'lr': 0.04108579749959848, 'optimizer': 'SGD', 'sparsity': 0.8714081564232685, 'steps_to_train': 99, 'weight_decay': 0.01100066846990613}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:04:22 DISPATCHER: Starting worker discovery
23:04:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:04:22 DISPATCHER: Finished worker discovery
23:04:48 WORKER: done with job (0, 0, 22), trying to register it.
23:04:48 WORKER: registered result for job (0, 0, 22) with dispatcher
23:04:48 DISPATCHER: job (0, 0, 22) finished
23:04:48 DISPATCHER: register_result: lock acquired
23:04:48 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:04:48 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 882, 'last_n_outputs': 45, 'leak_rate': 0.8304038235050764, 'lr': 0.04108579749959848, 'optimizer': 'SGD', 'sparsity': 0.8714081564232685, 'steps_to_train': 99, 'weight_decay': 0.01100066846990613}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7349056597260263, 'info': {'data05': 0.7349056597260263, 'config': "{'batch_size': 16, 'hidden_dim': 882, 'last_n_outputs': 45, 'leak_rate': 0.8304038235050764, 'lr': 0.04108579749959848, 'optimizer': 'SGD', 'sparsity': 0.8714081564232685, 'steps_to_train': 99, 'weight_decay': 0.01100066846990613}"}}
exception: None

23:04:48 DISPATCHER: Trying to submit another job.
23:04:48 job_callback for (0, 0, 22) started
23:04:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:04:48 job_callback for (0, 0, 22) got condition
23:04:48 done building a new model for budget 44.444444 based on 10/19 split
Best loss for this budget:-0.756787





23:04:48 HBMASTER: Trying to run another job!
23:04:48 job_callback for (0, 0, 22) finished
23:04:48 start sampling a new configuration.
23:04:48 done sampling a new configuration.
23:04:48 HBMASTER: schedule new run for iteration 0
23:04:48 HBMASTER: trying submitting job (0, 0, 23) to dispatcher
23:04:48 HBMASTER: submitting job (0, 0, 23) to dispatcher
23:04:48 DISPATCHER: trying to submit job (0, 0, 23)
23:04:48 DISPATCHER: trying to notify the job_runner thread.
23:04:48 HBMASTER: job (0, 0, 23) submitted to dispatcher
23:04:48 DISPATCHER: Trying to submit another job.
23:04:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:04:48 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:04:48 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:04:48 WORKER: start processing job (0, 0, 23)
23:04:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:04:48 WORKER: args: ()
23:04:48 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 786, 'last_n_outputs': 18, 'leak_rate': 0.833119170019827, 'lr': 0.03351868097772142, 'optimizer': 'Adam', 'sparsity': 0.9252350423391008, 'steps_to_train': 92, 'weight_decay': 0.016165488040307534}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:05:22 DISPATCHER: Starting worker discovery
23:05:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:05:22 DISPATCHER: Finished worker discovery
23:05:49 WORKER: done with job (0, 0, 23), trying to register it.
23:05:49 WORKER: registered result for job (0, 0, 23) with dispatcher
23:05:49 DISPATCHER: job (0, 0, 23) finished
23:05:49 DISPATCHER: register_result: lock acquired
23:05:49 DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:05:49 job_id: (0, 0, 23)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 786, 'last_n_outputs': 18, 'leak_rate': 0.833119170019827, 'lr': 0.03351868097772142, 'optimizer': 'Adam', 'sparsity': 0.9252350423391008, 'steps_to_train': 92, 'weight_decay': 0.016165488040307534}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.24909794660100087, 'info': {'data05': 0.24909794660100087, 'config': "{'batch_size': 16, 'hidden_dim': 786, 'last_n_outputs': 18, 'leak_rate': 0.833119170019827, 'lr': 0.03351868097772142, 'optimizer': 'Adam', 'sparsity': 0.9252350423391008, 'steps_to_train': 92, 'weight_decay': 0.016165488040307534}"}}
exception: None

23:05:49 job_callback for (0, 0, 23) started
23:05:49 job_callback for (0, 0, 23) got condition
23:05:49 DISPATCHER: Trying to submit another job.
23:05:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:05:49 done building a new model for budget 44.444444 based on 10/20 split
Best loss for this budget:-0.756787





23:05:49 HBMASTER: Trying to run another job!
23:05:49 job_callback for (0, 0, 23) finished
23:05:49 start sampling a new configuration.
23:05:49 best_vector: [2, 0.5445189173464279, 0.9760234893171027, 0.9885699703080917, 0.042353727653823225, 1, 0.809247358511038, 0.3248336438095809, 0.4413942146907738], 0.0009365012758740614, 0.09286429171401911, 8.696752767331992e-05
23:05:49 done sampling a new configuration.
23:05:49 HBMASTER: schedule new run for iteration 0
23:05:49 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
23:05:49 HBMASTER: submitting job (0, 0, 24) to dispatcher
23:05:49 DISPATCHER: trying to submit job (0, 0, 24)
23:05:49 DISPATCHER: trying to notify the job_runner thread.
23:05:49 HBMASTER: job (0, 0, 24) submitted to dispatcher
23:05:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:05:49 DISPATCHER: Trying to submit another job.
23:05:49 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:05:49 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:05:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:05:49 WORKER: start processing job (0, 0, 24)
23:05:49 WORKER: args: ()
23:05:49 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 636, 'last_n_outputs': 50, 'leak_rate': 0.9971424925770229, 'lr': 0.0012153670426124478, 'optimizer': 'SGD', 'sparsity': 0.9442193660426491, 'steps_to_train': 39, 'weight_decay': 0.03752037006778302}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:06:22 DISPATCHER: Starting worker discovery
23:06:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:06:22 DISPATCHER: Finished worker discovery
23:06:47 WORKER: done with job (0, 0, 24), trying to register it.
23:06:47 WORKER: registered result for job (0, 0, 24) with dispatcher
23:06:47 DISPATCHER: job (0, 0, 24) finished
23:06:47 DISPATCHER: register_result: lock acquired
23:06:47 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:06:47 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 636, 'last_n_outputs': 50, 'leak_rate': 0.9971424925770229, 'lr': 0.0012153670426124478, 'optimizer': 'SGD', 'sparsity': 0.9442193660426491, 'steps_to_train': 39, 'weight_decay': 0.03752037006778302}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6284520616371897, 'info': {'data05': 0.6284520616371897, 'config': "{'batch_size': 64, 'hidden_dim': 636, 'last_n_outputs': 50, 'leak_rate': 0.9971424925770229, 'lr': 0.0012153670426124478, 'optimizer': 'SGD', 'sparsity': 0.9442193660426491, 'steps_to_train': 39, 'weight_decay': 0.03752037006778302}"}}
exception: None

23:06:47 job_callback for (0, 0, 24) started
23:06:47 DISPATCHER: Trying to submit another job.
23:06:47 job_callback for (0, 0, 24) got condition
23:06:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:06:47 done building a new model for budget 44.444444 based on 10/21 split
Best loss for this budget:-0.756787





23:06:47 HBMASTER: Trying to run another job!
23:06:47 job_callback for (0, 0, 24) finished
23:06:47 start sampling a new configuration.
23:06:47 done sampling a new configuration.
23:06:47 HBMASTER: schedule new run for iteration 0
23:06:47 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
23:06:47 HBMASTER: submitting job (0, 0, 25) to dispatcher
23:06:47 DISPATCHER: trying to submit job (0, 0, 25)
23:06:47 DISPATCHER: trying to notify the job_runner thread.
23:06:47 HBMASTER: job (0, 0, 25) submitted to dispatcher
23:06:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:06:47 DISPATCHER: Trying to submit another job.
23:06:47 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:06:47 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:06:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:06:47 WORKER: start processing job (0, 0, 25)
23:06:47 WORKER: args: ()
23:06:47 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 267, 'last_n_outputs': 22, 'leak_rate': 0.7904355419292535, 'lr': 0.06391995852288714, 'optimizer': 'SGD', 'sparsity': 0.8032425246936347, 'steps_to_train': 36, 'weight_decay': 0.09740767801515102}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:07:22 DISPATCHER: Starting worker discovery
23:07:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:07:22 DISPATCHER: Finished worker discovery
23:07:46 WORKER: done with job (0, 0, 25), trying to register it.
23:07:46 WORKER: registered result for job (0, 0, 25) with dispatcher
23:07:46 DISPATCHER: job (0, 0, 25) finished
23:07:46 DISPATCHER: register_result: lock acquired
23:07:46 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:07:46 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 267, 'last_n_outputs': 22, 'leak_rate': 0.7904355419292535, 'lr': 0.06391995852288714, 'optimizer': 'SGD', 'sparsity': 0.8032425246936347, 'steps_to_train': 36, 'weight_decay': 0.09740767801515102}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1581723502418103, 'info': {'data05': 0.1581723502418103, 'config': "{'batch_size': 16, 'hidden_dim': 267, 'last_n_outputs': 22, 'leak_rate': 0.7904355419292535, 'lr': 0.06391995852288714, 'optimizer': 'SGD', 'sparsity': 0.8032425246936347, 'steps_to_train': 36, 'weight_decay': 0.09740767801515102}"}}
exception: None

23:07:46 job_callback for (0, 0, 25) started
23:07:46 job_callback for (0, 0, 25) got condition
23:07:46 DISPATCHER: Trying to submit another job.
23:07:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:07:46 done building a new model for budget 44.444444 based on 10/22 split
Best loss for this budget:-0.756787





23:07:46 HBMASTER: Trying to run another job!
23:07:46 job_callback for (0, 0, 25) finished
23:07:46 start sampling a new configuration.
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/statsmodels/nonparametric/kernels.py:62: RuntimeWarning: divide by zero encountered in true_divide
  kernel_value = np.ones(Xi.size) * h / (num_levels - 1)
23:07:46 best_vector: [0, 0.9978680040701149, 0.9242394928386033, 0.14352932067563257, 0.05982820814271163, 1, 0.9946149338913552, 0.499164811352781, 0.4231383381044962], 0.0003686901790639977, 0.10121907455380048, 3.7318478721932834e-05
23:07:46 done sampling a new configuration.
23:07:46 HBMASTER: schedule new run for iteration 0
23:07:46 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
23:07:46 HBMASTER: submitting job (0, 0, 26) to dispatcher
23:07:46 DISPATCHER: trying to submit job (0, 0, 26)
23:07:46 DISPATCHER: trying to notify the job_runner thread.
23:07:46 HBMASTER: job (0, 0, 26) submitted to dispatcher
23:07:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:07:46 DISPATCHER: Trying to submit another job.
23:07:46 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:07:46 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:07:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:07:46 WORKER: start processing job (0, 0, 26)
23:07:46 WORKER: args: ()
23:07:46 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 999, 'last_n_outputs': 47, 'leak_rate': 0.7858823301689082, 'lr': 0.0013172142375598068, 'optimizer': 'SGD', 'sparsity': 0.9887075841339252, 'steps_to_train': 55, 'weight_decay': 0.03552349358182905}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:08:22 DISPATCHER: Starting worker discovery
23:08:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:08:22 DISPATCHER: Finished worker discovery
23:08:43 WORKER: done with job (0, 0, 26), trying to register it.
23:08:43 WORKER: registered result for job (0, 0, 26) with dispatcher
23:08:43 DISPATCHER: job (0, 0, 26) finished
23:08:43 DISPATCHER: register_result: lock acquired
23:08:43 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:08:43 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 999, 'last_n_outputs': 47, 'leak_rate': 0.7858823301689082, 'lr': 0.0013172142375598068, 'optimizer': 'SGD', 'sparsity': 0.9887075841339252, 'steps_to_train': 55, 'weight_decay': 0.03552349358182905}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.655333817190858, 'info': {'data05': 0.655333817190858, 'config': "{'batch_size': 16, 'hidden_dim': 999, 'last_n_outputs': 47, 'leak_rate': 0.7858823301689082, 'lr': 0.0013172142375598068, 'optimizer': 'SGD', 'sparsity': 0.9887075841339252, 'steps_to_train': 55, 'weight_decay': 0.03552349358182905}"}}
exception: None

23:08:43 job_callback for (0, 0, 26) started
23:08:43 job_callback for (0, 0, 26) got condition
23:08:43 DISPATCHER: Trying to submit another job.
23:08:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:08:43 done building a new model for budget 44.444444 based on 10/22 split
Best loss for this budget:-0.756787





23:08:43 HBMASTER: Trying to run another job!
23:08:43 job_callback for (0, 0, 26) finished
23:08:43 ITERATION: Advancing config (0, 0, 5) to next budget 133.333333
23:08:43 ITERATION: Advancing config (0, 0, 7) to next budget 133.333333
23:08:43 ITERATION: Advancing config (0, 0, 8) to next budget 133.333333
23:08:43 ITERATION: Advancing config (0, 0, 11) to next budget 133.333333
23:08:43 ITERATION: Advancing config (0, 0, 19) to next budget 133.333333
23:08:43 ITERATION: Advancing config (0, 0, 20) to next budget 133.333333
23:08:43 ITERATION: Advancing config (0, 0, 22) to next budget 133.333333
23:08:43 ITERATION: Advancing config (0, 0, 24) to next budget 133.333333
23:08:43 ITERATION: Advancing config (0, 0, 26) to next budget 133.333333
23:08:43 HBMASTER: schedule new run for iteration 0
23:08:43 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
23:08:43 HBMASTER: submitting job (0, 0, 5) to dispatcher
23:08:43 DISPATCHER: trying to submit job (0, 0, 5)
23:08:43 DISPATCHER: trying to notify the job_runner thread.
23:08:43 HBMASTER: job (0, 0, 5) submitted to dispatcher
23:08:43 DISPATCHER: Trying to submit another job.
23:08:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:08:43 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:08:43 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:08:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:08:43 WORKER: start processing job (0, 0, 5)
23:08:43 WORKER: args: ()
23:08:43 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 993, 'last_n_outputs': 38, 'leak_rate': 0.8370780530009059, 'lr': 0.04269315588254884, 'optimizer': 'SGD', 'sparsity': 0.9401581960445465, 'steps_to_train': 100, 'weight_decay': 0.010702851945979875}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:09:22 DISPATCHER: Starting worker discovery
23:09:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:09:22 DISPATCHER: Finished worker discovery
23:10:22 DISPATCHER: Starting worker discovery
23:10:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:10:22 DISPATCHER: Finished worker discovery
23:11:16 WORKER: done with job (0, 0, 5), trying to register it.
23:11:16 WORKER: registered result for job (0, 0, 5) with dispatcher
23:11:16 DISPATCHER: job (0, 0, 5) finished
23:11:16 DISPATCHER: register_result: lock acquired
23:11:16 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:11:16 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 993, 'last_n_outputs': 38, 'leak_rate': 0.8370780530009059, 'lr': 0.04269315588254884, 'optimizer': 'SGD', 'sparsity': 0.9401581960445465, 'steps_to_train': 100, 'weight_decay': 0.010702851945979875}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.720154251251103, 'info': {'data05': 0.720154251251103, 'config': "{'batch_size': 128, 'hidden_dim': 993, 'last_n_outputs': 38, 'leak_rate': 0.8370780530009059, 'lr': 0.04269315588254884, 'optimizer': 'SGD', 'sparsity': 0.9401581960445465, 'steps_to_train': 100, 'weight_decay': 0.010702851945979875}"}}
exception: None

23:11:16 job_callback for (0, 0, 5) started
23:11:16 DISPATCHER: Trying to submit another job.
23:11:16 job_callback for (0, 0, 5) got condition
23:11:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:11:16 Only 1 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
23:11:16 HBMASTER: Trying to run another job!
23:11:16 job_callback for (0, 0, 5) finished
23:11:16 HBMASTER: schedule new run for iteration 0
23:11:16 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
23:11:16 HBMASTER: submitting job (0, 0, 7) to dispatcher
23:11:16 DISPATCHER: trying to submit job (0, 0, 7)
23:11:16 DISPATCHER: trying to notify the job_runner thread.
23:11:16 HBMASTER: job (0, 0, 7) submitted to dispatcher
23:11:16 DISPATCHER: Trying to submit another job.
23:11:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:11:16 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:11:16 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:11:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:11:16 WORKER: start processing job (0, 0, 7)
23:11:16 WORKER: args: ()
23:11:16 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 304, 'last_n_outputs': 44, 'leak_rate': 0.8454013769665221, 'lr': 0.03283994206507779, 'optimizer': 'SGD', 'sparsity': 0.9416829915152293, 'steps_to_train': 50, 'weight_decay': 0.016065976288656286}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:11:22 DISPATCHER: Starting worker discovery
23:11:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:11:22 DISPATCHER: Finished worker discovery
23:12:22 DISPATCHER: Starting worker discovery
23:12:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:12:22 DISPATCHER: Finished worker discovery
23:13:22 DISPATCHER: Starting worker discovery
23:13:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:13:22 DISPATCHER: Finished worker discovery
23:13:46 WORKER: done with job (0, 0, 7), trying to register it.
23:13:46 WORKER: registered result for job (0, 0, 7) with dispatcher
23:13:46 DISPATCHER: job (0, 0, 7) finished
23:13:46 DISPATCHER: register_result: lock acquired
23:13:46 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:13:46 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 304, 'last_n_outputs': 44, 'leak_rate': 0.8454013769665221, 'lr': 0.03283994206507779, 'optimizer': 'SGD', 'sparsity': 0.9416829915152293, 'steps_to_train': 50, 'weight_decay': 0.016065976288656286}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7088656892204069, 'info': {'data05': 0.7088656892204069, 'config': "{'batch_size': 64, 'hidden_dim': 304, 'last_n_outputs': 44, 'leak_rate': 0.8454013769665221, 'lr': 0.03283994206507779, 'optimizer': 'SGD', 'sparsity': 0.9416829915152293, 'steps_to_train': 50, 'weight_decay': 0.016065976288656286}"}}
exception: None

23:13:46 job_callback for (0, 0, 7) started
23:13:46 DISPATCHER: Trying to submit another job.
23:13:46 job_callback for (0, 0, 7) got condition
23:13:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:13:46 Only 2 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
23:13:46 HBMASTER: Trying to run another job!
23:13:46 job_callback for (0, 0, 7) finished
23:13:46 HBMASTER: schedule new run for iteration 0
23:13:46 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
23:13:46 HBMASTER: submitting job (0, 0, 8) to dispatcher
23:13:46 DISPATCHER: trying to submit job (0, 0, 8)
23:13:46 DISPATCHER: trying to notify the job_runner thread.
23:13:46 HBMASTER: job (0, 0, 8) submitted to dispatcher
23:13:46 DISPATCHER: Trying to submit another job.
23:13:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:13:46 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:13:46 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:13:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:13:46 WORKER: start processing job (0, 0, 8)
23:13:46 WORKER: args: ()
23:13:46 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 855, 'last_n_outputs': 44, 'leak_rate': 0.8927030492189386, 'lr': 0.0019568121476006813, 'optimizer': 'SGD', 'sparsity': 0.9489950724201204, 'steps_to_train': 23, 'weight_decay': 0.027098171454306475}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:14:22 DISPATCHER: Starting worker discovery
23:14:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:14:22 DISPATCHER: Finished worker discovery
23:15:22 DISPATCHER: Starting worker discovery
23:15:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:15:22 DISPATCHER: Finished worker discovery
23:16:14 WORKER: done with job (0, 0, 8), trying to register it.
23:16:14 WORKER: registered result for job (0, 0, 8) with dispatcher
23:16:14 DISPATCHER: job (0, 0, 8) finished
23:16:14 DISPATCHER: register_result: lock acquired
23:16:14 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:16:14 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 855, 'last_n_outputs': 44, 'leak_rate': 0.8927030492189386, 'lr': 0.0019568121476006813, 'optimizer': 'SGD', 'sparsity': 0.9489950724201204, 'steps_to_train': 23, 'weight_decay': 0.027098171454306475}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7373006401077664, 'info': {'data05': 0.7373006401077664, 'config': "{'batch_size': 128, 'hidden_dim': 855, 'last_n_outputs': 44, 'leak_rate': 0.8927030492189386, 'lr': 0.0019568121476006813, 'optimizer': 'SGD', 'sparsity': 0.9489950724201204, 'steps_to_train': 23, 'weight_decay': 0.027098171454306475}"}}
exception: None

23:16:14 job_callback for (0, 0, 8) started
23:16:14 DISPATCHER: Trying to submit another job.
23:16:14 job_callback for (0, 0, 8) got condition
23:16:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:16:14 Only 3 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
23:16:14 HBMASTER: Trying to run another job!
23:16:14 job_callback for (0, 0, 8) finished
23:16:14 HBMASTER: schedule new run for iteration 0
23:16:14 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
23:16:14 HBMASTER: submitting job (0, 0, 11) to dispatcher
23:16:14 DISPATCHER: trying to submit job (0, 0, 11)
23:16:14 DISPATCHER: trying to notify the job_runner thread.
23:16:14 HBMASTER: job (0, 0, 11) submitted to dispatcher
23:16:14 DISPATCHER: Trying to submit another job.
23:16:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:16:14 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:16:14 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:16:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:16:14 WORKER: start processing job (0, 0, 11)
23:16:14 WORKER: args: ()
23:16:14 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 987, 'last_n_outputs': 49, 'leak_rate': 0.9925223501264618, 'lr': 0.011866833529571635, 'optimizer': 'SGD', 'sparsity': 0.8128538944226172, 'steps_to_train': 93, 'weight_decay': 0.04240512958885776}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:16:22 DISPATCHER: Starting worker discovery
23:16:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:16:22 DISPATCHER: Finished worker discovery
23:17:22 DISPATCHER: Starting worker discovery
23:17:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:17:22 DISPATCHER: Finished worker discovery
23:18:22 DISPATCHER: Starting worker discovery
23:18:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:18:22 DISPATCHER: Finished worker discovery
23:18:39 WORKER: done with job (0, 0, 11), trying to register it.
23:18:39 WORKER: registered result for job (0, 0, 11) with dispatcher
23:18:39 DISPATCHER: job (0, 0, 11) finished
23:18:39 DISPATCHER: register_result: lock acquired
23:18:39 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:18:39 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 987, 'last_n_outputs': 49, 'leak_rate': 0.9925223501264618, 'lr': 0.011866833529571635, 'optimizer': 'SGD', 'sparsity': 0.8128538944226172, 'steps_to_train': 93, 'weight_decay': 0.04240512958885776}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.746096789022657, 'info': {'data05': 0.746096789022657, 'config': "{'batch_size': 64, 'hidden_dim': 987, 'last_n_outputs': 49, 'leak_rate': 0.9925223501264618, 'lr': 0.011866833529571635, 'optimizer': 'SGD', 'sparsity': 0.8128538944226172, 'steps_to_train': 93, 'weight_decay': 0.04240512958885776}"}}
exception: None

23:18:39 job_callback for (0, 0, 11) started
23:18:39 job_callback for (0, 0, 11) got condition
23:18:39 DISPATCHER: Trying to submit another job.
23:18:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:18:39 Only 4 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
23:18:39 HBMASTER: Trying to run another job!
23:18:39 job_callback for (0, 0, 11) finished
23:18:39 HBMASTER: schedule new run for iteration 0
23:18:39 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
23:18:39 HBMASTER: submitting job (0, 0, 19) to dispatcher
23:18:39 DISPATCHER: trying to submit job (0, 0, 19)
23:18:39 DISPATCHER: trying to notify the job_runner thread.
23:18:39 HBMASTER: job (0, 0, 19) submitted to dispatcher
23:18:39 DISPATCHER: Trying to submit another job.
23:18:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:18:39 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:18:39 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:18:39 WORKER: start processing job (0, 0, 19)
23:18:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:18:39 WORKER: args: ()
23:18:39 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 693, 'last_n_outputs': 41, 'leak_rate': 0.9420026048978825, 'lr': 0.0011472292777285505, 'optimizer': 'SGD', 'sparsity': 0.832154359044843, 'steps_to_train': 10, 'weight_decay': 0.024056600439953585}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:19:22 DISPATCHER: Starting worker discovery
23:19:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:19:22 DISPATCHER: Finished worker discovery
23:20:22 DISPATCHER: Starting worker discovery
23:20:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:20:22 DISPATCHER: Finished worker discovery
23:21:09 WORKER: done with job (0, 0, 19), trying to register it.
23:21:09 WORKER: registered result for job (0, 0, 19) with dispatcher
23:21:09 DISPATCHER: job (0, 0, 19) finished
23:21:09 DISPATCHER: register_result: lock acquired
23:21:09 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:21:09 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 693, 'last_n_outputs': 41, 'leak_rate': 0.9420026048978825, 'lr': 0.0011472292777285505, 'optimizer': 'SGD', 'sparsity': 0.832154359044843, 'steps_to_train': 10, 'weight_decay': 0.024056600439953585}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6405092576940751, 'info': {'data05': 0.6405092576940751, 'config': "{'batch_size': 64, 'hidden_dim': 693, 'last_n_outputs': 41, 'leak_rate': 0.9420026048978825, 'lr': 0.0011472292777285505, 'optimizer': 'SGD', 'sparsity': 0.832154359044843, 'steps_to_train': 10, 'weight_decay': 0.024056600439953585}"}}
exception: None

23:21:09 job_callback for (0, 0, 19) started
23:21:09 DISPATCHER: Trying to submit another job.
23:21:09 job_callback for (0, 0, 19) got condition
23:21:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:21:09 Only 5 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
23:21:09 HBMASTER: Trying to run another job!
23:21:09 job_callback for (0, 0, 19) finished
23:21:09 HBMASTER: schedule new run for iteration 0
23:21:09 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
23:21:09 HBMASTER: submitting job (0, 0, 20) to dispatcher
23:21:09 DISPATCHER: trying to submit job (0, 0, 20)
23:21:09 DISPATCHER: trying to notify the job_runner thread.
23:21:09 HBMASTER: job (0, 0, 20) submitted to dispatcher
23:21:09 DISPATCHER: Trying to submit another job.
23:21:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:21:09 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:21:09 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:21:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:21:09 WORKER: start processing job (0, 0, 20)
23:21:09 WORKER: args: ()
23:21:09 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 656, 'last_n_outputs': 47, 'leak_rate': 0.9738988552452543, 'lr': 0.002659324763539236, 'optimizer': 'SGD', 'sparsity': 0.7837993169131319, 'steps_to_train': 10, 'weight_decay': 0.05215676511607621}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:21:22 DISPATCHER: Starting worker discovery
23:21:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:21:22 DISPATCHER: Finished worker discovery
23:22:22 DISPATCHER: Starting worker discovery
23:22:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:22:22 DISPATCHER: Finished worker discovery
23:23:22 DISPATCHER: Starting worker discovery
23:23:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:23:22 DISPATCHER: Finished worker discovery
23:23:37 WORKER: done with job (0, 0, 20), trying to register it.
23:23:37 WORKER: registered result for job (0, 0, 20) with dispatcher
23:23:37 DISPATCHER: job (0, 0, 20) finished
23:23:37 DISPATCHER: register_result: lock acquired
23:23:37 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:23:37 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 656, 'last_n_outputs': 47, 'leak_rate': 0.9738988552452543, 'lr': 0.002659324763539236, 'optimizer': 'SGD', 'sparsity': 0.7837993169131319, 'steps_to_train': 10, 'weight_decay': 0.05215676511607621}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7207805506175861, 'info': {'data05': 0.7207805506175861, 'config': "{'batch_size': 128, 'hidden_dim': 656, 'last_n_outputs': 47, 'leak_rate': 0.9738988552452543, 'lr': 0.002659324763539236, 'optimizer': 'SGD', 'sparsity': 0.7837993169131319, 'steps_to_train': 10, 'weight_decay': 0.05215676511607621}"}}
exception: None

23:23:37 job_callback for (0, 0, 20) started
23:23:37 job_callback for (0, 0, 20) got condition
23:23:37 DISPATCHER: Trying to submit another job.
23:23:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:23:37 Only 6 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
23:23:37 HBMASTER: Trying to run another job!
23:23:37 job_callback for (0, 0, 20) finished
23:23:37 HBMASTER: schedule new run for iteration 0
23:23:37 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
23:23:37 HBMASTER: submitting job (0, 0, 22) to dispatcher
23:23:37 DISPATCHER: trying to submit job (0, 0, 22)
23:23:37 DISPATCHER: trying to notify the job_runner thread.
23:23:37 HBMASTER: job (0, 0, 22) submitted to dispatcher
23:23:37 DISPATCHER: Trying to submit another job.
23:23:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:23:37 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:23:37 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:23:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:23:38 WORKER: start processing job (0, 0, 22)
23:23:38 WORKER: args: ()
23:23:38 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 882, 'last_n_outputs': 45, 'leak_rate': 0.8304038235050764, 'lr': 0.04108579749959848, 'optimizer': 'SGD', 'sparsity': 0.8714081564232685, 'steps_to_train': 99, 'weight_decay': 0.01100066846990613}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:24:22 DISPATCHER: Starting worker discovery
23:24:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:24:22 DISPATCHER: Finished worker discovery
23:25:22 DISPATCHER: Starting worker discovery
23:25:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:25:22 DISPATCHER: Finished worker discovery
23:26:07 WORKER: done with job (0, 0, 22), trying to register it.
23:26:07 WORKER: registered result for job (0, 0, 22) with dispatcher
23:26:07 DISPATCHER: job (0, 0, 22) finished
23:26:07 DISPATCHER: register_result: lock acquired
23:26:07 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:26:07 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 882, 'last_n_outputs': 45, 'leak_rate': 0.8304038235050764, 'lr': 0.04108579749959848, 'optimizer': 'SGD', 'sparsity': 0.8714081564232685, 'steps_to_train': 99, 'weight_decay': 0.01100066846990613}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7404810932477158, 'info': {'data05': 0.7404810932477158, 'config': "{'batch_size': 16, 'hidden_dim': 882, 'last_n_outputs': 45, 'leak_rate': 0.8304038235050764, 'lr': 0.04108579749959848, 'optimizer': 'SGD', 'sparsity': 0.8714081564232685, 'steps_to_train': 99, 'weight_decay': 0.01100066846990613}"}}
exception: None

23:26:07 job_callback for (0, 0, 22) started
23:26:07 DISPATCHER: Trying to submit another job.
23:26:07 job_callback for (0, 0, 22) got condition
23:26:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:26:07 Only 7 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
23:26:07 HBMASTER: Trying to run another job!
23:26:07 job_callback for (0, 0, 22) finished
23:26:07 HBMASTER: schedule new run for iteration 0
23:26:07 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
23:26:07 HBMASTER: submitting job (0, 0, 24) to dispatcher
23:26:07 DISPATCHER: trying to submit job (0, 0, 24)
23:26:07 DISPATCHER: trying to notify the job_runner thread.
23:26:07 HBMASTER: job (0, 0, 24) submitted to dispatcher
23:26:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:26:07 DISPATCHER: Trying to submit another job.
23:26:07 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:26:07 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:26:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:26:07 WORKER: start processing job (0, 0, 24)
23:26:07 WORKER: args: ()
23:26:07 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 636, 'last_n_outputs': 50, 'leak_rate': 0.9971424925770229, 'lr': 0.0012153670426124478, 'optimizer': 'SGD', 'sparsity': 0.9442193660426491, 'steps_to_train': 39, 'weight_decay': 0.03752037006778302}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:26:22 DISPATCHER: Starting worker discovery
23:26:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:26:22 DISPATCHER: Finished worker discovery
23:27:22 DISPATCHER: Starting worker discovery
23:27:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:27:22 DISPATCHER: Finished worker discovery
23:28:22 DISPATCHER: Starting worker discovery
23:28:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:28:22 DISPATCHER: Finished worker discovery
23:28:33 WORKER: done with job (0, 0, 24), trying to register it.
23:28:33 WORKER: registered result for job (0, 0, 24) with dispatcher
23:28:33 DISPATCHER: job (0, 0, 24) finished
23:28:33 DISPATCHER: register_result: lock acquired
23:28:33 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:28:33 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 636, 'last_n_outputs': 50, 'leak_rate': 0.9971424925770229, 'lr': 0.0012153670426124478, 'optimizer': 'SGD', 'sparsity': 0.9442193660426491, 'steps_to_train': 39, 'weight_decay': 0.03752037006778302}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6936911595172834, 'info': {'data05': 0.6936911595172834, 'config': "{'batch_size': 64, 'hidden_dim': 636, 'last_n_outputs': 50, 'leak_rate': 0.9971424925770229, 'lr': 0.0012153670426124478, 'optimizer': 'SGD', 'sparsity': 0.9442193660426491, 'steps_to_train': 39, 'weight_decay': 0.03752037006778302}"}}
exception: None

23:28:33 job_callback for (0, 0, 24) started
23:28:33 DISPATCHER: Trying to submit another job.
23:28:33 job_callback for (0, 0, 24) got condition
23:28:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:28:33 Only 8 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
23:28:33 HBMASTER: Trying to run another job!
23:28:33 job_callback for (0, 0, 24) finished
23:28:33 HBMASTER: schedule new run for iteration 0
23:28:33 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
23:28:33 HBMASTER: submitting job (0, 0, 26) to dispatcher
23:28:33 DISPATCHER: trying to submit job (0, 0, 26)
23:28:33 DISPATCHER: trying to notify the job_runner thread.
23:28:33 HBMASTER: job (0, 0, 26) submitted to dispatcher
23:28:33 DISPATCHER: Trying to submit another job.
23:28:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:28:33 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:28:33 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:28:33 WORKER: start processing job (0, 0, 26)
23:28:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:28:33 WORKER: args: ()
23:28:33 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 999, 'last_n_outputs': 47, 'leak_rate': 0.7858823301689082, 'lr': 0.0013172142375598068, 'optimizer': 'SGD', 'sparsity': 0.9887075841339252, 'steps_to_train': 55, 'weight_decay': 0.03552349358182905}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:29:22 DISPATCHER: Starting worker discovery
23:29:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:29:22 DISPATCHER: Finished worker discovery
23:30:22 DISPATCHER: Starting worker discovery
23:30:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:30:22 DISPATCHER: Finished worker discovery
23:31:00 WORKER: done with job (0, 0, 26), trying to register it.
23:31:00 WORKER: registered result for job (0, 0, 26) with dispatcher
23:31:00 DISPATCHER: job (0, 0, 26) finished
23:31:00 DISPATCHER: register_result: lock acquired
23:31:00 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:31:00 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 999, 'last_n_outputs': 47, 'leak_rate': 0.7858823301689082, 'lr': 0.0013172142375598068, 'optimizer': 'SGD', 'sparsity': 0.9887075841339252, 'steps_to_train': 55, 'weight_decay': 0.03552349358182905}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7201557981654261, 'info': {'data05': 0.7201557981654261, 'config': "{'batch_size': 16, 'hidden_dim': 999, 'last_n_outputs': 47, 'leak_rate': 0.7858823301689082, 'lr': 0.0013172142375598068, 'optimizer': 'SGD', 'sparsity': 0.9887075841339252, 'steps_to_train': 55, 'weight_decay': 0.03552349358182905}"}}
exception: None

23:31:00 job_callback for (0, 0, 26) started
23:31:00 job_callback for (0, 0, 26) got condition
23:31:00 DISPATCHER: Trying to submit another job.
23:31:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:31:00 Only 9 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
23:31:00 HBMASTER: Trying to run another job!
23:31:00 job_callback for (0, 0, 26) finished
23:31:00 ITERATION: Advancing config (0, 0, 8) to next budget 400.000000
23:31:00 ITERATION: Advancing config (0, 0, 11) to next budget 400.000000
23:31:00 ITERATION: Advancing config (0, 0, 22) to next budget 400.000000
23:31:00 HBMASTER: schedule new run for iteration 0
23:31:00 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
23:31:00 HBMASTER: submitting job (0, 0, 8) to dispatcher
23:31:00 DISPATCHER: trying to submit job (0, 0, 8)
23:31:00 DISPATCHER: trying to notify the job_runner thread.
23:31:00 HBMASTER: job (0, 0, 8) submitted to dispatcher
23:31:00 DISPATCHER: Trying to submit another job.
23:31:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:31:00 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:31:00 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:31:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:31:00 WORKER: start processing job (0, 0, 8)
23:31:00 WORKER: args: ()
23:31:00 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 855, 'last_n_outputs': 44, 'leak_rate': 0.8927030492189386, 'lr': 0.0019568121476006813, 'optimizer': 'SGD', 'sparsity': 0.9489950724201204, 'steps_to_train': 23, 'weight_decay': 0.027098171454306475}, 'budget': 400.0, 'working_directory': '.'}
23:31:22 DISPATCHER: Starting worker discovery
23:31:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:31:22 DISPATCHER: Finished worker discovery
23:32:22 DISPATCHER: Starting worker discovery
23:32:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:32:22 DISPATCHER: Finished worker discovery
23:33:22 DISPATCHER: Starting worker discovery
23:33:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:33:22 DISPATCHER: Finished worker discovery
23:34:22 DISPATCHER: Starting worker discovery
23:34:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:34:22 DISPATCHER: Finished worker discovery
23:35:22 DISPATCHER: Starting worker discovery
23:35:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:35:22 DISPATCHER: Finished worker discovery
23:36:22 DISPATCHER: Starting worker discovery
23:36:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:36:22 DISPATCHER: Finished worker discovery
23:37:22 DISPATCHER: Starting worker discovery
23:37:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:37:22 DISPATCHER: Finished worker discovery
23:37:57 WORKER: done with job (0, 0, 8), trying to register it.
23:37:57 WORKER: registered result for job (0, 0, 8) with dispatcher
23:37:57 DISPATCHER: job (0, 0, 8) finished
23:37:57 DISPATCHER: register_result: lock acquired
23:37:57 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:37:57 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 855, 'last_n_outputs': 44, 'leak_rate': 0.8927030492189386, 'lr': 0.0019568121476006813, 'optimizer': 'SGD', 'sparsity': 0.9489950724201204, 'steps_to_train': 23, 'weight_decay': 0.027098171454306475}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7439424565038032, 'info': {'data05': 0.7439424565038032, 'config': "{'batch_size': 128, 'hidden_dim': 855, 'last_n_outputs': 44, 'leak_rate': 0.8927030492189386, 'lr': 0.0019568121476006813, 'optimizer': 'SGD', 'sparsity': 0.9489950724201204, 'steps_to_train': 23, 'weight_decay': 0.027098171454306475}"}}
exception: None

23:37:57 job_callback for (0, 0, 8) started
23:37:57 job_callback for (0, 0, 8) got condition
23:37:57 DISPATCHER: Trying to submit another job.
23:37:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:37:57 Only 1 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
23:37:57 HBMASTER: Trying to run another job!
23:37:57 job_callback for (0, 0, 8) finished
23:37:57 HBMASTER: schedule new run for iteration 0
23:37:57 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
23:37:57 HBMASTER: submitting job (0, 0, 11) to dispatcher
23:37:57 DISPATCHER: trying to submit job (0, 0, 11)
23:37:57 DISPATCHER: trying to notify the job_runner thread.
23:37:57 HBMASTER: job (0, 0, 11) submitted to dispatcher
23:37:57 DISPATCHER: Trying to submit another job.
23:37:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:37:57 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:37:57 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:37:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:37:57 WORKER: start processing job (0, 0, 11)
23:37:57 WORKER: args: ()
23:37:57 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 987, 'last_n_outputs': 49, 'leak_rate': 0.9925223501264618, 'lr': 0.011866833529571635, 'optimizer': 'SGD', 'sparsity': 0.8128538944226172, 'steps_to_train': 93, 'weight_decay': 0.04240512958885776}, 'budget': 400.0, 'working_directory': '.'}
23:38:22 DISPATCHER: Starting worker discovery
23:38:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:38:22 DISPATCHER: Finished worker discovery
23:39:22 DISPATCHER: Starting worker discovery
23:39:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:39:22 DISPATCHER: Finished worker discovery
23:40:22 DISPATCHER: Starting worker discovery
23:40:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:40:22 DISPATCHER: Finished worker discovery
23:41:22 DISPATCHER: Starting worker discovery
23:41:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:41:22 DISPATCHER: Finished worker discovery
23:42:22 DISPATCHER: Starting worker discovery
23:42:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:42:22 DISPATCHER: Finished worker discovery
23:43:22 DISPATCHER: Starting worker discovery
23:43:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:43:22 DISPATCHER: Finished worker discovery
23:44:22 DISPATCHER: Starting worker discovery
23:44:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:44:22 DISPATCHER: Finished worker discovery
23:44:50 WORKER: done with job (0, 0, 11), trying to register it.
23:44:50 WORKER: registered result for job (0, 0, 11) with dispatcher
23:44:50 DISPATCHER: job (0, 0, 11) finished
23:44:50 DISPATCHER: register_result: lock acquired
23:44:50 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:44:50 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 987, 'last_n_outputs': 49, 'leak_rate': 0.9925223501264618, 'lr': 0.011866833529571635, 'optimizer': 'SGD', 'sparsity': 0.8128538944226172, 'steps_to_train': 93, 'weight_decay': 0.04240512958885776}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.750808119942497, 'info': {'data05': 0.750808119942497, 'config': "{'batch_size': 64, 'hidden_dim': 987, 'last_n_outputs': 49, 'leak_rate': 0.9925223501264618, 'lr': 0.011866833529571635, 'optimizer': 'SGD', 'sparsity': 0.8128538944226172, 'steps_to_train': 93, 'weight_decay': 0.04240512958885776}"}}
exception: None

23:44:50 job_callback for (0, 0, 11) started
23:44:50 job_callback for (0, 0, 11) got condition
23:44:50 DISPATCHER: Trying to submit another job.
23:44:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:44:50 Only 2 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
23:44:50 HBMASTER: Trying to run another job!
23:44:50 job_callback for (0, 0, 11) finished
23:44:50 HBMASTER: schedule new run for iteration 0
23:44:50 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
23:44:50 HBMASTER: submitting job (0, 0, 22) to dispatcher
23:44:50 DISPATCHER: trying to submit job (0, 0, 22)
23:44:50 DISPATCHER: trying to notify the job_runner thread.
23:44:50 HBMASTER: job (0, 0, 22) submitted to dispatcher
23:44:50 DISPATCHER: Trying to submit another job.
23:44:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:44:50 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:44:50 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:44:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:44:50 WORKER: start processing job (0, 0, 22)
23:44:50 WORKER: args: ()
23:44:50 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 882, 'last_n_outputs': 45, 'leak_rate': 0.8304038235050764, 'lr': 0.04108579749959848, 'optimizer': 'SGD', 'sparsity': 0.8714081564232685, 'steps_to_train': 99, 'weight_decay': 0.01100066846990613}, 'budget': 400.0, 'working_directory': '.'}
23:45:22 DISPATCHER: Starting worker discovery
23:45:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:45:22 DISPATCHER: Finished worker discovery
23:46:22 DISPATCHER: Starting worker discovery
23:46:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:46:22 DISPATCHER: Finished worker discovery
23:47:22 DISPATCHER: Starting worker discovery
23:47:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:47:22 DISPATCHER: Finished worker discovery
23:48:22 DISPATCHER: Starting worker discovery
23:48:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:48:22 DISPATCHER: Finished worker discovery
23:49:22 DISPATCHER: Starting worker discovery
23:49:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:49:22 DISPATCHER: Finished worker discovery
23:50:22 DISPATCHER: Starting worker discovery
23:50:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:50:22 DISPATCHER: Finished worker discovery
23:51:22 DISPATCHER: Starting worker discovery
23:51:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:51:22 DISPATCHER: Finished worker discovery
23:51:47 WORKER: done with job (0, 0, 22), trying to register it.
23:51:47 WORKER: registered result for job (0, 0, 22) with dispatcher
23:51:47 DISPATCHER: job (0, 0, 22) finished
23:51:47 DISPATCHER: register_result: lock acquired
23:51:47 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:51:47 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 882, 'last_n_outputs': 45, 'leak_rate': 0.8304038235050764, 'lr': 0.04108579749959848, 'optimizer': 'SGD', 'sparsity': 0.8714081564232685, 'steps_to_train': 99, 'weight_decay': 0.01100066846990613}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7373133236623788, 'info': {'data05': 0.7373133236623788, 'config': "{'batch_size': 16, 'hidden_dim': 882, 'last_n_outputs': 45, 'leak_rate': 0.8304038235050764, 'lr': 0.04108579749959848, 'optimizer': 'SGD', 'sparsity': 0.8714081564232685, 'steps_to_train': 99, 'weight_decay': 0.01100066846990613}"}}
exception: None

23:51:47 job_callback for (0, 0, 22) started
23:51:47 job_callback for (0, 0, 22) got condition
23:51:47 DISPATCHER: Trying to submit another job.
23:51:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:51:47 Only 3 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
23:51:47 HBMASTER: Trying to run another job!
23:51:47 job_callback for (0, 0, 22) finished
23:51:47 ITERATION: Advancing config (0, 0, 11) to next budget 1200.000000
23:51:47 HBMASTER: schedule new run for iteration 0
23:51:47 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
23:51:47 HBMASTER: submitting job (0, 0, 11) to dispatcher
23:51:47 DISPATCHER: trying to submit job (0, 0, 11)
23:51:47 DISPATCHER: trying to notify the job_runner thread.
23:51:47 HBMASTER: job (0, 0, 11) submitted to dispatcher
23:51:47 DISPATCHER: Trying to submit another job.
23:51:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:51:47 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:51:47 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:51:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:51:47 WORKER: start processing job (0, 0, 11)
23:51:47 WORKER: args: ()
23:51:47 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 987, 'last_n_outputs': 49, 'leak_rate': 0.9925223501264618, 'lr': 0.011866833529571635, 'optimizer': 'SGD', 'sparsity': 0.8128538944226172, 'steps_to_train': 93, 'weight_decay': 0.04240512958885776}, 'budget': 1200.0, 'working_directory': '.'}
23:52:22 DISPATCHER: Starting worker discovery
23:52:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:52:22 DISPATCHER: Finished worker discovery
23:53:22 DISPATCHER: Starting worker discovery
23:53:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:53:22 DISPATCHER: Finished worker discovery
23:54:22 DISPATCHER: Starting worker discovery
23:54:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:54:22 DISPATCHER: Finished worker discovery
23:55:22 DISPATCHER: Starting worker discovery
23:55:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:55:22 DISPATCHER: Finished worker discovery
23:56:22 DISPATCHER: Starting worker discovery
23:56:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:56:22 DISPATCHER: Finished worker discovery
23:57:22 DISPATCHER: Starting worker discovery
23:57:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:57:22 DISPATCHER: Finished worker discovery
23:58:22 DISPATCHER: Starting worker discovery
23:58:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:58:22 DISPATCHER: Finished worker discovery
23:59:22 DISPATCHER: Starting worker discovery
23:59:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:59:22 DISPATCHER: Finished worker discovery
00:00:22 DISPATCHER: Starting worker discovery
00:00:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:00:22 DISPATCHER: Finished worker discovery
00:01:22 DISPATCHER: Starting worker discovery
00:01:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:01:22 DISPATCHER: Finished worker discovery
00:02:22 DISPATCHER: Starting worker discovery
00:02:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:02:22 DISPATCHER: Finished worker discovery
00:03:22 DISPATCHER: Starting worker discovery
00:03:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:03:22 DISPATCHER: Finished worker discovery
00:04:22 DISPATCHER: Starting worker discovery
00:04:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:04:22 DISPATCHER: Finished worker discovery
00:05:22 DISPATCHER: Starting worker discovery
00:05:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:05:22 DISPATCHER: Finished worker discovery
00:06:22 DISPATCHER: Starting worker discovery
00:06:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:06:22 DISPATCHER: Finished worker discovery
00:07:22 DISPATCHER: Starting worker discovery
00:07:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:07:22 DISPATCHER: Finished worker discovery
00:08:22 DISPATCHER: Starting worker discovery
00:08:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:08:22 DISPATCHER: Finished worker discovery
00:09:22 DISPATCHER: Starting worker discovery
00:09:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:09:22 DISPATCHER: Finished worker discovery
00:10:22 DISPATCHER: Starting worker discovery
00:10:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:10:22 DISPATCHER: Finished worker discovery
00:11:22 DISPATCHER: Starting worker discovery
00:11:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:11:22 DISPATCHER: Finished worker discovery
00:12:11 WORKER: done with job (0, 0, 11), trying to register it.
00:12:11 WORKER: registered result for job (0, 0, 11) with dispatcher
00:12:11 DISPATCHER: job (0, 0, 11) finished
00:12:11 DISPATCHER: register_result: lock acquired
00:12:11 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
00:12:11 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 987, 'last_n_outputs': 49, 'leak_rate': 0.9925223501264618, 'lr': 0.011866833529571635, 'optimizer': 'SGD', 'sparsity': 0.8128538944226172, 'steps_to_train': 93, 'weight_decay': 0.04240512958885776}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.757834473901681, 'info': {'data05': 0.757834473901681, 'config': "{'batch_size': 64, 'hidden_dim': 987, 'last_n_outputs': 49, 'leak_rate': 0.9925223501264618, 'lr': 0.011866833529571635, 'optimizer': 'SGD', 'sparsity': 0.8128538944226172, 'steps_to_train': 93, 'weight_decay': 0.04240512958885776}"}}
exception: None

00:12:11 job_callback for (0, 0, 11) started
00:12:11 job_callback for (0, 0, 11) got condition
00:12:11 DISPATCHER: Trying to submit another job.
00:12:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:12:11 Only 1 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
00:12:11 HBMASTER: Trying to run another job!
00:12:11 job_callback for (0, 0, 11) finished
00:12:11 start sampling a new configuration.
00:12:11 best_vector: [3, 0.709986838234417, 0.9637677647788374, 0.20182371414621958, 0.820042185981945, 1, 0.38240629826809863, 0.7991803142870362, 0.16236439419163], 0.0006453064306286061, 0.7723185743481567, 0.0004983821425207827
00:12:11 done sampling a new configuration.
00:12:11 HBMASTER: schedule new run for iteration 1
00:12:11 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
00:12:11 HBMASTER: submitting job (1, 0, 0) to dispatcher
00:12:11 DISPATCHER: trying to submit job (1, 0, 0)
00:12:11 DISPATCHER: trying to notify the job_runner thread.
00:12:11 HBMASTER: job (1, 0, 0) submitted to dispatcher
00:12:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:12:11 DISPATCHER: Trying to submit another job.
00:12:11 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:12:11 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:12:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:12:11 WORKER: start processing job (1, 0, 0)
00:12:11 WORKER: args: ()
00:12:11 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 768, 'last_n_outputs': 49, 'leak_rate': 0.8004559285365549, 'lr': 0.04366006439919181, 'optimizer': 'SGD', 'sparsity': 0.8417775115843437, 'steps_to_train': 82, 'weight_decay': 0.016264508622655337}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:12:22 DISPATCHER: Starting worker discovery
00:12:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:12:23 DISPATCHER: Finished worker discovery
00:13:23 DISPATCHER: Starting worker discovery
00:13:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:13:23 DISPATCHER: Finished worker discovery
00:14:23 DISPATCHER: Starting worker discovery
00:14:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:14:23 DISPATCHER: Finished worker discovery
00:14:45 WORKER: done with job (1, 0, 0), trying to register it.
00:14:45 WORKER: registered result for job (1, 0, 0) with dispatcher
00:14:45 DISPATCHER: job (1, 0, 0) finished
00:14:45 DISPATCHER: register_result: lock acquired
00:14:45 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
00:14:45 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 768, 'last_n_outputs': 49, 'leak_rate': 0.8004559285365549, 'lr': 0.04366006439919181, 'optimizer': 'SGD', 'sparsity': 0.8417775115843437, 'steps_to_train': 82, 'weight_decay': 0.016264508622655337}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7699564325500257, 'info': {'data05': 0.7699564325500257, 'config': "{'batch_size': 128, 'hidden_dim': 768, 'last_n_outputs': 49, 'leak_rate': 0.8004559285365549, 'lr': 0.04366006439919181, 'optimizer': 'SGD', 'sparsity': 0.8417775115843437, 'steps_to_train': 82, 'weight_decay': 0.016264508622655337}"}}
exception: None

00:14:45 job_callback for (1, 0, 0) started
00:14:45 DISPATCHER: Trying to submit another job.
00:14:45 job_callback for (1, 0, 0) got condition
00:14:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:14:45 HBMASTER: Trying to run another job!
00:14:45 job_callback for (1, 0, 0) finished
00:14:45 start sampling a new configuration.
00:14:45 best_vector: [1, 0.38319211026304195, 0.9312961621518978, 0.6931872659795606, 0.16634272514425108, 1, 0.11683079448482453, 0.4425396573843895, 0.7506051244558991], 0.0001172215360794116, 0.3089078371683537, 3.6210651179843175e-05
00:14:45 done sampling a new configuration.
00:14:45 HBMASTER: schedule new run for iteration 1
00:14:45 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
00:14:45 HBMASTER: submitting job (1, 0, 1) to dispatcher
00:14:45 DISPATCHER: trying to submit job (1, 0, 1)
00:14:45 DISPATCHER: trying to notify the job_runner thread.
00:14:45 HBMASTER: job (1, 0, 1) submitted to dispatcher
00:14:45 DISPATCHER: Trying to submit another job.
00:14:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:14:45 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:14:45 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:14:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:14:45 WORKER: start processing job (1, 0, 1)
00:14:45 WORKER: args: ()
00:14:45 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 506, 'last_n_outputs': 48, 'leak_rate': 0.9232968164948901, 'lr': 0.002151223087916185, 'optimizer': 'SGD', 'sparsity': 0.7780393906763579, 'steps_to_train': 50, 'weight_decay': 0.09474575956423659}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:15:23 DISPATCHER: Starting worker discovery
00:15:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:15:23 DISPATCHER: Finished worker discovery
00:16:23 DISPATCHER: Starting worker discovery
00:16:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:16:23 DISPATCHER: Finished worker discovery
00:17:15 WORKER: done with job (1, 0, 1), trying to register it.
00:17:15 WORKER: registered result for job (1, 0, 1) with dispatcher
00:17:15 DISPATCHER: job (1, 0, 1) finished
00:17:15 DISPATCHER: register_result: lock acquired
00:17:15 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
00:17:15 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 506, 'last_n_outputs': 48, 'leak_rate': 0.9232968164948901, 'lr': 0.002151223087916185, 'optimizer': 'SGD', 'sparsity': 0.7780393906763579, 'steps_to_train': 50, 'weight_decay': 0.09474575956423659}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7069868111810436, 'info': {'data05': 0.7069868111810436, 'config': "{'batch_size': 32, 'hidden_dim': 506, 'last_n_outputs': 48, 'leak_rate': 0.9232968164948901, 'lr': 0.002151223087916185, 'optimizer': 'SGD', 'sparsity': 0.7780393906763579, 'steps_to_train': 50, 'weight_decay': 0.09474575956423659}"}}
exception: None

00:17:15 job_callback for (1, 0, 1) started
00:17:15 DISPATCHER: Trying to submit another job.
00:17:15 job_callback for (1, 0, 1) got condition
00:17:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:17:15 HBMASTER: Trying to run another job!
00:17:15 job_callback for (1, 0, 1) finished
00:17:15 start sampling a new configuration.
00:17:16 best_vector: [1, 0.6305564644071937, 0.9743800472243394, 0.4300405947399889, 0.02300497226944012, 1, 0.3806034983261329, 0.5443459933262039, 0.7024264967606882], 0.00040179517491769826, 0.0730405839755919, 2.934735421456378e-05
00:17:16 done sampling a new configuration.
00:17:16 HBMASTER: schedule new run for iteration 1
00:17:16 HBMASTER: trying submitting job (1, 0, 2) to dispatcher
00:17:16 HBMASTER: submitting job (1, 0, 2) to dispatcher
00:17:16 DISPATCHER: trying to submit job (1, 0, 2)
00:17:16 DISPATCHER: trying to notify the job_runner thread.
00:17:16 HBMASTER: job (1, 0, 2) submitted to dispatcher
00:17:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:17:16 DISPATCHER: Trying to submit another job.
00:17:16 DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:17:16 DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:17:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:17:16 WORKER: start processing job (1, 0, 2)
00:17:16 WORKER: args: ()
00:17:16 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 705, 'last_n_outputs': 49, 'leak_rate': 0.8575101486849972, 'lr': 0.0011117571841695445, 'optimizer': 'SGD', 'sparsity': 0.8413448395982719, 'steps_to_train': 59, 'weight_decay': 0.08201210178669058}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:17:23 DISPATCHER: Starting worker discovery
00:17:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:17:23 DISPATCHER: Finished worker discovery
00:18:23 DISPATCHER: Starting worker discovery
00:18:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:18:23 DISPATCHER: Finished worker discovery
00:19:23 DISPATCHER: Starting worker discovery
00:19:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:19:23 DISPATCHER: Finished worker discovery
00:19:47 WORKER: done with job (1, 0, 2), trying to register it.
00:19:47 WORKER: registered result for job (1, 0, 2) with dispatcher
00:19:47 DISPATCHER: job (1, 0, 2) finished
00:19:47 DISPATCHER: register_result: lock acquired
00:19:47 DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
00:19:47 job_id: (1, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 705, 'last_n_outputs': 49, 'leak_rate': 0.8575101486849972, 'lr': 0.0011117571841695445, 'optimizer': 'SGD', 'sparsity': 0.8413448395982719, 'steps_to_train': 59, 'weight_decay': 0.08201210178669058}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.710317135406952, 'info': {'data05': 0.710317135406952, 'config': "{'batch_size': 32, 'hidden_dim': 705, 'last_n_outputs': 49, 'leak_rate': 0.8575101486849972, 'lr': 0.0011117571841695445, 'optimizer': 'SGD', 'sparsity': 0.8413448395982719, 'steps_to_train': 59, 'weight_decay': 0.08201210178669058}"}}
exception: None

00:19:47 job_callback for (1, 0, 2) started
00:19:47 job_callback for (1, 0, 2) got condition
00:19:47 DISPATCHER: Trying to submit another job.
00:19:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:19:47 HBMASTER: Trying to run another job!
00:19:47 job_callback for (1, 0, 2) finished
00:19:47 start sampling a new configuration.
00:19:47 best_vector: [3, 0.6809927560719129, 0.8728746557663225, 0.8132033049784546, 0.11209349115528383, 1, 0.9375797397643189, 0.2725072104745052, 0.704446421018291], 0.0007137894365824714, 0.3411782334935838, 0.00024352941905958803
00:19:47 done sampling a new configuration.
00:19:47 HBMASTER: schedule new run for iteration 1
00:19:47 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
00:19:47 HBMASTER: submitting job (1, 0, 3) to dispatcher
00:19:47 DISPATCHER: trying to submit job (1, 0, 3)
00:19:47 DISPATCHER: trying to notify the job_runner thread.
00:19:47 HBMASTER: job (1, 0, 3) submitted to dispatcher
00:19:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:19:47 DISPATCHER: Trying to submit another job.
00:19:47 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:19:47 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:19:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:19:47 WORKER: start processing job (1, 0, 3)
00:19:47 WORKER: args: ()
00:19:47 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 745, 'last_n_outputs': 45, 'leak_rate': 0.9533008262446137, 'lr': 0.0016756641656845974, 'optimizer': 'SGD', 'sparsity': 0.9750191375434365, 'steps_to_train': 34, 'weight_decay': 0.08250987403306027}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:20:23 DISPATCHER: Starting worker discovery
00:20:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:20:23 DISPATCHER: Finished worker discovery
00:21:23 DISPATCHER: Starting worker discovery
00:21:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:21:23 DISPATCHER: Finished worker discovery
00:22:15 WORKER: done with job (1, 0, 3), trying to register it.
00:22:15 WORKER: registered result for job (1, 0, 3) with dispatcher
00:22:15 DISPATCHER: job (1, 0, 3) finished
00:22:15 DISPATCHER: register_result: lock acquired
00:22:15 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
00:22:15 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 745, 'last_n_outputs': 45, 'leak_rate': 0.9533008262446137, 'lr': 0.0016756641656845974, 'optimizer': 'SGD', 'sparsity': 0.9750191375434365, 'steps_to_train': 34, 'weight_decay': 0.08250987403306027}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7076634682225168, 'info': {'data05': 0.7076634682225168, 'config': "{'batch_size': 128, 'hidden_dim': 745, 'last_n_outputs': 45, 'leak_rate': 0.9533008262446137, 'lr': 0.0016756641656845974, 'optimizer': 'SGD', 'sparsity': 0.9750191375434365, 'steps_to_train': 34, 'weight_decay': 0.08250987403306027}"}}
exception: None

00:22:15 job_callback for (1, 0, 3) started
00:22:15 job_callback for (1, 0, 3) got condition
00:22:15 DISPATCHER: Trying to submit another job.
00:22:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:22:15 HBMASTER: Trying to run another job!
00:22:15 job_callback for (1, 0, 3) finished
00:22:15 start sampling a new configuration.
00:22:15 best_vector: [3, 0.05296431591787486, 0.8646914869114327, 0.35410744995312443, 0.38845749325075074, 1, 0.9763443315148966, 0.8029895827928953, 0.10853026855196812], 0.0022885515216777377, 0.32920138321766074, 0.0007533943265011935
00:22:15 done sampling a new configuration.
00:22:15 HBMASTER: schedule new run for iteration 1
00:22:15 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
00:22:15 HBMASTER: submitting job (1, 0, 4) to dispatcher
00:22:15 DISPATCHER: trying to submit job (1, 0, 4)
00:22:15 DISPATCHER: trying to notify the job_runner thread.
00:22:15 HBMASTER: job (1, 0, 4) submitted to dispatcher
00:22:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:22:15 DISPATCHER: Trying to submit another job.
00:22:15 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:22:15 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:22:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:22:15 WORKER: start processing job (1, 0, 4)
00:22:15 WORKER: args: ()
00:22:15 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 242, 'last_n_outputs': 45, 'leak_rate': 0.8385268624882811, 'lr': 0.005982944669676063, 'optimizer': 'SGD', 'sparsity': 0.9843226395635751, 'steps_to_train': 83, 'weight_decay': 0.01384207298536242}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:22:23 DISPATCHER: Starting worker discovery
00:22:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:22:23 DISPATCHER: Finished worker discovery
00:23:23 DISPATCHER: Starting worker discovery
00:23:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:23:23 DISPATCHER: Finished worker discovery
00:24:23 DISPATCHER: Starting worker discovery
00:24:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:24:23 DISPATCHER: Finished worker discovery
00:24:41 WORKER: done with job (1, 0, 4), trying to register it.
00:24:41 WORKER: registered result for job (1, 0, 4) with dispatcher
00:24:41 DISPATCHER: job (1, 0, 4) finished
00:24:41 DISPATCHER: register_result: lock acquired
00:24:41 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
00:24:41 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 242, 'last_n_outputs': 45, 'leak_rate': 0.8385268624882811, 'lr': 0.005982944669676063, 'optimizer': 'SGD', 'sparsity': 0.9843226395635751, 'steps_to_train': 83, 'weight_decay': 0.01384207298536242}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7156663509041549, 'info': {'data05': 0.7156663509041549, 'config': "{'batch_size': 128, 'hidden_dim': 242, 'last_n_outputs': 45, 'leak_rate': 0.8385268624882811, 'lr': 0.005982944669676063, 'optimizer': 'SGD', 'sparsity': 0.9843226395635751, 'steps_to_train': 83, 'weight_decay': 0.01384207298536242}"}}
exception: None

00:24:41 job_callback for (1, 0, 4) started
00:24:41 DISPATCHER: Trying to submit another job.
00:24:41 job_callback for (1, 0, 4) got condition
00:24:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:24:41 HBMASTER: Trying to run another job!
00:24:41 job_callback for (1, 0, 4) finished
00:24:41 start sampling a new configuration.
00:24:41 done sampling a new configuration.
00:24:41 HBMASTER: schedule new run for iteration 1
00:24:41 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
00:24:41 HBMASTER: submitting job (1, 0, 5) to dispatcher
00:24:41 DISPATCHER: trying to submit job (1, 0, 5)
00:24:41 DISPATCHER: trying to notify the job_runner thread.
00:24:41 HBMASTER: job (1, 0, 5) submitted to dispatcher
00:24:41 DISPATCHER: Trying to submit another job.
00:24:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:24:41 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:24:41 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:24:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:24:41 WORKER: start processing job (1, 0, 5)
00:24:41 WORKER: args: ()
00:24:41 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 866, 'last_n_outputs': 11, 'leak_rate': 0.9380377056657428, 'lr': 0.008514228509200793, 'optimizer': 'SGD', 'sparsity': 0.9776830148709178, 'steps_to_train': 58, 'weight_decay': 0.04027073269845015}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:25:23 DISPATCHER: Starting worker discovery
00:25:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:25:23 DISPATCHER: Finished worker discovery
00:26:23 DISPATCHER: Starting worker discovery
00:26:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:26:23 DISPATCHER: Finished worker discovery
00:27:10 WORKER: done with job (1, 0, 5), trying to register it.
00:27:10 WORKER: registered result for job (1, 0, 5) with dispatcher
00:27:10 DISPATCHER: job (1, 0, 5) finished
00:27:10 DISPATCHER: register_result: lock acquired
00:27:10 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
00:27:10 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 866, 'last_n_outputs': 11, 'leak_rate': 0.9380377056657428, 'lr': 0.008514228509200793, 'optimizer': 'SGD', 'sparsity': 0.9776830148709178, 'steps_to_train': 58, 'weight_decay': 0.04027073269845015}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.542143364461093, 'info': {'data05': 0.542143364461093, 'config': "{'batch_size': 32, 'hidden_dim': 866, 'last_n_outputs': 11, 'leak_rate': 0.9380377056657428, 'lr': 0.008514228509200793, 'optimizer': 'SGD', 'sparsity': 0.9776830148709178, 'steps_to_train': 58, 'weight_decay': 0.04027073269845015}"}}
exception: None

00:27:10 job_callback for (1, 0, 5) started
00:27:10 job_callback for (1, 0, 5) got condition
00:27:10 DISPATCHER: Trying to submit another job.
00:27:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:27:10 HBMASTER: Trying to run another job!
00:27:10 job_callback for (1, 0, 5) finished
00:27:10 start sampling a new configuration.
00:27:10 best_vector: [1, 0.431897174429139, 0.9658598299439674, 0.7799334434174137, 0.07394558974445889, 1, 0.5917088155893471, 0.04999179876890558, 0.5354534234362598], 0.00016551322357394449, 1.0852107465248608, 0.0001796167289144165
00:27:10 done sampling a new configuration.
00:27:10 HBMASTER: schedule new run for iteration 1
00:27:10 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
00:27:10 HBMASTER: submitting job (1, 0, 6) to dispatcher
00:27:10 DISPATCHER: trying to submit job (1, 0, 6)
00:27:10 DISPATCHER: trying to notify the job_runner thread.
00:27:10 HBMASTER: job (1, 0, 6) submitted to dispatcher
00:27:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:27:10 DISPATCHER: Trying to submit another job.
00:27:10 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:27:10 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:27:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:27:10 WORKER: start processing job (1, 0, 6)
00:27:10 WORKER: args: ()
00:27:10 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 545, 'last_n_outputs': 49, 'leak_rate': 0.9449833608543534, 'lr': 0.0014056952570650192, 'optimizer': 'SGD', 'sparsity': 0.8920101157414433, 'steps_to_train': 14, 'weight_decay': 0.04973257716689793}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:27:23 DISPATCHER: Starting worker discovery
00:27:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:27:23 DISPATCHER: Finished worker discovery
00:28:23 DISPATCHER: Starting worker discovery
00:28:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:28:23 DISPATCHER: Finished worker discovery
00:29:23 DISPATCHER: Starting worker discovery
00:29:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:29:23 DISPATCHER: Finished worker discovery
00:29:39 WORKER: done with job (1, 0, 6), trying to register it.
00:29:39 WORKER: registered result for job (1, 0, 6) with dispatcher
00:29:39 DISPATCHER: job (1, 0, 6) finished
00:29:39 DISPATCHER: register_result: lock acquired
00:29:39 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
00:29:39 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 545, 'last_n_outputs': 49, 'leak_rate': 0.9449833608543534, 'lr': 0.0014056952570650192, 'optimizer': 'SGD', 'sparsity': 0.8920101157414433, 'steps_to_train': 14, 'weight_decay': 0.04973257716689793}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6775868249385487, 'info': {'data05': 0.6775868249385487, 'config': "{'batch_size': 32, 'hidden_dim': 545, 'last_n_outputs': 49, 'leak_rate': 0.9449833608543534, 'lr': 0.0014056952570650192, 'optimizer': 'SGD', 'sparsity': 0.8920101157414433, 'steps_to_train': 14, 'weight_decay': 0.04973257716689793}"}}
exception: None

00:29:39 job_callback for (1, 0, 6) started
00:29:39 job_callback for (1, 0, 6) got condition
00:29:39 DISPATCHER: Trying to submit another job.
00:29:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:29:39 HBMASTER: Trying to run another job!
00:29:39 job_callback for (1, 0, 6) finished
00:29:39 start sampling a new configuration.
00:29:39 done sampling a new configuration.
00:29:39 HBMASTER: schedule new run for iteration 1
00:29:39 HBMASTER: trying submitting job (1, 0, 7) to dispatcher
00:29:39 HBMASTER: submitting job (1, 0, 7) to dispatcher
00:29:39 DISPATCHER: trying to submit job (1, 0, 7)
00:29:39 DISPATCHER: trying to notify the job_runner thread.
00:29:39 HBMASTER: job (1, 0, 7) submitted to dispatcher
00:29:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:29:39 DISPATCHER: Trying to submit another job.
00:29:39 DISPATCHER: starting job (1, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:29:39 DISPATCHER: job (1, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:29:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:29:39 WORKER: start processing job (1, 0, 7)
00:29:39 WORKER: args: ()
00:29:39 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 503, 'last_n_outputs': 28, 'leak_rate': 0.9548694589473206, 'lr': 0.009232275194949712, 'optimizer': 'SGD', 'sparsity': 0.8742477598500951, 'steps_to_train': 82, 'weight_decay': 0.03332248984053063}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:30:23 DISPATCHER: Starting worker discovery
00:30:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:30:23 DISPATCHER: Finished worker discovery
00:31:23 DISPATCHER: Starting worker discovery
00:31:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:31:23 DISPATCHER: Finished worker discovery
00:32:11 WORKER: done with job (1, 0, 7), trying to register it.
00:32:11 WORKER: registered result for job (1, 0, 7) with dispatcher
00:32:11 DISPATCHER: job (1, 0, 7) finished
00:32:11 DISPATCHER: register_result: lock acquired
00:32:11 DISPATCHER: job (1, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
00:32:11 job_id: (1, 0, 7)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 503, 'last_n_outputs': 28, 'leak_rate': 0.9548694589473206, 'lr': 0.009232275194949712, 'optimizer': 'SGD', 'sparsity': 0.8742477598500951, 'steps_to_train': 82, 'weight_decay': 0.03332248984053063}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6219377449707647, 'info': {'data05': 0.6219377449707647, 'config': "{'batch_size': 64, 'hidden_dim': 503, 'last_n_outputs': 28, 'leak_rate': 0.9548694589473206, 'lr': 0.009232275194949712, 'optimizer': 'SGD', 'sparsity': 0.8742477598500951, 'steps_to_train': 82, 'weight_decay': 0.03332248984053063}"}}
exception: None

00:32:11 job_callback for (1, 0, 7) started
00:32:11 job_callback for (1, 0, 7) got condition
00:32:11 DISPATCHER: Trying to submit another job.
00:32:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:32:11 HBMASTER: Trying to run another job!
00:32:11 job_callback for (1, 0, 7) finished
00:32:11 start sampling a new configuration.
00:32:11 done sampling a new configuration.
00:32:11 HBMASTER: schedule new run for iteration 1
00:32:11 HBMASTER: trying submitting job (1, 0, 8) to dispatcher
00:32:11 HBMASTER: submitting job (1, 0, 8) to dispatcher
00:32:11 DISPATCHER: trying to submit job (1, 0, 8)
00:32:11 DISPATCHER: trying to notify the job_runner thread.
00:32:11 HBMASTER: job (1, 0, 8) submitted to dispatcher
00:32:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:32:11 DISPATCHER: Trying to submit another job.
00:32:11 DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:32:11 DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:32:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:32:11 WORKER: start processing job (1, 0, 8)
00:32:11 WORKER: args: ()
00:32:11 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 478, 'last_n_outputs': 16, 'leak_rate': 0.9544564768572619, 'lr': 0.032037733947231944, 'optimizer': 'Adam', 'sparsity': 0.9520923345367063, 'steps_to_train': 10, 'weight_decay': 0.017439072757767484}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:32:23 DISPATCHER: Starting worker discovery
00:32:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:32:23 DISPATCHER: Finished worker discovery
00:33:23 DISPATCHER: Starting worker discovery
00:33:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:33:23 DISPATCHER: Finished worker discovery
00:34:23 DISPATCHER: Starting worker discovery
00:34:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:34:23 DISPATCHER: Finished worker discovery
00:34:40 WORKER: done with job (1, 0, 8), trying to register it.
00:34:40 WORKER: registered result for job (1, 0, 8) with dispatcher
00:34:40 DISPATCHER: job (1, 0, 8) finished
00:34:40 DISPATCHER: register_result: lock acquired
00:34:40 DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
00:34:40 job_id: (1, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 478, 'last_n_outputs': 16, 'leak_rate': 0.9544564768572619, 'lr': 0.032037733947231944, 'optimizer': 'Adam', 'sparsity': 0.9520923345367063, 'steps_to_train': 10, 'weight_decay': 0.017439072757767484}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.020020258751429824, 'info': {'data05': 0.020020258751429824, 'config': "{'batch_size': 16, 'hidden_dim': 478, 'last_n_outputs': 16, 'leak_rate': 0.9544564768572619, 'lr': 0.032037733947231944, 'optimizer': 'Adam', 'sparsity': 0.9520923345367063, 'steps_to_train': 10, 'weight_decay': 0.017439072757767484}"}}
exception: None

00:34:40 job_callback for (1, 0, 8) started
00:34:40 job_callback for (1, 0, 8) got condition
00:34:40 DISPATCHER: Trying to submit another job.
00:34:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:34:40 HBMASTER: Trying to run another job!
00:34:40 job_callback for (1, 0, 8) finished
00:34:40 ITERATION: Advancing config (1, 0, 0) to next budget 400.000000
00:34:40 ITERATION: Advancing config (1, 0, 2) to next budget 400.000000
00:34:40 ITERATION: Advancing config (1, 0, 4) to next budget 400.000000
00:34:40 HBMASTER: schedule new run for iteration 1
00:34:40 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
00:34:40 HBMASTER: submitting job (1, 0, 0) to dispatcher
00:34:40 DISPATCHER: trying to submit job (1, 0, 0)
00:34:40 DISPATCHER: trying to notify the job_runner thread.
00:34:40 HBMASTER: job (1, 0, 0) submitted to dispatcher
00:34:40 DISPATCHER: Trying to submit another job.
00:34:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:34:40 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:34:40 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:34:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:34:40 WORKER: start processing job (1, 0, 0)
00:34:40 WORKER: args: ()
00:34:40 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 768, 'last_n_outputs': 49, 'leak_rate': 0.8004559285365549, 'lr': 0.04366006439919181, 'optimizer': 'SGD', 'sparsity': 0.8417775115843437, 'steps_to_train': 82, 'weight_decay': 0.016264508622655337}, 'budget': 400.0, 'working_directory': '.'}
00:35:23 DISPATCHER: Starting worker discovery
00:35:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:35:23 DISPATCHER: Finished worker discovery
00:36:23 DISPATCHER: Starting worker discovery
00:36:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:36:23 DISPATCHER: Finished worker discovery
00:37:23 DISPATCHER: Starting worker discovery
00:37:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:37:23 DISPATCHER: Finished worker discovery
00:38:23 DISPATCHER: Starting worker discovery
00:38:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:38:23 DISPATCHER: Finished worker discovery
00:39:23 DISPATCHER: Starting worker discovery
00:39:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:39:23 DISPATCHER: Finished worker discovery
00:40:23 DISPATCHER: Starting worker discovery
00:40:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:40:23 DISPATCHER: Finished worker discovery
00:41:23 DISPATCHER: Starting worker discovery
00:41:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:41:23 DISPATCHER: Finished worker discovery
00:41:36 WORKER: done with job (1, 0, 0), trying to register it.
00:41:36 WORKER: registered result for job (1, 0, 0) with dispatcher
00:41:36 DISPATCHER: job (1, 0, 0) finished
00:41:36 DISPATCHER: register_result: lock acquired
00:41:36 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
00:41:36 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 768, 'last_n_outputs': 49, 'leak_rate': 0.8004559285365549, 'lr': 0.04366006439919181, 'optimizer': 'SGD', 'sparsity': 0.8417775115843437, 'steps_to_train': 82, 'weight_decay': 0.016264508622655337}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7731404460783824, 'info': {'data05': 0.7731404460783824, 'config': "{'batch_size': 128, 'hidden_dim': 768, 'last_n_outputs': 49, 'leak_rate': 0.8004559285365549, 'lr': 0.04366006439919181, 'optimizer': 'SGD', 'sparsity': 0.8417775115843437, 'steps_to_train': 82, 'weight_decay': 0.016264508622655337}"}}
exception: None

00:41:36 job_callback for (1, 0, 0) started
00:41:36 job_callback for (1, 0, 0) got condition
00:41:36 DISPATCHER: Trying to submit another job.
00:41:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:41:36 Only 4 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
00:41:36 HBMASTER: Trying to run another job!
00:41:36 job_callback for (1, 0, 0) finished
00:41:36 HBMASTER: schedule new run for iteration 1
00:41:36 HBMASTER: trying submitting job (1, 0, 2) to dispatcher
00:41:36 HBMASTER: submitting job (1, 0, 2) to dispatcher
00:41:36 DISPATCHER: trying to submit job (1, 0, 2)
00:41:36 DISPATCHER: trying to notify the job_runner thread.
00:41:36 HBMASTER: job (1, 0, 2) submitted to dispatcher
00:41:36 DISPATCHER: Trying to submit another job.
00:41:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:41:36 DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:41:36 DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:41:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:41:36 WORKER: start processing job (1, 0, 2)
00:41:36 WORKER: args: ()
00:41:36 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 705, 'last_n_outputs': 49, 'leak_rate': 0.8575101486849972, 'lr': 0.0011117571841695445, 'optimizer': 'SGD', 'sparsity': 0.8413448395982719, 'steps_to_train': 59, 'weight_decay': 0.08201210178669058}, 'budget': 400.0, 'working_directory': '.'}
00:42:23 DISPATCHER: Starting worker discovery
00:42:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:42:23 DISPATCHER: Finished worker discovery
00:43:23 DISPATCHER: Starting worker discovery
00:43:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:43:23 DISPATCHER: Finished worker discovery
00:44:23 DISPATCHER: Starting worker discovery
00:44:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:44:23 DISPATCHER: Finished worker discovery
00:45:23 DISPATCHER: Starting worker discovery
00:45:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:45:23 DISPATCHER: Finished worker discovery
00:46:23 DISPATCHER: Starting worker discovery
00:46:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:46:23 DISPATCHER: Finished worker discovery
00:47:23 DISPATCHER: Starting worker discovery
00:47:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:47:23 DISPATCHER: Finished worker discovery
00:48:23 DISPATCHER: Starting worker discovery
00:48:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:48:23 DISPATCHER: Finished worker discovery
00:48:30 WORKER: done with job (1, 0, 2), trying to register it.
00:48:30 WORKER: registered result for job (1, 0, 2) with dispatcher
00:48:30 DISPATCHER: job (1, 0, 2) finished
00:48:30 DISPATCHER: register_result: lock acquired
00:48:30 DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
00:48:30 job_id: (1, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 705, 'last_n_outputs': 49, 'leak_rate': 0.8575101486849972, 'lr': 0.0011117571841695445, 'optimizer': 'SGD', 'sparsity': 0.8413448395982719, 'steps_to_train': 59, 'weight_decay': 0.08201210178669058}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7173098527634301, 'info': {'data05': 0.7173098527634301, 'config': "{'batch_size': 32, 'hidden_dim': 705, 'last_n_outputs': 49, 'leak_rate': 0.8575101486849972, 'lr': 0.0011117571841695445, 'optimizer': 'SGD', 'sparsity': 0.8413448395982719, 'steps_to_train': 59, 'weight_decay': 0.08201210178669058}"}}
exception: None

00:48:30 job_callback for (1, 0, 2) started
00:48:30 job_callback for (1, 0, 2) got condition
00:48:30 DISPATCHER: Trying to submit another job.
00:48:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:48:30 Only 5 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
00:48:30 HBMASTER: Trying to run another job!
00:48:30 job_callback for (1, 0, 2) finished
00:48:30 HBMASTER: schedule new run for iteration 1
00:48:30 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
00:48:30 HBMASTER: submitting job (1, 0, 4) to dispatcher
00:48:30 DISPATCHER: trying to submit job (1, 0, 4)
00:48:30 DISPATCHER: trying to notify the job_runner thread.
00:48:30 HBMASTER: job (1, 0, 4) submitted to dispatcher
00:48:30 DISPATCHER: Trying to submit another job.
00:48:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:48:30 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:48:30 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:48:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:48:30 WORKER: start processing job (1, 0, 4)
00:48:30 WORKER: args: ()
00:48:30 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 242, 'last_n_outputs': 45, 'leak_rate': 0.8385268624882811, 'lr': 0.005982944669676063, 'optimizer': 'SGD', 'sparsity': 0.9843226395635751, 'steps_to_train': 83, 'weight_decay': 0.01384207298536242}, 'budget': 400.0, 'working_directory': '.'}
00:49:23 DISPATCHER: Starting worker discovery
00:49:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:49:23 DISPATCHER: Finished worker discovery
00:50:23 DISPATCHER: Starting worker discovery
00:50:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:50:23 DISPATCHER: Finished worker discovery
00:51:23 DISPATCHER: Starting worker discovery
00:51:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:51:23 DISPATCHER: Finished worker discovery
00:52:23 DISPATCHER: Starting worker discovery
00:52:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:52:23 DISPATCHER: Finished worker discovery
00:53:23 DISPATCHER: Starting worker discovery
00:53:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:53:23 DISPATCHER: Finished worker discovery
00:54:23 DISPATCHER: Starting worker discovery
00:54:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:54:23 DISPATCHER: Finished worker discovery
00:55:23 DISPATCHER: Starting worker discovery
00:55:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:55:23 DISPATCHER: Finished worker discovery
00:55:26 WORKER: done with job (1, 0, 4), trying to register it.
00:55:26 WORKER: registered result for job (1, 0, 4) with dispatcher
00:55:26 DISPATCHER: job (1, 0, 4) finished
00:55:26 DISPATCHER: register_result: lock acquired
00:55:26 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
00:55:26 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 242, 'last_n_outputs': 45, 'leak_rate': 0.8385268624882811, 'lr': 0.005982944669676063, 'optimizer': 'SGD', 'sparsity': 0.9843226395635751, 'steps_to_train': 83, 'weight_decay': 0.01384207298536242}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6886081015629513, 'info': {'data05': 0.6886081015629513, 'config': "{'batch_size': 128, 'hidden_dim': 242, 'last_n_outputs': 45, 'leak_rate': 0.8385268624882811, 'lr': 0.005982944669676063, 'optimizer': 'SGD', 'sparsity': 0.9843226395635751, 'steps_to_train': 83, 'weight_decay': 0.01384207298536242}"}}
exception: None

00:55:26 job_callback for (1, 0, 4) started
00:55:26 DISPATCHER: Trying to submit another job.
00:55:26 job_callback for (1, 0, 4) got condition
00:55:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:55:26 Only 6 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
00:55:26 HBMASTER: Trying to run another job!
00:55:26 job_callback for (1, 0, 4) finished
00:55:26 ITERATION: Advancing config (1, 0, 0) to next budget 1200.000000
00:55:26 HBMASTER: schedule new run for iteration 1
00:55:26 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
00:55:26 HBMASTER: submitting job (1, 0, 0) to dispatcher
00:55:26 DISPATCHER: trying to submit job (1, 0, 0)
00:55:26 DISPATCHER: trying to notify the job_runner thread.
00:55:26 HBMASTER: job (1, 0, 0) submitted to dispatcher
00:55:26 DISPATCHER: Trying to submit another job.
00:55:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:55:26 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:55:26 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:55:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:55:26 WORKER: start processing job (1, 0, 0)
00:55:26 WORKER: args: ()
00:55:26 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 768, 'last_n_outputs': 49, 'leak_rate': 0.8004559285365549, 'lr': 0.04366006439919181, 'optimizer': 'SGD', 'sparsity': 0.8417775115843437, 'steps_to_train': 82, 'weight_decay': 0.016264508622655337}, 'budget': 1200.0, 'working_directory': '.'}
00:56:23 DISPATCHER: Starting worker discovery
00:56:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:56:23 DISPATCHER: Finished worker discovery
00:57:23 DISPATCHER: Starting worker discovery
00:57:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:57:23 DISPATCHER: Finished worker discovery
00:58:23 DISPATCHER: Starting worker discovery
00:58:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:58:23 DISPATCHER: Finished worker discovery
00:59:23 DISPATCHER: Starting worker discovery
00:59:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:59:23 DISPATCHER: Finished worker discovery
01:00:23 DISPATCHER: Starting worker discovery
01:00:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:00:23 DISPATCHER: Finished worker discovery
01:01:23 DISPATCHER: Starting worker discovery
01:01:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:01:23 DISPATCHER: Finished worker discovery
01:02:23 DISPATCHER: Starting worker discovery
01:02:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:02:23 DISPATCHER: Finished worker discovery
01:03:23 DISPATCHER: Starting worker discovery
01:03:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:03:23 DISPATCHER: Finished worker discovery
01:04:23 DISPATCHER: Starting worker discovery
01:04:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:04:23 DISPATCHER: Finished worker discovery
01:05:23 DISPATCHER: Starting worker discovery
01:05:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:05:23 DISPATCHER: Finished worker discovery
01:06:23 DISPATCHER: Starting worker discovery
01:06:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:06:23 DISPATCHER: Finished worker discovery
01:07:23 DISPATCHER: Starting worker discovery
01:07:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:07:23 DISPATCHER: Finished worker discovery
01:08:23 DISPATCHER: Starting worker discovery
01:08:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:08:23 DISPATCHER: Finished worker discovery
01:09:23 DISPATCHER: Starting worker discovery
01:09:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:09:23 DISPATCHER: Finished worker discovery
01:10:23 DISPATCHER: Starting worker discovery
01:10:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:10:23 DISPATCHER: Finished worker discovery
01:11:23 DISPATCHER: Starting worker discovery
01:11:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:11:23 DISPATCHER: Finished worker discovery
01:12:23 DISPATCHER: Starting worker discovery
01:12:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:12:23 DISPATCHER: Finished worker discovery
01:13:23 DISPATCHER: Starting worker discovery
01:13:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:13:23 DISPATCHER: Finished worker discovery
01:14:23 DISPATCHER: Starting worker discovery
01:14:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:14:23 DISPATCHER: Finished worker discovery
01:15:23 DISPATCHER: Starting worker discovery
01:15:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:15:23 DISPATCHER: Finished worker discovery
01:15:44 WORKER: done with job (1, 0, 0), trying to register it.
01:15:44 WORKER: registered result for job (1, 0, 0) with dispatcher
01:15:44 DISPATCHER: job (1, 0, 0) finished
01:15:44 DISPATCHER: register_result: lock acquired
01:15:44 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:15:44 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 768, 'last_n_outputs': 49, 'leak_rate': 0.8004559285365549, 'lr': 0.04366006439919181, 'optimizer': 'SGD', 'sparsity': 0.8417775115843437, 'steps_to_train': 82, 'weight_decay': 0.016264508622655337}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.7641389969249914, 'info': {'data05': 0.7641389969249914, 'config': "{'batch_size': 128, 'hidden_dim': 768, 'last_n_outputs': 49, 'leak_rate': 0.8004559285365549, 'lr': 0.04366006439919181, 'optimizer': 'SGD', 'sparsity': 0.8417775115843437, 'steps_to_train': 82, 'weight_decay': 0.016264508622655337}"}}
exception: None

01:15:44 job_callback for (1, 0, 0) started
01:15:44 job_callback for (1, 0, 0) got condition
01:15:44 DISPATCHER: Trying to submit another job.
01:15:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:15:44 Only 2 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
01:15:44 HBMASTER: Trying to run another job!
01:15:44 job_callback for (1, 0, 0) finished
01:15:44 start sampling a new configuration.
01:15:44 best_vector: [2, 0.931396326215137, 0.9467363954152777, 0.9200918673786185, 0.16363862607865293, 1, 0.8524388141507407, 0.011089812170461066, 0.6686902976076463], 0.00023882605069885978, 0.10462880686984569, 2.4988084734058974e-05
01:15:44 done sampling a new configuration.
01:15:44 HBMASTER: schedule new run for iteration 2
01:15:44 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
01:15:44 HBMASTER: submitting job (2, 0, 0) to dispatcher
01:15:44 DISPATCHER: trying to submit job (2, 0, 0)
01:15:44 DISPATCHER: trying to notify the job_runner thread.
01:15:44 HBMASTER: job (2, 0, 0) submitted to dispatcher
01:15:44 DISPATCHER: Trying to submit another job.
01:15:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:15:44 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:15:44 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:15:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:15:44 WORKER: start processing job (2, 0, 0)
01:15:44 WORKER: args: ()
01:15:44 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 946, 'last_n_outputs': 48, 'leak_rate': 0.9800229668446546, 'lr': 0.002124600366981531, 'optimizer': 'SGD', 'sparsity': 0.9545853153961777, 'steps_to_train': 11, 'weight_decay': 0.07412865750903984}, 'budget': 400.0, 'working_directory': '.'}
01:16:23 DISPATCHER: Starting worker discovery
01:16:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:16:23 DISPATCHER: Finished worker discovery
01:17:23 DISPATCHER: Starting worker discovery
01:17:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:17:23 DISPATCHER: Finished worker discovery
01:18:23 DISPATCHER: Starting worker discovery
01:18:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:18:23 DISPATCHER: Finished worker discovery
01:19:23 DISPATCHER: Starting worker discovery
01:19:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:19:23 DISPATCHER: Finished worker discovery
01:20:23 DISPATCHER: Starting worker discovery
01:20:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:20:23 DISPATCHER: Finished worker discovery
01:21:23 DISPATCHER: Starting worker discovery
01:21:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:21:23 DISPATCHER: Finished worker discovery
01:22:23 DISPATCHER: Starting worker discovery
01:22:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:22:23 DISPATCHER: Finished worker discovery
01:22:45 WORKER: done with job (2, 0, 0), trying to register it.
01:22:45 WORKER: registered result for job (2, 0, 0) with dispatcher
01:22:45 DISPATCHER: job (2, 0, 0) finished
01:22:45 DISPATCHER: register_result: lock acquired
01:22:45 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:22:45 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 946, 'last_n_outputs': 48, 'leak_rate': 0.9800229668446546, 'lr': 0.002124600366981531, 'optimizer': 'SGD', 'sparsity': 0.9545853153961777, 'steps_to_train': 11, 'weight_decay': 0.07412865750903984}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7358000190617321, 'info': {'data05': 0.7358000190617321, 'config': "{'batch_size': 64, 'hidden_dim': 946, 'last_n_outputs': 48, 'leak_rate': 0.9800229668446546, 'lr': 0.002124600366981531, 'optimizer': 'SGD', 'sparsity': 0.9545853153961777, 'steps_to_train': 11, 'weight_decay': 0.07412865750903984}"}}
exception: None

01:22:45 job_callback for (2, 0, 0) started
01:22:45 DISPATCHER: Trying to submit another job.
01:22:45 job_callback for (2, 0, 0) got condition
01:22:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:22:45 Only 7 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
01:22:45 HBMASTER: Trying to run another job!
01:22:45 job_callback for (2, 0, 0) finished
01:22:45 start sampling a new configuration.
01:22:46 best_vector: [3, 0.9933306948446141, 0.9283386399852015, 0.024415155037448733, 0.4103297990206379, 1, 0.9251119792113454, 0.22940571737345827, 0.7523308689370911], 0.0009268909819698362, 0.13836770066349952, 0.00012825177394089942
01:22:46 done sampling a new configuration.
01:22:46 HBMASTER: schedule new run for iteration 2
01:22:46 HBMASTER: trying submitting job (2, 0, 1) to dispatcher
01:22:46 HBMASTER: submitting job (2, 0, 1) to dispatcher
01:22:46 DISPATCHER: trying to submit job (2, 0, 1)
01:22:46 DISPATCHER: trying to notify the job_runner thread.
01:22:46 HBMASTER: job (2, 0, 1) submitted to dispatcher
01:22:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:22:46 DISPATCHER: Trying to submit another job.
01:22:46 DISPATCHER: starting job (2, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:22:46 DISPATCHER: job (2, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:22:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:22:46 WORKER: start processing job (2, 0, 1)
01:22:46 WORKER: args: ()
01:22:46 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 995, 'last_n_outputs': 48, 'leak_rate': 0.7561037887593622, 'lr': 0.006616976588052614, 'optimizer': 'SGD', 'sparsity': 0.9720268750107228, 'steps_to_train': 30, 'weight_decay': 0.09523685102157013}, 'budget': 400.0, 'working_directory': '.'}
01:23:23 DISPATCHER: Starting worker discovery
01:23:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:23:23 DISPATCHER: Finished worker discovery
01:24:23 DISPATCHER: Starting worker discovery
01:24:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:24:23 DISPATCHER: Finished worker discovery
01:25:23 DISPATCHER: Starting worker discovery
01:25:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:25:23 DISPATCHER: Finished worker discovery
01:26:23 DISPATCHER: Starting worker discovery
01:26:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:26:23 DISPATCHER: Finished worker discovery
01:27:23 DISPATCHER: Starting worker discovery
01:27:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:27:23 DISPATCHER: Finished worker discovery
01:28:23 DISPATCHER: Starting worker discovery
01:28:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:28:23 DISPATCHER: Finished worker discovery
01:29:23 DISPATCHER: Starting worker discovery
01:29:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:29:23 DISPATCHER: Finished worker discovery
01:29:43 WORKER: done with job (2, 0, 1), trying to register it.
01:29:43 WORKER: registered result for job (2, 0, 1) with dispatcher
01:29:43 DISPATCHER: job (2, 0, 1) finished
01:29:43 DISPATCHER: register_result: lock acquired
01:29:43 DISPATCHER: job (2, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:29:43 job_id: (2, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 995, 'last_n_outputs': 48, 'leak_rate': 0.7561037887593622, 'lr': 0.006616976588052614, 'optimizer': 'SGD', 'sparsity': 0.9720268750107228, 'steps_to_train': 30, 'weight_decay': 0.09523685102157013}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7735065344592348, 'info': {'data05': 0.7735065344592348, 'config': "{'batch_size': 128, 'hidden_dim': 995, 'last_n_outputs': 48, 'leak_rate': 0.7561037887593622, 'lr': 0.006616976588052614, 'optimizer': 'SGD', 'sparsity': 0.9720268750107228, 'steps_to_train': 30, 'weight_decay': 0.09523685102157013}"}}
exception: None

01:29:43 job_callback for (2, 0, 1) started
01:29:43 DISPATCHER: Trying to submit another job.
01:29:43 job_callback for (2, 0, 1) got condition
01:29:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:29:43 Only 8 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
01:29:43 HBMASTER: Trying to run another job!
01:29:43 job_callback for (2, 0, 1) finished
01:29:43 start sampling a new configuration.
01:29:43 best_vector: [1, 0.46805246487003366, 0.940183468674958, 0.9205457413113441, 0.33478511443281767, 1, 0.27124274866088016, 0.1860935044340638, 0.9476566420698527], 6.422378950572809e-05, 0.17370910863688674, 1.1156257228323066e-05
01:29:43 done sampling a new configuration.
01:29:43 HBMASTER: schedule new run for iteration 2
01:29:43 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
01:29:43 HBMASTER: submitting job (2, 0, 2) to dispatcher
01:29:43 DISPATCHER: trying to submit job (2, 0, 2)
01:29:43 DISPATCHER: trying to notify the job_runner thread.
01:29:43 HBMASTER: job (2, 0, 2) submitted to dispatcher
01:29:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:29:43 DISPATCHER: Trying to submit another job.
01:29:43 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:29:43 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:29:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:29:43 WORKER: start processing job (2, 0, 2)
01:29:43 WORKER: args: ()
01:29:43 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 574, 'last_n_outputs': 48, 'leak_rate': 0.980136435327836, 'lr': 0.0046727250673681536, 'optimizer': 'SGD', 'sparsity': 0.8150982596786113, 'steps_to_train': 26, 'weight_decay': 0.1709738600974625}, 'budget': 400.0, 'working_directory': '.'}
01:30:23 DISPATCHER: Starting worker discovery
01:30:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:30:23 DISPATCHER: Finished worker discovery
01:31:23 DISPATCHER: Starting worker discovery
01:31:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:31:23 DISPATCHER: Finished worker discovery
01:32:23 DISPATCHER: Starting worker discovery
01:32:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:32:23 DISPATCHER: Finished worker discovery
01:33:23 DISPATCHER: Starting worker discovery
01:33:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:33:23 DISPATCHER: Finished worker discovery
01:34:23 DISPATCHER: Starting worker discovery
01:34:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:34:23 DISPATCHER: Finished worker discovery
01:35:23 DISPATCHER: Starting worker discovery
01:35:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:35:23 DISPATCHER: Finished worker discovery
01:36:23 DISPATCHER: Starting worker discovery
01:36:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:36:23 DISPATCHER: Finished worker discovery
01:36:40 WORKER: done with job (2, 0, 2), trying to register it.
01:36:41 WORKER: registered result for job (2, 0, 2) with dispatcher
01:36:41 DISPATCHER: job (2, 0, 2) finished
01:36:41 DISPATCHER: register_result: lock acquired
01:36:41 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:36:41 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 574, 'last_n_outputs': 48, 'leak_rate': 0.980136435327836, 'lr': 0.0046727250673681536, 'optimizer': 'SGD', 'sparsity': 0.8150982596786113, 'steps_to_train': 26, 'weight_decay': 0.1709738600974625}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7197051877457161, 'info': {'data05': 0.7197051877457161, 'config': "{'batch_size': 32, 'hidden_dim': 574, 'last_n_outputs': 48, 'leak_rate': 0.980136435327836, 'lr': 0.0046727250673681536, 'optimizer': 'SGD', 'sparsity': 0.8150982596786113, 'steps_to_train': 26, 'weight_decay': 0.1709738600974625}"}}
exception: None

01:36:41 job_callback for (2, 0, 2) started
01:36:41 DISPATCHER: Trying to submit another job.
01:36:41 job_callback for (2, 0, 2) got condition
01:36:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:36:41 Only 9 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
01:36:41 HBMASTER: Trying to run another job!
01:36:41 job_callback for (2, 0, 2) finished
01:36:41 start sampling a new configuration.
01:36:41 done sampling a new configuration.
01:36:41 HBMASTER: schedule new run for iteration 2
01:36:41 HBMASTER: trying submitting job (2, 0, 3) to dispatcher
01:36:41 HBMASTER: submitting job (2, 0, 3) to dispatcher
01:36:41 DISPATCHER: trying to submit job (2, 0, 3)
01:36:41 DISPATCHER: trying to notify the job_runner thread.
01:36:41 HBMASTER: job (2, 0, 3) submitted to dispatcher
01:36:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:36:41 DISPATCHER: Trying to submit another job.
01:36:41 DISPATCHER: starting job (2, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:36:41 DISPATCHER: job (2, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:36:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:36:41 WORKER: start processing job (2, 0, 3)
01:36:41 WORKER: args: ()
01:36:41 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 793, 'last_n_outputs': 21, 'leak_rate': 0.8474782248497745, 'lr': 0.008970454417823143, 'optimizer': 'Adam', 'sparsity': 0.8442829432564147, 'steps_to_train': 84, 'weight_decay': 0.010342497915273795}, 'budget': 400.0, 'working_directory': '.'}
01:37:23 DISPATCHER: Starting worker discovery
01:37:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:37:23 DISPATCHER: Finished worker discovery
01:38:23 DISPATCHER: Starting worker discovery
01:38:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:38:23 DISPATCHER: Finished worker discovery
01:39:23 DISPATCHER: Starting worker discovery
01:39:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:39:23 DISPATCHER: Finished worker discovery
01:40:23 DISPATCHER: Starting worker discovery
01:40:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:40:23 DISPATCHER: Finished worker discovery
01:41:23 DISPATCHER: Starting worker discovery
01:41:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:41:23 DISPATCHER: Finished worker discovery
01:42:23 DISPATCHER: Starting worker discovery
01:42:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:42:23 DISPATCHER: Finished worker discovery
01:43:23 DISPATCHER: Starting worker discovery
01:43:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:43:23 DISPATCHER: Finished worker discovery
01:43:43 WORKER: done with job (2, 0, 3), trying to register it.
01:43:43 WORKER: registered result for job (2, 0, 3) with dispatcher
01:43:43 DISPATCHER: job (2, 0, 3) finished
01:43:43 DISPATCHER: register_result: lock acquired
01:43:43 DISPATCHER: job (2, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:43:43 job_id: (2, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 793, 'last_n_outputs': 21, 'leak_rate': 0.8474782248497745, 'lr': 0.008970454417823143, 'optimizer': 'Adam', 'sparsity': 0.8442829432564147, 'steps_to_train': 84, 'weight_decay': 0.010342497915273795}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6400991151996132, 'info': {'data05': 0.6400991151996132, 'config': "{'batch_size': 128, 'hidden_dim': 793, 'last_n_outputs': 21, 'leak_rate': 0.8474782248497745, 'lr': 0.008970454417823143, 'optimizer': 'Adam', 'sparsity': 0.8442829432564147, 'steps_to_train': 84, 'weight_decay': 0.010342497915273795}"}}
exception: None

01:43:43 job_callback for (2, 0, 3) started
01:43:43 DISPATCHER: Trying to submit another job.
01:43:43 job_callback for (2, 0, 3) got condition
01:43:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:43:43 HBMASTER: Trying to run another job!
01:43:43 job_callback for (2, 0, 3) finished
01:43:43 start sampling a new configuration.
01:43:43 best_vector: [1, 0.5971926128265336, 0.9406260444449334, 0.1974906089233993, 0.23304041305677475, 1, 0.07853096280243177, 0.9852814451140567, 0.04621755449245599], 0.00013688592290957472, 0.026283482778852462, 3.597838797461133e-06
01:43:43 done sampling a new configuration.
01:43:43 HBMASTER: schedule new run for iteration 2
01:43:43 HBMASTER: trying submitting job (2, 0, 4) to dispatcher
01:43:43 HBMASTER: submitting job (2, 0, 4) to dispatcher
01:43:43 DISPATCHER: trying to submit job (2, 0, 4)
01:43:43 DISPATCHER: trying to notify the job_runner thread.
01:43:43 HBMASTER: job (2, 0, 4) submitted to dispatcher
01:43:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:43:43 DISPATCHER: Trying to submit another job.
01:43:43 DISPATCHER: starting job (2, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:43:43 DISPATCHER: job (2, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:43:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:43:43 WORKER: start processing job (2, 0, 4)
01:43:43 WORKER: args: ()
01:43:43 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 678, 'last_n_outputs': 48, 'leak_rate': 0.7993726522308499, 'lr': 0.002924696639574891, 'optimizer': 'SGD', 'sparsity': 0.7688474310725836, 'steps_to_train': 99, 'weight_decay': 0.011484984799047214}, 'budget': 400.0, 'working_directory': '.'}
01:44:23 DISPATCHER: Starting worker discovery
01:44:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:44:23 DISPATCHER: Finished worker discovery
01:45:23 DISPATCHER: Starting worker discovery
01:45:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:45:23 DISPATCHER: Finished worker discovery
01:46:23 DISPATCHER: Starting worker discovery
01:46:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:46:23 DISPATCHER: Finished worker discovery
01:47:23 DISPATCHER: Starting worker discovery
01:47:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:47:23 DISPATCHER: Finished worker discovery
01:48:23 DISPATCHER: Starting worker discovery
01:48:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:48:23 DISPATCHER: Finished worker discovery
01:49:23 DISPATCHER: Starting worker discovery
01:49:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:49:23 DISPATCHER: Finished worker discovery
01:50:23 DISPATCHER: Starting worker discovery
01:50:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:50:23 DISPATCHER: Finished worker discovery
01:50:42 WORKER: done with job (2, 0, 4), trying to register it.
01:50:42 WORKER: registered result for job (2, 0, 4) with dispatcher
01:50:42 DISPATCHER: job (2, 0, 4) finished
01:50:42 DISPATCHER: register_result: lock acquired
01:50:42 DISPATCHER: job (2, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:50:42 job_id: (2, 0, 4)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 678, 'last_n_outputs': 48, 'leak_rate': 0.7993726522308499, 'lr': 0.002924696639574891, 'optimizer': 'SGD', 'sparsity': 0.7688474310725836, 'steps_to_train': 99, 'weight_decay': 0.011484984799047214}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7424005982568682, 'info': {'data05': 0.7424005982568682, 'config': "{'batch_size': 32, 'hidden_dim': 678, 'last_n_outputs': 48, 'leak_rate': 0.7993726522308499, 'lr': 0.002924696639574891, 'optimizer': 'SGD', 'sparsity': 0.7688474310725836, 'steps_to_train': 99, 'weight_decay': 0.011484984799047214}"}}
exception: None

01:50:42 job_callback for (2, 0, 4) started
01:50:42 job_callback for (2, 0, 4) got condition
01:50:42 DISPATCHER: Trying to submit another job.
01:50:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:50:42 HBMASTER: Trying to run another job!
01:50:42 job_callback for (2, 0, 4) finished
01:50:42 start sampling a new configuration.
01:50:42 done sampling a new configuration.
01:50:42 HBMASTER: schedule new run for iteration 2
01:50:42 HBMASTER: trying submitting job (2, 0, 5) to dispatcher
01:50:42 HBMASTER: submitting job (2, 0, 5) to dispatcher
01:50:42 DISPATCHER: trying to submit job (2, 0, 5)
01:50:42 DISPATCHER: trying to notify the job_runner thread.
01:50:42 HBMASTER: job (2, 0, 5) submitted to dispatcher
01:50:42 DISPATCHER: Trying to submit another job.
01:50:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:50:42 DISPATCHER: starting job (2, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:50:42 DISPATCHER: job (2, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:50:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:50:42 WORKER: start processing job (2, 0, 5)
01:50:42 WORKER: args: ()
01:50:42 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 954, 'last_n_outputs': 18, 'leak_rate': 0.8245752619620914, 'lr': 0.02431685482378216, 'optimizer': 'SGD', 'sparsity': 0.7783218561603024, 'steps_to_train': 84, 'weight_decay': 0.05824882174194135}, 'budget': 400.0, 'working_directory': '.'}
01:51:23 DISPATCHER: Starting worker discovery
01:51:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:51:23 DISPATCHER: Finished worker discovery
01:52:23 DISPATCHER: Starting worker discovery
01:52:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:52:23 DISPATCHER: Finished worker discovery
01:53:23 DISPATCHER: Starting worker discovery
01:53:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:53:23 DISPATCHER: Finished worker discovery
01:54:23 DISPATCHER: Starting worker discovery
01:54:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:54:23 DISPATCHER: Finished worker discovery
01:55:23 DISPATCHER: Starting worker discovery
01:55:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:55:23 DISPATCHER: Finished worker discovery
01:56:23 DISPATCHER: Starting worker discovery
01:56:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:56:23 DISPATCHER: Finished worker discovery
01:57:23 DISPATCHER: Starting worker discovery
01:57:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:57:23 DISPATCHER: Finished worker discovery
01:57:35 WORKER: done with job (2, 0, 5), trying to register it.
01:57:35 WORKER: registered result for job (2, 0, 5) with dispatcher
01:57:35 DISPATCHER: job (2, 0, 5) finished
01:57:35 DISPATCHER: register_result: lock acquired
01:57:35 DISPATCHER: job (2, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:57:35 job_id: (2, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 954, 'last_n_outputs': 18, 'leak_rate': 0.8245752619620914, 'lr': 0.02431685482378216, 'optimizer': 'SGD', 'sparsity': 0.7783218561603024, 'steps_to_train': 84, 'weight_decay': 0.05824882174194135}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.578561965172945, 'info': {'data05': 0.578561965172945, 'config': "{'batch_size': 128, 'hidden_dim': 954, 'last_n_outputs': 18, 'leak_rate': 0.8245752619620914, 'lr': 0.02431685482378216, 'optimizer': 'SGD', 'sparsity': 0.7783218561603024, 'steps_to_train': 84, 'weight_decay': 0.05824882174194135}"}}
exception: None

01:57:35 job_callback for (2, 0, 5) started
01:57:35 DISPATCHER: Trying to submit another job.
01:57:35 job_callback for (2, 0, 5) got condition
01:57:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:57:35 HBMASTER: Trying to run another job!
01:57:35 job_callback for (2, 0, 5) finished
01:57:35 ITERATION: Advancing config (2, 0, 1) to next budget 1200.000000
01:57:35 ITERATION: Advancing config (2, 0, 4) to next budget 1200.000000
01:57:35 HBMASTER: schedule new run for iteration 2
01:57:35 HBMASTER: trying submitting job (2, 0, 1) to dispatcher
01:57:35 HBMASTER: submitting job (2, 0, 1) to dispatcher
01:57:35 DISPATCHER: trying to submit job (2, 0, 1)
01:57:35 DISPATCHER: trying to notify the job_runner thread.
01:57:35 HBMASTER: job (2, 0, 1) submitted to dispatcher
01:57:35 DISPATCHER: Trying to submit another job.
01:57:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:57:35 DISPATCHER: starting job (2, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:57:35 DISPATCHER: job (2, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:57:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:57:35 WORKER: start processing job (2, 0, 1)
01:57:35 WORKER: args: ()
01:57:35 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 995, 'last_n_outputs': 48, 'leak_rate': 0.7561037887593622, 'lr': 0.006616976588052614, 'optimizer': 'SGD', 'sparsity': 0.9720268750107228, 'steps_to_train': 30, 'weight_decay': 0.09523685102157013}, 'budget': 1200.0, 'working_directory': '.'}
01:58:23 DISPATCHER: Starting worker discovery
01:58:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:58:23 DISPATCHER: Finished worker discovery
01:59:23 DISPATCHER: Starting worker discovery
01:59:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:59:23 DISPATCHER: Finished worker discovery
02:00:23 DISPATCHER: Starting worker discovery
02:00:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:00:23 DISPATCHER: Finished worker discovery
02:01:23 DISPATCHER: Starting worker discovery
02:01:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:01:23 DISPATCHER: Finished worker discovery
02:02:23 DISPATCHER: Starting worker discovery
02:02:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:02:23 DISPATCHER: Finished worker discovery
02:03:23 DISPATCHER: Starting worker discovery
02:03:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:03:23 DISPATCHER: Finished worker discovery
02:04:23 DISPATCHER: Starting worker discovery
02:04:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:04:23 DISPATCHER: Finished worker discovery
02:05:23 DISPATCHER: Starting worker discovery
02:05:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:05:23 DISPATCHER: Finished worker discovery
02:06:23 DISPATCHER: Starting worker discovery
02:06:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:06:23 DISPATCHER: Finished worker discovery
02:07:23 DISPATCHER: Starting worker discovery
02:07:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:07:23 DISPATCHER: Finished worker discovery
02:08:23 DISPATCHER: Starting worker discovery
02:08:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:08:23 DISPATCHER: Finished worker discovery
02:09:23 DISPATCHER: Starting worker discovery
02:09:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:09:23 DISPATCHER: Finished worker discovery
02:10:23 DISPATCHER: Starting worker discovery
02:10:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:10:23 DISPATCHER: Finished worker discovery
02:11:23 DISPATCHER: Starting worker discovery
02:11:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:11:23 DISPATCHER: Finished worker discovery
02:12:23 DISPATCHER: Starting worker discovery
02:12:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:12:23 DISPATCHER: Finished worker discovery
02:13:23 DISPATCHER: Starting worker discovery
02:13:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:13:23 DISPATCHER: Finished worker discovery
02:14:23 DISPATCHER: Starting worker discovery
02:14:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:14:23 DISPATCHER: Finished worker discovery
02:15:23 DISPATCHER: Starting worker discovery
02:15:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:15:23 DISPATCHER: Finished worker discovery
02:16:23 DISPATCHER: Starting worker discovery
02:16:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:16:23 DISPATCHER: Finished worker discovery
02:17:23 DISPATCHER: Starting worker discovery
02:17:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:17:23 DISPATCHER: Finished worker discovery
02:17:58 WORKER: done with job (2, 0, 1), trying to register it.
02:17:58 WORKER: registered result for job (2, 0, 1) with dispatcher
02:17:58 DISPATCHER: job (2, 0, 1) finished
02:17:58 DISPATCHER: register_result: lock acquired
02:17:58 DISPATCHER: job (2, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
02:17:58 job_id: (2, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 995, 'last_n_outputs': 48, 'leak_rate': 0.7561037887593622, 'lr': 0.006616976588052614, 'optimizer': 'SGD', 'sparsity': 0.9720268750107228, 'steps_to_train': 30, 'weight_decay': 0.09523685102157013}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.7731647509266937, 'info': {'data05': 0.7731647509266937, 'config': "{'batch_size': 128, 'hidden_dim': 995, 'last_n_outputs': 48, 'leak_rate': 0.7561037887593622, 'lr': 0.006616976588052614, 'optimizer': 'SGD', 'sparsity': 0.9720268750107228, 'steps_to_train': 30, 'weight_decay': 0.09523685102157013}"}}
exception: None

02:17:58 job_callback for (2, 0, 1) started
02:17:58 DISPATCHER: Trying to submit another job.
02:17:58 job_callback for (2, 0, 1) got condition
02:17:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:17:58 Only 3 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
02:17:58 HBMASTER: Trying to run another job!
02:17:58 job_callback for (2, 0, 1) finished
02:17:58 HBMASTER: schedule new run for iteration 2
02:17:58 HBMASTER: trying submitting job (2, 0, 4) to dispatcher
02:17:58 HBMASTER: submitting job (2, 0, 4) to dispatcher
02:17:58 DISPATCHER: trying to submit job (2, 0, 4)
02:17:58 DISPATCHER: trying to notify the job_runner thread.
02:17:58 HBMASTER: job (2, 0, 4) submitted to dispatcher
02:17:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:17:58 DISPATCHER: Trying to submit another job.
02:17:58 DISPATCHER: starting job (2, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:17:58 DISPATCHER: job (2, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:17:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:17:58 WORKER: start processing job (2, 0, 4)
02:17:58 WORKER: args: ()
02:17:58 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 678, 'last_n_outputs': 48, 'leak_rate': 0.7993726522308499, 'lr': 0.002924696639574891, 'optimizer': 'SGD', 'sparsity': 0.7688474310725836, 'steps_to_train': 99, 'weight_decay': 0.011484984799047214}, 'budget': 1200.0, 'working_directory': '.'}
02:18:23 DISPATCHER: Starting worker discovery
02:18:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:18:23 DISPATCHER: Finished worker discovery
02:19:23 DISPATCHER: Starting worker discovery
02:19:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:19:23 DISPATCHER: Finished worker discovery
02:20:23 DISPATCHER: Starting worker discovery
02:20:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:20:23 DISPATCHER: Finished worker discovery
02:21:23 DISPATCHER: Starting worker discovery
02:21:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:21:23 DISPATCHER: Finished worker discovery
02:22:23 DISPATCHER: Starting worker discovery
02:22:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:22:23 DISPATCHER: Finished worker discovery
02:23:23 DISPATCHER: Starting worker discovery
02:23:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:23:23 DISPATCHER: Finished worker discovery
02:24:23 DISPATCHER: Starting worker discovery
02:24:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:24:23 DISPATCHER: Finished worker discovery
02:25:23 DISPATCHER: Starting worker discovery
02:25:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:25:23 DISPATCHER: Finished worker discovery
02:26:23 DISPATCHER: Starting worker discovery
02:26:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:26:23 DISPATCHER: Finished worker discovery
02:27:23 DISPATCHER: Starting worker discovery
02:27:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:27:23 DISPATCHER: Finished worker discovery
02:28:23 DISPATCHER: Starting worker discovery
02:28:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:28:23 DISPATCHER: Finished worker discovery
02:29:23 DISPATCHER: Starting worker discovery
02:29:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:29:23 DISPATCHER: Finished worker discovery
02:30:23 DISPATCHER: Starting worker discovery
02:30:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:30:23 DISPATCHER: Finished worker discovery
02:31:23 DISPATCHER: Starting worker discovery
02:31:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:31:23 DISPATCHER: Finished worker discovery
02:32:23 DISPATCHER: Starting worker discovery
02:32:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:32:23 DISPATCHER: Finished worker discovery
02:33:23 DISPATCHER: Starting worker discovery
02:33:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:33:23 DISPATCHER: Finished worker discovery
02:34:23 DISPATCHER: Starting worker discovery
02:34:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:34:23 DISPATCHER: Finished worker discovery
02:35:23 DISPATCHER: Starting worker discovery
02:35:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:35:23 DISPATCHER: Finished worker discovery
02:36:23 DISPATCHER: Starting worker discovery
02:36:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:36:24 DISPATCHER: Finished worker discovery
02:37:24 DISPATCHER: Starting worker discovery
02:37:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:37:24 DISPATCHER: Finished worker discovery
02:38:21 WORKER: done with job (2, 0, 4), trying to register it.
02:38:21 WORKER: registered result for job (2, 0, 4) with dispatcher
02:38:21 DISPATCHER: job (2, 0, 4) finished
02:38:21 DISPATCHER: register_result: lock acquired
02:38:21 DISPATCHER: job (2, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
02:38:21 job_id: (2, 0, 4)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 678, 'last_n_outputs': 48, 'leak_rate': 0.7993726522308499, 'lr': 0.002924696639574891, 'optimizer': 'SGD', 'sparsity': 0.7688474310725836, 'steps_to_train': 99, 'weight_decay': 0.011484984799047214}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.7485606628301902, 'info': {'data05': 0.7485606628301902, 'config': "{'batch_size': 32, 'hidden_dim': 678, 'last_n_outputs': 48, 'leak_rate': 0.7993726522308499, 'lr': 0.002924696639574891, 'optimizer': 'SGD', 'sparsity': 0.7688474310725836, 'steps_to_train': 99, 'weight_decay': 0.011484984799047214}"}}
exception: None

02:38:21 job_callback for (2, 0, 4) started
02:38:21 job_callback for (2, 0, 4) got condition
02:38:21 DISPATCHER: Trying to submit another job.
02:38:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:38:21 Only 4 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
02:38:21 HBMASTER: Trying to run another job!
02:38:21 job_callback for (2, 0, 4) finished
02:38:21 start sampling a new configuration.
02:38:21 done sampling a new configuration.
02:38:21 HBMASTER: schedule new run for iteration 3
02:38:21 HBMASTER: trying submitting job (3, 0, 0) to dispatcher
02:38:21 HBMASTER: submitting job (3, 0, 0) to dispatcher
02:38:21 DISPATCHER: trying to submit job (3, 0, 0)
02:38:21 DISPATCHER: trying to notify the job_runner thread.
02:38:21 HBMASTER: job (3, 0, 0) submitted to dispatcher
02:38:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:38:21 DISPATCHER: Trying to submit another job.
02:38:21 DISPATCHER: starting job (3, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:38:21 DISPATCHER: job (3, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:38:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:38:21 WORKER: start processing job (3, 0, 0)
02:38:21 WORKER: args: ()
02:38:21 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 228, 'last_n_outputs': 13, 'leak_rate': 0.8087078341808908, 'lr': 0.0012329714336443466, 'optimizer': 'Adam', 'sparsity': 0.830094475066896, 'steps_to_train': 49, 'weight_decay': 0.08768422905075798}, 'budget': 1200.0, 'working_directory': '.'}
02:38:24 DISPATCHER: Starting worker discovery
02:38:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:38:24 DISPATCHER: Finished worker discovery
02:39:24 DISPATCHER: Starting worker discovery
02:39:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:39:24 DISPATCHER: Finished worker discovery
02:40:24 DISPATCHER: Starting worker discovery
02:40:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:40:24 DISPATCHER: Finished worker discovery
02:41:24 DISPATCHER: Starting worker discovery
02:41:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:41:24 DISPATCHER: Finished worker discovery
02:42:24 DISPATCHER: Starting worker discovery
02:42:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:42:24 DISPATCHER: Finished worker discovery
02:43:24 DISPATCHER: Starting worker discovery
02:43:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:43:24 DISPATCHER: Finished worker discovery
02:44:24 DISPATCHER: Starting worker discovery
02:44:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:44:24 DISPATCHER: Finished worker discovery
02:45:24 DISPATCHER: Starting worker discovery
02:45:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:45:24 DISPATCHER: Finished worker discovery
02:46:24 DISPATCHER: Starting worker discovery
02:46:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:46:24 DISPATCHER: Finished worker discovery
02:47:24 DISPATCHER: Starting worker discovery
02:47:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:47:24 DISPATCHER: Finished worker discovery
02:48:24 DISPATCHER: Starting worker discovery
02:48:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:48:24 DISPATCHER: Finished worker discovery
02:49:24 DISPATCHER: Starting worker discovery
02:49:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:49:24 DISPATCHER: Finished worker discovery
02:50:24 DISPATCHER: Starting worker discovery
02:50:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:50:24 DISPATCHER: Finished worker discovery
02:51:24 DISPATCHER: Starting worker discovery
02:51:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:51:24 DISPATCHER: Finished worker discovery
02:52:24 DISPATCHER: Starting worker discovery
02:52:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:52:24 DISPATCHER: Finished worker discovery
02:53:24 DISPATCHER: Starting worker discovery
02:53:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:53:24 DISPATCHER: Finished worker discovery
02:54:24 DISPATCHER: Starting worker discovery
02:54:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:54:24 DISPATCHER: Finished worker discovery
02:55:24 DISPATCHER: Starting worker discovery
02:55:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:55:24 DISPATCHER: Finished worker discovery
02:56:24 DISPATCHER: Starting worker discovery
02:56:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:56:24 DISPATCHER: Finished worker discovery
02:57:24 DISPATCHER: Starting worker discovery
02:57:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:57:24 DISPATCHER: Finished worker discovery
02:58:24 DISPATCHER: Starting worker discovery
02:58:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:58:24 DISPATCHER: Finished worker discovery
02:58:40 WORKER: done with job (3, 0, 0), trying to register it.
02:58:40 WORKER: registered result for job (3, 0, 0) with dispatcher
02:58:40 DISPATCHER: job (3, 0, 0) finished
02:58:40 DISPATCHER: register_result: lock acquired
02:58:40 DISPATCHER: job (3, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
02:58:40 job_id: (3, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 228, 'last_n_outputs': 13, 'leak_rate': 0.8087078341808908, 'lr': 0.0012329714336443466, 'optimizer': 'Adam', 'sparsity': 0.830094475066896, 'steps_to_train': 49, 'weight_decay': 0.08768422905075798}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.44906154025939443, 'info': {'data05': 0.44906154025939443, 'config': "{'batch_size': 32, 'hidden_dim': 228, 'last_n_outputs': 13, 'leak_rate': 0.8087078341808908, 'lr': 0.0012329714336443466, 'optimizer': 'Adam', 'sparsity': 0.830094475066896, 'steps_to_train': 49, 'weight_decay': 0.08768422905075798}"}}
exception: None

02:58:40 job_callback for (3, 0, 0) started
02:58:40 DISPATCHER: Trying to submit another job.
02:58:40 job_callback for (3, 0, 0) got condition
02:58:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:58:40 Only 5 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
02:58:40 HBMASTER: Trying to run another job!
02:58:40 job_callback for (3, 0, 0) finished
02:58:40 start sampling a new configuration.
02:58:40 done sampling a new configuration.
02:58:40 HBMASTER: schedule new run for iteration 3
02:58:40 HBMASTER: trying submitting job (3, 0, 1) to dispatcher
02:58:40 HBMASTER: submitting job (3, 0, 1) to dispatcher
02:58:40 DISPATCHER: trying to submit job (3, 0, 1)
02:58:40 DISPATCHER: trying to notify the job_runner thread.
02:58:40 HBMASTER: job (3, 0, 1) submitted to dispatcher
02:58:40 DISPATCHER: Trying to submit another job.
02:58:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:58:40 DISPATCHER: starting job (3, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:58:40 DISPATCHER: job (3, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:58:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:58:40 WORKER: start processing job (3, 0, 1)
02:58:40 WORKER: args: ()
02:58:40 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 251, 'last_n_outputs': 30, 'leak_rate': 0.9176035106780855, 'lr': 0.07494003070984737, 'optimizer': 'SGD', 'sparsity': 0.914663660578731, 'steps_to_train': 27, 'weight_decay': 0.018534887333306646}, 'budget': 1200.0, 'working_directory': '.'}
02:59:24 DISPATCHER: Starting worker discovery
02:59:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:59:24 DISPATCHER: Finished worker discovery
03:00:24 DISPATCHER: Starting worker discovery
03:00:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:00:24 DISPATCHER: Finished worker discovery
03:01:24 DISPATCHER: Starting worker discovery
03:01:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:01:24 DISPATCHER: Finished worker discovery
03:02:24 DISPATCHER: Starting worker discovery
03:02:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:02:24 DISPATCHER: Finished worker discovery
03:03:24 DISPATCHER: Starting worker discovery
03:03:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:03:24 DISPATCHER: Finished worker discovery
03:04:24 DISPATCHER: Starting worker discovery
03:04:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:04:24 DISPATCHER: Finished worker discovery
03:05:24 DISPATCHER: Starting worker discovery
03:05:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:05:24 DISPATCHER: Finished worker discovery
03:06:24 DISPATCHER: Starting worker discovery
03:06:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:06:24 DISPATCHER: Finished worker discovery
03:07:24 DISPATCHER: Starting worker discovery
03:07:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:07:24 DISPATCHER: Finished worker discovery
03:08:24 DISPATCHER: Starting worker discovery
03:08:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:08:24 DISPATCHER: Finished worker discovery
03:09:24 DISPATCHER: Starting worker discovery
03:09:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:09:24 DISPATCHER: Finished worker discovery
03:10:24 DISPATCHER: Starting worker discovery
03:10:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:10:24 DISPATCHER: Finished worker discovery
03:11:24 DISPATCHER: Starting worker discovery
03:11:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:11:24 DISPATCHER: Finished worker discovery
03:12:24 DISPATCHER: Starting worker discovery
03:12:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:12:24 DISPATCHER: Finished worker discovery
03:13:24 DISPATCHER: Starting worker discovery
03:13:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:13:24 DISPATCHER: Finished worker discovery
03:14:24 DISPATCHER: Starting worker discovery
03:14:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:14:24 DISPATCHER: Finished worker discovery
03:15:24 DISPATCHER: Starting worker discovery
03:15:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:15:24 DISPATCHER: Finished worker discovery
03:16:24 DISPATCHER: Starting worker discovery
03:16:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:16:24 DISPATCHER: Finished worker discovery
03:17:24 DISPATCHER: Starting worker discovery
03:17:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:17:24 DISPATCHER: Finished worker discovery
03:18:24 DISPATCHER: Starting worker discovery
03:18:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:18:24 DISPATCHER: Finished worker discovery
03:19:06 WORKER: done with job (3, 0, 1), trying to register it.
03:19:07 WORKER: registered result for job (3, 0, 1) with dispatcher
03:19:07 DISPATCHER: job (3, 0, 1) finished
03:19:07 DISPATCHER: register_result: lock acquired
03:19:07 DISPATCHER: job (3, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
03:19:07 job_id: (3, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 251, 'last_n_outputs': 30, 'leak_rate': 0.9176035106780855, 'lr': 0.07494003070984737, 'optimizer': 'SGD', 'sparsity': 0.914663660578731, 'steps_to_train': 27, 'weight_decay': 0.018534887333306646}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.6117499703194877, 'info': {'data05': 0.6117499703194877, 'config': "{'batch_size': 64, 'hidden_dim': 251, 'last_n_outputs': 30, 'leak_rate': 0.9176035106780855, 'lr': 0.07494003070984737, 'optimizer': 'SGD', 'sparsity': 0.914663660578731, 'steps_to_train': 27, 'weight_decay': 0.018534887333306646}"}}
exception: None

03:19:07 job_callback for (3, 0, 1) started
03:19:07 job_callback for (3, 0, 1) got condition
03:19:07 DISPATCHER: Trying to submit another job.
03:19:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:19:07 Only 6 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
03:19:07 HBMASTER: Trying to run another job!
03:19:07 job_callback for (3, 0, 1) finished
03:19:07 start sampling a new configuration.
03:19:07 best_vector: [1, 0.7755350348654899, 0.7839185263550359, 0.8248668882714418, 0.03934254367662471, 1, 0.029808896854105926, 0.8712233250156096, 0.11544927835024692], 0.0004995451338041863, 0.02877917527629521, 1.437649696417102e-05
03:19:07 done sampling a new configuration.
03:19:07 HBMASTER: schedule new run for iteration 3
03:19:07 HBMASTER: trying submitting job (3, 0, 2) to dispatcher
03:19:07 HBMASTER: submitting job (3, 0, 2) to dispatcher
03:19:07 DISPATCHER: trying to submit job (3, 0, 2)
03:19:07 DISPATCHER: trying to notify the job_runner thread.
03:19:07 HBMASTER: job (3, 0, 2) submitted to dispatcher
03:19:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:19:07 DISPATCHER: Trying to submit another job.
03:19:07 DISPATCHER: starting job (3, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
03:19:07 DISPATCHER: job (3, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
03:19:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:19:07 WORKER: start processing job (3, 0, 2)
03:19:07 WORKER: args: ()
03:19:07 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 821, 'last_n_outputs': 42, 'leak_rate': 0.9562167220678605, 'lr': 0.0011986298456776795, 'optimizer': 'SGD', 'sparsity': 0.7571541352449854, 'steps_to_train': 89, 'weight_decay': 0.014131978697573514}, 'budget': 1200.0, 'working_directory': '.'}
03:19:24 DISPATCHER: Starting worker discovery
03:19:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:19:24 DISPATCHER: Finished worker discovery
03:20:24 DISPATCHER: Starting worker discovery
03:20:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:20:24 DISPATCHER: Finished worker discovery
03:21:24 DISPATCHER: Starting worker discovery
03:21:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:21:24 DISPATCHER: Finished worker discovery
03:22:24 DISPATCHER: Starting worker discovery
03:22:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:22:24 DISPATCHER: Finished worker discovery
03:23:24 DISPATCHER: Starting worker discovery
03:23:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:23:24 DISPATCHER: Finished worker discovery
03:24:24 DISPATCHER: Starting worker discovery
03:24:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:24:24 DISPATCHER: Finished worker discovery
03:25:24 DISPATCHER: Starting worker discovery
03:25:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:25:24 DISPATCHER: Finished worker discovery
03:26:24 DISPATCHER: Starting worker discovery
03:26:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:26:24 DISPATCHER: Finished worker discovery
03:27:24 DISPATCHER: Starting worker discovery
03:27:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:27:24 DISPATCHER: Finished worker discovery
03:28:24 DISPATCHER: Starting worker discovery
03:28:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:28:24 DISPATCHER: Finished worker discovery
03:29:24 DISPATCHER: Starting worker discovery
03:29:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:29:24 DISPATCHER: Finished worker discovery
03:30:24 DISPATCHER: Starting worker discovery
03:30:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:30:24 DISPATCHER: Finished worker discovery
03:31:24 DISPATCHER: Starting worker discovery
03:31:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:31:24 DISPATCHER: Finished worker discovery
03:32:24 DISPATCHER: Starting worker discovery
03:32:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:32:24 DISPATCHER: Finished worker discovery
03:33:24 DISPATCHER: Starting worker discovery
03:33:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:33:24 DISPATCHER: Finished worker discovery
03:34:24 DISPATCHER: Starting worker discovery
03:34:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:34:24 DISPATCHER: Finished worker discovery
03:35:24 DISPATCHER: Starting worker discovery
03:35:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:35:24 DISPATCHER: Finished worker discovery
03:36:24 DISPATCHER: Starting worker discovery
03:36:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:36:24 DISPATCHER: Finished worker discovery
03:37:24 DISPATCHER: Starting worker discovery
03:37:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:37:24 DISPATCHER: Finished worker discovery
03:38:24 DISPATCHER: Starting worker discovery
03:38:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:38:24 DISPATCHER: Finished worker discovery
03:39:24 DISPATCHER: Starting worker discovery
03:39:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:39:24 DISPATCHER: Finished worker discovery
03:39:31 WORKER: done with job (3, 0, 2), trying to register it.
03:39:31 WORKER: registered result for job (3, 0, 2) with dispatcher
03:39:31 DISPATCHER: job (3, 0, 2) finished
03:39:31 DISPATCHER: register_result: lock acquired
03:39:31 DISPATCHER: job (3, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
03:39:31 job_id: (3, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 821, 'last_n_outputs': 42, 'leak_rate': 0.9562167220678605, 'lr': 0.0011986298456776795, 'optimizer': 'SGD', 'sparsity': 0.7571541352449854, 'steps_to_train': 89, 'weight_decay': 0.014131978697573514}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.7150870288418574, 'info': {'data05': 0.7150870288418574, 'config': "{'batch_size': 32, 'hidden_dim': 821, 'last_n_outputs': 42, 'leak_rate': 0.9562167220678605, 'lr': 0.0011986298456776795, 'optimizer': 'SGD', 'sparsity': 0.7571541352449854, 'steps_to_train': 89, 'weight_decay': 0.014131978697573514}"}}
exception: None

03:39:31 job_callback for (3, 0, 2) started
03:39:31 job_callback for (3, 0, 2) got condition
03:39:31 DISPATCHER: Trying to submit another job.
03:39:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:39:31 Only 7 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
03:39:31 HBMASTER: Trying to run another job!
03:39:31 job_callback for (3, 0, 2) finished
03:39:31 start sampling a new configuration.
03:39:31 best_vector: [2, 0.8168297815453137, 0.7956960687890252, 0.20085608002762262, 0.21279776764941832, 1, 0.6257146832517598, 0.4011123362541885, 0.5746126683411786], 0.007391263566217022, 0.3760143309708706, 0.002779221024880465
03:39:31 done sampling a new configuration.
03:39:31 HBMASTER: schedule new run for iteration 3
03:39:31 HBMASTER: trying submitting job (3, 0, 3) to dispatcher
03:39:31 HBMASTER: submitting job (3, 0, 3) to dispatcher
03:39:31 DISPATCHER: trying to submit job (3, 0, 3)
03:39:31 DISPATCHER: trying to notify the job_runner thread.
03:39:31 HBMASTER: job (3, 0, 3) submitted to dispatcher
03:39:31 DISPATCHER: Trying to submit another job.
03:39:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:39:31 DISPATCHER: starting job (3, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
03:39:31 DISPATCHER: job (3, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
03:39:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:39:31 WORKER: start processing job (3, 0, 3)
03:39:31 WORKER: args: ()
03:39:31 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 854, 'last_n_outputs': 42, 'leak_rate': 0.8002140200069057, 'lr': 0.0026643761368533134, 'optimizer': 'SGD', 'sparsity': 0.9001715239804223, 'steps_to_train': 46, 'weight_decay': 0.055922723952532595}, 'budget': 1200.0, 'working_directory': '.'}
03:40:24 DISPATCHER: Starting worker discovery
03:40:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:40:24 DISPATCHER: Finished worker discovery
03:41:24 DISPATCHER: Starting worker discovery
03:41:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:41:24 DISPATCHER: Finished worker discovery
03:42:24 DISPATCHER: Starting worker discovery
03:42:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:42:24 DISPATCHER: Finished worker discovery
03:43:24 DISPATCHER: Starting worker discovery
03:43:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:43:24 DISPATCHER: Finished worker discovery
03:44:24 DISPATCHER: Starting worker discovery
03:44:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:44:24 DISPATCHER: Finished worker discovery
03:45:24 DISPATCHER: Starting worker discovery
03:45:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:45:24 DISPATCHER: Finished worker discovery
03:46:24 DISPATCHER: Starting worker discovery
03:46:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:46:24 DISPATCHER: Finished worker discovery
03:47:24 DISPATCHER: Starting worker discovery
03:47:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:47:24 DISPATCHER: Finished worker discovery
03:48:24 DISPATCHER: Starting worker discovery
03:48:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:48:24 DISPATCHER: Finished worker discovery
03:49:24 DISPATCHER: Starting worker discovery
03:49:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:49:24 DISPATCHER: Finished worker discovery
03:50:24 DISPATCHER: Starting worker discovery
03:50:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:50:24 DISPATCHER: Finished worker discovery
03:51:24 DISPATCHER: Starting worker discovery
03:51:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:51:24 DISPATCHER: Finished worker discovery
03:52:24 DISPATCHER: Starting worker discovery
03:52:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:52:24 DISPATCHER: Finished worker discovery
03:53:24 DISPATCHER: Starting worker discovery
03:53:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:53:24 DISPATCHER: Finished worker discovery
03:54:24 DISPATCHER: Starting worker discovery
03:54:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:54:24 DISPATCHER: Finished worker discovery
03:55:24 DISPATCHER: Starting worker discovery
03:55:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:55:24 DISPATCHER: Finished worker discovery
03:56:24 DISPATCHER: Starting worker discovery
03:56:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:56:24 DISPATCHER: Finished worker discovery
03:57:24 DISPATCHER: Starting worker discovery
03:57:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:57:24 DISPATCHER: Finished worker discovery
03:58:24 DISPATCHER: Starting worker discovery
03:58:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:58:24 DISPATCHER: Finished worker discovery
03:59:24 DISPATCHER: Starting worker discovery
03:59:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:59:24 DISPATCHER: Finished worker discovery
03:59:51 WORKER: done with job (3, 0, 3), trying to register it.
03:59:51 WORKER: registered result for job (3, 0, 3) with dispatcher
03:59:51 DISPATCHER: job (3, 0, 3) finished
03:59:51 DISPATCHER: register_result: lock acquired
03:59:51 DISPATCHER: job (3, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
03:59:51 job_id: (3, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 854, 'last_n_outputs': 42, 'leak_rate': 0.8002140200069057, 'lr': 0.0026643761368533134, 'optimizer': 'SGD', 'sparsity': 0.9001715239804223, 'steps_to_train': 46, 'weight_decay': 0.055922723952532595}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.7290320365183827, 'info': {'data05': 0.7290320365183827, 'config': "{'batch_size': 64, 'hidden_dim': 854, 'last_n_outputs': 42, 'leak_rate': 0.8002140200069057, 'lr': 0.0026643761368533134, 'optimizer': 'SGD', 'sparsity': 0.9001715239804223, 'steps_to_train': 46, 'weight_decay': 0.055922723952532595}"}}
exception: None

03:59:51 job_callback for (3, 0, 3) started
03:59:51 DISPATCHER: Trying to submit another job.
03:59:51 job_callback for (3, 0, 3) got condition
03:59:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:59:51 Only 8 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
03:59:51 HBMASTER: Trying to run another job!
03:59:51 job_callback for (3, 0, 3) finished
03:59:51 start sampling a new configuration.
03:59:51 done sampling a new configuration.
03:59:51 HBMASTER: schedule new run for iteration 4
03:59:51 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
03:59:51 HBMASTER: submitting job (4, 0, 0) to dispatcher
03:59:51 DISPATCHER: trying to submit job (4, 0, 0)
03:59:51 DISPATCHER: trying to notify the job_runner thread.
03:59:51 HBMASTER: job (4, 0, 0) submitted to dispatcher
03:59:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:59:51 DISPATCHER: Trying to submit another job.
03:59:51 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
03:59:51 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
03:59:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:59:51 WORKER: start processing job (4, 0, 0)
03:59:51 WORKER: args: ()
03:59:51 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 265, 'last_n_outputs': 49, 'leak_rate': 0.8361238848475713, 'lr': 0.05892899153715867, 'optimizer': 'SGD', 'sparsity': 0.8278846267663941, 'steps_to_train': 64, 'weight_decay': 0.12549326564742933}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:00:24 DISPATCHER: Starting worker discovery
04:00:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:00:24 DISPATCHER: Finished worker discovery
04:00:48 WORKER: done with job (4, 0, 0), trying to register it.
04:00:48 WORKER: registered result for job (4, 0, 0) with dispatcher
04:00:48 DISPATCHER: job (4, 0, 0) finished
04:00:48 DISPATCHER: register_result: lock acquired
04:00:48 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
04:00:48 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 265, 'last_n_outputs': 49, 'leak_rate': 0.8361238848475713, 'lr': 0.05892899153715867, 'optimizer': 'SGD', 'sparsity': 0.8278846267663941, 'steps_to_train': 64, 'weight_decay': 0.12549326564742933}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5785563359644542, 'info': {'data05': 0.5785563359644542, 'config': "{'batch_size': 128, 'hidden_dim': 265, 'last_n_outputs': 49, 'leak_rate': 0.8361238848475713, 'lr': 0.05892899153715867, 'optimizer': 'SGD', 'sparsity': 0.8278846267663941, 'steps_to_train': 64, 'weight_decay': 0.12549326564742933}"}}
exception: None

04:00:48 job_callback for (4, 0, 0) started
04:00:48 job_callback for (4, 0, 0) got condition
04:00:48 DISPATCHER: Trying to submit another job.
04:00:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:00:48 done building a new model for budget 44.444444 based on 10/23 split
Best loss for this budget:-0.756787





04:00:48 HBMASTER: Trying to run another job!
04:00:48 job_callback for (4, 0, 0) finished
04:00:48 start sampling a new configuration.
04:00:48 done sampling a new configuration.
04:00:48 HBMASTER: schedule new run for iteration 4
04:00:48 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
04:00:48 HBMASTER: submitting job (4, 0, 1) to dispatcher
04:00:48 DISPATCHER: trying to submit job (4, 0, 1)
04:00:48 DISPATCHER: trying to notify the job_runner thread.
04:00:48 HBMASTER: job (4, 0, 1) submitted to dispatcher
04:00:48 DISPATCHER: Trying to submit another job.
04:00:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:00:48 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:00:48 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:00:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:00:48 WORKER: start processing job (4, 0, 1)
04:00:48 WORKER: args: ()
04:00:48 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 670, 'last_n_outputs': 12, 'leak_rate': 0.985131821399076, 'lr': 0.07234942835463004, 'optimizer': 'Adam', 'sparsity': 0.7704140946974631, 'steps_to_train': 28, 'weight_decay': 0.07231236412490089}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:01:24 DISPATCHER: Starting worker discovery
04:01:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:01:24 DISPATCHER: Finished worker discovery
04:01:46 WORKER: done with job (4, 0, 1), trying to register it.
04:01:46 WORKER: registered result for job (4, 0, 1) with dispatcher
04:01:46 DISPATCHER: job (4, 0, 1) finished
04:01:46 DISPATCHER: register_result: lock acquired
04:01:46 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
04:01:46 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 670, 'last_n_outputs': 12, 'leak_rate': 0.985131821399076, 'lr': 0.07234942835463004, 'optimizer': 'Adam', 'sparsity': 0.7704140946974631, 'steps_to_train': 28, 'weight_decay': 0.07231236412490089}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0024085952554640877, 'info': {'data05': 0.0024085952554640877, 'config': "{'batch_size': 128, 'hidden_dim': 670, 'last_n_outputs': 12, 'leak_rate': 0.985131821399076, 'lr': 0.07234942835463004, 'optimizer': 'Adam', 'sparsity': 0.7704140946974631, 'steps_to_train': 28, 'weight_decay': 0.07231236412490089}"}}
exception: None

04:01:46 job_callback for (4, 0, 1) started
04:01:46 DISPATCHER: Trying to submit another job.
04:01:46 job_callback for (4, 0, 1) got condition
04:01:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:01:46 done building a new model for budget 44.444444 based on 10/24 split
Best loss for this budget:-0.756787





04:01:46 HBMASTER: Trying to run another job!
04:01:46 job_callback for (4, 0, 1) finished
04:01:46 start sampling a new configuration.
04:01:46 best_vector: [1, 0.8317961498698994, 0.9930423514592467, 0.5045664743561402, 0.4407812652565149, 1, 0.8005435734387685, 0.24757375428807377, 0.592497741573722], 0.0010868912223475414, 0.3000474552476781, 0.0003261189453964181
04:01:46 done sampling a new configuration.
04:01:46 HBMASTER: schedule new run for iteration 4
04:01:46 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
04:01:46 HBMASTER: submitting job (4, 0, 2) to dispatcher
04:01:46 DISPATCHER: trying to submit job (4, 0, 2)
04:01:46 DISPATCHER: trying to notify the job_runner thread.
04:01:46 HBMASTER: job (4, 0, 2) submitted to dispatcher
04:01:46 DISPATCHER: Trying to submit another job.
04:01:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:01:46 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:01:46 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:01:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:01:46 WORKER: start processing job (4, 0, 2)
04:01:46 WORKER: args: ()
04:01:46 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 866, 'last_n_outputs': 50, 'leak_rate': 0.876141618589035, 'lr': 0.007613117461710608, 'optimizer': 'SGD', 'sparsity': 0.9421304576253045, 'steps_to_train': 32, 'weight_decay': 0.05900072308061692}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:02:24 DISPATCHER: Starting worker discovery
04:02:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:02:24 DISPATCHER: Finished worker discovery
04:02:42 WORKER: done with job (4, 0, 2), trying to register it.
04:02:42 WORKER: registered result for job (4, 0, 2) with dispatcher
04:02:42 DISPATCHER: job (4, 0, 2) finished
04:02:42 DISPATCHER: register_result: lock acquired
04:02:42 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
04:02:42 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 866, 'last_n_outputs': 50, 'leak_rate': 0.876141618589035, 'lr': 0.007613117461710608, 'optimizer': 'SGD', 'sparsity': 0.9421304576253045, 'steps_to_train': 32, 'weight_decay': 0.05900072308061692}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7702324962588041, 'info': {'data05': 0.7702324962588041, 'config': "{'batch_size': 32, 'hidden_dim': 866, 'last_n_outputs': 50, 'leak_rate': 0.876141618589035, 'lr': 0.007613117461710608, 'optimizer': 'SGD', 'sparsity': 0.9421304576253045, 'steps_to_train': 32, 'weight_decay': 0.05900072308061692}"}}
exception: None

04:02:42 job_callback for (4, 0, 2) started
04:02:42 DISPATCHER: Trying to submit another job.
04:02:42 job_callback for (4, 0, 2) got condition
04:02:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:02:42 done building a new model for budget 44.444444 based on 10/25 split
Best loss for this budget:-0.770232





04:02:42 HBMASTER: Trying to run another job!
04:02:42 job_callback for (4, 0, 2) finished
04:02:42 start sampling a new configuration.
04:02:42 best_vector: [0, 0.9475673249452661, 0.8956629333143336, 0.7621208758373939, 0.09696972659286518, 1, 0.9142714329482702, 0.5227012562525204, 0.02058796445001687], 0.0009537814079471485, 0.1492953476300251, 0.00014239512686252433
04:02:42 done sampling a new configuration.
04:02:42 HBMASTER: schedule new run for iteration 4
04:02:42 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
04:02:42 HBMASTER: submitting job (4, 0, 3) to dispatcher
04:02:42 DISPATCHER: trying to submit job (4, 0, 3)
04:02:42 DISPATCHER: trying to notify the job_runner thread.
04:02:42 HBMASTER: job (4, 0, 3) submitted to dispatcher
04:02:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:02:42 DISPATCHER: Trying to submit another job.
04:02:42 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:02:42 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:02:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:02:42 WORKER: start processing job (4, 0, 3)
04:02:42 WORKER: args: ()
04:02:42 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 959, 'last_n_outputs': 46, 'leak_rate': 0.9405302189593485, 'lr': 0.001562929732865643, 'optimizer': 'SGD', 'sparsity': 0.9694251439075848, 'steps_to_train': 57, 'weight_decay': 0.010636177081971487}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:03:24 DISPATCHER: Starting worker discovery
04:03:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:03:24 DISPATCHER: Finished worker discovery
04:03:41 WORKER: done with job (4, 0, 3), trying to register it.
04:03:41 WORKER: registered result for job (4, 0, 3) with dispatcher
04:03:41 DISPATCHER: job (4, 0, 3) finished
04:03:41 DISPATCHER: register_result: lock acquired
04:03:41 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
04:03:41 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 959, 'last_n_outputs': 46, 'leak_rate': 0.9405302189593485, 'lr': 0.001562929732865643, 'optimizer': 'SGD', 'sparsity': 0.9694251439075848, 'steps_to_train': 57, 'weight_decay': 0.010636177081971487}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.659359955024547, 'info': {'data05': 0.659359955024547, 'config': "{'batch_size': 16, 'hidden_dim': 959, 'last_n_outputs': 46, 'leak_rate': 0.9405302189593485, 'lr': 0.001562929732865643, 'optimizer': 'SGD', 'sparsity': 0.9694251439075848, 'steps_to_train': 57, 'weight_decay': 0.010636177081971487}"}}
exception: None

04:03:41 job_callback for (4, 0, 3) started
04:03:41 DISPATCHER: Trying to submit another job.
04:03:41 job_callback for (4, 0, 3) got condition
04:03:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:03:41 done building a new model for budget 44.444444 based on 10/26 split
Best loss for this budget:-0.770232





04:03:41 HBMASTER: Trying to run another job!
04:03:41 job_callback for (4, 0, 3) finished
04:03:41 start sampling a new configuration.
04:03:41 done sampling a new configuration.
04:03:41 HBMASTER: schedule new run for iteration 4
04:03:41 HBMASTER: trying submitting job (4, 0, 4) to dispatcher
04:03:41 HBMASTER: submitting job (4, 0, 4) to dispatcher
04:03:41 DISPATCHER: trying to submit job (4, 0, 4)
04:03:41 DISPATCHER: trying to notify the job_runner thread.
04:03:41 HBMASTER: job (4, 0, 4) submitted to dispatcher
04:03:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:03:41 DISPATCHER: Trying to submit another job.
04:03:41 DISPATCHER: starting job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:03:41 DISPATCHER: job (4, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:03:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:03:41 WORKER: start processing job (4, 0, 4)
04:03:41 WORKER: args: ()
04:03:41 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 897, 'last_n_outputs': 38, 'leak_rate': 0.904651117165817, 'lr': 0.0012863138646073318, 'optimizer': 'SGD', 'sparsity': 0.784487908624708, 'steps_to_train': 97, 'weight_decay': 0.011035169740675768}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:04:24 DISPATCHER: Starting worker discovery
04:04:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:04:24 DISPATCHER: Finished worker discovery
04:04:37 WORKER: done with job (4, 0, 4), trying to register it.
04:04:37 WORKER: registered result for job (4, 0, 4) with dispatcher
04:04:37 DISPATCHER: job (4, 0, 4) finished
04:04:37 DISPATCHER: register_result: lock acquired
04:04:37 DISPATCHER: job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
04:04:37 job_id: (4, 0, 4)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 897, 'last_n_outputs': 38, 'leak_rate': 0.904651117165817, 'lr': 0.0012863138646073318, 'optimizer': 'SGD', 'sparsity': 0.784487908624708, 'steps_to_train': 97, 'weight_decay': 0.011035169740675768}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6175395188617336, 'info': {'data05': 0.6175395188617336, 'config': "{'batch_size': 16, 'hidden_dim': 897, 'last_n_outputs': 38, 'leak_rate': 0.904651117165817, 'lr': 0.0012863138646073318, 'optimizer': 'SGD', 'sparsity': 0.784487908624708, 'steps_to_train': 97, 'weight_decay': 0.011035169740675768}"}}
exception: None

04:04:37 job_callback for (4, 0, 4) started
04:04:37 job_callback for (4, 0, 4) got condition
04:04:37 DISPATCHER: Trying to submit another job.
04:04:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:04:37 done building a new model for budget 44.444444 based on 10/27 split
Best loss for this budget:-0.770232





04:04:37 HBMASTER: Trying to run another job!
04:04:37 job_callback for (4, 0, 4) finished
04:04:37 start sampling a new configuration.
04:04:37 best_vector: [0, 0.8711983882601054, 0.9610642050384983, 0.0408866508220192, 0.33879880175104954, 1, 0.8259792949254686, 0.20032663801344486, 0.6951303117530657], 0.00035551918788942835, 0.45331269646856587, 0.00016116136170847147
04:04:37 done sampling a new configuration.
04:04:37 HBMASTER: schedule new run for iteration 4
04:04:37 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
04:04:37 HBMASTER: submitting job (4, 0, 5) to dispatcher
04:04:37 DISPATCHER: trying to submit job (4, 0, 5)
04:04:37 DISPATCHER: trying to notify the job_runner thread.
04:04:37 HBMASTER: job (4, 0, 5) submitted to dispatcher
04:04:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:04:37 DISPATCHER: Trying to submit another job.
04:04:37 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:04:37 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:04:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:04:37 WORKER: start processing job (4, 0, 5)
04:04:37 WORKER: args: ()
04:04:37 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 897, 'last_n_outputs': 49, 'leak_rate': 0.7602216627055048, 'lr': 0.004759897530817441, 'optimizer': 'SGD', 'sparsity': 0.9482350307821125, 'steps_to_train': 28, 'weight_decay': 0.08023897763534726}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:05:24 DISPATCHER: Starting worker discovery
04:05:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:05:24 DISPATCHER: Finished worker discovery
04:05:33 WORKER: done with job (4, 0, 5), trying to register it.
04:05:33 WORKER: registered result for job (4, 0, 5) with dispatcher
04:05:33 DISPATCHER: job (4, 0, 5) finished
04:05:33 DISPATCHER: register_result: lock acquired
04:05:33 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
04:05:33 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 897, 'last_n_outputs': 49, 'leak_rate': 0.7602216627055048, 'lr': 0.004759897530817441, 'optimizer': 'SGD', 'sparsity': 0.9482350307821125, 'steps_to_train': 28, 'weight_decay': 0.08023897763534726}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7576104945621308, 'info': {'data05': 0.7576104945621308, 'config': "{'batch_size': 16, 'hidden_dim': 897, 'last_n_outputs': 49, 'leak_rate': 0.7602216627055048, 'lr': 0.004759897530817441, 'optimizer': 'SGD', 'sparsity': 0.9482350307821125, 'steps_to_train': 28, 'weight_decay': 0.08023897763534726}"}}
exception: None

04:05:33 job_callback for (4, 0, 5) started
04:05:33 DISPATCHER: Trying to submit another job.
04:05:33 job_callback for (4, 0, 5) got condition
04:05:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:05:33 done building a new model for budget 44.444444 based on 10/28 split
Best loss for this budget:-0.770232





04:05:33 HBMASTER: Trying to run another job!
04:05:33 job_callback for (4, 0, 5) finished
04:05:33 start sampling a new configuration.
04:05:33 best_vector: [1, 0.9028695403151069, 0.8178315348863661, 0.5599797401913633, 0.47047978811622515, 1, 0.9110192424697867, 0.829791393780169, 0.14950560328114984], 0.00303692666083136, 0.6419413476429243, 0.0019495287933468093
04:05:33 done sampling a new configuration.
04:05:33 HBMASTER: schedule new run for iteration 4
04:05:33 HBMASTER: trying submitting job (4, 0, 6) to dispatcher
04:05:33 HBMASTER: submitting job (4, 0, 6) to dispatcher
04:05:33 DISPATCHER: trying to submit job (4, 0, 6)
04:05:33 DISPATCHER: trying to notify the job_runner thread.
04:05:33 HBMASTER: job (4, 0, 6) submitted to dispatcher
04:05:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:05:33 DISPATCHER: Trying to submit another job.
04:05:33 DISPATCHER: starting job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:05:33 DISPATCHER: job (4, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:05:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:05:33 WORKER: start processing job (4, 0, 6)
04:05:33 WORKER: args: ()
04:05:33 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 923, 'last_n_outputs': 43, 'leak_rate': 0.8899949350478409, 'lr': 0.008728901167239329, 'optimizer': 'SGD', 'sparsity': 0.9686446181927488, 'steps_to_train': 85, 'weight_decay': 0.01564988946184848}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:06:24 DISPATCHER: Starting worker discovery
04:06:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:06:24 DISPATCHER: Finished worker discovery
04:06:35 WORKER: done with job (4, 0, 6), trying to register it.
04:06:35 WORKER: registered result for job (4, 0, 6) with dispatcher
04:06:35 DISPATCHER: job (4, 0, 6) finished
04:06:35 DISPATCHER: register_result: lock acquired
04:06:35 DISPATCHER: job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
04:06:35 job_id: (4, 0, 6)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 923, 'last_n_outputs': 43, 'leak_rate': 0.8899949350478409, 'lr': 0.008728901167239329, 'optimizer': 'SGD', 'sparsity': 0.9686446181927488, 'steps_to_train': 85, 'weight_decay': 0.01564988946184848}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7321424192654893, 'info': {'data05': 0.7321424192654893, 'config': "{'batch_size': 32, 'hidden_dim': 923, 'last_n_outputs': 43, 'leak_rate': 0.8899949350478409, 'lr': 0.008728901167239329, 'optimizer': 'SGD', 'sparsity': 0.9686446181927488, 'steps_to_train': 85, 'weight_decay': 0.01564988946184848}"}}
exception: None

04:06:35 job_callback for (4, 0, 6) started
04:06:35 DISPATCHER: Trying to submit another job.
04:06:35 job_callback for (4, 0, 6) got condition
04:06:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:06:35 done building a new model for budget 44.444444 based on 10/28 split
Best loss for this budget:-0.770232





04:06:35 HBMASTER: Trying to run another job!
04:06:35 job_callback for (4, 0, 6) finished
04:06:35 start sampling a new configuration.
04:06:35 done sampling a new configuration.
04:06:36 HBMASTER: schedule new run for iteration 4
04:06:36 HBMASTER: trying submitting job (4, 0, 7) to dispatcher
04:06:36 HBMASTER: submitting job (4, 0, 7) to dispatcher
04:06:36 DISPATCHER: trying to submit job (4, 0, 7)
04:06:36 DISPATCHER: trying to notify the job_runner thread.
04:06:36 HBMASTER: job (4, 0, 7) submitted to dispatcher
04:06:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:06:36 DISPATCHER: Trying to submit another job.
04:06:36 DISPATCHER: starting job (4, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:06:36 DISPATCHER: job (4, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:06:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:06:36 WORKER: start processing job (4, 0, 7)
04:06:36 WORKER: args: ()
04:06:36 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 666, 'last_n_outputs': 22, 'leak_rate': 0.765960904646413, 'lr': 0.0027486941307190453, 'optimizer': 'Adam', 'sparsity': 0.760421475518458, 'steps_to_train': 41, 'weight_decay': 0.02443543458396733}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:07:24 DISPATCHER: Starting worker discovery
04:07:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:07:24 DISPATCHER: Finished worker discovery
04:07:35 WORKER: done with job (4, 0, 7), trying to register it.
04:07:35 WORKER: registered result for job (4, 0, 7) with dispatcher
04:07:35 DISPATCHER: job (4, 0, 7) finished
04:07:35 DISPATCHER: register_result: lock acquired
04:07:35 DISPATCHER: job (4, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
04:07:35 job_id: (4, 0, 7)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 666, 'last_n_outputs': 22, 'leak_rate': 0.765960904646413, 'lr': 0.0027486941307190453, 'optimizer': 'Adam', 'sparsity': 0.760421475518458, 'steps_to_train': 41, 'weight_decay': 0.02443543458396733}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5404527607377748, 'info': {'data05': 0.5404527607377748, 'config': "{'batch_size': 64, 'hidden_dim': 666, 'last_n_outputs': 22, 'leak_rate': 0.765960904646413, 'lr': 0.0027486941307190453, 'optimizer': 'Adam', 'sparsity': 0.760421475518458, 'steps_to_train': 41, 'weight_decay': 0.02443543458396733}"}}
exception: None

04:07:35 job_callback for (4, 0, 7) started
04:07:35 job_callback for (4, 0, 7) got condition
04:07:35 DISPATCHER: Trying to submit another job.
04:07:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:07:35 done building a new model for budget 44.444444 based on 10/29 split
Best loss for this budget:-0.770232





04:07:35 HBMASTER: Trying to run another job!
04:07:35 job_callback for (4, 0, 7) finished
04:07:35 start sampling a new configuration.
04:07:35 done sampling a new configuration.
04:07:35 HBMASTER: schedule new run for iteration 4
04:07:35 HBMASTER: trying submitting job (4, 0, 8) to dispatcher
04:07:35 HBMASTER: submitting job (4, 0, 8) to dispatcher
04:07:35 DISPATCHER: trying to submit job (4, 0, 8)
04:07:35 DISPATCHER: trying to notify the job_runner thread.
04:07:35 HBMASTER: job (4, 0, 8) submitted to dispatcher
04:07:35 DISPATCHER: Trying to submit another job.
04:07:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:07:35 DISPATCHER: starting job (4, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:07:35 DISPATCHER: job (4, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:07:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:07:35 WORKER: start processing job (4, 0, 8)
04:07:35 WORKER: args: ()
04:07:35 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 295, 'last_n_outputs': 45, 'leak_rate': 0.8077599039418585, 'lr': 0.0035634290044580714, 'optimizer': 'SGD', 'sparsity': 0.9836485918835722, 'steps_to_train': 27, 'weight_decay': 0.031016550815623455}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:08:24 DISPATCHER: Starting worker discovery
04:08:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:08:24 DISPATCHER: Finished worker discovery
04:08:34 WORKER: done with job (4, 0, 8), trying to register it.
04:08:34 WORKER: registered result for job (4, 0, 8) with dispatcher
04:08:34 DISPATCHER: job (4, 0, 8) finished
04:08:34 DISPATCHER: register_result: lock acquired
04:08:34 DISPATCHER: job (4, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
04:08:34 job_id: (4, 0, 8)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 295, 'last_n_outputs': 45, 'leak_rate': 0.8077599039418585, 'lr': 0.0035634290044580714, 'optimizer': 'SGD', 'sparsity': 0.9836485918835722, 'steps_to_train': 27, 'weight_decay': 0.031016550815623455}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6612633830572248, 'info': {'data05': 0.6612633830572248, 'config': "{'batch_size': 32, 'hidden_dim': 295, 'last_n_outputs': 45, 'leak_rate': 0.8077599039418585, 'lr': 0.0035634290044580714, 'optimizer': 'SGD', 'sparsity': 0.9836485918835722, 'steps_to_train': 27, 'weight_decay': 0.031016550815623455}"}}
exception: None

04:08:34 job_callback for (4, 0, 8) started
04:08:34 DISPATCHER: Trying to submit another job.
04:08:34 job_callback for (4, 0, 8) got condition
04:08:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:08:34 done building a new model for budget 44.444444 based on 10/30 split
Best loss for this budget:-0.770232





04:08:34 HBMASTER: Trying to run another job!
04:08:34 job_callback for (4, 0, 8) finished
04:08:34 start sampling a new configuration.
04:08:34 done sampling a new configuration.
04:08:34 HBMASTER: schedule new run for iteration 4
04:08:34 HBMASTER: trying submitting job (4, 0, 9) to dispatcher
04:08:34 HBMASTER: submitting job (4, 0, 9) to dispatcher
04:08:34 DISPATCHER: trying to submit job (4, 0, 9)
04:08:34 DISPATCHER: trying to notify the job_runner thread.
04:08:34 HBMASTER: job (4, 0, 9) submitted to dispatcher
04:08:34 DISPATCHER: Trying to submit another job.
04:08:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:08:34 DISPATCHER: starting job (4, 0, 9) on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:08:34 DISPATCHER: job (4, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:08:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:08:34 WORKER: start processing job (4, 0, 9)
04:08:34 WORKER: args: ()
04:08:34 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 296, 'last_n_outputs': 15, 'leak_rate': 0.8007666587129226, 'lr': 0.009949623750317903, 'optimizer': 'Adam', 'sparsity': 0.7750025361449326, 'steps_to_train': 49, 'weight_decay': 0.022302888731065184}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:09:24 DISPATCHER: Starting worker discovery
04:09:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:09:24 DISPATCHER: Finished worker discovery
04:09:31 WORKER: done with job (4, 0, 9), trying to register it.
04:09:31 WORKER: registered result for job (4, 0, 9) with dispatcher
04:09:31 DISPATCHER: job (4, 0, 9) finished
04:09:31 DISPATCHER: register_result: lock acquired
04:09:31 DISPATCHER: job (4, 0, 9) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
04:09:31 job_id: (4, 0, 9)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 296, 'last_n_outputs': 15, 'leak_rate': 0.8007666587129226, 'lr': 0.009949623750317903, 'optimizer': 'Adam', 'sparsity': 0.7750025361449326, 'steps_to_train': 49, 'weight_decay': 0.022302888731065184}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.26606606751371925, 'info': {'data05': 0.26606606751371925, 'config': "{'batch_size': 16, 'hidden_dim': 296, 'last_n_outputs': 15, 'leak_rate': 0.8007666587129226, 'lr': 0.009949623750317903, 'optimizer': 'Adam', 'sparsity': 0.7750025361449326, 'steps_to_train': 49, 'weight_decay': 0.022302888731065184}"}}
exception: None

04:09:31 job_callback for (4, 0, 9) started
04:09:31 DISPATCHER: Trying to submit another job.
04:09:31 job_callback for (4, 0, 9) got condition
04:09:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:09:31 done building a new model for budget 44.444444 based on 10/31 split
Best loss for this budget:-0.770232





04:09:31 HBMASTER: Trying to run another job!
04:09:31 job_callback for (4, 0, 9) finished
04:09:31 start sampling a new configuration.
04:09:31 done sampling a new configuration.
04:09:31 HBMASTER: schedule new run for iteration 4
04:09:31 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
04:09:31 HBMASTER: submitting job (4, 0, 10) to dispatcher
04:09:31 DISPATCHER: trying to submit job (4, 0, 10)
04:09:31 DISPATCHER: trying to notify the job_runner thread.
04:09:31 HBMASTER: job (4, 0, 10) submitted to dispatcher
04:09:31 DISPATCHER: Trying to submit another job.
04:09:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:09:31 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:09:31 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:09:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:09:31 WORKER: start processing job (4, 0, 10)
04:09:31 WORKER: args: ()
04:09:31 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 528, 'last_n_outputs': 49, 'leak_rate': 0.9344237470098795, 'lr': 0.028080758366601174, 'optimizer': 'SGD', 'sparsity': 0.9163504976479833, 'steps_to_train': 34, 'weight_decay': 0.03532203562474624}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:10:24 DISPATCHER: Starting worker discovery
04:10:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:10:24 DISPATCHER: Finished worker discovery
04:10:29 WORKER: done with job (4, 0, 10), trying to register it.
04:10:29 WORKER: registered result for job (4, 0, 10) with dispatcher
04:10:29 DISPATCHER: job (4, 0, 10) finished
04:10:29 DISPATCHER: register_result: lock acquired
04:10:29 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
04:10:29 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 528, 'last_n_outputs': 49, 'leak_rate': 0.9344237470098795, 'lr': 0.028080758366601174, 'optimizer': 'SGD', 'sparsity': 0.9163504976479833, 'steps_to_train': 34, 'weight_decay': 0.03532203562474624}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6563573344598239, 'info': {'data05': 0.6563573344598239, 'config': "{'batch_size': 16, 'hidden_dim': 528, 'last_n_outputs': 49, 'leak_rate': 0.9344237470098795, 'lr': 0.028080758366601174, 'optimizer': 'SGD', 'sparsity': 0.9163504976479833, 'steps_to_train': 34, 'weight_decay': 0.03532203562474624}"}}
exception: None

04:10:29 job_callback for (4, 0, 10) started
04:10:29 DISPATCHER: Trying to submit another job.
04:10:29 job_callback for (4, 0, 10) got condition
04:10:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:10:29 done building a new model for budget 44.444444 based on 10/32 split
Best loss for this budget:-0.770232





04:10:29 HBMASTER: Trying to run another job!
04:10:29 job_callback for (4, 0, 10) finished
04:10:29 start sampling a new configuration.
04:10:29 done sampling a new configuration.
04:10:29 HBMASTER: schedule new run for iteration 4
04:10:29 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
04:10:29 HBMASTER: submitting job (4, 0, 11) to dispatcher
04:10:29 DISPATCHER: trying to submit job (4, 0, 11)
04:10:29 DISPATCHER: trying to notify the job_runner thread.
04:10:29 HBMASTER: job (4, 0, 11) submitted to dispatcher
04:10:29 DISPATCHER: Trying to submit another job.
04:10:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:10:29 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:10:29 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:10:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:10:29 WORKER: start processing job (4, 0, 11)
04:10:29 WORKER: args: ()
04:10:29 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 270, 'last_n_outputs': 49, 'leak_rate': 0.766810983040299, 'lr': 0.02988800094294711, 'optimizer': 'Adam', 'sparsity': 0.7501491163609193, 'steps_to_train': 98, 'weight_decay': 0.01176640247394691}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:11:24 DISPATCHER: Starting worker discovery
04:11:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:11:24 DISPATCHER: Finished worker discovery
04:11:33 WORKER: done with job (4, 0, 11), trying to register it.
04:11:33 WORKER: registered result for job (4, 0, 11) with dispatcher
04:11:33 DISPATCHER: job (4, 0, 11) finished
04:11:33 DISPATCHER: register_result: lock acquired
04:11:33 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
04:11:33 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 270, 'last_n_outputs': 49, 'leak_rate': 0.766810983040299, 'lr': 0.02988800094294711, 'optimizer': 'Adam', 'sparsity': 0.7501491163609193, 'steps_to_train': 98, 'weight_decay': 0.01176640247394691}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.30316628863041767, 'info': {'data05': 0.30316628863041767, 'config': "{'batch_size': 64, 'hidden_dim': 270, 'last_n_outputs': 49, 'leak_rate': 0.766810983040299, 'lr': 0.02988800094294711, 'optimizer': 'Adam', 'sparsity': 0.7501491163609193, 'steps_to_train': 98, 'weight_decay': 0.01176640247394691}"}}
exception: None

04:11:33 job_callback for (4, 0, 11) started
04:11:33 job_callback for (4, 0, 11) got condition
04:11:33 DISPATCHER: Trying to submit another job.
04:11:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:11:33 done building a new model for budget 44.444444 based on 10/33 split
Best loss for this budget:-0.770232





04:11:33 HBMASTER: Trying to run another job!
04:11:33 job_callback for (4, 0, 11) finished
04:11:33 start sampling a new configuration.
04:11:33 best_vector: [1, 0.5854999750256439, 0.972766659766868, 0.8066325009720992, 0.34860954622382495, 1, 0.25318257066575794, 0.8119980892399873, 0.7670855081860946], 0.005022242790465301, 0.32862733498026436, 0.001650446263854458
04:11:33 done sampling a new configuration.
04:11:33 HBMASTER: schedule new run for iteration 4
04:11:33 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
04:11:33 HBMASTER: submitting job (4, 0, 12) to dispatcher
04:11:33 DISPATCHER: trying to submit job (4, 0, 12)
04:11:33 DISPATCHER: trying to notify the job_runner thread.
04:11:33 HBMASTER: job (4, 0, 12) submitted to dispatcher
04:11:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:11:33 DISPATCHER: Trying to submit another job.
04:11:33 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:11:33 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:11:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:11:33 WORKER: start processing job (4, 0, 12)
04:11:33 WORKER: args: ()
04:11:33 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 668, 'last_n_outputs': 49, 'leak_rate': 0.9516581252430247, 'lr': 0.004979882462352569, 'optimizer': 'SGD', 'sparsity': 0.810763816959782, 'steps_to_train': 83, 'weight_decay': 0.09954082947149888}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:12:24 DISPATCHER: Starting worker discovery
04:12:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:12:24 DISPATCHER: Finished worker discovery
04:12:38 WORKER: done with job (4, 0, 12), trying to register it.
04:12:38 WORKER: registered result for job (4, 0, 12) with dispatcher
04:12:38 DISPATCHER: job (4, 0, 12) finished
04:12:38 DISPATCHER: register_result: lock acquired
04:12:38 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
04:12:38 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 668, 'last_n_outputs': 49, 'leak_rate': 0.9516581252430247, 'lr': 0.004979882462352569, 'optimizer': 'SGD', 'sparsity': 0.810763816959782, 'steps_to_train': 83, 'weight_decay': 0.09954082947149888}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7338205082367661, 'info': {'data05': 0.7338205082367661, 'config': "{'batch_size': 32, 'hidden_dim': 668, 'last_n_outputs': 49, 'leak_rate': 0.9516581252430247, 'lr': 0.004979882462352569, 'optimizer': 'SGD', 'sparsity': 0.810763816959782, 'steps_to_train': 83, 'weight_decay': 0.09954082947149888}"}}
exception: None

04:12:38 job_callback for (4, 0, 12) started
04:12:38 DISPATCHER: Trying to submit another job.
04:12:38 job_callback for (4, 0, 12) got condition
04:12:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:12:38 done building a new model for budget 44.444444 based on 10/34 split
Best loss for this budget:-0.770232





04:12:38 HBMASTER: Trying to run another job!
04:12:38 job_callback for (4, 0, 12) finished
04:12:38 start sampling a new configuration.
04:12:38 best_vector: [0, 0.5981022907812845, 0.8207470834371071, 0.37262150508361097, 0.5170230992145767, 1, 0.7542423523535325, 0.8421513240658562, 0.11257421337591494], 0.0015526266980464287, 1.307333579149071, 0.0020298010182394416
04:12:38 done sampling a new configuration.
04:12:38 HBMASTER: schedule new run for iteration 4
04:12:38 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
04:12:38 HBMASTER: submitting job (4, 0, 13) to dispatcher
04:12:38 DISPATCHER: trying to submit job (4, 0, 13)
04:12:38 DISPATCHER: trying to notify the job_runner thread.
04:12:38 HBMASTER: job (4, 0, 13) submitted to dispatcher
04:12:38 DISPATCHER: Trying to submit another job.
04:12:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:12:38 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:12:38 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:12:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:12:38 WORKER: start processing job (4, 0, 13)
04:12:38 WORKER: args: ()
04:12:38 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 679, 'last_n_outputs': 43, 'leak_rate': 0.8431553762709028, 'lr': 0.010815489958339768, 'optimizer': 'SGD', 'sparsity': 0.9310181645648479, 'steps_to_train': 86, 'weight_decay': 0.014010783696841179}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:13:24 DISPATCHER: Starting worker discovery
04:13:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:13:24 DISPATCHER: Finished worker discovery
04:13:43 WORKER: done with job (4, 0, 13), trying to register it.
04:13:43 WORKER: registered result for job (4, 0, 13) with dispatcher
04:13:43 DISPATCHER: job (4, 0, 13) finished
04:13:43 DISPATCHER: register_result: lock acquired
04:13:43 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
04:13:43 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 679, 'last_n_outputs': 43, 'leak_rate': 0.8431553762709028, 'lr': 0.010815489958339768, 'optimizer': 'SGD', 'sparsity': 0.9310181645648479, 'steps_to_train': 86, 'weight_decay': 0.014010783696841179}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7259855855571112, 'info': {'data05': 0.7259855855571112, 'config': "{'batch_size': 16, 'hidden_dim': 679, 'last_n_outputs': 43, 'leak_rate': 0.8431553762709028, 'lr': 0.010815489958339768, 'optimizer': 'SGD', 'sparsity': 0.9310181645648479, 'steps_to_train': 86, 'weight_decay': 0.014010783696841179}"}}
exception: None

04:13:43 job_callback for (4, 0, 13) started
04:13:43 job_callback for (4, 0, 13) got condition
04:13:43 DISPATCHER: Trying to submit another job.
04:13:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:13:43 done building a new model for budget 44.444444 based on 10/34 split
Best loss for this budget:-0.770232





04:13:43 HBMASTER: Trying to run another job!
04:13:43 job_callback for (4, 0, 13) finished
04:13:43 start sampling a new configuration.
04:13:43 best_vector: [0, 0.9342698965587584, 0.952316812009455, 0.5459899493136382, 0.2810793968351277, 1, 0.7369810225695645, 0.34733293655574216, 0.925547730073689], 0.0010792541008610784, 1.0428641045042681, 0.0011255153614270475
04:13:43 done sampling a new configuration.
04:13:43 HBMASTER: schedule new run for iteration 4
04:13:43 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
04:13:43 HBMASTER: submitting job (4, 0, 14) to dispatcher
04:13:43 DISPATCHER: trying to submit job (4, 0, 14)
04:13:43 DISPATCHER: trying to notify the job_runner thread.
04:13:43 HBMASTER: job (4, 0, 14) submitted to dispatcher
04:13:43 DISPATCHER: Trying to submit another job.
04:13:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:13:43 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:13:43 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:13:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:13:43 WORKER: start processing job (4, 0, 14)
04:13:43 WORKER: args: ()
04:13:43 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 948, 'last_n_outputs': 49, 'leak_rate': 0.8864974873284095, 'lr': 0.00364887338462012, 'optimizer': 'SGD', 'sparsity': 0.9268754454166954, 'steps_to_train': 41, 'weight_decay': 0.16001671822643088}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:14:24 DISPATCHER: Starting worker discovery
04:14:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:14:24 DISPATCHER: Finished worker discovery
04:14:43 WORKER: done with job (4, 0, 14), trying to register it.
04:14:43 WORKER: registered result for job (4, 0, 14) with dispatcher
04:14:43 DISPATCHER: job (4, 0, 14) finished
04:14:43 DISPATCHER: register_result: lock acquired
04:14:43 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
04:14:43 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 948, 'last_n_outputs': 49, 'leak_rate': 0.8864974873284095, 'lr': 0.00364887338462012, 'optimizer': 'SGD', 'sparsity': 0.9268754454166954, 'steps_to_train': 41, 'weight_decay': 0.16001671822643088}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7263649712884847, 'info': {'data05': 0.7263649712884847, 'config': "{'batch_size': 16, 'hidden_dim': 948, 'last_n_outputs': 49, 'leak_rate': 0.8864974873284095, 'lr': 0.00364887338462012, 'optimizer': 'SGD', 'sparsity': 0.9268754454166954, 'steps_to_train': 41, 'weight_decay': 0.16001671822643088}"}}
exception: None

04:14:43 job_callback for (4, 0, 14) started
04:14:43 DISPATCHER: Trying to submit another job.
04:14:43 job_callback for (4, 0, 14) got condition
04:14:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:14:43 done building a new model for budget 44.444444 based on 10/35 split
Best loss for this budget:-0.770232





04:14:43 HBMASTER: Trying to run another job!
04:14:43 job_callback for (4, 0, 14) finished
04:14:43 start sampling a new configuration.
04:14:43 best_vector: [0, 0.7596876820260412, 0.9611333434762769, 0.5758951418165597, 0.17842756648090585, 1, 0.511517506348743, 0.46410657694538915, 0.9296034072574603], 0.0026731229055592847, 0.8717409826281, 0.0023302707883779326
04:14:43 done sampling a new configuration.
04:14:43 HBMASTER: schedule new run for iteration 4
04:14:43 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
04:14:43 HBMASTER: submitting job (4, 0, 15) to dispatcher
04:14:43 DISPATCHER: trying to submit job (4, 0, 15)
04:14:43 DISPATCHER: trying to notify the job_runner thread.
04:14:43 HBMASTER: job (4, 0, 15) submitted to dispatcher
04:14:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:14:43 DISPATCHER: Trying to submit another job.
04:14:43 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:14:43 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:14:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:14:43 WORKER: start processing job (4, 0, 15)
04:14:43 WORKER: args: ()
04:14:43 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 808, 'last_n_outputs': 49, 'leak_rate': 0.8939737854541399, 'lr': 0.0022743386560780785, 'optimizer': 'SGD', 'sparsity': 0.8727642015236983, 'steps_to_train': 52, 'weight_decay': 0.1619727355057073}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:15:24 DISPATCHER: Starting worker discovery
04:15:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:15:24 DISPATCHER: Finished worker discovery
04:15:43 WORKER: done with job (4, 0, 15), trying to register it.
04:15:43 WORKER: registered result for job (4, 0, 15) with dispatcher
04:15:43 DISPATCHER: job (4, 0, 15) finished
04:15:43 DISPATCHER: register_result: lock acquired
04:15:43 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
04:15:43 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 808, 'last_n_outputs': 49, 'leak_rate': 0.8939737854541399, 'lr': 0.0022743386560780785, 'optimizer': 'SGD', 'sparsity': 0.8727642015236983, 'steps_to_train': 52, 'weight_decay': 0.1619727355057073}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7024033605079544, 'info': {'data05': 0.7024033605079544, 'config': "{'batch_size': 16, 'hidden_dim': 808, 'last_n_outputs': 49, 'leak_rate': 0.8939737854541399, 'lr': 0.0022743386560780785, 'optimizer': 'SGD', 'sparsity': 0.8727642015236983, 'steps_to_train': 52, 'weight_decay': 0.1619727355057073}"}}
exception: None

04:15:43 job_callback for (4, 0, 15) started
04:15:43 DISPATCHER: Trying to submit another job.
04:15:43 job_callback for (4, 0, 15) got condition
04:15:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:15:43 done building a new model for budget 44.444444 based on 10/36 split
Best loss for this budget:-0.770232





04:15:43 HBMASTER: Trying to run another job!
04:15:43 job_callback for (4, 0, 15) finished
04:15:43 start sampling a new configuration.
04:15:43 done sampling a new configuration.
04:15:43 HBMASTER: schedule new run for iteration 4
04:15:43 HBMASTER: trying submitting job (4, 0, 16) to dispatcher
04:15:43 HBMASTER: submitting job (4, 0, 16) to dispatcher
04:15:43 DISPATCHER: trying to submit job (4, 0, 16)
04:15:43 DISPATCHER: trying to notify the job_runner thread.
04:15:43 HBMASTER: job (4, 0, 16) submitted to dispatcher
04:15:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:15:43 DISPATCHER: Trying to submit another job.
04:15:43 DISPATCHER: starting job (4, 0, 16) on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:15:43 DISPATCHER: job (4, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:15:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:15:43 WORKER: start processing job (4, 0, 16)
04:15:43 WORKER: args: ()
04:15:43 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 750, 'last_n_outputs': 41, 'leak_rate': 0.7656934690207551, 'lr': 0.005220196549230092, 'optimizer': 'SGD', 'sparsity': 0.9757433054191733, 'steps_to_train': 69, 'weight_decay': 0.14113135370752436}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:16:24 DISPATCHER: Starting worker discovery
04:16:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:16:24 DISPATCHER: Finished worker discovery
04:16:42 WORKER: done with job (4, 0, 16), trying to register it.
04:16:42 WORKER: registered result for job (4, 0, 16) with dispatcher
04:16:42 DISPATCHER: job (4, 0, 16) finished
04:16:42 DISPATCHER: register_result: lock acquired
04:16:42 DISPATCHER: job (4, 0, 16) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
04:16:42 job_id: (4, 0, 16)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 750, 'last_n_outputs': 41, 'leak_rate': 0.7656934690207551, 'lr': 0.005220196549230092, 'optimizer': 'SGD', 'sparsity': 0.9757433054191733, 'steps_to_train': 69, 'weight_decay': 0.14113135370752436}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7098983745987184, 'info': {'data05': 0.7098983745987184, 'config': "{'batch_size': 16, 'hidden_dim': 750, 'last_n_outputs': 41, 'leak_rate': 0.7656934690207551, 'lr': 0.005220196549230092, 'optimizer': 'SGD', 'sparsity': 0.9757433054191733, 'steps_to_train': 69, 'weight_decay': 0.14113135370752436}"}}
exception: None

04:16:42 job_callback for (4, 0, 16) started
04:16:42 job_callback for (4, 0, 16) got condition
04:16:42 DISPATCHER: Trying to submit another job.
04:16:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:16:42 done building a new model for budget 44.444444 based on 10/37 split
Best loss for this budget:-0.770232





04:16:42 HBMASTER: Trying to run another job!
04:16:42 job_callback for (4, 0, 16) finished
04:16:42 start sampling a new configuration.
04:16:42 best_vector: [2, 0.8881523791941459, 0.897075601609347, 0.5108928263333659, 0.4048353429992374, 1, 0.7105307149238871, 0.8996127514493372, 0.2875544020576619], 0.004853214160009427, 2.1809627731387593, 0.010584679413050455
04:16:42 done sampling a new configuration.
04:16:42 HBMASTER: schedule new run for iteration 4
04:16:42 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
04:16:42 HBMASTER: submitting job (4, 0, 17) to dispatcher
04:16:42 DISPATCHER: trying to submit job (4, 0, 17)
04:16:42 DISPATCHER: trying to notify the job_runner thread.
04:16:42 HBMASTER: job (4, 0, 17) submitted to dispatcher
04:16:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:16:42 DISPATCHER: Trying to submit another job.
04:16:42 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:16:42 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:16:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:16:42 WORKER: start processing job (4, 0, 17)
04:16:42 WORKER: args: ()
04:16:42 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 911, 'last_n_outputs': 46, 'leak_rate': 0.8777232065833415, 'lr': 0.006451648321074381, 'optimizer': 'SGD', 'sparsity': 0.9205273715817329, 'steps_to_train': 91, 'weight_decay': 0.023665566364242357}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:17:24 DISPATCHER: Starting worker discovery
04:17:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:17:24 DISPATCHER: Finished worker discovery
04:17:45 WORKER: done with job (4, 0, 17), trying to register it.
04:17:45 WORKER: registered result for job (4, 0, 17) with dispatcher
04:17:45 DISPATCHER: job (4, 0, 17) finished
04:17:45 DISPATCHER: register_result: lock acquired
04:17:45 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
04:17:45 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 911, 'last_n_outputs': 46, 'leak_rate': 0.8777232065833415, 'lr': 0.006451648321074381, 'optimizer': 'SGD', 'sparsity': 0.9205273715817329, 'steps_to_train': 91, 'weight_decay': 0.023665566364242357}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7318220439736067, 'info': {'data05': 0.7318220439736067, 'config': "{'batch_size': 64, 'hidden_dim': 911, 'last_n_outputs': 46, 'leak_rate': 0.8777232065833415, 'lr': 0.006451648321074381, 'optimizer': 'SGD', 'sparsity': 0.9205273715817329, 'steps_to_train': 91, 'weight_decay': 0.023665566364242357}"}}
exception: None

04:17:45 job_callback for (4, 0, 17) started
04:17:45 job_callback for (4, 0, 17) got condition
04:17:45 DISPATCHER: Trying to submit another job.
04:17:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:17:45 done building a new model for budget 44.444444 based on 10/38 split
Best loss for this budget:-0.770232





04:17:45 HBMASTER: Trying to run another job!
04:17:45 job_callback for (4, 0, 17) finished
04:17:45 start sampling a new configuration.
04:17:45 done sampling a new configuration.
04:17:45 HBMASTER: schedule new run for iteration 4
04:17:45 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
04:17:45 HBMASTER: submitting job (4, 0, 18) to dispatcher
04:17:45 DISPATCHER: trying to submit job (4, 0, 18)
04:17:45 DISPATCHER: trying to notify the job_runner thread.
04:17:45 HBMASTER: job (4, 0, 18) submitted to dispatcher
04:17:45 DISPATCHER: Trying to submit another job.
04:17:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:17:45 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:17:45 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:17:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:17:45 WORKER: start processing job (4, 0, 18)
04:17:45 WORKER: args: ()
04:17:45 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 416, 'last_n_outputs': 30, 'leak_rate': 0.9177833232591965, 'lr': 0.0018836595949934623, 'optimizer': 'SGD', 'sparsity': 0.8845477827331417, 'steps_to_train': 82, 'weight_decay': 0.10407152643912723}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:18:24 DISPATCHER: Starting worker discovery
04:18:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:18:24 DISPATCHER: Finished worker discovery
04:18:45 WORKER: done with job (4, 0, 18), trying to register it.
04:18:45 WORKER: registered result for job (4, 0, 18) with dispatcher
04:18:45 DISPATCHER: job (4, 0, 18) finished
04:18:45 DISPATCHER: register_result: lock acquired
04:18:45 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
04:18:45 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 416, 'last_n_outputs': 30, 'leak_rate': 0.9177833232591965, 'lr': 0.0018836595949934623, 'optimizer': 'SGD', 'sparsity': 0.8845477827331417, 'steps_to_train': 82, 'weight_decay': 0.10407152643912723}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5603424956786197, 'info': {'data05': 0.5603424956786197, 'config': "{'batch_size': 32, 'hidden_dim': 416, 'last_n_outputs': 30, 'leak_rate': 0.9177833232591965, 'lr': 0.0018836595949934623, 'optimizer': 'SGD', 'sparsity': 0.8845477827331417, 'steps_to_train': 82, 'weight_decay': 0.10407152643912723}"}}
exception: None

04:18:45 job_callback for (4, 0, 18) started
04:18:45 job_callback for (4, 0, 18) got condition
04:18:45 DISPATCHER: Trying to submit another job.
04:18:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:18:45 done building a new model for budget 44.444444 based on 10/39 split
Best loss for this budget:-0.770232





04:18:45 HBMASTER: Trying to run another job!
04:18:45 job_callback for (4, 0, 18) finished
04:18:45 start sampling a new configuration.
04:18:45 done sampling a new configuration.
04:18:45 HBMASTER: schedule new run for iteration 4
04:18:45 HBMASTER: trying submitting job (4, 0, 19) to dispatcher
04:18:45 HBMASTER: submitting job (4, 0, 19) to dispatcher
04:18:45 DISPATCHER: trying to submit job (4, 0, 19)
04:18:45 DISPATCHER: trying to notify the job_runner thread.
04:18:45 HBMASTER: job (4, 0, 19) submitted to dispatcher
04:18:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:18:45 DISPATCHER: Trying to submit another job.
04:18:45 DISPATCHER: starting job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:18:45 DISPATCHER: job (4, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:18:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:18:45 WORKER: start processing job (4, 0, 19)
04:18:45 WORKER: args: ()
04:18:45 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 584, 'last_n_outputs': 22, 'leak_rate': 0.8534583788744715, 'lr': 0.02573908566607014, 'optimizer': 'SGD', 'sparsity': 0.7858562145615543, 'steps_to_train': 81, 'weight_decay': 0.023105259105154576}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:19:24 DISPATCHER: Starting worker discovery
04:19:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:19:24 DISPATCHER: Finished worker discovery
04:19:41 WORKER: done with job (4, 0, 19), trying to register it.
04:19:41 WORKER: registered result for job (4, 0, 19) with dispatcher
04:19:41 DISPATCHER: job (4, 0, 19) finished
04:19:41 DISPATCHER: register_result: lock acquired
04:19:41 DISPATCHER: job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
04:19:41 job_id: (4, 0, 19)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 584, 'last_n_outputs': 22, 'leak_rate': 0.8534583788744715, 'lr': 0.02573908566607014, 'optimizer': 'SGD', 'sparsity': 0.7858562145615543, 'steps_to_train': 81, 'weight_decay': 0.023105259105154576}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5117878496287931, 'info': {'data05': 0.5117878496287931, 'config': "{'batch_size': 64, 'hidden_dim': 584, 'last_n_outputs': 22, 'leak_rate': 0.8534583788744715, 'lr': 0.02573908566607014, 'optimizer': 'SGD', 'sparsity': 0.7858562145615543, 'steps_to_train': 81, 'weight_decay': 0.023105259105154576}"}}
exception: None

04:19:41 job_callback for (4, 0, 19) started
04:19:41 job_callback for (4, 0, 19) got condition
04:19:41 DISPATCHER: Trying to submit another job.
04:19:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:19:41 done building a new model for budget 44.444444 based on 10/39 split
Best loss for this budget:-0.770232





04:19:41 HBMASTER: Trying to run another job!
04:19:41 job_callback for (4, 0, 19) finished
04:19:41 start sampling a new configuration.
04:19:41 best_vector: [3, 0.7810697814050288, 0.8807084803565012, 0.8494047387233076, 0.5281995100542456, 1, 0.18688205753291434, 0.7974220166664298, 0.4528634072175331], 0.004972865077492048, 1.9027862351250437, 0.009462299218585903
04:19:41 done sampling a new configuration.
04:19:41 HBMASTER: schedule new run for iteration 4
04:19:41 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
04:19:41 HBMASTER: submitting job (4, 0, 20) to dispatcher
04:19:41 DISPATCHER: trying to submit job (4, 0, 20)
04:19:41 DISPATCHER: trying to notify the job_runner thread.
04:19:41 HBMASTER: job (4, 0, 20) submitted to dispatcher
04:19:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:19:41 DISPATCHER: Trying to submit another job.
04:19:41 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:19:41 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:19:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:19:41 WORKER: start processing job (4, 0, 20)
04:19:41 WORKER: args: ()
04:19:41 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 825, 'last_n_outputs': 46, 'leak_rate': 0.9623511846808269, 'lr': 0.011386729927781353, 'optimizer': 'SGD', 'sparsity': 0.7948516938078994, 'steps_to_train': 82, 'weight_decay': 0.038831921113764774}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:20:24 DISPATCHER: Starting worker discovery
04:20:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:20:24 DISPATCHER: Finished worker discovery
04:20:39 WORKER: done with job (4, 0, 20), trying to register it.
04:20:39 WORKER: registered result for job (4, 0, 20) with dispatcher
04:20:39 DISPATCHER: job (4, 0, 20) finished
04:20:39 DISPATCHER: register_result: lock acquired
04:20:39 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
04:20:39 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 825, 'last_n_outputs': 46, 'leak_rate': 0.9623511846808269, 'lr': 0.011386729927781353, 'optimizer': 'SGD', 'sparsity': 0.7948516938078994, 'steps_to_train': 82, 'weight_decay': 0.038831921113764774}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.754219369086797, 'info': {'data05': 0.754219369086797, 'config': "{'batch_size': 128, 'hidden_dim': 825, 'last_n_outputs': 46, 'leak_rate': 0.9623511846808269, 'lr': 0.011386729927781353, 'optimizer': 'SGD', 'sparsity': 0.7948516938078994, 'steps_to_train': 82, 'weight_decay': 0.038831921113764774}"}}
exception: None

04:20:39 job_callback for (4, 0, 20) started
04:20:39 DISPATCHER: Trying to submit another job.
04:20:39 job_callback for (4, 0, 20) got condition
04:20:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:20:39 done building a new model for budget 44.444444 based on 10/40 split
Best loss for this budget:-0.770232





04:20:39 HBMASTER: Trying to run another job!
04:20:39 job_callback for (4, 0, 20) finished
04:20:39 start sampling a new configuration.
04:20:39 done sampling a new configuration.
04:20:39 HBMASTER: schedule new run for iteration 4
04:20:39 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
04:20:39 HBMASTER: submitting job (4, 0, 21) to dispatcher
04:20:39 DISPATCHER: trying to submit job (4, 0, 21)
04:20:39 DISPATCHER: trying to notify the job_runner thread.
04:20:39 HBMASTER: job (4, 0, 21) submitted to dispatcher
04:20:39 DISPATCHER: Trying to submit another job.
04:20:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:20:39 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:20:39 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:20:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:20:39 WORKER: start processing job (4, 0, 21)
04:20:39 WORKER: args: ()
04:20:39 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 637, 'last_n_outputs': 32, 'leak_rate': 0.8829453207487679, 'lr': 0.0015153414191855972, 'optimizer': 'SGD', 'sparsity': 0.8358602392866984, 'steps_to_train': 90, 'weight_decay': 0.01337693348244874}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:21:24 DISPATCHER: Starting worker discovery
04:21:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:21:24 DISPATCHER: Finished worker discovery
04:21:40 WORKER: done with job (4, 0, 21), trying to register it.
04:21:40 WORKER: registered result for job (4, 0, 21) with dispatcher
04:21:40 DISPATCHER: job (4, 0, 21) finished
04:21:40 DISPATCHER: register_result: lock acquired
04:21:40 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
04:21:40 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 637, 'last_n_outputs': 32, 'leak_rate': 0.8829453207487679, 'lr': 0.0015153414191855972, 'optimizer': 'SGD', 'sparsity': 0.8358602392866984, 'steps_to_train': 90, 'weight_decay': 0.01337693348244874}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5794582101360062, 'info': {'data05': 0.5794582101360062, 'config': "{'batch_size': 128, 'hidden_dim': 637, 'last_n_outputs': 32, 'leak_rate': 0.8829453207487679, 'lr': 0.0015153414191855972, 'optimizer': 'SGD', 'sparsity': 0.8358602392866984, 'steps_to_train': 90, 'weight_decay': 0.01337693348244874}"}}
exception: None

04:21:40 job_callback for (4, 0, 21) started
04:21:40 DISPATCHER: Trying to submit another job.
04:21:40 job_callback for (4, 0, 21) got condition
04:21:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:21:40 done building a new model for budget 44.444444 based on 10/41 split
Best loss for this budget:-0.770232





04:21:40 HBMASTER: Trying to run another job!
04:21:40 job_callback for (4, 0, 21) finished
04:21:40 start sampling a new configuration.
04:21:40 done sampling a new configuration.
04:21:40 HBMASTER: schedule new run for iteration 4
04:21:40 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
04:21:40 HBMASTER: submitting job (4, 0, 22) to dispatcher
04:21:40 DISPATCHER: trying to submit job (4, 0, 22)
04:21:40 DISPATCHER: trying to notify the job_runner thread.
04:21:40 HBMASTER: job (4, 0, 22) submitted to dispatcher
04:21:40 DISPATCHER: Trying to submit another job.
04:21:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:21:40 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:21:40 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:21:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:21:40 WORKER: start processing job (4, 0, 22)
04:21:40 WORKER: args: ()
04:21:40 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 537, 'last_n_outputs': 27, 'leak_rate': 0.8215638590706685, 'lr': 0.0032551139942502074, 'optimizer': 'Adam', 'sparsity': 0.9766673219921991, 'steps_to_train': 57, 'weight_decay': 0.10932533277376406}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:22:24 DISPATCHER: Starting worker discovery
04:22:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:22:24 DISPATCHER: Finished worker discovery
04:22:37 WORKER: done with job (4, 0, 22), trying to register it.
04:22:37 WORKER: registered result for job (4, 0, 22) with dispatcher
04:22:37 DISPATCHER: job (4, 0, 22) finished
04:22:37 DISPATCHER: register_result: lock acquired
04:22:37 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
04:22:37 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 537, 'last_n_outputs': 27, 'leak_rate': 0.8215638590706685, 'lr': 0.0032551139942502074, 'optimizer': 'Adam', 'sparsity': 0.9766673219921991, 'steps_to_train': 57, 'weight_decay': 0.10932533277376406}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.364053220099097, 'info': {'data05': 0.364053220099097, 'config': "{'batch_size': 16, 'hidden_dim': 537, 'last_n_outputs': 27, 'leak_rate': 0.8215638590706685, 'lr': 0.0032551139942502074, 'optimizer': 'Adam', 'sparsity': 0.9766673219921991, 'steps_to_train': 57, 'weight_decay': 0.10932533277376406}"}}
exception: None

04:22:37 job_callback for (4, 0, 22) started
04:22:37 job_callback for (4, 0, 22) got condition
04:22:37 DISPATCHER: Trying to submit another job.
04:22:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:22:37 done building a new model for budget 44.444444 based on 10/42 split
Best loss for this budget:-0.770232





04:22:37 HBMASTER: Trying to run another job!
04:22:37 job_callback for (4, 0, 22) finished
04:22:37 start sampling a new configuration.
04:22:37 best_vector: [2, 0.9098023155789984, 0.8574788521060748, 0.7974621940114133, 0.42927383173187067, 1, 0.12565049355261398, 0.8272020608221647, 0.6316075645219765], 0.0015056940832474277, 3.312027506226233, 0.004986900219677572
04:22:37 done sampling a new configuration.
04:22:37 HBMASTER: schedule new run for iteration 4
04:22:37 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
04:22:37 HBMASTER: submitting job (4, 0, 23) to dispatcher
04:22:37 DISPATCHER: trying to submit job (4, 0, 23)
04:22:37 DISPATCHER: trying to notify the job_runner thread.
04:22:37 HBMASTER: job (4, 0, 23) submitted to dispatcher
04:22:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:22:37 DISPATCHER: Trying to submit another job.
04:22:37 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:22:37 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:22:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:22:37 WORKER: start processing job (4, 0, 23)
04:22:37 WORKER: args: ()
04:22:37 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 928, 'last_n_outputs': 45, 'leak_rate': 0.9493655485028534, 'lr': 0.007220173994073297, 'optimizer': 'SGD', 'sparsity': 0.7801561184526273, 'steps_to_train': 85, 'weight_decay': 0.06633464158530063}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:23:24 DISPATCHER: Starting worker discovery
04:23:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:23:24 DISPATCHER: Finished worker discovery
04:23:36 WORKER: done with job (4, 0, 23), trying to register it.
04:23:36 WORKER: registered result for job (4, 0, 23) with dispatcher
04:23:36 DISPATCHER: job (4, 0, 23) finished
04:23:36 DISPATCHER: register_result: lock acquired
04:23:36 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
04:23:36 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 928, 'last_n_outputs': 45, 'leak_rate': 0.9493655485028534, 'lr': 0.007220173994073297, 'optimizer': 'SGD', 'sparsity': 0.7801561184526273, 'steps_to_train': 85, 'weight_decay': 0.06633464158530063}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7228510709800966, 'info': {'data05': 0.7228510709800966, 'config': "{'batch_size': 64, 'hidden_dim': 928, 'last_n_outputs': 45, 'leak_rate': 0.9493655485028534, 'lr': 0.007220173994073297, 'optimizer': 'SGD', 'sparsity': 0.7801561184526273, 'steps_to_train': 85, 'weight_decay': 0.06633464158530063}"}}
exception: None

04:23:36 job_callback for (4, 0, 23) started
04:23:36 job_callback for (4, 0, 23) got condition
04:23:36 DISPATCHER: Trying to submit another job.
04:23:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:23:36 done building a new model for budget 44.444444 based on 10/43 split
Best loss for this budget:-0.770232





04:23:36 HBMASTER: Trying to run another job!
04:23:36 job_callback for (4, 0, 23) finished
04:23:36 start sampling a new configuration.
04:23:36 best_vector: [2, 0.6022180774593496, 0.8301680084362357, 0.804239606207054, 0.5690978923242672, 1, 0.03527317966316082, 0.5142099539302816, 0.6154884037340681], 0.012304609002924355, 1.1277355987169302, 0.013876345600890625
04:23:36 done sampling a new configuration.
04:23:36 HBMASTER: schedule new run for iteration 4
04:23:36 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
04:23:36 HBMASTER: submitting job (4, 0, 24) to dispatcher
04:23:36 DISPATCHER: trying to submit job (4, 0, 24)
04:23:36 DISPATCHER: trying to notify the job_runner thread.
04:23:36 HBMASTER: job (4, 0, 24) submitted to dispatcher
04:23:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:23:36 DISPATCHER: Trying to submit another job.
04:23:36 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:23:36 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:23:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:23:36 WORKER: start processing job (4, 0, 24)
04:23:36 WORKER: args: ()
04:23:36 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 682, 'last_n_outputs': 44, 'leak_rate': 0.9510599015517636, 'lr': 0.013746615476371031, 'optimizer': 'SGD', 'sparsity': 0.7584655631191586, 'steps_to_train': 56, 'weight_decay': 0.06320753811794966}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:24:24 DISPATCHER: Starting worker discovery
04:24:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:24:24 DISPATCHER: Finished worker discovery
04:24:36 WORKER: done with job (4, 0, 24), trying to register it.
04:24:36 WORKER: registered result for job (4, 0, 24) with dispatcher
04:24:36 DISPATCHER: job (4, 0, 24) finished
04:24:36 DISPATCHER: register_result: lock acquired
04:24:36 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
04:24:36 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 682, 'last_n_outputs': 44, 'leak_rate': 0.9510599015517636, 'lr': 0.013746615476371031, 'optimizer': 'SGD', 'sparsity': 0.7584655631191586, 'steps_to_train': 56, 'weight_decay': 0.06320753811794966}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6963746452695179, 'info': {'data05': 0.6963746452695179, 'config': "{'batch_size': 64, 'hidden_dim': 682, 'last_n_outputs': 44, 'leak_rate': 0.9510599015517636, 'lr': 0.013746615476371031, 'optimizer': 'SGD', 'sparsity': 0.7584655631191586, 'steps_to_train': 56, 'weight_decay': 0.06320753811794966}"}}
exception: None

04:24:36 job_callback for (4, 0, 24) started
04:24:36 DISPATCHER: Trying to submit another job.
04:24:36 job_callback for (4, 0, 24) got condition
04:24:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:24:36 done building a new model for budget 44.444444 based on 10/44 split
Best loss for this budget:-0.770232





04:24:36 HBMASTER: Trying to run another job!
04:24:36 job_callback for (4, 0, 24) finished
04:24:36 start sampling a new configuration.
04:24:36 best_vector: [1, 0.09083302121216152, 0.7429365625448949, 0.2796068429437533, 0.7744179090585144, 1, 0.6031178638516617, 0.6858504001347401, 0.06866054924604101], 0.01117109821548958, 0.9508253595657239, 0.010621763477486897
04:24:36 done sampling a new configuration.
04:24:36 HBMASTER: schedule new run for iteration 4
04:24:36 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
04:24:36 HBMASTER: submitting job (4, 0, 25) to dispatcher
04:24:36 DISPATCHER: trying to submit job (4, 0, 25)
04:24:36 DISPATCHER: trying to notify the job_runner thread.
04:24:36 HBMASTER: job (4, 0, 25) submitted to dispatcher
04:24:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:24:36 DISPATCHER: Trying to submit another job.
04:24:36 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:24:36 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:24:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:24:36 WORKER: start processing job (4, 0, 25)
04:24:36 WORKER: args: ()
04:24:36 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 272, 'last_n_outputs': 40, 'leak_rate': 0.8199017107359383, 'lr': 0.035386354024571194, 'optimizer': 'SGD', 'sparsity': 0.8947482873243988, 'steps_to_train': 72, 'weight_decay': 0.012283706584339806}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:25:24 DISPATCHER: Starting worker discovery
04:25:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:25:24 DISPATCHER: Finished worker discovery
04:25:39 WORKER: done with job (4, 0, 25), trying to register it.
04:25:39 WORKER: registered result for job (4, 0, 25) with dispatcher
04:25:39 DISPATCHER: job (4, 0, 25) finished
04:25:39 DISPATCHER: register_result: lock acquired
04:25:39 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
04:25:39 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 272, 'last_n_outputs': 40, 'leak_rate': 0.8199017107359383, 'lr': 0.035386354024571194, 'optimizer': 'SGD', 'sparsity': 0.8947482873243988, 'steps_to_train': 72, 'weight_decay': 0.012283706584339806}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6663193435176806, 'info': {'data05': 0.6663193435176806, 'config': "{'batch_size': 32, 'hidden_dim': 272, 'last_n_outputs': 40, 'leak_rate': 0.8199017107359383, 'lr': 0.035386354024571194, 'optimizer': 'SGD', 'sparsity': 0.8947482873243988, 'steps_to_train': 72, 'weight_decay': 0.012283706584339806}"}}
exception: None

04:25:39 job_callback for (4, 0, 25) started
04:25:39 DISPATCHER: Trying to submit another job.
04:25:39 job_callback for (4, 0, 25) got condition
04:25:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:25:39 done building a new model for budget 44.444444 based on 10/45 split
Best loss for this budget:-0.770232





04:25:39 HBMASTER: Trying to run another job!
04:25:39 job_callback for (4, 0, 25) finished
04:25:39 start sampling a new configuration.
04:25:39 best_vector: [1, 0.8115798540044978, 0.9309385732257601, 0.672924538009125, 0.5536190413192889, 1, 0.7354570614446172, 0.5424654587326008, 0.467193103503465], 0.034973680569902875, 1.325932855173173, 0.04637275213396584
04:25:39 done sampling a new configuration.
04:25:39 HBMASTER: schedule new run for iteration 4
04:25:39 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
04:25:39 HBMASTER: submitting job (4, 0, 26) to dispatcher
04:25:39 DISPATCHER: trying to submit job (4, 0, 26)
04:25:39 DISPATCHER: trying to notify the job_runner thread.
04:25:39 HBMASTER: job (4, 0, 26) submitted to dispatcher
04:25:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:25:39 DISPATCHER: Trying to submit another job.
04:25:39 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:25:39 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:25:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:25:39 WORKER: start processing job (4, 0, 26)
04:25:39 WORKER: args: ()
04:25:39 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 850, 'last_n_outputs': 48, 'leak_rate': 0.9182311345022812, 'lr': 0.012800828603501109, 'optimizer': 'SGD', 'sparsity': 0.9265096947467082, 'steps_to_train': 59, 'weight_decay': 0.04053519265121536}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:26:24 DISPATCHER: Starting worker discovery
04:26:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:26:24 DISPATCHER: Finished worker discovery
04:26:39 WORKER: done with job (4, 0, 26), trying to register it.
04:26:39 WORKER: registered result for job (4, 0, 26) with dispatcher
04:26:39 DISPATCHER: job (4, 0, 26) finished
04:26:39 DISPATCHER: register_result: lock acquired
04:26:39 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
04:26:39 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 850, 'last_n_outputs': 48, 'leak_rate': 0.9182311345022812, 'lr': 0.012800828603501109, 'optimizer': 'SGD', 'sparsity': 0.9265096947467082, 'steps_to_train': 59, 'weight_decay': 0.04053519265121536}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7510542230125861, 'info': {'data05': 0.7510542230125861, 'config': "{'batch_size': 32, 'hidden_dim': 850, 'last_n_outputs': 48, 'leak_rate': 0.9182311345022812, 'lr': 0.012800828603501109, 'optimizer': 'SGD', 'sparsity': 0.9265096947467082, 'steps_to_train': 59, 'weight_decay': 0.04053519265121536}"}}
exception: None

04:26:39 job_callback for (4, 0, 26) started
04:26:39 DISPATCHER: Trying to submit another job.
04:26:39 job_callback for (4, 0, 26) got condition
04:26:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:26:39 done building a new model for budget 44.444444 based on 10/45 split
Best loss for this budget:-0.770232





04:26:39 HBMASTER: Trying to run another job!
04:26:39 job_callback for (4, 0, 26) finished
04:26:39 ITERATION: Advancing config (4, 0, 2) to next budget 133.333333
04:26:39 ITERATION: Advancing config (4, 0, 5) to next budget 133.333333
04:26:39 ITERATION: Advancing config (4, 0, 6) to next budget 133.333333
04:26:39 ITERATION: Advancing config (4, 0, 12) to next budget 133.333333
04:26:39 ITERATION: Advancing config (4, 0, 13) to next budget 133.333333
04:26:39 ITERATION: Advancing config (4, 0, 14) to next budget 133.333333
04:26:39 ITERATION: Advancing config (4, 0, 17) to next budget 133.333333
04:26:39 ITERATION: Advancing config (4, 0, 20) to next budget 133.333333
04:26:39 ITERATION: Advancing config (4, 0, 26) to next budget 133.333333
04:26:39 HBMASTER: schedule new run for iteration 4
04:26:39 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
04:26:39 HBMASTER: submitting job (4, 0, 2) to dispatcher
04:26:39 DISPATCHER: trying to submit job (4, 0, 2)
04:26:39 DISPATCHER: trying to notify the job_runner thread.
04:26:39 HBMASTER: job (4, 0, 2) submitted to dispatcher
04:26:39 DISPATCHER: Trying to submit another job.
04:26:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:26:39 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:26:39 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:26:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:26:39 WORKER: start processing job (4, 0, 2)
04:26:39 WORKER: args: ()
04:26:39 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 866, 'last_n_outputs': 50, 'leak_rate': 0.876141618589035, 'lr': 0.007613117461710608, 'optimizer': 'SGD', 'sparsity': 0.9421304576253045, 'steps_to_train': 32, 'weight_decay': 0.05900072308061692}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:27:24 DISPATCHER: Starting worker discovery
04:27:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:27:24 DISPATCHER: Finished worker discovery
04:28:24 DISPATCHER: Starting worker discovery
04:28:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:28:24 DISPATCHER: Finished worker discovery
04:29:08 WORKER: done with job (4, 0, 2), trying to register it.
04:29:08 WORKER: registered result for job (4, 0, 2) with dispatcher
04:29:08 DISPATCHER: job (4, 0, 2) finished
04:29:08 DISPATCHER: register_result: lock acquired
04:29:08 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
04:29:08 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 866, 'last_n_outputs': 50, 'leak_rate': 0.876141618589035, 'lr': 0.007613117461710608, 'optimizer': 'SGD', 'sparsity': 0.9421304576253045, 'steps_to_train': 32, 'weight_decay': 0.05900072308061692}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7360705711620158, 'info': {'data05': 0.7360705711620158, 'config': "{'batch_size': 32, 'hidden_dim': 866, 'last_n_outputs': 50, 'leak_rate': 0.876141618589035, 'lr': 0.007613117461710608, 'optimizer': 'SGD', 'sparsity': 0.9421304576253045, 'steps_to_train': 32, 'weight_decay': 0.05900072308061692}"}}
exception: None

04:29:08 job_callback for (4, 0, 2) started
04:29:08 job_callback for (4, 0, 2) got condition
04:29:08 DISPATCHER: Trying to submit another job.
04:29:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:29:08 HBMASTER: Trying to run another job!
04:29:08 job_callback for (4, 0, 2) finished
04:29:08 HBMASTER: schedule new run for iteration 4
04:29:08 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
04:29:08 HBMASTER: submitting job (4, 0, 5) to dispatcher
04:29:08 DISPATCHER: trying to submit job (4, 0, 5)
04:29:08 DISPATCHER: trying to notify the job_runner thread.
04:29:08 HBMASTER: job (4, 0, 5) submitted to dispatcher
04:29:08 DISPATCHER: Trying to submit another job.
04:29:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:29:08 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:29:08 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:29:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:29:08 WORKER: start processing job (4, 0, 5)
04:29:08 WORKER: args: ()
04:29:08 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 897, 'last_n_outputs': 49, 'leak_rate': 0.7602216627055048, 'lr': 0.004759897530817441, 'optimizer': 'SGD', 'sparsity': 0.9482350307821125, 'steps_to_train': 28, 'weight_decay': 0.08023897763534726}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:29:24 DISPATCHER: Starting worker discovery
04:29:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:29:24 DISPATCHER: Finished worker discovery
04:30:24 DISPATCHER: Starting worker discovery
04:30:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:30:24 DISPATCHER: Finished worker discovery
04:31:24 DISPATCHER: Starting worker discovery
04:31:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:31:24 DISPATCHER: Finished worker discovery
04:31:37 WORKER: done with job (4, 0, 5), trying to register it.
04:31:37 WORKER: registered result for job (4, 0, 5) with dispatcher
04:31:37 DISPATCHER: job (4, 0, 5) finished
04:31:37 DISPATCHER: register_result: lock acquired
04:31:37 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
04:31:37 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 897, 'last_n_outputs': 49, 'leak_rate': 0.7602216627055048, 'lr': 0.004759897530817441, 'optimizer': 'SGD', 'sparsity': 0.9482350307821125, 'steps_to_train': 28, 'weight_decay': 0.08023897763534726}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7602058186396634, 'info': {'data05': 0.7602058186396634, 'config': "{'batch_size': 16, 'hidden_dim': 897, 'last_n_outputs': 49, 'leak_rate': 0.7602216627055048, 'lr': 0.004759897530817441, 'optimizer': 'SGD', 'sparsity': 0.9482350307821125, 'steps_to_train': 28, 'weight_decay': 0.08023897763534726}"}}
exception: None

04:31:37 job_callback for (4, 0, 5) started
04:31:37 DISPATCHER: Trying to submit another job.
04:31:37 job_callback for (4, 0, 5) got condition
04:31:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:31:37 done building a new model for budget 133.333333 based on 10/17 split
Best loss for this budget:-0.769956





04:31:37 HBMASTER: Trying to run another job!
04:31:37 job_callback for (4, 0, 5) finished
04:31:37 HBMASTER: schedule new run for iteration 4
04:31:37 HBMASTER: trying submitting job (4, 0, 6) to dispatcher
04:31:37 HBMASTER: submitting job (4, 0, 6) to dispatcher
04:31:37 DISPATCHER: trying to submit job (4, 0, 6)
04:31:37 DISPATCHER: trying to notify the job_runner thread.
04:31:37 HBMASTER: job (4, 0, 6) submitted to dispatcher
04:31:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:31:37 DISPATCHER: Trying to submit another job.
04:31:37 DISPATCHER: starting job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:31:37 DISPATCHER: job (4, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:31:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:31:37 WORKER: start processing job (4, 0, 6)
04:31:37 WORKER: args: ()
04:31:37 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 923, 'last_n_outputs': 43, 'leak_rate': 0.8899949350478409, 'lr': 0.008728901167239329, 'optimizer': 'SGD', 'sparsity': 0.9686446181927488, 'steps_to_train': 85, 'weight_decay': 0.01564988946184848}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:32:24 DISPATCHER: Starting worker discovery
04:32:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:32:24 DISPATCHER: Finished worker discovery
04:33:24 DISPATCHER: Starting worker discovery
04:33:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:33:24 DISPATCHER: Finished worker discovery
04:34:08 WORKER: done with job (4, 0, 6), trying to register it.
04:34:08 WORKER: registered result for job (4, 0, 6) with dispatcher
04:34:08 DISPATCHER: job (4, 0, 6) finished
04:34:08 DISPATCHER: register_result: lock acquired
04:34:08 DISPATCHER: job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
04:34:08 job_id: (4, 0, 6)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 923, 'last_n_outputs': 43, 'leak_rate': 0.8899949350478409, 'lr': 0.008728901167239329, 'optimizer': 'SGD', 'sparsity': 0.9686446181927488, 'steps_to_train': 85, 'weight_decay': 0.01564988946184848}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7265856879979968, 'info': {'data05': 0.7265856879979968, 'config': "{'batch_size': 32, 'hidden_dim': 923, 'last_n_outputs': 43, 'leak_rate': 0.8899949350478409, 'lr': 0.008728901167239329, 'optimizer': 'SGD', 'sparsity': 0.9686446181927488, 'steps_to_train': 85, 'weight_decay': 0.01564988946184848}"}}
exception: None

04:34:08 job_callback for (4, 0, 6) started
04:34:08 DISPATCHER: Trying to submit another job.
04:34:08 job_callback for (4, 0, 6) got condition
04:34:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:34:08 done building a new model for budget 133.333333 based on 10/17 split
Best loss for this budget:-0.769956





04:34:08 HBMASTER: Trying to run another job!
04:34:08 job_callback for (4, 0, 6) finished
04:34:08 HBMASTER: schedule new run for iteration 4
04:34:08 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
04:34:08 HBMASTER: submitting job (4, 0, 12) to dispatcher
04:34:08 DISPATCHER: trying to submit job (4, 0, 12)
04:34:08 DISPATCHER: trying to notify the job_runner thread.
04:34:08 HBMASTER: job (4, 0, 12) submitted to dispatcher
04:34:08 DISPATCHER: Trying to submit another job.
04:34:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:34:08 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:34:08 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:34:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:34:08 WORKER: start processing job (4, 0, 12)
04:34:08 WORKER: args: ()
04:34:08 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 668, 'last_n_outputs': 49, 'leak_rate': 0.9516581252430247, 'lr': 0.004979882462352569, 'optimizer': 'SGD', 'sparsity': 0.810763816959782, 'steps_to_train': 83, 'weight_decay': 0.09954082947149888}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:34:24 DISPATCHER: Starting worker discovery
04:34:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:34:24 DISPATCHER: Finished worker discovery
04:35:24 DISPATCHER: Starting worker discovery
04:35:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:35:24 DISPATCHER: Finished worker discovery
04:36:24 DISPATCHER: Starting worker discovery
04:36:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:36:24 DISPATCHER: Finished worker discovery
04:36:39 WORKER: done with job (4, 0, 12), trying to register it.
04:36:39 WORKER: registered result for job (4, 0, 12) with dispatcher
04:36:39 DISPATCHER: job (4, 0, 12) finished
04:36:39 DISPATCHER: register_result: lock acquired
04:36:39 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
04:36:39 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 668, 'last_n_outputs': 49, 'leak_rate': 0.9516581252430247, 'lr': 0.004979882462352569, 'optimizer': 'SGD', 'sparsity': 0.810763816959782, 'steps_to_train': 83, 'weight_decay': 0.09954082947149888}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7334072482826537, 'info': {'data05': 0.7334072482826537, 'config': "{'batch_size': 32, 'hidden_dim': 668, 'last_n_outputs': 49, 'leak_rate': 0.9516581252430247, 'lr': 0.004979882462352569, 'optimizer': 'SGD', 'sparsity': 0.810763816959782, 'steps_to_train': 83, 'weight_decay': 0.09954082947149888}"}}
exception: None

04:36:39 job_callback for (4, 0, 12) started
04:36:39 job_callback for (4, 0, 12) got condition
04:36:39 DISPATCHER: Trying to submit another job.
04:36:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:36:39 done building a new model for budget 133.333333 based on 10/18 split
Best loss for this budget:-0.769956





04:36:39 HBMASTER: Trying to run another job!
04:36:39 job_callback for (4, 0, 12) finished
04:36:39 HBMASTER: schedule new run for iteration 4
04:36:39 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
04:36:39 HBMASTER: submitting job (4, 0, 13) to dispatcher
04:36:39 DISPATCHER: trying to submit job (4, 0, 13)
04:36:39 DISPATCHER: trying to notify the job_runner thread.
04:36:39 HBMASTER: job (4, 0, 13) submitted to dispatcher
04:36:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:36:39 DISPATCHER: Trying to submit another job.
04:36:39 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:36:39 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:36:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:36:39 WORKER: start processing job (4, 0, 13)
04:36:39 WORKER: args: ()
04:36:39 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 679, 'last_n_outputs': 43, 'leak_rate': 0.8431553762709028, 'lr': 0.010815489958339768, 'optimizer': 'SGD', 'sparsity': 0.9310181645648479, 'steps_to_train': 86, 'weight_decay': 0.014010783696841179}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:37:24 DISPATCHER: Starting worker discovery
04:37:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:37:24 DISPATCHER: Finished worker discovery
04:38:24 DISPATCHER: Starting worker discovery
04:38:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:38:24 DISPATCHER: Finished worker discovery
04:39:12 WORKER: done with job (4, 0, 13), trying to register it.
04:39:12 WORKER: registered result for job (4, 0, 13) with dispatcher
04:39:12 DISPATCHER: job (4, 0, 13) finished
04:39:12 DISPATCHER: register_result: lock acquired
04:39:12 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
04:39:12 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 679, 'last_n_outputs': 43, 'leak_rate': 0.8431553762709028, 'lr': 0.010815489958339768, 'optimizer': 'SGD', 'sparsity': 0.9310181645648479, 'steps_to_train': 86, 'weight_decay': 0.014010783696841179}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7253180617312344, 'info': {'data05': 0.7253180617312344, 'config': "{'batch_size': 16, 'hidden_dim': 679, 'last_n_outputs': 43, 'leak_rate': 0.8431553762709028, 'lr': 0.010815489958339768, 'optimizer': 'SGD', 'sparsity': 0.9310181645648479, 'steps_to_train': 86, 'weight_decay': 0.014010783696841179}"}}
exception: None

04:39:12 job_callback for (4, 0, 13) started
04:39:12 DISPATCHER: Trying to submit another job.
04:39:12 job_callback for (4, 0, 13) got condition
04:39:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:39:12 done building a new model for budget 133.333333 based on 10/19 split
Best loss for this budget:-0.769956





04:39:12 HBMASTER: Trying to run another job!
04:39:12 job_callback for (4, 0, 13) finished
04:39:12 HBMASTER: schedule new run for iteration 4
04:39:12 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
04:39:12 HBMASTER: submitting job (4, 0, 14) to dispatcher
04:39:12 DISPATCHER: trying to submit job (4, 0, 14)
04:39:12 DISPATCHER: trying to notify the job_runner thread.
04:39:12 HBMASTER: job (4, 0, 14) submitted to dispatcher
04:39:12 DISPATCHER: Trying to submit another job.
04:39:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:39:12 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:39:12 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:39:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:39:12 WORKER: start processing job (4, 0, 14)
04:39:12 WORKER: args: ()
04:39:12 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 948, 'last_n_outputs': 49, 'leak_rate': 0.8864974873284095, 'lr': 0.00364887338462012, 'optimizer': 'SGD', 'sparsity': 0.9268754454166954, 'steps_to_train': 41, 'weight_decay': 0.16001671822643088}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:39:24 DISPATCHER: Starting worker discovery
04:39:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:39:24 DISPATCHER: Finished worker discovery
04:40:24 DISPATCHER: Starting worker discovery
04:40:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:40:24 DISPATCHER: Finished worker discovery
04:41:24 DISPATCHER: Starting worker discovery
04:41:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:41:24 DISPATCHER: Finished worker discovery
04:41:41 WORKER: done with job (4, 0, 14), trying to register it.
04:41:41 WORKER: registered result for job (4, 0, 14) with dispatcher
04:41:41 DISPATCHER: job (4, 0, 14) finished
04:41:41 DISPATCHER: register_result: lock acquired
04:41:41 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
04:41:41 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 948, 'last_n_outputs': 49, 'leak_rate': 0.8864974873284095, 'lr': 0.00364887338462012, 'optimizer': 'SGD', 'sparsity': 0.9268754454166954, 'steps_to_train': 41, 'weight_decay': 0.16001671822643088}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.759950756964775, 'info': {'data05': 0.759950756964775, 'config': "{'batch_size': 16, 'hidden_dim': 948, 'last_n_outputs': 49, 'leak_rate': 0.8864974873284095, 'lr': 0.00364887338462012, 'optimizer': 'SGD', 'sparsity': 0.9268754454166954, 'steps_to_train': 41, 'weight_decay': 0.16001671822643088}"}}
exception: None

04:41:41 job_callback for (4, 0, 14) started
04:41:41 job_callback for (4, 0, 14) got condition
04:41:41 DISPATCHER: Trying to submit another job.
04:41:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:41:41 done building a new model for budget 133.333333 based on 10/20 split
Best loss for this budget:-0.769956





04:41:41 HBMASTER: Trying to run another job!
04:41:41 job_callback for (4, 0, 14) finished
04:41:41 HBMASTER: schedule new run for iteration 4
04:41:41 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
04:41:41 HBMASTER: submitting job (4, 0, 17) to dispatcher
04:41:41 DISPATCHER: trying to submit job (4, 0, 17)
04:41:41 DISPATCHER: trying to notify the job_runner thread.
04:41:41 HBMASTER: job (4, 0, 17) submitted to dispatcher
04:41:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:41:41 DISPATCHER: Trying to submit another job.
04:41:41 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:41:41 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:41:41 WORKER: start processing job (4, 0, 17)
04:41:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:41:41 WORKER: args: ()
04:41:41 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 911, 'last_n_outputs': 46, 'leak_rate': 0.8777232065833415, 'lr': 0.006451648321074381, 'optimizer': 'SGD', 'sparsity': 0.9205273715817329, 'steps_to_train': 91, 'weight_decay': 0.023665566364242357}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:42:24 DISPATCHER: Starting worker discovery
04:42:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:42:24 DISPATCHER: Finished worker discovery
04:43:24 DISPATCHER: Starting worker discovery
04:43:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:43:24 DISPATCHER: Finished worker discovery
04:44:12 WORKER: done with job (4, 0, 17), trying to register it.
04:44:12 WORKER: registered result for job (4, 0, 17) with dispatcher
04:44:12 DISPATCHER: job (4, 0, 17) finished
04:44:12 DISPATCHER: register_result: lock acquired
04:44:12 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
04:44:12 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 911, 'last_n_outputs': 46, 'leak_rate': 0.8777232065833415, 'lr': 0.006451648321074381, 'optimizer': 'SGD', 'sparsity': 0.9205273715817329, 'steps_to_train': 91, 'weight_decay': 0.023665566364242357}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7598114138264851, 'info': {'data05': 0.7598114138264851, 'config': "{'batch_size': 64, 'hidden_dim': 911, 'last_n_outputs': 46, 'leak_rate': 0.8777232065833415, 'lr': 0.006451648321074381, 'optimizer': 'SGD', 'sparsity': 0.9205273715817329, 'steps_to_train': 91, 'weight_decay': 0.023665566364242357}"}}
exception: None

04:44:12 job_callback for (4, 0, 17) started
04:44:12 DISPATCHER: Trying to submit another job.
04:44:12 job_callback for (4, 0, 17) got condition
04:44:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:44:12 done building a new model for budget 133.333333 based on 10/21 split
Best loss for this budget:-0.769956





04:44:12 HBMASTER: Trying to run another job!
04:44:12 job_callback for (4, 0, 17) finished
04:44:12 HBMASTER: schedule new run for iteration 4
04:44:12 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
04:44:12 HBMASTER: submitting job (4, 0, 20) to dispatcher
04:44:12 DISPATCHER: trying to submit job (4, 0, 20)
04:44:12 DISPATCHER: trying to notify the job_runner thread.
04:44:12 HBMASTER: job (4, 0, 20) submitted to dispatcher
04:44:12 DISPATCHER: Trying to submit another job.
04:44:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:44:12 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:44:12 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:44:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:44:12 WORKER: start processing job (4, 0, 20)
04:44:12 WORKER: args: ()
04:44:12 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 825, 'last_n_outputs': 46, 'leak_rate': 0.9623511846808269, 'lr': 0.011386729927781353, 'optimizer': 'SGD', 'sparsity': 0.7948516938078994, 'steps_to_train': 82, 'weight_decay': 0.038831921113764774}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:44:24 DISPATCHER: Starting worker discovery
04:44:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:44:24 DISPATCHER: Finished worker discovery
04:45:24 DISPATCHER: Starting worker discovery
04:45:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:45:24 DISPATCHER: Finished worker discovery
04:46:24 DISPATCHER: Starting worker discovery
04:46:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:46:24 DISPATCHER: Finished worker discovery
04:46:46 WORKER: done with job (4, 0, 20), trying to register it.
04:46:46 WORKER: registered result for job (4, 0, 20) with dispatcher
04:46:46 DISPATCHER: job (4, 0, 20) finished
04:46:46 DISPATCHER: register_result: lock acquired
04:46:46 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
04:46:46 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 825, 'last_n_outputs': 46, 'leak_rate': 0.9623511846808269, 'lr': 0.011386729927781353, 'optimizer': 'SGD', 'sparsity': 0.7948516938078994, 'steps_to_train': 82, 'weight_decay': 0.038831921113764774}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7372302240517479, 'info': {'data05': 0.7372302240517479, 'config': "{'batch_size': 128, 'hidden_dim': 825, 'last_n_outputs': 46, 'leak_rate': 0.9623511846808269, 'lr': 0.011386729927781353, 'optimizer': 'SGD', 'sparsity': 0.7948516938078994, 'steps_to_train': 82, 'weight_decay': 0.038831921113764774}"}}
exception: None

04:46:46 job_callback for (4, 0, 20) started
04:46:46 job_callback for (4, 0, 20) got condition
04:46:46 DISPATCHER: Trying to submit another job.
04:46:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:46:46 done building a new model for budget 133.333333 based on 10/22 split
Best loss for this budget:-0.769956





04:46:46 HBMASTER: Trying to run another job!
04:46:46 job_callback for (4, 0, 20) finished
04:46:46 HBMASTER: schedule new run for iteration 4
04:46:46 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
04:46:46 HBMASTER: submitting job (4, 0, 26) to dispatcher
04:46:46 DISPATCHER: trying to submit job (4, 0, 26)
04:46:46 DISPATCHER: trying to notify the job_runner thread.
04:46:46 HBMASTER: job (4, 0, 26) submitted to dispatcher
04:46:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:46:46 DISPATCHER: Trying to submit another job.
04:46:46 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:46:46 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:46:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:46:46 WORKER: start processing job (4, 0, 26)
04:46:46 WORKER: args: ()
04:46:46 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 850, 'last_n_outputs': 48, 'leak_rate': 0.9182311345022812, 'lr': 0.012800828603501109, 'optimizer': 'SGD', 'sparsity': 0.9265096947467082, 'steps_to_train': 59, 'weight_decay': 0.04053519265121536}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:47:24 DISPATCHER: Starting worker discovery
04:47:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:47:24 DISPATCHER: Finished worker discovery
04:48:24 DISPATCHER: Starting worker discovery
04:48:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:48:25 DISPATCHER: Finished worker discovery
04:49:15 WORKER: done with job (4, 0, 26), trying to register it.
04:49:15 WORKER: registered result for job (4, 0, 26) with dispatcher
04:49:15 DISPATCHER: job (4, 0, 26) finished
04:49:15 DISPATCHER: register_result: lock acquired
04:49:15 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
04:49:15 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 850, 'last_n_outputs': 48, 'leak_rate': 0.9182311345022812, 'lr': 0.012800828603501109, 'optimizer': 'SGD', 'sparsity': 0.9265096947467082, 'steps_to_train': 59, 'weight_decay': 0.04053519265121536}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7382009821700022, 'info': {'data05': 0.7382009821700022, 'config': "{'batch_size': 32, 'hidden_dim': 850, 'last_n_outputs': 48, 'leak_rate': 0.9182311345022812, 'lr': 0.012800828603501109, 'optimizer': 'SGD', 'sparsity': 0.9265096947467082, 'steps_to_train': 59, 'weight_decay': 0.04053519265121536}"}}
exception: None

04:49:15 job_callback for (4, 0, 26) started
04:49:15 job_callback for (4, 0, 26) got condition
04:49:15 DISPATCHER: Trying to submit another job.
04:49:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:49:15 done building a new model for budget 133.333333 based on 10/22 split
Best loss for this budget:-0.769956





04:49:15 HBMASTER: Trying to run another job!
04:49:15 job_callback for (4, 0, 26) finished
04:49:15 ITERATION: Advancing config (4, 0, 5) to next budget 400.000000
04:49:15 ITERATION: Advancing config (4, 0, 14) to next budget 400.000000
04:49:15 ITERATION: Advancing config (4, 0, 17) to next budget 400.000000
04:49:15 HBMASTER: schedule new run for iteration 4
04:49:15 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
04:49:15 HBMASTER: submitting job (4, 0, 5) to dispatcher
04:49:15 DISPATCHER: trying to submit job (4, 0, 5)
04:49:15 DISPATCHER: trying to notify the job_runner thread.
04:49:15 HBMASTER: job (4, 0, 5) submitted to dispatcher
04:49:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:49:15 DISPATCHER: Trying to submit another job.
04:49:15 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:49:15 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:49:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:49:15 WORKER: start processing job (4, 0, 5)
04:49:15 WORKER: args: ()
04:49:15 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 897, 'last_n_outputs': 49, 'leak_rate': 0.7602216627055048, 'lr': 0.004759897530817441, 'optimizer': 'SGD', 'sparsity': 0.9482350307821125, 'steps_to_train': 28, 'weight_decay': 0.08023897763534726}, 'budget': 400.0, 'working_directory': '.'}
04:49:25 DISPATCHER: Starting worker discovery
04:49:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:49:25 DISPATCHER: Finished worker discovery
04:50:25 DISPATCHER: Starting worker discovery
04:50:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:50:25 DISPATCHER: Finished worker discovery
04:51:25 DISPATCHER: Starting worker discovery
04:51:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:51:25 DISPATCHER: Finished worker discovery
04:52:25 DISPATCHER: Starting worker discovery
04:52:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:52:25 DISPATCHER: Finished worker discovery
04:53:25 DISPATCHER: Starting worker discovery
04:53:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:53:25 DISPATCHER: Finished worker discovery
04:54:25 DISPATCHER: Starting worker discovery
04:54:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:54:25 DISPATCHER: Finished worker discovery
04:55:25 DISPATCHER: Starting worker discovery
04:55:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:55:25 DISPATCHER: Finished worker discovery
04:56:11 WORKER: done with job (4, 0, 5), trying to register it.
04:56:11 WORKER: registered result for job (4, 0, 5) with dispatcher
04:56:11 DISPATCHER: job (4, 0, 5) finished
04:56:11 DISPATCHER: register_result: lock acquired
04:56:11 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
04:56:11 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 897, 'last_n_outputs': 49, 'leak_rate': 0.7602216627055048, 'lr': 0.004759897530817441, 'optimizer': 'SGD', 'sparsity': 0.9482350307821125, 'steps_to_train': 28, 'weight_decay': 0.08023897763534726}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7548563148818865, 'info': {'data05': 0.7548563148818865, 'config': "{'batch_size': 16, 'hidden_dim': 897, 'last_n_outputs': 49, 'leak_rate': 0.7602216627055048, 'lr': 0.004759897530817441, 'optimizer': 'SGD', 'sparsity': 0.9482350307821125, 'steps_to_train': 28, 'weight_decay': 0.08023897763534726}"}}
exception: None

04:56:11 job_callback for (4, 0, 5) started
04:56:11 DISPATCHER: Trying to submit another job.
04:56:11 job_callback for (4, 0, 5) got condition
04:56:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:56:11 HBMASTER: Trying to run another job!
04:56:11 job_callback for (4, 0, 5) finished
04:56:11 HBMASTER: schedule new run for iteration 4
04:56:11 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
04:56:11 HBMASTER: submitting job (4, 0, 14) to dispatcher
04:56:11 DISPATCHER: trying to submit job (4, 0, 14)
04:56:11 DISPATCHER: trying to notify the job_runner thread.
04:56:11 HBMASTER: job (4, 0, 14) submitted to dispatcher
04:56:11 DISPATCHER: Trying to submit another job.
04:56:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:56:11 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:56:11 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:56:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:56:11 WORKER: start processing job (4, 0, 14)
04:56:11 WORKER: args: ()
04:56:11 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 948, 'last_n_outputs': 49, 'leak_rate': 0.8864974873284095, 'lr': 0.00364887338462012, 'optimizer': 'SGD', 'sparsity': 0.9268754454166954, 'steps_to_train': 41, 'weight_decay': 0.16001671822643088}, 'budget': 400.0, 'working_directory': '.'}
04:56:25 DISPATCHER: Starting worker discovery
04:56:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:56:25 DISPATCHER: Finished worker discovery
04:57:25 DISPATCHER: Starting worker discovery
04:57:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:57:25 DISPATCHER: Finished worker discovery
04:58:25 DISPATCHER: Starting worker discovery
04:58:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:58:25 DISPATCHER: Finished worker discovery
04:59:25 DISPATCHER: Starting worker discovery
04:59:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:59:25 DISPATCHER: Finished worker discovery
05:00:25 DISPATCHER: Starting worker discovery
05:00:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:00:25 DISPATCHER: Finished worker discovery
05:01:25 DISPATCHER: Starting worker discovery
05:01:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:01:25 DISPATCHER: Finished worker discovery
05:02:25 DISPATCHER: Starting worker discovery
05:02:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:02:25 DISPATCHER: Finished worker discovery
05:03:09 WORKER: done with job (4, 0, 14), trying to register it.
05:03:09 WORKER: registered result for job (4, 0, 14) with dispatcher
05:03:09 DISPATCHER: job (4, 0, 14) finished
05:03:09 DISPATCHER: register_result: lock acquired
05:03:09 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
05:03:09 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 948, 'last_n_outputs': 49, 'leak_rate': 0.8864974873284095, 'lr': 0.00364887338462012, 'optimizer': 'SGD', 'sparsity': 0.9268754454166954, 'steps_to_train': 41, 'weight_decay': 0.16001671822643088}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7448104956020483, 'info': {'data05': 0.7448104956020483, 'config': "{'batch_size': 16, 'hidden_dim': 948, 'last_n_outputs': 49, 'leak_rate': 0.8864974873284095, 'lr': 0.00364887338462012, 'optimizer': 'SGD', 'sparsity': 0.9268754454166954, 'steps_to_train': 41, 'weight_decay': 0.16001671822643088}"}}
exception: None

05:03:09 job_callback for (4, 0, 14) started
05:03:09 job_callback for (4, 0, 14) got condition
05:03:09 DISPATCHER: Trying to submit another job.
05:03:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:03:09 HBMASTER: Trying to run another job!
05:03:09 job_callback for (4, 0, 14) finished
05:03:09 HBMASTER: schedule new run for iteration 4
05:03:09 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
05:03:09 HBMASTER: submitting job (4, 0, 17) to dispatcher
05:03:09 DISPATCHER: trying to submit job (4, 0, 17)
05:03:09 DISPATCHER: trying to notify the job_runner thread.
05:03:09 HBMASTER: job (4, 0, 17) submitted to dispatcher
05:03:09 DISPATCHER: Trying to submit another job.
05:03:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:03:09 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.13101140314513094464
05:03:09 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
05:03:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:03:09 WORKER: start processing job (4, 0, 17)
05:03:09 WORKER: args: ()
05:03:09 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 911, 'last_n_outputs': 46, 'leak_rate': 0.8777232065833415, 'lr': 0.006451648321074381, 'optimizer': 'SGD', 'sparsity': 0.9205273715817329, 'steps_to_train': 91, 'weight_decay': 0.023665566364242357}, 'budget': 400.0, 'working_directory': '.'}
05:03:25 DISPATCHER: Starting worker discovery
05:03:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:03:25 DISPATCHER: Finished worker discovery
05:04:25 DISPATCHER: Starting worker discovery
05:04:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:04:25 DISPATCHER: Finished worker discovery
05:05:25 DISPATCHER: Starting worker discovery
05:05:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:05:25 DISPATCHER: Finished worker discovery
05:06:25 DISPATCHER: Starting worker discovery
05:06:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:06:25 DISPATCHER: Finished worker discovery
05:07:25 DISPATCHER: Starting worker discovery
05:07:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:07:25 DISPATCHER: Finished worker discovery
05:08:25 DISPATCHER: Starting worker discovery
05:08:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:08:25 DISPATCHER: Finished worker discovery
05:09:25 DISPATCHER: Starting worker discovery
05:09:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:09:25 DISPATCHER: Finished worker discovery
05:10:09 WORKER: done with job (4, 0, 17), trying to register it.
05:10:09 WORKER: registered result for job (4, 0, 17) with dispatcher
05:10:09 DISPATCHER: job (4, 0, 17) finished
05:10:09 DISPATCHER: register_result: lock acquired
05:10:09 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
05:10:09 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 911, 'last_n_outputs': 46, 'leak_rate': 0.8777232065833415, 'lr': 0.006451648321074381, 'optimizer': 'SGD', 'sparsity': 0.9205273715817329, 'steps_to_train': 91, 'weight_decay': 0.023665566364242357}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7467974676165814, 'info': {'data05': 0.7467974676165814, 'config': "{'batch_size': 64, 'hidden_dim': 911, 'last_n_outputs': 46, 'leak_rate': 0.8777232065833415, 'lr': 0.006451648321074381, 'optimizer': 'SGD', 'sparsity': 0.9205273715817329, 'steps_to_train': 91, 'weight_decay': 0.023665566364242357}"}}
exception: None

05:10:09 job_callback for (4, 0, 17) started
05:10:09 job_callback for (4, 0, 17) got condition
05:10:09 DISPATCHER: Trying to submit another job.
05:10:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:10:09 HBMASTER: Trying to run another job!
05:10:09 job_callback for (4, 0, 17) finished
05:10:09 ITERATION: Advancing config (4, 0, 5) to next budget 1200.000000
05:10:09 HBMASTER: schedule new run for iteration 4
05:10:09 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
05:10:09 HBMASTER: submitting job (4, 0, 5) to dispatcher
05:10:09 DISPATCHER: trying to submit job (4, 0, 5)
05:10:09 DISPATCHER: trying to notify the job_runner thread.
05:10:09 HBMASTER: job (4, 0, 5) submitted to dispatcher
05:10:09 DISPATCHER: Trying to submit another job.
05:10:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:10:09 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
05:10:09 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
05:10:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:10:09 WORKER: start processing job (4, 0, 5)
05:10:09 WORKER: args: ()
05:10:09 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 897, 'last_n_outputs': 49, 'leak_rate': 0.7602216627055048, 'lr': 0.004759897530817441, 'optimizer': 'SGD', 'sparsity': 0.9482350307821125, 'steps_to_train': 28, 'weight_decay': 0.08023897763534726}, 'budget': 1200.0, 'working_directory': '.'}
05:10:25 DISPATCHER: Starting worker discovery
05:10:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:10:25 DISPATCHER: Finished worker discovery
05:11:25 DISPATCHER: Starting worker discovery
05:11:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:11:25 DISPATCHER: Finished worker discovery
05:12:25 DISPATCHER: Starting worker discovery
05:12:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:12:25 DISPATCHER: Finished worker discovery
05:13:25 DISPATCHER: Starting worker discovery
05:13:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:13:25 DISPATCHER: Finished worker discovery
05:14:25 DISPATCHER: Starting worker discovery
05:14:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:14:25 DISPATCHER: Finished worker discovery
05:15:25 DISPATCHER: Starting worker discovery
05:15:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:15:25 DISPATCHER: Finished worker discovery
05:16:25 DISPATCHER: Starting worker discovery
05:16:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:16:25 DISPATCHER: Finished worker discovery
05:17:25 DISPATCHER: Starting worker discovery
05:17:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:17:25 DISPATCHER: Finished worker discovery
05:18:25 DISPATCHER: Starting worker discovery
05:18:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:18:25 DISPATCHER: Finished worker discovery
05:19:25 DISPATCHER: Starting worker discovery
05:19:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:19:25 DISPATCHER: Finished worker discovery
05:20:25 DISPATCHER: Starting worker discovery
05:20:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:20:25 DISPATCHER: Finished worker discovery
05:21:25 DISPATCHER: Starting worker discovery
05:21:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:21:25 DISPATCHER: Finished worker discovery
05:22:25 DISPATCHER: Starting worker discovery
05:22:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:22:25 DISPATCHER: Finished worker discovery
05:23:25 DISPATCHER: Starting worker discovery
05:23:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:23:25 DISPATCHER: Finished worker discovery
05:24:25 DISPATCHER: Starting worker discovery
05:24:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:24:25 DISPATCHER: Finished worker discovery
05:25:25 DISPATCHER: Starting worker discovery
05:25:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:25:25 DISPATCHER: Finished worker discovery
05:26:25 DISPATCHER: Starting worker discovery
05:26:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:26:25 DISPATCHER: Finished worker discovery
05:27:25 DISPATCHER: Starting worker discovery
05:27:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:27:25 DISPATCHER: Finished worker discovery
05:28:25 DISPATCHER: Starting worker discovery
05:28:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:28:25 DISPATCHER: Finished worker discovery
05:29:25 DISPATCHER: Starting worker discovery
05:29:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:29:25 DISPATCHER: Finished worker discovery
05:30:25 DISPATCHER: Starting worker discovery
05:30:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:30:25 DISPATCHER: Finished worker discovery
05:30:35 WORKER: done with job (4, 0, 5), trying to register it.
05:30:35 WORKER: registered result for job (4, 0, 5) with dispatcher
05:30:35 DISPATCHER: job (4, 0, 5) finished
05:30:35 DISPATCHER: register_result: lock acquired
05:30:35 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
05:30:35 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 897, 'last_n_outputs': 49, 'leak_rate': 0.7602216627055048, 'lr': 0.004759897530817441, 'optimizer': 'SGD', 'sparsity': 0.9482350307821125, 'steps_to_train': 28, 'weight_decay': 0.08023897763534726}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.7691735825802783, 'info': {'data05': 0.7691735825802783, 'config': "{'batch_size': 16, 'hidden_dim': 897, 'last_n_outputs': 49, 'leak_rate': 0.7602216627055048, 'lr': 0.004759897530817441, 'optimizer': 'SGD', 'sparsity': 0.9482350307821125, 'steps_to_train': 28, 'weight_decay': 0.08023897763534726}"}}
exception: None

05:30:35 job_callback for (4, 0, 5) started
05:30:35 job_callback for (4, 0, 5) got condition
05:30:35 DISPATCHER: Trying to submit another job.
05:30:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:30:35 Only 9 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
05:30:35 HBMASTER: Trying to run another job!
05:30:35 job_callback for (4, 0, 5) finished
05:30:35 start sampling a new configuration.
05:30:35 done sampling a new configuration.
05:30:35 HBMASTER: schedule new run for iteration 5
05:30:35 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
05:30:35 HBMASTER: submitting job (5, 0, 0) to dispatcher
05:30:35 DISPATCHER: trying to submit job (5, 0, 0)
05:30:35 DISPATCHER: trying to notify the job_runner thread.
05:30:35 HBMASTER: job (5, 0, 0) submitted to dispatcher
05:30:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:30:35 DISPATCHER: Trying to submit another job.
05:30:35 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
05:30:35 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
05:30:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:30:35 WORKER: start processing job (5, 0, 0)
05:30:35 WORKER: args: ()
05:30:35 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 363, 'last_n_outputs': 26, 'leak_rate': 0.9101567607688811, 'lr': 0.009518022444638294, 'optimizer': 'SGD', 'sparsity': 0.7917364229240641, 'steps_to_train': 96, 'weight_decay': 0.03537873123798815}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:31:25 DISPATCHER: Starting worker discovery
05:31:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:31:25 DISPATCHER: Finished worker discovery
05:32:25 DISPATCHER: Starting worker discovery
05:32:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:32:25 DISPATCHER: Finished worker discovery
05:33:05 WORKER: done with job (5, 0, 0), trying to register it.
05:33:05 WORKER: registered result for job (5, 0, 0) with dispatcher
05:33:05 DISPATCHER: job (5, 0, 0) finished
05:33:05 DISPATCHER: register_result: lock acquired
05:33:05 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
05:33:05 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 363, 'last_n_outputs': 26, 'leak_rate': 0.9101567607688811, 'lr': 0.009518022444638294, 'optimizer': 'SGD', 'sparsity': 0.7917364229240641, 'steps_to_train': 96, 'weight_decay': 0.03537873123798815}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6256433598318608, 'info': {'data05': 0.6256433598318608, 'config': "{'batch_size': 16, 'hidden_dim': 363, 'last_n_outputs': 26, 'leak_rate': 0.9101567607688811, 'lr': 0.009518022444638294, 'optimizer': 'SGD', 'sparsity': 0.7917364229240641, 'steps_to_train': 96, 'weight_decay': 0.03537873123798815}"}}
exception: None

05:33:05 job_callback for (5, 0, 0) started
05:33:05 job_callback for (5, 0, 0) got condition
05:33:05 DISPATCHER: Trying to submit another job.
05:33:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:33:05 done building a new model for budget 133.333333 based on 10/23 split
Best loss for this budget:-0.769956





05:33:05 HBMASTER: Trying to run another job!
05:33:05 job_callback for (5, 0, 0) finished
05:33:05 start sampling a new configuration.
05:33:05 best_vector: [2, 0.8746330780875795, 0.8998402099684645, 0.2966987009861827, 0.6696198441902288, 1, 0.7740772163289571, 0.6334242405138316, 0.7328911580814074], 0.0025243882431238806, 2.453246543619704, 0.006192946732197877
05:33:05 done sampling a new configuration.
05:33:05 HBMASTER: schedule new run for iteration 5
05:33:05 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
05:33:05 HBMASTER: submitting job (5, 0, 1) to dispatcher
05:33:05 DISPATCHER: trying to submit job (5, 0, 1)
05:33:05 DISPATCHER: trying to notify the job_runner thread.
05:33:05 HBMASTER: job (5, 0, 1) submitted to dispatcher
05:33:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:33:05 DISPATCHER: Trying to submit another job.
05:33:05 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
05:33:05 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
05:33:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:33:05 WORKER: start processing job (5, 0, 1)
05:33:05 WORKER: args: ()
05:33:05 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 900, 'last_n_outputs': 46, 'leak_rate': 0.8241746752465456, 'lr': 0.021839348992808184, 'optimizer': 'SGD', 'sparsity': 0.9357785319189497, 'steps_to_train': 67, 'weight_decay': 0.08984902738182744}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:33:25 DISPATCHER: Starting worker discovery
05:33:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:33:25 DISPATCHER: Finished worker discovery
05:34:25 DISPATCHER: Starting worker discovery
05:34:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:34:25 DISPATCHER: Finished worker discovery
05:35:25 DISPATCHER: Starting worker discovery
05:35:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:35:25 DISPATCHER: Finished worker discovery
05:35:32 WORKER: done with job (5, 0, 1), trying to register it.
05:35:32 WORKER: registered result for job (5, 0, 1) with dispatcher
05:35:32 DISPATCHER: job (5, 0, 1) finished
05:35:32 DISPATCHER: register_result: lock acquired
05:35:32 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
05:35:32 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 900, 'last_n_outputs': 46, 'leak_rate': 0.8241746752465456, 'lr': 0.021839348992808184, 'optimizer': 'SGD', 'sparsity': 0.9357785319189497, 'steps_to_train': 67, 'weight_decay': 0.08984902738182744}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7631104473488122, 'info': {'data05': 0.7631104473488122, 'config': "{'batch_size': 64, 'hidden_dim': 900, 'last_n_outputs': 46, 'leak_rate': 0.8241746752465456, 'lr': 0.021839348992808184, 'optimizer': 'SGD', 'sparsity': 0.9357785319189497, 'steps_to_train': 67, 'weight_decay': 0.08984902738182744}"}}
exception: None

05:35:32 job_callback for (5, 0, 1) started
05:35:32 job_callback for (5, 0, 1) got condition
05:35:32 DISPATCHER: Trying to submit another job.
05:35:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:35:32 done building a new model for budget 133.333333 based on 10/24 split
Best loss for this budget:-0.769956





05:35:32 HBMASTER: Trying to run another job!
05:35:32 job_callback for (5, 0, 1) finished
05:35:32 start sampling a new configuration.
05:35:32 best_vector: [0, 0.908564011618693, 0.8902672508511453, 0.08456150205243015, 0.6708509873447319, 1, 0.6768209359235077, 0.6793502424729274, 0.7751752805198737], 0.00027011882434810434, 21.43966241959337, 0.005791256407200795
05:35:32 done sampling a new configuration.
05:35:32 HBMASTER: schedule new run for iteration 5
05:35:32 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
05:35:32 HBMASTER: submitting job (5, 0, 2) to dispatcher
05:35:32 DISPATCHER: trying to submit job (5, 0, 2)
05:35:32 DISPATCHER: trying to notify the job_runner thread.
05:35:32 HBMASTER: job (5, 0, 2) submitted to dispatcher
05:35:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:35:32 DISPATCHER: Trying to submit another job.
05:35:32 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
05:35:32 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
05:35:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:35:32 WORKER: start processing job (5, 0, 2)
05:35:32 WORKER: args: ()
05:35:32 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 927, 'last_n_outputs': 46, 'leak_rate': 0.7711403755131075, 'lr': 0.021963521557776432, 'optimizer': 'SGD', 'sparsity': 0.9124370246216418, 'steps_to_train': 71, 'weight_decay': 0.10198264976869893}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:36:25 DISPATCHER: Starting worker discovery
05:36:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:36:25 DISPATCHER: Finished worker discovery
05:37:25 DISPATCHER: Starting worker discovery
05:37:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:37:25 DISPATCHER: Finished worker discovery
05:38:03 WORKER: done with job (5, 0, 2), trying to register it.
05:38:03 WORKER: registered result for job (5, 0, 2) with dispatcher
05:38:03 DISPATCHER: job (5, 0, 2) finished
05:38:03 DISPATCHER: register_result: lock acquired
05:38:03 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
05:38:03 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 927, 'last_n_outputs': 46, 'leak_rate': 0.7711403755131075, 'lr': 0.021963521557776432, 'optimizer': 'SGD', 'sparsity': 0.9124370246216418, 'steps_to_train': 71, 'weight_decay': 0.10198264976869893}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6936663316647532, 'info': {'data05': 0.6936663316647532, 'config': "{'batch_size': 16, 'hidden_dim': 927, 'last_n_outputs': 46, 'leak_rate': 0.7711403755131075, 'lr': 0.021963521557776432, 'optimizer': 'SGD', 'sparsity': 0.9124370246216418, 'steps_to_train': 71, 'weight_decay': 0.10198264976869893}"}}
exception: None

05:38:03 job_callback for (5, 0, 2) started
05:38:03 job_callback for (5, 0, 2) got condition
05:38:03 DISPATCHER: Trying to submit another job.
05:38:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:38:03 done building a new model for budget 133.333333 based on 10/25 split
Best loss for this budget:-0.769956





05:38:03 HBMASTER: Trying to run another job!
05:38:03 job_callback for (5, 0, 2) finished
05:38:03 start sampling a new configuration.
05:38:03 done sampling a new configuration.
05:38:03 HBMASTER: schedule new run for iteration 5
05:38:03 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
05:38:03 HBMASTER: submitting job (5, 0, 3) to dispatcher
05:38:03 DISPATCHER: trying to submit job (5, 0, 3)
05:38:03 DISPATCHER: trying to notify the job_runner thread.
05:38:03 HBMASTER: job (5, 0, 3) submitted to dispatcher
05:38:03 DISPATCHER: Trying to submit another job.
05:38:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:38:03 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
05:38:03 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
05:38:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:38:03 WORKER: start processing job (5, 0, 3)
05:38:03 WORKER: args: ()
05:38:03 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 917, 'last_n_outputs': 49, 'leak_rate': 0.9664697908948476, 'lr': 0.0020363731381277147, 'optimizer': 'SGD', 'sparsity': 0.8236822484781423, 'steps_to_train': 25, 'weight_decay': 0.010615997963914074}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:38:25 DISPATCHER: Starting worker discovery
05:38:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:38:25 DISPATCHER: Finished worker discovery
05:39:25 DISPATCHER: Starting worker discovery
05:39:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:39:25 DISPATCHER: Finished worker discovery
05:40:25 DISPATCHER: Starting worker discovery
05:40:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:40:25 DISPATCHER: Finished worker discovery
05:40:29 WORKER: done with job (5, 0, 3), trying to register it.
05:40:29 WORKER: registered result for job (5, 0, 3) with dispatcher
05:40:29 DISPATCHER: job (5, 0, 3) finished
05:40:29 DISPATCHER: register_result: lock acquired
05:40:29 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
05:40:29 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 917, 'last_n_outputs': 49, 'leak_rate': 0.9664697908948476, 'lr': 0.0020363731381277147, 'optimizer': 'SGD', 'sparsity': 0.8236822484781423, 'steps_to_train': 25, 'weight_decay': 0.010615997963914074}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7254273439336109, 'info': {'data05': 0.7254273439336109, 'config': "{'batch_size': 16, 'hidden_dim': 917, 'last_n_outputs': 49, 'leak_rate': 0.9664697908948476, 'lr': 0.0020363731381277147, 'optimizer': 'SGD', 'sparsity': 0.8236822484781423, 'steps_to_train': 25, 'weight_decay': 0.010615997963914074}"}}
exception: None

05:40:29 job_callback for (5, 0, 3) started
05:40:29 DISPATCHER: Trying to submit another job.
05:40:29 job_callback for (5, 0, 3) got condition
05:40:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:40:29 done building a new model for budget 133.333333 based on 10/26 split
Best loss for this budget:-0.769956





05:40:29 HBMASTER: Trying to run another job!
05:40:29 job_callback for (5, 0, 3) finished
05:40:29 start sampling a new configuration.
05:40:29 best_vector: [2, 0.8664883351341187, 0.9150800010892782, 0.3927697298747379, 0.7623987436648181, 1, 0.17327811190281472, 0.7926622972309402, 0.2885692162603758], 0.004551574161686523, 3.0751790553541354, 0.01399690553090945
05:40:29 done sampling a new configuration.
05:40:29 HBMASTER: schedule new run for iteration 5
05:40:29 HBMASTER: trying submitting job (5, 0, 4) to dispatcher
05:40:29 HBMASTER: submitting job (5, 0, 4) to dispatcher
05:40:29 DISPATCHER: trying to submit job (5, 0, 4)
05:40:29 DISPATCHER: trying to notify the job_runner thread.
05:40:29 HBMASTER: job (5, 0, 4) submitted to dispatcher
05:40:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:40:29 DISPATCHER: Trying to submit another job.
05:40:29 DISPATCHER: starting job (5, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464
05:40:29 DISPATCHER: job (5, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
05:40:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:40:29 WORKER: start processing job (5, 0, 4)
05:40:29 WORKER: args: ()
05:40:29 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 894, 'last_n_outputs': 47, 'leak_rate': 0.8481924324686845, 'lr': 0.03348092802953821, 'optimizer': 'SGD', 'sparsity': 0.7915867468566755, 'steps_to_train': 82, 'weight_decay': 0.02373762180124746}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:41:25 DISPATCHER: Starting worker discovery
05:41:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:41:25 DISPATCHER: Finished worker discovery
05:42:25 DISPATCHER: Starting worker discovery
05:42:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:42:25 DISPATCHER: Finished worker discovery
05:42:58 WORKER: done with job (5, 0, 4), trying to register it.
05:42:58 WORKER: registered result for job (5, 0, 4) with dispatcher
05:42:58 DISPATCHER: job (5, 0, 4) finished
05:42:58 DISPATCHER: register_result: lock acquired
05:42:58 DISPATCHER: job (5, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
05:42:58 job_id: (5, 0, 4)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 894, 'last_n_outputs': 47, 'leak_rate': 0.8481924324686845, 'lr': 0.03348092802953821, 'optimizer': 'SGD', 'sparsity': 0.7915867468566755, 'steps_to_train': 82, 'weight_decay': 0.02373762180124746}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7411232960448686, 'info': {'data05': 0.7411232960448686, 'config': "{'batch_size': 64, 'hidden_dim': 894, 'last_n_outputs': 47, 'leak_rate': 0.8481924324686845, 'lr': 0.03348092802953821, 'optimizer': 'SGD', 'sparsity': 0.7915867468566755, 'steps_to_train': 82, 'weight_decay': 0.02373762180124746}"}}
exception: None

05:42:58 job_callback for (5, 0, 4) started
05:42:58 job_callback for (5, 0, 4) got condition
05:42:58 DISPATCHER: Trying to submit another job.
05:42:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:42:58 done building a new model for budget 133.333333 based on 10/27 split
Best loss for this budget:-0.769956





05:42:58 HBMASTER: Trying to run another job!
05:42:58 job_callback for (5, 0, 4) finished
05:42:58 start sampling a new configuration.
05:42:58 best_vector: [0, 0.8338193387917834, 0.8984458132498686, 0.059329511189530115, 0.7027562178689734, 1, 0.8235375793444453, 0.5636932522747897, 0.7087100076940143], 0.006528712153000858, 17.16939955394239, 0.1120940675275512
05:42:58 done sampling a new configuration.
05:42:58 HBMASTER: schedule new run for iteration 5
05:42:58 HBMASTER: trying submitting job (5, 0, 5) to dispatcher
05:42:58 HBMASTER: submitting job (5, 0, 5) to dispatcher
05:42:58 DISPATCHER: trying to submit job (5, 0, 5)
05:42:58 DISPATCHER: trying to notify the job_runner thread.
05:42:58 HBMASTER: job (5, 0, 5) submitted to dispatcher
05:42:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:42:58 DISPATCHER: Trying to submit another job.
05:42:58 DISPATCHER: starting job (5, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
05:42:58 DISPATCHER: job (5, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
05:42:58 WORKER: start processing job (5, 0, 5)
05:42:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:42:58 WORKER: args: ()
05:42:58 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 867, 'last_n_outputs': 46, 'leak_rate': 0.7648323777973826, 'lr': 0.025439726370765695, 'optimizer': 'SGD', 'sparsity': 0.9476490190426669, 'steps_to_train': 61, 'weight_decay': 0.08357049570698338}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:43:25 DISPATCHER: Starting worker discovery
05:43:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:43:25 DISPATCHER: Finished worker discovery
05:44:25 DISPATCHER: Starting worker discovery
05:44:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:44:25 DISPATCHER: Finished worker discovery
05:45:25 WORKER: done with job (5, 0, 5), trying to register it.
05:45:25 WORKER: registered result for job (5, 0, 5) with dispatcher
05:45:25 DISPATCHER: job (5, 0, 5) finished
05:45:25 DISPATCHER: register_result: lock acquired
05:45:25 DISPATCHER: job (5, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
05:45:25 job_id: (5, 0, 5)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 867, 'last_n_outputs': 46, 'leak_rate': 0.7648323777973826, 'lr': 0.025439726370765695, 'optimizer': 'SGD', 'sparsity': 0.9476490190426669, 'steps_to_train': 61, 'weight_decay': 0.08357049570698338}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7275571190181749, 'info': {'data05': 0.7275571190181749, 'config': "{'batch_size': 16, 'hidden_dim': 867, 'last_n_outputs': 46, 'leak_rate': 0.7648323777973826, 'lr': 0.025439726370765695, 'optimizer': 'SGD', 'sparsity': 0.9476490190426669, 'steps_to_train': 61, 'weight_decay': 0.08357049570698338}"}}
exception: None

05:45:25 job_callback for (5, 0, 5) started
05:45:25 DISPATCHER: Trying to submit another job.
05:45:25 job_callback for (5, 0, 5) got condition
05:45:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:45:25 done building a new model for budget 133.333333 based on 10/28 split
Best loss for this budget:-0.769956





05:45:25 HBMASTER: Trying to run another job!
05:45:25 job_callback for (5, 0, 5) finished
05:45:25 start sampling a new configuration.
05:45:25 done sampling a new configuration.
05:45:25 DISPATCHER: Starting worker discovery
05:45:25 HBMASTER: schedule new run for iteration 5
05:45:25 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
05:45:25 HBMASTER: submitting job (5, 0, 6) to dispatcher
05:45:25 DISPATCHER: trying to submit job (5, 0, 6)
05:45:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:45:25 DISPATCHER: Finished worker discovery
05:45:25 DISPATCHER: trying to notify the job_runner thread.
05:45:25 HBMASTER: job (5, 0, 6) submitted to dispatcher
05:45:25 DISPATCHER: Trying to submit another job.
05:45:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:45:25 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464
05:45:25 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
05:45:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:45:25 WORKER: start processing job (5, 0, 6)
05:45:25 WORKER: args: ()
05:45:25 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 552, 'last_n_outputs': 10, 'leak_rate': 0.857028736728898, 'lr': 0.0016513456282737616, 'optimizer': 'SGD', 'sparsity': 0.872931602681936, 'steps_to_train': 94, 'weight_decay': 0.011541093587214871}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:46:25 DISPATCHER: Starting worker discovery
05:46:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:46:25 DISPATCHER: Finished worker discovery
05:47:25 DISPATCHER: Starting worker discovery
05:47:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:47:25 DISPATCHER: Finished worker discovery
05:47:53 WORKER: done with job (5, 0, 6), trying to register it.
05:47:53 WORKER: registered result for job (5, 0, 6) with dispatcher
05:47:53 DISPATCHER: job (5, 0, 6) finished
05:47:53 DISPATCHER: register_result: lock acquired
05:47:53 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
05:47:53 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 552, 'last_n_outputs': 10, 'leak_rate': 0.857028736728898, 'lr': 0.0016513456282737616, 'optimizer': 'SGD', 'sparsity': 0.872931602681936, 'steps_to_train': 94, 'weight_decay': 0.011541093587214871}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.437153724226712, 'info': {'data05': 0.437153724226712, 'config': "{'batch_size': 64, 'hidden_dim': 552, 'last_n_outputs': 10, 'leak_rate': 0.857028736728898, 'lr': 0.0016513456282737616, 'optimizer': 'SGD', 'sparsity': 0.872931602681936, 'steps_to_train': 94, 'weight_decay': 0.011541093587214871}"}}
exception: None

05:47:53 job_callback for (5, 0, 6) started
05:47:53 DISPATCHER: Trying to submit another job.
05:47:53 job_callback for (5, 0, 6) got condition
05:47:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:47:53 done building a new model for budget 133.333333 based on 10/28 split
Best loss for this budget:-0.769956





05:47:53 HBMASTER: Trying to run another job!
05:47:53 job_callback for (5, 0, 6) finished
05:47:53 start sampling a new configuration.
05:47:53 done sampling a new configuration.
05:47:53 HBMASTER: schedule new run for iteration 5
05:47:53 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
05:47:53 HBMASTER: submitting job (5, 0, 7) to dispatcher
05:47:53 DISPATCHER: trying to submit job (5, 0, 7)
05:47:53 DISPATCHER: trying to notify the job_runner thread.
05:47:53 HBMASTER: job (5, 0, 7) submitted to dispatcher
05:47:53 DISPATCHER: Trying to submit another job.
05:47:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:47:53 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464
05:47:53 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
05:47:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:47:53 WORKER: start processing job (5, 0, 7)
05:47:53 WORKER: args: ()
05:47:53 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 381, 'last_n_outputs': 39, 'leak_rate': 0.8491092610915492, 'lr': 0.0023679003578224696, 'optimizer': 'Adam', 'sparsity': 0.8354304834948225, 'steps_to_train': 77, 'weight_decay': 0.01724738257501471}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:48:25 DISPATCHER: Starting worker discovery
05:48:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:48:25 DISPATCHER: Finished worker discovery
05:49:25 DISPATCHER: Starting worker discovery
05:49:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:49:25 DISPATCHER: Finished worker discovery
05:50:22 WORKER: done with job (5, 0, 7), trying to register it.
05:50:22 WORKER: registered result for job (5, 0, 7) with dispatcher
05:50:22 DISPATCHER: job (5, 0, 7) finished
05:50:22 DISPATCHER: register_result: lock acquired
05:50:22 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
05:50:22 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 381, 'last_n_outputs': 39, 'leak_rate': 0.8491092610915492, 'lr': 0.0023679003578224696, 'optimizer': 'Adam', 'sparsity': 0.8354304834948225, 'steps_to_train': 77, 'weight_decay': 0.01724738257501471}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.685552916776884, 'info': {'data05': 0.685552916776884, 'config': "{'batch_size': 64, 'hidden_dim': 381, 'last_n_outputs': 39, 'leak_rate': 0.8491092610915492, 'lr': 0.0023679003578224696, 'optimizer': 'Adam', 'sparsity': 0.8354304834948225, 'steps_to_train': 77, 'weight_decay': 0.01724738257501471}"}}
exception: None

05:50:22 job_callback for (5, 0, 7) started
05:50:22 DISPATCHER: Trying to submit another job.
05:50:22 job_callback for (5, 0, 7) got condition
05:50:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:50:22 done building a new model for budget 133.333333 based on 10/29 split
Best loss for this budget:-0.769956





05:50:22 HBMASTER: Trying to run another job!
05:50:22 job_callback for (5, 0, 7) finished
05:50:22 start sampling a new configuration.
05:50:22 done sampling a new configuration.
05:50:22 HBMASTER: schedule new run for iteration 5
05:50:22 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
05:50:22 HBMASTER: submitting job (5, 0, 8) to dispatcher
05:50:22 DISPATCHER: trying to submit job (5, 0, 8)
05:50:22 DISPATCHER: trying to notify the job_runner thread.
05:50:22 HBMASTER: job (5, 0, 8) submitted to dispatcher
05:50:22 DISPATCHER: Trying to submit another job.
05:50:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:50:22 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464
05:50:22 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
05:50:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:50:22 WORKER: start processing job (5, 0, 8)
05:50:22 WORKER: args: ()
05:50:22 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 388, 'last_n_outputs': 40, 'leak_rate': 0.7867753581338552, 'lr': 0.0016093676515360306, 'optimizer': 'Adam', 'sparsity': 0.9042359478612297, 'steps_to_train': 40, 'weight_decay': 0.05527435503719037}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:50:25 DISPATCHER: Starting worker discovery
05:50:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:50:25 DISPATCHER: Finished worker discovery
05:51:25 DISPATCHER: Starting worker discovery
05:51:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:51:25 DISPATCHER: Finished worker discovery
05:52:25 DISPATCHER: Starting worker discovery
05:52:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:52:25 DISPATCHER: Finished worker discovery
05:52:51 WORKER: done with job (5, 0, 8), trying to register it.
05:52:51 WORKER: registered result for job (5, 0, 8) with dispatcher
05:52:51 DISPATCHER: job (5, 0, 8) finished
05:52:51 DISPATCHER: register_result: lock acquired
05:52:51 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
05:52:51 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 388, 'last_n_outputs': 40, 'leak_rate': 0.7867753581338552, 'lr': 0.0016093676515360306, 'optimizer': 'Adam', 'sparsity': 0.9042359478612297, 'steps_to_train': 40, 'weight_decay': 0.05527435503719037}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6596811851204356, 'info': {'data05': 0.6596811851204356, 'config': "{'batch_size': 128, 'hidden_dim': 388, 'last_n_outputs': 40, 'leak_rate': 0.7867753581338552, 'lr': 0.0016093676515360306, 'optimizer': 'Adam', 'sparsity': 0.9042359478612297, 'steps_to_train': 40, 'weight_decay': 0.05527435503719037}"}}
exception: None

05:52:51 job_callback for (5, 0, 8) started
05:52:51 DISPATCHER: Trying to submit another job.
05:52:51 job_callback for (5, 0, 8) got condition
05:52:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:52:51 done building a new model for budget 133.333333 based on 10/30 split
Best loss for this budget:-0.769956





05:52:51 HBMASTER: Trying to run another job!
05:52:51 job_callback for (5, 0, 8) finished
05:52:51 ITERATION: Advancing config (5, 0, 1) to next budget 400.000000
05:52:51 ITERATION: Advancing config (5, 0, 4) to next budget 400.000000
05:52:51 ITERATION: Advancing config (5, 0, 5) to next budget 400.000000
05:52:51 HBMASTER: schedule new run for iteration 5
05:52:51 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
05:52:51 HBMASTER: submitting job (5, 0, 1) to dispatcher
05:52:51 DISPATCHER: trying to submit job (5, 0, 1)
05:52:51 DISPATCHER: trying to notify the job_runner thread.
05:52:51 HBMASTER: job (5, 0, 1) submitted to dispatcher
05:52:51 DISPATCHER: Trying to submit another job.
05:52:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:52:51 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
05:52:51 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
05:52:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:52:51 WORKER: start processing job (5, 0, 1)
05:52:51 WORKER: args: ()
05:52:51 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 900, 'last_n_outputs': 46, 'leak_rate': 0.8241746752465456, 'lr': 0.021839348992808184, 'optimizer': 'SGD', 'sparsity': 0.9357785319189497, 'steps_to_train': 67, 'weight_decay': 0.08984902738182744}, 'budget': 400.0, 'working_directory': '.'}
05:53:25 DISPATCHER: Starting worker discovery
05:53:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:53:25 DISPATCHER: Finished worker discovery
05:54:25 DISPATCHER: Starting worker discovery
05:54:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:54:25 DISPATCHER: Finished worker discovery
05:55:25 DISPATCHER: Starting worker discovery
05:55:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:55:25 DISPATCHER: Finished worker discovery
05:56:25 DISPATCHER: Starting worker discovery
05:56:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:56:25 DISPATCHER: Finished worker discovery
05:57:25 DISPATCHER: Starting worker discovery
05:57:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:57:25 DISPATCHER: Finished worker discovery
05:58:25 DISPATCHER: Starting worker discovery
05:58:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:58:25 DISPATCHER: Finished worker discovery
05:59:25 DISPATCHER: Starting worker discovery
05:59:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:59:25 DISPATCHER: Finished worker discovery
05:59:50 WORKER: done with job (5, 0, 1), trying to register it.
05:59:50 WORKER: registered result for job (5, 0, 1) with dispatcher
05:59:50 DISPATCHER: job (5, 0, 1) finished
05:59:50 DISPATCHER: register_result: lock acquired
05:59:50 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
05:59:50 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 900, 'last_n_outputs': 46, 'leak_rate': 0.8241746752465456, 'lr': 0.021839348992808184, 'optimizer': 'SGD', 'sparsity': 0.9357785319189497, 'steps_to_train': 67, 'weight_decay': 0.08984902738182744}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6841684351112824, 'info': {'data05': 0.6841684351112824, 'config': "{'batch_size': 64, 'hidden_dim': 900, 'last_n_outputs': 46, 'leak_rate': 0.8241746752465456, 'lr': 0.021839348992808184, 'optimizer': 'SGD', 'sparsity': 0.9357785319189497, 'steps_to_train': 67, 'weight_decay': 0.08984902738182744}"}}
exception: None

05:59:50 job_callback for (5, 0, 1) started
05:59:50 DISPATCHER: Trying to submit another job.
05:59:50 job_callback for (5, 0, 1) got condition
05:59:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:59:50 HBMASTER: Trying to run another job!
05:59:50 job_callback for (5, 0, 1) finished
05:59:50 HBMASTER: schedule new run for iteration 5
05:59:50 HBMASTER: trying submitting job (5, 0, 4) to dispatcher
05:59:50 HBMASTER: submitting job (5, 0, 4) to dispatcher
05:59:50 DISPATCHER: trying to submit job (5, 0, 4)
05:59:50 DISPATCHER: trying to notify the job_runner thread.
05:59:50 HBMASTER: job (5, 0, 4) submitted to dispatcher
05:59:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:59:50 DISPATCHER: Trying to submit another job.
05:59:50 DISPATCHER: starting job (5, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464
05:59:50 DISPATCHER: job (5, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
05:59:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:59:50 WORKER: start processing job (5, 0, 4)
05:59:50 WORKER: args: ()
05:59:50 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 894, 'last_n_outputs': 47, 'leak_rate': 0.8481924324686845, 'lr': 0.03348092802953821, 'optimizer': 'SGD', 'sparsity': 0.7915867468566755, 'steps_to_train': 82, 'weight_decay': 0.02373762180124746}, 'budget': 400.0, 'working_directory': '.'}
06:00:25 DISPATCHER: Starting worker discovery
06:00:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:00:25 DISPATCHER: Finished worker discovery
06:01:25 DISPATCHER: Starting worker discovery
06:01:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:01:25 DISPATCHER: Finished worker discovery
06:02:25 DISPATCHER: Starting worker discovery
06:02:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:02:25 DISPATCHER: Finished worker discovery
06:03:25 DISPATCHER: Starting worker discovery
06:03:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:03:25 DISPATCHER: Finished worker discovery
06:04:25 DISPATCHER: Starting worker discovery
06:04:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:04:25 DISPATCHER: Finished worker discovery
06:05:25 DISPATCHER: Starting worker discovery
06:05:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:05:25 DISPATCHER: Finished worker discovery
06:06:25 DISPATCHER: Starting worker discovery
06:06:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:06:25 DISPATCHER: Finished worker discovery
06:06:45 WORKER: done with job (5, 0, 4), trying to register it.
06:06:45 WORKER: registered result for job (5, 0, 4) with dispatcher
06:06:45 DISPATCHER: job (5, 0, 4) finished
06:06:45 DISPATCHER: register_result: lock acquired
06:06:45 DISPATCHER: job (5, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
06:06:45 job_id: (5, 0, 4)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 894, 'last_n_outputs': 47, 'leak_rate': 0.8481924324686845, 'lr': 0.03348092802953821, 'optimizer': 'SGD', 'sparsity': 0.7915867468566755, 'steps_to_train': 82, 'weight_decay': 0.02373762180124746}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7220084268557343, 'info': {'data05': 0.7220084268557343, 'config': "{'batch_size': 64, 'hidden_dim': 894, 'last_n_outputs': 47, 'leak_rate': 0.8481924324686845, 'lr': 0.03348092802953821, 'optimizer': 'SGD', 'sparsity': 0.7915867468566755, 'steps_to_train': 82, 'weight_decay': 0.02373762180124746}"}}
exception: None

06:06:45 job_callback for (5, 0, 4) started
06:06:45 DISPATCHER: Trying to submit another job.
06:06:45 job_callback for (5, 0, 4) got condition
06:06:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:06:45 HBMASTER: Trying to run another job!
06:06:45 job_callback for (5, 0, 4) finished
06:06:45 HBMASTER: schedule new run for iteration 5
06:06:45 HBMASTER: trying submitting job (5, 0, 5) to dispatcher
06:06:45 HBMASTER: submitting job (5, 0, 5) to dispatcher
06:06:45 DISPATCHER: trying to submit job (5, 0, 5)
06:06:45 DISPATCHER: trying to notify the job_runner thread.
06:06:45 HBMASTER: job (5, 0, 5) submitted to dispatcher
06:06:45 DISPATCHER: Trying to submit another job.
06:06:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:06:45 DISPATCHER: starting job (5, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:06:45 DISPATCHER: job (5, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:06:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:06:45 WORKER: start processing job (5, 0, 5)
06:06:45 WORKER: args: ()
06:06:45 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 867, 'last_n_outputs': 46, 'leak_rate': 0.7648323777973826, 'lr': 0.025439726370765695, 'optimizer': 'SGD', 'sparsity': 0.9476490190426669, 'steps_to_train': 61, 'weight_decay': 0.08357049570698338}, 'budget': 400.0, 'working_directory': '.'}
06:07:25 DISPATCHER: Starting worker discovery
06:07:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:07:25 DISPATCHER: Finished worker discovery
06:08:25 DISPATCHER: Starting worker discovery
06:08:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:08:25 DISPATCHER: Finished worker discovery
06:09:25 DISPATCHER: Starting worker discovery
06:09:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:09:25 DISPATCHER: Finished worker discovery
06:10:25 DISPATCHER: Starting worker discovery
06:10:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:10:25 DISPATCHER: Finished worker discovery
06:11:25 DISPATCHER: Starting worker discovery
06:11:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:11:25 DISPATCHER: Finished worker discovery
06:12:25 DISPATCHER: Starting worker discovery
06:12:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:12:25 DISPATCHER: Finished worker discovery
06:13:25 DISPATCHER: Starting worker discovery
06:13:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:13:25 DISPATCHER: Finished worker discovery
06:13:42 WORKER: done with job (5, 0, 5), trying to register it.
06:13:42 WORKER: registered result for job (5, 0, 5) with dispatcher
06:13:42 DISPATCHER: job (5, 0, 5) finished
06:13:42 DISPATCHER: register_result: lock acquired
06:13:42 DISPATCHER: job (5, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
06:13:42 job_id: (5, 0, 5)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 867, 'last_n_outputs': 46, 'leak_rate': 0.7648323777973826, 'lr': 0.025439726370765695, 'optimizer': 'SGD', 'sparsity': 0.9476490190426669, 'steps_to_train': 61, 'weight_decay': 0.08357049570698338}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7029385674019719, 'info': {'data05': 0.7029385674019719, 'config': "{'batch_size': 16, 'hidden_dim': 867, 'last_n_outputs': 46, 'leak_rate': 0.7648323777973826, 'lr': 0.025439726370765695, 'optimizer': 'SGD', 'sparsity': 0.9476490190426669, 'steps_to_train': 61, 'weight_decay': 0.08357049570698338}"}}
exception: None

06:13:42 job_callback for (5, 0, 5) started
06:13:42 job_callback for (5, 0, 5) got condition
06:13:42 DISPATCHER: Trying to submit another job.
06:13:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:13:42 HBMASTER: Trying to run another job!
06:13:42 job_callback for (5, 0, 5) finished
06:13:42 ITERATION: Advancing config (5, 0, 4) to next budget 1200.000000
06:13:42 HBMASTER: schedule new run for iteration 5
06:13:42 HBMASTER: trying submitting job (5, 0, 4) to dispatcher
06:13:42 HBMASTER: submitting job (5, 0, 4) to dispatcher
06:13:42 DISPATCHER: trying to submit job (5, 0, 4)
06:13:42 DISPATCHER: trying to notify the job_runner thread.
06:13:42 HBMASTER: job (5, 0, 4) submitted to dispatcher
06:13:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:13:42 DISPATCHER: Trying to submit another job.
06:13:42 DISPATCHER: starting job (5, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:13:42 DISPATCHER: job (5, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:13:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:13:42 WORKER: start processing job (5, 0, 4)
06:13:42 WORKER: args: ()
06:13:42 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 894, 'last_n_outputs': 47, 'leak_rate': 0.8481924324686845, 'lr': 0.03348092802953821, 'optimizer': 'SGD', 'sparsity': 0.7915867468566755, 'steps_to_train': 82, 'weight_decay': 0.02373762180124746}, 'budget': 1200.0, 'working_directory': '.'}
06:14:25 DISPATCHER: Starting worker discovery
06:14:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:14:25 DISPATCHER: Finished worker discovery
06:15:25 DISPATCHER: Starting worker discovery
06:15:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:15:25 DISPATCHER: Finished worker discovery
06:16:25 DISPATCHER: Starting worker discovery
06:16:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:16:25 DISPATCHER: Finished worker discovery
06:17:25 DISPATCHER: Starting worker discovery
06:17:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:17:25 DISPATCHER: Finished worker discovery
06:18:25 DISPATCHER: Starting worker discovery
06:18:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:18:25 DISPATCHER: Finished worker discovery
06:19:25 DISPATCHER: Starting worker discovery
06:19:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:19:25 DISPATCHER: Finished worker discovery
06:20:25 DISPATCHER: Starting worker discovery
06:20:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:20:25 DISPATCHER: Finished worker discovery
06:21:25 DISPATCHER: Starting worker discovery
06:21:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:21:25 DISPATCHER: Finished worker discovery
06:22:25 DISPATCHER: Starting worker discovery
06:22:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:22:25 DISPATCHER: Finished worker discovery
06:23:25 DISPATCHER: Starting worker discovery
06:23:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:23:25 DISPATCHER: Finished worker discovery
06:24:25 DISPATCHER: Starting worker discovery
06:24:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:24:25 DISPATCHER: Finished worker discovery
06:25:25 DISPATCHER: Starting worker discovery
06:25:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:25:25 DISPATCHER: Finished worker discovery
06:26:25 DISPATCHER: Starting worker discovery
06:26:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:26:25 DISPATCHER: Finished worker discovery
06:27:25 DISPATCHER: Starting worker discovery
06:27:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:27:25 DISPATCHER: Finished worker discovery
06:28:25 DISPATCHER: Starting worker discovery
06:28:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:28:25 DISPATCHER: Finished worker discovery
06:29:25 DISPATCHER: Starting worker discovery
06:29:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:29:25 DISPATCHER: Finished worker discovery
06:30:25 DISPATCHER: Starting worker discovery
06:30:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:30:25 DISPATCHER: Finished worker discovery
06:31:25 DISPATCHER: Starting worker discovery
06:31:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:31:25 DISPATCHER: Finished worker discovery
06:32:25 DISPATCHER: Starting worker discovery
06:32:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:32:25 DISPATCHER: Finished worker discovery
06:33:25 DISPATCHER: Starting worker discovery
06:33:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:33:25 DISPATCHER: Finished worker discovery
06:33:59 WORKER: done with job (5, 0, 4), trying to register it.
06:33:59 WORKER: registered result for job (5, 0, 4) with dispatcher
06:33:59 DISPATCHER: job (5, 0, 4) finished
06:33:59 DISPATCHER: register_result: lock acquired
06:33:59 DISPATCHER: job (5, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
06:33:59 job_id: (5, 0, 4)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 894, 'last_n_outputs': 47, 'leak_rate': 0.8481924324686845, 'lr': 0.03348092802953821, 'optimizer': 'SGD', 'sparsity': 0.7915867468566755, 'steps_to_train': 82, 'weight_decay': 0.02373762180124746}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.7406851058885031, 'info': {'data05': 0.7406851058885031, 'config': "{'batch_size': 64, 'hidden_dim': 894, 'last_n_outputs': 47, 'leak_rate': 0.8481924324686845, 'lr': 0.03348092802953821, 'optimizer': 'SGD', 'sparsity': 0.7915867468566755, 'steps_to_train': 82, 'weight_decay': 0.02373762180124746}"}}
exception: None

06:33:59 job_callback for (5, 0, 4) started
06:33:59 job_callback for (5, 0, 4) got condition
06:33:59 DISPATCHER: Trying to submit another job.
06:33:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:33:59 HBMASTER: Trying to run another job!
06:33:59 job_callback for (5, 0, 4) finished
06:33:59 start sampling a new configuration.
06:33:59 done sampling a new configuration.
06:33:59 HBMASTER: schedule new run for iteration 6
06:33:59 HBMASTER: trying submitting job (6, 0, 0) to dispatcher
06:33:59 HBMASTER: submitting job (6, 0, 0) to dispatcher
06:33:59 DISPATCHER: trying to submit job (6, 0, 0)
06:33:59 DISPATCHER: trying to notify the job_runner thread.
06:33:59 HBMASTER: job (6, 0, 0) submitted to dispatcher
06:33:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:33:59 DISPATCHER: Trying to submit another job.
06:33:59 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:33:59 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:33:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:33:59 WORKER: start processing job (6, 0, 0)
06:33:59 WORKER: args: ()
06:33:59 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 273, 'last_n_outputs': 22, 'leak_rate': 0.8596886139870658, 'lr': 0.010706345978624849, 'optimizer': 'Adam', 'sparsity': 0.9207524659885987, 'steps_to_train': 54, 'weight_decay': 0.14561060906600742}, 'budget': 400.0, 'working_directory': '.'}
06:34:25 DISPATCHER: Starting worker discovery
06:34:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:34:25 DISPATCHER: Finished worker discovery
06:35:25 DISPATCHER: Starting worker discovery
06:35:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:35:25 DISPATCHER: Finished worker discovery
06:36:25 DISPATCHER: Starting worker discovery
06:36:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:36:25 DISPATCHER: Finished worker discovery
06:37:25 DISPATCHER: Starting worker discovery
06:37:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:37:25 DISPATCHER: Finished worker discovery
06:38:25 DISPATCHER: Starting worker discovery
06:38:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:38:25 DISPATCHER: Finished worker discovery
06:39:25 DISPATCHER: Starting worker discovery
06:39:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:39:25 DISPATCHER: Finished worker discovery
06:40:25 DISPATCHER: Starting worker discovery
06:40:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:40:25 DISPATCHER: Finished worker discovery
06:40:55 WORKER: done with job (6, 0, 0), trying to register it.
06:40:55 WORKER: registered result for job (6, 0, 0) with dispatcher
06:40:55 DISPATCHER: job (6, 0, 0) finished
06:40:55 DISPATCHER: register_result: lock acquired
06:40:55 DISPATCHER: job (6, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
06:40:55 job_id: (6, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 273, 'last_n_outputs': 22, 'leak_rate': 0.8596886139870658, 'lr': 0.010706345978624849, 'optimizer': 'Adam', 'sparsity': 0.9207524659885987, 'steps_to_train': 54, 'weight_decay': 0.14561060906600742}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.12220918952347862, 'info': {'data05': 0.12220918952347862, 'config': "{'batch_size': 32, 'hidden_dim': 273, 'last_n_outputs': 22, 'leak_rate': 0.8596886139870658, 'lr': 0.010706345978624849, 'optimizer': 'Adam', 'sparsity': 0.9207524659885987, 'steps_to_train': 54, 'weight_decay': 0.14561060906600742}"}}
exception: None

06:40:55 job_callback for (6, 0, 0) started
06:40:55 job_callback for (6, 0, 0) got condition
06:40:55 DISPATCHER: Trying to submit another job.
06:40:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:40:55 HBMASTER: Trying to run another job!
06:40:55 job_callback for (6, 0, 0) finished
06:40:55 start sampling a new configuration.
06:40:55 best_vector: [2, 0.7749159174122576, 0.9718061514621927, 0.34282503534139874, 0.9424933808357174, 1, 0.3264862387645616, 0.6704864796752545, 0.31308945764230484], 0.001183437919511556, 11.065572663885103, 0.013095418291552132
06:40:55 done sampling a new configuration.
06:40:55 HBMASTER: schedule new run for iteration 6
06:40:55 HBMASTER: trying submitting job (6, 0, 1) to dispatcher
06:40:55 HBMASTER: submitting job (6, 0, 1) to dispatcher
06:40:55 DISPATCHER: trying to submit job (6, 0, 1)
06:40:55 DISPATCHER: trying to notify the job_runner thread.
06:40:55 HBMASTER: job (6, 0, 1) submitted to dispatcher
06:40:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:40:55 DISPATCHER: Trying to submit another job.
06:40:55 DISPATCHER: starting job (6, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:40:55 DISPATCHER: job (6, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:40:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:40:55 WORKER: start processing job (6, 0, 1)
06:40:55 WORKER: args: ()
06:40:55 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 820, 'last_n_outputs': 49, 'leak_rate': 0.8357062588353497, 'lr': 0.07673380987153335, 'optimizer': 'SGD', 'sparsity': 0.8283566973034948, 'steps_to_train': 71, 'weight_decay': 0.025546933394881954}, 'budget': 400.0, 'working_directory': '.'}
06:41:25 DISPATCHER: Starting worker discovery
06:41:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:41:25 DISPATCHER: Finished worker discovery
06:42:25 DISPATCHER: Starting worker discovery
06:42:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:42:25 DISPATCHER: Finished worker discovery
06:43:25 DISPATCHER: Starting worker discovery
06:43:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:43:25 DISPATCHER: Finished worker discovery
06:44:25 DISPATCHER: Starting worker discovery
06:44:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:44:25 DISPATCHER: Finished worker discovery
06:45:25 DISPATCHER: Starting worker discovery
06:45:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:45:25 DISPATCHER: Finished worker discovery
06:46:25 DISPATCHER: Starting worker discovery
06:46:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:46:25 DISPATCHER: Finished worker discovery
06:47:25 DISPATCHER: Starting worker discovery
06:47:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:47:25 DISPATCHER: Finished worker discovery
06:47:52 WORKER: done with job (6, 0, 1), trying to register it.
06:47:52 WORKER: registered result for job (6, 0, 1) with dispatcher
06:47:52 DISPATCHER: job (6, 0, 1) finished
06:47:52 DISPATCHER: register_result: lock acquired
06:47:52 DISPATCHER: job (6, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
06:47:52 job_id: (6, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 820, 'last_n_outputs': 49, 'leak_rate': 0.8357062588353497, 'lr': 0.07673380987153335, 'optimizer': 'SGD', 'sparsity': 0.8283566973034948, 'steps_to_train': 71, 'weight_decay': 0.025546933394881954}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.625839828687984, 'info': {'data05': 0.625839828687984, 'config': "{'batch_size': 64, 'hidden_dim': 820, 'last_n_outputs': 49, 'leak_rate': 0.8357062588353497, 'lr': 0.07673380987153335, 'optimizer': 'SGD', 'sparsity': 0.8283566973034948, 'steps_to_train': 71, 'weight_decay': 0.025546933394881954}"}}
exception: None

06:47:52 job_callback for (6, 0, 1) started
06:47:52 job_callback for (6, 0, 1) got condition
06:47:52 DISPATCHER: Trying to submit another job.
06:47:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:47:52 done building a new model for budget 400.000000 based on 10/17 split
Best loss for this budget:-0.773507





06:47:52 HBMASTER: Trying to run another job!
06:47:52 job_callback for (6, 0, 1) finished
06:47:52 start sampling a new configuration.
06:47:52 best_vector: [0, 0.9366342702135503, 0.9043837305831761, 0.8562752441335271, 0.11558053174904678, 1, 0.9990417603251665, 0.8040532041570296, 0.07565397377878569], 0.00013958152580933255, 0.6808538390473836, 9.503461770737552e-05
06:47:52 done sampling a new configuration.
06:47:52 HBMASTER: schedule new run for iteration 6
06:47:52 HBMASTER: trying submitting job (6, 0, 2) to dispatcher
06:47:52 HBMASTER: submitting job (6, 0, 2) to dispatcher
06:47:52 DISPATCHER: trying to submit job (6, 0, 2)
06:47:52 DISPATCHER: trying to notify the job_runner thread.
06:47:52 HBMASTER: job (6, 0, 2) submitted to dispatcher
06:47:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:47:52 DISPATCHER: Trying to submit another job.
06:47:52 DISPATCHER: starting job (6, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:47:52 DISPATCHER: job (6, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:47:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:47:52 WORKER: start processing job (6, 0, 2)
06:47:52 WORKER: args: ()
06:47:52 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 950, 'last_n_outputs': 47, 'leak_rate': 0.9640688110333817, 'lr': 0.0017027898920721266, 'optimizer': 'SGD', 'sparsity': 0.9897700224780399, 'steps_to_train': 83, 'weight_decay': 0.012543770199257658}, 'budget': 400.0, 'working_directory': '.'}
06:48:25 DISPATCHER: Starting worker discovery
06:48:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:48:25 DISPATCHER: Finished worker discovery
06:49:25 DISPATCHER: Starting worker discovery
06:49:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:49:25 DISPATCHER: Finished worker discovery
06:50:25 DISPATCHER: Starting worker discovery
06:50:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:50:26 DISPATCHER: Finished worker discovery
06:51:26 DISPATCHER: Starting worker discovery
06:51:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:51:26 DISPATCHER: Finished worker discovery
06:52:26 DISPATCHER: Starting worker discovery
06:52:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:52:26 DISPATCHER: Finished worker discovery
06:53:26 DISPATCHER: Starting worker discovery
06:53:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:53:26 DISPATCHER: Finished worker discovery
06:54:26 DISPATCHER: Starting worker discovery
06:54:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:54:26 DISPATCHER: Finished worker discovery
06:54:49 WORKER: done with job (6, 0, 2), trying to register it.
06:54:49 WORKER: registered result for job (6, 0, 2) with dispatcher
06:54:49 DISPATCHER: job (6, 0, 2) finished
06:54:49 DISPATCHER: register_result: lock acquired
06:54:49 DISPATCHER: job (6, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
06:54:49 job_id: (6, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 950, 'last_n_outputs': 47, 'leak_rate': 0.9640688110333817, 'lr': 0.0017027898920721266, 'optimizer': 'SGD', 'sparsity': 0.9897700224780399, 'steps_to_train': 83, 'weight_decay': 0.012543770199257658}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7383523798672673, 'info': {'data05': 0.7383523798672673, 'config': "{'batch_size': 16, 'hidden_dim': 950, 'last_n_outputs': 47, 'leak_rate': 0.9640688110333817, 'lr': 0.0017027898920721266, 'optimizer': 'SGD', 'sparsity': 0.9897700224780399, 'steps_to_train': 83, 'weight_decay': 0.012543770199257658}"}}
exception: None

06:54:49 job_callback for (6, 0, 2) started
06:54:49 job_callback for (6, 0, 2) got condition
06:54:49 DISPATCHER: Trying to submit another job.
06:54:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:54:49 done building a new model for budget 400.000000 based on 10/17 split
Best loss for this budget:-0.773507





06:54:49 HBMASTER: Trying to run another job!
06:54:49 job_callback for (6, 0, 2) finished
06:54:49 start sampling a new configuration.
06:54:49 best_vector: [3, 0.8041257628282672, 0.8433062343506802, 0.9363060423740215, 0.20275585059096013, 1, 0.8613548177779413, 0.8718154251065862, 0.06770642795418536], 0.0002454244817217062, 1.1662770789727928, 0.0002862329476508031
06:54:49 done sampling a new configuration.
06:54:49 HBMASTER: schedule new run for iteration 6
06:54:49 HBMASTER: trying submitting job (6, 0, 3) to dispatcher
06:54:49 HBMASTER: submitting job (6, 0, 3) to dispatcher
06:54:49 DISPATCHER: trying to submit job (6, 0, 3)
06:54:49 DISPATCHER: trying to notify the job_runner thread.
06:54:49 HBMASTER: job (6, 0, 3) submitted to dispatcher
06:54:49 DISPATCHER: Trying to submit another job.
06:54:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:54:49 DISPATCHER: starting job (6, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:54:49 DISPATCHER: job (6, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:54:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:54:49 WORKER: start processing job (6, 0, 3)
06:54:49 WORKER: args: ()
06:54:49 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 844, 'last_n_outputs': 44, 'leak_rate': 0.9840765105935054, 'lr': 0.0025439683342614763, 'optimizer': 'SGD', 'sparsity': 0.9567251562667058, 'steps_to_train': 89, 'weight_decay': 0.012248646294872987}, 'budget': 400.0, 'working_directory': '.'}
06:55:26 DISPATCHER: Starting worker discovery
06:55:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:55:26 DISPATCHER: Finished worker discovery
06:56:26 DISPATCHER: Starting worker discovery
06:56:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:56:26 DISPATCHER: Finished worker discovery
06:57:26 DISPATCHER: Starting worker discovery
06:57:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:57:26 DISPATCHER: Finished worker discovery
06:58:26 DISPATCHER: Starting worker discovery
06:58:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:58:26 DISPATCHER: Finished worker discovery
06:59:26 DISPATCHER: Starting worker discovery
06:59:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:59:26 DISPATCHER: Finished worker discovery
07:00:26 DISPATCHER: Starting worker discovery
07:00:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:00:26 DISPATCHER: Finished worker discovery
07:01:26 DISPATCHER: Starting worker discovery
07:01:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:01:26 DISPATCHER: Finished worker discovery
07:01:45 WORKER: done with job (6, 0, 3), trying to register it.
07:01:45 WORKER: registered result for job (6, 0, 3) with dispatcher
07:01:45 DISPATCHER: job (6, 0, 3) finished
07:01:45 DISPATCHER: register_result: lock acquired
07:01:45 DISPATCHER: job (6, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
07:01:45 job_id: (6, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 844, 'last_n_outputs': 44, 'leak_rate': 0.9840765105935054, 'lr': 0.0025439683342614763, 'optimizer': 'SGD', 'sparsity': 0.9567251562667058, 'steps_to_train': 89, 'weight_decay': 0.012248646294872987}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.711183130263743, 'info': {'data05': 0.711183130263743, 'config': "{'batch_size': 128, 'hidden_dim': 844, 'last_n_outputs': 44, 'leak_rate': 0.9840765105935054, 'lr': 0.0025439683342614763, 'optimizer': 'SGD', 'sparsity': 0.9567251562667058, 'steps_to_train': 89, 'weight_decay': 0.012248646294872987}"}}
exception: None

07:01:45 job_callback for (6, 0, 3) started
07:01:45 job_callback for (6, 0, 3) got condition
07:01:45 DISPATCHER: Trying to submit another job.
07:01:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:01:45 done building a new model for budget 400.000000 based on 10/18 split
Best loss for this budget:-0.773507





07:01:45 HBMASTER: Trying to run another job!
07:01:45 job_callback for (6, 0, 3) finished
07:01:45 start sampling a new configuration.
07:01:45 best_vector: [2, 0.5965420503824448, 0.8545577767831526, 0.49308608952984434, 0.011492603211691987, 1, 0.9792386536535584, 0.09902321284940507, 0.11969112722077113], 0.004148814245939387, 0.6190258380622893, 0.0025682232155573937
07:01:45 done sampling a new configuration.
07:01:45 HBMASTER: schedule new run for iteration 6
07:01:45 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
07:01:45 HBMASTER: submitting job (6, 0, 4) to dispatcher
07:01:45 DISPATCHER: trying to submit job (6, 0, 4)
07:01:45 DISPATCHER: trying to notify the job_runner thread.
07:01:45 HBMASTER: job (6, 0, 4) submitted to dispatcher
07:01:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:01:45 DISPATCHER: Trying to submit another job.
07:01:45 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464
07:01:45 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
07:01:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:01:45 WORKER: start processing job (6, 0, 4)
07:01:45 WORKER: args: ()
07:01:45 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 677, 'last_n_outputs': 45, 'leak_rate': 0.8732715223824611, 'lr': 0.0010543509809276181, 'optimizer': 'SGD', 'sparsity': 0.985017276876854, 'steps_to_train': 19, 'weight_decay': 0.0143127058775317}, 'budget': 400.0, 'working_directory': '.'}
07:02:26 DISPATCHER: Starting worker discovery
07:02:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:02:26 DISPATCHER: Finished worker discovery
07:03:26 DISPATCHER: Starting worker discovery
07:03:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:03:26 DISPATCHER: Finished worker discovery
07:04:26 DISPATCHER: Starting worker discovery
07:04:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:04:26 DISPATCHER: Finished worker discovery
07:05:26 DISPATCHER: Starting worker discovery
07:05:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:05:26 DISPATCHER: Finished worker discovery
07:06:26 DISPATCHER: Starting worker discovery
07:06:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:06:26 DISPATCHER: Finished worker discovery
07:07:26 DISPATCHER: Starting worker discovery
07:07:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:07:26 DISPATCHER: Finished worker discovery
07:08:26 DISPATCHER: Starting worker discovery
07:08:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:08:26 DISPATCHER: Finished worker discovery
07:08:43 WORKER: done with job (6, 0, 4), trying to register it.
07:08:43 WORKER: registered result for job (6, 0, 4) with dispatcher
07:08:43 DISPATCHER: job (6, 0, 4) finished
07:08:43 DISPATCHER: register_result: lock acquired
07:08:43 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
07:08:43 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 677, 'last_n_outputs': 45, 'leak_rate': 0.8732715223824611, 'lr': 0.0010543509809276181, 'optimizer': 'SGD', 'sparsity': 0.985017276876854, 'steps_to_train': 19, 'weight_decay': 0.0143127058775317}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6905934905121472, 'info': {'data05': 0.6905934905121472, 'config': "{'batch_size': 64, 'hidden_dim': 677, 'last_n_outputs': 45, 'leak_rate': 0.8732715223824611, 'lr': 0.0010543509809276181, 'optimizer': 'SGD', 'sparsity': 0.985017276876854, 'steps_to_train': 19, 'weight_decay': 0.0143127058775317}"}}
exception: None

07:08:43 job_callback for (6, 0, 4) started
07:08:43 job_callback for (6, 0, 4) got condition
07:08:43 DISPATCHER: Trying to submit another job.
07:08:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:08:43 done building a new model for budget 400.000000 based on 10/19 split
Best loss for this budget:-0.773507





07:08:43 HBMASTER: Trying to run another job!
07:08:43 job_callback for (6, 0, 4) finished
07:08:43 start sampling a new configuration.
07:08:43 best_vector: [1, 0.8259015843156843, 0.938118009222108, 0.9890309080379189, 0.5057777018259508, 1, 0.3238930286257722, 0.9017996612594442, 0.5545238764116213], 0.0028766101873855146, 3.3436374744135406, 0.009618341621821964
07:08:43 done sampling a new configuration.
07:08:43 HBMASTER: schedule new run for iteration 6
07:08:43 HBMASTER: trying submitting job (6, 0, 5) to dispatcher
07:08:43 HBMASTER: submitting job (6, 0, 5) to dispatcher
07:08:43 DISPATCHER: trying to submit job (6, 0, 5)
07:08:43 DISPATCHER: trying to notify the job_runner thread.
07:08:43 HBMASTER: job (6, 0, 5) submitted to dispatcher
07:08:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:08:43 DISPATCHER: Trying to submit another job.
07:08:43 DISPATCHER: starting job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
07:08:43 DISPATCHER: job (6, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
07:08:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:08:43 WORKER: start processing job (6, 0, 5)
07:08:43 WORKER: args: ()
07:08:43 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 861, 'last_n_outputs': 48, 'leak_rate': 0.9972577270094798, 'lr': 0.010269644348314469, 'optimizer': 'SGD', 'sparsity': 0.8277343268701853, 'steps_to_train': 92, 'weight_decay': 0.05265652518385435}, 'budget': 400.0, 'working_directory': '.'}
07:09:26 DISPATCHER: Starting worker discovery
07:09:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:09:26 DISPATCHER: Finished worker discovery
07:10:26 DISPATCHER: Starting worker discovery
07:10:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:10:26 DISPATCHER: Finished worker discovery
07:11:26 DISPATCHER: Starting worker discovery
07:11:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:11:26 DISPATCHER: Finished worker discovery
07:12:26 DISPATCHER: Starting worker discovery
07:12:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:12:26 DISPATCHER: Finished worker discovery
07:13:26 DISPATCHER: Starting worker discovery
07:13:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:13:26 DISPATCHER: Finished worker discovery
07:14:26 DISPATCHER: Starting worker discovery
07:14:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:14:26 DISPATCHER: Finished worker discovery
07:15:26 DISPATCHER: Starting worker discovery
07:15:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:15:26 DISPATCHER: Finished worker discovery
07:15:36 WORKER: done with job (6, 0, 5), trying to register it.
07:15:36 WORKER: registered result for job (6, 0, 5) with dispatcher
07:15:36 DISPATCHER: job (6, 0, 5) finished
07:15:36 DISPATCHER: register_result: lock acquired
07:15:36 DISPATCHER: job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
07:15:36 job_id: (6, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 861, 'last_n_outputs': 48, 'leak_rate': 0.9972577270094798, 'lr': 0.010269644348314469, 'optimizer': 'SGD', 'sparsity': 0.8277343268701853, 'steps_to_train': 92, 'weight_decay': 0.05265652518385435}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7391208234969342, 'info': {'data05': 0.7391208234969342, 'config': "{'batch_size': 32, 'hidden_dim': 861, 'last_n_outputs': 48, 'leak_rate': 0.9972577270094798, 'lr': 0.010269644348314469, 'optimizer': 'SGD', 'sparsity': 0.8277343268701853, 'steps_to_train': 92, 'weight_decay': 0.05265652518385435}"}}
exception: None

07:15:36 job_callback for (6, 0, 5) started
07:15:36 DISPATCHER: Trying to submit another job.
07:15:36 job_callback for (6, 0, 5) got condition
07:15:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:15:36 done building a new model for budget 400.000000 based on 10/20 split
Best loss for this budget:-0.773507





07:15:36 HBMASTER: Trying to run another job!
07:15:36 job_callback for (6, 0, 5) finished
07:15:36 ITERATION: Advancing config (6, 0, 2) to next budget 1200.000000
07:15:36 ITERATION: Advancing config (6, 0, 5) to next budget 1200.000000
07:15:36 HBMASTER: schedule new run for iteration 6
07:15:36 HBMASTER: trying submitting job (6, 0, 2) to dispatcher
07:15:36 HBMASTER: submitting job (6, 0, 2) to dispatcher
07:15:36 DISPATCHER: trying to submit job (6, 0, 2)
07:15:36 DISPATCHER: trying to notify the job_runner thread.
07:15:36 HBMASTER: job (6, 0, 2) submitted to dispatcher
07:15:36 DISPATCHER: Trying to submit another job.
07:15:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:15:36 DISPATCHER: starting job (6, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
07:15:36 DISPATCHER: job (6, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
07:15:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:15:36 WORKER: start processing job (6, 0, 2)
07:15:36 WORKER: args: ()
07:15:36 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 950, 'last_n_outputs': 47, 'leak_rate': 0.9640688110333817, 'lr': 0.0017027898920721266, 'optimizer': 'SGD', 'sparsity': 0.9897700224780399, 'steps_to_train': 83, 'weight_decay': 0.012543770199257658}, 'budget': 1200.0, 'working_directory': '.'}
07:16:26 DISPATCHER: Starting worker discovery
07:16:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:16:26 DISPATCHER: Finished worker discovery
07:17:26 DISPATCHER: Starting worker discovery
07:17:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:17:26 DISPATCHER: Finished worker discovery
07:18:26 DISPATCHER: Starting worker discovery
07:18:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:18:26 DISPATCHER: Finished worker discovery
07:19:26 DISPATCHER: Starting worker discovery
07:19:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:19:26 DISPATCHER: Finished worker discovery
07:20:26 DISPATCHER: Starting worker discovery
07:20:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:20:26 DISPATCHER: Finished worker discovery
07:21:26 DISPATCHER: Starting worker discovery
07:21:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:21:26 DISPATCHER: Finished worker discovery
07:22:26 DISPATCHER: Starting worker discovery
07:22:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:22:26 DISPATCHER: Finished worker discovery
07:23:26 DISPATCHER: Starting worker discovery
07:23:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:23:26 DISPATCHER: Finished worker discovery
07:24:26 DISPATCHER: Starting worker discovery
07:24:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:24:26 DISPATCHER: Finished worker discovery
07:25:26 DISPATCHER: Starting worker discovery
07:25:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:25:26 DISPATCHER: Finished worker discovery
07:26:26 DISPATCHER: Starting worker discovery
07:26:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:26:26 DISPATCHER: Finished worker discovery
07:27:26 DISPATCHER: Starting worker discovery
07:27:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:27:26 DISPATCHER: Finished worker discovery
07:28:26 DISPATCHER: Starting worker discovery
07:28:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:28:26 DISPATCHER: Finished worker discovery
07:29:26 DISPATCHER: Starting worker discovery
07:29:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:29:26 DISPATCHER: Finished worker discovery
07:30:26 DISPATCHER: Starting worker discovery
07:30:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:30:26 DISPATCHER: Finished worker discovery
07:31:26 DISPATCHER: Starting worker discovery
07:31:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:31:26 DISPATCHER: Finished worker discovery
07:32:26 DISPATCHER: Starting worker discovery
07:32:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:32:26 DISPATCHER: Finished worker discovery
07:33:26 DISPATCHER: Starting worker discovery
07:33:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:33:26 DISPATCHER: Finished worker discovery
07:34:26 DISPATCHER: Starting worker discovery
07:34:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:34:26 DISPATCHER: Finished worker discovery
07:35:26 DISPATCHER: Starting worker discovery
07:35:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:35:26 DISPATCHER: Finished worker discovery
07:35:59 WORKER: done with job (6, 0, 2), trying to register it.
07:35:59 WORKER: registered result for job (6, 0, 2) with dispatcher
07:35:59 DISPATCHER: job (6, 0, 2) finished
07:35:59 DISPATCHER: register_result: lock acquired
07:35:59 DISPATCHER: job (6, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
07:35:59 job_id: (6, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 950, 'last_n_outputs': 47, 'leak_rate': 0.9640688110333817, 'lr': 0.0017027898920721266, 'optimizer': 'SGD', 'sparsity': 0.9897700224780399, 'steps_to_train': 83, 'weight_decay': 0.012543770199257658}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.7310246694438138, 'info': {'data05': 0.7310246694438138, 'config': "{'batch_size': 16, 'hidden_dim': 950, 'last_n_outputs': 47, 'leak_rate': 0.9640688110333817, 'lr': 0.0017027898920721266, 'optimizer': 'SGD', 'sparsity': 0.9897700224780399, 'steps_to_train': 83, 'weight_decay': 0.012543770199257658}"}}
exception: None

07:35:59 job_callback for (6, 0, 2) started
07:35:59 DISPATCHER: Trying to submit another job.
07:35:59 job_callback for (6, 0, 2) got condition
07:35:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:36:00 HBMASTER: Trying to run another job!
07:36:00 job_callback for (6, 0, 2) finished
07:36:00 HBMASTER: schedule new run for iteration 6
07:36:00 HBMASTER: trying submitting job (6, 0, 5) to dispatcher
07:36:00 HBMASTER: submitting job (6, 0, 5) to dispatcher
07:36:00 DISPATCHER: trying to submit job (6, 0, 5)
07:36:00 DISPATCHER: trying to notify the job_runner thread.
07:36:00 HBMASTER: job (6, 0, 5) submitted to dispatcher
07:36:00 DISPATCHER: Trying to submit another job.
07:36:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:36:00 DISPATCHER: starting job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
07:36:00 DISPATCHER: job (6, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
07:36:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:36:00 WORKER: start processing job (6, 0, 5)
07:36:00 WORKER: args: ()
07:36:00 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 861, 'last_n_outputs': 48, 'leak_rate': 0.9972577270094798, 'lr': 0.010269644348314469, 'optimizer': 'SGD', 'sparsity': 0.8277343268701853, 'steps_to_train': 92, 'weight_decay': 0.05265652518385435}, 'budget': 1200.0, 'working_directory': '.'}
07:36:26 DISPATCHER: Starting worker discovery
07:36:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:36:26 DISPATCHER: Finished worker discovery
07:37:26 DISPATCHER: Starting worker discovery
07:37:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:37:26 DISPATCHER: Finished worker discovery
07:38:26 DISPATCHER: Starting worker discovery
07:38:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:38:26 DISPATCHER: Finished worker discovery
07:39:26 DISPATCHER: Starting worker discovery
07:39:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:39:26 DISPATCHER: Finished worker discovery
07:40:26 DISPATCHER: Starting worker discovery
07:40:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:40:26 DISPATCHER: Finished worker discovery
07:41:26 DISPATCHER: Starting worker discovery
07:41:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:41:26 DISPATCHER: Finished worker discovery
07:42:26 DISPATCHER: Starting worker discovery
07:42:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:42:26 DISPATCHER: Finished worker discovery
07:43:26 DISPATCHER: Starting worker discovery
07:43:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:43:26 DISPATCHER: Finished worker discovery
07:44:26 DISPATCHER: Starting worker discovery
07:44:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:44:26 DISPATCHER: Finished worker discovery
07:45:26 DISPATCHER: Starting worker discovery
07:45:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:45:26 DISPATCHER: Finished worker discovery
07:46:26 DISPATCHER: Starting worker discovery
07:46:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:46:26 DISPATCHER: Finished worker discovery
07:47:26 DISPATCHER: Starting worker discovery
07:47:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:47:26 DISPATCHER: Finished worker discovery
07:48:26 DISPATCHER: Starting worker discovery
07:48:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:48:26 DISPATCHER: Finished worker discovery
07:49:26 DISPATCHER: Starting worker discovery
07:49:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:49:26 DISPATCHER: Finished worker discovery
07:50:26 DISPATCHER: Starting worker discovery
07:50:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:50:26 DISPATCHER: Finished worker discovery
07:51:26 DISPATCHER: Starting worker discovery
07:51:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:51:26 DISPATCHER: Finished worker discovery
07:52:26 DISPATCHER: Starting worker discovery
07:52:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:52:26 DISPATCHER: Finished worker discovery
07:53:26 DISPATCHER: Starting worker discovery
07:53:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:53:26 DISPATCHER: Finished worker discovery
07:54:26 DISPATCHER: Starting worker discovery
07:54:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:54:26 DISPATCHER: Finished worker discovery
07:55:26 DISPATCHER: Starting worker discovery
07:55:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:55:26 DISPATCHER: Finished worker discovery
07:56:25 WORKER: done with job (6, 0, 5), trying to register it.
07:56:25 WORKER: registered result for job (6, 0, 5) with dispatcher
07:56:25 DISPATCHER: job (6, 0, 5) finished
07:56:25 DISPATCHER: register_result: lock acquired
07:56:25 DISPATCHER: job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
07:56:25 job_id: (6, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 861, 'last_n_outputs': 48, 'leak_rate': 0.9972577270094798, 'lr': 0.010269644348314469, 'optimizer': 'SGD', 'sparsity': 0.8277343268701853, 'steps_to_train': 92, 'weight_decay': 0.05265652518385435}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.7291140835875041, 'info': {'data05': 0.7291140835875041, 'config': "{'batch_size': 32, 'hidden_dim': 861, 'last_n_outputs': 48, 'leak_rate': 0.9972577270094798, 'lr': 0.010269644348314469, 'optimizer': 'SGD', 'sparsity': 0.8277343268701853, 'steps_to_train': 92, 'weight_decay': 0.05265652518385435}"}}
exception: None

07:56:25 job_callback for (6, 0, 5) started
07:56:25 DISPATCHER: Trying to submit another job.
07:56:25 job_callback for (6, 0, 5) got condition
07:56:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:56:25 HBMASTER: Trying to run another job!
07:56:25 job_callback for (6, 0, 5) finished
07:56:25 start sampling a new configuration.
07:56:25 best_vector: [2, 0.815991604008658, 0.9299544159647541, 0.9240545436473988, 0.6010835444214113, 1, 0.5659364840330676, 0.7387776788197415, 0.35082035983197724], 0.007801365005168363, 4.7734962094790525, 0.03723978628093371
07:56:25 done sampling a new configuration.
07:56:25 HBMASTER: schedule new run for iteration 7
07:56:25 HBMASTER: trying submitting job (7, 0, 0) to dispatcher
07:56:25 HBMASTER: submitting job (7, 0, 0) to dispatcher
07:56:25 DISPATCHER: trying to submit job (7, 0, 0)
07:56:25 DISPATCHER: trying to notify the job_runner thread.
07:56:25 HBMASTER: job (7, 0, 0) submitted to dispatcher
07:56:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:56:25 DISPATCHER: Trying to submit another job.
07:56:25 DISPATCHER: starting job (7, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
07:56:25 DISPATCHER: job (7, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
07:56:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:56:25 WORKER: start processing job (7, 0, 0)
07:56:25 WORKER: args: ()
07:56:25 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 853, 'last_n_outputs': 48, 'leak_rate': 0.9810136359118498, 'lr': 0.015928214253677894, 'optimizer': 'SGD', 'sparsity': 0.8858247561679362, 'steps_to_train': 77, 'weight_decay': 0.028604068620402538}, 'budget': 1200.0, 'working_directory': '.'}
07:56:26 DISPATCHER: Starting worker discovery
07:56:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:56:26 DISPATCHER: Finished worker discovery
07:57:26 DISPATCHER: Starting worker discovery
07:57:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:57:26 DISPATCHER: Finished worker discovery
07:58:26 DISPATCHER: Starting worker discovery
07:58:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:58:26 DISPATCHER: Finished worker discovery
07:59:26 DISPATCHER: Starting worker discovery
07:59:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:59:26 DISPATCHER: Finished worker discovery
08:00:26 DISPATCHER: Starting worker discovery
08:00:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:00:26 DISPATCHER: Finished worker discovery
08:01:26 DISPATCHER: Starting worker discovery
08:01:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:01:26 DISPATCHER: Finished worker discovery
08:02:26 DISPATCHER: Starting worker discovery
08:02:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:02:26 DISPATCHER: Finished worker discovery
08:03:26 DISPATCHER: Starting worker discovery
08:03:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:03:26 DISPATCHER: Finished worker discovery
08:04:26 DISPATCHER: Starting worker discovery
08:04:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:04:26 DISPATCHER: Finished worker discovery
08:05:26 DISPATCHER: Starting worker discovery
08:05:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:05:26 DISPATCHER: Finished worker discovery
08:06:26 DISPATCHER: Starting worker discovery
08:06:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:06:26 DISPATCHER: Finished worker discovery
08:07:26 DISPATCHER: Starting worker discovery
08:07:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:07:26 DISPATCHER: Finished worker discovery
08:08:26 DISPATCHER: Starting worker discovery
08:08:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:08:26 DISPATCHER: Finished worker discovery
08:09:26 DISPATCHER: Starting worker discovery
08:09:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:09:26 DISPATCHER: Finished worker discovery
08:10:26 DISPATCHER: Starting worker discovery
08:10:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:10:26 DISPATCHER: Finished worker discovery
08:11:26 DISPATCHER: Starting worker discovery
08:11:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:11:26 DISPATCHER: Finished worker discovery
08:12:26 DISPATCHER: Starting worker discovery
08:12:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:12:26 DISPATCHER: Finished worker discovery
08:13:26 DISPATCHER: Starting worker discovery
08:13:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:13:26 DISPATCHER: Finished worker discovery
08:14:26 DISPATCHER: Starting worker discovery
08:14:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:14:26 DISPATCHER: Finished worker discovery
08:15:26 DISPATCHER: Starting worker discovery
08:15:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:15:26 DISPATCHER: Finished worker discovery
08:16:26 DISPATCHER: Starting worker discovery
08:16:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:16:26 DISPATCHER: Finished worker discovery
08:16:50 WORKER: done with job (7, 0, 0), trying to register it.
08:16:50 WORKER: registered result for job (7, 0, 0) with dispatcher
08:16:50 DISPATCHER: job (7, 0, 0) finished
08:16:50 DISPATCHER: register_result: lock acquired
08:16:50 DISPATCHER: job (7, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
08:16:50 job_id: (7, 0, 0)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 853, 'last_n_outputs': 48, 'leak_rate': 0.9810136359118498, 'lr': 0.015928214253677894, 'optimizer': 'SGD', 'sparsity': 0.8858247561679362, 'steps_to_train': 77, 'weight_decay': 0.028604068620402538}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.7615567173771668, 'info': {'data05': 0.7615567173771668, 'config': "{'batch_size': 64, 'hidden_dim': 853, 'last_n_outputs': 48, 'leak_rate': 0.9810136359118498, 'lr': 0.015928214253677894, 'optimizer': 'SGD', 'sparsity': 0.8858247561679362, 'steps_to_train': 77, 'weight_decay': 0.028604068620402538}"}}
exception: None

08:16:50 job_callback for (7, 0, 0) started
08:16:50 DISPATCHER: Trying to submit another job.
08:16:50 job_callback for (7, 0, 0) got condition
08:16:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:16:50 HBMASTER: Trying to run another job!
08:16:50 job_callback for (7, 0, 0) finished
08:16:50 start sampling a new configuration.
08:16:50 best_vector: [1, 0.9726469017873275, 0.8619231085189336, 0.6140367519959817, 0.28118239954422164, 1, 0.3515004796763697, 0.9658767786013028, 0.1566935910537458], 0.024402528436697105, 2.067478680298385, 0.05045170728824635
08:16:50 done sampling a new configuration.
08:16:50 HBMASTER: schedule new run for iteration 7
08:16:50 HBMASTER: trying submitting job (7, 0, 1) to dispatcher
08:16:50 HBMASTER: submitting job (7, 0, 1) to dispatcher
08:16:50 DISPATCHER: trying to submit job (7, 0, 1)
08:16:50 DISPATCHER: trying to notify the job_runner thread.
08:16:50 HBMASTER: job (7, 0, 1) submitted to dispatcher
08:16:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:16:50 DISPATCHER: Trying to submit another job.
08:16:50 DISPATCHER: starting job (7, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
08:16:50 DISPATCHER: job (7, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
08:16:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:16:50 WORKER: start processing job (7, 0, 1)
08:16:50 WORKER: args: ()
08:16:50 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 979, 'last_n_outputs': 45, 'leak_rate': 0.9035091879989954, 'lr': 0.0036506046200529556, 'optimizer': 'SGD', 'sparsity': 0.8343601151223288, 'steps_to_train': 97, 'weight_decay': 0.015990537495725723}, 'budget': 1200.0, 'working_directory': '.'}
08:17:26 DISPATCHER: Starting worker discovery
08:17:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:17:26 DISPATCHER: Finished worker discovery
08:18:26 DISPATCHER: Starting worker discovery
08:18:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:18:26 DISPATCHER: Finished worker discovery
08:19:26 DISPATCHER: Starting worker discovery
08:19:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:19:26 DISPATCHER: Finished worker discovery
08:20:26 DISPATCHER: Starting worker discovery
08:20:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:20:26 DISPATCHER: Finished worker discovery
08:21:26 DISPATCHER: Starting worker discovery
08:21:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:21:26 DISPATCHER: Finished worker discovery
08:22:26 DISPATCHER: Starting worker discovery
08:22:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:22:26 DISPATCHER: Finished worker discovery
08:23:26 DISPATCHER: Starting worker discovery
08:23:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:23:26 DISPATCHER: Finished worker discovery
08:24:26 DISPATCHER: Starting worker discovery
08:24:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:24:26 DISPATCHER: Finished worker discovery
08:25:26 DISPATCHER: Starting worker discovery
08:25:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:25:26 DISPATCHER: Finished worker discovery
08:26:26 DISPATCHER: Starting worker discovery
08:26:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:26:26 DISPATCHER: Finished worker discovery
08:27:26 DISPATCHER: Starting worker discovery
08:27:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:27:26 DISPATCHER: Finished worker discovery
08:28:26 DISPATCHER: Starting worker discovery
08:28:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:28:26 DISPATCHER: Finished worker discovery
08:29:26 DISPATCHER: Starting worker discovery
08:29:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:29:26 DISPATCHER: Finished worker discovery
08:30:26 DISPATCHER: Starting worker discovery
08:30:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:30:26 DISPATCHER: Finished worker discovery
08:31:26 DISPATCHER: Starting worker discovery
08:31:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:31:26 DISPATCHER: Finished worker discovery
08:32:26 DISPATCHER: Starting worker discovery
08:32:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:32:26 DISPATCHER: Finished worker discovery
08:33:26 DISPATCHER: Starting worker discovery
08:33:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:33:26 DISPATCHER: Finished worker discovery
08:34:26 DISPATCHER: Starting worker discovery
08:34:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:34:26 DISPATCHER: Finished worker discovery
08:35:26 DISPATCHER: Starting worker discovery
08:35:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:35:26 DISPATCHER: Finished worker discovery
08:36:26 DISPATCHER: Starting worker discovery
08:36:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:36:26 DISPATCHER: Finished worker discovery
08:37:10 WORKER: done with job (7, 0, 1), trying to register it.
08:37:10 WORKER: registered result for job (7, 0, 1) with dispatcher
08:37:10 DISPATCHER: job (7, 0, 1) finished
08:37:10 DISPATCHER: register_result: lock acquired
08:37:10 DISPATCHER: job (7, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
08:37:10 job_id: (7, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 979, 'last_n_outputs': 45, 'leak_rate': 0.9035091879989954, 'lr': 0.0036506046200529556, 'optimizer': 'SGD', 'sparsity': 0.8343601151223288, 'steps_to_train': 97, 'weight_decay': 0.015990537495725723}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.746241386373073, 'info': {'data05': 0.746241386373073, 'config': "{'batch_size': 32, 'hidden_dim': 979, 'last_n_outputs': 45, 'leak_rate': 0.9035091879989954, 'lr': 0.0036506046200529556, 'optimizer': 'SGD', 'sparsity': 0.8343601151223288, 'steps_to_train': 97, 'weight_decay': 0.015990537495725723}"}}
exception: None

08:37:10 job_callback for (7, 0, 1) started
08:37:10 DISPATCHER: Trying to submit another job.
08:37:10 job_callback for (7, 0, 1) got condition
08:37:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:37:10 HBMASTER: Trying to run another job!
08:37:10 job_callback for (7, 0, 1) finished
08:37:10 start sampling a new configuration.
08:37:10 best_vector: [0, 0.939364780789995, 0.8744972227108957, 0.293930607100915, 0.05369218190200309, 1, 0.9947890670968011, 0.759111094176128, 0.3513650720750746], 0.01703464549625446, 0.759588610383144, 0.012939322700869406
08:37:10 done sampling a new configuration.
08:37:10 HBMASTER: schedule new run for iteration 7
08:37:10 HBMASTER: trying submitting job (7, 0, 2) to dispatcher
08:37:10 HBMASTER: submitting job (7, 0, 2) to dispatcher
08:37:10 DISPATCHER: trying to submit job (7, 0, 2)
08:37:10 DISPATCHER: trying to notify the job_runner thread.
08:37:10 HBMASTER: job (7, 0, 2) submitted to dispatcher
08:37:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:37:10 DISPATCHER: Trying to submit another job.
08:37:10 DISPATCHER: starting job (7, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
08:37:10 DISPATCHER: job (7, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
08:37:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:37:10 WORKER: start processing job (7, 0, 2)
08:37:10 WORKER: args: ()
08:37:10 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 952, 'last_n_outputs': 45, 'leak_rate': 0.8234826517752287, 'lr': 0.00128051409666456, 'optimizer': 'SGD', 'sparsity': 0.9887493761032322, 'steps_to_train': 79, 'weight_decay': 0.028650783188486167}, 'budget': 1200.0, 'working_directory': '.'}
08:37:26 DISPATCHER: Starting worker discovery
08:37:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:37:26 DISPATCHER: Finished worker discovery
08:38:26 DISPATCHER: Starting worker discovery
08:38:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:38:26 DISPATCHER: Finished worker discovery
08:39:26 DISPATCHER: Starting worker discovery
08:39:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:39:26 DISPATCHER: Finished worker discovery
08:40:26 DISPATCHER: Starting worker discovery
08:40:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:40:26 DISPATCHER: Finished worker discovery
08:41:26 DISPATCHER: Starting worker discovery
08:41:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:41:26 DISPATCHER: Finished worker discovery
08:42:26 DISPATCHER: Starting worker discovery
08:42:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:42:26 DISPATCHER: Finished worker discovery
08:43:26 DISPATCHER: Starting worker discovery
08:43:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:43:26 DISPATCHER: Finished worker discovery
08:44:26 DISPATCHER: Starting worker discovery
08:44:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:44:26 DISPATCHER: Finished worker discovery
08:45:26 DISPATCHER: Starting worker discovery
08:45:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:45:26 DISPATCHER: Finished worker discovery
08:46:26 DISPATCHER: Starting worker discovery
08:46:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:46:26 DISPATCHER: Finished worker discovery
08:47:26 DISPATCHER: Starting worker discovery
08:47:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:47:26 DISPATCHER: Finished worker discovery
08:48:26 DISPATCHER: Starting worker discovery
08:48:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:48:26 DISPATCHER: Finished worker discovery
08:49:26 DISPATCHER: Starting worker discovery
08:49:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:49:26 DISPATCHER: Finished worker discovery
08:50:26 DISPATCHER: Starting worker discovery
08:50:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:50:26 DISPATCHER: Finished worker discovery
08:51:26 DISPATCHER: Starting worker discovery
08:51:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:51:26 DISPATCHER: Finished worker discovery
08:52:26 DISPATCHER: Starting worker discovery
08:52:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:52:26 DISPATCHER: Finished worker discovery
08:53:26 DISPATCHER: Starting worker discovery
08:53:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:53:26 DISPATCHER: Finished worker discovery
08:54:26 DISPATCHER: Starting worker discovery
08:54:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:54:26 DISPATCHER: Finished worker discovery
08:55:26 DISPATCHER: Starting worker discovery
08:55:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:55:26 DISPATCHER: Finished worker discovery
08:56:26 DISPATCHER: Starting worker discovery
08:56:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:56:26 DISPATCHER: Finished worker discovery
08:57:26 DISPATCHER: Starting worker discovery
08:57:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:57:27 DISPATCHER: Finished worker discovery
08:57:27 WORKER: done with job (7, 0, 2), trying to register it.
08:57:27 WORKER: registered result for job (7, 0, 2) with dispatcher
08:57:27 DISPATCHER: job (7, 0, 2) finished
08:57:27 DISPATCHER: register_result: lock acquired
08:57:27 DISPATCHER: job (7, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
08:57:27 job_id: (7, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 952, 'last_n_outputs': 45, 'leak_rate': 0.8234826517752287, 'lr': 0.00128051409666456, 'optimizer': 'SGD', 'sparsity': 0.9887493761032322, 'steps_to_train': 79, 'weight_decay': 0.028650783188486167}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.7162845391920645, 'info': {'data05': 0.7162845391920645, 'config': "{'batch_size': 16, 'hidden_dim': 952, 'last_n_outputs': 45, 'leak_rate': 0.8234826517752287, 'lr': 0.00128051409666456, 'optimizer': 'SGD', 'sparsity': 0.9887493761032322, 'steps_to_train': 79, 'weight_decay': 0.028650783188486167}"}}
exception: None

08:57:27 job_callback for (7, 0, 2) started
08:57:27 job_callback for (7, 0, 2) got condition
08:57:27 DISPATCHER: Trying to submit another job.
08:57:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:57:27 HBMASTER: Trying to run another job!
08:57:27 job_callback for (7, 0, 2) finished
08:57:27 start sampling a new configuration.
08:57:27 done sampling a new configuration.
08:57:27 HBMASTER: schedule new run for iteration 7
08:57:27 HBMASTER: trying submitting job (7, 0, 3) to dispatcher
08:57:27 HBMASTER: submitting job (7, 0, 3) to dispatcher
08:57:27 DISPATCHER: trying to submit job (7, 0, 3)
08:57:27 DISPATCHER: trying to notify the job_runner thread.
08:57:27 HBMASTER: job (7, 0, 3) submitted to dispatcher
08:57:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:57:27 DISPATCHER: Trying to submit another job.
08:57:27 DISPATCHER: starting job (7, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
08:57:27 DISPATCHER: job (7, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
08:57:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:57:27 WORKER: start processing job (7, 0, 3)
08:57:27 WORKER: args: ()
08:57:27 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 861, 'last_n_outputs': 38, 'leak_rate': 0.8671789345747911, 'lr': 0.02575587739766478, 'optimizer': 'SGD', 'sparsity': 0.8868981228743417, 'steps_to_train': 58, 'weight_decay': 0.01846451908484445}, 'budget': 1200.0, 'working_directory': '.'}
08:58:27 DISPATCHER: Starting worker discovery
08:58:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:58:27 DISPATCHER: Finished worker discovery
08:59:27 DISPATCHER: Starting worker discovery
08:59:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:59:27 DISPATCHER: Finished worker discovery
09:00:27 DISPATCHER: Starting worker discovery
09:00:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:00:27 DISPATCHER: Finished worker discovery
09:01:27 DISPATCHER: Starting worker discovery
09:01:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:01:27 DISPATCHER: Finished worker discovery
09:02:27 DISPATCHER: Starting worker discovery
09:02:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:02:27 DISPATCHER: Finished worker discovery
09:03:27 DISPATCHER: Starting worker discovery
09:03:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:03:27 DISPATCHER: Finished worker discovery
09:04:27 DISPATCHER: Starting worker discovery
09:04:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:04:27 DISPATCHER: Finished worker discovery
09:05:27 DISPATCHER: Starting worker discovery
09:05:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:05:27 DISPATCHER: Finished worker discovery
09:06:27 DISPATCHER: Starting worker discovery
09:06:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:06:27 DISPATCHER: Finished worker discovery
09:07:27 DISPATCHER: Starting worker discovery
09:07:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:07:27 DISPATCHER: Finished worker discovery
09:08:27 DISPATCHER: Starting worker discovery
09:08:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:08:27 DISPATCHER: Finished worker discovery
09:09:27 DISPATCHER: Starting worker discovery
09:09:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:09:27 DISPATCHER: Finished worker discovery
09:10:27 DISPATCHER: Starting worker discovery
09:10:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:10:27 DISPATCHER: Finished worker discovery
09:11:27 DISPATCHER: Starting worker discovery
09:11:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:11:27 DISPATCHER: Finished worker discovery
09:12:27 DISPATCHER: Starting worker discovery
09:12:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:12:27 DISPATCHER: Finished worker discovery
09:13:27 DISPATCHER: Starting worker discovery
09:13:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:13:27 DISPATCHER: Finished worker discovery
09:14:27 DISPATCHER: Starting worker discovery
09:14:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:14:27 DISPATCHER: Finished worker discovery
09:15:27 DISPATCHER: Starting worker discovery
09:15:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:15:27 DISPATCHER: Finished worker discovery
09:16:27 DISPATCHER: Starting worker discovery
09:16:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:16:27 DISPATCHER: Finished worker discovery
09:17:27 DISPATCHER: Starting worker discovery
09:17:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:17:27 DISPATCHER: Finished worker discovery
09:17:48 WORKER: done with job (7, 0, 3), trying to register it.
09:17:48 WORKER: registered result for job (7, 0, 3) with dispatcher
09:17:48 DISPATCHER: job (7, 0, 3) finished
09:17:48 DISPATCHER: register_result: lock acquired
09:17:48 DISPATCHER: job (7, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
09:17:48 job_id: (7, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 861, 'last_n_outputs': 38, 'leak_rate': 0.8671789345747911, 'lr': 0.02575587739766478, 'optimizer': 'SGD', 'sparsity': 0.8868981228743417, 'steps_to_train': 58, 'weight_decay': 0.01846451908484445}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.7173998349384275, 'info': {'data05': 0.7173998349384275, 'config': "{'batch_size': 16, 'hidden_dim': 861, 'last_n_outputs': 38, 'leak_rate': 0.8671789345747911, 'lr': 0.02575587739766478, 'optimizer': 'SGD', 'sparsity': 0.8868981228743417, 'steps_to_train': 58, 'weight_decay': 0.01846451908484445}"}}
exception: None

09:17:48 job_callback for (7, 0, 3) started
09:17:48 job_callback for (7, 0, 3) got condition
09:17:48 DISPATCHER: Trying to submit another job.
09:17:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:17:48 HBMASTER: Trying to run another job!
09:17:48 job_callback for (7, 0, 3) finished
09:17:48 start sampling a new configuration.
09:17:48 best_vector: [3, 0.7346286143732603, 0.9990179946597193, 0.964395381797416, 0.4195025863692039, 1, 0.6957195387634606, 0.9079163812743117, 0.6971457057968333], 0.012956496777965017, 0.7321700430217771, 0.009486358803334163
09:17:48 done sampling a new configuration.
09:17:48 HBMASTER: schedule new run for iteration 8
09:17:48 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
09:17:48 HBMASTER: submitting job (8, 0, 0) to dispatcher
09:17:48 DISPATCHER: trying to submit job (8, 0, 0)
09:17:48 DISPATCHER: trying to notify the job_runner thread.
09:17:48 HBMASTER: job (8, 0, 0) submitted to dispatcher
09:17:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:17:48 DISPATCHER: Trying to submit another job.
09:17:48 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:17:48 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:17:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:17:48 WORKER: start processing job (8, 0, 0)
09:17:48 WORKER: args: ()
09:17:48 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 788, 'last_n_outputs': 50, 'leak_rate': 0.991098845449354, 'lr': 0.00690248025107967, 'optimizer': 'SGD', 'sparsity': 0.9169726893032305, 'steps_to_train': 92, 'weight_decay': 0.08072489235932702}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:18:27 DISPATCHER: Starting worker discovery
09:18:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:18:27 DISPATCHER: Finished worker discovery
09:18:51 WORKER: done with job (8, 0, 0), trying to register it.
09:18:51 WORKER: registered result for job (8, 0, 0) with dispatcher
09:18:51 DISPATCHER: job (8, 0, 0) finished
09:18:51 DISPATCHER: register_result: lock acquired
09:18:51 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
09:18:51 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 788, 'last_n_outputs': 50, 'leak_rate': 0.991098845449354, 'lr': 0.00690248025107967, 'optimizer': 'SGD', 'sparsity': 0.9169726893032305, 'steps_to_train': 92, 'weight_decay': 0.08072489235932702}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7202604441353937, 'info': {'data05': 0.7202604441353937, 'config': "{'batch_size': 128, 'hidden_dim': 788, 'last_n_outputs': 50, 'leak_rate': 0.991098845449354, 'lr': 0.00690248025107967, 'optimizer': 'SGD', 'sparsity': 0.9169726893032305, 'steps_to_train': 92, 'weight_decay': 0.08072489235932702}"}}
exception: None

09:18:51 job_callback for (8, 0, 0) started
09:18:51 job_callback for (8, 0, 0) got condition
09:18:51 DISPATCHER: Trying to submit another job.
09:18:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:18:51 HBMASTER: Trying to run another job!
09:18:51 job_callback for (8, 0, 0) finished
09:18:51 start sampling a new configuration.
09:18:51 best_vector: [1, 0.7978494560000118, 0.9361610584578124, 0.11830238753277272, 0.25016596194040175, 1, 0.6278807078248769, 0.01942696746160638, 0.8471492873174782], 0.0020071787813218853, 5.292778279125138, 0.010623552256101341
09:18:51 done sampling a new configuration.
09:18:51 HBMASTER: schedule new run for iteration 8
09:18:51 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
09:18:51 HBMASTER: submitting job (8, 0, 1) to dispatcher
09:18:51 DISPATCHER: trying to submit job (8, 0, 1)
09:18:51 DISPATCHER: trying to notify the job_runner thread.
09:18:51 HBMASTER: job (8, 0, 1) submitted to dispatcher
09:18:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:18:51 DISPATCHER: Trying to submit another job.
09:18:51 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:18:51 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:18:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:18:51 WORKER: start processing job (8, 0, 1)
09:18:51 WORKER: args: ()
09:18:51 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 839, 'last_n_outputs': 48, 'leak_rate': 0.7795755968831932, 'lr': 0.0031646954589854633, 'optimizer': 'SGD', 'sparsity': 0.9006913698779705, 'steps_to_train': 11, 'weight_decay': 0.12652217048083564}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:19:27 DISPATCHER: Starting worker discovery
09:19:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:19:27 DISPATCHER: Finished worker discovery
09:19:48 WORKER: done with job (8, 0, 1), trying to register it.
09:19:48 WORKER: registered result for job (8, 0, 1) with dispatcher
09:19:48 DISPATCHER: job (8, 0, 1) finished
09:19:48 DISPATCHER: register_result: lock acquired
09:19:48 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
09:19:48 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 839, 'last_n_outputs': 48, 'leak_rate': 0.7795755968831932, 'lr': 0.0031646954589854633, 'optimizer': 'SGD', 'sparsity': 0.9006913698779705, 'steps_to_train': 11, 'weight_decay': 0.12652217048083564}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6456476745130876, 'info': {'data05': 0.6456476745130876, 'config': "{'batch_size': 32, 'hidden_dim': 839, 'last_n_outputs': 48, 'leak_rate': 0.7795755968831932, 'lr': 0.0031646954589854633, 'optimizer': 'SGD', 'sparsity': 0.9006913698779705, 'steps_to_train': 11, 'weight_decay': 0.12652217048083564}"}}
exception: None

09:19:48 job_callback for (8, 0, 1) started
09:19:48 job_callback for (8, 0, 1) got condition
09:19:48 DISPATCHER: Trying to submit another job.
09:19:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:19:48 HBMASTER: Trying to run another job!
09:19:48 job_callback for (8, 0, 1) finished
09:19:48 start sampling a new configuration.
09:19:48 best_vector: [2, 0.8032906164608894, 0.8358020196217415, 0.010587209603813874, 0.06713051924943601, 1, 0.7522034800561614, 0.25163552348177964, 0.37297364406879485], 0.0053692026031751374, 2.3011230504600055, 0.012355195872756174
09:19:48 done sampling a new configuration.
09:19:48 HBMASTER: schedule new run for iteration 8
09:19:48 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
09:19:48 HBMASTER: submitting job (8, 0, 2) to dispatcher
09:19:48 DISPATCHER: trying to submit job (8, 0, 2)
09:19:48 DISPATCHER: trying to notify the job_runner thread.
09:19:48 HBMASTER: job (8, 0, 2) submitted to dispatcher
09:19:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:19:48 DISPATCHER: Trying to submit another job.
09:19:48 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:19:48 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:19:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:19:48 WORKER: start processing job (8, 0, 2)
09:19:48 WORKER: args: ()
09:19:48 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 843, 'last_n_outputs': 44, 'leak_rate': 0.7526468024009535, 'lr': 0.001362263242954788, 'optimizer': 'SGD', 'sparsity': 0.9305288352134787, 'steps_to_train': 32, 'weight_decay': 0.03056679459215323}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:20:27 DISPATCHER: Starting worker discovery
09:20:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:20:27 DISPATCHER: Finished worker discovery
09:20:45 WORKER: done with job (8, 0, 2), trying to register it.
09:20:45 WORKER: registered result for job (8, 0, 2) with dispatcher
09:20:45 DISPATCHER: job (8, 0, 2) finished
09:20:45 DISPATCHER: register_result: lock acquired
09:20:45 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
09:20:45 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 843, 'last_n_outputs': 44, 'leak_rate': 0.7526468024009535, 'lr': 0.001362263242954788, 'optimizer': 'SGD', 'sparsity': 0.9305288352134787, 'steps_to_train': 32, 'weight_decay': 0.03056679459215323}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5890712999385016, 'info': {'data05': 0.5890712999385016, 'config': "{'batch_size': 64, 'hidden_dim': 843, 'last_n_outputs': 44, 'leak_rate': 0.7526468024009535, 'lr': 0.001362263242954788, 'optimizer': 'SGD', 'sparsity': 0.9305288352134787, 'steps_to_train': 32, 'weight_decay': 0.03056679459215323}"}}
exception: None

09:20:45 job_callback for (8, 0, 2) started
09:20:45 DISPATCHER: Trying to submit another job.
09:20:45 job_callback for (8, 0, 2) got condition
09:20:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:20:45 HBMASTER: Trying to run another job!
09:20:45 job_callback for (8, 0, 2) finished
09:20:45 start sampling a new configuration.
09:20:45 done sampling a new configuration.
09:20:45 HBMASTER: schedule new run for iteration 8
09:20:45 HBMASTER: trying submitting job (8, 0, 3) to dispatcher
09:20:45 HBMASTER: submitting job (8, 0, 3) to dispatcher
09:20:45 DISPATCHER: trying to submit job (8, 0, 3)
09:20:45 DISPATCHER: trying to notify the job_runner thread.
09:20:45 HBMASTER: job (8, 0, 3) submitted to dispatcher
09:20:45 DISPATCHER: Trying to submit another job.
09:20:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:20:45 DISPATCHER: starting job (8, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:20:45 DISPATCHER: job (8, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:20:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:20:45 WORKER: start processing job (8, 0, 3)
09:20:45 WORKER: args: ()
09:20:45 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 513, 'last_n_outputs': 31, 'leak_rate': 0.9598792802226666, 'lr': 0.008384169150491332, 'optimizer': 'SGD', 'sparsity': 0.7752058647636332, 'steps_to_train': 32, 'weight_decay': 0.045210055437048306}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:21:27 DISPATCHER: Starting worker discovery
09:21:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:21:27 DISPATCHER: Finished worker discovery
09:21:42 WORKER: done with job (8, 0, 3), trying to register it.
09:21:42 WORKER: registered result for job (8, 0, 3) with dispatcher
09:21:42 DISPATCHER: job (8, 0, 3) finished
09:21:42 DISPATCHER: register_result: lock acquired
09:21:42 DISPATCHER: job (8, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
09:21:42 job_id: (8, 0, 3)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 513, 'last_n_outputs': 31, 'leak_rate': 0.9598792802226666, 'lr': 0.008384169150491332, 'optimizer': 'SGD', 'sparsity': 0.7752058647636332, 'steps_to_train': 32, 'weight_decay': 0.045210055437048306}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6071418282989776, 'info': {'data05': 0.6071418282989776, 'config': "{'batch_size': 32, 'hidden_dim': 513, 'last_n_outputs': 31, 'leak_rate': 0.9598792802226666, 'lr': 0.008384169150491332, 'optimizer': 'SGD', 'sparsity': 0.7752058647636332, 'steps_to_train': 32, 'weight_decay': 0.045210055437048306}"}}
exception: None

09:21:42 job_callback for (8, 0, 3) started
09:21:42 DISPATCHER: Trying to submit another job.
09:21:42 job_callback for (8, 0, 3) got condition
09:21:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:21:42 HBMASTER: Trying to run another job!
09:21:42 job_callback for (8, 0, 3) finished
09:21:42 start sampling a new configuration.
09:21:43 best_vector: [3, 0.6209359267812333, 0.9255844392183379, 0.9641961403827415, 0.09844305305018301, 1, 0.021329939837366085, 0.9852036495564079, 0.416892211352364], 0.006961688061336659, 0.22076740659310795, 0.0015369138188114956
09:21:43 done sampling a new configuration.
09:21:43 HBMASTER: schedule new run for iteration 8
09:21:43 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
09:21:43 HBMASTER: submitting job (8, 0, 4) to dispatcher
09:21:43 DISPATCHER: trying to submit job (8, 0, 4)
09:21:43 DISPATCHER: trying to notify the job_runner thread.
09:21:43 HBMASTER: job (8, 0, 4) submitted to dispatcher
09:21:43 DISPATCHER: Trying to submit another job.
09:21:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:21:43 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:21:43 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:21:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:21:43 WORKER: start processing job (8, 0, 4)
09:21:43 WORKER: args: ()
09:21:43 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 697, 'last_n_outputs': 47, 'leak_rate': 0.9910490350956853, 'lr': 0.0015735701409583516, 'optimizer': 'SGD', 'sparsity': 0.7551191855609679, 'steps_to_train': 99, 'weight_decay': 0.03486496807980456}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:22:27 DISPATCHER: Starting worker discovery
09:22:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:22:27 DISPATCHER: Finished worker discovery
09:22:47 WORKER: done with job (8, 0, 4), trying to register it.
09:22:47 WORKER: registered result for job (8, 0, 4) with dispatcher
09:22:47 DISPATCHER: job (8, 0, 4) finished
09:22:47 DISPATCHER: register_result: lock acquired
09:22:47 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
09:22:47 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 697, 'last_n_outputs': 47, 'leak_rate': 0.9910490350956853, 'lr': 0.0015735701409583516, 'optimizer': 'SGD', 'sparsity': 0.7551191855609679, 'steps_to_train': 99, 'weight_decay': 0.03486496807980456}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6708450035594794, 'info': {'data05': 0.6708450035594794, 'config': "{'batch_size': 128, 'hidden_dim': 697, 'last_n_outputs': 47, 'leak_rate': 0.9910490350956853, 'lr': 0.0015735701409583516, 'optimizer': 'SGD', 'sparsity': 0.7551191855609679, 'steps_to_train': 99, 'weight_decay': 0.03486496807980456}"}}
exception: None

09:22:47 job_callback for (8, 0, 4) started
09:22:47 job_callback for (8, 0, 4) got condition
09:22:47 DISPATCHER: Trying to submit another job.
09:22:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:22:47 HBMASTER: Trying to run another job!
09:22:47 job_callback for (8, 0, 4) finished
09:22:47 start sampling a new configuration.
09:22:47 best_vector: [1, 0.990085273827275, 0.9501113235884664, 0.8191235788052237, 0.4382597544613733, 1, 0.2796864208196215, 0.7368134123821979, 0.270171329433785], 0.00603894133876251, 6.169664329522866, 0.03725824096584412
09:22:47 done sampling a new configuration.
09:22:47 HBMASTER: schedule new run for iteration 8
09:22:47 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
09:22:47 HBMASTER: submitting job (8, 0, 5) to dispatcher
09:22:47 DISPATCHER: trying to submit job (8, 0, 5)
09:22:47 DISPATCHER: trying to notify the job_runner thread.
09:22:47 HBMASTER: job (8, 0, 5) submitted to dispatcher
09:22:47 DISPATCHER: Trying to submit another job.
09:22:47 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:22:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:22:47 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:22:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:22:47 WORKER: start processing job (8, 0, 5)
09:22:47 WORKER: args: ()
09:22:47 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 993, 'last_n_outputs': 48, 'leak_rate': 0.9547808947013059, 'lr': 0.00752522533444974, 'optimizer': 'SGD', 'sparsity': 0.8171247409967092, 'steps_to_train': 77, 'weight_decay': 0.022464719671026697}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:23:27 DISPATCHER: Starting worker discovery
09:23:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:23:27 DISPATCHER: Finished worker discovery
09:23:48 WORKER: done with job (8, 0, 5), trying to register it.
09:23:48 WORKER: registered result for job (8, 0, 5) with dispatcher
09:23:48 DISPATCHER: job (8, 0, 5) finished
09:23:48 DISPATCHER: register_result: lock acquired
09:23:48 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
09:23:48 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 993, 'last_n_outputs': 48, 'leak_rate': 0.9547808947013059, 'lr': 0.00752522533444974, 'optimizer': 'SGD', 'sparsity': 0.8171247409967092, 'steps_to_train': 77, 'weight_decay': 0.022464719671026697}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7187793258316727, 'info': {'data05': 0.7187793258316727, 'config': "{'batch_size': 32, 'hidden_dim': 993, 'last_n_outputs': 48, 'leak_rate': 0.9547808947013059, 'lr': 0.00752522533444974, 'optimizer': 'SGD', 'sparsity': 0.8171247409967092, 'steps_to_train': 77, 'weight_decay': 0.022464719671026697}"}}
exception: None

09:23:48 job_callback for (8, 0, 5) started
09:23:48 DISPATCHER: Trying to submit another job.
09:23:48 job_callback for (8, 0, 5) got condition
09:23:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:23:48 HBMASTER: Trying to run another job!
09:23:48 job_callback for (8, 0, 5) finished
09:23:48 start sampling a new configuration.
09:23:49 best_vector: [3, 0.84466506827284, 0.9285076892659498, 0.9589179398131193, 0.39199714443158173, 1, 0.8541417384534742, 0.7990856758581875, 0.8473810330206445], 0.004504596642291843, 1.5840368640214404, 0.00713544713893748
09:23:49 done sampling a new configuration.
09:23:49 HBMASTER: schedule new run for iteration 8
09:23:49 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
09:23:49 HBMASTER: submitting job (8, 0, 6) to dispatcher
09:23:49 DISPATCHER: trying to submit job (8, 0, 6)
09:23:49 DISPATCHER: trying to notify the job_runner thread.
09:23:49 HBMASTER: job (8, 0, 6) submitted to dispatcher
09:23:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:23:49 DISPATCHER: Trying to submit another job.
09:23:49 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:23:49 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:23:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:23:49 WORKER: start processing job (8, 0, 6)
09:23:49 WORKER: args: ()
09:23:49 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 876, 'last_n_outputs': 48, 'leak_rate': 0.9897294849532798, 'lr': 0.006081270041258285, 'optimizer': 'SGD', 'sparsity': 0.9549940172288338, 'steps_to_train': 82, 'weight_decay': 0.12661003875271226}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:24:27 DISPATCHER: Starting worker discovery
09:24:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:24:27 DISPATCHER: Finished worker discovery
09:24:46 WORKER: done with job (8, 0, 6), trying to register it.
09:24:46 WORKER: registered result for job (8, 0, 6) with dispatcher
09:24:46 DISPATCHER: job (8, 0, 6) finished
09:24:46 DISPATCHER: register_result: lock acquired
09:24:46 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
09:24:46 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 876, 'last_n_outputs': 48, 'leak_rate': 0.9897294849532798, 'lr': 0.006081270041258285, 'optimizer': 'SGD', 'sparsity': 0.9549940172288338, 'steps_to_train': 82, 'weight_decay': 0.12661003875271226}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7419750405447301, 'info': {'data05': 0.7419750405447301, 'config': "{'batch_size': 128, 'hidden_dim': 876, 'last_n_outputs': 48, 'leak_rate': 0.9897294849532798, 'lr': 0.006081270041258285, 'optimizer': 'SGD', 'sparsity': 0.9549940172288338, 'steps_to_train': 82, 'weight_decay': 0.12661003875271226}"}}
exception: None

09:24:46 job_callback for (8, 0, 6) started
09:24:46 job_callback for (8, 0, 6) got condition
09:24:46 DISPATCHER: Trying to submit another job.
09:24:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:24:46 HBMASTER: Trying to run another job!
09:24:46 job_callback for (8, 0, 6) finished
09:24:46 start sampling a new configuration.
09:24:47 best_vector: [1, 0.857747030267797, 0.8919526988964009, 0.32939288342774165, 0.20570521823291818, 1, 0.8891656128983246, 0.7829255343810562, 0.3516288510891622], 0.007831577687270424, 5.950019357625342, 0.04659803884000573
09:24:47 done sampling a new configuration.
09:24:47 HBMASTER: schedule new run for iteration 8
09:24:47 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
09:24:47 HBMASTER: submitting job (8, 0, 7) to dispatcher
09:24:47 DISPATCHER: trying to submit job (8, 0, 7)
09:24:47 DISPATCHER: trying to notify the job_runner thread.
09:24:47 HBMASTER: job (8, 0, 7) submitted to dispatcher
09:24:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:24:47 DISPATCHER: Trying to submit another job.
09:24:47 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:24:47 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:24:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:24:47 WORKER: start processing job (8, 0, 7)
09:24:47 WORKER: args: ()
09:24:47 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 887, 'last_n_outputs': 46, 'leak_rate': 0.8323482208569354, 'lr': 0.002578757098548007, 'optimizer': 'SGD', 'sparsity': 0.963399747095598, 'steps_to_train': 81, 'weight_decay': 0.028673432308892605}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:25:27 DISPATCHER: Starting worker discovery
09:25:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:25:27 DISPATCHER: Finished worker discovery
09:25:47 WORKER: done with job (8, 0, 7), trying to register it.
09:25:47 WORKER: registered result for job (8, 0, 7) with dispatcher
09:25:47 DISPATCHER: job (8, 0, 7) finished
09:25:47 DISPATCHER: register_result: lock acquired
09:25:47 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
09:25:47 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 887, 'last_n_outputs': 46, 'leak_rate': 0.8323482208569354, 'lr': 0.002578757098548007, 'optimizer': 'SGD', 'sparsity': 0.963399747095598, 'steps_to_train': 81, 'weight_decay': 0.028673432308892605}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6977192043327133, 'info': {'data05': 0.6977192043327133, 'config': "{'batch_size': 32, 'hidden_dim': 887, 'last_n_outputs': 46, 'leak_rate': 0.8323482208569354, 'lr': 0.002578757098548007, 'optimizer': 'SGD', 'sparsity': 0.963399747095598, 'steps_to_train': 81, 'weight_decay': 0.028673432308892605}"}}
exception: None

09:25:47 job_callback for (8, 0, 7) started
09:25:47 DISPATCHER: Trying to submit another job.
09:25:47 job_callback for (8, 0, 7) got condition
09:25:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:25:47 HBMASTER: Trying to run another job!
09:25:47 job_callback for (8, 0, 7) finished
09:25:47 start sampling a new configuration.
09:25:47 best_vector: [3, 0.995501257645814, 0.9353644771247992, 0.8007264191997314, 0.5300613878176788, 1, 0.5705493823700779, 0.9847475542413511, 0.7678164134476646], 0.0027397165171813577, 4.300558031371767, 0.011782309871646173
09:25:47 done sampling a new configuration.
09:25:47 HBMASTER: schedule new run for iteration 8
09:25:47 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
09:25:47 HBMASTER: submitting job (8, 0, 8) to dispatcher
09:25:47 DISPATCHER: trying to submit job (8, 0, 8)
09:25:47 DISPATCHER: trying to notify the job_runner thread.
09:25:47 HBMASTER: job (8, 0, 8) submitted to dispatcher
09:25:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:25:47 DISPATCHER: Trying to submit another job.
09:25:47 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:25:47 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:25:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:25:47 WORKER: start processing job (8, 0, 8)
09:25:47 WORKER: args: ()
09:25:47 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 997, 'last_n_outputs': 48, 'leak_rate': 0.9501816047999329, 'lr': 0.011484782519576853, 'optimizer': 'SGD', 'sparsity': 0.8869318517688187, 'steps_to_train': 99, 'weight_decay': 0.0997590225116073}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:26:27 DISPATCHER: Starting worker discovery
09:26:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:26:27 DISPATCHER: Finished worker discovery
09:26:44 WORKER: done with job (8, 0, 8), trying to register it.
09:26:44 WORKER: registered result for job (8, 0, 8) with dispatcher
09:26:44 DISPATCHER: job (8, 0, 8) finished
09:26:44 DISPATCHER: register_result: lock acquired
09:26:44 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
09:26:44 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 997, 'last_n_outputs': 48, 'leak_rate': 0.9501816047999329, 'lr': 0.011484782519576853, 'optimizer': 'SGD', 'sparsity': 0.8869318517688187, 'steps_to_train': 99, 'weight_decay': 0.0997590225116073}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7443024496804752, 'info': {'data05': 0.7443024496804752, 'config': "{'batch_size': 128, 'hidden_dim': 997, 'last_n_outputs': 48, 'leak_rate': 0.9501816047999329, 'lr': 0.011484782519576853, 'optimizer': 'SGD', 'sparsity': 0.8869318517688187, 'steps_to_train': 99, 'weight_decay': 0.0997590225116073}"}}
exception: None

09:26:44 job_callback for (8, 0, 8) started
09:26:44 job_callback for (8, 0, 8) got condition
09:26:44 DISPATCHER: Trying to submit another job.
09:26:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:26:44 HBMASTER: Trying to run another job!
09:26:44 job_callback for (8, 0, 8) finished
09:26:44 start sampling a new configuration.
09:26:44 done sampling a new configuration.
09:26:44 HBMASTER: schedule new run for iteration 8
09:26:44 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
09:26:44 HBMASTER: submitting job (8, 0, 9) to dispatcher
09:26:44 DISPATCHER: trying to submit job (8, 0, 9)
09:26:44 DISPATCHER: trying to notify the job_runner thread.
09:26:44 HBMASTER: job (8, 0, 9) submitted to dispatcher
09:26:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:26:44 DISPATCHER: Trying to submit another job.
09:26:44 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:26:44 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:26:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:26:44 WORKER: start processing job (8, 0, 9)
09:26:44 WORKER: args: ()
09:26:44 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 847, 'last_n_outputs': 24, 'leak_rate': 0.813515697386276, 'lr': 0.020897858449493344, 'optimizer': 'SGD', 'sparsity': 0.7986876801602829, 'steps_to_train': 81, 'weight_decay': 0.15571430296887623}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:27:27 DISPATCHER: Starting worker discovery
09:27:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:27:27 DISPATCHER: Finished worker discovery
09:27:43 WORKER: done with job (8, 0, 9), trying to register it.
09:27:43 WORKER: registered result for job (8, 0, 9) with dispatcher
09:27:43 DISPATCHER: job (8, 0, 9) finished
09:27:43 DISPATCHER: register_result: lock acquired
09:27:43 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
09:27:43 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 847, 'last_n_outputs': 24, 'leak_rate': 0.813515697386276, 'lr': 0.020897858449493344, 'optimizer': 'SGD', 'sparsity': 0.7986876801602829, 'steps_to_train': 81, 'weight_decay': 0.15571430296887623}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.488818497087539, 'info': {'data05': 0.488818497087539, 'config': "{'batch_size': 32, 'hidden_dim': 847, 'last_n_outputs': 24, 'leak_rate': 0.813515697386276, 'lr': 0.020897858449493344, 'optimizer': 'SGD', 'sparsity': 0.7986876801602829, 'steps_to_train': 81, 'weight_decay': 0.15571430296887623}"}}
exception: None

09:27:43 job_callback for (8, 0, 9) started
09:27:43 job_callback for (8, 0, 9) got condition
09:27:43 DISPATCHER: Trying to submit another job.
09:27:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:27:43 HBMASTER: Trying to run another job!
09:27:43 job_callback for (8, 0, 9) finished
09:27:43 start sampling a new configuration.
09:27:43 done sampling a new configuration.
09:27:43 HBMASTER: schedule new run for iteration 8
09:27:43 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
09:27:43 HBMASTER: submitting job (8, 0, 10) to dispatcher
09:27:43 DISPATCHER: trying to submit job (8, 0, 10)
09:27:43 DISPATCHER: trying to notify the job_runner thread.
09:27:43 HBMASTER: job (8, 0, 10) submitted to dispatcher
09:27:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:27:43 DISPATCHER: Trying to submit another job.
09:27:43 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:27:43 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:27:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:27:43 WORKER: start processing job (8, 0, 10)
09:27:43 WORKER: args: ()
09:27:43 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 778, 'last_n_outputs': 20, 'leak_rate': 0.9345151723089515, 'lr': 0.00289204348098234, 'optimizer': 'Adam', 'sparsity': 0.9817794131410167, 'steps_to_train': 25, 'weight_decay': 0.08787966205577992}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:28:27 DISPATCHER: Starting worker discovery
09:28:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:28:27 DISPATCHER: Finished worker discovery
09:28:41 WORKER: done with job (8, 0, 10), trying to register it.
09:28:41 WORKER: registered result for job (8, 0, 10) with dispatcher
09:28:41 DISPATCHER: job (8, 0, 10) finished
09:28:41 DISPATCHER: register_result: lock acquired
09:28:41 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
09:28:41 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 778, 'last_n_outputs': 20, 'leak_rate': 0.9345151723089515, 'lr': 0.00289204348098234, 'optimizer': 'Adam', 'sparsity': 0.9817794131410167, 'steps_to_train': 25, 'weight_decay': 0.08787966205577992}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2856575839654145, 'info': {'data05': 0.2856575839654145, 'config': "{'batch_size': 32, 'hidden_dim': 778, 'last_n_outputs': 20, 'leak_rate': 0.9345151723089515, 'lr': 0.00289204348098234, 'optimizer': 'Adam', 'sparsity': 0.9817794131410167, 'steps_to_train': 25, 'weight_decay': 0.08787966205577992}"}}
exception: None

09:28:41 job_callback for (8, 0, 10) started
09:28:41 job_callback for (8, 0, 10) got condition
09:28:41 DISPATCHER: Trying to submit another job.
09:28:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:28:41 HBMASTER: Trying to run another job!
09:28:41 job_callback for (8, 0, 10) finished
09:28:41 start sampling a new configuration.
09:28:41 done sampling a new configuration.
09:28:41 HBMASTER: schedule new run for iteration 8
09:28:41 HBMASTER: trying submitting job (8, 0, 11) to dispatcher
09:28:41 HBMASTER: submitting job (8, 0, 11) to dispatcher
09:28:41 DISPATCHER: trying to submit job (8, 0, 11)
09:28:41 DISPATCHER: trying to notify the job_runner thread.
09:28:41 HBMASTER: job (8, 0, 11) submitted to dispatcher
09:28:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:28:41 DISPATCHER: Trying to submit another job.
09:28:41 DISPATCHER: starting job (8, 0, 11) on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:28:41 DISPATCHER: job (8, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:28:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:28:41 WORKER: start processing job (8, 0, 11)
09:28:41 WORKER: args: ()
09:28:41 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 403, 'last_n_outputs': 15, 'leak_rate': 0.7750043665797723, 'lr': 0.03248206636003802, 'optimizer': 'SGD', 'sparsity': 0.8138765675368919, 'steps_to_train': 66, 'weight_decay': 0.03088070386871659}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:29:27 DISPATCHER: Starting worker discovery
09:29:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:29:27 DISPATCHER: Finished worker discovery
09:29:36 WORKER: done with job (8, 0, 11), trying to register it.
09:29:36 WORKER: registered result for job (8, 0, 11) with dispatcher
09:29:36 DISPATCHER: job (8, 0, 11) finished
09:29:36 DISPATCHER: register_result: lock acquired
09:29:36 DISPATCHER: job (8, 0, 11) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
09:29:36 job_id: (8, 0, 11)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 403, 'last_n_outputs': 15, 'leak_rate': 0.7750043665797723, 'lr': 0.03248206636003802, 'optimizer': 'SGD', 'sparsity': 0.8138765675368919, 'steps_to_train': 66, 'weight_decay': 0.03088070386871659}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5273616092819529, 'info': {'data05': 0.5273616092819529, 'config': "{'batch_size': 64, 'hidden_dim': 403, 'last_n_outputs': 15, 'leak_rate': 0.7750043665797723, 'lr': 0.03248206636003802, 'optimizer': 'SGD', 'sparsity': 0.8138765675368919, 'steps_to_train': 66, 'weight_decay': 0.03088070386871659}"}}
exception: None

09:29:36 job_callback for (8, 0, 11) started
09:29:36 DISPATCHER: Trying to submit another job.
09:29:36 job_callback for (8, 0, 11) got condition
09:29:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:29:36 HBMASTER: Trying to run another job!
09:29:36 job_callback for (8, 0, 11) finished
09:29:36 start sampling a new configuration.
09:29:36 done sampling a new configuration.
09:29:36 HBMASTER: schedule new run for iteration 8
09:29:36 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
09:29:36 HBMASTER: submitting job (8, 0, 12) to dispatcher
09:29:36 DISPATCHER: trying to submit job (8, 0, 12)
09:29:36 DISPATCHER: trying to notify the job_runner thread.
09:29:36 HBMASTER: job (8, 0, 12) submitted to dispatcher
09:29:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:29:36 DISPATCHER: Trying to submit another job.
09:29:36 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:29:36 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:29:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:29:36 WORKER: start processing job (8, 0, 12)
09:29:36 WORKER: args: ()
09:29:36 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 704, 'last_n_outputs': 47, 'leak_rate': 0.8970619677702375, 'lr': 0.014777410976963211, 'optimizer': 'Adam', 'sparsity': 0.7778500162050919, 'steps_to_train': 77, 'weight_decay': 0.028453576239554492}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:30:27 DISPATCHER: Starting worker discovery
09:30:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:30:27 DISPATCHER: Finished worker discovery
09:30:40 WORKER: done with job (8, 0, 12), trying to register it.
09:30:40 WORKER: registered result for job (8, 0, 12) with dispatcher
09:30:40 DISPATCHER: job (8, 0, 12) finished
09:30:40 DISPATCHER: register_result: lock acquired
09:30:40 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
09:30:40 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 704, 'last_n_outputs': 47, 'leak_rate': 0.8970619677702375, 'lr': 0.014777410976963211, 'optimizer': 'Adam', 'sparsity': 0.7778500162050919, 'steps_to_train': 77, 'weight_decay': 0.028453576239554492}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.49141213927560395, 'info': {'data05': 0.49141213927560395, 'config': "{'batch_size': 128, 'hidden_dim': 704, 'last_n_outputs': 47, 'leak_rate': 0.8970619677702375, 'lr': 0.014777410976963211, 'optimizer': 'Adam', 'sparsity': 0.7778500162050919, 'steps_to_train': 77, 'weight_decay': 0.028453576239554492}"}}
exception: None

09:30:40 job_callback for (8, 0, 12) started
09:30:40 DISPATCHER: Trying to submit another job.
09:30:40 job_callback for (8, 0, 12) got condition
09:30:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:30:40 HBMASTER: Trying to run another job!
09:30:40 job_callback for (8, 0, 12) finished
09:30:40 start sampling a new configuration.
09:30:40 best_vector: [3, 0.6723326092884812, 0.9522172695502379, 0.0960682837981246, 0.13311365286815968, 1, 0.2061991432623259, 0.522675345634541, 0.027564369835581692], 0.003941830534099828, 2.224549593564034, 0.008768797512530072
09:30:40 done sampling a new configuration.
09:30:40 HBMASTER: schedule new run for iteration 8
09:30:40 HBMASTER: trying submitting job (8, 0, 13) to dispatcher
09:30:40 HBMASTER: submitting job (8, 0, 13) to dispatcher
09:30:40 DISPATCHER: trying to submit job (8, 0, 13)
09:30:40 DISPATCHER: trying to notify the job_runner thread.
09:30:40 HBMASTER: job (8, 0, 13) submitted to dispatcher
09:30:40 DISPATCHER: Trying to submit another job.
09:30:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:30:40 DISPATCHER: starting job (8, 0, 13) on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:30:40 DISPATCHER: job (8, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:30:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:30:40 WORKER: start processing job (8, 0, 13)
09:30:40 WORKER: args: ()
09:30:40 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 738, 'last_n_outputs': 49, 'leak_rate': 0.7740170709495311, 'lr': 0.0018459813360296798, 'optimizer': 'SGD', 'sparsity': 0.7994877943829583, 'steps_to_train': 57, 'weight_decay': 0.010860806393678396}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:31:27 DISPATCHER: Starting worker discovery
09:31:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:31:27 DISPATCHER: Finished worker discovery
09:31:41 WORKER: done with job (8, 0, 13), trying to register it.
09:31:41 WORKER: registered result for job (8, 0, 13) with dispatcher
09:31:41 DISPATCHER: job (8, 0, 13) finished
09:31:41 DISPATCHER: register_result: lock acquired
09:31:41 DISPATCHER: job (8, 0, 13) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
09:31:41 job_id: (8, 0, 13)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 738, 'last_n_outputs': 49, 'leak_rate': 0.7740170709495311, 'lr': 0.0018459813360296798, 'optimizer': 'SGD', 'sparsity': 0.7994877943829583, 'steps_to_train': 57, 'weight_decay': 0.010860806393678396}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7041917719509465, 'info': {'data05': 0.7041917719509465, 'config': "{'batch_size': 128, 'hidden_dim': 738, 'last_n_outputs': 49, 'leak_rate': 0.7740170709495311, 'lr': 0.0018459813360296798, 'optimizer': 'SGD', 'sparsity': 0.7994877943829583, 'steps_to_train': 57, 'weight_decay': 0.010860806393678396}"}}
exception: None

09:31:41 job_callback for (8, 0, 13) started
09:31:41 job_callback for (8, 0, 13) got condition
09:31:41 DISPATCHER: Trying to submit another job.
09:31:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:31:41 HBMASTER: Trying to run another job!
09:31:41 job_callback for (8, 0, 13) finished
09:31:41 start sampling a new configuration.
09:31:41 done sampling a new configuration.
09:31:41 HBMASTER: schedule new run for iteration 8
09:31:41 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
09:31:41 HBMASTER: submitting job (8, 0, 14) to dispatcher
09:31:41 DISPATCHER: trying to submit job (8, 0, 14)
09:31:41 DISPATCHER: trying to notify the job_runner thread.
09:31:41 HBMASTER: job (8, 0, 14) submitted to dispatcher
09:31:41 DISPATCHER: Trying to submit another job.
09:31:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:31:41 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:31:41 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:31:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:31:41 WORKER: start processing job (8, 0, 14)
09:31:41 WORKER: args: ()
09:31:41 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 589, 'last_n_outputs': 11, 'leak_rate': 0.7601587640169951, 'lr': 0.004328153931648257, 'optimizer': 'Adam', 'sparsity': 0.8439934000990518, 'steps_to_train': 40, 'weight_decay': 0.17023319865909115}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:32:27 DISPATCHER: Starting worker discovery
09:32:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:32:27 DISPATCHER: Finished worker discovery
09:32:40 WORKER: done with job (8, 0, 14), trying to register it.
09:32:40 WORKER: registered result for job (8, 0, 14) with dispatcher
09:32:40 DISPATCHER: job (8, 0, 14) finished
09:32:40 DISPATCHER: register_result: lock acquired
09:32:40 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
09:32:40 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 589, 'last_n_outputs': 11, 'leak_rate': 0.7601587640169951, 'lr': 0.004328153931648257, 'optimizer': 'Adam', 'sparsity': 0.8439934000990518, 'steps_to_train': 40, 'weight_decay': 0.17023319865909115}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.23807543952167978, 'info': {'data05': 0.23807543952167978, 'config': "{'batch_size': 32, 'hidden_dim': 589, 'last_n_outputs': 11, 'leak_rate': 0.7601587640169951, 'lr': 0.004328153931648257, 'optimizer': 'Adam', 'sparsity': 0.8439934000990518, 'steps_to_train': 40, 'weight_decay': 0.17023319865909115}"}}
exception: None

09:32:40 job_callback for (8, 0, 14) started
09:32:40 DISPATCHER: Trying to submit another job.
09:32:40 job_callback for (8, 0, 14) got condition
09:32:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:32:40 HBMASTER: Trying to run another job!
09:32:40 job_callback for (8, 0, 14) finished
09:32:40 start sampling a new configuration.
09:32:40 done sampling a new configuration.
09:32:40 HBMASTER: schedule new run for iteration 8
09:32:40 HBMASTER: trying submitting job (8, 0, 15) to dispatcher
09:32:40 HBMASTER: submitting job (8, 0, 15) to dispatcher
09:32:40 DISPATCHER: trying to submit job (8, 0, 15)
09:32:40 DISPATCHER: trying to notify the job_runner thread.
09:32:40 HBMASTER: job (8, 0, 15) submitted to dispatcher
09:32:40 DISPATCHER: Trying to submit another job.
09:32:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:32:40 DISPATCHER: starting job (8, 0, 15) on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:32:40 DISPATCHER: job (8, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:32:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:32:40 WORKER: start processing job (8, 0, 15)
09:32:40 WORKER: args: ()
09:32:40 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 667, 'last_n_outputs': 11, 'leak_rate': 0.8933553529862565, 'lr': 0.008772414872626824, 'optimizer': 'SGD', 'sparsity': 0.7904991668588046, 'steps_to_train': 56, 'weight_decay': 0.022338489632575356}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:33:27 DISPATCHER: Starting worker discovery
09:33:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:33:27 DISPATCHER: Finished worker discovery
09:33:36 WORKER: done with job (8, 0, 15), trying to register it.
09:33:36 WORKER: registered result for job (8, 0, 15) with dispatcher
09:33:36 DISPATCHER: job (8, 0, 15) finished
09:33:36 DISPATCHER: register_result: lock acquired
09:33:36 DISPATCHER: job (8, 0, 15) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
09:33:36 job_id: (8, 0, 15)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 667, 'last_n_outputs': 11, 'leak_rate': 0.8933553529862565, 'lr': 0.008772414872626824, 'optimizer': 'SGD', 'sparsity': 0.7904991668588046, 'steps_to_train': 56, 'weight_decay': 0.022338489632575356}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4298081120166322, 'info': {'data05': 0.4298081120166322, 'config': "{'batch_size': 64, 'hidden_dim': 667, 'last_n_outputs': 11, 'leak_rate': 0.8933553529862565, 'lr': 0.008772414872626824, 'optimizer': 'SGD', 'sparsity': 0.7904991668588046, 'steps_to_train': 56, 'weight_decay': 0.022338489632575356}"}}
exception: None

09:33:36 job_callback for (8, 0, 15) started
09:33:36 DISPATCHER: Trying to submit another job.
09:33:36 job_callback for (8, 0, 15) got condition
09:33:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:33:36 HBMASTER: Trying to run another job!
09:33:36 job_callback for (8, 0, 15) finished
09:33:36 start sampling a new configuration.
09:33:36 best_vector: [2, 0.9454675189109366, 0.9543052765955062, 0.24803625267607793, 0.16211222661863955, 1, 0.909453902459409, 0.7133644659479598, 0.5435459396442259], 0.015786842013845007, 2.5292243585316436, 0.03992846536570754
09:33:36 done sampling a new configuration.
09:33:36 HBMASTER: schedule new run for iteration 8
09:33:36 HBMASTER: trying submitting job (8, 0, 16) to dispatcher
09:33:36 HBMASTER: submitting job (8, 0, 16) to dispatcher
09:33:36 DISPATCHER: trying to submit job (8, 0, 16)
09:33:36 DISPATCHER: trying to notify the job_runner thread.
09:33:36 HBMASTER: job (8, 0, 16) submitted to dispatcher
09:33:36 DISPATCHER: Trying to submit another job.
09:33:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:33:36 DISPATCHER: starting job (8, 0, 16) on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:33:36 DISPATCHER: job (8, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:33:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:33:36 WORKER: start processing job (8, 0, 16)
09:33:36 WORKER: args: ()
09:33:36 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 957, 'last_n_outputs': 49, 'leak_rate': 0.8120090631690194, 'lr': 0.0021097182184429356, 'optimizer': 'SGD', 'sparsity': 0.9682689365902581, 'steps_to_train': 74, 'weight_decay': 0.05095297795539562}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:34:27 DISPATCHER: Starting worker discovery
09:34:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:34:27 DISPATCHER: Finished worker discovery
09:34:39 WORKER: done with job (8, 0, 16), trying to register it.
09:34:39 WORKER: registered result for job (8, 0, 16) with dispatcher
09:34:39 DISPATCHER: job (8, 0, 16) finished
09:34:39 DISPATCHER: register_result: lock acquired
09:34:39 DISPATCHER: job (8, 0, 16) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
09:34:39 job_id: (8, 0, 16)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 957, 'last_n_outputs': 49, 'leak_rate': 0.8120090631690194, 'lr': 0.0021097182184429356, 'optimizer': 'SGD', 'sparsity': 0.9682689365902581, 'steps_to_train': 74, 'weight_decay': 0.05095297795539562}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6659394256456249, 'info': {'data05': 0.6659394256456249, 'config': "{'batch_size': 64, 'hidden_dim': 957, 'last_n_outputs': 49, 'leak_rate': 0.8120090631690194, 'lr': 0.0021097182184429356, 'optimizer': 'SGD', 'sparsity': 0.9682689365902581, 'steps_to_train': 74, 'weight_decay': 0.05095297795539562}"}}
exception: None

09:34:39 job_callback for (8, 0, 16) started
09:34:39 DISPATCHER: Trying to submit another job.
09:34:39 job_callback for (8, 0, 16) got condition
09:34:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:34:39 HBMASTER: Trying to run another job!
09:34:39 job_callback for (8, 0, 16) finished
09:34:39 start sampling a new configuration.
09:34:39 done sampling a new configuration.
09:34:39 HBMASTER: schedule new run for iteration 8
09:34:39 HBMASTER: trying submitting job (8, 0, 17) to dispatcher
09:34:39 HBMASTER: submitting job (8, 0, 17) to dispatcher
09:34:39 DISPATCHER: trying to submit job (8, 0, 17)
09:34:39 DISPATCHER: trying to notify the job_runner thread.
09:34:39 HBMASTER: job (8, 0, 17) submitted to dispatcher
09:34:39 DISPATCHER: Trying to submit another job.
09:34:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:34:39 DISPATCHER: starting job (8, 0, 17) on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:34:39 DISPATCHER: job (8, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:34:39 WORKER: start processing job (8, 0, 17)
09:34:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:34:39 WORKER: args: ()
09:34:39 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 267, 'last_n_outputs': 40, 'leak_rate': 0.9065758620793739, 'lr': 0.09288540948237607, 'optimizer': 'SGD', 'sparsity': 0.9081618807684712, 'steps_to_train': 71, 'weight_decay': 0.13149975378527318}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:35:27 DISPATCHER: Starting worker discovery
09:35:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:35:27 DISPATCHER: Finished worker discovery
09:35:40 WORKER: done with job (8, 0, 17), trying to register it.
09:35:40 WORKER: registered result for job (8, 0, 17) with dispatcher
09:35:40 DISPATCHER: job (8, 0, 17) finished
09:35:40 DISPATCHER: register_result: lock acquired
09:35:40 DISPATCHER: job (8, 0, 17) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
09:35:40 job_id: (8, 0, 17)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 267, 'last_n_outputs': 40, 'leak_rate': 0.9065758620793739, 'lr': 0.09288540948237607, 'optimizer': 'SGD', 'sparsity': 0.9081618807684712, 'steps_to_train': 71, 'weight_decay': 0.13149975378527318}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.22315842909567637, 'info': {'data05': 0.22315842909567637, 'config': "{'batch_size': 16, 'hidden_dim': 267, 'last_n_outputs': 40, 'leak_rate': 0.9065758620793739, 'lr': 0.09288540948237607, 'optimizer': 'SGD', 'sparsity': 0.9081618807684712, 'steps_to_train': 71, 'weight_decay': 0.13149975378527318}"}}
exception: None

09:35:40 job_callback for (8, 0, 17) started
09:35:40 job_callback for (8, 0, 17) got condition
09:35:40 DISPATCHER: Trying to submit another job.
09:35:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:35:40 HBMASTER: Trying to run another job!
09:35:40 job_callback for (8, 0, 17) finished
09:35:40 start sampling a new configuration.
09:35:40 done sampling a new configuration.
09:35:40 HBMASTER: schedule new run for iteration 8
09:35:40 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
09:35:40 HBMASTER: submitting job (8, 0, 18) to dispatcher
09:35:40 DISPATCHER: trying to submit job (8, 0, 18)
09:35:40 DISPATCHER: trying to notify the job_runner thread.
09:35:40 HBMASTER: job (8, 0, 18) submitted to dispatcher
09:35:40 DISPATCHER: Trying to submit another job.
09:35:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:35:40 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:35:40 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:35:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:35:40 WORKER: start processing job (8, 0, 18)
09:35:40 WORKER: args: ()
09:35:40 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 920, 'last_n_outputs': 41, 'leak_rate': 0.9593258241432709, 'lr': 0.03316577954186267, 'optimizer': 'SGD', 'sparsity': 0.8342013734882947, 'steps_to_train': 38, 'weight_decay': 0.018861116176900488}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:36:27 DISPATCHER: Starting worker discovery
09:36:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:36:27 DISPATCHER: Finished worker discovery
09:36:38 WORKER: done with job (8, 0, 18), trying to register it.
09:36:38 WORKER: registered result for job (8, 0, 18) with dispatcher
09:36:38 DISPATCHER: job (8, 0, 18) finished
09:36:38 DISPATCHER: register_result: lock acquired
09:36:38 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
09:36:38 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 920, 'last_n_outputs': 41, 'leak_rate': 0.9593258241432709, 'lr': 0.03316577954186267, 'optimizer': 'SGD', 'sparsity': 0.8342013734882947, 'steps_to_train': 38, 'weight_decay': 0.018861116176900488}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7388129651432032, 'info': {'data05': 0.7388129651432032, 'config': "{'batch_size': 128, 'hidden_dim': 920, 'last_n_outputs': 41, 'leak_rate': 0.9593258241432709, 'lr': 0.03316577954186267, 'optimizer': 'SGD', 'sparsity': 0.8342013734882947, 'steps_to_train': 38, 'weight_decay': 0.018861116176900488}"}}
exception: None

09:36:38 job_callback for (8, 0, 18) started
09:36:38 DISPATCHER: Trying to submit another job.
09:36:38 job_callback for (8, 0, 18) got condition
09:36:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:36:38 HBMASTER: Trying to run another job!
09:36:38 job_callback for (8, 0, 18) finished
09:36:38 start sampling a new configuration.
09:36:38 best_vector: [1, 0.9439898545991046, 0.9365130907346364, 0.6506784988916694, 0.42234498268347365, 1, 0.5964321909327553, 0.9214300417507628, 0.5497405707394748], 0.013221970771475088, 4.619349683697816, 0.06107690650107522
09:36:38 done sampling a new configuration.
09:36:38 HBMASTER: schedule new run for iteration 8
09:36:38 HBMASTER: trying submitting job (8, 0, 19) to dispatcher
09:36:38 HBMASTER: submitting job (8, 0, 19) to dispatcher
09:36:38 DISPATCHER: trying to submit job (8, 0, 19)
09:36:38 DISPATCHER: trying to notify the job_runner thread.
09:36:38 HBMASTER: job (8, 0, 19) submitted to dispatcher
09:36:38 DISPATCHER: Trying to submit another job.
09:36:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:36:38 DISPATCHER: starting job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:36:38 DISPATCHER: job (8, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:36:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:36:38 WORKER: start processing job (8, 0, 19)
09:36:38 WORKER: args: ()
09:36:38 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 956, 'last_n_outputs': 48, 'leak_rate': 0.9126696247229173, 'lr': 0.006993425702977817, 'optimizer': 'SGD', 'sparsity': 0.8931437258238613, 'steps_to_train': 93, 'weight_decay': 0.05190736371383446}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:37:27 DISPATCHER: Starting worker discovery
09:37:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:37:27 DISPATCHER: Finished worker discovery
09:37:36 WORKER: done with job (8, 0, 19), trying to register it.
09:37:36 WORKER: registered result for job (8, 0, 19) with dispatcher
09:37:36 DISPATCHER: job (8, 0, 19) finished
09:37:36 DISPATCHER: register_result: lock acquired
09:37:36 DISPATCHER: job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
09:37:36 job_id: (8, 0, 19)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 956, 'last_n_outputs': 48, 'leak_rate': 0.9126696247229173, 'lr': 0.006993425702977817, 'optimizer': 'SGD', 'sparsity': 0.8931437258238613, 'steps_to_train': 93, 'weight_decay': 0.05190736371383446}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7283953753360112, 'info': {'data05': 0.7283953753360112, 'config': "{'batch_size': 32, 'hidden_dim': 956, 'last_n_outputs': 48, 'leak_rate': 0.9126696247229173, 'lr': 0.006993425702977817, 'optimizer': 'SGD', 'sparsity': 0.8931437258238613, 'steps_to_train': 93, 'weight_decay': 0.05190736371383446}"}}
exception: None

09:37:36 job_callback for (8, 0, 19) started
09:37:36 DISPATCHER: Trying to submit another job.
09:37:36 job_callback for (8, 0, 19) got condition
09:37:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:37:36 HBMASTER: Trying to run another job!
09:37:36 job_callback for (8, 0, 19) finished
09:37:36 start sampling a new configuration.
09:37:36 done sampling a new configuration.
09:37:36 HBMASTER: schedule new run for iteration 8
09:37:36 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
09:37:36 HBMASTER: submitting job (8, 0, 20) to dispatcher
09:37:36 DISPATCHER: trying to submit job (8, 0, 20)
09:37:36 DISPATCHER: trying to notify the job_runner thread.
09:37:36 HBMASTER: job (8, 0, 20) submitted to dispatcher
09:37:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:37:36 DISPATCHER: Trying to submit another job.
09:37:36 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:37:36 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:37:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:37:36 WORKER: start processing job (8, 0, 20)
09:37:36 WORKER: args: ()
09:37:36 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 399, 'last_n_outputs': 23, 'leak_rate': 0.9873625795135762, 'lr': 0.0017185290644782653, 'optimizer': 'Adam', 'sparsity': 0.8457811304598502, 'steps_to_train': 38, 'weight_decay': 0.03461832852951767}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:38:27 DISPATCHER: Starting worker discovery
09:38:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:38:27 DISPATCHER: Finished worker discovery
09:38:33 WORKER: done with job (8, 0, 20), trying to register it.
09:38:33 WORKER: registered result for job (8, 0, 20) with dispatcher
09:38:33 DISPATCHER: job (8, 0, 20) finished
09:38:33 DISPATCHER: register_result: lock acquired
09:38:33 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
09:38:33 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 399, 'last_n_outputs': 23, 'leak_rate': 0.9873625795135762, 'lr': 0.0017185290644782653, 'optimizer': 'Adam', 'sparsity': 0.8457811304598502, 'steps_to_train': 38, 'weight_decay': 0.03461832852951767}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6261289921186056, 'info': {'data05': 0.6261289921186056, 'config': "{'batch_size': 128, 'hidden_dim': 399, 'last_n_outputs': 23, 'leak_rate': 0.9873625795135762, 'lr': 0.0017185290644782653, 'optimizer': 'Adam', 'sparsity': 0.8457811304598502, 'steps_to_train': 38, 'weight_decay': 0.03461832852951767}"}}
exception: None

09:38:33 job_callback for (8, 0, 20) started
09:38:33 DISPATCHER: Trying to submit another job.
09:38:33 job_callback for (8, 0, 20) got condition
09:38:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:38:33 HBMASTER: Trying to run another job!
09:38:33 job_callback for (8, 0, 20) finished
09:38:33 start sampling a new configuration.
09:38:33 best_vector: [1, 0.9321135103173426, 0.9477263497582187, 0.3071696368022114, 0.5580082826748296, 1, 0.6800051341365309, 0.015343472682704445, 0.6824288411966158], 0.0053156833365766805, 6.289386152523399, 0.03343238516826475
09:38:33 done sampling a new configuration.
09:38:33 HBMASTER: schedule new run for iteration 8
09:38:33 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
09:38:33 HBMASTER: submitting job (8, 0, 21) to dispatcher
09:38:33 DISPATCHER: trying to submit job (8, 0, 21)
09:38:33 DISPATCHER: trying to notify the job_runner thread.
09:38:33 HBMASTER: job (8, 0, 21) submitted to dispatcher
09:38:33 DISPATCHER: Trying to submit another job.
09:38:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:38:33 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:38:33 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:38:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:38:33 WORKER: start processing job (8, 0, 21)
09:38:33 WORKER: args: ()
09:38:33 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 946, 'last_n_outputs': 48, 'leak_rate': 0.8267924092005529, 'lr': 0.013062207105243386, 'optimizer': 'SGD', 'sparsity': 0.9132012321927674, 'steps_to_train': 11, 'weight_decay': 0.07724322401934976}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:39:27 DISPATCHER: Starting worker discovery
09:39:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:39:27 DISPATCHER: Finished worker discovery
09:39:31 WORKER: done with job (8, 0, 21), trying to register it.
09:39:31 WORKER: registered result for job (8, 0, 21) with dispatcher
09:39:31 DISPATCHER: job (8, 0, 21) finished
09:39:31 DISPATCHER: register_result: lock acquired
09:39:31 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
09:39:31 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 946, 'last_n_outputs': 48, 'leak_rate': 0.8267924092005529, 'lr': 0.013062207105243386, 'optimizer': 'SGD', 'sparsity': 0.9132012321927674, 'steps_to_train': 11, 'weight_decay': 0.07724322401934976}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.720104760464519, 'info': {'data05': 0.720104760464519, 'config': "{'batch_size': 32, 'hidden_dim': 946, 'last_n_outputs': 48, 'leak_rate': 0.8267924092005529, 'lr': 0.013062207105243386, 'optimizer': 'SGD', 'sparsity': 0.9132012321927674, 'steps_to_train': 11, 'weight_decay': 0.07724322401934976}"}}
exception: None

09:39:31 job_callback for (8, 0, 21) started
09:39:31 DISPATCHER: Trying to submit another job.
09:39:31 job_callback for (8, 0, 21) got condition
09:39:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:39:31 HBMASTER: Trying to run another job!
09:39:31 job_callback for (8, 0, 21) finished
09:39:31 start sampling a new configuration.
09:39:31 best_vector: [2, 0.6554022067450647, 0.9894120716095121, 0.10804745625752646, 0.12985048491922907, 1, 0.3902707546757087, 0.9388031812768681, 0.07325693843574464], 0.005181493619036187, 1.7079655554127016, 0.00884981262690451
09:39:31 done sampling a new configuration.
09:39:31 HBMASTER: schedule new run for iteration 8
09:39:31 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
09:39:31 HBMASTER: submitting job (8, 0, 22) to dispatcher
09:39:31 DISPATCHER: trying to submit job (8, 0, 22)
09:39:31 DISPATCHER: trying to notify the job_runner thread.
09:39:31 HBMASTER: job (8, 0, 22) submitted to dispatcher
09:39:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:39:31 DISPATCHER: Trying to submit another job.
09:39:31 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:39:31 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:39:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:39:31 WORKER: start processing job (8, 0, 22)
09:39:31 WORKER: args: ()
09:39:31 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 724, 'last_n_outputs': 50, 'leak_rate': 0.7770118640643816, 'lr': 0.001818448348680061, 'optimizer': 'SGD', 'sparsity': 0.8436649811221701, 'steps_to_train': 95, 'weight_decay': 0.012454017576062432}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:40:27 DISPATCHER: Starting worker discovery
09:40:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:40:27 DISPATCHER: Finished worker discovery
09:40:32 WORKER: done with job (8, 0, 22), trying to register it.
09:40:32 WORKER: registered result for job (8, 0, 22) with dispatcher
09:40:32 DISPATCHER: job (8, 0, 22) finished
09:40:32 DISPATCHER: register_result: lock acquired
09:40:32 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
09:40:32 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 724, 'last_n_outputs': 50, 'leak_rate': 0.7770118640643816, 'lr': 0.001818448348680061, 'optimizer': 'SGD', 'sparsity': 0.8436649811221701, 'steps_to_train': 95, 'weight_decay': 0.012454017576062432}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6974804055392547, 'info': {'data05': 0.6974804055392547, 'config': "{'batch_size': 64, 'hidden_dim': 724, 'last_n_outputs': 50, 'leak_rate': 0.7770118640643816, 'lr': 0.001818448348680061, 'optimizer': 'SGD', 'sparsity': 0.8436649811221701, 'steps_to_train': 95, 'weight_decay': 0.012454017576062432}"}}
exception: None

09:40:32 job_callback for (8, 0, 22) started
09:40:32 job_callback for (8, 0, 22) got condition
09:40:32 DISPATCHER: Trying to submit another job.
09:40:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:40:32 HBMASTER: Trying to run another job!
09:40:32 job_callback for (8, 0, 22) finished
09:40:32 start sampling a new configuration.
09:40:32 best_vector: [0, 0.7991416546110127, 0.946315348455709, 0.938764036900106, 0.37482920264458464, 1, 0.14839338271780983, 0.6333707226752929, 0.4307466779497042], 0.002566016923107096, 6.046801724307147, 0.015516195555245306
09:40:32 done sampling a new configuration.
09:40:32 HBMASTER: schedule new run for iteration 8
09:40:32 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
09:40:32 HBMASTER: submitting job (8, 0, 23) to dispatcher
09:40:32 DISPATCHER: trying to submit job (8, 0, 23)
09:40:32 DISPATCHER: trying to notify the job_runner thread.
09:40:32 HBMASTER: job (8, 0, 23) submitted to dispatcher
09:40:32 DISPATCHER: Trying to submit another job.
09:40:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:40:32 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:40:32 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:40:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:40:32 WORKER: start processing job (8, 0, 23)
09:40:32 WORKER: args: ()
09:40:32 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 840, 'last_n_outputs': 48, 'leak_rate': 0.9846910092250265, 'lr': 0.005618991890251881, 'optimizer': 'SGD', 'sparsity': 0.7856144118522743, 'steps_to_train': 67, 'weight_decay': 0.036342462295976825}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:41:27 DISPATCHER: Starting worker discovery
09:41:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:41:27 DISPATCHER: Finished worker discovery
09:41:33 WORKER: done with job (8, 0, 23), trying to register it.
09:41:33 WORKER: registered result for job (8, 0, 23) with dispatcher
09:41:33 DISPATCHER: job (8, 0, 23) finished
09:41:33 DISPATCHER: register_result: lock acquired
09:41:33 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
09:41:33 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 840, 'last_n_outputs': 48, 'leak_rate': 0.9846910092250265, 'lr': 0.005618991890251881, 'optimizer': 'SGD', 'sparsity': 0.7856144118522743, 'steps_to_train': 67, 'weight_decay': 0.036342462295976825}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7042444292582983, 'info': {'data05': 0.7042444292582983, 'config': "{'batch_size': 16, 'hidden_dim': 840, 'last_n_outputs': 48, 'leak_rate': 0.9846910092250265, 'lr': 0.005618991890251881, 'optimizer': 'SGD', 'sparsity': 0.7856144118522743, 'steps_to_train': 67, 'weight_decay': 0.036342462295976825}"}}
exception: None

09:41:33 job_callback for (8, 0, 23) started
09:41:33 job_callback for (8, 0, 23) got condition
09:41:33 DISPATCHER: Trying to submit another job.
09:41:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:41:33 HBMASTER: Trying to run another job!
09:41:33 job_callback for (8, 0, 23) finished
09:41:33 start sampling a new configuration.
09:41:33 best_vector: [1, 0.9434384932669414, 0.9431054130291141, 0.25009875875166054, 0.15025508613923017, 1, 0.6962992801950968, 0.18046463825683756, 0.9932056066650095], 0.0018815894475667245, 8.377372881881247, 0.015762776412879393
09:41:33 done sampling a new configuration.
09:41:33 HBMASTER: schedule new run for iteration 8
09:41:33 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
09:41:33 HBMASTER: submitting job (8, 0, 24) to dispatcher
09:41:33 DISPATCHER: trying to submit job (8, 0, 24)
09:41:33 DISPATCHER: trying to notify the job_runner thread.
09:41:33 HBMASTER: job (8, 0, 24) submitted to dispatcher
09:41:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:41:33 DISPATCHER: Trying to submit another job.
09:41:33 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:41:33 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:41:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:41:33 WORKER: start processing job (8, 0, 24)
09:41:33 WORKER: args: ()
09:41:33 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 955, 'last_n_outputs': 48, 'leak_rate': 0.8125246896879151, 'lr': 0.0019976075569311576, 'optimizer': 'SGD', 'sparsity': 0.9171118272468233, 'steps_to_train': 26, 'weight_decay': 0.19597031293773154}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:42:27 DISPATCHER: Starting worker discovery
09:42:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:42:27 DISPATCHER: Finished worker discovery
09:42:30 WORKER: done with job (8, 0, 24), trying to register it.
09:42:30 WORKER: registered result for job (8, 0, 24) with dispatcher
09:42:30 DISPATCHER: job (8, 0, 24) finished
09:42:30 DISPATCHER: register_result: lock acquired
09:42:30 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
09:42:30 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 955, 'last_n_outputs': 48, 'leak_rate': 0.8125246896879151, 'lr': 0.0019976075569311576, 'optimizer': 'SGD', 'sparsity': 0.9171118272468233, 'steps_to_train': 26, 'weight_decay': 0.19597031293773154}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6868892252278929, 'info': {'data05': 0.6868892252278929, 'config': "{'batch_size': 32, 'hidden_dim': 955, 'last_n_outputs': 48, 'leak_rate': 0.8125246896879151, 'lr': 0.0019976075569311576, 'optimizer': 'SGD', 'sparsity': 0.9171118272468233, 'steps_to_train': 26, 'weight_decay': 0.19597031293773154}"}}
exception: None

09:42:30 job_callback for (8, 0, 24) started
09:42:30 DISPATCHER: Trying to submit another job.
09:42:30 job_callback for (8, 0, 24) got condition
09:42:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:42:30 HBMASTER: Trying to run another job!
09:42:30 job_callback for (8, 0, 24) finished
09:42:30 start sampling a new configuration.
09:42:30 done sampling a new configuration.
09:42:30 HBMASTER: schedule new run for iteration 8
09:42:30 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
09:42:30 HBMASTER: submitting job (8, 0, 25) to dispatcher
09:42:30 DISPATCHER: trying to submit job (8, 0, 25)
09:42:30 DISPATCHER: trying to notify the job_runner thread.
09:42:30 HBMASTER: job (8, 0, 25) submitted to dispatcher
09:42:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:42:30 DISPATCHER: Trying to submit another job.
09:42:30 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:42:30 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:42:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:42:30 WORKER: start processing job (8, 0, 25)
09:42:30 WORKER: args: ()
09:42:30 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 701, 'last_n_outputs': 37, 'leak_rate': 0.8190842778173294, 'lr': 0.0030459949550492404, 'optimizer': 'SGD', 'sparsity': 0.777552861835175, 'steps_to_train': 41, 'weight_decay': 0.11667753787682628}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:43:27 DISPATCHER: Starting worker discovery
09:43:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:43:27 DISPATCHER: Finished worker discovery
09:43:29 WORKER: done with job (8, 0, 25), trying to register it.
09:43:29 WORKER: registered result for job (8, 0, 25) with dispatcher
09:43:29 DISPATCHER: job (8, 0, 25) finished
09:43:29 DISPATCHER: register_result: lock acquired
09:43:29 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
09:43:29 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 701, 'last_n_outputs': 37, 'leak_rate': 0.8190842778173294, 'lr': 0.0030459949550492404, 'optimizer': 'SGD', 'sparsity': 0.777552861835175, 'steps_to_train': 41, 'weight_decay': 0.11667753787682628}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.671380292247272, 'info': {'data05': 0.671380292247272, 'config': "{'batch_size': 128, 'hidden_dim': 701, 'last_n_outputs': 37, 'leak_rate': 0.8190842778173294, 'lr': 0.0030459949550492404, 'optimizer': 'SGD', 'sparsity': 0.777552861835175, 'steps_to_train': 41, 'weight_decay': 0.11667753787682628}"}}
exception: None

09:43:29 job_callback for (8, 0, 25) started
09:43:29 DISPATCHER: Trying to submit another job.
09:43:29 job_callback for (8, 0, 25) got condition
09:43:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:43:29 HBMASTER: Trying to run another job!
09:43:29 job_callback for (8, 0, 25) finished
09:43:29 start sampling a new configuration.
09:43:29 best_vector: [1, 0.9647106964911822, 0.9603513253481369, 0.8190150042874902, 0.02855138732626772, 1, 0.7855516489999563, 0.5426725651245883, 0.9694769418773317], 0.008837914045692122, 2.748942111374284, 0.024294914096909342
09:43:29 done sampling a new configuration.
09:43:29 HBMASTER: schedule new run for iteration 8
09:43:29 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
09:43:29 HBMASTER: submitting job (8, 0, 26) to dispatcher
09:43:29 DISPATCHER: trying to submit job (8, 0, 26)
09:43:29 DISPATCHER: trying to notify the job_runner thread.
09:43:29 HBMASTER: job (8, 0, 26) submitted to dispatcher
09:43:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:43:29 DISPATCHER: Trying to submit another job.
09:43:29 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:43:29 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:43:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:43:29 WORKER: start processing job (8, 0, 26)
09:43:29 WORKER: args: ()
09:43:29 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 972, 'last_n_outputs': 49, 'leak_rate': 0.9547537510718725, 'lr': 0.0011405196566198522, 'optimizer': 'SGD', 'sparsity': 0.9385323957599895, 'steps_to_train': 59, 'weight_decay': 0.18252341318934995}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:44:26 WORKER: done with job (8, 0, 26), trying to register it.
09:44:26 WORKER: registered result for job (8, 0, 26) with dispatcher
09:44:26 DISPATCHER: job (8, 0, 26) finished
09:44:26 DISPATCHER: register_result: lock acquired
09:44:26 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
09:44:26 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 972, 'last_n_outputs': 49, 'leak_rate': 0.9547537510718725, 'lr': 0.0011405196566198522, 'optimizer': 'SGD', 'sparsity': 0.9385323957599895, 'steps_to_train': 59, 'weight_decay': 0.18252341318934995}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5412701235586016, 'info': {'data05': 0.5412701235586016, 'config': "{'batch_size': 32, 'hidden_dim': 972, 'last_n_outputs': 49, 'leak_rate': 0.9547537510718725, 'lr': 0.0011405196566198522, 'optimizer': 'SGD', 'sparsity': 0.9385323957599895, 'steps_to_train': 59, 'weight_decay': 0.18252341318934995}"}}
exception: None

09:44:26 job_callback for (8, 0, 26) started
09:44:26 job_callback for (8, 0, 26) got condition
09:44:26 DISPATCHER: Trying to submit another job.
09:44:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:44:26 HBMASTER: Trying to run another job!
09:44:26 job_callback for (8, 0, 26) finished
09:44:26 ITERATION: Advancing config (8, 0, 0) to next budget 133.333333
09:44:26 ITERATION: Advancing config (8, 0, 5) to next budget 133.333333
09:44:26 ITERATION: Advancing config (8, 0, 6) to next budget 133.333333
09:44:26 ITERATION: Advancing config (8, 0, 8) to next budget 133.333333
09:44:26 ITERATION: Advancing config (8, 0, 13) to next budget 133.333333
09:44:26 ITERATION: Advancing config (8, 0, 18) to next budget 133.333333
09:44:26 ITERATION: Advancing config (8, 0, 19) to next budget 133.333333
09:44:26 ITERATION: Advancing config (8, 0, 21) to next budget 133.333333
09:44:26 ITERATION: Advancing config (8, 0, 23) to next budget 133.333333
09:44:26 HBMASTER: schedule new run for iteration 8
09:44:26 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
09:44:26 HBMASTER: submitting job (8, 0, 0) to dispatcher
09:44:26 DISPATCHER: trying to submit job (8, 0, 0)
09:44:26 DISPATCHER: trying to notify the job_runner thread.
09:44:26 HBMASTER: job (8, 0, 0) submitted to dispatcher
09:44:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:44:26 DISPATCHER: Trying to submit another job.
09:44:26 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:44:26 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:44:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:44:26 WORKER: start processing job (8, 0, 0)
09:44:26 WORKER: args: ()
09:44:26 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 788, 'last_n_outputs': 50, 'leak_rate': 0.991098845449354, 'lr': 0.00690248025107967, 'optimizer': 'SGD', 'sparsity': 0.9169726893032305, 'steps_to_train': 92, 'weight_decay': 0.08072489235932702}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:44:27 DISPATCHER: Starting worker discovery
09:44:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:44:27 DISPATCHER: Finished worker discovery
09:45:27 DISPATCHER: Starting worker discovery
09:45:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:45:27 DISPATCHER: Finished worker discovery
09:46:27 DISPATCHER: Starting worker discovery
09:46:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:46:27 DISPATCHER: Finished worker discovery
09:46:54 WORKER: done with job (8, 0, 0), trying to register it.
09:46:54 WORKER: registered result for job (8, 0, 0) with dispatcher
09:46:54 DISPATCHER: job (8, 0, 0) finished
09:46:54 DISPATCHER: register_result: lock acquired
09:46:54 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
09:46:54 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 788, 'last_n_outputs': 50, 'leak_rate': 0.991098845449354, 'lr': 0.00690248025107967, 'optimizer': 'SGD', 'sparsity': 0.9169726893032305, 'steps_to_train': 92, 'weight_decay': 0.08072489235932702}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7511623956644282, 'info': {'data05': 0.7511623956644282, 'config': "{'batch_size': 128, 'hidden_dim': 788, 'last_n_outputs': 50, 'leak_rate': 0.991098845449354, 'lr': 0.00690248025107967, 'optimizer': 'SGD', 'sparsity': 0.9169726893032305, 'steps_to_train': 92, 'weight_decay': 0.08072489235932702}"}}
exception: None

09:46:54 job_callback for (8, 0, 0) started
09:46:54 DISPATCHER: Trying to submit another job.
09:46:54 job_callback for (8, 0, 0) got condition
09:46:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:46:54 HBMASTER: Trying to run another job!
09:46:54 job_callback for (8, 0, 0) finished
09:46:54 HBMASTER: schedule new run for iteration 8
09:46:54 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
09:46:54 HBMASTER: submitting job (8, 0, 5) to dispatcher
09:46:54 DISPATCHER: trying to submit job (8, 0, 5)
09:46:54 DISPATCHER: trying to notify the job_runner thread.
09:46:54 HBMASTER: job (8, 0, 5) submitted to dispatcher
09:46:54 DISPATCHER: Trying to submit another job.
09:46:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:46:54 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:46:54 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:46:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:46:54 WORKER: start processing job (8, 0, 5)
09:46:54 WORKER: args: ()
09:46:54 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 993, 'last_n_outputs': 48, 'leak_rate': 0.9547808947013059, 'lr': 0.00752522533444974, 'optimizer': 'SGD', 'sparsity': 0.8171247409967092, 'steps_to_train': 77, 'weight_decay': 0.022464719671026697}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:47:27 DISPATCHER: Starting worker discovery
09:47:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:47:27 DISPATCHER: Finished worker discovery
09:48:27 DISPATCHER: Starting worker discovery
09:48:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:48:27 DISPATCHER: Finished worker discovery
09:49:27 DISPATCHER: Starting worker discovery
09:49:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:49:27 DISPATCHER: Finished worker discovery
09:49:28 WORKER: done with job (8, 0, 5), trying to register it.
09:49:28 WORKER: registered result for job (8, 0, 5) with dispatcher
09:49:28 DISPATCHER: job (8, 0, 5) finished
09:49:28 DISPATCHER: register_result: lock acquired
09:49:28 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
09:49:28 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 993, 'last_n_outputs': 48, 'leak_rate': 0.9547808947013059, 'lr': 0.00752522533444974, 'optimizer': 'SGD', 'sparsity': 0.8171247409967092, 'steps_to_train': 77, 'weight_decay': 0.022464719671026697}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.73213726853483, 'info': {'data05': 0.73213726853483, 'config': "{'batch_size': 32, 'hidden_dim': 993, 'last_n_outputs': 48, 'leak_rate': 0.9547808947013059, 'lr': 0.00752522533444974, 'optimizer': 'SGD', 'sparsity': 0.8171247409967092, 'steps_to_train': 77, 'weight_decay': 0.022464719671026697}"}}
exception: None

09:49:28 job_callback for (8, 0, 5) started
09:49:28 DISPATCHER: Trying to submit another job.
09:49:28 job_callback for (8, 0, 5) got condition
09:49:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:49:28 HBMASTER: Trying to run another job!
09:49:28 job_callback for (8, 0, 5) finished
09:49:28 HBMASTER: schedule new run for iteration 8
09:49:28 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
09:49:28 HBMASTER: submitting job (8, 0, 6) to dispatcher
09:49:28 DISPATCHER: trying to submit job (8, 0, 6)
09:49:28 DISPATCHER: trying to notify the job_runner thread.
09:49:28 HBMASTER: job (8, 0, 6) submitted to dispatcher
09:49:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:49:28 DISPATCHER: Trying to submit another job.
09:49:28 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:49:28 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:49:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:49:28 WORKER: start processing job (8, 0, 6)
09:49:28 WORKER: args: ()
09:49:28 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 876, 'last_n_outputs': 48, 'leak_rate': 0.9897294849532798, 'lr': 0.006081270041258285, 'optimizer': 'SGD', 'sparsity': 0.9549940172288338, 'steps_to_train': 82, 'weight_decay': 0.12661003875271226}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:50:27 DISPATCHER: Starting worker discovery
09:50:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:50:27 DISPATCHER: Finished worker discovery
09:51:27 DISPATCHER: Starting worker discovery
09:51:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:51:27 DISPATCHER: Finished worker discovery
09:51:58 WORKER: done with job (8, 0, 6), trying to register it.
09:51:58 WORKER: registered result for job (8, 0, 6) with dispatcher
09:51:58 DISPATCHER: job (8, 0, 6) finished
09:51:58 DISPATCHER: register_result: lock acquired
09:51:58 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
09:51:58 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 876, 'last_n_outputs': 48, 'leak_rate': 0.9897294849532798, 'lr': 0.006081270041258285, 'optimizer': 'SGD', 'sparsity': 0.9549940172288338, 'steps_to_train': 82, 'weight_decay': 0.12661003875271226}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7390432209748747, 'info': {'data05': 0.7390432209748747, 'config': "{'batch_size': 128, 'hidden_dim': 876, 'last_n_outputs': 48, 'leak_rate': 0.9897294849532798, 'lr': 0.006081270041258285, 'optimizer': 'SGD', 'sparsity': 0.9549940172288338, 'steps_to_train': 82, 'weight_decay': 0.12661003875271226}"}}
exception: None

09:51:58 job_callback for (8, 0, 6) started
09:51:58 job_callback for (8, 0, 6) got condition
09:51:58 DISPATCHER: Trying to submit another job.
09:51:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:51:58 HBMASTER: Trying to run another job!
09:51:58 job_callback for (8, 0, 6) finished
09:51:58 HBMASTER: schedule new run for iteration 8
09:51:58 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
09:51:58 HBMASTER: submitting job (8, 0, 8) to dispatcher
09:51:58 DISPATCHER: trying to submit job (8, 0, 8)
09:51:58 DISPATCHER: trying to notify the job_runner thread.
09:51:58 HBMASTER: job (8, 0, 8) submitted to dispatcher
09:51:58 DISPATCHER: Trying to submit another job.
09:51:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:51:58 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:51:58 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:51:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:51:58 WORKER: start processing job (8, 0, 8)
09:51:58 WORKER: args: ()
09:51:58 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 997, 'last_n_outputs': 48, 'leak_rate': 0.9501816047999329, 'lr': 0.011484782519576853, 'optimizer': 'SGD', 'sparsity': 0.8869318517688187, 'steps_to_train': 99, 'weight_decay': 0.0997590225116073}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:52:27 DISPATCHER: Starting worker discovery
09:52:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:52:27 DISPATCHER: Finished worker discovery
09:53:27 DISPATCHER: Starting worker discovery
09:53:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:53:27 DISPATCHER: Finished worker discovery
09:54:27 DISPATCHER: Starting worker discovery
09:54:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:54:27 DISPATCHER: Finished worker discovery
09:54:30 WORKER: done with job (8, 0, 8), trying to register it.
09:54:30 WORKER: registered result for job (8, 0, 8) with dispatcher
09:54:30 DISPATCHER: job (8, 0, 8) finished
09:54:30 DISPATCHER: register_result: lock acquired
09:54:30 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
09:54:30 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 997, 'last_n_outputs': 48, 'leak_rate': 0.9501816047999329, 'lr': 0.011484782519576853, 'optimizer': 'SGD', 'sparsity': 0.8869318517688187, 'steps_to_train': 99, 'weight_decay': 0.0997590225116073}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7460219972650116, 'info': {'data05': 0.7460219972650116, 'config': "{'batch_size': 128, 'hidden_dim': 997, 'last_n_outputs': 48, 'leak_rate': 0.9501816047999329, 'lr': 0.011484782519576853, 'optimizer': 'SGD', 'sparsity': 0.8869318517688187, 'steps_to_train': 99, 'weight_decay': 0.0997590225116073}"}}
exception: None

09:54:30 job_callback for (8, 0, 8) started
09:54:30 job_callback for (8, 0, 8) got condition
09:54:30 DISPATCHER: Trying to submit another job.
09:54:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:54:30 HBMASTER: Trying to run another job!
09:54:30 job_callback for (8, 0, 8) finished
09:54:30 HBMASTER: schedule new run for iteration 8
09:54:30 HBMASTER: trying submitting job (8, 0, 13) to dispatcher
09:54:30 HBMASTER: submitting job (8, 0, 13) to dispatcher
09:54:30 DISPATCHER: trying to submit job (8, 0, 13)
09:54:30 DISPATCHER: trying to notify the job_runner thread.
09:54:30 HBMASTER: job (8, 0, 13) submitted to dispatcher
09:54:30 DISPATCHER: Trying to submit another job.
09:54:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:54:30 DISPATCHER: starting job (8, 0, 13) on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:54:30 DISPATCHER: job (8, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:54:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:54:30 WORKER: start processing job (8, 0, 13)
09:54:30 WORKER: args: ()
09:54:30 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 738, 'last_n_outputs': 49, 'leak_rate': 0.7740170709495311, 'lr': 0.0018459813360296798, 'optimizer': 'SGD', 'sparsity': 0.7994877943829583, 'steps_to_train': 57, 'weight_decay': 0.010860806393678396}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:55:27 DISPATCHER: Starting worker discovery
09:55:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:55:27 DISPATCHER: Finished worker discovery
09:56:27 DISPATCHER: Starting worker discovery
09:56:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:56:27 DISPATCHER: Finished worker discovery
09:57:01 WORKER: done with job (8, 0, 13), trying to register it.
09:57:01 WORKER: registered result for job (8, 0, 13) with dispatcher
09:57:01 DISPATCHER: job (8, 0, 13) finished
09:57:01 DISPATCHER: register_result: lock acquired
09:57:01 DISPATCHER: job (8, 0, 13) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
09:57:01 job_id: (8, 0, 13)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 738, 'last_n_outputs': 49, 'leak_rate': 0.7740170709495311, 'lr': 0.0018459813360296798, 'optimizer': 'SGD', 'sparsity': 0.7994877943829583, 'steps_to_train': 57, 'weight_decay': 0.010860806393678396}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7323898618518774, 'info': {'data05': 0.7323898618518774, 'config': "{'batch_size': 128, 'hidden_dim': 738, 'last_n_outputs': 49, 'leak_rate': 0.7740170709495311, 'lr': 0.0018459813360296798, 'optimizer': 'SGD', 'sparsity': 0.7994877943829583, 'steps_to_train': 57, 'weight_decay': 0.010860806393678396}"}}
exception: None

09:57:01 job_callback for (8, 0, 13) started
09:57:01 DISPATCHER: Trying to submit another job.
09:57:01 job_callback for (8, 0, 13) got condition
09:57:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:57:01 HBMASTER: Trying to run another job!
09:57:01 job_callback for (8, 0, 13) finished
09:57:01 HBMASTER: schedule new run for iteration 8
09:57:01 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
09:57:01 HBMASTER: submitting job (8, 0, 18) to dispatcher
09:57:01 DISPATCHER: trying to submit job (8, 0, 18)
09:57:01 DISPATCHER: trying to notify the job_runner thread.
09:57:01 HBMASTER: job (8, 0, 18) submitted to dispatcher
09:57:01 DISPATCHER: Trying to submit another job.
09:57:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:57:01 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:57:01 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:57:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:57:01 WORKER: start processing job (8, 0, 18)
09:57:01 WORKER: args: ()
09:57:01 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 920, 'last_n_outputs': 41, 'leak_rate': 0.9593258241432709, 'lr': 0.03316577954186267, 'optimizer': 'SGD', 'sparsity': 0.8342013734882947, 'steps_to_train': 38, 'weight_decay': 0.018861116176900488}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:57:27 DISPATCHER: Starting worker discovery
09:57:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:57:27 DISPATCHER: Finished worker discovery
09:58:27 DISPATCHER: Starting worker discovery
09:58:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:58:27 DISPATCHER: Finished worker discovery
09:59:27 DISPATCHER: Starting worker discovery
09:59:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:59:27 DISPATCHER: Finished worker discovery
09:59:29 WORKER: done with job (8, 0, 18), trying to register it.
09:59:29 WORKER: registered result for job (8, 0, 18) with dispatcher
09:59:29 DISPATCHER: job (8, 0, 18) finished
09:59:29 DISPATCHER: register_result: lock acquired
09:59:29 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
09:59:29 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 920, 'last_n_outputs': 41, 'leak_rate': 0.9593258241432709, 'lr': 0.03316577954186267, 'optimizer': 'SGD', 'sparsity': 0.8342013734882947, 'steps_to_train': 38, 'weight_decay': 0.018861116176900488}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7444374583922762, 'info': {'data05': 0.7444374583922762, 'config': "{'batch_size': 128, 'hidden_dim': 920, 'last_n_outputs': 41, 'leak_rate': 0.9593258241432709, 'lr': 0.03316577954186267, 'optimizer': 'SGD', 'sparsity': 0.8342013734882947, 'steps_to_train': 38, 'weight_decay': 0.018861116176900488}"}}
exception: None

09:59:29 job_callback for (8, 0, 18) started
09:59:29 job_callback for (8, 0, 18) got condition
09:59:29 DISPATCHER: Trying to submit another job.
09:59:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:59:29 HBMASTER: Trying to run another job!
09:59:29 job_callback for (8, 0, 18) finished
09:59:29 HBMASTER: schedule new run for iteration 8
09:59:29 HBMASTER: trying submitting job (8, 0, 19) to dispatcher
09:59:29 HBMASTER: submitting job (8, 0, 19) to dispatcher
09:59:29 DISPATCHER: trying to submit job (8, 0, 19)
09:59:29 DISPATCHER: trying to notify the job_runner thread.
09:59:29 HBMASTER: job (8, 0, 19) submitted to dispatcher
09:59:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:59:29 DISPATCHER: Trying to submit another job.
09:59:29 DISPATCHER: starting job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:59:29 DISPATCHER: job (8, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:59:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:59:29 WORKER: start processing job (8, 0, 19)
09:59:29 WORKER: args: ()
09:59:29 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 956, 'last_n_outputs': 48, 'leak_rate': 0.9126696247229173, 'lr': 0.006993425702977817, 'optimizer': 'SGD', 'sparsity': 0.8931437258238613, 'steps_to_train': 93, 'weight_decay': 0.05190736371383446}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:00:27 DISPATCHER: Starting worker discovery
10:00:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:00:27 DISPATCHER: Finished worker discovery
10:01:27 DISPATCHER: Starting worker discovery
10:01:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:01:27 DISPATCHER: Finished worker discovery
10:02:01 WORKER: done with job (8, 0, 19), trying to register it.
10:02:01 WORKER: registered result for job (8, 0, 19) with dispatcher
10:02:01 DISPATCHER: job (8, 0, 19) finished
10:02:01 DISPATCHER: register_result: lock acquired
10:02:01 DISPATCHER: job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
10:02:01 job_id: (8, 0, 19)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 956, 'last_n_outputs': 48, 'leak_rate': 0.9126696247229173, 'lr': 0.006993425702977817, 'optimizer': 'SGD', 'sparsity': 0.8931437258238613, 'steps_to_train': 93, 'weight_decay': 0.05190736371383446}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7486199059080741, 'info': {'data05': 0.7486199059080741, 'config': "{'batch_size': 32, 'hidden_dim': 956, 'last_n_outputs': 48, 'leak_rate': 0.9126696247229173, 'lr': 0.006993425702977817, 'optimizer': 'SGD', 'sparsity': 0.8931437258238613, 'steps_to_train': 93, 'weight_decay': 0.05190736371383446}"}}
exception: None

10:02:01 job_callback for (8, 0, 19) started
10:02:01 job_callback for (8, 0, 19) got condition
10:02:01 DISPATCHER: Trying to submit another job.
10:02:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:02:01 HBMASTER: Trying to run another job!
10:02:01 job_callback for (8, 0, 19) finished
10:02:01 HBMASTER: schedule new run for iteration 8
10:02:01 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
10:02:01 HBMASTER: submitting job (8, 0, 21) to dispatcher
10:02:01 DISPATCHER: trying to submit job (8, 0, 21)
10:02:01 DISPATCHER: trying to notify the job_runner thread.
10:02:01 HBMASTER: job (8, 0, 21) submitted to dispatcher
10:02:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:02:01 DISPATCHER: Trying to submit another job.
10:02:01 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.13101140314513094464
10:02:01 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
10:02:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:02:01 WORKER: start processing job (8, 0, 21)
10:02:01 WORKER: args: ()
10:02:01 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 946, 'last_n_outputs': 48, 'leak_rate': 0.8267924092005529, 'lr': 0.013062207105243386, 'optimizer': 'SGD', 'sparsity': 0.9132012321927674, 'steps_to_train': 11, 'weight_decay': 0.07724322401934976}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:02:27 DISPATCHER: Starting worker discovery
10:02:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:02:27 DISPATCHER: Finished worker discovery
10:03:27 DISPATCHER: Starting worker discovery
10:03:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:03:27 DISPATCHER: Finished worker discovery
10:04:27 DISPATCHER: Starting worker discovery
10:04:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:04:27 DISPATCHER: Finished worker discovery
10:04:30 WORKER: done with job (8, 0, 21), trying to register it.
10:04:30 WORKER: registered result for job (8, 0, 21) with dispatcher
10:04:30 DISPATCHER: job (8, 0, 21) finished
10:04:30 DISPATCHER: register_result: lock acquired
10:04:30 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
10:04:30 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 946, 'last_n_outputs': 48, 'leak_rate': 0.8267924092005529, 'lr': 0.013062207105243386, 'optimizer': 'SGD', 'sparsity': 0.9132012321927674, 'steps_to_train': 11, 'weight_decay': 0.07724322401934976}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7428105853661993, 'info': {'data05': 0.7428105853661993, 'config': "{'batch_size': 32, 'hidden_dim': 946, 'last_n_outputs': 48, 'leak_rate': 0.8267924092005529, 'lr': 0.013062207105243386, 'optimizer': 'SGD', 'sparsity': 0.9132012321927674, 'steps_to_train': 11, 'weight_decay': 0.07724322401934976}"}}
exception: None

10:04:30 job_callback for (8, 0, 21) started
10:04:30 DISPATCHER: Trying to submit another job.
10:04:30 job_callback for (8, 0, 21) got condition
10:04:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:04:30 HBMASTER: Trying to run another job!
10:04:30 job_callback for (8, 0, 21) finished
10:04:30 HBMASTER: schedule new run for iteration 8
10:04:30 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
10:04:30 HBMASTER: submitting job (8, 0, 23) to dispatcher
10:04:30 DISPATCHER: trying to submit job (8, 0, 23)
10:04:30 DISPATCHER: trying to notify the job_runner thread.
10:04:30 HBMASTER: job (8, 0, 23) submitted to dispatcher
10:04:30 DISPATCHER: Trying to submit another job.
10:04:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:04:30 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.13101140314513094464
10:04:30 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
10:04:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:04:30 WORKER: start processing job (8, 0, 23)
10:04:30 WORKER: args: ()
10:04:30 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 840, 'last_n_outputs': 48, 'leak_rate': 0.9846910092250265, 'lr': 0.005618991890251881, 'optimizer': 'SGD', 'sparsity': 0.7856144118522743, 'steps_to_train': 67, 'weight_decay': 0.036342462295976825}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:05:27 DISPATCHER: Starting worker discovery
10:05:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:05:27 DISPATCHER: Finished worker discovery
10:06:27 DISPATCHER: Starting worker discovery
10:06:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:06:27 DISPATCHER: Finished worker discovery
10:06:56 WORKER: done with job (8, 0, 23), trying to register it.
10:06:56 WORKER: registered result for job (8, 0, 23) with dispatcher
10:06:56 DISPATCHER: job (8, 0, 23) finished
10:06:56 DISPATCHER: register_result: lock acquired
10:06:56 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
10:06:56 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 840, 'last_n_outputs': 48, 'leak_rate': 0.9846910092250265, 'lr': 0.005618991890251881, 'optimizer': 'SGD', 'sparsity': 0.7856144118522743, 'steps_to_train': 67, 'weight_decay': 0.036342462295976825}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.727014888444017, 'info': {'data05': 0.727014888444017, 'config': "{'batch_size': 16, 'hidden_dim': 840, 'last_n_outputs': 48, 'leak_rate': 0.9846910092250265, 'lr': 0.005618991890251881, 'optimizer': 'SGD', 'sparsity': 0.7856144118522743, 'steps_to_train': 67, 'weight_decay': 0.036342462295976825}"}}
exception: None

10:06:56 job_callback for (8, 0, 23) started
10:06:56 job_callback for (8, 0, 23) got condition
10:06:56 DISPATCHER: Trying to submit another job.
10:06:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:06:56 HBMASTER: Trying to run another job!
10:06:56 job_callback for (8, 0, 23) finished
10:06:56 ITERATION: Advancing config (8, 0, 0) to next budget 400.000000
10:06:56 ITERATION: Advancing config (8, 0, 8) to next budget 400.000000
10:06:56 ITERATION: Advancing config (8, 0, 19) to next budget 400.000000
10:06:56 HBMASTER: schedule new run for iteration 8
10:06:56 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
10:06:56 HBMASTER: submitting job (8, 0, 0) to dispatcher
10:06:56 DISPATCHER: trying to submit job (8, 0, 0)
10:06:56 DISPATCHER: trying to notify the job_runner thread.
10:06:56 HBMASTER: job (8, 0, 0) submitted to dispatcher
10:06:56 DISPATCHER: Trying to submit another job.
10:06:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:06:56 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
10:06:56 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
10:06:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:06:56 WORKER: start processing job (8, 0, 0)
10:06:56 WORKER: args: ()
10:06:56 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 788, 'last_n_outputs': 50, 'leak_rate': 0.991098845449354, 'lr': 0.00690248025107967, 'optimizer': 'SGD', 'sparsity': 0.9169726893032305, 'steps_to_train': 92, 'weight_decay': 0.08072489235932702}, 'budget': 400.0, 'working_directory': '.'}
10:07:27 DISPATCHER: Starting worker discovery
10:07:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:07:27 DISPATCHER: Finished worker discovery
10:08:27 DISPATCHER: Starting worker discovery
10:08:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:08:27 DISPATCHER: Finished worker discovery
10:09:27 DISPATCHER: Starting worker discovery
10:09:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:09:27 DISPATCHER: Finished worker discovery
10:10:27 DISPATCHER: Starting worker discovery
10:10:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:10:27 DISPATCHER: Finished worker discovery
10:11:27 DISPATCHER: Starting worker discovery
10:11:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:11:27 DISPATCHER: Finished worker discovery
10:12:27 DISPATCHER: Starting worker discovery
10:12:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:12:27 DISPATCHER: Finished worker discovery
10:13:27 DISPATCHER: Starting worker discovery
10:13:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:13:27 DISPATCHER: Finished worker discovery
10:13:57 WORKER: done with job (8, 0, 0), trying to register it.
10:13:57 WORKER: registered result for job (8, 0, 0) with dispatcher
10:13:57 DISPATCHER: job (8, 0, 0) finished
10:13:57 DISPATCHER: register_result: lock acquired
10:13:57 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
10:13:57 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 788, 'last_n_outputs': 50, 'leak_rate': 0.991098845449354, 'lr': 0.00690248025107967, 'optimizer': 'SGD', 'sparsity': 0.9169726893032305, 'steps_to_train': 92, 'weight_decay': 0.08072489235932702}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7476050292685528, 'info': {'data05': 0.7476050292685528, 'config': "{'batch_size': 128, 'hidden_dim': 788, 'last_n_outputs': 50, 'leak_rate': 0.991098845449354, 'lr': 0.00690248025107967, 'optimizer': 'SGD', 'sparsity': 0.9169726893032305, 'steps_to_train': 92, 'weight_decay': 0.08072489235932702}"}}
exception: None

10:13:57 job_callback for (8, 0, 0) started
10:13:57 DISPATCHER: Trying to submit another job.
10:13:57 job_callback for (8, 0, 0) got condition
10:13:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:13:57 done building a new model for budget 400.000000 based on 10/21 split
Best loss for this budget:-0.773507





10:13:57 HBMASTER: Trying to run another job!
10:13:57 job_callback for (8, 0, 0) finished
10:13:57 HBMASTER: schedule new run for iteration 8
10:13:57 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
10:13:57 HBMASTER: submitting job (8, 0, 8) to dispatcher
10:13:57 DISPATCHER: trying to submit job (8, 0, 8)
10:13:57 DISPATCHER: trying to notify the job_runner thread.
10:13:57 HBMASTER: job (8, 0, 8) submitted to dispatcher
10:13:57 DISPATCHER: Trying to submit another job.
10:13:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:13:57 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464
10:13:57 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
10:13:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:13:57 WORKER: start processing job (8, 0, 8)
10:13:57 WORKER: args: ()
10:13:57 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 997, 'last_n_outputs': 48, 'leak_rate': 0.9501816047999329, 'lr': 0.011484782519576853, 'optimizer': 'SGD', 'sparsity': 0.8869318517688187, 'steps_to_train': 99, 'weight_decay': 0.0997590225116073}, 'budget': 400.0, 'working_directory': '.'}
10:14:27 DISPATCHER: Starting worker discovery
10:14:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:14:27 DISPATCHER: Finished worker discovery
10:15:27 DISPATCHER: Starting worker discovery
10:15:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:15:27 DISPATCHER: Finished worker discovery
10:16:27 DISPATCHER: Starting worker discovery
10:16:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:16:27 DISPATCHER: Finished worker discovery
10:17:27 DISPATCHER: Starting worker discovery
10:17:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:17:27 DISPATCHER: Finished worker discovery
10:18:27 DISPATCHER: Starting worker discovery
10:18:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:18:27 DISPATCHER: Finished worker discovery
10:19:27 DISPATCHER: Starting worker discovery
10:19:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:19:27 DISPATCHER: Finished worker discovery
10:20:27 DISPATCHER: Starting worker discovery
10:20:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:20:27 DISPATCHER: Finished worker discovery
10:20:58 WORKER: done with job (8, 0, 8), trying to register it.
10:20:58 WORKER: registered result for job (8, 0, 8) with dispatcher
10:20:58 DISPATCHER: job (8, 0, 8) finished
10:20:58 DISPATCHER: register_result: lock acquired
10:20:58 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
10:20:58 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 997, 'last_n_outputs': 48, 'leak_rate': 0.9501816047999329, 'lr': 0.011484782519576853, 'optimizer': 'SGD', 'sparsity': 0.8869318517688187, 'steps_to_train': 99, 'weight_decay': 0.0997590225116073}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7401662564599416, 'info': {'data05': 0.7401662564599416, 'config': "{'batch_size': 128, 'hidden_dim': 997, 'last_n_outputs': 48, 'leak_rate': 0.9501816047999329, 'lr': 0.011484782519576853, 'optimizer': 'SGD', 'sparsity': 0.8869318517688187, 'steps_to_train': 99, 'weight_decay': 0.0997590225116073}"}}
exception: None

10:20:58 job_callback for (8, 0, 8) started
10:20:58 DISPATCHER: Trying to submit another job.
10:20:58 job_callback for (8, 0, 8) got condition
10:20:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:20:58 done building a new model for budget 400.000000 based on 10/22 split
Best loss for this budget:-0.773507





10:20:58 HBMASTER: Trying to run another job!
10:20:58 job_callback for (8, 0, 8) finished
10:20:58 HBMASTER: schedule new run for iteration 8
10:20:58 HBMASTER: trying submitting job (8, 0, 19) to dispatcher
10:20:58 HBMASTER: submitting job (8, 0, 19) to dispatcher
10:20:58 DISPATCHER: trying to submit job (8, 0, 19)
10:20:58 DISPATCHER: trying to notify the job_runner thread.
10:20:58 HBMASTER: job (8, 0, 19) submitted to dispatcher
10:20:58 DISPATCHER: Trying to submit another job.
10:20:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:20:58 DISPATCHER: starting job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.13101140314513094464
10:20:58 DISPATCHER: job (8, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
10:20:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:20:58 WORKER: start processing job (8, 0, 19)
10:20:58 WORKER: args: ()
10:20:58 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 956, 'last_n_outputs': 48, 'leak_rate': 0.9126696247229173, 'lr': 0.006993425702977817, 'optimizer': 'SGD', 'sparsity': 0.8931437258238613, 'steps_to_train': 93, 'weight_decay': 0.05190736371383446}, 'budget': 400.0, 'working_directory': '.'}
10:21:27 DISPATCHER: Starting worker discovery
10:21:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:21:27 DISPATCHER: Finished worker discovery
10:22:27 DISPATCHER: Starting worker discovery
10:22:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:22:27 DISPATCHER: Finished worker discovery
10:23:27 DISPATCHER: Starting worker discovery
10:23:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:23:27 DISPATCHER: Finished worker discovery
10:24:27 DISPATCHER: Starting worker discovery
10:24:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:24:27 DISPATCHER: Finished worker discovery
10:25:27 DISPATCHER: Starting worker discovery
10:25:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:25:27 DISPATCHER: Finished worker discovery
10:26:27 DISPATCHER: Starting worker discovery
10:26:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:26:27 DISPATCHER: Finished worker discovery
10:27:27 DISPATCHER: Starting worker discovery
10:27:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:27:27 DISPATCHER: Finished worker discovery
10:27:53 WORKER: done with job (8, 0, 19), trying to register it.
10:27:53 WORKER: registered result for job (8, 0, 19) with dispatcher
10:27:53 DISPATCHER: job (8, 0, 19) finished
10:27:53 DISPATCHER: register_result: lock acquired
10:27:53 DISPATCHER: job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
10:27:53 job_id: (8, 0, 19)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 956, 'last_n_outputs': 48, 'leak_rate': 0.9126696247229173, 'lr': 0.006993425702977817, 'optimizer': 'SGD', 'sparsity': 0.8931437258238613, 'steps_to_train': 93, 'weight_decay': 0.05190736371383446}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7505586306842233, 'info': {'data05': 0.7505586306842233, 'config': "{'batch_size': 32, 'hidden_dim': 956, 'last_n_outputs': 48, 'leak_rate': 0.9126696247229173, 'lr': 0.006993425702977817, 'optimizer': 'SGD', 'sparsity': 0.8931437258238613, 'steps_to_train': 93, 'weight_decay': 0.05190736371383446}"}}
exception: None

10:27:53 job_callback for (8, 0, 19) started
10:27:53 DISPATCHER: Trying to submit another job.
10:27:53 job_callback for (8, 0, 19) got condition
10:27:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:27:53 done building a new model for budget 400.000000 based on 10/22 split
Best loss for this budget:-0.773507





10:27:53 HBMASTER: Trying to run another job!
10:27:53 job_callback for (8, 0, 19) finished
10:27:53 ITERATION: Advancing config (8, 0, 19) to next budget 1200.000000
10:27:53 HBMASTER: schedule new run for iteration 8
10:27:53 HBMASTER: trying submitting job (8, 0, 19) to dispatcher
10:27:53 HBMASTER: submitting job (8, 0, 19) to dispatcher
10:27:53 DISPATCHER: trying to submit job (8, 0, 19)
10:27:53 DISPATCHER: trying to notify the job_runner thread.
10:27:53 HBMASTER: job (8, 0, 19) submitted to dispatcher
10:27:53 DISPATCHER: Trying to submit another job.
10:27:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:27:53 DISPATCHER: starting job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.13101140314513094464
10:27:53 DISPATCHER: job (8, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
10:27:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:27:53 WORKER: start processing job (8, 0, 19)
10:27:53 WORKER: args: ()
10:27:53 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 956, 'last_n_outputs': 48, 'leak_rate': 0.9126696247229173, 'lr': 0.006993425702977817, 'optimizer': 'SGD', 'sparsity': 0.8931437258238613, 'steps_to_train': 93, 'weight_decay': 0.05190736371383446}, 'budget': 1200.0, 'working_directory': '.'}
10:28:27 DISPATCHER: Starting worker discovery
10:28:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:28:27 DISPATCHER: Finished worker discovery
10:29:27 DISPATCHER: Starting worker discovery
10:29:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:29:27 DISPATCHER: Finished worker discovery
10:30:27 DISPATCHER: Starting worker discovery
10:30:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:30:27 DISPATCHER: Finished worker discovery
10:31:27 DISPATCHER: Starting worker discovery
10:31:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:31:27 DISPATCHER: Finished worker discovery
10:32:27 DISPATCHER: Starting worker discovery
10:32:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:32:27 DISPATCHER: Finished worker discovery
10:33:27 DISPATCHER: Starting worker discovery
10:33:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:33:27 DISPATCHER: Finished worker discovery
10:34:27 DISPATCHER: Starting worker discovery
10:34:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:34:27 DISPATCHER: Finished worker discovery
10:35:27 DISPATCHER: Starting worker discovery
10:35:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:35:27 DISPATCHER: Finished worker discovery
10:36:27 DISPATCHER: Starting worker discovery
10:36:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:36:27 DISPATCHER: Finished worker discovery
10:37:27 DISPATCHER: Starting worker discovery
10:37:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:37:27 DISPATCHER: Finished worker discovery
10:38:27 DISPATCHER: Starting worker discovery
10:38:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:38:27 DISPATCHER: Finished worker discovery
10:39:27 DISPATCHER: Starting worker discovery
10:39:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:39:27 DISPATCHER: Finished worker discovery
10:40:27 DISPATCHER: Starting worker discovery
10:40:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:40:27 DISPATCHER: Finished worker discovery
10:41:27 DISPATCHER: Starting worker discovery
10:41:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:41:27 DISPATCHER: Finished worker discovery
10:42:27 DISPATCHER: Starting worker discovery
10:42:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:42:27 DISPATCHER: Finished worker discovery
10:43:27 DISPATCHER: Starting worker discovery
10:43:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:43:27 DISPATCHER: Finished worker discovery
10:44:27 DISPATCHER: Starting worker discovery
10:44:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:44:27 DISPATCHER: Finished worker discovery
10:45:27 DISPATCHER: Starting worker discovery
10:45:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:45:27 DISPATCHER: Finished worker discovery
10:46:27 DISPATCHER: Starting worker discovery
10:46:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:46:27 DISPATCHER: Finished worker discovery
10:47:27 DISPATCHER: Starting worker discovery
10:47:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:47:27 DISPATCHER: Finished worker discovery
10:48:10 WORKER: done with job (8, 0, 19), trying to register it.
10:48:10 WORKER: registered result for job (8, 0, 19) with dispatcher
10:48:10 DISPATCHER: job (8, 0, 19) finished
10:48:10 DISPATCHER: register_result: lock acquired
10:48:10 DISPATCHER: job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
10:48:10 job_id: (8, 0, 19)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 956, 'last_n_outputs': 48, 'leak_rate': 0.9126696247229173, 'lr': 0.006993425702977817, 'optimizer': 'SGD', 'sparsity': 0.8931437258238613, 'steps_to_train': 93, 'weight_decay': 0.05190736371383446}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.7542188211139643, 'info': {'data05': 0.7542188211139643, 'config': "{'batch_size': 32, 'hidden_dim': 956, 'last_n_outputs': 48, 'leak_rate': 0.9126696247229173, 'lr': 0.006993425702977817, 'optimizer': 'SGD', 'sparsity': 0.8931437258238613, 'steps_to_train': 93, 'weight_decay': 0.05190736371383446}"}}
exception: None

10:48:10 job_callback for (8, 0, 19) started
10:48:10 DISPATCHER: Trying to submit another job.
10:48:10 job_callback for (8, 0, 19) got condition
10:48:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:48:10 HBMASTER: Trying to run another job!
10:48:10 job_callback for (8, 0, 19) finished
10:48:10 start sampling a new configuration.
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/numpy/core/_methods.py:38: RuntimeWarning: invalid value encountered in reduce
  return umr_sum(a, axis, dtype, out, keepdims, initial, where)
10:48:10 sampled vector: [0, 0.9992855452254811, 0.7260102494242962, 0.25208568983444773, 0.09713868614607424, 0, 0.9809976170005117, 0.09815376719205449, 0.9433864798175129] has EI value nan
10:48:10 data in the KDEs:
[[3.         0.9931336  0.9390246  0.02441516 0.4103298  1.
  0.92511198 0.22527466 0.75233087]
 [3.         0.70973783 0.96341486 0.20182371 0.82004219 1.
  0.3824063  0.79670336 0.16236439]
 [0.         0.87078653 0.96341486 0.04088665 0.3387988  1.
  0.82597929 0.20329664 0.69513031]
 [2.         0.98314608 0.96341486 0.9700894  0.53716743 1.
  0.26189123 0.91758251 0.48224745]
 [1.         0.94444446 0.9390246  0.6506785  0.42234498 1.
  0.59643219 0.91758251 0.54974057]
 [3.         0.73470662 0.98780512 0.96439538 0.41950259 1.
  0.69571954 0.9065935  0.69714571]
 [2.         0.88826468 0.89024409 0.51089283 0.40483534 1.
  0.71053071 0.89560448 0.2875544 ]
 [0.         0.93445694 0.96341486 0.54598995 0.2810794  1.
  0.73698102 0.34615381 0.92554773]
 [3.         0.81835207 0.84146358 0.5708122  0.14577457 1.
  0.82914614 0.14835157 0.33276711]
 [1.         0.59737828 0.9390246  0.19749061 0.23304041 1.
  0.07853096 0.98351659 0.04621755]]
[[3.         0.99563047 0.9390246  0.80072642 0.53006139 1.
  0.57054938 0.98351659 0.76781641]
 [1.         0.8258427  0.9390246  0.98903091 0.5057777  1.
  0.32389303 0.9065935  0.55452388]
 [0.         0.93695382 0.91463435 0.85627524 0.11558053 1.
  0.99904176 0.80769238 0.07565397]
 [0.         0.85205993 0.86585384 0.32161529 0.80684586 1.
  0.50586732 0.98351659 0.0318356 ]
 [2.         0.93196006 0.9390246  0.92009187 0.16363863 1.
  0.85243881 0.01648341 0.6686903 ]
 [2.         0.86704121 0.91463435 0.39276973 0.76239874 1.
  0.17327811 0.79670336 0.28856922]
 [1.         0.46754057 0.9390246  0.92054574 0.33478511 1.
  0.27124275 0.18131861 0.94765664]
 [1.         0.63108615 0.96341486 0.43004059 0.02300497 1.
  0.3806035  0.54395605 0.7024265 ]
 [3.         0.80461923 0.84146358 0.93630604 0.20275585 1.
  0.86135482 0.87362646 0.06770643]
 [0.         0.83333334 0.89024409 0.05932951 0.70275622 1.
  0.82353758 0.56593408 0.70871001]
 [2.         0.59612984 0.86585384 0.49308609 0.0114926  1.
  0.97923865 0.10439552 0.11969113]
 [3.         0.05305867 0.86585384 0.35410745 0.38845749 1.
  0.97634433 0.80769238 0.10853027]
 [2.         0.87453184 0.89024409 0.2966987  0.66961984 1.
  0.77407722 0.63186816 0.73289116]
 [3.         0.74094882 0.2804877  0.3899129  0.47640722 0.
  0.3928456  0.81868139 0.01124143]
 [2.         0.77465669 0.96341486 0.34282504 0.94249338 1.
  0.32648624 0.67582421 0.31308946]
 [3.         0.94194758 0.20731693 0.29830105 0.6929537  1.
  0.11800773 0.81868139 0.58821637]
 [1.         0.09176029 0.30487795 0.43875446 0.51482064 0.
  0.71146861 0.48901099 0.8940555 ]]
10:48:10 bandwidth of the KDEs:
[1.03550510e+00 1.10148724e-01 3.62391631e-02 2.90938236e-01
 1.55487394e-01 1.00000000e-03 2.32029020e-01 2.97623354e-01
 2.37767611e-01]
[0.91364203 0.23033647 0.21225155 0.24059586 0.23549513 0.27464244
 0.248284   0.24725299 0.27414139]
10:48:10 l(x) = nan
10:48:10 g(x) = 0.0016750829002494371
10:48:10 best_vector: [2, 0.8469587234891438, 0.9253388346947394, 0.23937076399165103, 0.4222143520728919, 1, 0.8259209372742078, 0.05597622504212141, 0.2287790066374385], 0.00838929130699135, 1.4552231423759614, 0.012208290858067291
10:48:10 done sampling a new configuration.
10:48:10 HBMASTER: schedule new run for iteration 9
10:48:10 HBMASTER: trying submitting job (9, 0, 0) to dispatcher
10:48:10 HBMASTER: submitting job (9, 0, 0) to dispatcher
10:48:10 DISPATCHER: trying to submit job (9, 0, 0)
10:48:10 DISPATCHER: trying to notify the job_runner thread.
10:48:10 HBMASTER: job (9, 0, 0) submitted to dispatcher
10:48:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:48:10 DISPATCHER: Trying to submit another job.
10:48:10 DISPATCHER: starting job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
10:48:10 DISPATCHER: job (9, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
10:48:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:48:10 WORKER: start processing job (9, 0, 0)
10:48:10 WORKER: args: ()
10:48:10 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 878, 'last_n_outputs': 47, 'leak_rate': 0.8098426909979127, 'lr': 0.006989219889751191, 'optimizer': 'SGD', 'sparsity': 0.9482210249458098, 'steps_to_train': 15, 'weight_decay': 0.01984487419211664}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:48:27 DISPATCHER: Starting worker discovery
10:48:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:48:27 DISPATCHER: Finished worker discovery
10:49:27 DISPATCHER: Starting worker discovery
10:49:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:49:27 DISPATCHER: Finished worker discovery
10:50:27 DISPATCHER: Starting worker discovery
10:50:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:50:27 DISPATCHER: Finished worker discovery
10:50:37 WORKER: done with job (9, 0, 0), trying to register it.
10:50:37 WORKER: registered result for job (9, 0, 0) with dispatcher
10:50:37 DISPATCHER: job (9, 0, 0) finished
10:50:37 DISPATCHER: register_result: lock acquired
10:50:37 DISPATCHER: job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
10:50:37 job_id: (9, 0, 0)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 878, 'last_n_outputs': 47, 'leak_rate': 0.8098426909979127, 'lr': 0.006989219889751191, 'optimizer': 'SGD', 'sparsity': 0.9482210249458098, 'steps_to_train': 15, 'weight_decay': 0.01984487419211664}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.741867437443801, 'info': {'data05': 0.741867437443801, 'config': "{'batch_size': 64, 'hidden_dim': 878, 'last_n_outputs': 47, 'leak_rate': 0.8098426909979127, 'lr': 0.006989219889751191, 'optimizer': 'SGD', 'sparsity': 0.9482210249458098, 'steps_to_train': 15, 'weight_decay': 0.01984487419211664}"}}
exception: None

10:50:37 job_callback for (9, 0, 0) started
10:50:37 job_callback for (9, 0, 0) got condition
10:50:37 DISPATCHER: Trying to submit another job.
10:50:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:50:37 HBMASTER: Trying to run another job!
10:50:37 job_callback for (9, 0, 0) finished
10:50:37 start sampling a new configuration.
10:50:38 best_vector: [2, 0.9907193071496488, 0.9469634557918946, 0.4873993391815349, 0.22029080541435836, 1, 0.9205312802951523, 0.5490876919779124, 0.7767509294575992], 0.004065420310329137, 9.398919769498438, 0.038210559326073
10:50:38 done sampling a new configuration.
10:50:38 HBMASTER: schedule new run for iteration 9
10:50:38 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
10:50:38 HBMASTER: submitting job (9, 0, 1) to dispatcher
10:50:38 DISPATCHER: trying to submit job (9, 0, 1)
10:50:38 DISPATCHER: trying to notify the job_runner thread.
10:50:38 HBMASTER: job (9, 0, 1) submitted to dispatcher
10:50:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:50:38 DISPATCHER: Trying to submit another job.
10:50:38 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
10:50:38 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
10:50:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:50:38 WORKER: start processing job (9, 0, 1)
10:50:38 WORKER: args: ()
10:50:38 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 993, 'last_n_outputs': 48, 'leak_rate': 0.8718498347953837, 'lr': 0.0027579196605485063, 'optimizer': 'SGD', 'sparsity': 0.9709275072708365, 'steps_to_train': 59, 'weight_decay': 0.10246516845580692}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:51:27 DISPATCHER: Starting worker discovery
10:51:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:51:27 DISPATCHER: Finished worker discovery
10:52:27 DISPATCHER: Starting worker discovery
10:52:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:52:27 DISPATCHER: Finished worker discovery
10:53:08 WORKER: done with job (9, 0, 1), trying to register it.
10:53:08 WORKER: registered result for job (9, 0, 1) with dispatcher
10:53:08 DISPATCHER: job (9, 0, 1) finished
10:53:08 DISPATCHER: register_result: lock acquired
10:53:08 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
10:53:08 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 993, 'last_n_outputs': 48, 'leak_rate': 0.8718498347953837, 'lr': 0.0027579196605485063, 'optimizer': 'SGD', 'sparsity': 0.9709275072708365, 'steps_to_train': 59, 'weight_decay': 0.10246516845580692}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.733886558050275, 'info': {'data05': 0.733886558050275, 'config': "{'batch_size': 64, 'hidden_dim': 993, 'last_n_outputs': 48, 'leak_rate': 0.8718498347953837, 'lr': 0.0027579196605485063, 'optimizer': 'SGD', 'sparsity': 0.9709275072708365, 'steps_to_train': 59, 'weight_decay': 0.10246516845580692}"}}
exception: None

10:53:08 job_callback for (9, 0, 1) started
10:53:08 job_callback for (9, 0, 1) got condition
10:53:08 DISPATCHER: Trying to submit another job.
10:53:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:53:08 HBMASTER: Trying to run another job!
10:53:08 job_callback for (9, 0, 1) finished
10:53:08 start sampling a new configuration.
10:53:08 done sampling a new configuration.
10:53:08 HBMASTER: schedule new run for iteration 9
10:53:08 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
10:53:08 HBMASTER: submitting job (9, 0, 2) to dispatcher
10:53:08 DISPATCHER: trying to submit job (9, 0, 2)
10:53:08 DISPATCHER: trying to notify the job_runner thread.
10:53:08 HBMASTER: job (9, 0, 2) submitted to dispatcher
10:53:08 DISPATCHER: Trying to submit another job.
10:53:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:53:08 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
10:53:08 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
10:53:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:53:08 WORKER: start processing job (9, 0, 2)
10:53:08 WORKER: args: ()
10:53:08 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 604, 'last_n_outputs': 24, 'leak_rate': 0.895283096341619, 'lr': 0.06643889822862963, 'optimizer': 'Adam', 'sparsity': 0.9109140089201908, 'steps_to_train': 24, 'weight_decay': 0.012918862687146013}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:53:27 DISPATCHER: Starting worker discovery
10:53:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:53:27 DISPATCHER: Finished worker discovery
10:54:27 DISPATCHER: Starting worker discovery
10:54:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:54:27 DISPATCHER: Finished worker discovery
10:55:27 DISPATCHER: Starting worker discovery
10:55:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:55:27 DISPATCHER: Finished worker discovery
10:55:35 WORKER: done with job (9, 0, 2), trying to register it.
10:55:35 WORKER: registered result for job (9, 0, 2) with dispatcher
10:55:35 DISPATCHER: job (9, 0, 2) finished
10:55:35 DISPATCHER: register_result: lock acquired
10:55:35 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
10:55:35 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 604, 'last_n_outputs': 24, 'leak_rate': 0.895283096341619, 'lr': 0.06643889822862963, 'optimizer': 'Adam', 'sparsity': 0.9109140089201908, 'steps_to_train': 24, 'weight_decay': 0.012918862687146013}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.03821331773619356, 'info': {'data05': 0.03821331773619356, 'config': "{'batch_size': 64, 'hidden_dim': 604, 'last_n_outputs': 24, 'leak_rate': 0.895283096341619, 'lr': 0.06643889822862963, 'optimizer': 'Adam', 'sparsity': 0.9109140089201908, 'steps_to_train': 24, 'weight_decay': 0.012918862687146013}"}}
exception: None

10:55:35 job_callback for (9, 0, 2) started
10:55:35 job_callback for (9, 0, 2) got condition
10:55:35 DISPATCHER: Trying to submit another job.
10:55:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:55:35 HBMASTER: Trying to run another job!
10:55:35 job_callback for (9, 0, 2) finished
10:55:35 start sampling a new configuration.
10:55:35 sampled vector: [2, 0.9548224682138624, 0.9959707660936876, 0.24902147432606836, 0.10019394149239663, 0, 0.22216065624642164, 0.9886334210081106, 0.43510960884917027] has EI value nan
10:55:35 data in the KDEs:
[[3.         0.9931336  0.9390246  0.02441516 0.4103298  1.
  0.92511198 0.22527466 0.75233087]
 [3.         0.70973783 0.96341486 0.20182371 0.82004219 1.
  0.3824063  0.79670336 0.16236439]
 [0.         0.87078653 0.96341486 0.04088665 0.3387988  1.
  0.82597929 0.20329664 0.69513031]
 [2.         0.98314608 0.96341486 0.9700894  0.53716743 1.
  0.26189123 0.91758251 0.48224745]
 [1.         0.94444446 0.9390246  0.6506785  0.42234498 1.
  0.59643219 0.91758251 0.54974057]
 [3.         0.73470662 0.98780512 0.96439538 0.41950259 1.
  0.69571954 0.9065935  0.69714571]
 [2.         0.88826468 0.89024409 0.51089283 0.40483534 1.
  0.71053071 0.89560448 0.2875544 ]
 [0.         0.93445694 0.96341486 0.54598995 0.2810794  1.
  0.73698102 0.34615381 0.92554773]
 [3.         0.81835207 0.84146358 0.5708122  0.14577457 1.
  0.82914614 0.14835157 0.33276711]
 [1.         0.59737828 0.9390246  0.19749061 0.23304041 1.
  0.07853096 0.98351659 0.04621755]]
[[3.         0.99563047 0.9390246  0.80072642 0.53006139 1.
  0.57054938 0.98351659 0.76781641]
 [1.         0.8258427  0.9390246  0.98903091 0.5057777  1.
  0.32389303 0.9065935  0.55452388]
 [0.         0.93695382 0.91463435 0.85627524 0.11558053 1.
  0.99904176 0.80769238 0.07565397]
 [0.         0.85205993 0.86585384 0.32161529 0.80684586 1.
  0.50586732 0.98351659 0.0318356 ]
 [2.         0.93196006 0.9390246  0.92009187 0.16363863 1.
  0.85243881 0.01648341 0.6686903 ]
 [2.         0.86704121 0.91463435 0.39276973 0.76239874 1.
  0.17327811 0.79670336 0.28856922]
 [1.         0.46754057 0.9390246  0.92054574 0.33478511 1.
  0.27124275 0.18131861 0.94765664]
 [1.         0.63108615 0.96341486 0.43004059 0.02300497 1.
  0.3806035  0.54395605 0.7024265 ]
 [3.         0.80461923 0.84146358 0.93630604 0.20275585 1.
  0.86135482 0.87362646 0.06770643]
 [0.         0.83333334 0.89024409 0.05932951 0.70275622 1.
  0.82353758 0.56593408 0.70871001]
 [2.         0.59612984 0.86585384 0.49308609 0.0114926  1.
  0.97923865 0.10439552 0.11969113]
 [3.         0.05305867 0.86585384 0.35410745 0.38845749 1.
  0.97634433 0.80769238 0.10853027]
 [2.         0.87453184 0.89024409 0.2966987  0.66961984 1.
  0.77407722 0.63186816 0.73289116]
 [3.         0.74094882 0.2804877  0.3899129  0.47640722 0.
  0.3928456  0.81868139 0.01124143]
 [2.         0.77465669 0.96341486 0.34282504 0.94249338 1.
  0.32648624 0.67582421 0.31308946]
 [3.         0.94194758 0.20731693 0.29830105 0.6929537  1.
  0.11800773 0.81868139 0.58821637]
 [1.         0.09176029 0.30487795 0.43875446 0.51482064 0.
  0.71146861 0.48901099 0.8940555 ]]
10:55:35 bandwidth of the KDEs:
[1.03550510e+00 1.10148724e-01 3.62391631e-02 2.90938236e-01
 1.55487394e-01 1.00000000e-03 2.32029020e-01 2.97623354e-01
 2.37767611e-01]
[0.91364203 0.23033647 0.21225155 0.24059586 0.23549513 0.27464244
 0.248284   0.24725299 0.27414139]
10:55:35 l(x) = nan
10:55:35 g(x) = 0.005930806882182591
10:55:35 best_vector: [2, 0.9577206023000482, 0.9863683063466284, 0.4837540516037167, 0.4159542533220709, 1, 0.9126370084820647, 0.004093399638546796, 0.7098169286632245], 0.00276216721706682, 6.540231371136154, 0.018065212685384264
10:55:35 done sampling a new configuration.
10:55:35 HBMASTER: schedule new run for iteration 9
10:55:35 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
10:55:35 HBMASTER: submitting job (9, 0, 3) to dispatcher
10:55:35 DISPATCHER: trying to submit job (9, 0, 3)
10:55:35 DISPATCHER: trying to notify the job_runner thread.
10:55:35 HBMASTER: job (9, 0, 3) submitted to dispatcher
10:55:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:55:35 DISPATCHER: Trying to submit another job.
10:55:35 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
10:55:35 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
10:55:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:55:35 WORKER: start processing job (9, 0, 3)
10:55:35 WORKER: args: ()
10:55:35 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 967, 'last_n_outputs': 50, 'leak_rate': 0.8709385129009292, 'lr': 0.00679060559018793, 'optimizer': 'SGD', 'sparsity': 0.9690328820356955, 'steps_to_train': 10, 'weight_decay': 0.08384807870291924}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:56:27 DISPATCHER: Starting worker discovery
10:56:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:56:27 DISPATCHER: Finished worker discovery
10:57:27 DISPATCHER: Starting worker discovery
10:57:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:57:27 DISPATCHER: Finished worker discovery
10:58:04 WORKER: done with job (9, 0, 3), trying to register it.
10:58:04 WORKER: registered result for job (9, 0, 3) with dispatcher
10:58:04 DISPATCHER: job (9, 0, 3) finished
10:58:04 DISPATCHER: register_result: lock acquired
10:58:04 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
10:58:04 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 967, 'last_n_outputs': 50, 'leak_rate': 0.8709385129009292, 'lr': 0.00679060559018793, 'optimizer': 'SGD', 'sparsity': 0.9690328820356955, 'steps_to_train': 10, 'weight_decay': 0.08384807870291924}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7405132728611815, 'info': {'data05': 0.7405132728611815, 'config': "{'batch_size': 64, 'hidden_dim': 967, 'last_n_outputs': 50, 'leak_rate': 0.8709385129009292, 'lr': 0.00679060559018793, 'optimizer': 'SGD', 'sparsity': 0.9690328820356955, 'steps_to_train': 10, 'weight_decay': 0.08384807870291924}"}}
exception: None

10:58:04 job_callback for (9, 0, 3) started
10:58:04 job_callback for (9, 0, 3) got condition
10:58:04 DISPATCHER: Trying to submit another job.
10:58:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:58:04 HBMASTER: Trying to run another job!
10:58:04 job_callback for (9, 0, 3) finished
10:58:04 start sampling a new configuration.
10:58:04 done sampling a new configuration.
10:58:04 HBMASTER: schedule new run for iteration 9
10:58:04 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
10:58:04 HBMASTER: submitting job (9, 0, 4) to dispatcher
10:58:04 DISPATCHER: trying to submit job (9, 0, 4)
10:58:04 DISPATCHER: trying to notify the job_runner thread.
10:58:04 HBMASTER: job (9, 0, 4) submitted to dispatcher
10:58:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:58:04 DISPATCHER: Trying to submit another job.
10:58:04 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464
10:58:04 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
10:58:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:58:04 WORKER: start processing job (9, 0, 4)
10:58:04 WORKER: args: ()
10:58:04 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 951, 'last_n_outputs': 39, 'leak_rate': 0.8102337301261942, 'lr': 0.019663492803048816, 'optimizer': 'SGD', 'sparsity': 0.7740059043358033, 'steps_to_train': 61, 'weight_decay': 0.1115507497592884}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:58:27 DISPATCHER: Starting worker discovery
10:58:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:58:27 DISPATCHER: Finished worker discovery
10:59:27 DISPATCHER: Starting worker discovery
10:59:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:59:27 DISPATCHER: Finished worker discovery
11:00:27 DISPATCHER: Starting worker discovery
11:00:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:00:27 DISPATCHER: Finished worker discovery
11:00:32 WORKER: done with job (9, 0, 4), trying to register it.
11:00:32 WORKER: registered result for job (9, 0, 4) with dispatcher
11:00:32 DISPATCHER: job (9, 0, 4) finished
11:00:32 DISPATCHER: register_result: lock acquired
11:00:32 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
11:00:32 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 951, 'last_n_outputs': 39, 'leak_rate': 0.8102337301261942, 'lr': 0.019663492803048816, 'optimizer': 'SGD', 'sparsity': 0.7740059043358033, 'steps_to_train': 61, 'weight_decay': 0.1115507497592884}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.21606258793749522, 'info': {'data05': 0.21606258793749522, 'config': "{'batch_size': 64, 'hidden_dim': 951, 'last_n_outputs': 39, 'leak_rate': 0.8102337301261942, 'lr': 0.019663492803048816, 'optimizer': 'SGD', 'sparsity': 0.7740059043358033, 'steps_to_train': 61, 'weight_decay': 0.1115507497592884}"}}
exception: None

11:00:32 job_callback for (9, 0, 4) started
11:00:32 DISPATCHER: Trying to submit another job.
11:00:32 job_callback for (9, 0, 4) got condition
11:00:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:00:32 HBMASTER: Trying to run another job!
11:00:32 job_callback for (9, 0, 4) finished
11:00:32 start sampling a new configuration.
11:00:32 best_vector: [1, 0.8850387030256961, 0.9195063922559215, 0.17555227412288954, 0.07279575359905388, 1, 0.48339941935106706, 0.09007012837588624, 0.44948839592893186], 0.017629123604579678, 0.6338342321137104, 0.011173942022746446
11:00:32 done sampling a new configuration.
11:00:32 HBMASTER: schedule new run for iteration 9
11:00:32 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
11:00:32 HBMASTER: submitting job (9, 0, 5) to dispatcher
11:00:32 DISPATCHER: trying to submit job (9, 0, 5)
11:00:32 DISPATCHER: trying to notify the job_runner thread.
11:00:32 HBMASTER: job (9, 0, 5) submitted to dispatcher
11:00:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:00:32 DISPATCHER: Trying to submit another job.
11:00:32 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:00:32 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:00:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:00:32 WORKER: start processing job (9, 0, 5)
11:00:32 WORKER: args: ()
11:00:32 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 908, 'last_n_outputs': 47, 'leak_rate': 0.7938880685307224, 'lr': 0.0013982715044412492, 'optimizer': 'SGD', 'sparsity': 0.8660158606442561, 'steps_to_train': 18, 'weight_decay': 0.03844128403907989}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:01:27 DISPATCHER: Starting worker discovery
11:01:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:01:27 DISPATCHER: Finished worker discovery
11:02:27 DISPATCHER: Starting worker discovery
11:02:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:02:27 DISPATCHER: Finished worker discovery
11:02:59 WORKER: done with job (9, 0, 5), trying to register it.
11:02:59 WORKER: registered result for job (9, 0, 5) with dispatcher
11:02:59 DISPATCHER: job (9, 0, 5) finished
11:02:59 DISPATCHER: register_result: lock acquired
11:02:59 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
11:02:59 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 908, 'last_n_outputs': 47, 'leak_rate': 0.7938880685307224, 'lr': 0.0013982715044412492, 'optimizer': 'SGD', 'sparsity': 0.8660158606442561, 'steps_to_train': 18, 'weight_decay': 0.03844128403907989}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7278234475896181, 'info': {'data05': 0.7278234475896181, 'config': "{'batch_size': 32, 'hidden_dim': 908, 'last_n_outputs': 47, 'leak_rate': 0.7938880685307224, 'lr': 0.0013982715044412492, 'optimizer': 'SGD', 'sparsity': 0.8660158606442561, 'steps_to_train': 18, 'weight_decay': 0.03844128403907989}"}}
exception: None

11:02:59 job_callback for (9, 0, 5) started
11:02:59 DISPATCHER: Trying to submit another job.
11:02:59 job_callback for (9, 0, 5) got condition
11:02:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:02:59 HBMASTER: Trying to run another job!
11:02:59 job_callback for (9, 0, 5) finished
11:02:59 start sampling a new configuration.
11:02:59 best_vector: [0, 0.9916696693172973, 0.9200087633237523, 0.20613206211366691, 0.22113031551868279, 1, 0.964812819663506, 0.35840700522719937, 0.730706549802944], 0.006689862403505202, 5.4261128130936935, 0.03629994810549335
11:02:59 done sampling a new configuration.
11:02:59 HBMASTER: schedule new run for iteration 9
11:02:59 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
11:02:59 HBMASTER: submitting job (9, 0, 6) to dispatcher
11:02:59 DISPATCHER: trying to submit job (9, 0, 6)
11:02:59 DISPATCHER: trying to notify the job_runner thread.
11:02:59 HBMASTER: job (9, 0, 6) submitted to dispatcher
11:02:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:02:59 DISPATCHER: Trying to submit another job.
11:02:59 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:02:59 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:02:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:02:59 WORKER: start processing job (9, 0, 6)
11:02:59 WORKER: args: ()
11:02:59 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 994, 'last_n_outputs': 47, 'leak_rate': 0.8015330155284167, 'lr': 0.002768602655014697, 'optimizer': 'SGD', 'sparsity': 0.9815550767192414, 'steps_to_train': 42, 'weight_decay': 0.08926293023386002}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:03:27 DISPATCHER: Starting worker discovery
11:03:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:03:27 DISPATCHER: Finished worker discovery
11:04:27 DISPATCHER: Starting worker discovery
11:04:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:04:27 DISPATCHER: Finished worker discovery
11:05:27 DISPATCHER: Starting worker discovery
11:05:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:05:27 DISPATCHER: Finished worker discovery
11:05:30 WORKER: done with job (9, 0, 6), trying to register it.
11:05:30 WORKER: registered result for job (9, 0, 6) with dispatcher
11:05:30 DISPATCHER: job (9, 0, 6) finished
11:05:30 DISPATCHER: register_result: lock acquired
11:05:30 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
11:05:30 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 994, 'last_n_outputs': 47, 'leak_rate': 0.8015330155284167, 'lr': 0.002768602655014697, 'optimizer': 'SGD', 'sparsity': 0.9815550767192414, 'steps_to_train': 42, 'weight_decay': 0.08926293023386002}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7371840816946793, 'info': {'data05': 0.7371840816946793, 'config': "{'batch_size': 16, 'hidden_dim': 994, 'last_n_outputs': 47, 'leak_rate': 0.8015330155284167, 'lr': 0.002768602655014697, 'optimizer': 'SGD', 'sparsity': 0.9815550767192414, 'steps_to_train': 42, 'weight_decay': 0.08926293023386002}"}}
exception: None

11:05:30 job_callback for (9, 0, 6) started
11:05:30 DISPATCHER: Trying to submit another job.
11:05:30 job_callback for (9, 0, 6) got condition
11:05:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:05:30 HBMASTER: Trying to run another job!
11:05:30 job_callback for (9, 0, 6) finished
11:05:30 start sampling a new configuration.
11:05:30 done sampling a new configuration.
11:05:30 HBMASTER: schedule new run for iteration 9
11:05:30 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
11:05:30 HBMASTER: submitting job (9, 0, 7) to dispatcher
11:05:30 DISPATCHER: trying to submit job (9, 0, 7)
11:05:30 DISPATCHER: trying to notify the job_runner thread.
11:05:30 HBMASTER: job (9, 0, 7) submitted to dispatcher
11:05:30 DISPATCHER: Trying to submit another job.
11:05:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:05:30 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:05:30 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:05:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:05:30 WORKER: start processing job (9, 0, 7)
11:05:30 WORKER: args: ()
11:05:30 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 453, 'last_n_outputs': 17, 'leak_rate': 0.8072584135669112, 'lr': 0.0032155714449318864, 'optimizer': 'Adam', 'sparsity': 0.7955035436642174, 'steps_to_train': 96, 'weight_decay': 0.09881696030708743}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:06:27 DISPATCHER: Starting worker discovery
11:06:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:06:28 DISPATCHER: Finished worker discovery
11:07:28 DISPATCHER: Starting worker discovery
11:07:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:07:28 DISPATCHER: Finished worker discovery
11:07:56 WORKER: done with job (9, 0, 7), trying to register it.
11:07:56 WORKER: registered result for job (9, 0, 7) with dispatcher
11:07:56 DISPATCHER: job (9, 0, 7) finished
11:07:56 DISPATCHER: register_result: lock acquired
11:07:56 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
11:07:56 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 453, 'last_n_outputs': 17, 'leak_rate': 0.8072584135669112, 'lr': 0.0032155714449318864, 'optimizer': 'Adam', 'sparsity': 0.7955035436642174, 'steps_to_train': 96, 'weight_decay': 0.09881696030708743}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3624182977546713, 'info': {'data05': 0.3624182977546713, 'config': "{'batch_size': 32, 'hidden_dim': 453, 'last_n_outputs': 17, 'leak_rate': 0.8072584135669112, 'lr': 0.0032155714449318864, 'optimizer': 'Adam', 'sparsity': 0.7955035436642174, 'steps_to_train': 96, 'weight_decay': 0.09881696030708743}"}}
exception: None

11:07:56 job_callback for (9, 0, 7) started
11:07:56 DISPATCHER: Trying to submit another job.
11:07:56 job_callback for (9, 0, 7) got condition
11:07:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:07:56 HBMASTER: Trying to run another job!
11:07:56 job_callback for (9, 0, 7) finished
11:07:56 start sampling a new configuration.
11:07:57 best_vector: [2, 0.8085371635999419, 0.9670817543995166, 0.05652824336583322, 0.4976035582088503, 1, 0.4333469542811156, 0.26319736248128695, 0.17146527476821483], 0.025246198825140245, 0.48212644355833223, 0.012171860052931412
11:07:57 done sampling a new configuration.
11:07:57 HBMASTER: schedule new run for iteration 9
11:07:57 HBMASTER: trying submitting job (9, 0, 8) to dispatcher
11:07:57 HBMASTER: submitting job (9, 0, 8) to dispatcher
11:07:57 DISPATCHER: trying to submit job (9, 0, 8)
11:07:57 DISPATCHER: trying to notify the job_runner thread.
11:07:57 HBMASTER: job (9, 0, 8) submitted to dispatcher
11:07:57 DISPATCHER: Trying to submit another job.
11:07:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:07:57 DISPATCHER: starting job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:07:57 DISPATCHER: job (9, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:07:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:07:57 WORKER: start processing job (9, 0, 8)
11:07:57 WORKER: args: ()
11:07:57 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 847, 'last_n_outputs': 49, 'leak_rate': 0.7641320608414583, 'lr': 0.00989024651201808, 'optimizer': 'SGD', 'sparsity': 0.8540032690274677, 'steps_to_train': 33, 'weight_decay': 0.016714041096964314}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:08:28 DISPATCHER: Starting worker discovery
11:08:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:08:28 DISPATCHER: Finished worker discovery
11:09:28 DISPATCHER: Starting worker discovery
11:09:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:09:28 DISPATCHER: Finished worker discovery
11:10:23 WORKER: done with job (9, 0, 8), trying to register it.
11:10:23 WORKER: registered result for job (9, 0, 8) with dispatcher
11:10:23 DISPATCHER: job (9, 0, 8) finished
11:10:23 DISPATCHER: register_result: lock acquired
11:10:23 DISPATCHER: job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
11:10:23 job_id: (9, 0, 8)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 847, 'last_n_outputs': 49, 'leak_rate': 0.7641320608414583, 'lr': 0.00989024651201808, 'optimizer': 'SGD', 'sparsity': 0.8540032690274677, 'steps_to_train': 33, 'weight_decay': 0.016714041096964314}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7741919414322351, 'info': {'data05': 0.7741919414322351, 'config': "{'batch_size': 64, 'hidden_dim': 847, 'last_n_outputs': 49, 'leak_rate': 0.7641320608414583, 'lr': 0.00989024651201808, 'optimizer': 'SGD', 'sparsity': 0.8540032690274677, 'steps_to_train': 33, 'weight_decay': 0.016714041096964314}"}}
exception: None

11:10:23 job_callback for (9, 0, 8) started
11:10:23 job_callback for (9, 0, 8) got condition
11:10:23 DISPATCHER: Trying to submit another job.
11:10:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:10:23 HBMASTER: Trying to run another job!
11:10:23 job_callback for (9, 0, 8) finished
11:10:23 ITERATION: Advancing config (9, 0, 0) to next budget 400.000000
11:10:23 ITERATION: Advancing config (9, 0, 3) to next budget 400.000000
11:10:23 ITERATION: Advancing config (9, 0, 8) to next budget 400.000000
11:10:23 HBMASTER: schedule new run for iteration 9
11:10:23 HBMASTER: trying submitting job (9, 0, 0) to dispatcher
11:10:23 HBMASTER: submitting job (9, 0, 0) to dispatcher
11:10:23 DISPATCHER: trying to submit job (9, 0, 0)
11:10:23 DISPATCHER: trying to notify the job_runner thread.
11:10:23 HBMASTER: job (9, 0, 0) submitted to dispatcher
11:10:23 DISPATCHER: Trying to submit another job.
11:10:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:10:23 DISPATCHER: starting job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:10:23 DISPATCHER: job (9, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:10:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:10:23 WORKER: start processing job (9, 0, 0)
11:10:23 WORKER: args: ()
11:10:23 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 878, 'last_n_outputs': 47, 'leak_rate': 0.8098426909979127, 'lr': 0.006989219889751191, 'optimizer': 'SGD', 'sparsity': 0.9482210249458098, 'steps_to_train': 15, 'weight_decay': 0.01984487419211664}, 'budget': 400.0, 'working_directory': '.'}
11:10:28 DISPATCHER: Starting worker discovery
11:10:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:10:28 DISPATCHER: Finished worker discovery
11:11:28 DISPATCHER: Starting worker discovery
11:11:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:11:28 DISPATCHER: Finished worker discovery
11:12:28 DISPATCHER: Starting worker discovery
11:12:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:12:28 DISPATCHER: Finished worker discovery
11:13:28 DISPATCHER: Starting worker discovery
11:13:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:13:28 DISPATCHER: Finished worker discovery
11:14:28 DISPATCHER: Starting worker discovery
11:14:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:14:28 DISPATCHER: Finished worker discovery
11:15:28 DISPATCHER: Starting worker discovery
11:15:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:15:28 DISPATCHER: Finished worker discovery
11:16:28 DISPATCHER: Starting worker discovery
11:16:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:16:28 DISPATCHER: Finished worker discovery
11:17:21 WORKER: done with job (9, 0, 0), trying to register it.
11:17:21 WORKER: registered result for job (9, 0, 0) with dispatcher
11:17:21 DISPATCHER: job (9, 0, 0) finished
11:17:21 DISPATCHER: register_result: lock acquired
11:17:21 DISPATCHER: job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
11:17:21 job_id: (9, 0, 0)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 878, 'last_n_outputs': 47, 'leak_rate': 0.8098426909979127, 'lr': 0.006989219889751191, 'optimizer': 'SGD', 'sparsity': 0.9482210249458098, 'steps_to_train': 15, 'weight_decay': 0.01984487419211664}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7689099607853931, 'info': {'data05': 0.7689099607853931, 'config': "{'batch_size': 64, 'hidden_dim': 878, 'last_n_outputs': 47, 'leak_rate': 0.8098426909979127, 'lr': 0.006989219889751191, 'optimizer': 'SGD', 'sparsity': 0.9482210249458098, 'steps_to_train': 15, 'weight_decay': 0.01984487419211664}"}}
exception: None

11:17:21 job_callback for (9, 0, 0) started
11:17:21 job_callback for (9, 0, 0) got condition
11:17:21 DISPATCHER: Trying to submit another job.
11:17:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:17:21 done building a new model for budget 400.000000 based on 10/23 split
Best loss for this budget:-0.773507





11:17:21 HBMASTER: Trying to run another job!
11:17:21 job_callback for (9, 0, 0) finished
11:17:21 HBMASTER: schedule new run for iteration 9
11:17:21 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
11:17:21 HBMASTER: submitting job (9, 0, 3) to dispatcher
11:17:21 DISPATCHER: trying to submit job (9, 0, 3)
11:17:21 DISPATCHER: trying to notify the job_runner thread.
11:17:21 HBMASTER: job (9, 0, 3) submitted to dispatcher
11:17:21 DISPATCHER: Trying to submit another job.
11:17:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:17:21 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:17:21 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:17:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:17:21 WORKER: start processing job (9, 0, 3)
11:17:21 WORKER: args: ()
11:17:21 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 967, 'last_n_outputs': 50, 'leak_rate': 0.8709385129009292, 'lr': 0.00679060559018793, 'optimizer': 'SGD', 'sparsity': 0.9690328820356955, 'steps_to_train': 10, 'weight_decay': 0.08384807870291924}, 'budget': 400.0, 'working_directory': '.'}
11:17:28 DISPATCHER: Starting worker discovery
11:17:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:17:28 DISPATCHER: Finished worker discovery
11:18:28 DISPATCHER: Starting worker discovery
11:18:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:18:28 DISPATCHER: Finished worker discovery
11:19:28 DISPATCHER: Starting worker discovery
11:19:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:19:28 DISPATCHER: Finished worker discovery
11:20:28 DISPATCHER: Starting worker discovery
11:20:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:20:28 DISPATCHER: Finished worker discovery
11:21:28 DISPATCHER: Starting worker discovery
11:21:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:21:28 DISPATCHER: Finished worker discovery
11:22:28 DISPATCHER: Starting worker discovery
11:22:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:22:28 DISPATCHER: Finished worker discovery
11:23:28 DISPATCHER: Starting worker discovery
11:23:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:23:28 DISPATCHER: Finished worker discovery
11:24:24 WORKER: done with job (9, 0, 3), trying to register it.
11:24:24 WORKER: registered result for job (9, 0, 3) with dispatcher
11:24:24 DISPATCHER: job (9, 0, 3) finished
11:24:24 DISPATCHER: register_result: lock acquired
11:24:24 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
11:24:24 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 967, 'last_n_outputs': 50, 'leak_rate': 0.8709385129009292, 'lr': 0.00679060559018793, 'optimizer': 'SGD', 'sparsity': 0.9690328820356955, 'steps_to_train': 10, 'weight_decay': 0.08384807870291924}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7548784417250831, 'info': {'data05': 0.7548784417250831, 'config': "{'batch_size': 64, 'hidden_dim': 967, 'last_n_outputs': 50, 'leak_rate': 0.8709385129009292, 'lr': 0.00679060559018793, 'optimizer': 'SGD', 'sparsity': 0.9690328820356955, 'steps_to_train': 10, 'weight_decay': 0.08384807870291924}"}}
exception: None

11:24:24 job_callback for (9, 0, 3) started
11:24:24 job_callback for (9, 0, 3) got condition
11:24:24 DISPATCHER: Trying to submit another job.
11:24:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:24:24 done building a new model for budget 400.000000 based on 10/24 split
Best loss for this budget:-0.773507





11:24:24 HBMASTER: Trying to run another job!
11:24:24 job_callback for (9, 0, 3) finished
11:24:24 HBMASTER: schedule new run for iteration 9
11:24:24 HBMASTER: trying submitting job (9, 0, 8) to dispatcher
11:24:24 HBMASTER: submitting job (9, 0, 8) to dispatcher
11:24:24 DISPATCHER: trying to submit job (9, 0, 8)
11:24:24 DISPATCHER: trying to notify the job_runner thread.
11:24:24 HBMASTER: job (9, 0, 8) submitted to dispatcher
11:24:24 DISPATCHER: Trying to submit another job.
11:24:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:24:24 DISPATCHER: starting job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:24:24 DISPATCHER: job (9, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:24:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:24:24 WORKER: start processing job (9, 0, 8)
11:24:24 WORKER: args: ()
11:24:24 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 847, 'last_n_outputs': 49, 'leak_rate': 0.7641320608414583, 'lr': 0.00989024651201808, 'optimizer': 'SGD', 'sparsity': 0.8540032690274677, 'steps_to_train': 33, 'weight_decay': 0.016714041096964314}, 'budget': 400.0, 'working_directory': '.'}
11:24:28 DISPATCHER: Starting worker discovery
11:24:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:24:28 DISPATCHER: Finished worker discovery
11:25:28 DISPATCHER: Starting worker discovery
11:25:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:25:28 DISPATCHER: Finished worker discovery
11:26:28 DISPATCHER: Starting worker discovery
11:26:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:26:28 DISPATCHER: Finished worker discovery
11:27:28 DISPATCHER: Starting worker discovery
11:27:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:27:28 DISPATCHER: Finished worker discovery
11:28:28 DISPATCHER: Starting worker discovery
11:28:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:28:28 DISPATCHER: Finished worker discovery
11:29:28 DISPATCHER: Starting worker discovery
11:29:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:29:28 DISPATCHER: Finished worker discovery
11:30:28 DISPATCHER: Starting worker discovery
11:30:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:30:28 DISPATCHER: Finished worker discovery
11:31:21 WORKER: done with job (9, 0, 8), trying to register it.
11:31:21 WORKER: registered result for job (9, 0, 8) with dispatcher
11:31:21 DISPATCHER: job (9, 0, 8) finished
11:31:21 DISPATCHER: register_result: lock acquired
11:31:21 DISPATCHER: job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
11:31:21 job_id: (9, 0, 8)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 847, 'last_n_outputs': 49, 'leak_rate': 0.7641320608414583, 'lr': 0.00989024651201808, 'optimizer': 'SGD', 'sparsity': 0.8540032690274677, 'steps_to_train': 33, 'weight_decay': 0.016714041096964314}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7743622202219488, 'info': {'data05': 0.7743622202219488, 'config': "{'batch_size': 64, 'hidden_dim': 847, 'last_n_outputs': 49, 'leak_rate': 0.7641320608414583, 'lr': 0.00989024651201808, 'optimizer': 'SGD', 'sparsity': 0.8540032690274677, 'steps_to_train': 33, 'weight_decay': 0.016714041096964314}"}}
exception: None

11:31:21 job_callback for (9, 0, 8) started
11:31:21 job_callback for (9, 0, 8) got condition
11:31:21 DISPATCHER: Trying to submit another job.
11:31:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:31:21 done building a new model for budget 400.000000 based on 10/25 split
Best loss for this budget:-0.774362





11:31:21 HBMASTER: Trying to run another job!
11:31:21 job_callback for (9, 0, 8) finished
11:31:21 ITERATION: Advancing config (9, 0, 8) to next budget 1200.000000
11:31:21 HBMASTER: schedule new run for iteration 9
11:31:21 HBMASTER: trying submitting job (9, 0, 8) to dispatcher
11:31:21 HBMASTER: submitting job (9, 0, 8) to dispatcher
11:31:21 DISPATCHER: trying to submit job (9, 0, 8)
11:31:21 DISPATCHER: trying to notify the job_runner thread.
11:31:21 HBMASTER: job (9, 0, 8) submitted to dispatcher
11:31:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:31:21 DISPATCHER: Trying to submit another job.
11:31:21 DISPATCHER: starting job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:31:21 DISPATCHER: job (9, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:31:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:31:21 WORKER: start processing job (9, 0, 8)
11:31:21 WORKER: args: ()
11:31:21 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 847, 'last_n_outputs': 49, 'leak_rate': 0.7641320608414583, 'lr': 0.00989024651201808, 'optimizer': 'SGD', 'sparsity': 0.8540032690274677, 'steps_to_train': 33, 'weight_decay': 0.016714041096964314}, 'budget': 1200.0, 'working_directory': '.'}
11:31:28 DISPATCHER: Starting worker discovery
11:31:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:31:28 DISPATCHER: Finished worker discovery
11:32:28 DISPATCHER: Starting worker discovery
11:32:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:32:28 DISPATCHER: Finished worker discovery
11:33:28 DISPATCHER: Starting worker discovery
11:33:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:33:28 DISPATCHER: Finished worker discovery
11:34:28 DISPATCHER: Starting worker discovery
11:34:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:34:28 DISPATCHER: Finished worker discovery
11:35:28 DISPATCHER: Starting worker discovery
11:35:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:35:28 DISPATCHER: Finished worker discovery
11:36:28 DISPATCHER: Starting worker discovery
11:36:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:36:28 DISPATCHER: Finished worker discovery
11:37:28 DISPATCHER: Starting worker discovery
11:37:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:37:28 DISPATCHER: Finished worker discovery
11:38:28 DISPATCHER: Starting worker discovery
11:38:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:38:28 DISPATCHER: Finished worker discovery
11:39:28 DISPATCHER: Starting worker discovery
11:39:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:39:28 DISPATCHER: Finished worker discovery
11:40:28 DISPATCHER: Starting worker discovery
11:40:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:40:28 DISPATCHER: Finished worker discovery
11:41:28 DISPATCHER: Starting worker discovery
11:41:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:41:28 DISPATCHER: Finished worker discovery
11:42:28 DISPATCHER: Starting worker discovery
11:42:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:42:28 DISPATCHER: Finished worker discovery
11:43:28 DISPATCHER: Starting worker discovery
11:43:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:43:28 DISPATCHER: Finished worker discovery
11:44:28 DISPATCHER: Starting worker discovery
11:44:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:44:28 DISPATCHER: Finished worker discovery
11:45:28 DISPATCHER: Starting worker discovery
11:45:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:45:28 DISPATCHER: Finished worker discovery
11:46:28 DISPATCHER: Starting worker discovery
11:46:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:46:28 DISPATCHER: Finished worker discovery
11:47:28 DISPATCHER: Starting worker discovery
11:47:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:47:28 DISPATCHER: Finished worker discovery
11:48:28 DISPATCHER: Starting worker discovery
11:48:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:48:28 DISPATCHER: Finished worker discovery
11:49:28 DISPATCHER: Starting worker discovery
11:49:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:49:28 DISPATCHER: Finished worker discovery
11:50:28 DISPATCHER: Starting worker discovery
11:50:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:50:28 DISPATCHER: Finished worker discovery
11:51:28 DISPATCHER: Starting worker discovery
11:51:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:51:28 DISPATCHER: Finished worker discovery
11:51:46 WORKER: done with job (9, 0, 8), trying to register it.
11:51:46 WORKER: registered result for job (9, 0, 8) with dispatcher
11:51:46 DISPATCHER: job (9, 0, 8) finished
11:51:46 DISPATCHER: register_result: lock acquired
11:51:46 DISPATCHER: job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
11:51:46 job_id: (9, 0, 8)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 847, 'last_n_outputs': 49, 'leak_rate': 0.7641320608414583, 'lr': 0.00989024651201808, 'optimizer': 'SGD', 'sparsity': 0.8540032690274677, 'steps_to_train': 33, 'weight_decay': 0.016714041096964314}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.7535476478193178, 'info': {'data05': 0.7535476478193178, 'config': "{'batch_size': 64, 'hidden_dim': 847, 'last_n_outputs': 49, 'leak_rate': 0.7641320608414583, 'lr': 0.00989024651201808, 'optimizer': 'SGD', 'sparsity': 0.8540032690274677, 'steps_to_train': 33, 'weight_decay': 0.016714041096964314}"}}
exception: None

11:51:46 job_callback for (9, 0, 8) started
11:51:46 job_callback for (9, 0, 8) got condition
11:51:46 DISPATCHER: Trying to submit another job.
11:51:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:51:46 HBMASTER: Trying to run another job!
11:51:46 job_callback for (9, 0, 8) finished
11:51:46 HBMASTER: shutdown initiated, shutdown_workers = True
11:51:46 WORKER: shutting down now!
11:51:46 DISPATCHER: Dispatcher shutting down
11:51:46 DISPATCHER: discover_workers shutting down
11:51:46 DISPATCHER: Trying to submit another job.
11:51:46 DISPATCHER: 'discover_worker' thread exited
11:51:46 DISPATCHER: job_runner shutting down
11:51:46 DISPATCHER: 'job_runner' thread exited
11:51:46 DISPATCHER: shut down complete
11:51:46 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7f9d849d5be0; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:37620>
11:51:46 WORKER: No dispatcher found. Waiting for one to initiate contact.
11:51:46 WORKER: start listening for jobs
11:51:46 wait_for_workers trying to get the condition
11:51:46 DISPATCHER: started the 'discover_worker' thread
11:51:46 DISPATCHER: started the 'job_runner' thread
11:51:46 DISPATCHER: Pyro daemon running on localhost:40789
11:51:46 HBMASTER: only 0 worker(s) available, waiting for at least 1.
11:51:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:51:46 DISPATCHER: Starting worker discovery
11:51:46 DISPATCHER: Found 1 potential workers, 0 currently in the pool.
11:51:46 DISPATCHER: discovered new worker, hpbandster.run_0.worker.metagpuj.13101140314513094464
11:51:46 HBMASTER: number of workers changed to 1
11:51:46 adjust_queue_size: lock accquired
11:51:46 HBMASTER: adjusted queue size to (0, 1)
11:51:46 DISPATCHER: Finished worker discovery
11:51:46 DISPATCHER: A new worker triggered discover_worker
11:51:46 DISPATCHER: Trying to submit another job.
11:51:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:51:46 Enough workers to start this run!
11:51:46 DISPATCHER: Starting worker discovery
11:51:46 HBMASTER: starting run at 1583837506.8586283
11:51:46 start sampling a new configuration.
11:51:46 done sampling a new configuration.
11:51:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:51:46 HBMASTER: schedule new run for iteration 0
11:51:46 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
11:51:46 HBMASTER: submitting job (0, 0, 0) to dispatcher
11:51:46 DISPATCHER: trying to submit job (0, 0, 0)
11:51:46 DISPATCHER: Finished worker discovery
11:51:46 DISPATCHER: trying to notify the job_runner thread.
11:51:46 HBMASTER: job (0, 0, 0) submitted to dispatcher
11:51:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:51:46 DISPATCHER: Trying to submit another job.
11:51:46 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:51:46 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:51:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:51:46 WORKER: start processing job (0, 0, 0)
11:51:46 WORKER: args: ()
11:51:46 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.06480645950082745, 'num_filters_1': 51, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.01962837371432568, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 123, 'num_filters_3': 17, 'num_filters_4': 62}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:52:46 WORKER: done with job (0, 0, 0), trying to register it.
11:52:46 WORKER: registered result for job (0, 0, 0) with dispatcher
11:52:46 DISPATCHER: job (0, 0, 0) finished
11:52:46 DISPATCHER: register_result: lock acquired
11:52:46 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
11:52:46 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.06480645950082745, 'num_filters_1': 51, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.01962837371432568, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 123, 'num_filters_3': 17, 'num_filters_4': 62}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.42057887539018335, 'info': {'data05': 0.42057887539018335, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.06480645950082745, 'num_filters_1': 51, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.01962837371432568, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 123, 'num_filters_3': 17, 'num_filters_4': 62}"}}
exception: None

11:52:46 job_callback for (0, 0, 0) started
11:52:46 DISPATCHER: Trying to submit another job.
11:52:46 job_callback for (0, 0, 0) got condition
11:52:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:52:46 Only 1 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
11:52:46 HBMASTER: Trying to run another job!
11:52:46 job_callback for (0, 0, 0) finished
11:52:46 start sampling a new configuration.
11:52:46 done sampling a new configuration.
11:52:46 HBMASTER: schedule new run for iteration 0
11:52:46 HBMASTER: trying submitting job (0, 0, 1) to dispatcher
11:52:46 HBMASTER: submitting job (0, 0, 1) to dispatcher
11:52:46 DISPATCHER: trying to submit job (0, 0, 1)
11:52:46 DISPATCHER: trying to notify the job_runner thread.
11:52:46 HBMASTER: job (0, 0, 1) submitted to dispatcher
11:52:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:52:46 DISPATCHER: Trying to submit another job.
11:52:46 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:52:46 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:52:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:52:46 WORKER: start processing job (0, 0, 1)
11:52:46 WORKER: args: ()
11:52:46 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.012145696821790942, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.058375195583470915, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 81, 'num_filters_3': 66, 'num_filters_4': 30, 'num_filters_5': 50}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:52:46 DISPATCHER: Starting worker discovery
11:52:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:52:46 DISPATCHER: Finished worker discovery
11:53:44 WORKER: done with job (0, 0, 1), trying to register it.
11:53:44 WORKER: registered result for job (0, 0, 1) with dispatcher
11:53:44 DISPATCHER: job (0, 0, 1) finished
11:53:44 DISPATCHER: register_result: lock acquired
11:53:44 DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
11:53:44 job_id: (0, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.012145696821790942, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.058375195583470915, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 81, 'num_filters_3': 66, 'num_filters_4': 30, 'num_filters_5': 50}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5324967306186542, 'info': {'data05': 0.5324967306186542, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.012145696821790942, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.058375195583470915, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 81, 'num_filters_3': 66, 'num_filters_4': 30, 'num_filters_5': 50}"}}
exception: None

11:53:44 job_callback for (0, 0, 1) started
11:53:44 job_callback for (0, 0, 1) got condition
11:53:44 DISPATCHER: Trying to submit another job.
11:53:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:53:44 Only 2 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
11:53:44 HBMASTER: Trying to run another job!
11:53:44 job_callback for (0, 0, 1) finished
11:53:44 start sampling a new configuration.
11:53:44 done sampling a new configuration.
11:53:44 HBMASTER: schedule new run for iteration 0
11:53:44 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
11:53:44 HBMASTER: submitting job (0, 0, 2) to dispatcher
11:53:44 DISPATCHER: trying to submit job (0, 0, 2)
11:53:44 DISPATCHER: trying to notify the job_runner thread.
11:53:44 HBMASTER: job (0, 0, 2) submitted to dispatcher
11:53:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:53:44 DISPATCHER: Trying to submit another job.
11:53:44 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:53:44 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:53:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:53:45 WORKER: start processing job (0, 0, 2)
11:53:45 WORKER: args: ()
11:53:45 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0655351871224376, 'num_filters_1': 112, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 68, 'weight_decay': 0.16813476486643147, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 34, 'num_filters_3': 23, 'num_filters_4': 24, 'num_filters_5': 56}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:53:46 DISPATCHER: Starting worker discovery
11:53:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:53:46 DISPATCHER: Finished worker discovery
11:54:42 WORKER: done with job (0, 0, 2), trying to register it.
11:54:42 WORKER: registered result for job (0, 0, 2) with dispatcher
11:54:42 DISPATCHER: job (0, 0, 2) finished
11:54:42 DISPATCHER: register_result: lock acquired
11:54:42 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
11:54:42 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0655351871224376, 'num_filters_1': 112, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 68, 'weight_decay': 0.16813476486643147, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 34, 'num_filters_3': 23, 'num_filters_4': 24, 'num_filters_5': 56}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0002749998385484839, 'info': {'data05': 0.0002749998385484839, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0655351871224376, 'num_filters_1': 112, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 68, 'weight_decay': 0.16813476486643147, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 34, 'num_filters_3': 23, 'num_filters_4': 24, 'num_filters_5': 56}"}}
exception: None

11:54:42 DISPATCHER: Trying to submit another job.
11:54:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:54:42 job_callback for (0, 0, 2) started
11:54:42 job_callback for (0, 0, 2) got condition
11:54:42 Only 3 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
11:54:42 HBMASTER: Trying to run another job!
11:54:42 job_callback for (0, 0, 2) finished
11:54:42 start sampling a new configuration.
11:54:42 done sampling a new configuration.
11:54:42 HBMASTER: schedule new run for iteration 0
11:54:42 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
11:54:42 HBMASTER: submitting job (0, 0, 3) to dispatcher
11:54:42 DISPATCHER: trying to submit job (0, 0, 3)
11:54:42 DISPATCHER: trying to notify the job_runner thread.
11:54:42 HBMASTER: job (0, 0, 3) submitted to dispatcher
11:54:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:54:42 DISPATCHER: Trying to submit another job.
11:54:42 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:54:42 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:54:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:54:42 WORKER: start processing job (0, 0, 3)
11:54:42 WORKER: args: ()
11:54:42 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.003919647995096743, 'num_filters_1': 33, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.1584993627990004, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 30, 'num_filters_3': 28, 'num_filters_4': 64, 'num_filters_5': 53}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:54:46 DISPATCHER: Starting worker discovery
11:54:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:54:46 DISPATCHER: Finished worker discovery
11:55:39 WORKER: done with job (0, 0, 3), trying to register it.
11:55:39 WORKER: registered result for job (0, 0, 3) with dispatcher
11:55:39 DISPATCHER: job (0, 0, 3) finished
11:55:39 DISPATCHER: register_result: lock acquired
11:55:39 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
11:55:39 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.003919647995096743, 'num_filters_1': 33, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.1584993627990004, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 30, 'num_filters_3': 28, 'num_filters_4': 64, 'num_filters_5': 53}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.0070926430317516925, 'info': {'data05': -0.0070926430317516925, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.003919647995096743, 'num_filters_1': 33, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.1584993627990004, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 30, 'num_filters_3': 28, 'num_filters_4': 64, 'num_filters_5': 53}"}}
exception: None

11:55:39 job_callback for (0, 0, 3) started
11:55:39 DISPATCHER: Trying to submit another job.
11:55:39 job_callback for (0, 0, 3) got condition
11:55:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:55:39 Only 4 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
11:55:39 HBMASTER: Trying to run another job!
11:55:39 job_callback for (0, 0, 3) finished
11:55:39 start sampling a new configuration.
11:55:39 done sampling a new configuration.
11:55:39 HBMASTER: schedule new run for iteration 0
11:55:39 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
11:55:39 HBMASTER: submitting job (0, 0, 4) to dispatcher
11:55:39 DISPATCHER: trying to submit job (0, 0, 4)
11:55:39 DISPATCHER: trying to notify the job_runner thread.
11:55:39 HBMASTER: job (0, 0, 4) submitted to dispatcher
11:55:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:55:39 DISPATCHER: Trying to submit another job.
11:55:39 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:55:39 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:55:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:55:39 WORKER: start processing job (0, 0, 4)
11:55:39 WORKER: args: ()
11:55:39 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.02361167628159265, 'num_filters_1': 122, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.027452042517560196, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 80, 'num_filters_3': 123, 'num_filters_4': 74}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:55:46 DISPATCHER: Starting worker discovery
11:55:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:55:46 DISPATCHER: Finished worker discovery
11:56:39 WORKER: done with job (0, 0, 4), trying to register it.
11:56:39 WORKER: registered result for job (0, 0, 4) with dispatcher
11:56:39 DISPATCHER: job (0, 0, 4) finished
11:56:39 DISPATCHER: register_result: lock acquired
11:56:39 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
11:56:39 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.02361167628159265, 'num_filters_1': 122, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.027452042517560196, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 80, 'num_filters_3': 123, 'num_filters_4': 74}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.02361167628159265, 'num_filters_1': 122, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.027452042517560196, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 80, 'num_filters_3': 123, 'num_filters_4': 74}"}}
exception: None

11:56:39 job_callback for (0, 0, 4) started
11:56:39 job_callback for (0, 0, 4) got condition
11:56:39 DISPATCHER: Trying to submit another job.
11:56:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:56:39 Only 5 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
11:56:39 HBMASTER: Trying to run another job!
11:56:39 job_callback for (0, 0, 4) finished
11:56:39 start sampling a new configuration.
11:56:39 done sampling a new configuration.
11:56:39 HBMASTER: schedule new run for iteration 0
11:56:39 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
11:56:39 HBMASTER: submitting job (0, 0, 5) to dispatcher
11:56:39 DISPATCHER: trying to submit job (0, 0, 5)
11:56:39 DISPATCHER: trying to notify the job_runner thread.
11:56:39 HBMASTER: job (0, 0, 5) submitted to dispatcher
11:56:39 DISPATCHER: Trying to submit another job.
11:56:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:56:39 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:56:39 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:56:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:56:39 WORKER: start processing job (0, 0, 5)
11:56:39 WORKER: args: ()
11:56:39 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.04018090694380944, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.17055097936877092}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:56:46 DISPATCHER: Starting worker discovery
11:56:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:56:46 DISPATCHER: Finished worker discovery
11:57:36 WORKER: done with job (0, 0, 5), trying to register it.
11:57:36 WORKER: registered result for job (0, 0, 5) with dispatcher
11:57:36 DISPATCHER: job (0, 0, 5) finished
11:57:36 DISPATCHER: register_result: lock acquired
11:57:36 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
11:57:36 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.04018090694380944, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.17055097936877092}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.08134408979783275, 'info': {'data05': 0.08134408979783275, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.04018090694380944, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.17055097936877092}"}}
exception: None

11:57:36 job_callback for (0, 0, 5) started
11:57:36 job_callback for (0, 0, 5) got condition
11:57:36 DISPATCHER: Trying to submit another job.
11:57:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:57:36 Only 6 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
11:57:36 HBMASTER: Trying to run another job!
11:57:36 job_callback for (0, 0, 5) finished
11:57:36 start sampling a new configuration.
11:57:36 done sampling a new configuration.
11:57:36 HBMASTER: schedule new run for iteration 0
11:57:36 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
11:57:36 HBMASTER: submitting job (0, 0, 6) to dispatcher
11:57:36 DISPATCHER: trying to submit job (0, 0, 6)
11:57:36 DISPATCHER: trying to notify the job_runner thread.
11:57:36 HBMASTER: job (0, 0, 6) submitted to dispatcher
11:57:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:57:36 DISPATCHER: Trying to submit another job.
11:57:36 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:57:36 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:57:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:57:36 WORKER: start processing job (0, 0, 6)
11:57:36 WORKER: args: ()
11:57:36 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.08030858576843809, 'num_filters_1': 81, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.05306706203175475}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:57:46 DISPATCHER: Starting worker discovery
11:57:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:57:46 DISPATCHER: Finished worker discovery
11:58:35 WORKER: done with job (0, 0, 6), trying to register it.
11:58:35 WORKER: registered result for job (0, 0, 6) with dispatcher
11:58:35 DISPATCHER: job (0, 0, 6) finished
11:58:35 DISPATCHER: register_result: lock acquired
11:58:35 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
11:58:35 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.08030858576843809, 'num_filters_1': 81, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.05306706203175475}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.03636247988307889, 'info': {'data05': 0.03636247988307889, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.08030858576843809, 'num_filters_1': 81, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.05306706203175475}"}}
exception: None

11:58:35 job_callback for (0, 0, 6) started
11:58:35 job_callback for (0, 0, 6) got condition
11:58:35 DISPATCHER: Trying to submit another job.
11:58:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:58:35 Only 7 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
11:58:35 HBMASTER: Trying to run another job!
11:58:35 job_callback for (0, 0, 6) finished
11:58:35 start sampling a new configuration.
11:58:35 done sampling a new configuration.
11:58:35 HBMASTER: schedule new run for iteration 0
11:58:35 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
11:58:35 HBMASTER: submitting job (0, 0, 7) to dispatcher
11:58:35 DISPATCHER: trying to submit job (0, 0, 7)
11:58:35 DISPATCHER: trying to notify the job_runner thread.
11:58:35 HBMASTER: job (0, 0, 7) submitted to dispatcher
11:58:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:58:35 DISPATCHER: Trying to submit another job.
11:58:35 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:58:35 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:58:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:58:35 WORKER: start processing job (0, 0, 7)
11:58:35 WORKER: args: ()
11:58:35 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.022871979901065376, 'num_filters_1': 79, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.04028959295819538, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 25, 'num_filters_3': 115, 'num_filters_4': 68, 'num_filters_5': 77}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:58:46 DISPATCHER: Starting worker discovery
11:58:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:58:46 DISPATCHER: Finished worker discovery
11:59:33 WORKER: done with job (0, 0, 7), trying to register it.
11:59:33 WORKER: registered result for job (0, 0, 7) with dispatcher
11:59:33 DISPATCHER: job (0, 0, 7) finished
11:59:33 DISPATCHER: register_result: lock acquired
11:59:33 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
11:59:33 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.022871979901065376, 'num_filters_1': 79, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.04028959295819538, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 25, 'num_filters_3': 115, 'num_filters_4': 68, 'num_filters_5': 77}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6616586724996532, 'info': {'data05': 0.6616586724996532, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.022871979901065376, 'num_filters_1': 79, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.04028959295819538, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 25, 'num_filters_3': 115, 'num_filters_4': 68, 'num_filters_5': 77}"}}
exception: None

11:59:33 job_callback for (0, 0, 7) started
11:59:33 DISPATCHER: Trying to submit another job.
11:59:33 job_callback for (0, 0, 7) got condition
11:59:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:59:33 Only 8 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
11:59:33 HBMASTER: Trying to run another job!
11:59:33 job_callback for (0, 0, 7) finished
11:59:33 start sampling a new configuration.
11:59:33 done sampling a new configuration.
11:59:33 HBMASTER: schedule new run for iteration 0
11:59:33 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
11:59:33 HBMASTER: submitting job (0, 0, 8) to dispatcher
11:59:33 DISPATCHER: trying to submit job (0, 0, 8)
11:59:33 DISPATCHER: trying to notify the job_runner thread.
11:59:33 HBMASTER: job (0, 0, 8) submitted to dispatcher
11:59:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:59:33 DISPATCHER: Trying to submit another job.
11:59:33 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:59:33 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:59:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:59:33 WORKER: start processing job (0, 0, 8)
11:59:33 WORKER: args: ()
11:59:33 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0014920919128087013, 'num_filters_1': 36, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.019367989701785503, 'kernel_size_2': 3, 'num_filters_2': 56}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:59:46 DISPATCHER: Starting worker discovery
11:59:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:59:46 DISPATCHER: Finished worker discovery
12:00:30 WORKER: done with job (0, 0, 8), trying to register it.
12:00:30 WORKER: registered result for job (0, 0, 8) with dispatcher
12:00:30 DISPATCHER: job (0, 0, 8) finished
12:00:30 DISPATCHER: register_result: lock acquired
12:00:30 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:00:30 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0014920919128087013, 'num_filters_1': 36, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.019367989701785503, 'kernel_size_2': 3, 'num_filters_2': 56}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6421884821825827, 'info': {'data05': 0.6421884821825827, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0014920919128087013, 'num_filters_1': 36, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.019367989701785503, 'kernel_size_2': 3, 'num_filters_2': 56}"}}
exception: None

12:00:30 job_callback for (0, 0, 8) started
12:00:30 DISPATCHER: Trying to submit another job.
12:00:30 job_callback for (0, 0, 8) got condition
12:00:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:00:30 Only 9 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
12:00:30 HBMASTER: Trying to run another job!
12:00:30 job_callback for (0, 0, 8) finished
12:00:30 start sampling a new configuration.
12:00:30 done sampling a new configuration.
12:00:30 HBMASTER: schedule new run for iteration 0
12:00:30 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
12:00:30 HBMASTER: submitting job (0, 0, 9) to dispatcher
12:00:30 DISPATCHER: trying to submit job (0, 0, 9)
12:00:30 DISPATCHER: trying to notify the job_runner thread.
12:00:30 HBMASTER: job (0, 0, 9) submitted to dispatcher
12:00:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:00:30 DISPATCHER: Trying to submit another job.
12:00:30 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:00:30 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:00:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:00:30 WORKER: start processing job (0, 0, 9)
12:00:30 WORKER: args: ()
12:00:30 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0012205960244117706, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.08758167140756729, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 117, 'num_filters_3': 29, 'num_filters_4': 62}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:00:46 DISPATCHER: Starting worker discovery
12:00:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:00:46 DISPATCHER: Finished worker discovery
12:01:29 WORKER: done with job (0, 0, 9), trying to register it.
12:01:29 WORKER: registered result for job (0, 0, 9) with dispatcher
12:01:29 DISPATCHER: job (0, 0, 9) finished
12:01:29 DISPATCHER: register_result: lock acquired
12:01:29 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:01:29 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0012205960244117706, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.08758167140756729, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 117, 'num_filters_3': 29, 'num_filters_4': 62}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2028415576280698, 'info': {'data05': 0.2028415576280698, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0012205960244117706, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.08758167140756729, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 117, 'num_filters_3': 29, 'num_filters_4': 62}"}}
exception: None

12:01:29 job_callback for (0, 0, 9) started
12:01:29 DISPATCHER: Trying to submit another job.
12:01:29 job_callback for (0, 0, 9) got condition
12:01:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:01:29 Only 10 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
12:01:29 HBMASTER: Trying to run another job!
12:01:29 job_callback for (0, 0, 9) finished
12:01:29 start sampling a new configuration.
12:01:29 done sampling a new configuration.
12:01:29 HBMASTER: schedule new run for iteration 0
12:01:29 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
12:01:29 HBMASTER: submitting job (0, 0, 10) to dispatcher
12:01:29 DISPATCHER: trying to submit job (0, 0, 10)
12:01:29 DISPATCHER: trying to notify the job_runner thread.
12:01:29 HBMASTER: job (0, 0, 10) submitted to dispatcher
12:01:29 DISPATCHER: Trying to submit another job.
12:01:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:01:29 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:01:29 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:01:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:01:29 WORKER: start processing job (0, 0, 10)
12:01:29 WORKER: args: ()
12:01:29 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0019307686288535175, 'num_filters_1': 42, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.0974827709587014, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 61, 'num_filters_3': 40, 'num_filters_4': 81, 'num_filters_5': 110}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:01:46 DISPATCHER: Starting worker discovery
12:01:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:01:46 DISPATCHER: Finished worker discovery
12:02:27 WORKER: done with job (0, 0, 10), trying to register it.
12:02:27 WORKER: registered result for job (0, 0, 10) with dispatcher
12:02:27 DISPATCHER: job (0, 0, 10) finished
12:02:27 DISPATCHER: register_result: lock acquired
12:02:27 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:02:27 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0019307686288535175, 'num_filters_1': 42, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.0974827709587014, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 61, 'num_filters_3': 40, 'num_filters_4': 81, 'num_filters_5': 110}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0019307686288535175, 'num_filters_1': 42, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.0974827709587014, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 61, 'num_filters_3': 40, 'num_filters_4': 81, 'num_filters_5': 110}"}}
exception: None

12:02:27 job_callback for (0, 0, 10) started
12:02:27 job_callback for (0, 0, 10) got condition
12:02:27 DISPATCHER: Trying to submit another job.
12:02:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:02:27 Only 11 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
12:02:27 HBMASTER: Trying to run another job!
12:02:27 job_callback for (0, 0, 10) finished
12:02:27 start sampling a new configuration.
12:02:27 done sampling a new configuration.
12:02:27 HBMASTER: schedule new run for iteration 0
12:02:27 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
12:02:27 HBMASTER: submitting job (0, 0, 11) to dispatcher
12:02:27 DISPATCHER: trying to submit job (0, 0, 11)
12:02:27 DISPATCHER: trying to notify the job_runner thread.
12:02:27 HBMASTER: job (0, 0, 11) submitted to dispatcher
12:02:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:02:27 DISPATCHER: Trying to submit another job.
12:02:27 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:02:27 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:02:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:02:27 WORKER: start processing job (0, 0, 11)
12:02:27 WORKER: args: ()
12:02:27 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.057897431230597644, 'num_filters_1': 48, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.11393480435388782}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:02:46 DISPATCHER: Starting worker discovery
12:02:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:02:46 DISPATCHER: Finished worker discovery
12:03:29 WORKER: done with job (0, 0, 11), trying to register it.
12:03:29 WORKER: registered result for job (0, 0, 11) with dispatcher
12:03:29 DISPATCHER: job (0, 0, 11) finished
12:03:29 DISPATCHER: register_result: lock acquired
12:03:29 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:03:29 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.057897431230597644, 'num_filters_1': 48, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.11393480435388782}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.12577735121828906, 'info': {'data05': 0.12577735121828906, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.057897431230597644, 'num_filters_1': 48, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.11393480435388782}"}}
exception: None

12:03:29 job_callback for (0, 0, 11) started
12:03:29 job_callback for (0, 0, 11) got condition
12:03:29 DISPATCHER: Trying to submit another job.
12:03:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:03:29 Only 12 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
12:03:29 HBMASTER: Trying to run another job!
12:03:29 job_callback for (0, 0, 11) finished
12:03:29 start sampling a new configuration.
12:03:29 done sampling a new configuration.
12:03:29 HBMASTER: schedule new run for iteration 0
12:03:29 HBMASTER: trying submitting job (0, 0, 12) to dispatcher
12:03:29 HBMASTER: submitting job (0, 0, 12) to dispatcher
12:03:29 DISPATCHER: trying to submit job (0, 0, 12)
12:03:29 DISPATCHER: trying to notify the job_runner thread.
12:03:29 HBMASTER: job (0, 0, 12) submitted to dispatcher
12:03:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:03:29 DISPATCHER: Trying to submit another job.
12:03:29 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:03:29 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:03:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:03:29 WORKER: start processing job (0, 0, 12)
12:03:29 WORKER: args: ()
12:03:29 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0017336825347736894, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.02514758648261762, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 125, 'num_filters_3': 79}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:03:46 DISPATCHER: Starting worker discovery
12:03:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:03:46 DISPATCHER: Finished worker discovery
12:04:26 WORKER: done with job (0, 0, 12), trying to register it.
12:04:26 WORKER: registered result for job (0, 0, 12) with dispatcher
12:04:26 DISPATCHER: job (0, 0, 12) finished
12:04:26 DISPATCHER: register_result: lock acquired
12:04:26 DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:04:26 job_id: (0, 0, 12)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0017336825347736894, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.02514758648261762, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 125, 'num_filters_3': 79}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6604343461192297, 'info': {'data05': 0.6604343461192297, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0017336825347736894, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.02514758648261762, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 125, 'num_filters_3': 79}"}}
exception: None

12:04:26 job_callback for (0, 0, 12) started
12:04:26 DISPATCHER: Trying to submit another job.
12:04:26 job_callback for (0, 0, 12) got condition
12:04:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:04:26 Only 13 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
12:04:26 HBMASTER: Trying to run another job!
12:04:26 job_callback for (0, 0, 12) finished
12:04:26 start sampling a new configuration.
12:04:26 done sampling a new configuration.
12:04:26 HBMASTER: schedule new run for iteration 0
12:04:26 HBMASTER: trying submitting job (0, 0, 13) to dispatcher
12:04:26 HBMASTER: submitting job (0, 0, 13) to dispatcher
12:04:26 DISPATCHER: trying to submit job (0, 0, 13)
12:04:26 DISPATCHER: trying to notify the job_runner thread.
12:04:26 HBMASTER: job (0, 0, 13) submitted to dispatcher
12:04:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:04:26 DISPATCHER: Trying to submit another job.
12:04:26 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:04:26 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:04:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:04:26 WORKER: start processing job (0, 0, 13)
12:04:26 WORKER: args: ()
12:04:26 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0750363052642874, 'num_filters_1': 29, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.023146079991848662, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 18, 'num_filters_3': 57}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:04:46 DISPATCHER: Starting worker discovery
12:04:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:04:46 DISPATCHER: Finished worker discovery
12:05:23 WORKER: done with job (0, 0, 13), trying to register it.
12:05:23 WORKER: registered result for job (0, 0, 13) with dispatcher
12:05:23 DISPATCHER: job (0, 0, 13) finished
12:05:23 DISPATCHER: register_result: lock acquired
12:05:23 DISPATCHER: job (0, 0, 13) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:05:23 job_id: (0, 0, 13)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0750363052642874, 'num_filters_1': 29, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.023146079991848662, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 18, 'num_filters_3': 57}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0039546062103121464, 'info': {'data05': 0.0039546062103121464, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0750363052642874, 'num_filters_1': 29, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.023146079991848662, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 18, 'num_filters_3': 57}"}}
exception: None

12:05:23 job_callback for (0, 0, 13) started
12:05:23 job_callback for (0, 0, 13) got condition
12:05:23 DISPATCHER: Trying to submit another job.
12:05:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:05:23 Only 14 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
12:05:23 HBMASTER: Trying to run another job!
12:05:23 job_callback for (0, 0, 13) finished
12:05:23 start sampling a new configuration.
12:05:23 done sampling a new configuration.
12:05:23 HBMASTER: schedule new run for iteration 0
12:05:23 HBMASTER: trying submitting job (0, 0, 14) to dispatcher
12:05:23 HBMASTER: submitting job (0, 0, 14) to dispatcher
12:05:23 DISPATCHER: trying to submit job (0, 0, 14)
12:05:23 DISPATCHER: trying to notify the job_runner thread.
12:05:23 HBMASTER: job (0, 0, 14) submitted to dispatcher
12:05:23 DISPATCHER: Trying to submit another job.
12:05:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:05:23 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:05:23 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:05:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:05:23 WORKER: start processing job (0, 0, 14)
12:05:23 WORKER: args: ()
12:05:23 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.03495043327204684, 'num_filters_1': 118, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.012557114789038967, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 59, 'num_filters_3': 122, 'num_filters_4': 84, 'num_filters_5': 29}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:05:46 DISPATCHER: Starting worker discovery
12:05:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:05:46 DISPATCHER: Finished worker discovery
12:06:20 WORKER: done with job (0, 0, 14), trying to register it.
12:06:20 WORKER: registered result for job (0, 0, 14) with dispatcher
12:06:20 DISPATCHER: job (0, 0, 14) finished
12:06:20 DISPATCHER: register_result: lock acquired
12:06:20 DISPATCHER: job (0, 0, 14) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:06:20 job_id: (0, 0, 14)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.03495043327204684, 'num_filters_1': 118, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.012557114789038967, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 59, 'num_filters_3': 122, 'num_filters_4': 84, 'num_filters_5': 29}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.03495043327204684, 'num_filters_1': 118, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.012557114789038967, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 59, 'num_filters_3': 122, 'num_filters_4': 84, 'num_filters_5': 29}"}}
exception: None

12:06:20 job_callback for (0, 0, 14) started
12:06:20 job_callback for (0, 0, 14) got condition
12:06:20 DISPATCHER: Trying to submit another job.
12:06:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:06:20 Only 15 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
12:06:20 HBMASTER: Trying to run another job!
12:06:20 job_callback for (0, 0, 14) finished
12:06:20 start sampling a new configuration.
12:06:20 done sampling a new configuration.
12:06:20 HBMASTER: schedule new run for iteration 0
12:06:20 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
12:06:20 HBMASTER: submitting job (0, 0, 15) to dispatcher
12:06:20 DISPATCHER: trying to submit job (0, 0, 15)
12:06:20 DISPATCHER: trying to notify the job_runner thread.
12:06:20 HBMASTER: job (0, 0, 15) submitted to dispatcher
12:06:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:06:20 DISPATCHER: Trying to submit another job.
12:06:20 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:06:20 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:06:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:06:20 WORKER: start processing job (0, 0, 15)
12:06:20 WORKER: args: ()
12:06:20 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.026375991152633803, 'num_filters_1': 21, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.07079251490007674, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 126, 'num_filters_3': 69}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:06:46 DISPATCHER: Starting worker discovery
12:06:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:06:46 DISPATCHER: Finished worker discovery
12:07:18 WORKER: done with job (0, 0, 15), trying to register it.
12:07:18 WORKER: registered result for job (0, 0, 15) with dispatcher
12:07:18 DISPATCHER: job (0, 0, 15) finished
12:07:18 DISPATCHER: register_result: lock acquired
12:07:18 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:07:18 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.026375991152633803, 'num_filters_1': 21, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.07079251490007674, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 126, 'num_filters_3': 69}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.27173282287812944, 'info': {'data05': 0.27173282287812944, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.026375991152633803, 'num_filters_1': 21, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.07079251490007674, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 126, 'num_filters_3': 69}"}}
exception: None

12:07:18 job_callback for (0, 0, 15) started
12:07:18 DISPATCHER: Trying to submit another job.
12:07:18 job_callback for (0, 0, 15) got condition
12:07:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:07:18 Only 16 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
12:07:18 HBMASTER: Trying to run another job!
12:07:18 job_callback for (0, 0, 15) finished
12:07:18 start sampling a new configuration.
12:07:18 done sampling a new configuration.
12:07:18 HBMASTER: schedule new run for iteration 0
12:07:18 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
12:07:18 HBMASTER: submitting job (0, 0, 16) to dispatcher
12:07:18 DISPATCHER: trying to submit job (0, 0, 16)
12:07:18 DISPATCHER: trying to notify the job_runner thread.
12:07:18 HBMASTER: job (0, 0, 16) submitted to dispatcher
12:07:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:07:18 DISPATCHER: Trying to submit another job.
12:07:18 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:07:18 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:07:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:07:18 WORKER: start processing job (0, 0, 16)
12:07:18 WORKER: args: ()
12:07:18 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.009549791000660857, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.015919716650127425, 'kernel_size_2': 3, 'num_filters_2': 76}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:07:46 DISPATCHER: Starting worker discovery
12:07:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:07:46 DISPATCHER: Finished worker discovery
12:08:19 WORKER: done with job (0, 0, 16), trying to register it.
12:08:19 WORKER: registered result for job (0, 0, 16) with dispatcher
12:08:19 DISPATCHER: job (0, 0, 16) finished
12:08:19 DISPATCHER: register_result: lock acquired
12:08:19 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:08:19 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.009549791000660857, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.015919716650127425, 'kernel_size_2': 3, 'num_filters_2': 76}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.49254239158491964, 'info': {'data05': 0.49254239158491964, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.009549791000660857, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.015919716650127425, 'kernel_size_2': 3, 'num_filters_2': 76}"}}
exception: None

12:08:19 job_callback for (0, 0, 16) started
12:08:19 job_callback for (0, 0, 16) got condition
12:08:19 DISPATCHER: Trying to submit another job.
12:08:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:08:19 HBMASTER: Trying to run another job!
12:08:19 job_callback for (0, 0, 16) finished
12:08:19 start sampling a new configuration.
12:08:19 done sampling a new configuration.
12:08:19 HBMASTER: schedule new run for iteration 0
12:08:19 HBMASTER: trying submitting job (0, 0, 17) to dispatcher
12:08:19 HBMASTER: submitting job (0, 0, 17) to dispatcher
12:08:19 DISPATCHER: trying to submit job (0, 0, 17)
12:08:19 DISPATCHER: trying to notify the job_runner thread.
12:08:19 HBMASTER: job (0, 0, 17) submitted to dispatcher
12:08:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:08:19 DISPATCHER: Trying to submit another job.
12:08:19 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:08:19 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:08:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:08:19 WORKER: start processing job (0, 0, 17)
12:08:19 WORKER: args: ()
12:08:19 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.02049224181131292, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.11470892105739777, 'kernel_size_2': 3, 'num_filters_2': 53}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:08:46 DISPATCHER: Starting worker discovery
12:08:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:08:46 DISPATCHER: Finished worker discovery
12:09:15 WORKER: done with job (0, 0, 17), trying to register it.
12:09:15 WORKER: registered result for job (0, 0, 17) with dispatcher
12:09:15 DISPATCHER: job (0, 0, 17) finished
12:09:15 DISPATCHER: register_result: lock acquired
12:09:15 DISPATCHER: job (0, 0, 17) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:09:15 job_id: (0, 0, 17)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.02049224181131292, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.11470892105739777, 'kernel_size_2': 3, 'num_filters_2': 53}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.18466817967950905, 'info': {'data05': 0.18466817967950905, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.02049224181131292, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.11470892105739777, 'kernel_size_2': 3, 'num_filters_2': 53}"}}
exception: None

12:09:15 job_callback for (0, 0, 17) started
12:09:15 DISPATCHER: Trying to submit another job.
12:09:15 job_callback for (0, 0, 17) got condition
12:09:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:09:15 HBMASTER: Trying to run another job!
12:09:15 job_callback for (0, 0, 17) finished
12:09:15 start sampling a new configuration.
12:09:15 done sampling a new configuration.
12:09:15 HBMASTER: schedule new run for iteration 0
12:09:15 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
12:09:15 HBMASTER: submitting job (0, 0, 18) to dispatcher
12:09:15 DISPATCHER: trying to submit job (0, 0, 18)
12:09:15 DISPATCHER: trying to notify the job_runner thread.
12:09:15 HBMASTER: job (0, 0, 18) submitted to dispatcher
12:09:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:09:15 DISPATCHER: Trying to submit another job.
12:09:15 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:09:15 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:09:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:09:15 WORKER: start processing job (0, 0, 18)
12:09:15 WORKER: args: ()
12:09:15 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.045902202635169385, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.05516978253149992, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 80, 'num_filters_3': 16, 'num_filters_4': 65}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:09:46 DISPATCHER: Starting worker discovery
12:09:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:09:46 DISPATCHER: Finished worker discovery
12:10:13 WORKER: done with job (0, 0, 18), trying to register it.
12:10:13 WORKER: registered result for job (0, 0, 18) with dispatcher
12:10:13 DISPATCHER: job (0, 0, 18) finished
12:10:13 DISPATCHER: register_result: lock acquired
12:10:13 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:10:13 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.045902202635169385, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.05516978253149992, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 80, 'num_filters_3': 16, 'num_filters_4': 65}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.045902202635169385, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.05516978253149992, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 80, 'num_filters_3': 16, 'num_filters_4': 65}"}}
exception: None

12:10:13 job_callback for (0, 0, 18) started
12:10:13 DISPATCHER: Trying to submit another job.
12:10:13 job_callback for (0, 0, 18) got condition
12:10:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:10:13 HBMASTER: Trying to run another job!
12:10:13 job_callback for (0, 0, 18) finished
12:10:13 start sampling a new configuration.
12:10:13 done sampling a new configuration.
12:10:13 HBMASTER: schedule new run for iteration 0
12:10:13 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
12:10:13 HBMASTER: submitting job (0, 0, 19) to dispatcher
12:10:13 DISPATCHER: trying to submit job (0, 0, 19)
12:10:13 DISPATCHER: trying to notify the job_runner thread.
12:10:13 HBMASTER: job (0, 0, 19) submitted to dispatcher
12:10:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:10:13 DISPATCHER: Trying to submit another job.
12:10:13 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:10:13 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:10:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:10:13 WORKER: start processing job (0, 0, 19)
12:10:13 WORKER: args: ()
12:10:13 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.003429012671209636, 'num_filters_1': 30, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.03319538563948402, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 42, 'num_filters_3': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:10:46 DISPATCHER: Starting worker discovery
12:10:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:10:47 DISPATCHER: Finished worker discovery
12:11:11 WORKER: done with job (0, 0, 19), trying to register it.
12:11:11 WORKER: registered result for job (0, 0, 19) with dispatcher
12:11:11 DISPATCHER: job (0, 0, 19) finished
12:11:11 DISPATCHER: register_result: lock acquired
12:11:11 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:11:11 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.003429012671209636, 'num_filters_1': 30, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.03319538563948402, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 42, 'num_filters_3': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5846058100356232, 'info': {'data05': 0.5846058100356232, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.003429012671209636, 'num_filters_1': 30, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.03319538563948402, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 42, 'num_filters_3': 16}"}}
exception: None

12:11:11 job_callback for (0, 0, 19) started
12:11:11 job_callback for (0, 0, 19) got condition
12:11:11 DISPATCHER: Trying to submit another job.
12:11:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:11:11 HBMASTER: Trying to run another job!
12:11:11 job_callback for (0, 0, 19) finished
12:11:11 start sampling a new configuration.
12:11:11 done sampling a new configuration.
12:11:11 HBMASTER: schedule new run for iteration 0
12:11:11 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
12:11:11 HBMASTER: submitting job (0, 0, 20) to dispatcher
12:11:11 DISPATCHER: trying to submit job (0, 0, 20)
12:11:11 DISPATCHER: trying to notify the job_runner thread.
12:11:11 HBMASTER: job (0, 0, 20) submitted to dispatcher
12:11:11 DISPATCHER: Trying to submit another job.
12:11:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:11:11 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:11:11 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:11:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:11:11 WORKER: start processing job (0, 0, 20)
12:11:11 WORKER: args: ()
12:11:11 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.008516762738501741, 'num_filters_1': 29, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.018911498775788873, 'kernel_size_2': 5, 'num_filters_2': 47}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:11:47 DISPATCHER: Starting worker discovery
12:11:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:11:47 DISPATCHER: Finished worker discovery
12:12:08 WORKER: done with job (0, 0, 20), trying to register it.
12:12:08 WORKER: registered result for job (0, 0, 20) with dispatcher
12:12:08 DISPATCHER: job (0, 0, 20) finished
12:12:08 DISPATCHER: register_result: lock acquired
12:12:08 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:12:08 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.008516762738501741, 'num_filters_1': 29, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.018911498775788873, 'kernel_size_2': 5, 'num_filters_2': 47}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5143558200471842, 'info': {'data05': 0.5143558200471842, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.008516762738501741, 'num_filters_1': 29, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.018911498775788873, 'kernel_size_2': 5, 'num_filters_2': 47}"}}
exception: None

12:12:08 job_callback for (0, 0, 20) started
12:12:08 DISPATCHER: Trying to submit another job.
12:12:08 job_callback for (0, 0, 20) got condition
12:12:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:12:08 HBMASTER: Trying to run another job!
12:12:08 job_callback for (0, 0, 20) finished
12:12:08 start sampling a new configuration.
12:12:08 done sampling a new configuration.
12:12:08 HBMASTER: schedule new run for iteration 0
12:12:08 HBMASTER: trying submitting job (0, 0, 21) to dispatcher
12:12:08 HBMASTER: submitting job (0, 0, 21) to dispatcher
12:12:08 DISPATCHER: trying to submit job (0, 0, 21)
12:12:08 DISPATCHER: trying to notify the job_runner thread.
12:12:08 HBMASTER: job (0, 0, 21) submitted to dispatcher
12:12:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:12:08 DISPATCHER: Trying to submit another job.
12:12:08 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:12:08 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:12:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:12:08 WORKER: start processing job (0, 0, 21)
12:12:08 WORKER: args: ()
12:12:08 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.03706939946607779, 'num_filters_1': 39, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.017045100411276885, 'kernel_size_2': 7, 'num_filters_2': 96}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:12:47 DISPATCHER: Starting worker discovery
12:12:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:12:47 DISPATCHER: Finished worker discovery
12:13:09 WORKER: done with job (0, 0, 21), trying to register it.
12:13:09 WORKER: registered result for job (0, 0, 21) with dispatcher
12:13:09 DISPATCHER: job (0, 0, 21) finished
12:13:09 DISPATCHER: register_result: lock acquired
12:13:09 DISPATCHER: job (0, 0, 21) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:13:09 job_id: (0, 0, 21)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.03706939946607779, 'num_filters_1': 39, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.017045100411276885, 'kernel_size_2': 7, 'num_filters_2': 96}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.03706939946607779, 'num_filters_1': 39, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.017045100411276885, 'kernel_size_2': 7, 'num_filters_2': 96}"}}
exception: None

12:13:09 job_callback for (0, 0, 21) started
12:13:09 DISPATCHER: Trying to submit another job.
12:13:09 job_callback for (0, 0, 21) got condition
12:13:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:13:09 HBMASTER: Trying to run another job!
12:13:09 job_callback for (0, 0, 21) finished
12:13:09 start sampling a new configuration.
12:13:09 done sampling a new configuration.
12:13:09 HBMASTER: schedule new run for iteration 0
12:13:09 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
12:13:09 HBMASTER: submitting job (0, 0, 22) to dispatcher
12:13:09 DISPATCHER: trying to submit job (0, 0, 22)
12:13:09 DISPATCHER: trying to notify the job_runner thread.
12:13:09 HBMASTER: job (0, 0, 22) submitted to dispatcher
12:13:09 DISPATCHER: Trying to submit another job.
12:13:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:13:09 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:13:09 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:13:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:13:09 WORKER: start processing job (0, 0, 22)
12:13:09 WORKER: args: ()
12:13:09 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.00985438952162892, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.17461380012534336}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:13:47 DISPATCHER: Starting worker discovery
12:13:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:13:47 DISPATCHER: Finished worker discovery
12:14:07 WORKER: done with job (0, 0, 22), trying to register it.
12:14:07 WORKER: registered result for job (0, 0, 22) with dispatcher
12:14:07 DISPATCHER: job (0, 0, 22) finished
12:14:07 DISPATCHER: register_result: lock acquired
12:14:07 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:14:07 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.00985438952162892, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.17461380012534336}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0009274649547651781, 'info': {'data05': 0.0009274649547651781, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.00985438952162892, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.17461380012534336}"}}
exception: None

12:14:07 job_callback for (0, 0, 22) started
12:14:07 DISPATCHER: Trying to submit another job.
12:14:07 job_callback for (0, 0, 22) got condition
12:14:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:14:07 HBMASTER: Trying to run another job!
12:14:07 job_callback for (0, 0, 22) finished
12:14:07 start sampling a new configuration.
12:14:07 done sampling a new configuration.
12:14:07 HBMASTER: schedule new run for iteration 0
12:14:07 HBMASTER: trying submitting job (0, 0, 23) to dispatcher
12:14:07 HBMASTER: submitting job (0, 0, 23) to dispatcher
12:14:07 DISPATCHER: trying to submit job (0, 0, 23)
12:14:07 DISPATCHER: trying to notify the job_runner thread.
12:14:07 HBMASTER: job (0, 0, 23) submitted to dispatcher
12:14:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:14:07 DISPATCHER: Trying to submit another job.
12:14:07 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:14:07 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:14:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:14:07 WORKER: start processing job (0, 0, 23)
12:14:07 WORKER: args: ()
12:14:07 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.06914178633935918, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.017115679611907738, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 20, 'num_filters_3': 39, 'num_filters_4': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:14:47 DISPATCHER: Starting worker discovery
12:14:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:14:47 DISPATCHER: Finished worker discovery
12:15:05 WORKER: done with job (0, 0, 23), trying to register it.
12:15:05 WORKER: registered result for job (0, 0, 23) with dispatcher
12:15:05 DISPATCHER: job (0, 0, 23) finished
12:15:05 DISPATCHER: register_result: lock acquired
12:15:05 DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:15:05 job_id: (0, 0, 23)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.06914178633935918, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.017115679611907738, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 20, 'num_filters_3': 39, 'num_filters_4': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.06914178633935918, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.017115679611907738, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 20, 'num_filters_3': 39, 'num_filters_4': 19}"}}
exception: None

12:15:05 job_callback for (0, 0, 23) started
12:15:05 DISPATCHER: Trying to submit another job.
12:15:05 job_callback for (0, 0, 23) got condition
12:15:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:15:05 HBMASTER: Trying to run another job!
12:15:05 job_callback for (0, 0, 23) finished
12:15:05 start sampling a new configuration.
12:15:05 done sampling a new configuration.
12:15:05 HBMASTER: schedule new run for iteration 0
12:15:05 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
12:15:05 HBMASTER: submitting job (0, 0, 24) to dispatcher
12:15:05 DISPATCHER: trying to submit job (0, 0, 24)
12:15:05 DISPATCHER: trying to notify the job_runner thread.
12:15:05 HBMASTER: job (0, 0, 24) submitted to dispatcher
12:15:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:15:05 DISPATCHER: Trying to submit another job.
12:15:05 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:15:05 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:15:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:15:05 WORKER: start processing job (0, 0, 24)
12:15:05 WORKER: args: ()
12:15:05 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.02135858642792975, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.05298191862272997, 'kernel_size_2': 5, 'num_filters_2': 50}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:15:47 DISPATCHER: Starting worker discovery
12:15:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:15:47 DISPATCHER: Finished worker discovery
12:16:05 WORKER: done with job (0, 0, 24), trying to register it.
12:16:05 WORKER: registered result for job (0, 0, 24) with dispatcher
12:16:05 DISPATCHER: job (0, 0, 24) finished
12:16:05 DISPATCHER: register_result: lock acquired
12:16:05 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:16:05 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.02135858642792975, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.05298191862272997, 'kernel_size_2': 5, 'num_filters_2': 50}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.09801166752028487, 'info': {'data05': 0.09801166752028487, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.02135858642792975, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.05298191862272997, 'kernel_size_2': 5, 'num_filters_2': 50}"}}
exception: None

12:16:05 job_callback for (0, 0, 24) started
12:16:05 job_callback for (0, 0, 24) got condition
12:16:05 DISPATCHER: Trying to submit another job.
12:16:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:16:05 HBMASTER: Trying to run another job!
12:16:05 job_callback for (0, 0, 24) finished
12:16:05 start sampling a new configuration.
12:16:05 done sampling a new configuration.
12:16:05 HBMASTER: schedule new run for iteration 0
12:16:05 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
12:16:05 HBMASTER: submitting job (0, 0, 25) to dispatcher
12:16:05 DISPATCHER: trying to submit job (0, 0, 25)
12:16:05 DISPATCHER: trying to notify the job_runner thread.
12:16:05 HBMASTER: job (0, 0, 25) submitted to dispatcher
12:16:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:16:05 DISPATCHER: Trying to submit another job.
12:16:05 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:16:05 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:16:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:16:05 WORKER: start processing job (0, 0, 25)
12:16:05 WORKER: args: ()
12:16:05 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.007879927263284535, 'num_filters_1': 115, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.178373324215165, 'kernel_size_2': 5, 'num_filters_2': 106}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:16:47 DISPATCHER: Starting worker discovery
12:16:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:16:47 DISPATCHER: Finished worker discovery
12:17:05 WORKER: done with job (0, 0, 25), trying to register it.
12:17:05 WORKER: registered result for job (0, 0, 25) with dispatcher
12:17:05 DISPATCHER: job (0, 0, 25) finished
12:17:05 DISPATCHER: register_result: lock acquired
12:17:05 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:17:05 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.007879927263284535, 'num_filters_1': 115, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.178373324215165, 'kernel_size_2': 5, 'num_filters_2': 106}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.04381824221760065, 'info': {'data05': 0.04381824221760065, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.007879927263284535, 'num_filters_1': 115, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.178373324215165, 'kernel_size_2': 5, 'num_filters_2': 106}"}}
exception: None

12:17:05 job_callback for (0, 0, 25) started
12:17:05 DISPATCHER: Trying to submit another job.
12:17:05 job_callback for (0, 0, 25) got condition
12:17:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:17:05 HBMASTER: Trying to run another job!
12:17:05 job_callback for (0, 0, 25) finished
12:17:05 start sampling a new configuration.
12:17:05 done sampling a new configuration.
12:17:05 HBMASTER: schedule new run for iteration 0
12:17:05 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
12:17:05 HBMASTER: submitting job (0, 0, 26) to dispatcher
12:17:05 DISPATCHER: trying to submit job (0, 0, 26)
12:17:05 DISPATCHER: trying to notify the job_runner thread.
12:17:05 HBMASTER: job (0, 0, 26) submitted to dispatcher
12:17:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:17:05 DISPATCHER: Trying to submit another job.
12:17:05 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:17:05 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:17:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:17:05 WORKER: start processing job (0, 0, 26)
12:17:05 WORKER: args: ()
12:17:05 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0017865382355292457, 'num_filters_1': 33, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.02479780657386614, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 54, 'num_filters_3': 100, 'num_filters_4': 21, 'num_filters_5': 82}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:17:47 DISPATCHER: Starting worker discovery
12:17:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:17:47 DISPATCHER: Finished worker discovery
12:18:01 WORKER: done with job (0, 0, 26), trying to register it.
12:18:01 WORKER: registered result for job (0, 0, 26) with dispatcher
12:18:01 DISPATCHER: job (0, 0, 26) finished
12:18:01 DISPATCHER: register_result: lock acquired
12:18:01 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:18:01 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0017865382355292457, 'num_filters_1': 33, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.02479780657386614, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 54, 'num_filters_3': 100, 'num_filters_4': 21, 'num_filters_5': 82}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8144442525313054, 'info': {'data05': 0.8144442525313054, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0017865382355292457, 'num_filters_1': 33, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.02479780657386614, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 54, 'num_filters_3': 100, 'num_filters_4': 21, 'num_filters_5': 82}"}}
exception: None

12:18:01 job_callback for (0, 0, 26) started
12:18:01 DISPATCHER: Trying to submit another job.
12:18:01 job_callback for (0, 0, 26) got condition
12:18:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:18:01 HBMASTER: Trying to run another job!
12:18:01 job_callback for (0, 0, 26) finished
12:18:01 ITERATION: Advancing config (0, 0, 0) to next budget 133.333333
12:18:01 ITERATION: Advancing config (0, 0, 1) to next budget 133.333333
12:18:01 ITERATION: Advancing config (0, 0, 7) to next budget 133.333333
12:18:01 ITERATION: Advancing config (0, 0, 8) to next budget 133.333333
12:18:01 ITERATION: Advancing config (0, 0, 12) to next budget 133.333333
12:18:01 ITERATION: Advancing config (0, 0, 16) to next budget 133.333333
12:18:01 ITERATION: Advancing config (0, 0, 19) to next budget 133.333333
12:18:01 ITERATION: Advancing config (0, 0, 20) to next budget 133.333333
12:18:01 ITERATION: Advancing config (0, 0, 26) to next budget 133.333333
12:18:01 HBMASTER: schedule new run for iteration 0
12:18:01 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
12:18:01 HBMASTER: submitting job (0, 0, 0) to dispatcher
12:18:01 DISPATCHER: trying to submit job (0, 0, 0)
12:18:01 DISPATCHER: trying to notify the job_runner thread.
12:18:01 HBMASTER: job (0, 0, 0) submitted to dispatcher
12:18:01 DISPATCHER: Trying to submit another job.
12:18:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:18:01 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:18:01 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:18:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:18:01 WORKER: start processing job (0, 0, 0)
12:18:01 WORKER: args: ()
12:18:01 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.06480645950082745, 'num_filters_1': 51, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.01962837371432568, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 123, 'num_filters_3': 17, 'num_filters_4': 62}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:18:47 DISPATCHER: Starting worker discovery
12:18:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:18:47 DISPATCHER: Finished worker discovery
12:19:47 DISPATCHER: Starting worker discovery
12:19:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:19:47 DISPATCHER: Finished worker discovery
12:20:39 WORKER: done with job (0, 0, 0), trying to register it.
12:20:39 WORKER: registered result for job (0, 0, 0) with dispatcher
12:20:39 DISPATCHER: job (0, 0, 0) finished
12:20:39 DISPATCHER: register_result: lock acquired
12:20:39 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:20:39 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.06480645950082745, 'num_filters_1': 51, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.01962837371432568, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 123, 'num_filters_3': 17, 'num_filters_4': 62}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.11387770844809185, 'info': {'data05': 0.11387770844809185, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.06480645950082745, 'num_filters_1': 51, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.01962837371432568, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 123, 'num_filters_3': 17, 'num_filters_4': 62}"}}
exception: None

12:20:39 job_callback for (0, 0, 0) started
12:20:39 DISPATCHER: Trying to submit another job.
12:20:39 job_callback for (0, 0, 0) got condition
12:20:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:20:39 Only 1 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:20:39 HBMASTER: Trying to run another job!
12:20:39 job_callback for (0, 0, 0) finished
12:20:39 HBMASTER: schedule new run for iteration 0
12:20:39 HBMASTER: trying submitting job (0, 0, 1) to dispatcher
12:20:39 HBMASTER: submitting job (0, 0, 1) to dispatcher
12:20:39 DISPATCHER: trying to submit job (0, 0, 1)
12:20:39 DISPATCHER: trying to notify the job_runner thread.
12:20:39 HBMASTER: job (0, 0, 1) submitted to dispatcher
12:20:39 DISPATCHER: Trying to submit another job.
12:20:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:20:39 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:20:39 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:20:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:20:39 WORKER: start processing job (0, 0, 1)
12:20:39 WORKER: args: ()
12:20:39 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.012145696821790942, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.058375195583470915, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 81, 'num_filters_3': 66, 'num_filters_4': 30, 'num_filters_5': 50}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:20:47 DISPATCHER: Starting worker discovery
12:20:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:20:47 DISPATCHER: Finished worker discovery
12:21:47 DISPATCHER: Starting worker discovery
12:21:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:21:47 DISPATCHER: Finished worker discovery
12:22:47 DISPATCHER: Starting worker discovery
12:22:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:22:47 DISPATCHER: Finished worker discovery
12:23:10 WORKER: done with job (0, 0, 1), trying to register it.
12:23:10 WORKER: registered result for job (0, 0, 1) with dispatcher
12:23:10 DISPATCHER: job (0, 0, 1) finished
12:23:10 DISPATCHER: register_result: lock acquired
12:23:10 DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:23:10 job_id: (0, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.012145696821790942, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.058375195583470915, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 81, 'num_filters_3': 66, 'num_filters_4': 30, 'num_filters_5': 50}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5310045315970257, 'info': {'data05': 0.5310045315970257, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.012145696821790942, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.058375195583470915, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 81, 'num_filters_3': 66, 'num_filters_4': 30, 'num_filters_5': 50}"}}
exception: None

12:23:10 job_callback for (0, 0, 1) started
12:23:10 job_callback for (0, 0, 1) got condition
12:23:10 DISPATCHER: Trying to submit another job.
12:23:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:23:10 Only 2 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:23:10 HBMASTER: Trying to run another job!
12:23:10 job_callback for (0, 0, 1) finished
12:23:10 HBMASTER: schedule new run for iteration 0
12:23:10 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
12:23:10 HBMASTER: submitting job (0, 0, 7) to dispatcher
12:23:10 DISPATCHER: trying to submit job (0, 0, 7)
12:23:10 DISPATCHER: trying to notify the job_runner thread.
12:23:10 HBMASTER: job (0, 0, 7) submitted to dispatcher
12:23:10 DISPATCHER: Trying to submit another job.
12:23:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:23:10 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:23:10 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:23:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:23:10 WORKER: start processing job (0, 0, 7)
12:23:10 WORKER: args: ()
12:23:10 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.022871979901065376, 'num_filters_1': 79, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.04028959295819538, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 25, 'num_filters_3': 115, 'num_filters_4': 68, 'num_filters_5': 77}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:23:47 DISPATCHER: Starting worker discovery
12:23:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:23:47 DISPATCHER: Finished worker discovery
12:24:47 DISPATCHER: Starting worker discovery
12:24:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:24:47 DISPATCHER: Finished worker discovery
12:25:41 WORKER: done with job (0, 0, 7), trying to register it.
12:25:41 WORKER: registered result for job (0, 0, 7) with dispatcher
12:25:41 DISPATCHER: job (0, 0, 7) finished
12:25:41 DISPATCHER: register_result: lock acquired
12:25:41 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:25:41 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.022871979901065376, 'num_filters_1': 79, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.04028959295819538, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 25, 'num_filters_3': 115, 'num_filters_4': 68, 'num_filters_5': 77}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8250803853212593, 'info': {'data05': 0.8250803853212593, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.022871979901065376, 'num_filters_1': 79, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.04028959295819538, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 25, 'num_filters_3': 115, 'num_filters_4': 68, 'num_filters_5': 77}"}}
exception: None

12:25:41 job_callback for (0, 0, 7) started
12:25:41 job_callback for (0, 0, 7) got condition
12:25:41 DISPATCHER: Trying to submit another job.
12:25:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:25:41 Only 3 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:25:41 HBMASTER: Trying to run another job!
12:25:41 job_callback for (0, 0, 7) finished
12:25:41 HBMASTER: schedule new run for iteration 0
12:25:41 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
12:25:41 HBMASTER: submitting job (0, 0, 8) to dispatcher
12:25:41 DISPATCHER: trying to submit job (0, 0, 8)
12:25:41 DISPATCHER: trying to notify the job_runner thread.
12:25:41 HBMASTER: job (0, 0, 8) submitted to dispatcher
12:25:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:25:41 DISPATCHER: Trying to submit another job.
12:25:41 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:25:41 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:25:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:25:41 WORKER: start processing job (0, 0, 8)
12:25:41 WORKER: args: ()
12:25:41 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0014920919128087013, 'num_filters_1': 36, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.019367989701785503, 'kernel_size_2': 3, 'num_filters_2': 56}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:25:47 DISPATCHER: Starting worker discovery
12:25:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:25:47 DISPATCHER: Finished worker discovery
12:26:47 DISPATCHER: Starting worker discovery
12:26:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:26:47 DISPATCHER: Finished worker discovery
12:27:47 DISPATCHER: Starting worker discovery
12:27:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:27:47 DISPATCHER: Finished worker discovery
12:28:11 WORKER: done with job (0, 0, 8), trying to register it.
12:28:11 WORKER: registered result for job (0, 0, 8) with dispatcher
12:28:11 DISPATCHER: job (0, 0, 8) finished
12:28:11 DISPATCHER: register_result: lock acquired
12:28:11 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:28:11 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0014920919128087013, 'num_filters_1': 36, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.019367989701785503, 'kernel_size_2': 3, 'num_filters_2': 56}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5326676698281059, 'info': {'data05': 0.5326676698281059, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0014920919128087013, 'num_filters_1': 36, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.019367989701785503, 'kernel_size_2': 3, 'num_filters_2': 56}"}}
exception: None

12:28:11 job_callback for (0, 0, 8) started
12:28:11 job_callback for (0, 0, 8) got condition
12:28:11 DISPATCHER: Trying to submit another job.
12:28:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:28:11 Only 4 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:28:11 HBMASTER: Trying to run another job!
12:28:11 job_callback for (0, 0, 8) finished
12:28:11 HBMASTER: schedule new run for iteration 0
12:28:11 HBMASTER: trying submitting job (0, 0, 12) to dispatcher
12:28:11 HBMASTER: submitting job (0, 0, 12) to dispatcher
12:28:11 DISPATCHER: trying to submit job (0, 0, 12)
12:28:11 DISPATCHER: trying to notify the job_runner thread.
12:28:11 HBMASTER: job (0, 0, 12) submitted to dispatcher
12:28:11 DISPATCHER: Trying to submit another job.
12:28:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:28:11 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:28:11 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:28:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:28:11 WORKER: start processing job (0, 0, 12)
12:28:11 WORKER: args: ()
12:28:11 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0017336825347736894, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.02514758648261762, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 125, 'num_filters_3': 79}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:28:47 DISPATCHER: Starting worker discovery
12:28:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:28:47 DISPATCHER: Finished worker discovery
12:29:47 DISPATCHER: Starting worker discovery
12:29:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:29:47 DISPATCHER: Finished worker discovery
12:30:40 WORKER: done with job (0, 0, 12), trying to register it.
12:30:40 WORKER: registered result for job (0, 0, 12) with dispatcher
12:30:40 DISPATCHER: job (0, 0, 12) finished
12:30:40 DISPATCHER: register_result: lock acquired
12:30:40 DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:30:40 job_id: (0, 0, 12)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0017336825347736894, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.02514758648261762, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 125, 'num_filters_3': 79}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6533449054067662, 'info': {'data05': 0.6533449054067662, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0017336825347736894, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.02514758648261762, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 125, 'num_filters_3': 79}"}}
exception: None

12:30:40 job_callback for (0, 0, 12) started
12:30:40 job_callback for (0, 0, 12) got condition
12:30:40 DISPATCHER: Trying to submit another job.
12:30:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:30:40 Only 5 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:30:40 HBMASTER: Trying to run another job!
12:30:40 job_callback for (0, 0, 12) finished
12:30:40 HBMASTER: schedule new run for iteration 0
12:30:40 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
12:30:40 HBMASTER: submitting job (0, 0, 16) to dispatcher
12:30:40 DISPATCHER: trying to submit job (0, 0, 16)
12:30:40 DISPATCHER: trying to notify the job_runner thread.
12:30:40 HBMASTER: job (0, 0, 16) submitted to dispatcher
12:30:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:30:40 DISPATCHER: Trying to submit another job.
12:30:40 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:30:40 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:30:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:30:40 WORKER: start processing job (0, 0, 16)
12:30:40 WORKER: args: ()
12:30:40 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.009549791000660857, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.015919716650127425, 'kernel_size_2': 3, 'num_filters_2': 76}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:30:47 DISPATCHER: Starting worker discovery
12:30:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:30:47 DISPATCHER: Finished worker discovery
12:31:47 DISPATCHER: Starting worker discovery
12:31:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:31:47 DISPATCHER: Finished worker discovery
12:32:47 DISPATCHER: Starting worker discovery
12:32:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:32:47 DISPATCHER: Finished worker discovery
12:33:19 WORKER: done with job (0, 0, 16), trying to register it.
12:33:19 WORKER: registered result for job (0, 0, 16) with dispatcher
12:33:19 DISPATCHER: job (0, 0, 16) finished
12:33:19 DISPATCHER: register_result: lock acquired
12:33:19 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:33:19 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.009549791000660857, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.015919716650127425, 'kernel_size_2': 3, 'num_filters_2': 76}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4358521929774381, 'info': {'data05': 0.4358521929774381, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.009549791000660857, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.015919716650127425, 'kernel_size_2': 3, 'num_filters_2': 76}"}}
exception: None

12:33:19 job_callback for (0, 0, 16) started
12:33:19 DISPATCHER: Trying to submit another job.
12:33:19 job_callback for (0, 0, 16) got condition
12:33:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:33:19 Only 6 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:33:19 HBMASTER: Trying to run another job!
12:33:19 job_callback for (0, 0, 16) finished
12:33:19 HBMASTER: schedule new run for iteration 0
12:33:19 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
12:33:19 HBMASTER: submitting job (0, 0, 19) to dispatcher
12:33:19 DISPATCHER: trying to submit job (0, 0, 19)
12:33:19 DISPATCHER: trying to notify the job_runner thread.
12:33:19 HBMASTER: job (0, 0, 19) submitted to dispatcher
12:33:19 DISPATCHER: Trying to submit another job.
12:33:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:33:19 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:33:19 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:33:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:33:19 WORKER: start processing job (0, 0, 19)
12:33:19 WORKER: args: ()
12:33:19 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.003429012671209636, 'num_filters_1': 30, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.03319538563948402, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 42, 'num_filters_3': 16}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:33:47 DISPATCHER: Starting worker discovery
12:33:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:33:47 DISPATCHER: Finished worker discovery
12:34:47 DISPATCHER: Starting worker discovery
12:34:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:34:47 DISPATCHER: Finished worker discovery
12:35:47 DISPATCHER: Starting worker discovery
12:35:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:35:47 DISPATCHER: Finished worker discovery
12:35:50 WORKER: done with job (0, 0, 19), trying to register it.
12:35:50 WORKER: registered result for job (0, 0, 19) with dispatcher
12:35:50 DISPATCHER: job (0, 0, 19) finished
12:35:50 DISPATCHER: register_result: lock acquired
12:35:50 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:35:50 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.003429012671209636, 'num_filters_1': 30, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.03319538563948402, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 42, 'num_filters_3': 16}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5313563619600966, 'info': {'data05': 0.5313563619600966, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.003429012671209636, 'num_filters_1': 30, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.03319538563948402, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 42, 'num_filters_3': 16}"}}
exception: None

12:35:50 job_callback for (0, 0, 19) started
12:35:50 DISPATCHER: Trying to submit another job.
12:35:50 job_callback for (0, 0, 19) got condition
12:35:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:35:50 Only 7 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:35:50 HBMASTER: Trying to run another job!
12:35:50 job_callback for (0, 0, 19) finished
12:35:50 HBMASTER: schedule new run for iteration 0
12:35:50 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
12:35:50 HBMASTER: submitting job (0, 0, 20) to dispatcher
12:35:50 DISPATCHER: trying to submit job (0, 0, 20)
12:35:50 DISPATCHER: trying to notify the job_runner thread.
12:35:50 HBMASTER: job (0, 0, 20) submitted to dispatcher
12:35:50 DISPATCHER: Trying to submit another job.
12:35:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:35:50 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:35:50 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:35:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:35:50 WORKER: start processing job (0, 0, 20)
12:35:50 WORKER: args: ()
12:35:50 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.008516762738501741, 'num_filters_1': 29, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.018911498775788873, 'kernel_size_2': 5, 'num_filters_2': 47}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:36:47 DISPATCHER: Starting worker discovery
12:36:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:36:47 DISPATCHER: Finished worker discovery
12:37:47 DISPATCHER: Starting worker discovery
12:37:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:37:47 DISPATCHER: Finished worker discovery
12:38:21 WORKER: done with job (0, 0, 20), trying to register it.
12:38:21 WORKER: registered result for job (0, 0, 20) with dispatcher
12:38:21 DISPATCHER: job (0, 0, 20) finished
12:38:21 DISPATCHER: register_result: lock acquired
12:38:21 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:38:21 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.008516762738501741, 'num_filters_1': 29, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.018911498775788873, 'kernel_size_2': 5, 'num_filters_2': 47}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.238027003450976, 'info': {'data05': 0.238027003450976, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.008516762738501741, 'num_filters_1': 29, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.018911498775788873, 'kernel_size_2': 5, 'num_filters_2': 47}"}}
exception: None

12:38:21 job_callback for (0, 0, 20) started
12:38:21 job_callback for (0, 0, 20) got condition
12:38:21 DISPATCHER: Trying to submit another job.
12:38:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:38:21 Only 8 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:38:21 HBMASTER: Trying to run another job!
12:38:21 job_callback for (0, 0, 20) finished
12:38:21 HBMASTER: schedule new run for iteration 0
12:38:21 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
12:38:21 HBMASTER: submitting job (0, 0, 26) to dispatcher
12:38:21 DISPATCHER: trying to submit job (0, 0, 26)
12:38:21 DISPATCHER: trying to notify the job_runner thread.
12:38:21 HBMASTER: job (0, 0, 26) submitted to dispatcher
12:38:21 DISPATCHER: Trying to submit another job.
12:38:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:38:21 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:38:21 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:38:21 WORKER: start processing job (0, 0, 26)
12:38:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:38:21 WORKER: args: ()
12:38:21 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0017865382355292457, 'num_filters_1': 33, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.02479780657386614, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 54, 'num_filters_3': 100, 'num_filters_4': 21, 'num_filters_5': 82}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:38:47 DISPATCHER: Starting worker discovery
12:38:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:38:47 DISPATCHER: Finished worker discovery
12:39:47 DISPATCHER: Starting worker discovery
12:39:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:39:47 DISPATCHER: Finished worker discovery
12:40:47 DISPATCHER: Starting worker discovery
12:40:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:40:47 DISPATCHER: Finished worker discovery
12:40:50 WORKER: done with job (0, 0, 26), trying to register it.
12:40:50 WORKER: registered result for job (0, 0, 26) with dispatcher
12:40:50 DISPATCHER: job (0, 0, 26) finished
12:40:50 DISPATCHER: register_result: lock acquired
12:40:50 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:40:50 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0017865382355292457, 'num_filters_1': 33, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.02479780657386614, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 54, 'num_filters_3': 100, 'num_filters_4': 21, 'num_filters_5': 82}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8354223609449392, 'info': {'data05': 0.8354223609449392, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0017865382355292457, 'num_filters_1': 33, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.02479780657386614, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 54, 'num_filters_3': 100, 'num_filters_4': 21, 'num_filters_5': 82}"}}
exception: None

12:40:50 job_callback for (0, 0, 26) started
12:40:50 job_callback for (0, 0, 26) got condition
12:40:50 DISPATCHER: Trying to submit another job.
12:40:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:40:50 Only 9 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:40:50 HBMASTER: Trying to run another job!
12:40:50 job_callback for (0, 0, 26) finished
12:40:50 ITERATION: Advancing config (0, 0, 7) to next budget 400.000000
12:40:50 ITERATION: Advancing config (0, 0, 12) to next budget 400.000000
12:40:50 ITERATION: Advancing config (0, 0, 26) to next budget 400.000000
12:40:50 HBMASTER: schedule new run for iteration 0
12:40:50 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
12:40:50 HBMASTER: submitting job (0, 0, 7) to dispatcher
12:40:50 DISPATCHER: trying to submit job (0, 0, 7)
12:40:50 DISPATCHER: trying to notify the job_runner thread.
12:40:50 HBMASTER: job (0, 0, 7) submitted to dispatcher
12:40:50 DISPATCHER: Trying to submit another job.
12:40:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:40:50 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:40:50 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:40:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:40:50 WORKER: start processing job (0, 0, 7)
12:40:50 WORKER: args: ()
12:40:50 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.022871979901065376, 'num_filters_1': 79, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.04028959295819538, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 25, 'num_filters_3': 115, 'num_filters_4': 68, 'num_filters_5': 77}, 'budget': 400.0, 'working_directory': '.'}
12:41:47 DISPATCHER: Starting worker discovery
12:41:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:41:47 DISPATCHER: Finished worker discovery
12:42:47 DISPATCHER: Starting worker discovery
12:42:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:42:47 DISPATCHER: Finished worker discovery
12:43:47 DISPATCHER: Starting worker discovery
12:43:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:43:47 DISPATCHER: Finished worker discovery
12:44:47 DISPATCHER: Starting worker discovery
12:44:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:44:47 DISPATCHER: Finished worker discovery
12:45:47 DISPATCHER: Starting worker discovery
12:45:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:45:47 DISPATCHER: Finished worker discovery
12:46:47 DISPATCHER: Starting worker discovery
12:46:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:46:47 DISPATCHER: Finished worker discovery
12:47:47 DISPATCHER: Starting worker discovery
12:47:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:47:47 DISPATCHER: Finished worker discovery
12:47:57 WORKER: done with job (0, 0, 7), trying to register it.
12:47:57 WORKER: registered result for job (0, 0, 7) with dispatcher
12:47:57 DISPATCHER: job (0, 0, 7) finished
12:47:57 DISPATCHER: register_result: lock acquired
12:47:57 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:47:57 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.022871979901065376, 'num_filters_1': 79, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.04028959295819538, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 25, 'num_filters_3': 115, 'num_filters_4': 68, 'num_filters_5': 77}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.46379059075931117, 'info': {'data05': 0.46379059075931117, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.022871979901065376, 'num_filters_1': 79, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.04028959295819538, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 25, 'num_filters_3': 115, 'num_filters_4': 68, 'num_filters_5': 77}"}}
exception: None

12:47:57 job_callback for (0, 0, 7) started
12:47:57 DISPATCHER: Trying to submit another job.
12:47:57 job_callback for (0, 0, 7) got condition
12:47:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:47:57 Only 1 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
12:47:57 HBMASTER: Trying to run another job!
12:47:57 job_callback for (0, 0, 7) finished
12:47:57 HBMASTER: schedule new run for iteration 0
12:47:57 HBMASTER: trying submitting job (0, 0, 12) to dispatcher
12:47:57 HBMASTER: submitting job (0, 0, 12) to dispatcher
12:47:57 DISPATCHER: trying to submit job (0, 0, 12)
12:47:57 DISPATCHER: trying to notify the job_runner thread.
12:47:57 HBMASTER: job (0, 0, 12) submitted to dispatcher
12:47:57 DISPATCHER: Trying to submit another job.
12:47:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:47:57 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:47:57 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:47:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:47:57 WORKER: start processing job (0, 0, 12)
12:47:57 WORKER: args: ()
12:47:57 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0017336825347736894, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.02514758648261762, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 125, 'num_filters_3': 79}, 'budget': 400.0, 'working_directory': '.'}
12:48:47 DISPATCHER: Starting worker discovery
12:48:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:48:47 DISPATCHER: Finished worker discovery
12:49:47 DISPATCHER: Starting worker discovery
12:49:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:49:47 DISPATCHER: Finished worker discovery
12:50:47 DISPATCHER: Starting worker discovery
12:50:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:50:47 DISPATCHER: Finished worker discovery
12:51:47 DISPATCHER: Starting worker discovery
12:51:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:51:47 DISPATCHER: Finished worker discovery
12:52:47 DISPATCHER: Starting worker discovery
12:52:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:52:47 DISPATCHER: Finished worker discovery
12:53:47 DISPATCHER: Starting worker discovery
12:53:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:53:47 DISPATCHER: Finished worker discovery
12:54:47 DISPATCHER: Starting worker discovery
12:54:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:54:47 DISPATCHER: Finished worker discovery
12:54:58 WORKER: done with job (0, 0, 12), trying to register it.
12:54:58 WORKER: registered result for job (0, 0, 12) with dispatcher
12:54:58 DISPATCHER: job (0, 0, 12) finished
12:54:58 DISPATCHER: register_result: lock acquired
12:54:58 DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:54:58 job_id: (0, 0, 12)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0017336825347736894, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.02514758648261762, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 125, 'num_filters_3': 79}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5516969188530357, 'info': {'data05': 0.5516969188530357, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0017336825347736894, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.02514758648261762, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 125, 'num_filters_3': 79}"}}
exception: None

12:54:58 job_callback for (0, 0, 12) started
12:54:58 job_callback for (0, 0, 12) got condition
12:54:58 DISPATCHER: Trying to submit another job.
12:54:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:54:58 Only 2 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
12:54:58 HBMASTER: Trying to run another job!
12:54:58 job_callback for (0, 0, 12) finished
12:54:58 HBMASTER: schedule new run for iteration 0
12:54:58 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
12:54:58 HBMASTER: submitting job (0, 0, 26) to dispatcher
12:54:58 DISPATCHER: trying to submit job (0, 0, 26)
12:54:58 DISPATCHER: trying to notify the job_runner thread.
12:54:58 HBMASTER: job (0, 0, 26) submitted to dispatcher
12:54:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:54:58 DISPATCHER: Trying to submit another job.
12:54:58 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:54:58 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:54:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:54:58 WORKER: start processing job (0, 0, 26)
12:54:58 WORKER: args: ()
12:54:58 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0017865382355292457, 'num_filters_1': 33, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.02479780657386614, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 54, 'num_filters_3': 100, 'num_filters_4': 21, 'num_filters_5': 82}, 'budget': 400.0, 'working_directory': '.'}
12:55:47 DISPATCHER: Starting worker discovery
12:55:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:55:47 DISPATCHER: Finished worker discovery
12:56:47 DISPATCHER: Starting worker discovery
12:56:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:56:47 DISPATCHER: Finished worker discovery
12:57:47 DISPATCHER: Starting worker discovery
12:57:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:57:47 DISPATCHER: Finished worker discovery
12:58:47 DISPATCHER: Starting worker discovery
12:58:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:58:47 DISPATCHER: Finished worker discovery
12:59:47 DISPATCHER: Starting worker discovery
12:59:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:59:47 DISPATCHER: Finished worker discovery
13:00:47 DISPATCHER: Starting worker discovery
13:00:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:00:47 DISPATCHER: Finished worker discovery
13:01:47 DISPATCHER: Starting worker discovery
13:01:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:01:47 DISPATCHER: Finished worker discovery
13:01:56 WORKER: done with job (0, 0, 26), trying to register it.
13:01:56 WORKER: registered result for job (0, 0, 26) with dispatcher
13:01:56 DISPATCHER: job (0, 0, 26) finished
13:01:56 DISPATCHER: register_result: lock acquired
13:01:56 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
13:01:56 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0017865382355292457, 'num_filters_1': 33, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.02479780657386614, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 54, 'num_filters_3': 100, 'num_filters_4': 21, 'num_filters_5': 82}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8355544006942669, 'info': {'data05': 0.8355544006942669, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0017865382355292457, 'num_filters_1': 33, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.02479780657386614, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 54, 'num_filters_3': 100, 'num_filters_4': 21, 'num_filters_5': 82}"}}
exception: None

13:01:56 job_callback for (0, 0, 26) started
13:01:56 job_callback for (0, 0, 26) got condition
13:01:56 DISPATCHER: Trying to submit another job.
13:01:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:01:56 Only 3 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
13:01:56 HBMASTER: Trying to run another job!
13:01:56 job_callback for (0, 0, 26) finished
13:01:56 ITERATION: Advancing config (0, 0, 26) to next budget 1200.000000
13:01:56 HBMASTER: schedule new run for iteration 0
13:01:56 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
13:01:56 HBMASTER: submitting job (0, 0, 26) to dispatcher
13:01:56 DISPATCHER: trying to submit job (0, 0, 26)
13:01:56 DISPATCHER: trying to notify the job_runner thread.
13:01:56 HBMASTER: job (0, 0, 26) submitted to dispatcher
13:01:56 DISPATCHER: Trying to submit another job.
13:01:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:01:56 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:01:56 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:01:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:01:56 WORKER: start processing job (0, 0, 26)
13:01:56 WORKER: args: ()
13:01:56 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0017865382355292457, 'num_filters_1': 33, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.02479780657386614, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 54, 'num_filters_3': 100, 'num_filters_4': 21, 'num_filters_5': 82}, 'budget': 1200.0, 'working_directory': '.'}
13:02:47 DISPATCHER: Starting worker discovery
13:02:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:02:47 DISPATCHER: Finished worker discovery
13:03:47 DISPATCHER: Starting worker discovery
13:03:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:03:47 DISPATCHER: Finished worker discovery
13:04:47 DISPATCHER: Starting worker discovery
13:04:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:04:47 DISPATCHER: Finished worker discovery
13:05:47 DISPATCHER: Starting worker discovery
13:05:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:05:47 DISPATCHER: Finished worker discovery
13:06:47 DISPATCHER: Starting worker discovery
13:06:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:06:47 DISPATCHER: Finished worker discovery
13:07:47 DISPATCHER: Starting worker discovery
13:07:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:07:47 DISPATCHER: Finished worker discovery
13:08:47 DISPATCHER: Starting worker discovery
13:08:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:08:47 DISPATCHER: Finished worker discovery
13:09:47 DISPATCHER: Starting worker discovery
13:09:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:09:47 DISPATCHER: Finished worker discovery
13:10:47 DISPATCHER: Starting worker discovery
13:10:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:10:47 DISPATCHER: Finished worker discovery
13:11:47 DISPATCHER: Starting worker discovery
13:11:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:11:47 DISPATCHER: Finished worker discovery
13:12:47 DISPATCHER: Starting worker discovery
13:12:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:12:47 DISPATCHER: Finished worker discovery
13:13:47 DISPATCHER: Starting worker discovery
13:13:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:13:47 DISPATCHER: Finished worker discovery
13:14:47 DISPATCHER: Starting worker discovery
13:14:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:14:47 DISPATCHER: Finished worker discovery
13:15:47 DISPATCHER: Starting worker discovery
13:15:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:15:47 DISPATCHER: Finished worker discovery
13:16:47 DISPATCHER: Starting worker discovery
13:16:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:16:47 DISPATCHER: Finished worker discovery
13:17:47 DISPATCHER: Starting worker discovery
13:17:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:17:47 DISPATCHER: Finished worker discovery
13:18:47 DISPATCHER: Starting worker discovery
13:18:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:18:47 DISPATCHER: Finished worker discovery
13:19:47 DISPATCHER: Starting worker discovery
13:19:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:19:47 DISPATCHER: Finished worker discovery
13:20:47 DISPATCHER: Starting worker discovery
13:20:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:20:47 DISPATCHER: Finished worker discovery
13:21:47 DISPATCHER: Starting worker discovery
13:21:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:21:47 DISPATCHER: Finished worker discovery
13:22:30 WORKER: done with job (0, 0, 26), trying to register it.
13:22:30 WORKER: registered result for job (0, 0, 26) with dispatcher
13:22:30 DISPATCHER: job (0, 0, 26) finished
13:22:30 DISPATCHER: register_result: lock acquired
13:22:30 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
13:22:30 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0017865382355292457, 'num_filters_1': 33, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.02479780657386614, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 54, 'num_filters_3': 100, 'num_filters_4': 21, 'num_filters_5': 82}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.8612185741905203, 'info': {'data05': 0.8612185741905203, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0017865382355292457, 'num_filters_1': 33, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.02479780657386614, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 54, 'num_filters_3': 100, 'num_filters_4': 21, 'num_filters_5': 82}"}}
exception: None

13:22:30 job_callback for (0, 0, 26) started
13:22:30 job_callback for (0, 0, 26) got condition
13:22:30 DISPATCHER: Trying to submit another job.
13:22:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:22:30 Only 1 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
13:22:30 HBMASTER: Trying to run another job!
13:22:30 job_callback for (0, 0, 26) finished
13:22:30 start sampling a new configuration.
13:22:30 done sampling a new configuration.
13:22:30 HBMASTER: schedule new run for iteration 1
13:22:30 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
13:22:30 HBMASTER: submitting job (1, 0, 0) to dispatcher
13:22:30 DISPATCHER: trying to submit job (1, 0, 0)
13:22:30 DISPATCHER: trying to notify the job_runner thread.
13:22:30 HBMASTER: job (1, 0, 0) submitted to dispatcher
13:22:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:22:30 DISPATCHER: Trying to submit another job.
13:22:30 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:22:30 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:22:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:22:30 WORKER: start processing job (1, 0, 0)
13:22:30 WORKER: args: ()
13:22:30 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.006123668352855627, 'num_filters_1': 72, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.07818491848435356, 'kernel_size_2': 5, 'num_filters_2': 103}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:22:47 DISPATCHER: Starting worker discovery
13:22:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:22:47 DISPATCHER: Finished worker discovery
13:23:47 DISPATCHER: Starting worker discovery
13:23:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:23:47 DISPATCHER: Finished worker discovery
13:24:47 DISPATCHER: Starting worker discovery
13:24:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:24:47 DISPATCHER: Finished worker discovery
13:25:04 WORKER: done with job (1, 0, 0), trying to register it.
13:25:04 WORKER: registered result for job (1, 0, 0) with dispatcher
13:25:04 DISPATCHER: job (1, 0, 0) finished
13:25:04 DISPATCHER: register_result: lock acquired
13:25:04 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
13:25:04 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.006123668352855627, 'num_filters_1': 72, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.07818491848435356, 'kernel_size_2': 5, 'num_filters_2': 103}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.18077056802263505, 'info': {'data05': 0.18077056802263505, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.006123668352855627, 'num_filters_1': 72, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.07818491848435356, 'kernel_size_2': 5, 'num_filters_2': 103}"}}
exception: None

13:25:04 job_callback for (1, 0, 0) started
13:25:04 DISPATCHER: Trying to submit another job.
13:25:04 job_callback for (1, 0, 0) got condition
13:25:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:25:04 Only 10 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
13:25:04 HBMASTER: Trying to run another job!
13:25:04 job_callback for (1, 0, 0) finished
13:25:04 start sampling a new configuration.
13:25:04 done sampling a new configuration.
13:25:04 HBMASTER: schedule new run for iteration 1
13:25:04 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
13:25:04 HBMASTER: submitting job (1, 0, 1) to dispatcher
13:25:04 DISPATCHER: trying to submit job (1, 0, 1)
13:25:04 DISPATCHER: trying to notify the job_runner thread.
13:25:04 HBMASTER: job (1, 0, 1) submitted to dispatcher
13:25:04 DISPATCHER: Trying to submit another job.
13:25:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:25:04 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:25:04 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:25:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:25:04 WORKER: start processing job (1, 0, 1)
13:25:04 WORKER: args: ()
13:25:04 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.005597705496079009, 'num_filters_1': 37, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 53, 'weight_decay': 0.1394773676591541, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 27, 'num_filters_3': 62, 'num_filters_4': 68, 'num_filters_5': 29}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:25:47 DISPATCHER: Starting worker discovery
13:25:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:25:47 DISPATCHER: Finished worker discovery
13:26:47 DISPATCHER: Starting worker discovery
13:26:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:26:47 DISPATCHER: Finished worker discovery
13:27:33 WORKER: done with job (1, 0, 1), trying to register it.
13:27:33 WORKER: registered result for job (1, 0, 1) with dispatcher
13:27:33 DISPATCHER: job (1, 0, 1) finished
13:27:33 DISPATCHER: register_result: lock acquired
13:27:33 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
13:27:33 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.005597705496079009, 'num_filters_1': 37, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 53, 'weight_decay': 0.1394773676591541, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 27, 'num_filters_3': 62, 'num_filters_4': 68, 'num_filters_5': 29}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.18590933034322052, 'info': {'data05': 0.18590933034322052, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.005597705496079009, 'num_filters_1': 37, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 53, 'weight_decay': 0.1394773676591541, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 27, 'num_filters_3': 62, 'num_filters_4': 68, 'num_filters_5': 29}"}}
exception: None

13:27:33 job_callback for (1, 0, 1) started
13:27:33 DISPATCHER: Trying to submit another job.
13:27:33 job_callback for (1, 0, 1) got condition
13:27:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:27:33 Only 11 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
13:27:33 HBMASTER: Trying to run another job!
13:27:33 job_callback for (1, 0, 1) finished
13:27:33 start sampling a new configuration.
13:27:33 done sampling a new configuration.
13:27:33 HBMASTER: schedule new run for iteration 1
13:27:33 HBMASTER: trying submitting job (1, 0, 2) to dispatcher
13:27:33 HBMASTER: submitting job (1, 0, 2) to dispatcher
13:27:33 DISPATCHER: trying to submit job (1, 0, 2)
13:27:33 DISPATCHER: trying to notify the job_runner thread.
13:27:33 HBMASTER: job (1, 0, 2) submitted to dispatcher
13:27:33 DISPATCHER: Trying to submit another job.
13:27:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:27:33 DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:27:33 DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:27:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:27:33 WORKER: start processing job (1, 0, 2)
13:27:33 WORKER: args: ()
13:27:33 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0011560960658035186, 'num_filters_1': 22, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.08154726443713738, 'kernel_size_2': 5, 'num_filters_2': 120}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:27:47 DISPATCHER: Starting worker discovery
13:27:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:27:47 DISPATCHER: Finished worker discovery
13:28:47 DISPATCHER: Starting worker discovery
13:28:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:28:47 DISPATCHER: Finished worker discovery
13:29:47 DISPATCHER: Starting worker discovery
13:29:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:29:47 DISPATCHER: Finished worker discovery
13:30:01 WORKER: done with job (1, 0, 2), trying to register it.
13:30:01 WORKER: registered result for job (1, 0, 2) with dispatcher
13:30:01 DISPATCHER: job (1, 0, 2) finished
13:30:01 DISPATCHER: register_result: lock acquired
13:30:01 DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
13:30:01 job_id: (1, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0011560960658035186, 'num_filters_1': 22, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.08154726443713738, 'kernel_size_2': 5, 'num_filters_2': 120}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.20545307096575657, 'info': {'data05': 0.20545307096575657, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0011560960658035186, 'num_filters_1': 22, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.08154726443713738, 'kernel_size_2': 5, 'num_filters_2': 120}"}}
exception: None

13:30:01 job_callback for (1, 0, 2) started
13:30:01 job_callback for (1, 0, 2) got condition
13:30:01 DISPATCHER: Trying to submit another job.
13:30:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:30:01 Only 12 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
13:30:01 HBMASTER: Trying to run another job!
13:30:01 job_callback for (1, 0, 2) finished
13:30:01 start sampling a new configuration.
13:30:01 done sampling a new configuration.
13:30:01 HBMASTER: schedule new run for iteration 1
13:30:01 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
13:30:01 HBMASTER: submitting job (1, 0, 3) to dispatcher
13:30:01 DISPATCHER: trying to submit job (1, 0, 3)
13:30:01 DISPATCHER: trying to notify the job_runner thread.
13:30:01 HBMASTER: job (1, 0, 3) submitted to dispatcher
13:30:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:30:01 DISPATCHER: Trying to submit another job.
13:30:01 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:30:01 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:30:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:30:01 WORKER: start processing job (1, 0, 3)
13:30:01 WORKER: args: ()
13:30:01 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.07717790018878155, 'num_filters_1': 120, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.01737763690696568, 'kernel_size_2': 3, 'num_filters_2': 29}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:30:47 DISPATCHER: Starting worker discovery
13:30:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:30:47 DISPATCHER: Finished worker discovery
13:31:47 DISPATCHER: Starting worker discovery
13:31:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:31:47 DISPATCHER: Finished worker discovery
13:32:30 WORKER: done with job (1, 0, 3), trying to register it.
13:32:30 WORKER: registered result for job (1, 0, 3) with dispatcher
13:32:30 DISPATCHER: job (1, 0, 3) finished
13:32:30 DISPATCHER: register_result: lock acquired
13:32:30 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
13:32:30 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.07717790018878155, 'num_filters_1': 120, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.01737763690696568, 'kernel_size_2': 3, 'num_filters_2': 29}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.04403925687619924, 'info': {'data05': 0.04403925687619924, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.07717790018878155, 'num_filters_1': 120, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.01737763690696568, 'kernel_size_2': 3, 'num_filters_2': 29}"}}
exception: None

13:32:30 job_callback for (1, 0, 3) started
13:32:30 job_callback for (1, 0, 3) got condition
13:32:30 DISPATCHER: Trying to submit another job.
13:32:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:32:30 Only 13 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
13:32:30 HBMASTER: Trying to run another job!
13:32:30 job_callback for (1, 0, 3) finished
13:32:30 start sampling a new configuration.
13:32:30 done sampling a new configuration.
13:32:30 HBMASTER: schedule new run for iteration 1
13:32:30 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
13:32:30 HBMASTER: submitting job (1, 0, 4) to dispatcher
13:32:30 DISPATCHER: trying to submit job (1, 0, 4)
13:32:30 DISPATCHER: trying to notify the job_runner thread.
13:32:30 HBMASTER: job (1, 0, 4) submitted to dispatcher
13:32:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:32:30 DISPATCHER: Trying to submit another job.
13:32:30 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:32:30 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:32:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:32:30 WORKER: start processing job (1, 0, 4)
13:32:30 WORKER: args: ()
13:32:30 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.008065298362243609, 'num_filters_1': 102, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.05696118366927933, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 22, 'num_filters_3': 28, 'num_filters_4': 88, 'num_filters_5': 31}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:32:47 DISPATCHER: Starting worker discovery
13:32:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:32:47 DISPATCHER: Finished worker discovery
13:33:47 DISPATCHER: Starting worker discovery
13:33:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:33:47 DISPATCHER: Finished worker discovery
13:34:47 DISPATCHER: Starting worker discovery
13:34:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:34:47 DISPATCHER: Finished worker discovery
13:34:58 WORKER: done with job (1, 0, 4), trying to register it.
13:34:58 WORKER: registered result for job (1, 0, 4) with dispatcher
13:34:58 DISPATCHER: job (1, 0, 4) finished
13:34:58 DISPATCHER: register_result: lock acquired
13:34:58 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
13:34:58 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.008065298362243609, 'num_filters_1': 102, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.05696118366927933, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 22, 'num_filters_3': 28, 'num_filters_4': 88, 'num_filters_5': 31}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.008065298362243609, 'num_filters_1': 102, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.05696118366927933, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 22, 'num_filters_3': 28, 'num_filters_4': 88, 'num_filters_5': 31}"}}
exception: None

13:34:58 job_callback for (1, 0, 4) started
13:34:58 DISPATCHER: Trying to submit another job.
13:34:58 job_callback for (1, 0, 4) got condition
13:34:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:34:58 Only 14 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
13:34:58 HBMASTER: Trying to run another job!
13:34:58 job_callback for (1, 0, 4) finished
13:34:58 start sampling a new configuration.
13:34:58 done sampling a new configuration.
13:34:58 HBMASTER: schedule new run for iteration 1
13:34:58 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
13:34:58 HBMASTER: submitting job (1, 0, 5) to dispatcher
13:34:58 DISPATCHER: trying to submit job (1, 0, 5)
13:34:58 DISPATCHER: trying to notify the job_runner thread.
13:34:58 HBMASTER: job (1, 0, 5) submitted to dispatcher
13:34:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:34:58 DISPATCHER: Trying to submit another job.
13:34:58 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:34:58 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:34:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:34:58 WORKER: start processing job (1, 0, 5)
13:34:58 WORKER: args: ()
13:34:58 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.00723129090619713, 'num_filters_1': 65, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.011402924976429207, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 19, 'num_filters_3': 19, 'num_filters_4': 20}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:35:47 DISPATCHER: Starting worker discovery
13:35:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:35:47 DISPATCHER: Finished worker discovery
13:36:47 DISPATCHER: Starting worker discovery
13:36:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:36:47 DISPATCHER: Finished worker discovery
13:37:29 WORKER: done with job (1, 0, 5), trying to register it.
13:37:29 WORKER: registered result for job (1, 0, 5) with dispatcher
13:37:29 DISPATCHER: job (1, 0, 5) finished
13:37:29 DISPATCHER: register_result: lock acquired
13:37:29 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
13:37:29 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.00723129090619713, 'num_filters_1': 65, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.011402924976429207, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 19, 'num_filters_3': 19, 'num_filters_4': 20}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7818435920258308, 'info': {'data05': 0.7818435920258308, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.00723129090619713, 'num_filters_1': 65, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.011402924976429207, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 19, 'num_filters_3': 19, 'num_filters_4': 20}"}}
exception: None

13:37:29 job_callback for (1, 0, 5) started
13:37:29 job_callback for (1, 0, 5) got condition
13:37:29 DISPATCHER: Trying to submit another job.
13:37:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:37:29 Only 15 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
13:37:29 HBMASTER: Trying to run another job!
13:37:29 job_callback for (1, 0, 5) finished
13:37:29 start sampling a new configuration.
13:37:29 done sampling a new configuration.
13:37:29 HBMASTER: schedule new run for iteration 1
13:37:29 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
13:37:29 HBMASTER: submitting job (1, 0, 6) to dispatcher
13:37:29 DISPATCHER: trying to submit job (1, 0, 6)
13:37:29 DISPATCHER: trying to notify the job_runner thread.
13:37:29 HBMASTER: job (1, 0, 6) submitted to dispatcher
13:37:29 DISPATCHER: Trying to submit another job.
13:37:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:37:29 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:37:29 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:37:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:37:29 WORKER: start processing job (1, 0, 6)
13:37:29 WORKER: args: ()
13:37:29 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.002104669515513631, 'num_filters_1': 52, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.018018769972454884, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 56, 'num_filters_3': 22, 'num_filters_4': 28, 'num_filters_5': 99}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:37:47 DISPATCHER: Starting worker discovery
13:37:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:37:47 DISPATCHER: Finished worker discovery
13:38:47 DISPATCHER: Starting worker discovery
13:38:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:38:47 DISPATCHER: Finished worker discovery
13:39:47 DISPATCHER: Starting worker discovery
13:39:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:39:47 DISPATCHER: Finished worker discovery
13:40:10 WORKER: done with job (1, 0, 6), trying to register it.
13:40:10 WORKER: registered result for job (1, 0, 6) with dispatcher
13:40:10 DISPATCHER: job (1, 0, 6) finished
13:40:10 DISPATCHER: register_result: lock acquired
13:40:10 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
13:40:10 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.002104669515513631, 'num_filters_1': 52, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.018018769972454884, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 56, 'num_filters_3': 22, 'num_filters_4': 28, 'num_filters_5': 99}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5674424988629412, 'info': {'data05': 0.5674424988629412, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.002104669515513631, 'num_filters_1': 52, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.018018769972454884, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 56, 'num_filters_3': 22, 'num_filters_4': 28, 'num_filters_5': 99}"}}
exception: None

13:40:10 job_callback for (1, 0, 6) started
13:40:10 DISPATCHER: Trying to submit another job.
13:40:10 job_callback for (1, 0, 6) got condition
13:40:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:40:10 Only 16 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
13:40:10 HBMASTER: Trying to run another job!
13:40:10 job_callback for (1, 0, 6) finished
13:40:10 start sampling a new configuration.
13:40:10 done sampling a new configuration.
13:40:10 HBMASTER: schedule new run for iteration 1
13:40:10 HBMASTER: trying submitting job (1, 0, 7) to dispatcher
13:40:10 HBMASTER: submitting job (1, 0, 7) to dispatcher
13:40:10 DISPATCHER: trying to submit job (1, 0, 7)
13:40:10 DISPATCHER: trying to notify the job_runner thread.
13:40:10 HBMASTER: job (1, 0, 7) submitted to dispatcher
13:40:10 DISPATCHER: Trying to submit another job.
13:40:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:40:10 DISPATCHER: starting job (1, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:40:10 DISPATCHER: job (1, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:40:10 WORKER: start processing job (1, 0, 7)
13:40:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:40:10 WORKER: args: ()
13:40:10 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0032833299908014597, 'num_filters_1': 66, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.06336156741824073, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 121, 'num_filters_3': 25, 'num_filters_4': 33, 'num_filters_5': 48}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:40:47 DISPATCHER: Starting worker discovery
13:40:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:40:47 DISPATCHER: Finished worker discovery
13:41:47 DISPATCHER: Starting worker discovery
13:41:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:41:47 DISPATCHER: Finished worker discovery
13:42:38 WORKER: done with job (1, 0, 7), trying to register it.
13:42:38 WORKER: registered result for job (1, 0, 7) with dispatcher
13:42:38 DISPATCHER: job (1, 0, 7) finished
13:42:38 DISPATCHER: register_result: lock acquired
13:42:38 DISPATCHER: job (1, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
13:42:38 job_id: (1, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0032833299908014597, 'num_filters_1': 66, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.06336156741824073, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 121, 'num_filters_3': 25, 'num_filters_4': 33, 'num_filters_5': 48}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5469942825595688, 'info': {'data05': 0.5469942825595688, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0032833299908014597, 'num_filters_1': 66, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.06336156741824073, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 121, 'num_filters_3': 25, 'num_filters_4': 33, 'num_filters_5': 48}"}}
exception: None

13:42:38 job_callback for (1, 0, 7) started
13:42:38 job_callback for (1, 0, 7) got condition
13:42:38 DISPATCHER: Trying to submit another job.
13:42:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:42:38 HBMASTER: Trying to run another job!
13:42:38 job_callback for (1, 0, 7) finished
13:42:38 start sampling a new configuration.
13:42:38 done sampling a new configuration.
13:42:38 HBMASTER: schedule new run for iteration 1
13:42:38 HBMASTER: trying submitting job (1, 0, 8) to dispatcher
13:42:38 HBMASTER: submitting job (1, 0, 8) to dispatcher
13:42:38 DISPATCHER: trying to submit job (1, 0, 8)
13:42:38 DISPATCHER: trying to notify the job_runner thread.
13:42:38 HBMASTER: job (1, 0, 8) submitted to dispatcher
13:42:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:42:38 DISPATCHER: Trying to submit another job.
13:42:38 DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:42:38 DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:42:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:42:38 WORKER: start processing job (1, 0, 8)
13:42:38 WORKER: args: ()
13:42:38 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.009764798031080763, 'num_filters_1': 37, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 33, 'weight_decay': 0.011911195473769325, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 89, 'num_filters_3': 59, 'num_filters_4': 19, 'num_filters_5': 23}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:42:47 DISPATCHER: Starting worker discovery
13:42:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:42:47 DISPATCHER: Finished worker discovery
13:43:47 DISPATCHER: Starting worker discovery
13:43:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:43:47 DISPATCHER: Finished worker discovery
13:44:47 DISPATCHER: Starting worker discovery
13:44:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:44:47 DISPATCHER: Finished worker discovery
13:45:08 WORKER: done with job (1, 0, 8), trying to register it.
13:45:08 WORKER: registered result for job (1, 0, 8) with dispatcher
13:45:08 DISPATCHER: job (1, 0, 8) finished
13:45:08 DISPATCHER: register_result: lock acquired
13:45:08 DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
13:45:08 job_id: (1, 0, 8)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.009764798031080763, 'num_filters_1': 37, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 33, 'weight_decay': 0.011911195473769325, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 89, 'num_filters_3': 59, 'num_filters_4': 19, 'num_filters_5': 23}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.009764798031080763, 'num_filters_1': 37, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 33, 'weight_decay': 0.011911195473769325, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 89, 'num_filters_3': 59, 'num_filters_4': 19, 'num_filters_5': 23}"}}
exception: None

13:45:08 job_callback for (1, 0, 8) started
13:45:08 job_callback for (1, 0, 8) got condition
13:45:08 DISPATCHER: Trying to submit another job.
13:45:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:45:08 HBMASTER: Trying to run another job!
13:45:08 job_callback for (1, 0, 8) finished
13:45:08 ITERATION: Advancing config (1, 0, 5) to next budget 400.000000
13:45:08 ITERATION: Advancing config (1, 0, 6) to next budget 400.000000
13:45:08 ITERATION: Advancing config (1, 0, 7) to next budget 400.000000
13:45:08 HBMASTER: schedule new run for iteration 1
13:45:08 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
13:45:08 HBMASTER: submitting job (1, 0, 5) to dispatcher
13:45:08 DISPATCHER: trying to submit job (1, 0, 5)
13:45:08 DISPATCHER: trying to notify the job_runner thread.
13:45:08 HBMASTER: job (1, 0, 5) submitted to dispatcher
13:45:08 DISPATCHER: Trying to submit another job.
13:45:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:45:08 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:45:08 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:45:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:45:08 WORKER: start processing job (1, 0, 5)
13:45:08 WORKER: args: ()
13:45:08 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.00723129090619713, 'num_filters_1': 65, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.011402924976429207, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 19, 'num_filters_3': 19, 'num_filters_4': 20}, 'budget': 400.0, 'working_directory': '.'}
13:45:47 DISPATCHER: Starting worker discovery
13:45:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:45:47 DISPATCHER: Finished worker discovery
13:46:47 DISPATCHER: Starting worker discovery
13:46:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:46:47 DISPATCHER: Finished worker discovery
13:47:47 DISPATCHER: Starting worker discovery
13:47:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:47:47 DISPATCHER: Finished worker discovery
13:48:47 DISPATCHER: Starting worker discovery
13:48:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:48:47 DISPATCHER: Finished worker discovery
13:49:47 DISPATCHER: Starting worker discovery
13:49:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:49:47 DISPATCHER: Finished worker discovery
13:50:47 DISPATCHER: Starting worker discovery
13:50:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:50:47 DISPATCHER: Finished worker discovery
13:51:47 DISPATCHER: Starting worker discovery
13:51:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:51:47 DISPATCHER: Finished worker discovery
13:52:19 WORKER: done with job (1, 0, 5), trying to register it.
13:52:19 WORKER: registered result for job (1, 0, 5) with dispatcher
13:52:19 DISPATCHER: job (1, 0, 5) finished
13:52:19 DISPATCHER: register_result: lock acquired
13:52:19 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
13:52:19 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.00723129090619713, 'num_filters_1': 65, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.011402924976429207, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 19, 'num_filters_3': 19, 'num_filters_4': 20}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6545211822275354, 'info': {'data05': 0.6545211822275354, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.00723129090619713, 'num_filters_1': 65, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.011402924976429207, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 19, 'num_filters_3': 19, 'num_filters_4': 20}"}}
exception: None

13:52:19 job_callback for (1, 0, 5) started
13:52:19 DISPATCHER: Trying to submit another job.
13:52:19 job_callback for (1, 0, 5) got condition
13:52:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:52:19 Only 4 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
13:52:19 HBMASTER: Trying to run another job!
13:52:19 job_callback for (1, 0, 5) finished
13:52:19 HBMASTER: schedule new run for iteration 1
13:52:19 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
13:52:19 HBMASTER: submitting job (1, 0, 6) to dispatcher
13:52:19 DISPATCHER: trying to submit job (1, 0, 6)
13:52:19 DISPATCHER: trying to notify the job_runner thread.
13:52:19 HBMASTER: job (1, 0, 6) submitted to dispatcher
13:52:19 DISPATCHER: Trying to submit another job.
13:52:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:52:19 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:52:19 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:52:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:52:19 WORKER: start processing job (1, 0, 6)
13:52:19 WORKER: args: ()
13:52:19 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.002104669515513631, 'num_filters_1': 52, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.018018769972454884, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 56, 'num_filters_3': 22, 'num_filters_4': 28, 'num_filters_5': 99}, 'budget': 400.0, 'working_directory': '.'}
13:52:47 DISPATCHER: Starting worker discovery
13:52:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:52:48 DISPATCHER: Finished worker discovery
13:53:48 DISPATCHER: Starting worker discovery
13:53:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:53:48 DISPATCHER: Finished worker discovery
13:54:48 DISPATCHER: Starting worker discovery
13:54:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:54:48 DISPATCHER: Finished worker discovery
13:55:48 DISPATCHER: Starting worker discovery
13:55:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:55:48 DISPATCHER: Finished worker discovery
13:56:48 DISPATCHER: Starting worker discovery
13:56:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:56:48 DISPATCHER: Finished worker discovery
13:57:48 DISPATCHER: Starting worker discovery
13:57:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:57:48 DISPATCHER: Finished worker discovery
13:58:48 DISPATCHER: Starting worker discovery
13:58:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:58:48 DISPATCHER: Finished worker discovery
13:59:48 DISPATCHER: Starting worker discovery
13:59:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:59:48 DISPATCHER: Finished worker discovery
14:00:04 WORKER: done with job (1, 0, 6), trying to register it.
14:00:04 WORKER: registered result for job (1, 0, 6) with dispatcher
14:00:04 DISPATCHER: job (1, 0, 6) finished
14:00:04 DISPATCHER: register_result: lock acquired
14:00:04 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
14:00:04 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.002104669515513631, 'num_filters_1': 52, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.018018769972454884, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 56, 'num_filters_3': 22, 'num_filters_4': 28, 'num_filters_5': 99}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.30435856135928807, 'info': {'data05': 0.30435856135928807, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.002104669515513631, 'num_filters_1': 52, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.018018769972454884, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 56, 'num_filters_3': 22, 'num_filters_4': 28, 'num_filters_5': 99}"}}
exception: None

14:00:04 job_callback for (1, 0, 6) started
14:00:04 job_callback for (1, 0, 6) got condition
14:00:04 DISPATCHER: Trying to submit another job.
14:00:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:00:04 Only 5 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
14:00:04 HBMASTER: Trying to run another job!
14:00:04 job_callback for (1, 0, 6) finished
14:00:04 HBMASTER: schedule new run for iteration 1
14:00:04 HBMASTER: trying submitting job (1, 0, 7) to dispatcher
14:00:04 HBMASTER: submitting job (1, 0, 7) to dispatcher
14:00:04 DISPATCHER: trying to submit job (1, 0, 7)
14:00:04 DISPATCHER: trying to notify the job_runner thread.
14:00:04 HBMASTER: job (1, 0, 7) submitted to dispatcher
14:00:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:00:04 DISPATCHER: Trying to submit another job.
14:00:04 DISPATCHER: starting job (1, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:00:04 DISPATCHER: job (1, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:00:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:00:04 WORKER: start processing job (1, 0, 7)
14:00:04 WORKER: args: ()
14:00:04 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0032833299908014597, 'num_filters_1': 66, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.06336156741824073, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 121, 'num_filters_3': 25, 'num_filters_4': 33, 'num_filters_5': 48}, 'budget': 400.0, 'working_directory': '.'}
14:00:48 DISPATCHER: Starting worker discovery
14:00:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:00:48 DISPATCHER: Finished worker discovery
14:01:48 DISPATCHER: Starting worker discovery
14:01:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:01:48 DISPATCHER: Finished worker discovery
14:02:48 DISPATCHER: Starting worker discovery
14:02:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:02:48 DISPATCHER: Finished worker discovery
14:03:48 DISPATCHER: Starting worker discovery
14:03:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:03:48 DISPATCHER: Finished worker discovery
14:04:48 DISPATCHER: Starting worker discovery
14:04:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:04:48 DISPATCHER: Finished worker discovery
14:05:48 DISPATCHER: Starting worker discovery
14:05:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:05:48 DISPATCHER: Finished worker discovery
14:06:48 DISPATCHER: Starting worker discovery
14:06:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:06:48 DISPATCHER: Finished worker discovery
14:07:03 WORKER: done with job (1, 0, 7), trying to register it.
14:07:03 WORKER: registered result for job (1, 0, 7) with dispatcher
14:07:03 DISPATCHER: job (1, 0, 7) finished
14:07:03 DISPATCHER: register_result: lock acquired
14:07:03 DISPATCHER: job (1, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
14:07:03 job_id: (1, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0032833299908014597, 'num_filters_1': 66, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.06336156741824073, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 121, 'num_filters_3': 25, 'num_filters_4': 33, 'num_filters_5': 48}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.27097306288815115, 'info': {'data05': 0.27097306288815115, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0032833299908014597, 'num_filters_1': 66, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.06336156741824073, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 121, 'num_filters_3': 25, 'num_filters_4': 33, 'num_filters_5': 48}"}}
exception: None

14:07:03 job_callback for (1, 0, 7) started
14:07:03 job_callback for (1, 0, 7) got condition
14:07:03 DISPATCHER: Trying to submit another job.
14:07:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:07:03 Only 6 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
14:07:03 HBMASTER: Trying to run another job!
14:07:03 job_callback for (1, 0, 7) finished
14:07:03 ITERATION: Advancing config (1, 0, 5) to next budget 1200.000000
14:07:03 HBMASTER: schedule new run for iteration 1
14:07:03 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
14:07:03 HBMASTER: submitting job (1, 0, 5) to dispatcher
14:07:03 DISPATCHER: trying to submit job (1, 0, 5)
14:07:03 DISPATCHER: trying to notify the job_runner thread.
14:07:03 HBMASTER: job (1, 0, 5) submitted to dispatcher
14:07:03 DISPATCHER: Trying to submit another job.
14:07:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:07:03 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:07:03 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:07:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:07:03 WORKER: start processing job (1, 0, 5)
14:07:03 WORKER: args: ()
14:07:03 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.00723129090619713, 'num_filters_1': 65, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.011402924976429207, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 19, 'num_filters_3': 19, 'num_filters_4': 20}, 'budget': 1200.0, 'working_directory': '.'}
14:07:48 DISPATCHER: Starting worker discovery
14:07:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:07:48 DISPATCHER: Finished worker discovery
14:08:48 DISPATCHER: Starting worker discovery
14:08:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:08:48 DISPATCHER: Finished worker discovery
14:09:48 DISPATCHER: Starting worker discovery
14:09:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:09:48 DISPATCHER: Finished worker discovery
14:10:48 DISPATCHER: Starting worker discovery
14:10:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:10:48 DISPATCHER: Finished worker discovery
14:11:48 DISPATCHER: Starting worker discovery
14:11:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:11:48 DISPATCHER: Finished worker discovery
14:12:48 DISPATCHER: Starting worker discovery
14:12:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:12:48 DISPATCHER: Finished worker discovery
14:13:48 DISPATCHER: Starting worker discovery
14:13:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:13:48 DISPATCHER: Finished worker discovery
14:14:48 DISPATCHER: Starting worker discovery
14:14:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:14:48 DISPATCHER: Finished worker discovery
14:15:48 DISPATCHER: Starting worker discovery
14:15:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:15:48 DISPATCHER: Finished worker discovery
14:16:48 DISPATCHER: Starting worker discovery
14:16:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:16:48 DISPATCHER: Finished worker discovery
14:17:48 DISPATCHER: Starting worker discovery
14:17:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:17:48 DISPATCHER: Finished worker discovery
14:18:48 DISPATCHER: Starting worker discovery
14:18:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:18:48 DISPATCHER: Finished worker discovery
14:19:48 DISPATCHER: Starting worker discovery
14:19:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:19:48 DISPATCHER: Finished worker discovery
14:20:48 DISPATCHER: Starting worker discovery
14:20:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:20:48 DISPATCHER: Finished worker discovery
14:21:48 DISPATCHER: Starting worker discovery
14:21:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:21:48 DISPATCHER: Finished worker discovery
14:22:48 DISPATCHER: Starting worker discovery
14:22:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:22:48 DISPATCHER: Finished worker discovery
14:23:48 DISPATCHER: Starting worker discovery
14:23:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:23:48 DISPATCHER: Finished worker discovery
14:24:48 DISPATCHER: Starting worker discovery
14:24:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:24:48 DISPATCHER: Finished worker discovery
14:25:48 DISPATCHER: Starting worker discovery
14:25:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:25:48 DISPATCHER: Finished worker discovery
14:26:48 DISPATCHER: Starting worker discovery
14:26:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:26:48 DISPATCHER: Finished worker discovery
14:27:48 DISPATCHER: Starting worker discovery
14:27:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:27:48 DISPATCHER: Finished worker discovery
14:28:06 WORKER: done with job (1, 0, 5), trying to register it.
14:28:06 WORKER: registered result for job (1, 0, 5) with dispatcher
14:28:06 DISPATCHER: job (1, 0, 5) finished
14:28:06 DISPATCHER: register_result: lock acquired
14:28:06 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
14:28:06 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.00723129090619713, 'num_filters_1': 65, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.011402924976429207, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 19, 'num_filters_3': 19, 'num_filters_4': 20}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5689783759838296, 'info': {'data05': 0.5689783759838296, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.00723129090619713, 'num_filters_1': 65, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.011402924976429207, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 19, 'num_filters_3': 19, 'num_filters_4': 20}"}}
exception: None

14:28:06 job_callback for (1, 0, 5) started
14:28:06 job_callback for (1, 0, 5) got condition
14:28:06 DISPATCHER: Trying to submit another job.
14:28:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:28:06 Only 2 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
14:28:06 HBMASTER: Trying to run another job!
14:28:06 job_callback for (1, 0, 5) finished
14:28:06 start sampling a new configuration.
14:28:06 done sampling a new configuration.
14:28:06 HBMASTER: schedule new run for iteration 2
14:28:06 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
14:28:06 HBMASTER: submitting job (2, 0, 0) to dispatcher
14:28:06 DISPATCHER: trying to submit job (2, 0, 0)
14:28:06 DISPATCHER: trying to notify the job_runner thread.
14:28:06 HBMASTER: job (2, 0, 0) submitted to dispatcher
14:28:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:28:06 DISPATCHER: Trying to submit another job.
14:28:06 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:28:06 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:28:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:28:06 WORKER: start processing job (2, 0, 0)
14:28:06 WORKER: args: ()
14:28:06 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.036780491176171784, 'num_filters_1': 51, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.028520055054280336, 'kernel_size_2': 5, 'num_filters_2': 45}, 'budget': 400.0, 'working_directory': '.'}
14:28:48 DISPATCHER: Starting worker discovery
14:28:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:28:48 DISPATCHER: Finished worker discovery
14:29:48 DISPATCHER: Starting worker discovery
14:29:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:29:48 DISPATCHER: Finished worker discovery
14:30:48 DISPATCHER: Starting worker discovery
14:30:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:30:48 DISPATCHER: Finished worker discovery
14:31:48 DISPATCHER: Starting worker discovery
14:31:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:31:48 DISPATCHER: Finished worker discovery
14:32:48 DISPATCHER: Starting worker discovery
14:32:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:32:48 DISPATCHER: Finished worker discovery
14:33:48 DISPATCHER: Starting worker discovery
14:33:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:33:48 DISPATCHER: Finished worker discovery
14:34:48 DISPATCHER: Starting worker discovery
14:34:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:34:48 DISPATCHER: Finished worker discovery
14:35:36 WORKER: done with job (2, 0, 0), trying to register it.
14:35:36 WORKER: registered result for job (2, 0, 0) with dispatcher
14:35:36 DISPATCHER: job (2, 0, 0) finished
14:35:36 DISPATCHER: register_result: lock acquired
14:35:36 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
14:35:36 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.036780491176171784, 'num_filters_1': 51, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.028520055054280336, 'kernel_size_2': 5, 'num_filters_2': 45}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -7.09324112532123e-05, 'info': {'data05': 7.09324112532123e-05, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.036780491176171784, 'num_filters_1': 51, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.028520055054280336, 'kernel_size_2': 5, 'num_filters_2': 45}"}}
exception: None

14:35:36 job_callback for (2, 0, 0) started
14:35:36 job_callback for (2, 0, 0) got condition
14:35:36 DISPATCHER: Trying to submit another job.
14:35:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:35:36 Only 7 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
14:35:36 HBMASTER: Trying to run another job!
14:35:36 job_callback for (2, 0, 0) finished
14:35:36 start sampling a new configuration.
14:35:36 done sampling a new configuration.
14:35:36 HBMASTER: schedule new run for iteration 2
14:35:36 HBMASTER: trying submitting job (2, 0, 1) to dispatcher
14:35:36 HBMASTER: submitting job (2, 0, 1) to dispatcher
14:35:36 DISPATCHER: trying to submit job (2, 0, 1)
14:35:36 DISPATCHER: trying to notify the job_runner thread.
14:35:36 HBMASTER: job (2, 0, 1) submitted to dispatcher
14:35:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:35:36 DISPATCHER: Trying to submit another job.
14:35:36 DISPATCHER: starting job (2, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:35:36 DISPATCHER: job (2, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:35:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:35:36 WORKER: start processing job (2, 0, 1)
14:35:36 WORKER: args: ()
14:35:36 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0033476499646333266, 'num_filters_1': 73, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.01746954814408646, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 37, 'num_filters_3': 99, 'num_filters_4': 96, 'num_filters_5': 38}, 'budget': 400.0, 'working_directory': '.'}
14:35:48 DISPATCHER: Starting worker discovery
14:35:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:35:48 DISPATCHER: Finished worker discovery
14:36:48 DISPATCHER: Starting worker discovery
14:36:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:36:48 DISPATCHER: Finished worker discovery
14:37:48 DISPATCHER: Starting worker discovery
14:37:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:37:48 DISPATCHER: Finished worker discovery
14:38:48 DISPATCHER: Starting worker discovery
14:38:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:38:48 DISPATCHER: Finished worker discovery
14:39:48 DISPATCHER: Starting worker discovery
14:39:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:39:48 DISPATCHER: Finished worker discovery
14:40:48 DISPATCHER: Starting worker discovery
14:40:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:40:48 DISPATCHER: Finished worker discovery
14:41:48 DISPATCHER: Starting worker discovery
14:41:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:41:48 DISPATCHER: Finished worker discovery
14:42:48 DISPATCHER: Starting worker discovery
14:42:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:42:48 DISPATCHER: Finished worker discovery
14:42:54 WORKER: done with job (2, 0, 1), trying to register it.
14:42:54 WORKER: registered result for job (2, 0, 1) with dispatcher
14:42:54 DISPATCHER: job (2, 0, 1) finished
14:42:54 DISPATCHER: register_result: lock acquired
14:42:54 DISPATCHER: job (2, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
14:42:54 job_id: (2, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0033476499646333266, 'num_filters_1': 73, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.01746954814408646, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 37, 'num_filters_3': 99, 'num_filters_4': 96, 'num_filters_5': 38}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5158847717062023, 'info': {'data05': 0.5158847717062023, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0033476499646333266, 'num_filters_1': 73, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.01746954814408646, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 37, 'num_filters_3': 99, 'num_filters_4': 96, 'num_filters_5': 38}"}}
exception: None

14:42:54 job_callback for (2, 0, 1) started
14:42:54 DISPATCHER: Trying to submit another job.
14:42:54 job_callback for (2, 0, 1) got condition
14:42:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:42:54 Only 8 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
14:42:54 HBMASTER: Trying to run another job!
14:42:54 job_callback for (2, 0, 1) finished
14:42:54 start sampling a new configuration.
14:42:54 done sampling a new configuration.
14:42:54 HBMASTER: schedule new run for iteration 2
14:42:54 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
14:42:54 HBMASTER: submitting job (2, 0, 2) to dispatcher
14:42:54 DISPATCHER: trying to submit job (2, 0, 2)
14:42:54 DISPATCHER: trying to notify the job_runner thread.
14:42:54 HBMASTER: job (2, 0, 2) submitted to dispatcher
14:42:54 DISPATCHER: Trying to submit another job.
14:42:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:42:54 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:42:54 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:42:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:42:54 WORKER: start processing job (2, 0, 2)
14:42:54 WORKER: args: ()
14:42:54 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.021300338512353398, 'num_filters_1': 77, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.035725406763661004, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 20, 'num_filters_3': 101, 'num_filters_4': 18, 'num_filters_5': 54}, 'budget': 400.0, 'working_directory': '.'}
14:43:48 DISPATCHER: Starting worker discovery
14:43:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:43:48 DISPATCHER: Finished worker discovery
14:44:48 DISPATCHER: Starting worker discovery
14:44:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:44:48 DISPATCHER: Finished worker discovery
14:45:48 DISPATCHER: Starting worker discovery
14:45:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:45:48 DISPATCHER: Finished worker discovery
14:46:48 DISPATCHER: Starting worker discovery
14:46:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:46:48 DISPATCHER: Finished worker discovery
14:47:48 DISPATCHER: Starting worker discovery
14:47:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:47:48 DISPATCHER: Finished worker discovery
14:48:48 DISPATCHER: Starting worker discovery
14:48:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:48:48 DISPATCHER: Finished worker discovery
14:49:48 DISPATCHER: Starting worker discovery
14:49:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:49:48 DISPATCHER: Finished worker discovery
14:50:09 WORKER: done with job (2, 0, 2), trying to register it.
14:50:09 WORKER: registered result for job (2, 0, 2) with dispatcher
14:50:09 DISPATCHER: job (2, 0, 2) finished
14:50:09 DISPATCHER: register_result: lock acquired
14:50:09 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
14:50:09 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.021300338512353398, 'num_filters_1': 77, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.035725406763661004, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 20, 'num_filters_3': 101, 'num_filters_4': 18, 'num_filters_5': 54}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6350618683870187, 'info': {'data05': 0.6350618683870187, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.021300338512353398, 'num_filters_1': 77, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.035725406763661004, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 20, 'num_filters_3': 101, 'num_filters_4': 18, 'num_filters_5': 54}"}}
exception: None

14:50:09 job_callback for (2, 0, 2) started
14:50:09 DISPATCHER: Trying to submit another job.
14:50:09 job_callback for (2, 0, 2) got condition
14:50:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:50:09 Only 9 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
14:50:09 HBMASTER: Trying to run another job!
14:50:09 job_callback for (2, 0, 2) finished
14:50:09 start sampling a new configuration.
14:50:09 done sampling a new configuration.
14:50:09 HBMASTER: schedule new run for iteration 2
14:50:09 HBMASTER: trying submitting job (2, 0, 3) to dispatcher
14:50:09 HBMASTER: submitting job (2, 0, 3) to dispatcher
14:50:09 DISPATCHER: trying to submit job (2, 0, 3)
14:50:09 DISPATCHER: trying to notify the job_runner thread.
14:50:09 HBMASTER: job (2, 0, 3) submitted to dispatcher
14:50:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:50:09 DISPATCHER: Trying to submit another job.
14:50:09 DISPATCHER: starting job (2, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:50:09 DISPATCHER: job (2, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:50:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:50:09 WORKER: start processing job (2, 0, 3)
14:50:09 WORKER: args: ()
14:50:09 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.003519351997854279, 'num_filters_1': 79, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.0575533217035384, 'kernel_size_2': 7, 'num_filters_2': 97}, 'budget': 400.0, 'working_directory': '.'}
14:50:48 DISPATCHER: Starting worker discovery
14:50:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:50:48 DISPATCHER: Finished worker discovery
14:51:48 DISPATCHER: Starting worker discovery
14:51:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:51:48 DISPATCHER: Finished worker discovery
14:52:48 DISPATCHER: Starting worker discovery
14:52:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:52:48 DISPATCHER: Finished worker discovery
14:53:48 DISPATCHER: Starting worker discovery
14:53:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:53:48 DISPATCHER: Finished worker discovery
14:54:48 DISPATCHER: Starting worker discovery
14:54:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:54:48 DISPATCHER: Finished worker discovery
14:55:48 DISPATCHER: Starting worker discovery
14:55:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:55:48 DISPATCHER: Finished worker discovery
14:56:48 DISPATCHER: Starting worker discovery
14:56:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:56:48 DISPATCHER: Finished worker discovery
14:57:08 WORKER: done with job (2, 0, 3), trying to register it.
14:57:08 WORKER: registered result for job (2, 0, 3) with dispatcher
14:57:08 DISPATCHER: job (2, 0, 3) finished
14:57:08 DISPATCHER: register_result: lock acquired
14:57:08 DISPATCHER: job (2, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
14:57:08 job_id: (2, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.003519351997854279, 'num_filters_1': 79, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.0575533217035384, 'kernel_size_2': 7, 'num_filters_2': 97}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.19114887532744784, 'info': {'data05': 0.19114887532744784, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.003519351997854279, 'num_filters_1': 79, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.0575533217035384, 'kernel_size_2': 7, 'num_filters_2': 97}"}}
exception: None

14:57:08 job_callback for (2, 0, 3) started
14:57:08 DISPATCHER: Trying to submit another job.
14:57:08 job_callback for (2, 0, 3) got condition
14:57:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:57:08 Only 10 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
14:57:08 HBMASTER: Trying to run another job!
14:57:08 job_callback for (2, 0, 3) finished
14:57:08 start sampling a new configuration.
14:57:08 done sampling a new configuration.
14:57:08 HBMASTER: schedule new run for iteration 2
14:57:08 HBMASTER: trying submitting job (2, 0, 4) to dispatcher
14:57:08 HBMASTER: submitting job (2, 0, 4) to dispatcher
14:57:08 DISPATCHER: trying to submit job (2, 0, 4)
14:57:08 DISPATCHER: trying to notify the job_runner thread.
14:57:08 HBMASTER: job (2, 0, 4) submitted to dispatcher
14:57:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:57:08 DISPATCHER: Trying to submit another job.
14:57:08 DISPATCHER: starting job (2, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:57:08 DISPATCHER: job (2, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:57:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:57:08 WORKER: start processing job (2, 0, 4)
14:57:08 WORKER: args: ()
14:57:08 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.012024084237638425, 'num_filters_1': 56, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.04783417442876069, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 73, 'num_filters_3': 48, 'num_filters_4': 30, 'num_filters_5': 64}, 'budget': 400.0, 'working_directory': '.'}
14:57:48 DISPATCHER: Starting worker discovery
14:57:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:57:48 DISPATCHER: Finished worker discovery
14:58:48 DISPATCHER: Starting worker discovery
14:58:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:58:48 DISPATCHER: Finished worker discovery
14:59:48 DISPATCHER: Starting worker discovery
14:59:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:59:48 DISPATCHER: Finished worker discovery
15:00:48 DISPATCHER: Starting worker discovery
15:00:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:00:48 DISPATCHER: Finished worker discovery
15:01:48 DISPATCHER: Starting worker discovery
15:01:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:01:48 DISPATCHER: Finished worker discovery
15:02:48 DISPATCHER: Starting worker discovery
15:02:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:02:48 DISPATCHER: Finished worker discovery
15:03:48 DISPATCHER: Starting worker discovery
15:03:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:03:48 DISPATCHER: Finished worker discovery
15:04:09 WORKER: done with job (2, 0, 4), trying to register it.
15:04:09 WORKER: registered result for job (2, 0, 4) with dispatcher
15:04:09 DISPATCHER: job (2, 0, 4) finished
15:04:09 DISPATCHER: register_result: lock acquired
15:04:09 DISPATCHER: job (2, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
15:04:09 job_id: (2, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.012024084237638425, 'num_filters_1': 56, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.04783417442876069, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 73, 'num_filters_3': 48, 'num_filters_4': 30, 'num_filters_5': 64}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7280246441585699, 'info': {'data05': 0.7280246441585699, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.012024084237638425, 'num_filters_1': 56, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.04783417442876069, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 73, 'num_filters_3': 48, 'num_filters_4': 30, 'num_filters_5': 64}"}}
exception: None

15:04:09 job_callback for (2, 0, 4) started
15:04:09 job_callback for (2, 0, 4) got condition
15:04:09 DISPATCHER: Trying to submit another job.
15:04:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:04:09 Only 11 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
15:04:09 HBMASTER: Trying to run another job!
15:04:09 job_callback for (2, 0, 4) finished
15:04:09 start sampling a new configuration.
15:04:09 done sampling a new configuration.
15:04:09 HBMASTER: schedule new run for iteration 2
15:04:09 HBMASTER: trying submitting job (2, 0, 5) to dispatcher
15:04:09 HBMASTER: submitting job (2, 0, 5) to dispatcher
15:04:09 DISPATCHER: trying to submit job (2, 0, 5)
15:04:09 DISPATCHER: trying to notify the job_runner thread.
15:04:09 HBMASTER: job (2, 0, 5) submitted to dispatcher
15:04:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:04:09 DISPATCHER: Trying to submit another job.
15:04:09 DISPATCHER: starting job (2, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
15:04:09 DISPATCHER: job (2, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
15:04:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:04:09 WORKER: start processing job (2, 0, 5)
15:04:09 WORKER: args: ()
15:04:09 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0056375445385617815, 'num_filters_1': 62, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.11683370374662845}, 'budget': 400.0, 'working_directory': '.'}
15:04:48 DISPATCHER: Starting worker discovery
15:04:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:04:48 DISPATCHER: Finished worker discovery
15:05:48 DISPATCHER: Starting worker discovery
15:05:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:05:48 DISPATCHER: Finished worker discovery
15:06:48 DISPATCHER: Starting worker discovery
15:06:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:06:48 DISPATCHER: Finished worker discovery
15:07:48 DISPATCHER: Starting worker discovery
15:07:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:07:48 DISPATCHER: Finished worker discovery
15:08:48 DISPATCHER: Starting worker discovery
15:08:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:08:48 DISPATCHER: Finished worker discovery
15:09:48 DISPATCHER: Starting worker discovery
15:09:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:09:48 DISPATCHER: Finished worker discovery
15:10:48 DISPATCHER: Starting worker discovery
15:10:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:10:48 DISPATCHER: Finished worker discovery
15:11:34 WORKER: done with job (2, 0, 5), trying to register it.
15:11:34 WORKER: registered result for job (2, 0, 5) with dispatcher
15:11:34 DISPATCHER: job (2, 0, 5) finished
15:11:34 DISPATCHER: register_result: lock acquired
15:11:34 DISPATCHER: job (2, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
15:11:34 job_id: (2, 0, 5)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0056375445385617815, 'num_filters_1': 62, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.11683370374662845}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.18574748165425187, 'info': {'data05': 0.18574748165425187, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0056375445385617815, 'num_filters_1': 62, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.11683370374662845}"}}
exception: None

15:11:34 job_callback for (2, 0, 5) started
15:11:34 job_callback for (2, 0, 5) got condition
15:11:34 DISPATCHER: Trying to submit another job.
15:11:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:11:34 Only 12 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
15:11:34 HBMASTER: Trying to run another job!
15:11:34 job_callback for (2, 0, 5) finished
15:11:34 ITERATION: Advancing config (2, 0, 2) to next budget 1200.000000
15:11:34 ITERATION: Advancing config (2, 0, 4) to next budget 1200.000000
15:11:34 HBMASTER: schedule new run for iteration 2
15:11:34 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
15:11:34 HBMASTER: submitting job (2, 0, 2) to dispatcher
15:11:34 DISPATCHER: trying to submit job (2, 0, 2)
15:11:34 DISPATCHER: trying to notify the job_runner thread.
15:11:34 HBMASTER: job (2, 0, 2) submitted to dispatcher
15:11:34 DISPATCHER: Trying to submit another job.
15:11:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:11:34 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
15:11:34 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
15:11:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:11:34 WORKER: start processing job (2, 0, 2)
15:11:34 WORKER: args: ()
15:11:34 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.021300338512353398, 'num_filters_1': 77, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.035725406763661004, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 20, 'num_filters_3': 101, 'num_filters_4': 18, 'num_filters_5': 54}, 'budget': 1200.0, 'working_directory': '.'}
15:11:48 DISPATCHER: Starting worker discovery
15:11:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:11:48 DISPATCHER: Finished worker discovery
15:12:48 DISPATCHER: Starting worker discovery
15:12:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:12:48 DISPATCHER: Finished worker discovery
15:13:48 DISPATCHER: Starting worker discovery
15:13:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:13:48 DISPATCHER: Finished worker discovery
15:14:48 DISPATCHER: Starting worker discovery
15:14:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:14:48 DISPATCHER: Finished worker discovery
15:15:48 DISPATCHER: Starting worker discovery
15:15:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:15:48 DISPATCHER: Finished worker discovery
15:16:48 DISPATCHER: Starting worker discovery
15:16:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:16:48 DISPATCHER: Finished worker discovery
15:17:48 DISPATCHER: Starting worker discovery
15:17:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:17:48 DISPATCHER: Finished worker discovery
15:18:48 DISPATCHER: Starting worker discovery
15:18:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:18:48 DISPATCHER: Finished worker discovery
15:19:48 DISPATCHER: Starting worker discovery
15:19:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:19:48 DISPATCHER: Finished worker discovery
15:20:48 DISPATCHER: Starting worker discovery
15:20:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:20:48 DISPATCHER: Finished worker discovery
15:21:48 DISPATCHER: Starting worker discovery
15:21:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:21:48 DISPATCHER: Finished worker discovery
15:22:48 DISPATCHER: Starting worker discovery
15:22:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:22:48 DISPATCHER: Finished worker discovery
15:23:48 DISPATCHER: Starting worker discovery
15:23:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:23:48 DISPATCHER: Finished worker discovery
15:24:48 DISPATCHER: Starting worker discovery
15:24:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:24:48 DISPATCHER: Finished worker discovery
15:25:48 DISPATCHER: Starting worker discovery
15:25:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:25:48 DISPATCHER: Finished worker discovery
15:26:48 DISPATCHER: Starting worker discovery
15:26:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:26:48 DISPATCHER: Finished worker discovery
15:27:48 DISPATCHER: Starting worker discovery
15:27:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:27:48 DISPATCHER: Finished worker discovery
15:28:48 DISPATCHER: Starting worker discovery
15:28:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:28:49 DISPATCHER: Finished worker discovery
15:29:49 DISPATCHER: Starting worker discovery
15:29:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:29:49 DISPATCHER: Finished worker discovery
15:30:49 DISPATCHER: Starting worker discovery
15:30:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:30:49 DISPATCHER: Finished worker discovery
15:31:49 DISPATCHER: Starting worker discovery
15:31:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:31:49 DISPATCHER: Finished worker discovery
15:32:49 DISPATCHER: Starting worker discovery
15:32:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:32:49 DISPATCHER: Finished worker discovery
15:32:59 WORKER: done with job (2, 0, 2), trying to register it.
15:32:59 WORKER: registered result for job (2, 0, 2) with dispatcher
15:32:59 DISPATCHER: job (2, 0, 2) finished
15:32:59 DISPATCHER: register_result: lock acquired
15:32:59 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
15:32:59 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.021300338512353398, 'num_filters_1': 77, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.035725406763661004, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 20, 'num_filters_3': 101, 'num_filters_4': 18, 'num_filters_5': 54}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.6287622014164971, 'info': {'data05': 0.6287622014164971, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.021300338512353398, 'num_filters_1': 77, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.035725406763661004, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 20, 'num_filters_3': 101, 'num_filters_4': 18, 'num_filters_5': 54}"}}
exception: None

15:32:59 job_callback for (2, 0, 2) started
15:32:59 DISPATCHER: Trying to submit another job.
15:32:59 job_callback for (2, 0, 2) got condition
15:32:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:32:59 Only 3 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
15:32:59 HBMASTER: Trying to run another job!
15:32:59 job_callback for (2, 0, 2) finished
15:32:59 HBMASTER: schedule new run for iteration 2
15:32:59 HBMASTER: trying submitting job (2, 0, 4) to dispatcher
15:32:59 HBMASTER: submitting job (2, 0, 4) to dispatcher
15:32:59 DISPATCHER: trying to submit job (2, 0, 4)
15:32:59 DISPATCHER: trying to notify the job_runner thread.
15:32:59 HBMASTER: job (2, 0, 4) submitted to dispatcher
15:32:59 DISPATCHER: Trying to submit another job.
15:32:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:32:59 DISPATCHER: starting job (2, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464
15:32:59 DISPATCHER: job (2, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
15:32:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:32:59 WORKER: start processing job (2, 0, 4)
15:32:59 WORKER: args: ()
15:32:59 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.012024084237638425, 'num_filters_1': 56, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.04783417442876069, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 73, 'num_filters_3': 48, 'num_filters_4': 30, 'num_filters_5': 64}, 'budget': 1200.0, 'working_directory': '.'}
15:33:49 DISPATCHER: Starting worker discovery
15:33:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:33:49 DISPATCHER: Finished worker discovery
15:34:49 DISPATCHER: Starting worker discovery
15:34:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:34:49 DISPATCHER: Finished worker discovery
15:35:49 DISPATCHER: Starting worker discovery
15:35:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:35:49 DISPATCHER: Finished worker discovery
15:36:49 DISPATCHER: Starting worker discovery
15:36:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:36:49 DISPATCHER: Finished worker discovery
15:37:49 DISPATCHER: Starting worker discovery
15:37:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:37:49 DISPATCHER: Finished worker discovery
15:38:49 DISPATCHER: Starting worker discovery
15:38:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:38:49 DISPATCHER: Finished worker discovery
15:39:49 DISPATCHER: Starting worker discovery
15:39:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:39:49 DISPATCHER: Finished worker discovery
15:40:49 DISPATCHER: Starting worker discovery
15:40:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:40:49 DISPATCHER: Finished worker discovery
15:41:49 DISPATCHER: Starting worker discovery
15:41:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:41:49 DISPATCHER: Finished worker discovery
15:42:49 DISPATCHER: Starting worker discovery
15:42:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:42:49 DISPATCHER: Finished worker discovery
15:43:49 DISPATCHER: Starting worker discovery
15:43:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:43:49 DISPATCHER: Finished worker discovery
15:44:49 DISPATCHER: Starting worker discovery
15:44:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:44:49 DISPATCHER: Finished worker discovery
15:45:49 DISPATCHER: Starting worker discovery
15:45:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:45:49 DISPATCHER: Finished worker discovery
15:46:49 DISPATCHER: Starting worker discovery
15:46:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:46:49 DISPATCHER: Finished worker discovery
15:47:49 DISPATCHER: Starting worker discovery
15:47:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:47:49 DISPATCHER: Finished worker discovery
15:48:49 DISPATCHER: Starting worker discovery
15:48:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:48:49 DISPATCHER: Finished worker discovery
15:49:49 DISPATCHER: Starting worker discovery
15:49:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:49:49 DISPATCHER: Finished worker discovery
15:50:49 DISPATCHER: Starting worker discovery
15:50:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:50:49 DISPATCHER: Finished worker discovery
15:51:49 DISPATCHER: Starting worker discovery
15:51:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:51:49 DISPATCHER: Finished worker discovery
15:52:49 DISPATCHER: Starting worker discovery
15:52:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:52:49 DISPATCHER: Finished worker discovery
15:53:36 WORKER: done with job (2, 0, 4), trying to register it.
15:53:36 WORKER: registered result for job (2, 0, 4) with dispatcher
15:53:36 DISPATCHER: job (2, 0, 4) finished
15:53:36 DISPATCHER: register_result: lock acquired
15:53:36 DISPATCHER: job (2, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
15:53:36 job_id: (2, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.012024084237638425, 'num_filters_1': 56, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.04783417442876069, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 73, 'num_filters_3': 48, 'num_filters_4': 30, 'num_filters_5': 64}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.8285372355247598, 'info': {'data05': 0.8285372355247598, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.012024084237638425, 'num_filters_1': 56, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.04783417442876069, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 73, 'num_filters_3': 48, 'num_filters_4': 30, 'num_filters_5': 64}"}}
exception: None

15:53:36 job_callback for (2, 0, 4) started
15:53:36 job_callback for (2, 0, 4) got condition
15:53:36 DISPATCHER: Trying to submit another job.
15:53:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:53:36 Only 4 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
15:53:36 HBMASTER: Trying to run another job!
15:53:36 job_callback for (2, 0, 4) finished
15:53:36 start sampling a new configuration.
15:53:36 done sampling a new configuration.
15:53:36 HBMASTER: schedule new run for iteration 3
15:53:36 HBMASTER: trying submitting job (3, 0, 0) to dispatcher
15:53:36 HBMASTER: submitting job (3, 0, 0) to dispatcher
15:53:36 DISPATCHER: trying to submit job (3, 0, 0)
15:53:36 DISPATCHER: trying to notify the job_runner thread.
15:53:36 HBMASTER: job (3, 0, 0) submitted to dispatcher
15:53:36 DISPATCHER: Trying to submit another job.
15:53:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:53:36 DISPATCHER: starting job (3, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
15:53:36 DISPATCHER: job (3, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
15:53:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:53:36 WORKER: start processing job (3, 0, 0)
15:53:36 WORKER: args: ()
15:53:36 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.03809173241533196, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.03280699391576059, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 17, 'num_filters_3': 120, 'num_filters_4': 38}, 'budget': 1200.0, 'working_directory': '.'}
15:53:49 DISPATCHER: Starting worker discovery
15:53:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:53:49 DISPATCHER: Finished worker discovery
15:54:49 DISPATCHER: Starting worker discovery
15:54:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:54:49 DISPATCHER: Finished worker discovery
15:55:49 DISPATCHER: Starting worker discovery
15:55:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:55:49 DISPATCHER: Finished worker discovery
15:56:49 DISPATCHER: Starting worker discovery
15:56:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:56:49 DISPATCHER: Finished worker discovery
15:57:49 DISPATCHER: Starting worker discovery
15:57:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:57:49 DISPATCHER: Finished worker discovery
15:58:49 DISPATCHER: Starting worker discovery
15:58:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:58:49 DISPATCHER: Finished worker discovery
15:59:49 DISPATCHER: Starting worker discovery
15:59:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:59:49 DISPATCHER: Finished worker discovery
16:00:49 DISPATCHER: Starting worker discovery
16:00:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:00:49 DISPATCHER: Finished worker discovery
16:01:49 DISPATCHER: Starting worker discovery
16:01:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:01:49 DISPATCHER: Finished worker discovery
16:02:49 DISPATCHER: Starting worker discovery
16:02:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:02:49 DISPATCHER: Finished worker discovery
16:03:49 DISPATCHER: Starting worker discovery
16:03:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:03:49 DISPATCHER: Finished worker discovery
16:04:49 DISPATCHER: Starting worker discovery
16:04:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:04:49 DISPATCHER: Finished worker discovery
16:05:49 DISPATCHER: Starting worker discovery
16:05:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:05:49 DISPATCHER: Finished worker discovery
16:06:49 DISPATCHER: Starting worker discovery
16:06:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:06:49 DISPATCHER: Finished worker discovery
16:07:49 DISPATCHER: Starting worker discovery
16:07:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:07:49 DISPATCHER: Finished worker discovery
16:08:49 DISPATCHER: Starting worker discovery
16:08:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:08:49 DISPATCHER: Finished worker discovery
16:09:49 DISPATCHER: Starting worker discovery
16:09:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:09:49 DISPATCHER: Finished worker discovery
16:10:49 DISPATCHER: Starting worker discovery
16:10:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:10:49 DISPATCHER: Finished worker discovery
16:11:49 DISPATCHER: Starting worker discovery
16:11:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:11:49 DISPATCHER: Finished worker discovery
16:12:49 DISPATCHER: Starting worker discovery
16:12:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:12:49 DISPATCHER: Finished worker discovery
16:13:49 DISPATCHER: Starting worker discovery
16:13:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:13:49 DISPATCHER: Finished worker discovery
16:14:27 WORKER: done with job (3, 0, 0), trying to register it.
16:14:27 WORKER: registered result for job (3, 0, 0) with dispatcher
16:14:27 DISPATCHER: job (3, 0, 0) finished
16:14:27 DISPATCHER: register_result: lock acquired
16:14:27 DISPATCHER: job (3, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
16:14:27 job_id: (3, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.03809173241533196, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.03280699391576059, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 17, 'num_filters_3': 120, 'num_filters_4': 38}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.03809173241533196, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.03280699391576059, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 17, 'num_filters_3': 120, 'num_filters_4': 38}"}}
exception: None

16:14:27 job_callback for (3, 0, 0) started
16:14:27 DISPATCHER: Trying to submit another job.
16:14:27 job_callback for (3, 0, 0) got condition
16:14:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:14:27 Only 5 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
16:14:27 HBMASTER: Trying to run another job!
16:14:27 job_callback for (3, 0, 0) finished
16:14:27 start sampling a new configuration.
16:14:27 done sampling a new configuration.
16:14:27 HBMASTER: schedule new run for iteration 3
16:14:27 HBMASTER: trying submitting job (3, 0, 1) to dispatcher
16:14:27 HBMASTER: submitting job (3, 0, 1) to dispatcher
16:14:27 DISPATCHER: trying to submit job (3, 0, 1)
16:14:27 DISPATCHER: trying to notify the job_runner thread.
16:14:27 HBMASTER: job (3, 0, 1) submitted to dispatcher
16:14:27 DISPATCHER: Trying to submit another job.
16:14:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:14:27 DISPATCHER: starting job (3, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
16:14:27 DISPATCHER: job (3, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
16:14:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:14:27 WORKER: start processing job (3, 0, 1)
16:14:27 WORKER: args: ()
16:14:27 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0030884230541361364, 'num_filters_1': 91, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.12018812776870919, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 97, 'num_filters_3': 35, 'num_filters_4': 26}, 'budget': 1200.0, 'working_directory': '.'}
16:14:49 DISPATCHER: Starting worker discovery
16:14:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:14:49 DISPATCHER: Finished worker discovery
16:15:49 DISPATCHER: Starting worker discovery
16:15:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:15:49 DISPATCHER: Finished worker discovery
16:16:49 DISPATCHER: Starting worker discovery
16:16:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:16:49 DISPATCHER: Finished worker discovery
16:17:49 DISPATCHER: Starting worker discovery
16:17:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:17:49 DISPATCHER: Finished worker discovery
16:18:49 DISPATCHER: Starting worker discovery
16:18:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:18:49 DISPATCHER: Finished worker discovery
16:19:49 DISPATCHER: Starting worker discovery
16:19:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:19:49 DISPATCHER: Finished worker discovery
16:20:49 DISPATCHER: Starting worker discovery
16:20:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:20:49 DISPATCHER: Finished worker discovery
16:21:49 DISPATCHER: Starting worker discovery
16:21:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:21:49 DISPATCHER: Finished worker discovery
16:22:49 DISPATCHER: Starting worker discovery
16:22:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:22:49 DISPATCHER: Finished worker discovery
16:23:49 DISPATCHER: Starting worker discovery
16:23:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:23:49 DISPATCHER: Finished worker discovery
16:24:49 DISPATCHER: Starting worker discovery
16:24:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:24:49 DISPATCHER: Finished worker discovery
16:25:49 DISPATCHER: Starting worker discovery
16:25:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:25:49 DISPATCHER: Finished worker discovery
16:26:49 DISPATCHER: Starting worker discovery
16:26:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:26:49 DISPATCHER: Finished worker discovery
16:27:49 DISPATCHER: Starting worker discovery
16:27:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:27:49 DISPATCHER: Finished worker discovery
16:28:49 DISPATCHER: Starting worker discovery
16:28:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:28:49 DISPATCHER: Finished worker discovery
16:29:49 DISPATCHER: Starting worker discovery
16:29:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:29:49 DISPATCHER: Finished worker discovery
16:30:49 DISPATCHER: Starting worker discovery
16:30:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:30:49 DISPATCHER: Finished worker discovery
16:31:49 DISPATCHER: Starting worker discovery
16:31:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:31:49 DISPATCHER: Finished worker discovery
16:32:49 DISPATCHER: Starting worker discovery
16:32:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:32:49 DISPATCHER: Finished worker discovery
16:33:49 DISPATCHER: Starting worker discovery
16:33:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:33:49 DISPATCHER: Finished worker discovery
16:34:49 DISPATCHER: Starting worker discovery
16:34:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:34:49 DISPATCHER: Finished worker discovery
16:35:22 WORKER: done with job (3, 0, 1), trying to register it.
16:35:22 WORKER: registered result for job (3, 0, 1) with dispatcher
16:35:22 DISPATCHER: job (3, 0, 1) finished
16:35:22 DISPATCHER: register_result: lock acquired
16:35:22 DISPATCHER: job (3, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
16:35:22 job_id: (3, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0030884230541361364, 'num_filters_1': 91, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.12018812776870919, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 97, 'num_filters_3': 35, 'num_filters_4': 26}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.06851665785274712, 'info': {'data05': 0.06851665785274712, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0030884230541361364, 'num_filters_1': 91, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.12018812776870919, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 97, 'num_filters_3': 35, 'num_filters_4': 26}"}}
exception: None

16:35:22 job_callback for (3, 0, 1) started
16:35:22 job_callback for (3, 0, 1) got condition
16:35:22 DISPATCHER: Trying to submit another job.
16:35:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:35:22 Only 6 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
16:35:22 HBMASTER: Trying to run another job!
16:35:22 job_callback for (3, 0, 1) finished
16:35:22 start sampling a new configuration.
16:35:22 done sampling a new configuration.
16:35:22 HBMASTER: schedule new run for iteration 3
16:35:22 HBMASTER: trying submitting job (3, 0, 2) to dispatcher
16:35:22 HBMASTER: submitting job (3, 0, 2) to dispatcher
16:35:22 DISPATCHER: trying to submit job (3, 0, 2)
16:35:22 DISPATCHER: trying to notify the job_runner thread.
16:35:22 HBMASTER: job (3, 0, 2) submitted to dispatcher
16:35:22 DISPATCHER: Trying to submit another job.
16:35:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:35:22 DISPATCHER: starting job (3, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
16:35:22 DISPATCHER: job (3, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
16:35:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:35:22 WORKER: start processing job (3, 0, 2)
16:35:22 WORKER: args: ()
16:35:22 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0010877891540465937, 'num_filters_1': 19, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.03697387444587768, 'kernel_size_2': 5, 'num_filters_2': 31}, 'budget': 1200.0, 'working_directory': '.'}
16:35:49 DISPATCHER: Starting worker discovery
16:35:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:35:49 DISPATCHER: Finished worker discovery
16:36:49 DISPATCHER: Starting worker discovery
16:36:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:36:49 DISPATCHER: Finished worker discovery
16:37:49 DISPATCHER: Starting worker discovery
16:37:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:37:49 DISPATCHER: Finished worker discovery
16:38:49 DISPATCHER: Starting worker discovery
16:38:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:38:49 DISPATCHER: Finished worker discovery
16:39:49 DISPATCHER: Starting worker discovery
16:39:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:39:49 DISPATCHER: Finished worker discovery
16:40:49 DISPATCHER: Starting worker discovery
16:40:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:40:49 DISPATCHER: Finished worker discovery
16:41:49 DISPATCHER: Starting worker discovery
16:41:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:41:49 DISPATCHER: Finished worker discovery
16:42:49 DISPATCHER: Starting worker discovery
16:42:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:42:49 DISPATCHER: Finished worker discovery
16:43:49 DISPATCHER: Starting worker discovery
16:43:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:43:49 DISPATCHER: Finished worker discovery
16:44:49 DISPATCHER: Starting worker discovery
16:44:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:44:49 DISPATCHER: Finished worker discovery
16:45:49 DISPATCHER: Starting worker discovery
16:45:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:45:49 DISPATCHER: Finished worker discovery
16:46:49 DISPATCHER: Starting worker discovery
16:46:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:46:49 DISPATCHER: Finished worker discovery
16:47:49 DISPATCHER: Starting worker discovery
16:47:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:47:49 DISPATCHER: Finished worker discovery
16:48:49 DISPATCHER: Starting worker discovery
16:48:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:48:49 DISPATCHER: Finished worker discovery
16:49:49 DISPATCHER: Starting worker discovery
16:49:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:49:49 DISPATCHER: Finished worker discovery
16:50:49 DISPATCHER: Starting worker discovery
16:50:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:50:49 DISPATCHER: Finished worker discovery
16:51:49 DISPATCHER: Starting worker discovery
16:51:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:51:49 DISPATCHER: Finished worker discovery
16:52:49 DISPATCHER: Starting worker discovery
16:52:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:52:49 DISPATCHER: Finished worker discovery
16:53:49 DISPATCHER: Starting worker discovery
16:53:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:53:49 DISPATCHER: Finished worker discovery
16:54:49 DISPATCHER: Starting worker discovery
16:54:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:54:49 DISPATCHER: Finished worker discovery
16:55:49 DISPATCHER: Starting worker discovery
16:55:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:55:49 DISPATCHER: Finished worker discovery
16:56:13 WORKER: done with job (3, 0, 2), trying to register it.
16:56:13 WORKER: registered result for job (3, 0, 2) with dispatcher
16:56:13 DISPATCHER: job (3, 0, 2) finished
16:56:13 DISPATCHER: register_result: lock acquired
16:56:13 DISPATCHER: job (3, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
16:56:13 job_id: (3, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0010877891540465937, 'num_filters_1': 19, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.03697387444587768, 'kernel_size_2': 5, 'num_filters_2': 31}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.17359997443789338, 'info': {'data05': 0.17359997443789338, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0010877891540465937, 'num_filters_1': 19, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.03697387444587768, 'kernel_size_2': 5, 'num_filters_2': 31}"}}
exception: None

16:56:13 job_callback for (3, 0, 2) started
16:56:13 job_callback for (3, 0, 2) got condition
16:56:13 DISPATCHER: Trying to submit another job.
16:56:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:56:13 Only 7 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
16:56:13 HBMASTER: Trying to run another job!
16:56:13 job_callback for (3, 0, 2) finished
16:56:13 start sampling a new configuration.
16:56:13 done sampling a new configuration.
16:56:13 HBMASTER: schedule new run for iteration 3
16:56:13 HBMASTER: trying submitting job (3, 0, 3) to dispatcher
16:56:13 HBMASTER: submitting job (3, 0, 3) to dispatcher
16:56:13 DISPATCHER: trying to submit job (3, 0, 3)
16:56:13 DISPATCHER: trying to notify the job_runner thread.
16:56:13 HBMASTER: job (3, 0, 3) submitted to dispatcher
16:56:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:56:13 DISPATCHER: Trying to submit another job.
16:56:13 DISPATCHER: starting job (3, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
16:56:13 DISPATCHER: job (3, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
16:56:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:56:13 WORKER: start processing job (3, 0, 3)
16:56:13 WORKER: args: ()
16:56:13 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.004147505744079038, 'num_filters_1': 33, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.024755692765488713, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 30, 'num_filters_3': 69, 'num_filters_4': 77}, 'budget': 1200.0, 'working_directory': '.'}
16:56:49 DISPATCHER: Starting worker discovery
16:56:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:56:49 DISPATCHER: Finished worker discovery
16:57:49 DISPATCHER: Starting worker discovery
16:57:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:57:49 DISPATCHER: Finished worker discovery
16:58:49 DISPATCHER: Starting worker discovery
16:58:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:58:49 DISPATCHER: Finished worker discovery
16:59:49 DISPATCHER: Starting worker discovery
16:59:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:59:50 DISPATCHER: Finished worker discovery
17:00:50 DISPATCHER: Starting worker discovery
17:00:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:00:50 DISPATCHER: Finished worker discovery
17:01:50 DISPATCHER: Starting worker discovery
17:01:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:01:50 DISPATCHER: Finished worker discovery
17:02:50 DISPATCHER: Starting worker discovery
17:02:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:02:50 DISPATCHER: Finished worker discovery
17:03:50 DISPATCHER: Starting worker discovery
17:03:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:03:50 DISPATCHER: Finished worker discovery
17:04:50 DISPATCHER: Starting worker discovery
17:04:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:04:50 DISPATCHER: Finished worker discovery
17:05:50 DISPATCHER: Starting worker discovery
17:05:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:05:50 DISPATCHER: Finished worker discovery
17:06:50 DISPATCHER: Starting worker discovery
17:06:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:06:50 DISPATCHER: Finished worker discovery
17:07:50 DISPATCHER: Starting worker discovery
17:07:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:07:50 DISPATCHER: Finished worker discovery
17:08:50 DISPATCHER: Starting worker discovery
17:08:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:08:50 DISPATCHER: Finished worker discovery
17:09:50 DISPATCHER: Starting worker discovery
17:09:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:09:50 DISPATCHER: Finished worker discovery
17:10:50 DISPATCHER: Starting worker discovery
17:10:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:10:50 DISPATCHER: Finished worker discovery
17:11:50 DISPATCHER: Starting worker discovery
17:11:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:11:50 DISPATCHER: Finished worker discovery
17:12:50 DISPATCHER: Starting worker discovery
17:12:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:12:50 DISPATCHER: Finished worker discovery
17:13:50 DISPATCHER: Starting worker discovery
17:13:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:13:50 DISPATCHER: Finished worker discovery
17:14:50 DISPATCHER: Starting worker discovery
17:14:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:14:50 DISPATCHER: Finished worker discovery
17:15:50 DISPATCHER: Starting worker discovery
17:15:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:15:50 DISPATCHER: Finished worker discovery
17:16:50 DISPATCHER: Starting worker discovery
17:16:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:16:50 DISPATCHER: Finished worker discovery
17:16:53 WORKER: done with job (3, 0, 3), trying to register it.
17:16:53 WORKER: registered result for job (3, 0, 3) with dispatcher
17:16:53 DISPATCHER: job (3, 0, 3) finished
17:16:53 DISPATCHER: register_result: lock acquired
17:16:53 DISPATCHER: job (3, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
17:16:53 job_id: (3, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.004147505744079038, 'num_filters_1': 33, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.024755692765488713, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 30, 'num_filters_3': 69, 'num_filters_4': 77}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5945692541766197, 'info': {'data05': 0.5945692541766197, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.004147505744079038, 'num_filters_1': 33, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.024755692765488713, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 30, 'num_filters_3': 69, 'num_filters_4': 77}"}}
exception: None

17:16:53 job_callback for (3, 0, 3) started
17:16:53 job_callback for (3, 0, 3) got condition
17:16:53 DISPATCHER: Trying to submit another job.
17:16:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:16:53 Only 8 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
17:16:53 HBMASTER: Trying to run another job!
17:16:53 job_callback for (3, 0, 3) finished
17:16:53 start sampling a new configuration.
17:16:53 done sampling a new configuration.
17:16:53 HBMASTER: schedule new run for iteration 4
17:16:53 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
17:16:53 HBMASTER: submitting job (4, 0, 0) to dispatcher
17:16:53 DISPATCHER: trying to submit job (4, 0, 0)
17:16:53 DISPATCHER: trying to notify the job_runner thread.
17:16:53 HBMASTER: job (4, 0, 0) submitted to dispatcher
17:16:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:16:53 DISPATCHER: Trying to submit another job.
17:16:53 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:16:53 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:16:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:16:53 WORKER: start processing job (4, 0, 0)
17:16:53 WORKER: args: ()
17:16:53 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.025083048653531368, 'num_filters_1': 20, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.03492174739955284, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 30, 'num_filters_3': 108, 'num_filters_4': 38, 'num_filters_5': 36}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:17:50 DISPATCHER: Starting worker discovery
17:17:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:17:50 DISPATCHER: Finished worker discovery
17:17:50 WORKER: done with job (4, 0, 0), trying to register it.
17:17:50 WORKER: registered result for job (4, 0, 0) with dispatcher
17:17:50 DISPATCHER: job (4, 0, 0) finished
17:17:50 DISPATCHER: register_result: lock acquired
17:17:50 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
17:17:50 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.025083048653531368, 'num_filters_1': 20, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.03492174739955284, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 30, 'num_filters_3': 108, 'num_filters_4': 38, 'num_filters_5': 36}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.025083048653531368, 'num_filters_1': 20, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.03492174739955284, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 30, 'num_filters_3': 108, 'num_filters_4': 38, 'num_filters_5': 36}"}}
exception: None

17:17:50 job_callback for (4, 0, 0) started
17:17:50 DISPATCHER: Trying to submit another job.
17:17:50 job_callback for (4, 0, 0) got condition
17:17:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:17:50 HBMASTER: Trying to run another job!
17:17:50 job_callback for (4, 0, 0) finished
17:17:50 start sampling a new configuration.
17:17:50 done sampling a new configuration.
17:17:50 HBMASTER: schedule new run for iteration 4
17:17:50 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
17:17:50 HBMASTER: submitting job (4, 0, 1) to dispatcher
17:17:50 DISPATCHER: trying to submit job (4, 0, 1)
17:17:50 DISPATCHER: trying to notify the job_runner thread.
17:17:50 HBMASTER: job (4, 0, 1) submitted to dispatcher
17:17:50 DISPATCHER: Trying to submit another job.
17:17:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:17:50 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:17:50 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:17:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:17:50 WORKER: start processing job (4, 0, 1)
17:17:50 WORKER: args: ()
17:17:50 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0010758202227436264, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.11833085349976714, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 30, 'num_filters_3': 108}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:18:48 WORKER: done with job (4, 0, 1), trying to register it.
17:18:48 WORKER: registered result for job (4, 0, 1) with dispatcher
17:18:48 DISPATCHER: job (4, 0, 1) finished
17:18:48 DISPATCHER: register_result: lock acquired
17:18:48 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
17:18:48 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0010758202227436264, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.11833085349976714, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 30, 'num_filters_3': 108}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5655194744484358, 'info': {'data05': 0.5655194744484358, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0010758202227436264, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.11833085349976714, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 30, 'num_filters_3': 108}"}}
exception: None

17:18:48 job_callback for (4, 0, 1) started
17:18:48 DISPATCHER: Trying to submit another job.
17:18:48 job_callback for (4, 0, 1) got condition
17:18:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:18:48 HBMASTER: Trying to run another job!
17:18:48 job_callback for (4, 0, 1) finished
17:18:48 start sampling a new configuration.
17:18:48 done sampling a new configuration.
17:18:48 HBMASTER: schedule new run for iteration 4
17:18:48 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
17:18:48 HBMASTER: submitting job (4, 0, 2) to dispatcher
17:18:48 DISPATCHER: trying to submit job (4, 0, 2)
17:18:48 DISPATCHER: trying to notify the job_runner thread.
17:18:48 HBMASTER: job (4, 0, 2) submitted to dispatcher
17:18:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:18:48 DISPATCHER: Trying to submit another job.
17:18:48 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:18:48 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:18:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:18:48 WORKER: start processing job (4, 0, 2)
17:18:48 WORKER: args: ()
17:18:48 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.033349170229226587, 'num_filters_1': 20, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.014440781398827734}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:18:50 DISPATCHER: Starting worker discovery
17:18:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:18:50 DISPATCHER: Finished worker discovery
17:19:46 WORKER: done with job (4, 0, 2), trying to register it.
17:19:46 WORKER: registered result for job (4, 0, 2) with dispatcher
17:19:46 DISPATCHER: job (4, 0, 2) finished
17:19:46 DISPATCHER: register_result: lock acquired
17:19:46 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
17:19:46 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.033349170229226587, 'num_filters_1': 20, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.014440781398827734}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.39314976803666646, 'info': {'data05': 0.39314976803666646, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.033349170229226587, 'num_filters_1': 20, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.014440781398827734}"}}
exception: None

17:19:46 job_callback for (4, 0, 2) started
17:19:46 DISPATCHER: Trying to submit another job.
17:19:46 job_callback for (4, 0, 2) got condition
17:19:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:19:46 HBMASTER: Trying to run another job!
17:19:46 job_callback for (4, 0, 2) finished
17:19:46 start sampling a new configuration.
17:19:46 done sampling a new configuration.
17:19:46 HBMASTER: schedule new run for iteration 4
17:19:46 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
17:19:46 HBMASTER: submitting job (4, 0, 3) to dispatcher
17:19:46 DISPATCHER: trying to submit job (4, 0, 3)
17:19:46 DISPATCHER: trying to notify the job_runner thread.
17:19:46 HBMASTER: job (4, 0, 3) submitted to dispatcher
17:19:46 DISPATCHER: Trying to submit another job.
17:19:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:19:46 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:19:46 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:19:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:19:46 WORKER: start processing job (4, 0, 3)
17:19:46 WORKER: args: ()
17:19:46 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.00934515986129614, 'num_filters_1': 119, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.011284311760125816, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 48, 'num_filters_3': 53, 'num_filters_4': 100}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:19:50 DISPATCHER: Starting worker discovery
17:19:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:19:50 DISPATCHER: Finished worker discovery
17:20:43 WORKER: done with job (4, 0, 3), trying to register it.
17:20:43 WORKER: registered result for job (4, 0, 3) with dispatcher
17:20:43 DISPATCHER: job (4, 0, 3) finished
17:20:43 DISPATCHER: register_result: lock acquired
17:20:43 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
17:20:43 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.00934515986129614, 'num_filters_1': 119, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.011284311760125816, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 48, 'num_filters_3': 53, 'num_filters_4': 100}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8640068468756568, 'info': {'data05': 0.8640068468756568, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.00934515986129614, 'num_filters_1': 119, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.011284311760125816, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 48, 'num_filters_3': 53, 'num_filters_4': 100}"}}
exception: None

17:20:43 job_callback for (4, 0, 3) started
17:20:43 job_callback for (4, 0, 3) got condition
17:20:43 DISPATCHER: Trying to submit another job.
17:20:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:20:43 HBMASTER: Trying to run another job!
17:20:43 job_callback for (4, 0, 3) finished
17:20:43 start sampling a new configuration.
17:20:43 done sampling a new configuration.
17:20:43 HBMASTER: schedule new run for iteration 4
17:20:43 HBMASTER: trying submitting job (4, 0, 4) to dispatcher
17:20:43 HBMASTER: submitting job (4, 0, 4) to dispatcher
17:20:43 DISPATCHER: trying to submit job (4, 0, 4)
17:20:43 DISPATCHER: trying to notify the job_runner thread.
17:20:43 HBMASTER: job (4, 0, 4) submitted to dispatcher
17:20:43 DISPATCHER: Trying to submit another job.
17:20:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:20:43 DISPATCHER: starting job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:20:43 DISPATCHER: job (4, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:20:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:20:43 WORKER: start processing job (4, 0, 4)
17:20:43 WORKER: args: ()
17:20:43 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00537766344793745, 'num_filters_1': 40, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.013397535865848699, 'kernel_size_2': 7, 'num_filters_2': 71}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:20:50 DISPATCHER: Starting worker discovery
17:20:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:20:50 DISPATCHER: Finished worker discovery
17:21:41 WORKER: done with job (4, 0, 4), trying to register it.
17:21:41 WORKER: registered result for job (4, 0, 4) with dispatcher
17:21:41 DISPATCHER: job (4, 0, 4) finished
17:21:41 DISPATCHER: register_result: lock acquired
17:21:41 DISPATCHER: job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
17:21:41 job_id: (4, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00537766344793745, 'num_filters_1': 40, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.013397535865848699, 'kernel_size_2': 7, 'num_filters_2': 71}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7293637071530357, 'info': {'data05': 0.7293637071530357, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00537766344793745, 'num_filters_1': 40, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.013397535865848699, 'kernel_size_2': 7, 'num_filters_2': 71}"}}
exception: None

17:21:41 job_callback for (4, 0, 4) started
17:21:41 job_callback for (4, 0, 4) got condition
17:21:41 DISPATCHER: Trying to submit another job.
17:21:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:21:41 HBMASTER: Trying to run another job!
17:21:41 job_callback for (4, 0, 4) finished
17:21:41 start sampling a new configuration.
17:21:41 done sampling a new configuration.
17:21:41 HBMASTER: schedule new run for iteration 4
17:21:41 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
17:21:41 HBMASTER: submitting job (4, 0, 5) to dispatcher
17:21:41 DISPATCHER: trying to submit job (4, 0, 5)
17:21:41 DISPATCHER: trying to notify the job_runner thread.
17:21:41 HBMASTER: job (4, 0, 5) submitted to dispatcher
17:21:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:21:41 DISPATCHER: Trying to submit another job.
17:21:41 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:21:41 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:21:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:21:41 WORKER: start processing job (4, 0, 5)
17:21:41 WORKER: args: ()
17:21:41 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.020643612195266395, 'num_filters_1': 70, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.1882612957735522, 'kernel_size_2': 5, 'num_filters_2': 30}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:21:50 DISPATCHER: Starting worker discovery
17:21:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:21:50 DISPATCHER: Finished worker discovery
17:22:39 WORKER: done with job (4, 0, 5), trying to register it.
17:22:39 WORKER: registered result for job (4, 0, 5) with dispatcher
17:22:39 DISPATCHER: job (4, 0, 5) finished
17:22:39 DISPATCHER: register_result: lock acquired
17:22:39 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
17:22:39 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.020643612195266395, 'num_filters_1': 70, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.1882612957735522, 'kernel_size_2': 5, 'num_filters_2': 30}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.011975942736265436, 'info': {'data05': 0.011975942736265436, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.020643612195266395, 'num_filters_1': 70, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.1882612957735522, 'kernel_size_2': 5, 'num_filters_2': 30}"}}
exception: None

17:22:39 job_callback for (4, 0, 5) started
17:22:39 job_callback for (4, 0, 5) got condition
17:22:39 DISPATCHER: Trying to submit another job.
17:22:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:22:39 HBMASTER: Trying to run another job!
17:22:39 job_callback for (4, 0, 5) finished
17:22:39 start sampling a new configuration.
17:22:39 done sampling a new configuration.
17:22:39 HBMASTER: schedule new run for iteration 4
17:22:39 HBMASTER: trying submitting job (4, 0, 6) to dispatcher
17:22:39 HBMASTER: submitting job (4, 0, 6) to dispatcher
17:22:39 DISPATCHER: trying to submit job (4, 0, 6)
17:22:39 DISPATCHER: trying to notify the job_runner thread.
17:22:39 HBMASTER: job (4, 0, 6) submitted to dispatcher
17:22:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:22:39 DISPATCHER: Trying to submit another job.
17:22:39 DISPATCHER: starting job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:22:39 DISPATCHER: job (4, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:22:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:22:39 WORKER: start processing job (4, 0, 6)
17:22:39 WORKER: args: ()
17:22:39 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.028141731331014087, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.019489147702538574, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 16, 'num_filters_3': 29}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:22:50 DISPATCHER: Starting worker discovery
17:22:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:22:50 DISPATCHER: Finished worker discovery
17:23:37 WORKER: done with job (4, 0, 6), trying to register it.
17:23:37 WORKER: registered result for job (4, 0, 6) with dispatcher
17:23:37 DISPATCHER: job (4, 0, 6) finished
17:23:37 DISPATCHER: register_result: lock acquired
17:23:37 DISPATCHER: job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
17:23:37 job_id: (4, 0, 6)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.028141731331014087, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.019489147702538574, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 16, 'num_filters_3': 29}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3452597732749963, 'info': {'data05': 0.3452597732749963, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.028141731331014087, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.019489147702538574, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 16, 'num_filters_3': 29}"}}
exception: None

17:23:37 job_callback for (4, 0, 6) started
17:23:37 job_callback for (4, 0, 6) got condition
17:23:37 DISPATCHER: Trying to submit another job.
17:23:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:23:37 done building a new model for budget 44.444444 based on 17/28 split
Best loss for this budget:-0.864007





17:23:37 HBMASTER: Trying to run another job!
17:23:37 job_callback for (4, 0, 6) finished
17:23:37 start sampling a new configuration.
17:23:38 best_vector: [3, 0, 0.8418146273590202, 0.18115469940795617, 0.6166481806579875, 1, 0.32382110148639653, 0.5401916538311057, 0, 2, 2, 1, 0.9467878707992571, 0.2981909003115438, 0.2963598751369903, 0.5587473220869388], 3.335499552231593e-30, 0.002998051669144902, -0.0004908033262357593
17:23:38 done sampling a new configuration.
17:23:38 HBMASTER: schedule new run for iteration 4
17:23:38 HBMASTER: trying submitting job (4, 0, 7) to dispatcher
17:23:38 HBMASTER: submitting job (4, 0, 7) to dispatcher
17:23:38 DISPATCHER: trying to submit job (4, 0, 7)
17:23:38 DISPATCHER: trying to notify the job_runner thread.
17:23:38 HBMASTER: job (4, 0, 7) submitted to dispatcher
17:23:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:23:38 DISPATCHER: Trying to submit another job.
17:23:38 DISPATCHER: starting job (4, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:23:38 DISPATCHER: job (4, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:23:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:23:38 WORKER: start processing job (4, 0, 7)
17:23:38 WORKER: args: ()
17:23:38 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.04826466039619551, 'num_filters_1': 23, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.05044353865070697, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 115, 'num_filters_3': 29, 'num_filters_4': 29}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:23:50 DISPATCHER: Starting worker discovery
17:23:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:23:50 DISPATCHER: Finished worker discovery
17:24:35 WORKER: done with job (4, 0, 7), trying to register it.
17:24:35 WORKER: registered result for job (4, 0, 7) with dispatcher
17:24:35 DISPATCHER: job (4, 0, 7) finished
17:24:35 DISPATCHER: register_result: lock acquired
17:24:35 DISPATCHER: job (4, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
17:24:35 job_id: (4, 0, 7)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.04826466039619551, 'num_filters_1': 23, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.05044353865070697, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 115, 'num_filters_3': 29, 'num_filters_4': 29}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5333400607561345, 'info': {'data05': 0.5333400607561345, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.04826466039619551, 'num_filters_1': 23, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.05044353865070697, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 115, 'num_filters_3': 29, 'num_filters_4': 29}"}}
exception: None

17:24:35 job_callback for (4, 0, 7) started
17:24:35 job_callback for (4, 0, 7) got condition
17:24:35 DISPATCHER: Trying to submit another job.
17:24:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:24:35 done building a new model for budget 44.444444 based on 17/29 split
Best loss for this budget:-0.864007





17:24:35 HBMASTER: Trying to run another job!
17:24:35 job_callback for (4, 0, 7) finished
17:24:35 start sampling a new configuration.
17:24:35 best_vector: [3, 0, 0.6472247674957362, 0.05224473305886256, 0.634069589972049, 0, 0.1523756646788898, 0.8347252475055869, 0, 2, 2, 1, 0.8994062181198098, 0.2801720663851588, 0.5474631718342565, 0.566581651644025], 1.70038498707031e-29, 0.0005881021107596092, -0.0006244861463055272
17:24:35 done sampling a new configuration.
17:24:35 HBMASTER: schedule new run for iteration 4
17:24:35 HBMASTER: trying submitting job (4, 0, 8) to dispatcher
17:24:35 HBMASTER: submitting job (4, 0, 8) to dispatcher
17:24:35 DISPATCHER: trying to submit job (4, 0, 8)
17:24:35 DISPATCHER: trying to notify the job_runner thread.
17:24:35 HBMASTER: job (4, 0, 8) submitted to dispatcher
17:24:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:24:35 DISPATCHER: Trying to submit another job.
17:24:35 DISPATCHER: starting job (4, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:24:35 DISPATCHER: job (4, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:24:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:24:35 WORKER: start processing job (4, 0, 8)
17:24:35 WORKER: args: ()
17:24:35 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.01969924288761086, 'num_filters_1': 17, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.12189968549958197, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 104, 'num_filters_3': 28, 'num_filters_4': 49}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:24:50 DISPATCHER: Starting worker discovery
17:24:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:24:50 DISPATCHER: Finished worker discovery
17:25:34 WORKER: done with job (4, 0, 8), trying to register it.
17:25:34 WORKER: registered result for job (4, 0, 8) with dispatcher
17:25:34 DISPATCHER: job (4, 0, 8) finished
17:25:34 DISPATCHER: register_result: lock acquired
17:25:34 DISPATCHER: job (4, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
17:25:34 job_id: (4, 0, 8)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.01969924288761086, 'num_filters_1': 17, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.12189968549958197, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 104, 'num_filters_3': 28, 'num_filters_4': 49}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.01969924288761086, 'num_filters_1': 17, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.12189968549958197, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 104, 'num_filters_3': 28, 'num_filters_4': 49}"}}
exception: None

17:25:34 job_callback for (4, 0, 8) started
17:25:34 job_callback for (4, 0, 8) got condition
17:25:34 DISPATCHER: Trying to submit another job.
17:25:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:25:34 done building a new model for budget 44.444444 based on 17/30 split
Best loss for this budget:-0.864007





17:25:34 HBMASTER: Trying to run another job!
17:25:34 job_callback for (4, 0, 8) finished
17:25:34 start sampling a new configuration.
17:25:34 best_vector: [1, 0, 0.3896670147849214, 0.6556525378440261, 0.2539315064704415, 1, 0.5860270612083038, 0.5910217837351702, 0, 2, 1, 2, 0.9590854227932484, 0.648109935434144, 0.6164773425548336, 0.5432679778663199], 1.5273536670316628e-29, 0.0006547272066616053, -0.00025507112906589133
17:25:34 done sampling a new configuration.
17:25:34 HBMASTER: schedule new run for iteration 4
17:25:34 HBMASTER: trying submitting job (4, 0, 9) to dispatcher
17:25:34 HBMASTER: submitting job (4, 0, 9) to dispatcher
17:25:34 DISPATCHER: trying to submit job (4, 0, 9)
17:25:34 DISPATCHER: trying to notify the job_runner thread.
17:25:34 HBMASTER: job (4, 0, 9) submitted to dispatcher
17:25:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:25:34 DISPATCHER: Trying to submit another job.
17:25:34 DISPATCHER: starting job (4, 0, 9) on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:25:34 DISPATCHER: job (4, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:25:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:25:34 WORKER: start processing job (4, 0, 9)
17:25:34 WORKER: args: ()
17:25:34 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.006016362970083923, 'num_filters_1': 62, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.058740422878563375, 'kernel_size_2': 3, 'num_filters_2': 118}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:25:50 DISPATCHER: Starting worker discovery
17:25:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:25:50 DISPATCHER: Finished worker discovery
17:26:31 WORKER: done with job (4, 0, 9), trying to register it.
17:26:31 WORKER: registered result for job (4, 0, 9) with dispatcher
17:26:31 DISPATCHER: job (4, 0, 9) finished
17:26:31 DISPATCHER: register_result: lock acquired
17:26:31 DISPATCHER: job (4, 0, 9) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
17:26:31 job_id: (4, 0, 9)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.006016362970083923, 'num_filters_1': 62, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.058740422878563375, 'kernel_size_2': 3, 'num_filters_2': 118}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.39896096300651895, 'info': {'data05': 0.39896096300651895, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.006016362970083923, 'num_filters_1': 62, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.058740422878563375, 'kernel_size_2': 3, 'num_filters_2': 118}"}}
exception: None

17:26:31 job_callback for (4, 0, 9) started
17:26:31 DISPATCHER: Trying to submit another job.
17:26:31 job_callback for (4, 0, 9) got condition
17:26:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:26:31 done building a new model for budget 44.444444 based on 17/31 split
Best loss for this budget:-0.864007





17:26:31 HBMASTER: Trying to run another job!
17:26:31 job_callback for (4, 0, 9) finished
17:26:31 start sampling a new configuration.
17:26:32 best_vector: [0, 1, 0.7863438424686581, 0.21441009238486433, 0.2814942363017881, 1, 0.3628631482265801, 0.5930059281964482, 1, 2, 0, 1, 0.8530562965696726, 0.6383175051550258, 0.3836087045894772, 0.6530594533861088], 1.631786899256213e-30, 0.006128251185591767, -0.00011808882684209186
17:26:32 done sampling a new configuration.
17:26:32 HBMASTER: schedule new run for iteration 4
17:26:32 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
17:26:32 HBMASTER: submitting job (4, 0, 10) to dispatcher
17:26:32 DISPATCHER: trying to submit job (4, 0, 10)
17:26:32 DISPATCHER: trying to notify the job_runner thread.
17:26:32 HBMASTER: job (4, 0, 10) submitted to dispatcher
17:26:32 DISPATCHER: Trying to submit another job.
17:26:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:26:32 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:26:32 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:26:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:26:32 WORKER: start processing job (4, 0, 10)
17:26:32 WORKER: args: ()
17:26:32 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0373841650086244, 'num_filters_1': 24, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.05909061366131015, 'kernel_size_2': 5, 'num_filters_2': 94}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:26:50 DISPATCHER: Starting worker discovery
17:26:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:26:50 DISPATCHER: Finished worker discovery
17:27:30 WORKER: done with job (4, 0, 10), trying to register it.
17:27:30 WORKER: registered result for job (4, 0, 10) with dispatcher
17:27:30 DISPATCHER: job (4, 0, 10) finished
17:27:30 DISPATCHER: register_result: lock acquired
17:27:30 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
17:27:30 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0373841650086244, 'num_filters_1': 24, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.05909061366131015, 'kernel_size_2': 5, 'num_filters_2': 94}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0946719412050231, 'info': {'data05': 0.0946719412050231, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0373841650086244, 'num_filters_1': 24, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.05909061366131015, 'kernel_size_2': 5, 'num_filters_2': 94}"}}
exception: None

17:27:30 job_callback for (4, 0, 10) started
17:27:30 DISPATCHER: Trying to submit another job.
17:27:30 job_callback for (4, 0, 10) got condition
17:27:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:27:30 done building a new model for budget 44.444444 based on 17/32 split
Best loss for this budget:-0.864007





17:27:30 HBMASTER: Trying to run another job!
17:27:30 job_callback for (4, 0, 10) finished
17:27:30 start sampling a new configuration.
17:27:31 best_vector: [0, 2, 0.6019443722356181, 0.8280498365531799, 0.3494058826671622, 1, 0.45471781339464584, 0.03745437051607156, 0, 2, 2, 0, 0.6652479691784448, 0.7401092222288418, 0.8349443623401017, 0.6812495172316828], 3.635904629082058e-30, 0.0027503471680786797, -7.67172693393709e-05
17:27:31 done sampling a new configuration.
17:27:31 HBMASTER: schedule new run for iteration 4
17:27:31 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
17:27:31 HBMASTER: submitting job (4, 0, 11) to dispatcher
17:27:31 DISPATCHER: trying to submit job (4, 0, 11)
17:27:31 DISPATCHER: trying to notify the job_runner thread.
17:27:31 HBMASTER: job (4, 0, 11) submitted to dispatcher
17:27:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:27:31 DISPATCHER: Trying to submit another job.
17:27:31 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:27:31 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:27:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:27:31 WORKER: start processing job (4, 0, 11)
17:27:31 WORKER: args: ()
17:27:31 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.01599148313803213, 'num_filters_1': 89, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.011187402399934196, 'kernel_size_2': 3, 'num_filters_2': 63}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:27:50 DISPATCHER: Starting worker discovery
17:27:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:27:50 DISPATCHER: Finished worker discovery
17:28:29 WORKER: done with job (4, 0, 11), trying to register it.
17:28:29 WORKER: registered result for job (4, 0, 11) with dispatcher
17:28:29 DISPATCHER: job (4, 0, 11) finished
17:28:29 DISPATCHER: register_result: lock acquired
17:28:29 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
17:28:29 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.01599148313803213, 'num_filters_1': 89, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.011187402399934196, 'kernel_size_2': 3, 'num_filters_2': 63}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5573907972121435, 'info': {'data05': 0.5573907972121435, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.01599148313803213, 'num_filters_1': 89, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.011187402399934196, 'kernel_size_2': 3, 'num_filters_2': 63}"}}
exception: None

17:28:29 job_callback for (4, 0, 11) started
17:28:29 job_callback for (4, 0, 11) got condition
17:28:29 DISPATCHER: Trying to submit another job.
17:28:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:28:29 done building a new model for budget 44.444444 based on 17/33 split
Best loss for this budget:-0.864007





17:28:29 HBMASTER: Trying to run another job!
17:28:29 job_callback for (4, 0, 11) finished
17:28:29 start sampling a new configuration.
17:28:29 done sampling a new configuration.
17:28:29 HBMASTER: schedule new run for iteration 4
17:28:29 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
17:28:29 HBMASTER: submitting job (4, 0, 12) to dispatcher
17:28:29 DISPATCHER: trying to submit job (4, 0, 12)
17:28:29 DISPATCHER: trying to notify the job_runner thread.
17:28:29 HBMASTER: job (4, 0, 12) submitted to dispatcher
17:28:29 DISPATCHER: Trying to submit another job.
17:28:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:28:29 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:28:29 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:28:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:28:29 WORKER: start processing job (4, 0, 12)
17:28:29 WORKER: args: ()
17:28:29 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.005095917099878145, 'num_filters_1': 38, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.03268590019297526, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 30, 'num_filters_3': 23, 'num_filters_4': 83, 'num_filters_5': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:28:50 DISPATCHER: Starting worker discovery
17:28:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:28:50 DISPATCHER: Finished worker discovery
17:29:26 WORKER: done with job (4, 0, 12), trying to register it.
17:29:26 WORKER: registered result for job (4, 0, 12) with dispatcher
17:29:26 DISPATCHER: job (4, 0, 12) finished
17:29:26 DISPATCHER: register_result: lock acquired
17:29:26 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
17:29:26 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.005095917099878145, 'num_filters_1': 38, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.03268590019297526, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 30, 'num_filters_3': 23, 'num_filters_4': 83, 'num_filters_5': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3969298980669098, 'info': {'data05': 0.3969298980669098, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.005095917099878145, 'num_filters_1': 38, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.03268590019297526, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 30, 'num_filters_3': 23, 'num_filters_4': 83, 'num_filters_5': 17}"}}
exception: None

17:29:26 job_callback for (4, 0, 12) started
17:29:26 DISPATCHER: Trying to submit another job.
17:29:26 job_callback for (4, 0, 12) got condition
17:29:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:29:26 done building a new model for budget 44.444444 based on 17/34 split
Best loss for this budget:-0.864007





17:29:26 HBMASTER: Trying to run another job!
17:29:26 job_callback for (4, 0, 12) finished
17:29:26 start sampling a new configuration.
17:29:26 done sampling a new configuration.
17:29:26 HBMASTER: schedule new run for iteration 4
17:29:26 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
17:29:26 HBMASTER: submitting job (4, 0, 13) to dispatcher
17:29:26 DISPATCHER: trying to submit job (4, 0, 13)
17:29:26 DISPATCHER: trying to notify the job_runner thread.
17:29:26 HBMASTER: job (4, 0, 13) submitted to dispatcher
17:29:26 DISPATCHER: Trying to submit another job.
17:29:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:29:26 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:29:26 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:29:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:29:26 WORKER: start processing job (4, 0, 13)
17:29:26 WORKER: args: ()
17:29:26 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.00659714258485479, 'num_filters_1': 55, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.02591540689619576}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:29:50 DISPATCHER: Starting worker discovery
17:29:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:29:50 DISPATCHER: Finished worker discovery
17:30:26 WORKER: done with job (4, 0, 13), trying to register it.
17:30:26 WORKER: registered result for job (4, 0, 13) with dispatcher
17:30:26 DISPATCHER: job (4, 0, 13) finished
17:30:26 DISPATCHER: register_result: lock acquired
17:30:26 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
17:30:26 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.00659714258485479, 'num_filters_1': 55, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.02591540689619576}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5214641467226204, 'info': {'data05': 0.5214641467226204, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.00659714258485479, 'num_filters_1': 55, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.02591540689619576}"}}
exception: None

17:30:26 job_callback for (4, 0, 13) started
17:30:26 job_callback for (4, 0, 13) got condition
17:30:26 DISPATCHER: Trying to submit another job.
17:30:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:30:26 done building a new model for budget 44.444444 based on 17/34 split
Best loss for this budget:-0.864007





17:30:26 HBMASTER: Trying to run another job!
17:30:26 job_callback for (4, 0, 13) finished
17:30:26 start sampling a new configuration.
17:30:26 done sampling a new configuration.
17:30:26 HBMASTER: schedule new run for iteration 4
17:30:26 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
17:30:26 HBMASTER: submitting job (4, 0, 14) to dispatcher
17:30:26 DISPATCHER: trying to submit job (4, 0, 14)
17:30:26 DISPATCHER: trying to notify the job_runner thread.
17:30:26 HBMASTER: job (4, 0, 14) submitted to dispatcher
17:30:26 DISPATCHER: Trying to submit another job.
17:30:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:30:26 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:30:26 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:30:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:30:26 WORKER: start processing job (4, 0, 14)
17:30:26 WORKER: args: ()
17:30:26 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.00604156110122052, 'num_filters_1': 91, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.05863099834783703, 'kernel_size_2': 3, 'num_filters_2': 113}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:30:50 DISPATCHER: Starting worker discovery
17:30:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:30:50 DISPATCHER: Finished worker discovery
17:31:24 WORKER: done with job (4, 0, 14), trying to register it.
17:31:24 WORKER: registered result for job (4, 0, 14) with dispatcher
17:31:24 DISPATCHER: job (4, 0, 14) finished
17:31:24 DISPATCHER: register_result: lock acquired
17:31:24 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
17:31:24 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.00604156110122052, 'num_filters_1': 91, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.05863099834783703, 'kernel_size_2': 3, 'num_filters_2': 113}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2127965791355866, 'info': {'data05': 0.2127965791355866, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.00604156110122052, 'num_filters_1': 91, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.05863099834783703, 'kernel_size_2': 3, 'num_filters_2': 113}"}}
exception: None

17:31:24 job_callback for (4, 0, 14) started
17:31:24 DISPATCHER: Trying to submit another job.
17:31:24 job_callback for (4, 0, 14) got condition
17:31:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:31:24 done building a new model for budget 44.444444 based on 17/35 split
Best loss for this budget:-0.864007





17:31:24 HBMASTER: Trying to run another job!
17:31:24 job_callback for (4, 0, 14) finished
17:31:24 start sampling a new configuration.
17:31:24 best_vector: [3, 1, 0.6805505066818138, 0.25649490158168914, 0.4787444494542191, 1, 0.2921629153555606, 0.5961152595027184, 1, 0, 2, 1, 0.10930465808066947, 0.7664540865238575, 0.941064185278404, 0.7427597667991581], 1.9483853178475613e-28, 5.132455017186896e-05, -5.406223827551948e-05
17:31:24 done sampling a new configuration.
17:31:24 HBMASTER: schedule new run for iteration 4
17:31:24 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
17:31:24 HBMASTER: submitting job (4, 0, 15) to dispatcher
17:31:24 DISPATCHER: trying to submit job (4, 0, 15)
17:31:24 DISPATCHER: trying to notify the job_runner thread.
17:31:24 HBMASTER: job (4, 0, 15) submitted to dispatcher
17:31:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:31:24 DISPATCHER: Trying to submit another job.
17:31:24 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:31:24 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:31:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:31:24 WORKER: start processing job (4, 0, 15)
17:31:24 WORKER: args: ()
17:31:24 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.02296682775723854, 'num_filters_1': 27, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.05964359787647903, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 20, 'num_filters_3': 78}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:31:50 DISPATCHER: Starting worker discovery
17:31:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:31:50 DISPATCHER: Finished worker discovery
17:32:22 WORKER: done with job (4, 0, 15), trying to register it.
17:32:22 WORKER: registered result for job (4, 0, 15) with dispatcher
17:32:22 DISPATCHER: job (4, 0, 15) finished
17:32:22 DISPATCHER: register_result: lock acquired
17:32:22 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
17:32:22 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.02296682775723854, 'num_filters_1': 27, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.05964359787647903, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 20, 'num_filters_3': 78}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.33052636618589243, 'info': {'data05': 0.33052636618589243, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.02296682775723854, 'num_filters_1': 27, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.05964359787647903, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 20, 'num_filters_3': 78}"}}
exception: None

17:32:22 job_callback for (4, 0, 15) started
17:32:22 DISPATCHER: Trying to submit another job.
17:32:22 job_callback for (4, 0, 15) got condition
17:32:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:32:22 done building a new model for budget 44.444444 based on 17/36 split
Best loss for this budget:-0.864007





17:32:22 HBMASTER: Trying to run another job!
17:32:22 job_callback for (4, 0, 15) finished
17:32:22 start sampling a new configuration.
17:32:22 done sampling a new configuration.
17:32:22 HBMASTER: schedule new run for iteration 4
17:32:22 HBMASTER: trying submitting job (4, 0, 16) to dispatcher
17:32:22 HBMASTER: submitting job (4, 0, 16) to dispatcher
17:32:22 DISPATCHER: trying to submit job (4, 0, 16)
17:32:22 DISPATCHER: trying to notify the job_runner thread.
17:32:22 HBMASTER: job (4, 0, 16) submitted to dispatcher
17:32:22 DISPATCHER: Trying to submit another job.
17:32:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:32:22 DISPATCHER: starting job (4, 0, 16) on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:32:22 DISPATCHER: job (4, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:32:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:32:22 WORKER: start processing job (4, 0, 16)
17:32:22 WORKER: args: ()
17:32:22 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.019839331903950982, 'num_filters_1': 105, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.012093105752489773, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 42, 'num_filters_3': 16, 'num_filters_4': 56}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:32:50 DISPATCHER: Starting worker discovery
17:32:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:32:50 DISPATCHER: Finished worker discovery
17:33:19 WORKER: done with job (4, 0, 16), trying to register it.
17:33:19 WORKER: registered result for job (4, 0, 16) with dispatcher
17:33:19 DISPATCHER: job (4, 0, 16) finished
17:33:19 DISPATCHER: register_result: lock acquired
17:33:19 DISPATCHER: job (4, 0, 16) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
17:33:19 job_id: (4, 0, 16)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.019839331903950982, 'num_filters_1': 105, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.012093105752489773, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 42, 'num_filters_3': 16, 'num_filters_4': 56}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.872413516697638, 'info': {'data05': 0.872413516697638, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.019839331903950982, 'num_filters_1': 105, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.012093105752489773, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 42, 'num_filters_3': 16, 'num_filters_4': 56}"}}
exception: None

17:33:19 job_callback for (4, 0, 16) started
17:33:19 DISPATCHER: Trying to submit another job.
17:33:19 job_callback for (4, 0, 16) got condition
17:33:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:33:20 done building a new model for budget 44.444444 based on 17/37 split
Best loss for this budget:-0.872414





17:33:20 HBMASTER: Trying to run another job!
17:33:20 job_callback for (4, 0, 16) finished
17:33:20 start sampling a new configuration.
17:33:20 best_vector: [0, 2, 0.4820847670084994, 0.23787283346246557, 0.4350027084631567, 1, 0.2357045131398322, 0.35644132336633294, 0, 0, 2, 1, 0.6772156673413319, 0.9345450104885202, 0.7881276366229109, 0.7355802121390733], 9.03916527666271e-30, 0.0011062968420123892, -6.196380174939518e-06
17:33:20 done sampling a new configuration.
17:33:20 HBMASTER: schedule new run for iteration 4
17:33:20 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
17:33:20 HBMASTER: submitting job (4, 0, 17) to dispatcher
17:33:20 DISPATCHER: trying to submit job (4, 0, 17)
17:33:20 DISPATCHER: trying to notify the job_runner thread.
17:33:20 HBMASTER: job (4, 0, 17) submitted to dispatcher
17:33:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:33:20 DISPATCHER: Trying to submit another job.
17:33:20 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:33:20 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:33:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:33:20 WORKER: start processing job (4, 0, 17)
17:33:20 WORKER: args: ()
17:33:20 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.009208089545721396, 'num_filters_1': 26, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.029089807905510228, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 65, 'num_filters_3': 112}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:33:50 DISPATCHER: Starting worker discovery
17:33:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:33:50 DISPATCHER: Finished worker discovery
17:34:20 WORKER: done with job (4, 0, 17), trying to register it.
17:34:20 WORKER: registered result for job (4, 0, 17) with dispatcher
17:34:20 DISPATCHER: job (4, 0, 17) finished
17:34:20 DISPATCHER: register_result: lock acquired
17:34:20 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
17:34:20 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.009208089545721396, 'num_filters_1': 26, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.029089807905510228, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 65, 'num_filters_3': 112}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4057826839068821, 'info': {'data05': 0.4057826839068821, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.009208089545721396, 'num_filters_1': 26, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.029089807905510228, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 65, 'num_filters_3': 112}"}}
exception: None

17:34:20 job_callback for (4, 0, 17) started
17:34:20 DISPATCHER: Trying to submit another job.
17:34:20 job_callback for (4, 0, 17) got condition
17:34:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:34:20 done building a new model for budget 44.444444 based on 17/38 split
Best loss for this budget:-0.872414





17:34:20 HBMASTER: Trying to run another job!
17:34:20 job_callback for (4, 0, 17) finished
17:34:20 start sampling a new configuration.
17:34:20 best_vector: [0, 1, 0.653126689583736, 0.7119158819201419, 0.5103735294807761, 1, 0.05604482965813629, 0.24566315490411222, 2, 2, 2, 0, 0.8293420755186188, 0.756170361975748, 0.7326452992831006, 0.6231013600019605], 9.625940040598691e-30, 0.0010388595771242768, -1.747755703864625e-05
17:34:20 done sampling a new configuration.
17:34:20 HBMASTER: schedule new run for iteration 4
17:34:20 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
17:34:20 HBMASTER: submitting job (4, 0, 18) to dispatcher
17:34:20 DISPATCHER: trying to submit job (4, 0, 18)
17:34:20 DISPATCHER: trying to notify the job_runner thread.
17:34:20 HBMASTER: job (4, 0, 18) submitted to dispatcher
17:34:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:34:20 DISPATCHER: Trying to submit another job.
17:34:20 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:34:20 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:34:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:34:20 WORKER: start processing job (4, 0, 18)
17:34:20 WORKER: args: ()
17:34:20 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.020241998072504448, 'num_filters_1': 70, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.020874454414507332, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 90, 'num_filters_3': 77}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:34:50 DISPATCHER: Starting worker discovery
17:34:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:34:50 DISPATCHER: Finished worker discovery
17:35:23 WORKER: done with job (4, 0, 18), trying to register it.
17:35:23 WORKER: registered result for job (4, 0, 18) with dispatcher
17:35:23 DISPATCHER: job (4, 0, 18) finished
17:35:23 DISPATCHER: register_result: lock acquired
17:35:23 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
17:35:23 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.020241998072504448, 'num_filters_1': 70, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.020874454414507332, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 90, 'num_filters_3': 77}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5831282879056613, 'info': {'data05': 0.5831282879056613, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.020241998072504448, 'num_filters_1': 70, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.020874454414507332, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 90, 'num_filters_3': 77}"}}
exception: None

17:35:23 job_callback for (4, 0, 18) started
17:35:23 job_callback for (4, 0, 18) got condition
17:35:23 DISPATCHER: Trying to submit another job.
17:35:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:35:23 done building a new model for budget 44.444444 based on 17/39 split
Best loss for this budget:-0.872414





17:35:23 HBMASTER: Trying to run another job!
17:35:23 job_callback for (4, 0, 18) finished
17:35:23 start sampling a new configuration.
17:35:23 done sampling a new configuration.
17:35:23 HBMASTER: schedule new run for iteration 4
17:35:23 HBMASTER: trying submitting job (4, 0, 19) to dispatcher
17:35:23 HBMASTER: submitting job (4, 0, 19) to dispatcher
17:35:23 DISPATCHER: trying to submit job (4, 0, 19)
17:35:23 DISPATCHER: trying to notify the job_runner thread.
17:35:23 HBMASTER: job (4, 0, 19) submitted to dispatcher
17:35:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:35:23 DISPATCHER: Trying to submit another job.
17:35:23 DISPATCHER: starting job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:35:23 DISPATCHER: job (4, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:35:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:35:23 WORKER: start processing job (4, 0, 19)
17:35:23 WORKER: args: ()
17:35:23 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0044684620650043885, 'num_filters_1': 97, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.14882308016473567}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:35:50 DISPATCHER: Starting worker discovery
17:35:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:35:50 DISPATCHER: Finished worker discovery
17:36:21 WORKER: done with job (4, 0, 19), trying to register it.
17:36:21 WORKER: registered result for job (4, 0, 19) with dispatcher
17:36:21 DISPATCHER: job (4, 0, 19) finished
17:36:21 DISPATCHER: register_result: lock acquired
17:36:21 DISPATCHER: job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
17:36:21 job_id: (4, 0, 19)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0044684620650043885, 'num_filters_1': 97, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.14882308016473567}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3568844733002258, 'info': {'data05': 0.3568844733002258, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0044684620650043885, 'num_filters_1': 97, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.14882308016473567}"}}
exception: None

17:36:21 job_callback for (4, 0, 19) started
17:36:21 job_callback for (4, 0, 19) got condition
17:36:21 DISPATCHER: Trying to submit another job.
17:36:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:36:21 done building a new model for budget 44.444444 based on 17/39 split
Best loss for this budget:-0.872414





17:36:21 HBMASTER: Trying to run another job!
17:36:21 job_callback for (4, 0, 19) finished
17:36:21 start sampling a new configuration.
17:36:21 done sampling a new configuration.
17:36:21 HBMASTER: schedule new run for iteration 4
17:36:21 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
17:36:21 HBMASTER: submitting job (4, 0, 20) to dispatcher
17:36:21 DISPATCHER: trying to submit job (4, 0, 20)
17:36:21 DISPATCHER: trying to notify the job_runner thread.
17:36:21 HBMASTER: job (4, 0, 20) submitted to dispatcher
17:36:21 DISPATCHER: Trying to submit another job.
17:36:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:36:21 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:36:21 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:36:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:36:21 WORKER: start processing job (4, 0, 20)
17:36:21 WORKER: args: ()
17:36:21 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.056351127187391784, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.025105139361037206, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 41, 'num_filters_3': 125, 'num_filters_4': 56, 'num_filters_5': 27}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:36:50 DISPATCHER: Starting worker discovery
17:36:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:36:50 DISPATCHER: Finished worker discovery
17:37:18 WORKER: done with job (4, 0, 20), trying to register it.
17:37:18 WORKER: registered result for job (4, 0, 20) with dispatcher
17:37:18 DISPATCHER: job (4, 0, 20) finished
17:37:18 DISPATCHER: register_result: lock acquired
17:37:18 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
17:37:18 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.056351127187391784, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.025105139361037206, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 41, 'num_filters_3': 125, 'num_filters_4': 56, 'num_filters_5': 27}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.056351127187391784, 'num_filters_1': 19, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.025105139361037206, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 41, 'num_filters_3': 125, 'num_filters_4': 56, 'num_filters_5': 27}"}}
exception: None

17:37:18 job_callback for (4, 0, 20) started
17:37:18 DISPATCHER: Trying to submit another job.
17:37:18 job_callback for (4, 0, 20) got condition
17:37:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:37:18 done building a new model for budget 44.444444 based on 17/40 split
Best loss for this budget:-0.872414





17:37:18 HBMASTER: Trying to run another job!
17:37:18 job_callback for (4, 0, 20) finished
17:37:18 start sampling a new configuration.
17:37:19 best_vector: [0, 1, 0.3189094083344036, 0.4980595101698634, 0.5059000507961295, 1, 0.5266893830200428, 0.3273198770777251, 2, 2, 2, 1, 0.4053828155822422, 0.937727638845842, 0.9006037237681392, 0.6972205372519938], 7.481918902528684e-30, 0.0013365555187480412, -3.8743683993630464e-05
17:37:19 done sampling a new configuration.
17:37:19 HBMASTER: schedule new run for iteration 4
17:37:19 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
17:37:19 HBMASTER: submitting job (4, 0, 21) to dispatcher
17:37:19 DISPATCHER: trying to submit job (4, 0, 21)
17:37:19 DISPATCHER: trying to notify the job_runner thread.
17:37:19 HBMASTER: job (4, 0, 21) submitted to dispatcher
17:37:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:37:19 DISPATCHER: Trying to submit another job.
17:37:19 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:37:19 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:37:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:37:19 WORKER: start processing job (4, 0, 21)
17:37:19 WORKER: args: ()
17:37:19 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.004343289886423112, 'num_filters_1': 44, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.026659560054470163, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 37, 'num_filters_3': 113}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:37:50 DISPATCHER: Starting worker discovery
17:37:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:37:50 DISPATCHER: Finished worker discovery
17:38:16 WORKER: done with job (4, 0, 21), trying to register it.
17:38:16 WORKER: registered result for job (4, 0, 21) with dispatcher
17:38:16 DISPATCHER: job (4, 0, 21) finished
17:38:16 DISPATCHER: register_result: lock acquired
17:38:16 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
17:38:16 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.004343289886423112, 'num_filters_1': 44, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.026659560054470163, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 37, 'num_filters_3': 113}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7538854951028563, 'info': {'data05': 0.7538854951028563, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.004343289886423112, 'num_filters_1': 44, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.026659560054470163, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 37, 'num_filters_3': 113}"}}
exception: None

17:38:16 job_callback for (4, 0, 21) started
17:38:16 DISPATCHER: Trying to submit another job.
17:38:16 job_callback for (4, 0, 21) got condition
17:38:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:38:16 done building a new model for budget 44.444444 based on 17/41 split
Best loss for this budget:-0.872414





17:38:16 HBMASTER: Trying to run another job!
17:38:16 job_callback for (4, 0, 21) finished
17:38:16 start sampling a new configuration.
17:38:17 best_vector: [0, 1, 0.49131300398712474, 0.7271959988565992, 0.639056824568526, 1, 0.2687471203143847, 0.2814233453892295, 0, 2, 1, 1, 0.8811445670139457, 0.5312176017830756, 0.5061703898918645, 0.558008340653939], 9.84188697829694e-30, 0.001016065315731803, -2.8871131287154442e-05
17:38:17 done sampling a new configuration.
17:38:17 HBMASTER: schedule new run for iteration 4
17:38:17 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
17:38:17 HBMASTER: submitting job (4, 0, 22) to dispatcher
17:38:17 DISPATCHER: trying to submit job (4, 0, 22)
17:38:17 DISPATCHER: trying to notify the job_runner thread.
17:38:17 HBMASTER: job (4, 0, 22) submitted to dispatcher
17:38:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:38:17 DISPATCHER: Trying to submit another job.
17:38:17 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:38:17 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:38:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:38:17 WORKER: start processing job (4, 0, 22)
17:38:17 WORKER: args: ()
17:38:17 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.00960784543900048, 'num_filters_1': 72, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.02323486822937134, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 100, 'num_filters_3': 48, 'num_filters_4': 45}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:38:50 DISPATCHER: Starting worker discovery
17:38:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:38:50 DISPATCHER: Finished worker discovery
17:39:15 WORKER: done with job (4, 0, 22), trying to register it.
17:39:15 WORKER: registered result for job (4, 0, 22) with dispatcher
17:39:15 DISPATCHER: job (4, 0, 22) finished
17:39:15 DISPATCHER: register_result: lock acquired
17:39:15 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
17:39:15 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.00960784543900048, 'num_filters_1': 72, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.02323486822937134, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 100, 'num_filters_3': 48, 'num_filters_4': 45}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8236531771524399, 'info': {'data05': 0.8236531771524399, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.00960784543900048, 'num_filters_1': 72, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.02323486822937134, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 100, 'num_filters_3': 48, 'num_filters_4': 45}"}}
exception: None

17:39:15 job_callback for (4, 0, 22) started
17:39:15 DISPATCHER: Trying to submit another job.
17:39:15 job_callback for (4, 0, 22) got condition
17:39:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:39:15 done building a new model for budget 44.444444 based on 17/42 split
Best loss for this budget:-0.872414





17:39:15 HBMASTER: Trying to run another job!
17:39:15 job_callback for (4, 0, 22) finished
17:39:15 start sampling a new configuration.
17:39:15 best_vector: [2, 1, 0.22222129041029265, 0.32762243440597066, 0.8448567953489166, 1, 0.8517939826353561, 0.9147637314225663, 1, 0, 1, 1, 0.09334140875473418, 0.6034302717634377, 0.3668608680038903, 0.6323809555385617], 2.752883353951167e-27, 3.632554930323208e-06, -4.94801148542782e-06
17:39:15 done sampling a new configuration.
17:39:15 HBMASTER: schedule new run for iteration 4
17:39:15 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
17:39:15 HBMASTER: submitting job (4, 0, 23) to dispatcher
17:39:15 DISPATCHER: trying to submit job (4, 0, 23)
17:39:15 DISPATCHER: trying to notify the job_runner thread.
17:39:15 HBMASTER: job (4, 0, 23) submitted to dispatcher
17:39:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:39:15 DISPATCHER: Trying to submit another job.
17:39:15 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:39:15 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:39:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:39:15 WORKER: start processing job (4, 0, 23)
17:39:15 WORKER: args: ()
17:39:15 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0027825474618459614, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.1549298332776086, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 19, 'num_filters_3': 56, 'num_filters_4': 34, 'num_filters_5': 59}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:39:50 DISPATCHER: Starting worker discovery
17:39:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:39:50 DISPATCHER: Finished worker discovery
17:40:13 WORKER: done with job (4, 0, 23), trying to register it.
17:40:13 WORKER: registered result for job (4, 0, 23) with dispatcher
17:40:13 DISPATCHER: job (4, 0, 23) finished
17:40:13 DISPATCHER: register_result: lock acquired
17:40:13 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
17:40:13 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0027825474618459614, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.1549298332776086, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 19, 'num_filters_3': 56, 'num_filters_4': 34, 'num_filters_5': 59}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.14415285104529021, 'info': {'data05': 0.14415285104529021, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0027825474618459614, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.1549298332776086, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 19, 'num_filters_3': 56, 'num_filters_4': 34, 'num_filters_5': 59}"}}
exception: None

17:40:13 job_callback for (4, 0, 23) started
17:40:13 DISPATCHER: Trying to submit another job.
17:40:13 job_callback for (4, 0, 23) got condition
17:40:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:40:13 done building a new model for budget 44.444444 based on 17/43 split
Best loss for this budget:-0.872414





17:40:13 HBMASTER: Trying to run another job!
17:40:13 job_callback for (4, 0, 23) finished
17:40:13 start sampling a new configuration.
17:40:13 best_vector: [3, 0, 0.7884068514007139, 0.12173292295514715, 0.5183165724378778, 1, 0.11657753074476948, 0.9497428080252148, 1, 2, 0, 1, 0.0016118571233219026, 0.8228936048422493, 0.2925819261149187, 0.8420065033420665], 1.4798701473093488e-26, 6.757349635156619e-07, -3.727234245139313e-07
17:40:13 done sampling a new configuration.
17:40:13 HBMASTER: schedule new run for iteration 4
17:40:13 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
17:40:13 HBMASTER: submitting job (4, 0, 24) to dispatcher
17:40:13 DISPATCHER: trying to submit job (4, 0, 24)
17:40:13 DISPATCHER: trying to notify the job_runner thread.
17:40:13 HBMASTER: job (4, 0, 24) submitted to dispatcher
17:40:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:40:13 DISPATCHER: Trying to submit another job.
17:40:13 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:40:13 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:40:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:40:13 WORKER: start processing job (4, 0, 24)
17:40:13 WORKER: args: ()
17:40:13 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.037741026034680276, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.17204572329059847, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 16, 'num_filters_3': 88}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:40:50 DISPATCHER: Starting worker discovery
17:40:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:40:50 DISPATCHER: Finished worker discovery
17:41:13 WORKER: done with job (4, 0, 24), trying to register it.
17:41:13 WORKER: registered result for job (4, 0, 24) with dispatcher
17:41:13 DISPATCHER: job (4, 0, 24) finished
17:41:13 DISPATCHER: register_result: lock acquired
17:41:13 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
17:41:13 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.037741026034680276, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.17204572329059847, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 16, 'num_filters_3': 88}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.025746319413080598, 'info': {'data05': 0.025746319413080598, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.037741026034680276, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.17204572329059847, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 16, 'num_filters_3': 88}"}}
exception: None

17:41:13 job_callback for (4, 0, 24) started
17:41:13 job_callback for (4, 0, 24) got condition
17:41:13 DISPATCHER: Trying to submit another job.
17:41:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:41:13 done building a new model for budget 44.444444 based on 17/44 split
Best loss for this budget:-0.872414





17:41:13 HBMASTER: Trying to run another job!
17:41:13 job_callback for (4, 0, 24) finished
17:41:13 start sampling a new configuration.
17:41:13 best_vector: [2, 2, 0.010971459965809505, 0.6195353164564708, 0.6154273724003443, 0, 0.8887468107504236, 0.3129153269261279, 1, 2, 1, 0, 0.2411944960493571, 0.3192104046356453, 0.12865260323132988, 0.7892041973103735], 4.9929800988307605e-29, 0.00020028119083314127, -2.807788157324225e-07
17:41:13 done sampling a new configuration.
17:41:13 HBMASTER: schedule new run for iteration 4
17:41:13 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
17:41:13 HBMASTER: submitting job (4, 0, 25) to dispatcher
17:41:13 DISPATCHER: trying to submit job (4, 0, 25)
17:41:13 DISPATCHER: trying to notify the job_runner thread.
17:41:13 HBMASTER: job (4, 0, 25) submitted to dispatcher
17:41:13 DISPATCHER: Trying to submit another job.
17:41:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:41:13 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:41:13 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:41:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:41:13 WORKER: start processing job (4, 0, 25)
17:41:13 WORKER: args: ()
17:41:13 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0010518236217560456, 'num_filters_1': 57, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.02553361033774518, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 26, 'num_filters_3': 30, 'num_filters_4': 20}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:41:50 DISPATCHER: Starting worker discovery
17:41:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:41:50 DISPATCHER: Finished worker discovery
17:42:09 WORKER: done with job (4, 0, 25), trying to register it.
17:42:09 WORKER: registered result for job (4, 0, 25) with dispatcher
17:42:09 DISPATCHER: job (4, 0, 25) finished
17:42:09 DISPATCHER: register_result: lock acquired
17:42:09 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
17:42:09 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0010518236217560456, 'num_filters_1': 57, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.02553361033774518, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 26, 'num_filters_3': 30, 'num_filters_4': 20}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9138804516625767, 'info': {'data05': 0.9138804516625767, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0010518236217560456, 'num_filters_1': 57, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.02553361033774518, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 26, 'num_filters_3': 30, 'num_filters_4': 20}"}}
exception: None

17:42:09 job_callback for (4, 0, 25) started
17:42:09 DISPATCHER: Trying to submit another job.
17:42:09 job_callback for (4, 0, 25) got condition
17:42:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:42:09 done building a new model for budget 44.444444 based on 17/45 split
Best loss for this budget:-0.913880





17:42:09 HBMASTER: Trying to run another job!
17:42:09 job_callback for (4, 0, 25) finished
17:42:09 start sampling a new configuration.
17:42:09 best_vector: [2, 1, 0.8441608369057652, 0.3235413290432688, 0.7829137284124122, 1, 0.708180162826681, 0.5537716280988525, 0, 0, 2, 2, 0.9337211577285833, 0.248837557533073, 0.006468761997071415, 0.7085122406857465], 5.913320541610408e-30, 0.0016910972320260257, -3.2018756354625605e-06
17:42:09 done sampling a new configuration.
17:42:09 HBMASTER: schedule new run for iteration 4
17:42:09 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
17:42:09 HBMASTER: submitting job (4, 0, 26) to dispatcher
17:42:09 DISPATCHER: trying to submit job (4, 0, 26)
17:42:09 DISPATCHER: trying to notify the job_runner thread.
17:42:09 HBMASTER: job (4, 0, 26) submitted to dispatcher
17:42:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:42:09 DISPATCHER: Trying to submit another job.
17:42:09 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:42:09 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:42:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:42:09 WORKER: start processing job (4, 0, 26)
17:42:09 WORKER: args: ()
17:42:09 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.04878897271147908, 'num_filters_1': 31, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.05253799549070092, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 112, 'num_filters_3': 26, 'num_filters_4': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:42:50 DISPATCHER: Starting worker discovery
17:42:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:42:50 DISPATCHER: Finished worker discovery
17:43:07 WORKER: done with job (4, 0, 26), trying to register it.
17:43:07 WORKER: registered result for job (4, 0, 26) with dispatcher
17:43:07 DISPATCHER: job (4, 0, 26) finished
17:43:07 DISPATCHER: register_result: lock acquired
17:43:07 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
17:43:07 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.04878897271147908, 'num_filters_1': 31, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.05253799549070092, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 112, 'num_filters_3': 26, 'num_filters_4': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.261635712777855, 'info': {'data05': 0.261635712777855, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.04878897271147908, 'num_filters_1': 31, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.05253799549070092, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 112, 'num_filters_3': 26, 'num_filters_4': 16}"}}
exception: None

17:43:07 job_callback for (4, 0, 26) started
17:43:07 DISPATCHER: Trying to submit another job.
17:43:07 job_callback for (4, 0, 26) got condition
17:43:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:43:07 done building a new model for budget 44.444444 based on 17/45 split
Best loss for this budget:-0.913880





17:43:07 HBMASTER: Trying to run another job!
17:43:07 job_callback for (4, 0, 26) finished
17:43:07 ITERATION: Advancing config (4, 0, 1) to next budget 133.333333
17:43:07 ITERATION: Advancing config (4, 0, 3) to next budget 133.333333
17:43:07 ITERATION: Advancing config (4, 0, 4) to next budget 133.333333
17:43:07 ITERATION: Advancing config (4, 0, 11) to next budget 133.333333
17:43:07 ITERATION: Advancing config (4, 0, 16) to next budget 133.333333
17:43:07 ITERATION: Advancing config (4, 0, 18) to next budget 133.333333
17:43:07 ITERATION: Advancing config (4, 0, 21) to next budget 133.333333
17:43:07 ITERATION: Advancing config (4, 0, 22) to next budget 133.333333
17:43:07 ITERATION: Advancing config (4, 0, 25) to next budget 133.333333
17:43:07 HBMASTER: schedule new run for iteration 4
17:43:07 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
17:43:07 HBMASTER: submitting job (4, 0, 1) to dispatcher
17:43:07 DISPATCHER: trying to submit job (4, 0, 1)
17:43:07 DISPATCHER: trying to notify the job_runner thread.
17:43:07 HBMASTER: job (4, 0, 1) submitted to dispatcher
17:43:07 DISPATCHER: Trying to submit another job.
17:43:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:43:07 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:43:07 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:43:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:43:07 WORKER: start processing job (4, 0, 1)
17:43:07 WORKER: args: ()
17:43:07 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0010758202227436264, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.11833085349976714, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 30, 'num_filters_3': 108}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:43:50 DISPATCHER: Starting worker discovery
17:43:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:43:50 DISPATCHER: Finished worker discovery
17:44:50 DISPATCHER: Starting worker discovery
17:44:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:44:50 DISPATCHER: Finished worker discovery
17:45:37 WORKER: done with job (4, 0, 1), trying to register it.
17:45:37 WORKER: registered result for job (4, 0, 1) with dispatcher
17:45:37 DISPATCHER: job (4, 0, 1) finished
17:45:37 DISPATCHER: register_result: lock acquired
17:45:37 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
17:45:37 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0010758202227436264, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.11833085349976714, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 30, 'num_filters_3': 108}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3996112404096843, 'info': {'data05': 0.3996112404096843, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0010758202227436264, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.11833085349976714, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 30, 'num_filters_3': 108}"}}
exception: None

17:45:37 job_callback for (4, 0, 1) started
17:45:37 DISPATCHER: Trying to submit another job.
17:45:37 job_callback for (4, 0, 1) got condition
17:45:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:45:37 HBMASTER: Trying to run another job!
17:45:37 job_callback for (4, 0, 1) finished
17:45:37 HBMASTER: schedule new run for iteration 4
17:45:37 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
17:45:37 HBMASTER: submitting job (4, 0, 3) to dispatcher
17:45:37 DISPATCHER: trying to submit job (4, 0, 3)
17:45:37 DISPATCHER: trying to notify the job_runner thread.
17:45:37 HBMASTER: job (4, 0, 3) submitted to dispatcher
17:45:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:45:37 DISPATCHER: Trying to submit another job.
17:45:37 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:45:37 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:45:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:45:37 WORKER: start processing job (4, 0, 3)
17:45:37 WORKER: args: ()
17:45:37 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.00934515986129614, 'num_filters_1': 119, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.011284311760125816, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 48, 'num_filters_3': 53, 'num_filters_4': 100}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:45:50 DISPATCHER: Starting worker discovery
17:45:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:45:50 DISPATCHER: Finished worker discovery
17:46:50 DISPATCHER: Starting worker discovery
17:46:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:46:50 DISPATCHER: Finished worker discovery
17:47:50 DISPATCHER: Starting worker discovery
17:47:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:47:50 DISPATCHER: Finished worker discovery
17:48:05 WORKER: done with job (4, 0, 3), trying to register it.
17:48:05 WORKER: registered result for job (4, 0, 3) with dispatcher
17:48:05 DISPATCHER: job (4, 0, 3) finished
17:48:05 DISPATCHER: register_result: lock acquired
17:48:05 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
17:48:05 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.00934515986129614, 'num_filters_1': 119, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.011284311760125816, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 48, 'num_filters_3': 53, 'num_filters_4': 100}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.89006795772402, 'info': {'data05': 0.89006795772402, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.00934515986129614, 'num_filters_1': 119, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.011284311760125816, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 48, 'num_filters_3': 53, 'num_filters_4': 100}"}}
exception: None

17:48:05 job_callback for (4, 0, 3) started
17:48:05 DISPATCHER: Trying to submit another job.
17:48:05 job_callback for (4, 0, 3) got condition
17:48:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:48:05 HBMASTER: Trying to run another job!
17:48:05 job_callback for (4, 0, 3) finished
17:48:05 HBMASTER: schedule new run for iteration 4
17:48:05 HBMASTER: trying submitting job (4, 0, 4) to dispatcher
17:48:05 HBMASTER: submitting job (4, 0, 4) to dispatcher
17:48:05 DISPATCHER: trying to submit job (4, 0, 4)
17:48:05 DISPATCHER: trying to notify the job_runner thread.
17:48:05 HBMASTER: job (4, 0, 4) submitted to dispatcher
17:48:05 DISPATCHER: Trying to submit another job.
17:48:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:48:05 DISPATCHER: starting job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:48:05 DISPATCHER: job (4, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:48:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:48:05 WORKER: start processing job (4, 0, 4)
17:48:05 WORKER: args: ()
17:48:05 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00537766344793745, 'num_filters_1': 40, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.013397535865848699, 'kernel_size_2': 7, 'num_filters_2': 71}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:48:50 DISPATCHER: Starting worker discovery
17:48:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:48:50 DISPATCHER: Finished worker discovery
17:49:50 DISPATCHER: Starting worker discovery
17:49:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:49:50 DISPATCHER: Finished worker discovery
17:50:35 WORKER: done with job (4, 0, 4), trying to register it.
17:50:35 WORKER: registered result for job (4, 0, 4) with dispatcher
17:50:35 DISPATCHER: job (4, 0, 4) finished
17:50:35 DISPATCHER: register_result: lock acquired
17:50:35 DISPATCHER: job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
17:50:35 job_id: (4, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00537766344793745, 'num_filters_1': 40, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.013397535865848699, 'kernel_size_2': 7, 'num_filters_2': 71}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.18367059943394612, 'info': {'data05': 0.18367059943394612, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00537766344793745, 'num_filters_1': 40, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.013397535865848699, 'kernel_size_2': 7, 'num_filters_2': 71}"}}
exception: None

17:50:35 job_callback for (4, 0, 4) started
17:50:35 job_callback for (4, 0, 4) got condition
17:50:35 DISPATCHER: Trying to submit another job.
17:50:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:50:35 HBMASTER: Trying to run another job!
17:50:35 job_callback for (4, 0, 4) finished
17:50:35 HBMASTER: schedule new run for iteration 4
17:50:35 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
17:50:35 HBMASTER: submitting job (4, 0, 11) to dispatcher
17:50:35 DISPATCHER: trying to submit job (4, 0, 11)
17:50:35 DISPATCHER: trying to notify the job_runner thread.
17:50:35 HBMASTER: job (4, 0, 11) submitted to dispatcher
17:50:35 DISPATCHER: Trying to submit another job.
17:50:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:50:35 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:50:35 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:50:35 WORKER: start processing job (4, 0, 11)
17:50:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:50:35 WORKER: args: ()
17:50:35 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.01599148313803213, 'num_filters_1': 89, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.011187402399934196, 'kernel_size_2': 3, 'num_filters_2': 63}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:50:50 DISPATCHER: Starting worker discovery
17:50:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:50:50 DISPATCHER: Finished worker discovery
17:51:50 DISPATCHER: Starting worker discovery
17:51:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:51:50 DISPATCHER: Finished worker discovery
17:52:50 DISPATCHER: Starting worker discovery
17:52:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:52:50 DISPATCHER: Finished worker discovery
17:53:09 WORKER: done with job (4, 0, 11), trying to register it.
17:53:09 WORKER: registered result for job (4, 0, 11) with dispatcher
17:53:09 DISPATCHER: job (4, 0, 11) finished
17:53:09 DISPATCHER: register_result: lock acquired
17:53:09 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
17:53:09 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.01599148313803213, 'num_filters_1': 89, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.011187402399934196, 'kernel_size_2': 3, 'num_filters_2': 63}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.23742186542616422, 'info': {'data05': 0.23742186542616422, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.01599148313803213, 'num_filters_1': 89, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.011187402399934196, 'kernel_size_2': 3, 'num_filters_2': 63}"}}
exception: None

17:53:09 job_callback for (4, 0, 11) started
17:53:09 job_callback for (4, 0, 11) got condition
17:53:09 DISPATCHER: Trying to submit another job.
17:53:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:53:09 HBMASTER: Trying to run another job!
17:53:09 job_callback for (4, 0, 11) finished
17:53:09 HBMASTER: schedule new run for iteration 4
17:53:09 HBMASTER: trying submitting job (4, 0, 16) to dispatcher
17:53:09 HBMASTER: submitting job (4, 0, 16) to dispatcher
17:53:09 DISPATCHER: trying to submit job (4, 0, 16)
17:53:09 DISPATCHER: trying to notify the job_runner thread.
17:53:09 HBMASTER: job (4, 0, 16) submitted to dispatcher
17:53:09 DISPATCHER: Trying to submit another job.
17:53:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:53:09 DISPATCHER: starting job (4, 0, 16) on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:53:09 DISPATCHER: job (4, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:53:09 WORKER: start processing job (4, 0, 16)
17:53:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:53:09 WORKER: args: ()
17:53:09 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.019839331903950982, 'num_filters_1': 105, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.012093105752489773, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 42, 'num_filters_3': 16, 'num_filters_4': 56}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:53:50 DISPATCHER: Starting worker discovery
17:53:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:53:50 DISPATCHER: Finished worker discovery
17:54:50 DISPATCHER: Starting worker discovery
17:54:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:54:50 DISPATCHER: Finished worker discovery
17:55:38 WORKER: done with job (4, 0, 16), trying to register it.
17:55:38 WORKER: registered result for job (4, 0, 16) with dispatcher
17:55:38 DISPATCHER: job (4, 0, 16) finished
17:55:38 DISPATCHER: register_result: lock acquired
17:55:38 DISPATCHER: job (4, 0, 16) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
17:55:38 job_id: (4, 0, 16)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.019839331903950982, 'num_filters_1': 105, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.012093105752489773, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 42, 'num_filters_3': 16, 'num_filters_4': 56}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.819584030704958, 'info': {'data05': 0.819584030704958, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.019839331903950982, 'num_filters_1': 105, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.012093105752489773, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 42, 'num_filters_3': 16, 'num_filters_4': 56}"}}
exception: None

17:55:38 job_callback for (4, 0, 16) started
17:55:38 DISPATCHER: Trying to submit another job.
17:55:38 job_callback for (4, 0, 16) got condition
17:55:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:55:38 HBMASTER: Trying to run another job!
17:55:38 job_callback for (4, 0, 16) finished
17:55:38 HBMASTER: schedule new run for iteration 4
17:55:38 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
17:55:38 HBMASTER: submitting job (4, 0, 18) to dispatcher
17:55:38 DISPATCHER: trying to submit job (4, 0, 18)
17:55:38 DISPATCHER: trying to notify the job_runner thread.
17:55:38 HBMASTER: job (4, 0, 18) submitted to dispatcher
17:55:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:55:38 DISPATCHER: Trying to submit another job.
17:55:38 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:55:38 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:55:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:55:38 WORKER: start processing job (4, 0, 18)
17:55:38 WORKER: args: ()
17:55:38 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.020241998072504448, 'num_filters_1': 70, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.020874454414507332, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 90, 'num_filters_3': 77}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:55:50 DISPATCHER: Starting worker discovery
17:55:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:55:50 DISPATCHER: Finished worker discovery
17:56:50 DISPATCHER: Starting worker discovery
17:56:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:56:50 DISPATCHER: Finished worker discovery
17:57:50 DISPATCHER: Starting worker discovery
17:57:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:57:50 DISPATCHER: Finished worker discovery
17:58:28 WORKER: done with job (4, 0, 18), trying to register it.
17:58:28 WORKER: registered result for job (4, 0, 18) with dispatcher
17:58:28 DISPATCHER: job (4, 0, 18) finished
17:58:28 DISPATCHER: register_result: lock acquired
17:58:28 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
17:58:28 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.020241998072504448, 'num_filters_1': 70, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.020874454414507332, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 90, 'num_filters_3': 77}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.332824684201594, 'info': {'data05': 0.332824684201594, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.020241998072504448, 'num_filters_1': 70, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.020874454414507332, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 90, 'num_filters_3': 77}"}}
exception: None

17:58:28 job_callback for (4, 0, 18) started
17:58:28 DISPATCHER: Trying to submit another job.
17:58:28 job_callback for (4, 0, 18) got condition
17:58:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:58:28 HBMASTER: Trying to run another job!
17:58:28 job_callback for (4, 0, 18) finished
17:58:28 HBMASTER: schedule new run for iteration 4
17:58:28 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
17:58:28 HBMASTER: submitting job (4, 0, 21) to dispatcher
17:58:28 DISPATCHER: trying to submit job (4, 0, 21)
17:58:28 DISPATCHER: trying to notify the job_runner thread.
17:58:28 HBMASTER: job (4, 0, 21) submitted to dispatcher
17:58:28 DISPATCHER: Trying to submit another job.
17:58:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:58:28 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:58:28 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:58:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:58:28 WORKER: start processing job (4, 0, 21)
17:58:28 WORKER: args: ()
17:58:28 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.004343289886423112, 'num_filters_1': 44, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.026659560054470163, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 37, 'num_filters_3': 113}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:58:50 DISPATCHER: Starting worker discovery
17:58:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:58:50 DISPATCHER: Finished worker discovery
17:59:50 DISPATCHER: Starting worker discovery
17:59:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:59:50 DISPATCHER: Finished worker discovery
18:00:50 DISPATCHER: Starting worker discovery
18:00:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:00:50 DISPATCHER: Finished worker discovery
18:00:59 WORKER: done with job (4, 0, 21), trying to register it.
18:00:59 WORKER: registered result for job (4, 0, 21) with dispatcher
18:00:59 DISPATCHER: job (4, 0, 21) finished
18:00:59 DISPATCHER: register_result: lock acquired
18:00:59 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
18:00:59 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.004343289886423112, 'num_filters_1': 44, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.026659560054470163, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 37, 'num_filters_3': 113}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.565090835931614, 'info': {'data05': 0.565090835931614, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.004343289886423112, 'num_filters_1': 44, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.026659560054470163, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 37, 'num_filters_3': 113}"}}
exception: None

18:00:59 job_callback for (4, 0, 21) started
18:00:59 DISPATCHER: Trying to submit another job.
18:00:59 job_callback for (4, 0, 21) got condition
18:00:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:00:59 HBMASTER: Trying to run another job!
18:00:59 job_callback for (4, 0, 21) finished
18:00:59 HBMASTER: schedule new run for iteration 4
18:00:59 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
18:00:59 HBMASTER: submitting job (4, 0, 22) to dispatcher
18:00:59 DISPATCHER: trying to submit job (4, 0, 22)
18:00:59 DISPATCHER: trying to notify the job_runner thread.
18:00:59 HBMASTER: job (4, 0, 22) submitted to dispatcher
18:00:59 DISPATCHER: Trying to submit another job.
18:00:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:00:59 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.13101140314513094464
18:00:59 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
18:00:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:00:59 WORKER: start processing job (4, 0, 22)
18:00:59 WORKER: args: ()
18:00:59 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.00960784543900048, 'num_filters_1': 72, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.02323486822937134, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 100, 'num_filters_3': 48, 'num_filters_4': 45}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:01:50 DISPATCHER: Starting worker discovery
18:01:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:01:50 DISPATCHER: Finished worker discovery
18:02:50 DISPATCHER: Starting worker discovery
18:02:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:02:50 DISPATCHER: Finished worker discovery
18:03:36 WORKER: done with job (4, 0, 22), trying to register it.
18:03:36 WORKER: registered result for job (4, 0, 22) with dispatcher
18:03:36 DISPATCHER: job (4, 0, 22) finished
18:03:36 DISPATCHER: register_result: lock acquired
18:03:36 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
18:03:36 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.00960784543900048, 'num_filters_1': 72, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.02323486822937134, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 100, 'num_filters_3': 48, 'num_filters_4': 45}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8286190722214033, 'info': {'data05': 0.8286190722214033, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.00960784543900048, 'num_filters_1': 72, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.02323486822937134, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 100, 'num_filters_3': 48, 'num_filters_4': 45}"}}
exception: None

18:03:36 job_callback for (4, 0, 22) started
18:03:36 DISPATCHER: Trying to submit another job.
18:03:36 job_callback for (4, 0, 22) got condition
18:03:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:03:36 HBMASTER: Trying to run another job!
18:03:36 job_callback for (4, 0, 22) finished
18:03:36 HBMASTER: schedule new run for iteration 4
18:03:36 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
18:03:36 HBMASTER: submitting job (4, 0, 25) to dispatcher
18:03:36 DISPATCHER: trying to submit job (4, 0, 25)
18:03:36 DISPATCHER: trying to notify the job_runner thread.
18:03:36 HBMASTER: job (4, 0, 25) submitted to dispatcher
18:03:36 DISPATCHER: Trying to submit another job.
18:03:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:03:36 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.13101140314513094464
18:03:36 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
18:03:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:03:36 WORKER: start processing job (4, 0, 25)
18:03:36 WORKER: args: ()
18:03:36 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0010518236217560456, 'num_filters_1': 57, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.02553361033774518, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 26, 'num_filters_3': 30, 'num_filters_4': 20}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:03:50 DISPATCHER: Starting worker discovery
18:03:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:03:50 DISPATCHER: Finished worker discovery
18:04:50 DISPATCHER: Starting worker discovery
18:04:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:04:50 DISPATCHER: Finished worker discovery
18:05:50 DISPATCHER: Starting worker discovery
18:05:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:05:50 DISPATCHER: Finished worker discovery
18:06:04 WORKER: done with job (4, 0, 25), trying to register it.
18:06:04 WORKER: registered result for job (4, 0, 25) with dispatcher
18:06:04 DISPATCHER: job (4, 0, 25) finished
18:06:04 DISPATCHER: register_result: lock acquired
18:06:04 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
18:06:04 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0010518236217560456, 'num_filters_1': 57, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.02553361033774518, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 26, 'num_filters_3': 30, 'num_filters_4': 20}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8911766208846931, 'info': {'data05': 0.8911766208846931, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0010518236217560456, 'num_filters_1': 57, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.02553361033774518, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 26, 'num_filters_3': 30, 'num_filters_4': 20}"}}
exception: None

18:06:04 job_callback for (4, 0, 25) started
18:06:04 DISPATCHER: Trying to submit another job.
18:06:04 job_callback for (4, 0, 25) got condition
18:06:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:06:04 HBMASTER: Trying to run another job!
18:06:04 job_callback for (4, 0, 25) finished
18:06:04 ITERATION: Advancing config (4, 0, 3) to next budget 400.000000
18:06:04 ITERATION: Advancing config (4, 0, 22) to next budget 400.000000
18:06:04 ITERATION: Advancing config (4, 0, 25) to next budget 400.000000
18:06:04 HBMASTER: schedule new run for iteration 4
18:06:04 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
18:06:04 HBMASTER: submitting job (4, 0, 3) to dispatcher
18:06:04 DISPATCHER: trying to submit job (4, 0, 3)
18:06:04 DISPATCHER: trying to notify the job_runner thread.
18:06:04 HBMASTER: job (4, 0, 3) submitted to dispatcher
18:06:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:06:04 DISPATCHER: Trying to submit another job.
18:06:04 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
18:06:04 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
18:06:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:06:04 WORKER: start processing job (4, 0, 3)
18:06:04 WORKER: args: ()
18:06:04 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.00934515986129614, 'num_filters_1': 119, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.011284311760125816, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 48, 'num_filters_3': 53, 'num_filters_4': 100}, 'budget': 400.0, 'working_directory': '.'}
18:06:50 DISPATCHER: Starting worker discovery
18:06:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:06:50 DISPATCHER: Finished worker discovery
18:07:50 DISPATCHER: Starting worker discovery
18:07:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:07:50 DISPATCHER: Finished worker discovery
18:08:50 DISPATCHER: Starting worker discovery
18:08:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:08:50 DISPATCHER: Finished worker discovery
18:09:50 DISPATCHER: Starting worker discovery
18:09:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:09:50 DISPATCHER: Finished worker discovery
18:10:50 DISPATCHER: Starting worker discovery
18:10:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:10:50 DISPATCHER: Finished worker discovery
18:11:50 DISPATCHER: Starting worker discovery
18:11:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:11:50 DISPATCHER: Finished worker discovery
18:12:50 DISPATCHER: Starting worker discovery
18:12:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:12:50 DISPATCHER: Finished worker discovery
18:13:08 WORKER: done with job (4, 0, 3), trying to register it.
18:13:08 WORKER: registered result for job (4, 0, 3) with dispatcher
18:13:08 DISPATCHER: job (4, 0, 3) finished
18:13:08 DISPATCHER: register_result: lock acquired
18:13:08 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
18:13:08 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.00934515986129614, 'num_filters_1': 119, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.011284311760125816, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 48, 'num_filters_3': 53, 'num_filters_4': 100}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8623314497518461, 'info': {'data05': 0.8623314497518461, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.00934515986129614, 'num_filters_1': 119, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.011284311760125816, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 48, 'num_filters_3': 53, 'num_filters_4': 100}"}}
exception: None

18:13:08 job_callback for (4, 0, 3) started
18:13:08 DISPATCHER: Trying to submit another job.
18:13:08 job_callback for (4, 0, 3) got condition
18:13:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:13:08 Only 13 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
18:13:08 HBMASTER: Trying to run another job!
18:13:08 job_callback for (4, 0, 3) finished
18:13:08 HBMASTER: schedule new run for iteration 4
18:13:08 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
18:13:08 HBMASTER: submitting job (4, 0, 22) to dispatcher
18:13:08 DISPATCHER: trying to submit job (4, 0, 22)
18:13:08 DISPATCHER: trying to notify the job_runner thread.
18:13:08 HBMASTER: job (4, 0, 22) submitted to dispatcher
18:13:08 DISPATCHER: Trying to submit another job.
18:13:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:13:08 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.13101140314513094464
18:13:08 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
18:13:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:13:08 WORKER: start processing job (4, 0, 22)
18:13:08 WORKER: args: ()
18:13:08 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.00960784543900048, 'num_filters_1': 72, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.02323486822937134, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 100, 'num_filters_3': 48, 'num_filters_4': 45}, 'budget': 400.0, 'working_directory': '.'}
18:13:50 DISPATCHER: Starting worker discovery
18:13:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:13:50 DISPATCHER: Finished worker discovery
18:14:50 DISPATCHER: Starting worker discovery
18:14:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:14:50 DISPATCHER: Finished worker discovery
18:15:50 DISPATCHER: Starting worker discovery
18:15:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:15:50 DISPATCHER: Finished worker discovery
18:16:50 DISPATCHER: Starting worker discovery
18:16:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:16:50 DISPATCHER: Finished worker discovery
18:17:50 DISPATCHER: Starting worker discovery
18:17:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:17:50 DISPATCHER: Finished worker discovery
18:18:50 DISPATCHER: Starting worker discovery
18:18:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:18:50 DISPATCHER: Finished worker discovery
18:19:50 DISPATCHER: Starting worker discovery
18:19:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:19:50 DISPATCHER: Finished worker discovery
18:20:36 WORKER: done with job (4, 0, 22), trying to register it.
18:20:36 WORKER: registered result for job (4, 0, 22) with dispatcher
18:20:36 DISPATCHER: job (4, 0, 22) finished
18:20:36 DISPATCHER: register_result: lock acquired
18:20:36 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
18:20:36 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.00960784543900048, 'num_filters_1': 72, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.02323486822937134, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 100, 'num_filters_3': 48, 'num_filters_4': 45}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8102009852766846, 'info': {'data05': 0.8102009852766846, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.00960784543900048, 'num_filters_1': 72, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.02323486822937134, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 100, 'num_filters_3': 48, 'num_filters_4': 45}"}}
exception: None

18:20:36 job_callback for (4, 0, 22) started
18:20:36 job_callback for (4, 0, 22) got condition
18:20:36 DISPATCHER: Trying to submit another job.
18:20:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:20:36 Only 14 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
18:20:36 HBMASTER: Trying to run another job!
18:20:36 job_callback for (4, 0, 22) finished
18:20:36 HBMASTER: schedule new run for iteration 4
18:20:36 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
18:20:36 HBMASTER: submitting job (4, 0, 25) to dispatcher
18:20:36 DISPATCHER: trying to submit job (4, 0, 25)
18:20:36 DISPATCHER: trying to notify the job_runner thread.
18:20:36 HBMASTER: job (4, 0, 25) submitted to dispatcher
18:20:36 DISPATCHER: Trying to submit another job.
18:20:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:20:36 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.13101140314513094464
18:20:36 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
18:20:36 WORKER: start processing job (4, 0, 25)
18:20:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:20:36 WORKER: args: ()
18:20:36 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0010518236217560456, 'num_filters_1': 57, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.02553361033774518, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 26, 'num_filters_3': 30, 'num_filters_4': 20}, 'budget': 400.0, 'working_directory': '.'}
18:20:50 DISPATCHER: Starting worker discovery
18:20:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:20:50 DISPATCHER: Finished worker discovery
18:21:50 DISPATCHER: Starting worker discovery
18:21:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:21:50 DISPATCHER: Finished worker discovery
18:22:50 DISPATCHER: Starting worker discovery
18:22:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:22:50 DISPATCHER: Finished worker discovery
18:23:50 DISPATCHER: Starting worker discovery
18:23:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:23:50 DISPATCHER: Finished worker discovery
18:24:50 DISPATCHER: Starting worker discovery
18:24:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:24:50 DISPATCHER: Finished worker discovery
18:25:50 DISPATCHER: Starting worker discovery
18:25:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:25:50 DISPATCHER: Finished worker discovery
18:26:50 DISPATCHER: Starting worker discovery
18:26:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:26:50 DISPATCHER: Finished worker discovery
18:27:35 WORKER: done with job (4, 0, 25), trying to register it.
18:27:35 WORKER: registered result for job (4, 0, 25) with dispatcher
18:27:35 DISPATCHER: job (4, 0, 25) finished
18:27:35 DISPATCHER: register_result: lock acquired
18:27:35 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
18:27:35 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0010518236217560456, 'num_filters_1': 57, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.02553361033774518, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 26, 'num_filters_3': 30, 'num_filters_4': 20}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7704750707440716, 'info': {'data05': 0.7704750707440716, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0010518236217560456, 'num_filters_1': 57, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.02553361033774518, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 26, 'num_filters_3': 30, 'num_filters_4': 20}"}}
exception: None

18:27:35 job_callback for (4, 0, 25) started
18:27:35 DISPATCHER: Trying to submit another job.
18:27:35 job_callback for (4, 0, 25) got condition
18:27:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:27:35 Only 15 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
18:27:35 HBMASTER: Trying to run another job!
18:27:35 job_callback for (4, 0, 25) finished
18:27:35 ITERATION: Advancing config (4, 0, 3) to next budget 1200.000000
18:27:35 HBMASTER: schedule new run for iteration 4
18:27:35 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
18:27:35 HBMASTER: submitting job (4, 0, 3) to dispatcher
18:27:35 DISPATCHER: trying to submit job (4, 0, 3)
18:27:35 DISPATCHER: trying to notify the job_runner thread.
18:27:35 HBMASTER: job (4, 0, 3) submitted to dispatcher
18:27:35 DISPATCHER: Trying to submit another job.
18:27:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:27:35 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
18:27:35 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
18:27:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:27:35 WORKER: start processing job (4, 0, 3)
18:27:35 WORKER: args: ()
18:27:35 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.00934515986129614, 'num_filters_1': 119, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.011284311760125816, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 48, 'num_filters_3': 53, 'num_filters_4': 100}, 'budget': 1200.0, 'working_directory': '.'}
18:27:50 DISPATCHER: Starting worker discovery
18:27:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:27:50 DISPATCHER: Finished worker discovery
18:28:50 DISPATCHER: Starting worker discovery
18:28:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:28:50 DISPATCHER: Finished worker discovery
18:29:50 DISPATCHER: Starting worker discovery
18:29:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:29:50 DISPATCHER: Finished worker discovery
18:30:50 DISPATCHER: Starting worker discovery
18:30:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:30:50 DISPATCHER: Finished worker discovery
18:31:50 DISPATCHER: Starting worker discovery
18:31:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:31:50 DISPATCHER: Finished worker discovery
18:32:50 DISPATCHER: Starting worker discovery
18:32:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:32:50 DISPATCHER: Finished worker discovery
18:33:50 DISPATCHER: Starting worker discovery
18:33:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:33:50 DISPATCHER: Finished worker discovery
18:34:50 DISPATCHER: Starting worker discovery
18:34:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:34:50 DISPATCHER: Finished worker discovery
18:35:50 DISPATCHER: Starting worker discovery
18:35:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:35:50 DISPATCHER: Finished worker discovery
18:36:50 DISPATCHER: Starting worker discovery
18:36:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:36:50 DISPATCHER: Finished worker discovery
18:37:50 DISPATCHER: Starting worker discovery
18:37:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:37:50 DISPATCHER: Finished worker discovery
18:38:50 DISPATCHER: Starting worker discovery
18:38:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:38:50 DISPATCHER: Finished worker discovery
18:39:50 DISPATCHER: Starting worker discovery
18:39:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:39:50 DISPATCHER: Finished worker discovery
18:40:50 DISPATCHER: Starting worker discovery
18:40:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:40:50 DISPATCHER: Finished worker discovery
18:41:50 DISPATCHER: Starting worker discovery
18:41:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:41:50 DISPATCHER: Finished worker discovery
18:42:50 DISPATCHER: Starting worker discovery
18:42:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:42:50 DISPATCHER: Finished worker discovery
18:43:50 DISPATCHER: Starting worker discovery
18:43:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:43:50 DISPATCHER: Finished worker discovery
18:44:50 DISPATCHER: Starting worker discovery
18:44:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:44:50 DISPATCHER: Finished worker discovery
18:45:50 DISPATCHER: Starting worker discovery
18:45:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:45:50 DISPATCHER: Finished worker discovery
18:46:50 DISPATCHER: Starting worker discovery
18:46:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:46:50 DISPATCHER: Finished worker discovery
18:47:50 DISPATCHER: Starting worker discovery
18:47:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:47:51 DISPATCHER: Finished worker discovery
18:48:27 WORKER: done with job (4, 0, 3), trying to register it.
18:48:27 WORKER: registered result for job (4, 0, 3) with dispatcher
18:48:27 DISPATCHER: job (4, 0, 3) finished
18:48:27 DISPATCHER: register_result: lock acquired
18:48:27 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
18:48:27 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.00934515986129614, 'num_filters_1': 119, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.011284311760125816, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 48, 'num_filters_3': 53, 'num_filters_4': 100}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.7745272725399818, 'info': {'data05': 0.7745272725399818, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.00934515986129614, 'num_filters_1': 119, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.011284311760125816, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 48, 'num_filters_3': 53, 'num_filters_4': 100}"}}
exception: None

18:48:27 job_callback for (4, 0, 3) started
18:48:27 DISPATCHER: Trying to submit another job.
18:48:27 job_callback for (4, 0, 3) got condition
18:48:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:48:27 Only 9 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
18:48:27 HBMASTER: Trying to run another job!
18:48:27 job_callback for (4, 0, 3) finished
18:48:27 start sampling a new configuration.
18:48:27 best_vector: [0, 1, 0.02786084464790481, 0.19974709577814656, 0.5250750435324584, 1, 0.7769827683428565, 0.060385311788626994, 2, 2, 1, 0, 0.8887871118492668, 0.47189459966536196, 0.24324139943928302, 0.42551713677079434], 1.0741464756774613e-27, 9.30971727453933e-06, -2.0362427808484247e-07
18:48:27 done sampling a new configuration.
18:48:27 HBMASTER: schedule new run for iteration 5
18:48:27 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
18:48:27 HBMASTER: submitting job (5, 0, 0) to dispatcher
18:48:27 DISPATCHER: trying to submit job (5, 0, 0)
18:48:27 DISPATCHER: trying to notify the job_runner thread.
18:48:27 HBMASTER: job (5, 0, 0) submitted to dispatcher
18:48:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:48:27 DISPATCHER: Trying to submit another job.
18:48:27 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
18:48:27 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
18:48:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:48:27 WORKER: start processing job (5, 0, 0)
18:48:27 WORKER: args: ()
18:48:27 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0011368984890336796, 'num_filters_1': 24, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.011982932196393205, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 102, 'num_filters_3': 42}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:48:51 DISPATCHER: Starting worker discovery
18:48:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:48:51 DISPATCHER: Finished worker discovery
18:49:51 DISPATCHER: Starting worker discovery
18:49:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:49:51 DISPATCHER: Finished worker discovery
18:50:51 DISPATCHER: Starting worker discovery
18:50:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:50:51 DISPATCHER: Finished worker discovery
18:50:57 WORKER: done with job (5, 0, 0), trying to register it.
18:50:57 WORKER: registered result for job (5, 0, 0) with dispatcher
18:50:57 DISPATCHER: job (5, 0, 0) finished
18:50:57 DISPATCHER: register_result: lock acquired
18:50:57 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
18:50:57 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0011368984890336796, 'num_filters_1': 24, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.011982932196393205, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 102, 'num_filters_3': 42}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6822089301078174, 'info': {'data05': 0.6822089301078174, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0011368984890336796, 'num_filters_1': 24, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.011982932196393205, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 102, 'num_filters_3': 42}"}}
exception: None

18:50:57 job_callback for (5, 0, 0) started
18:50:57 job_callback for (5, 0, 0) got condition
18:50:57 DISPATCHER: Trying to submit another job.
18:50:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:50:57 HBMASTER: Trying to run another job!
18:50:57 job_callback for (5, 0, 0) finished
18:50:57 start sampling a new configuration.
18:50:57 done sampling a new configuration.
18:50:57 HBMASTER: schedule new run for iteration 5
18:50:57 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
18:50:57 HBMASTER: submitting job (5, 0, 1) to dispatcher
18:50:57 DISPATCHER: trying to submit job (5, 0, 1)
18:50:57 DISPATCHER: trying to notify the job_runner thread.
18:50:57 HBMASTER: job (5, 0, 1) submitted to dispatcher
18:50:57 DISPATCHER: Trying to submit another job.
18:50:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:50:57 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
18:50:57 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
18:50:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:50:57 WORKER: start processing job (5, 0, 1)
18:50:57 WORKER: args: ()
18:50:57 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0358522997550573, 'num_filters_1': 38, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.024018607564377546, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 41, 'num_filters_3': 26, 'num_filters_4': 38, 'num_filters_5': 19}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:51:51 DISPATCHER: Starting worker discovery
18:51:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:51:51 DISPATCHER: Finished worker discovery
18:52:51 DISPATCHER: Starting worker discovery
18:52:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:52:51 DISPATCHER: Finished worker discovery
18:53:25 WORKER: done with job (5, 0, 1), trying to register it.
18:53:25 WORKER: registered result for job (5, 0, 1) with dispatcher
18:53:25 DISPATCHER: job (5, 0, 1) finished
18:53:25 DISPATCHER: register_result: lock acquired
18:53:25 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
18:53:25 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0358522997550573, 'num_filters_1': 38, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.024018607564377546, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 41, 'num_filters_3': 26, 'num_filters_4': 38, 'num_filters_5': 19}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.000903075499120016, 'info': {'data05': 0.000903075499120016, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0358522997550573, 'num_filters_1': 38, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.024018607564377546, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 41, 'num_filters_3': 26, 'num_filters_4': 38, 'num_filters_5': 19}"}}
exception: None

18:53:25 job_callback for (5, 0, 1) started
18:53:25 job_callback for (5, 0, 1) got condition
18:53:25 DISPATCHER: Trying to submit another job.
18:53:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:53:25 HBMASTER: Trying to run another job!
18:53:25 job_callback for (5, 0, 1) finished
18:53:25 start sampling a new configuration.
18:53:25 done sampling a new configuration.
18:53:25 HBMASTER: schedule new run for iteration 5
18:53:25 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
18:53:25 HBMASTER: submitting job (5, 0, 2) to dispatcher
18:53:25 DISPATCHER: trying to submit job (5, 0, 2)
18:53:25 DISPATCHER: trying to notify the job_runner thread.
18:53:25 HBMASTER: job (5, 0, 2) submitted to dispatcher
18:53:25 DISPATCHER: Trying to submit another job.
18:53:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:53:25 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
18:53:25 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
18:53:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:53:25 WORKER: start processing job (5, 0, 2)
18:53:25 WORKER: args: ()
18:53:25 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.01755903150891119, 'num_filters_1': 50, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.047245728748276226, 'kernel_size_2': 5, 'num_filters_2': 65}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:53:51 DISPATCHER: Starting worker discovery
18:53:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:53:51 DISPATCHER: Finished worker discovery
18:54:51 DISPATCHER: Starting worker discovery
18:54:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:54:51 DISPATCHER: Finished worker discovery
18:55:51 DISPATCHER: Starting worker discovery
18:55:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:55:51 DISPATCHER: Finished worker discovery
18:55:55 WORKER: done with job (5, 0, 2), trying to register it.
18:55:55 WORKER: registered result for job (5, 0, 2) with dispatcher
18:55:55 DISPATCHER: job (5, 0, 2) finished
18:55:55 DISPATCHER: register_result: lock acquired
18:55:55 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
18:55:55 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.01755903150891119, 'num_filters_1': 50, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.047245728748276226, 'kernel_size_2': 5, 'num_filters_2': 65}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.01755903150891119, 'num_filters_1': 50, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.047245728748276226, 'kernel_size_2': 5, 'num_filters_2': 65}"}}
exception: None

18:55:55 job_callback for (5, 0, 2) started
18:55:55 job_callback for (5, 0, 2) got condition
18:55:55 DISPATCHER: Trying to submit another job.
18:55:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:55:55 HBMASTER: Trying to run another job!
18:55:55 job_callback for (5, 0, 2) finished
18:55:55 start sampling a new configuration.
18:55:56 best_vector: [2, 1, 0.6020253125998085, 0.8064014160967263, 0.8154430950470822, 1, 0.45527933757674455, 0.28937852712770507, 1, 2, 0, 1, 0.6883828405621768, 0.5624898606942681, 0.007191196118695925, 0.7434149141800726], 1.612081811500792e-30, 0.00620315912546048, -3.295355633972992e-06
18:55:56 done sampling a new configuration.
18:55:56 HBMASTER: schedule new run for iteration 5
18:55:56 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
18:55:56 HBMASTER: submitting job (5, 0, 3) to dispatcher
18:55:56 DISPATCHER: trying to submit job (5, 0, 3)
18:55:56 DISPATCHER: trying to notify the job_runner thread.
18:55:56 HBMASTER: job (5, 0, 3) submitted to dispatcher
18:55:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:55:56 DISPATCHER: Trying to submit another job.
18:55:56 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
18:55:56 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
18:55:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:55:56 WORKER: start processing job (5, 0, 3)
18:55:56 WORKER: args: ()
18:55:56 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.015997444980905846, 'num_filters_1': 85, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.02379524298176432, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 66, 'num_filters_3': 51, 'num_filters_4': 16, 'num_filters_5': 75}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:56:51 DISPATCHER: Starting worker discovery
18:56:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:56:51 DISPATCHER: Finished worker discovery
18:57:51 DISPATCHER: Starting worker discovery
18:57:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:57:51 DISPATCHER: Finished worker discovery
18:58:24 WORKER: done with job (5, 0, 3), trying to register it.
18:58:24 WORKER: registered result for job (5, 0, 3) with dispatcher
18:58:24 DISPATCHER: job (5, 0, 3) finished
18:58:24 DISPATCHER: register_result: lock acquired
18:58:24 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
18:58:24 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.015997444980905846, 'num_filters_1': 85, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.02379524298176432, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 66, 'num_filters_3': 51, 'num_filters_4': 16, 'num_filters_5': 75}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8529238838751565, 'info': {'data05': 0.8529238838751565, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.015997444980905846, 'num_filters_1': 85, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.02379524298176432, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 66, 'num_filters_3': 51, 'num_filters_4': 16, 'num_filters_5': 75}"}}
exception: None

18:58:24 job_callback for (5, 0, 3) started
18:58:24 job_callback for (5, 0, 3) got condition
18:58:24 DISPATCHER: Trying to submit another job.
18:58:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:58:24 HBMASTER: Trying to run another job!
18:58:24 job_callback for (5, 0, 3) finished
18:58:24 start sampling a new configuration.
18:58:24 best_vector: [0, 1, 0.4425358509438048, 0.052593651999608027, 0.32431958738116556, 1, 0.030037215895465597, 0.4145514245061227, 2, 0, 1, 1, 0.5585218667205367, 0.8674219377034007, 0.5245186696958677, 0.8326981796772011], 2.9540032764562126e-29, 0.0003385236597298754, -5.795717652741338e-07
18:58:24 done sampling a new configuration.
18:58:24 HBMASTER: schedule new run for iteration 5
18:58:24 HBMASTER: trying submitting job (5, 0, 4) to dispatcher
18:58:24 HBMASTER: submitting job (5, 0, 4) to dispatcher
18:58:24 DISPATCHER: trying to submit job (5, 0, 4)
18:58:24 DISPATCHER: trying to notify the job_runner thread.
18:58:24 HBMASTER: job (5, 0, 4) submitted to dispatcher
18:58:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:58:24 DISPATCHER: Trying to submit another job.
18:58:24 DISPATCHER: starting job (5, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464
18:58:24 DISPATCHER: job (5, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
18:58:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:58:24 WORKER: start processing job (5, 0, 4)
18:58:24 WORKER: args: ()
18:58:24 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0076748819097053455, 'num_filters_1': 17, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.03462133721248001, 'kernel_size_2': 7, 'num_filters_2': 51}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:58:51 DISPATCHER: Starting worker discovery
18:58:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:58:51 DISPATCHER: Finished worker discovery
18:59:51 DISPATCHER: Starting worker discovery
18:59:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:59:51 DISPATCHER: Finished worker discovery
19:00:51 DISPATCHER: Starting worker discovery
19:00:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:00:51 DISPATCHER: Finished worker discovery
19:01:25 WORKER: done with job (5, 0, 4), trying to register it.
19:01:25 WORKER: registered result for job (5, 0, 4) with dispatcher
19:01:25 DISPATCHER: job (5, 0, 4) finished
19:01:25 DISPATCHER: register_result: lock acquired
19:01:25 DISPATCHER: job (5, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
19:01:25 job_id: (5, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0076748819097053455, 'num_filters_1': 17, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.03462133721248001, 'kernel_size_2': 7, 'num_filters_2': 51}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.22523695161448923, 'info': {'data05': 0.22523695161448923, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0076748819097053455, 'num_filters_1': 17, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.03462133721248001, 'kernel_size_2': 7, 'num_filters_2': 51}"}}
exception: None

19:01:25 job_callback for (5, 0, 4) started
19:01:25 job_callback for (5, 0, 4) got condition
19:01:25 DISPATCHER: Trying to submit another job.
19:01:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:01:25 HBMASTER: Trying to run another job!
19:01:25 job_callback for (5, 0, 4) finished
19:01:25 start sampling a new configuration.
19:01:25 best_vector: [3, 2, 0.7660540894813819, 0.06920833397457943, 0.9564105886635555, 1, 0.651943549806085, 0.303531188603119, 1, 1, 2, 1, 0.6593745570482411, 0.6632296702004135, 0.9205317543812114, 0.5859484335414753], 3.627640743223005e-29, 0.00027566125500937626, -7.143820479463709e-06
19:01:25 done sampling a new configuration.
19:01:25 HBMASTER: schedule new run for iteration 5
19:01:25 HBMASTER: trying submitting job (5, 0, 5) to dispatcher
19:01:25 HBMASTER: submitting job (5, 0, 5) to dispatcher
19:01:25 DISPATCHER: trying to submit job (5, 0, 5)
19:01:25 DISPATCHER: trying to notify the job_runner thread.
19:01:25 HBMASTER: job (5, 0, 5) submitted to dispatcher
19:01:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:01:25 DISPATCHER: Trying to submit another job.
19:01:25 DISPATCHER: starting job (5, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:01:25 DISPATCHER: job (5, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:01:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:01:25 WORKER: start processing job (5, 0, 5)
19:01:25 WORKER: args: ()
19:01:25 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.03404929929697212, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.024825795921904797, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 63, 'num_filters_3': 63, 'num_filters_4': 109, 'num_filters_5': 54}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:01:51 DISPATCHER: Starting worker discovery
19:01:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:01:51 DISPATCHER: Finished worker discovery
19:02:51 DISPATCHER: Starting worker discovery
19:02:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:02:51 DISPATCHER: Finished worker discovery
19:03:51 DISPATCHER: Starting worker discovery
19:03:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:03:51 DISPATCHER: Finished worker discovery
19:03:53 WORKER: done with job (5, 0, 5), trying to register it.
19:03:53 WORKER: registered result for job (5, 0, 5) with dispatcher
19:03:53 DISPATCHER: job (5, 0, 5) finished
19:03:53 DISPATCHER: register_result: lock acquired
19:03:53 DISPATCHER: job (5, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
19:03:53 job_id: (5, 0, 5)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.03404929929697212, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.024825795921904797, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 63, 'num_filters_3': 63, 'num_filters_4': 109, 'num_filters_5': 54}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5650857713190117, 'info': {'data05': 0.5650857713190117, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.03404929929697212, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.024825795921904797, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 63, 'num_filters_3': 63, 'num_filters_4': 109, 'num_filters_5': 54}"}}
exception: None

19:03:53 job_callback for (5, 0, 5) started
19:03:53 job_callback for (5, 0, 5) got condition
19:03:53 DISPATCHER: Trying to submit another job.
19:03:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:03:53 HBMASTER: Trying to run another job!
19:03:53 job_callback for (5, 0, 5) finished
19:03:53 start sampling a new configuration.
19:03:53 best_vector: [3, 2, 0.7685315162647683, 0.21008565344735275, 0.3164525233560486, 1, 0.16643745959356906, 0.8699940586955124, 1, 2, 2, 0, 0.20383497434289966, 0.9112182708593063, 0.21498257694368705, 0.7039362378630918], 8.575590190858375e-29, 0.00011661004989091076, -2.1892782162159784e-05
19:03:53 done sampling a new configuration.
19:03:53 HBMASTER: schedule new run for iteration 5
19:03:53 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
19:03:53 HBMASTER: submitting job (5, 0, 6) to dispatcher
19:03:53 DISPATCHER: trying to submit job (5, 0, 6)
19:03:53 DISPATCHER: trying to notify the job_runner thread.
19:03:53 HBMASTER: job (5, 0, 6) submitted to dispatcher
19:03:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:03:53 DISPATCHER: Trying to submit another job.
19:03:53 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:03:53 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:03:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:03:53 WORKER: start processing job (5, 0, 6)
19:03:53 WORKER: args: ()
19:03:53 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.03443999125689751, 'num_filters_1': 24, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.13548411113236883, 'kernel_size_2': 5, 'num_filters_2': 24}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:04:51 DISPATCHER: Starting worker discovery
19:04:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:04:51 DISPATCHER: Finished worker discovery
19:05:51 DISPATCHER: Starting worker discovery
19:05:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:05:51 DISPATCHER: Finished worker discovery
19:06:29 WORKER: done with job (5, 0, 6), trying to register it.
19:06:29 WORKER: registered result for job (5, 0, 6) with dispatcher
19:06:29 DISPATCHER: job (5, 0, 6) finished
19:06:29 DISPATCHER: register_result: lock acquired
19:06:29 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
19:06:29 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.03443999125689751, 'num_filters_1': 24, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.13548411113236883, 'kernel_size_2': 5, 'num_filters_2': 24}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.09378372548854508, 'info': {'data05': 0.09378372548854508, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.03443999125689751, 'num_filters_1': 24, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.13548411113236883, 'kernel_size_2': 5, 'num_filters_2': 24}"}}
exception: None

19:06:29 job_callback for (5, 0, 6) started
19:06:29 DISPATCHER: Trying to submit another job.
19:06:29 job_callback for (5, 0, 6) got condition
19:06:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:06:29 done building a new model for budget 133.333333 based on 17/28 split
Best loss for this budget:-0.891177





19:06:29 HBMASTER: Trying to run another job!
19:06:29 job_callback for (5, 0, 6) finished
19:06:29 start sampling a new configuration.
19:06:29 best_vector: [2, 2, 0.12049698218780291, 0.060352324359447054, 0.4633902744398812, 1, 0.5456404528176475, 0.2000386535321425, 1, 1, 2, 1, 0.5773859006022376, 0.9551316683658898, 0.40549180637717164, 0.7737942773531286], 2.1970805570018654e-30, 0.00455149446757018, -6.606349423674937e-12
19:06:29 done sampling a new configuration.
19:06:29 HBMASTER: schedule new run for iteration 5
19:06:29 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
19:06:29 HBMASTER: submitting job (5, 0, 7) to dispatcher
19:06:29 DISPATCHER: trying to submit job (5, 0, 7)
19:06:29 DISPATCHER: trying to notify the job_runner thread.
19:06:29 HBMASTER: job (5, 0, 7) submitted to dispatcher
19:06:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:06:29 DISPATCHER: Trying to submit another job.
19:06:29 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:06:29 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:06:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:06:29 WORKER: start processing job (5, 0, 7)
19:06:29 WORKER: args: ()
19:06:29 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0017417826667312914, 'num_filters_1': 18, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.018207750286178152, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 53, 'num_filters_3': 117}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:06:51 DISPATCHER: Starting worker discovery
19:06:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:06:51 DISPATCHER: Finished worker discovery
19:07:51 DISPATCHER: Starting worker discovery
19:07:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:07:51 DISPATCHER: Finished worker discovery
19:08:51 DISPATCHER: Starting worker discovery
19:08:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:08:51 DISPATCHER: Finished worker discovery
19:08:58 WORKER: done with job (5, 0, 7), trying to register it.
19:08:58 WORKER: registered result for job (5, 0, 7) with dispatcher
19:08:58 DISPATCHER: job (5, 0, 7) finished
19:08:58 DISPATCHER: register_result: lock acquired
19:08:58 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
19:08:58 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0017417826667312914, 'num_filters_1': 18, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.018207750286178152, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 53, 'num_filters_3': 117}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6034592206886313, 'info': {'data05': 0.6034592206886313, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0017417826667312914, 'num_filters_1': 18, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.018207750286178152, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 53, 'num_filters_3': 117}"}}
exception: None

19:08:58 job_callback for (5, 0, 7) started
19:08:58 job_callback for (5, 0, 7) got condition
19:08:58 DISPATCHER: Trying to submit another job.
19:08:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:08:58 done building a new model for budget 133.333333 based on 17/29 split
Best loss for this budget:-0.891177





19:08:58 HBMASTER: Trying to run another job!
19:08:58 job_callback for (5, 0, 7) finished
19:08:58 start sampling a new configuration.
19:08:58 done sampling a new configuration.
19:08:58 HBMASTER: schedule new run for iteration 5
19:08:58 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
19:08:58 HBMASTER: submitting job (5, 0, 8) to dispatcher
19:08:58 DISPATCHER: trying to submit job (5, 0, 8)
19:08:58 DISPATCHER: trying to notify the job_runner thread.
19:08:58 HBMASTER: job (5, 0, 8) submitted to dispatcher
19:08:58 DISPATCHER: Trying to submit another job.
19:08:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:08:58 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:08:58 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:08:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:08:58 WORKER: start processing job (5, 0, 8)
19:08:58 WORKER: args: ()
19:08:58 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.023578507938552457, 'num_filters_1': 45, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.10087924387323353}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:09:51 DISPATCHER: Starting worker discovery
19:09:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:09:51 DISPATCHER: Finished worker discovery
19:10:51 DISPATCHER: Starting worker discovery
19:10:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:10:51 DISPATCHER: Finished worker discovery
19:11:26 WORKER: done with job (5, 0, 8), trying to register it.
19:11:26 WORKER: registered result for job (5, 0, 8) with dispatcher
19:11:26 DISPATCHER: job (5, 0, 8) finished
19:11:26 DISPATCHER: register_result: lock acquired
19:11:26 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
19:11:26 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.023578507938552457, 'num_filters_1': 45, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.10087924387323353}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.07135069575488166, 'info': {'data05': 0.07135069575488166, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.023578507938552457, 'num_filters_1': 45, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.10087924387323353}"}}
exception: None

19:11:26 job_callback for (5, 0, 8) started
19:11:26 job_callback for (5, 0, 8) got condition
19:11:26 DISPATCHER: Trying to submit another job.
19:11:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:11:26 done building a new model for budget 133.333333 based on 17/30 split
Best loss for this budget:-0.891177





19:11:26 HBMASTER: Trying to run another job!
19:11:26 job_callback for (5, 0, 8) finished
19:11:26 ITERATION: Advancing config (5, 0, 0) to next budget 400.000000
19:11:26 ITERATION: Advancing config (5, 0, 3) to next budget 400.000000
19:11:26 ITERATION: Advancing config (5, 0, 7) to next budget 400.000000
19:11:26 HBMASTER: schedule new run for iteration 5
19:11:26 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
19:11:26 HBMASTER: submitting job (5, 0, 0) to dispatcher
19:11:26 DISPATCHER: trying to submit job (5, 0, 0)
19:11:26 DISPATCHER: trying to notify the job_runner thread.
19:11:26 HBMASTER: job (5, 0, 0) submitted to dispatcher
19:11:26 DISPATCHER: Trying to submit another job.
19:11:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:11:26 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:11:26 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:11:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:11:26 WORKER: start processing job (5, 0, 0)
19:11:26 WORKER: args: ()
19:11:26 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0011368984890336796, 'num_filters_1': 24, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.011982932196393205, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 102, 'num_filters_3': 42}, 'budget': 400.0, 'working_directory': '.'}
19:11:51 DISPATCHER: Starting worker discovery
19:11:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:11:51 DISPATCHER: Finished worker discovery
19:12:51 DISPATCHER: Starting worker discovery
19:12:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:12:51 DISPATCHER: Finished worker discovery
19:13:51 DISPATCHER: Starting worker discovery
19:13:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:13:51 DISPATCHER: Finished worker discovery
19:14:51 DISPATCHER: Starting worker discovery
19:14:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:14:51 DISPATCHER: Finished worker discovery
19:15:51 DISPATCHER: Starting worker discovery
19:15:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:15:51 DISPATCHER: Finished worker discovery
19:16:51 DISPATCHER: Starting worker discovery
19:16:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:16:51 DISPATCHER: Finished worker discovery
19:17:51 DISPATCHER: Starting worker discovery
19:17:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:17:51 DISPATCHER: Finished worker discovery
19:18:33 WORKER: done with job (5, 0, 0), trying to register it.
19:18:33 WORKER: registered result for job (5, 0, 0) with dispatcher
19:18:33 DISPATCHER: job (5, 0, 0) finished
19:18:33 DISPATCHER: register_result: lock acquired
19:18:33 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
19:18:33 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0011368984890336796, 'num_filters_1': 24, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.011982932196393205, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 102, 'num_filters_3': 42}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5785693131155677, 'info': {'data05': 0.5785693131155677, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0011368984890336796, 'num_filters_1': 24, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.011982932196393205, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 102, 'num_filters_3': 42}"}}
exception: None

19:18:33 job_callback for (5, 0, 0) started
19:18:33 job_callback for (5, 0, 0) got condition
19:18:33 DISPATCHER: Trying to submit another job.
19:18:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:18:33 Only 16 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
19:18:33 HBMASTER: Trying to run another job!
19:18:33 job_callback for (5, 0, 0) finished
19:18:33 HBMASTER: schedule new run for iteration 5
19:18:33 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
19:18:33 HBMASTER: submitting job (5, 0, 3) to dispatcher
19:18:33 DISPATCHER: trying to submit job (5, 0, 3)
19:18:33 DISPATCHER: trying to notify the job_runner thread.
19:18:33 HBMASTER: job (5, 0, 3) submitted to dispatcher
19:18:33 DISPATCHER: Trying to submit another job.
19:18:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:18:33 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:18:33 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:18:33 WORKER: start processing job (5, 0, 3)
19:18:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:18:33 WORKER: args: ()
19:18:33 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.015997444980905846, 'num_filters_1': 85, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.02379524298176432, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 66, 'num_filters_3': 51, 'num_filters_4': 16, 'num_filters_5': 75}, 'budget': 400.0, 'working_directory': '.'}
19:18:51 DISPATCHER: Starting worker discovery
19:18:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:18:51 DISPATCHER: Finished worker discovery
19:19:51 DISPATCHER: Starting worker discovery
19:19:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:19:51 DISPATCHER: Finished worker discovery
19:20:51 DISPATCHER: Starting worker discovery
19:20:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:20:51 DISPATCHER: Finished worker discovery
19:21:51 DISPATCHER: Starting worker discovery
19:21:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:21:51 DISPATCHER: Finished worker discovery
19:22:51 DISPATCHER: Starting worker discovery
19:22:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:22:51 DISPATCHER: Finished worker discovery
19:23:51 DISPATCHER: Starting worker discovery
19:23:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:23:51 DISPATCHER: Finished worker discovery
19:24:51 DISPATCHER: Starting worker discovery
19:24:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:24:51 DISPATCHER: Finished worker discovery
19:25:36 WORKER: done with job (5, 0, 3), trying to register it.
19:25:36 WORKER: registered result for job (5, 0, 3) with dispatcher
19:25:36 DISPATCHER: job (5, 0, 3) finished
19:25:36 DISPATCHER: register_result: lock acquired
19:25:36 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
19:25:36 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.015997444980905846, 'num_filters_1': 85, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.02379524298176432, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 66, 'num_filters_3': 51, 'num_filters_4': 16, 'num_filters_5': 75}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8273611595444599, 'info': {'data05': 0.8273611595444599, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.015997444980905846, 'num_filters_1': 85, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.02379524298176432, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 66, 'num_filters_3': 51, 'num_filters_4': 16, 'num_filters_5': 75}"}}
exception: None

19:25:36 job_callback for (5, 0, 3) started
19:25:36 DISPATCHER: Trying to submit another job.
19:25:36 job_callback for (5, 0, 3) got condition
19:25:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:25:36 HBMASTER: Trying to run another job!
19:25:36 job_callback for (5, 0, 3) finished
19:25:36 HBMASTER: schedule new run for iteration 5
19:25:36 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
19:25:36 HBMASTER: submitting job (5, 0, 7) to dispatcher
19:25:36 DISPATCHER: trying to submit job (5, 0, 7)
19:25:36 DISPATCHER: trying to notify the job_runner thread.
19:25:36 HBMASTER: job (5, 0, 7) submitted to dispatcher
19:25:36 DISPATCHER: Trying to submit another job.
19:25:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:25:36 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:25:36 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:25:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:25:36 WORKER: start processing job (5, 0, 7)
19:25:36 WORKER: args: ()
19:25:36 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0017417826667312914, 'num_filters_1': 18, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.018207750286178152, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 53, 'num_filters_3': 117}, 'budget': 400.0, 'working_directory': '.'}
19:25:51 DISPATCHER: Starting worker discovery
19:25:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:25:51 DISPATCHER: Finished worker discovery
19:26:51 DISPATCHER: Starting worker discovery
19:26:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:26:51 DISPATCHER: Finished worker discovery
19:27:51 DISPATCHER: Starting worker discovery
19:27:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:27:51 DISPATCHER: Finished worker discovery
19:28:51 DISPATCHER: Starting worker discovery
19:28:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:28:51 DISPATCHER: Finished worker discovery
19:29:51 DISPATCHER: Starting worker discovery
19:29:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:29:51 DISPATCHER: Finished worker discovery
19:30:51 DISPATCHER: Starting worker discovery
19:30:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:30:51 DISPATCHER: Finished worker discovery
19:31:51 DISPATCHER: Starting worker discovery
19:31:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:31:51 DISPATCHER: Finished worker discovery
19:32:40 WORKER: done with job (5, 0, 7), trying to register it.
19:32:40 WORKER: registered result for job (5, 0, 7) with dispatcher
19:32:40 DISPATCHER: job (5, 0, 7) finished
19:32:40 DISPATCHER: register_result: lock acquired
19:32:40 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
19:32:40 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0017417826667312914, 'num_filters_1': 18, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.018207750286178152, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 53, 'num_filters_3': 117}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5162723240000111, 'info': {'data05': 0.5162723240000111, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0017417826667312914, 'num_filters_1': 18, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.018207750286178152, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 53, 'num_filters_3': 117}"}}
exception: None

19:32:40 job_callback for (5, 0, 7) started
19:32:40 job_callback for (5, 0, 7) got condition
19:32:40 DISPATCHER: Trying to submit another job.
19:32:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:32:40 HBMASTER: Trying to run another job!
19:32:40 job_callback for (5, 0, 7) finished
19:32:40 ITERATION: Advancing config (5, 0, 3) to next budget 1200.000000
19:32:40 HBMASTER: schedule new run for iteration 5
19:32:40 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
19:32:40 HBMASTER: submitting job (5, 0, 3) to dispatcher
19:32:40 DISPATCHER: trying to submit job (5, 0, 3)
19:32:40 DISPATCHER: trying to notify the job_runner thread.
19:32:40 HBMASTER: job (5, 0, 3) submitted to dispatcher
19:32:40 DISPATCHER: Trying to submit another job.
19:32:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:32:40 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:32:40 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:32:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:32:40 WORKER: start processing job (5, 0, 3)
19:32:40 WORKER: args: ()
19:32:40 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.015997444980905846, 'num_filters_1': 85, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.02379524298176432, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 66, 'num_filters_3': 51, 'num_filters_4': 16, 'num_filters_5': 75}, 'budget': 1200.0, 'working_directory': '.'}
19:32:51 DISPATCHER: Starting worker discovery
19:32:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:32:51 DISPATCHER: Finished worker discovery
19:33:51 DISPATCHER: Starting worker discovery
19:33:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:33:51 DISPATCHER: Finished worker discovery
19:34:51 DISPATCHER: Starting worker discovery
19:34:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:34:51 DISPATCHER: Finished worker discovery
19:35:51 DISPATCHER: Starting worker discovery
19:35:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:35:51 DISPATCHER: Finished worker discovery
19:36:51 DISPATCHER: Starting worker discovery
19:36:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:36:51 DISPATCHER: Finished worker discovery
19:37:51 DISPATCHER: Starting worker discovery
19:37:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:37:51 DISPATCHER: Finished worker discovery
19:38:51 DISPATCHER: Starting worker discovery
19:38:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:38:51 DISPATCHER: Finished worker discovery
19:39:51 DISPATCHER: Starting worker discovery
19:39:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:39:51 DISPATCHER: Finished worker discovery
19:40:51 DISPATCHER: Starting worker discovery
19:40:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:40:51 DISPATCHER: Finished worker discovery
19:41:51 DISPATCHER: Starting worker discovery
19:41:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:41:51 DISPATCHER: Finished worker discovery
19:42:51 DISPATCHER: Starting worker discovery
19:42:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:42:51 DISPATCHER: Finished worker discovery
19:43:51 DISPATCHER: Starting worker discovery
19:43:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:43:51 DISPATCHER: Finished worker discovery
19:44:51 DISPATCHER: Starting worker discovery
19:44:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:44:51 DISPATCHER: Finished worker discovery
19:45:51 DISPATCHER: Starting worker discovery
19:45:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:45:51 DISPATCHER: Finished worker discovery
19:46:51 DISPATCHER: Starting worker discovery
19:46:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:46:51 DISPATCHER: Finished worker discovery
19:47:51 DISPATCHER: Starting worker discovery
19:47:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:47:51 DISPATCHER: Finished worker discovery
19:48:51 DISPATCHER: Starting worker discovery
19:48:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:48:51 DISPATCHER: Finished worker discovery
19:49:51 DISPATCHER: Starting worker discovery
19:49:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:49:51 DISPATCHER: Finished worker discovery
19:50:51 DISPATCHER: Starting worker discovery
19:50:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:50:51 DISPATCHER: Finished worker discovery
19:51:51 DISPATCHER: Starting worker discovery
19:51:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:51:51 DISPATCHER: Finished worker discovery
19:52:51 DISPATCHER: Starting worker discovery
19:52:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:52:51 DISPATCHER: Finished worker discovery
19:53:26 WORKER: done with job (5, 0, 3), trying to register it.
19:53:26 WORKER: registered result for job (5, 0, 3) with dispatcher
19:53:26 DISPATCHER: job (5, 0, 3) finished
19:53:26 DISPATCHER: register_result: lock acquired
19:53:26 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
19:53:26 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.015997444980905846, 'num_filters_1': 85, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.02379524298176432, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 66, 'num_filters_3': 51, 'num_filters_4': 16, 'num_filters_5': 75}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.8527291355443336, 'info': {'data05': 0.8527291355443336, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.015997444980905846, 'num_filters_1': 85, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.02379524298176432, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 66, 'num_filters_3': 51, 'num_filters_4': 16, 'num_filters_5': 75}"}}
exception: None

19:53:26 job_callback for (5, 0, 3) started
19:53:26 job_callback for (5, 0, 3) got condition
19:53:26 DISPATCHER: Trying to submit another job.
19:53:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:53:26 Only 10 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
19:53:26 HBMASTER: Trying to run another job!
19:53:26 job_callback for (5, 0, 3) finished
19:53:26 start sampling a new configuration.
19:53:26 done sampling a new configuration.
19:53:26 HBMASTER: schedule new run for iteration 6
19:53:26 HBMASTER: trying submitting job (6, 0, 0) to dispatcher
19:53:26 HBMASTER: submitting job (6, 0, 0) to dispatcher
19:53:26 DISPATCHER: trying to submit job (6, 0, 0)
19:53:26 DISPATCHER: trying to notify the job_runner thread.
19:53:26 HBMASTER: job (6, 0, 0) submitted to dispatcher
19:53:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:53:26 DISPATCHER: Trying to submit another job.
19:53:26 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:53:26 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:53:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:53:26 WORKER: start processing job (6, 0, 0)
19:53:26 WORKER: args: ()
19:53:26 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.014523603487352387, 'num_filters_1': 29, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.03331771584708089, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 30, 'num_filters_3': 75, 'num_filters_4': 68, 'num_filters_5': 83}, 'budget': 400.0, 'working_directory': '.'}
19:53:51 DISPATCHER: Starting worker discovery
19:53:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:53:51 DISPATCHER: Finished worker discovery
19:54:51 DISPATCHER: Starting worker discovery
19:54:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:54:51 DISPATCHER: Finished worker discovery
19:55:51 DISPATCHER: Starting worker discovery
19:55:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:55:51 DISPATCHER: Finished worker discovery
19:56:51 DISPATCHER: Starting worker discovery
19:56:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:56:51 DISPATCHER: Finished worker discovery
19:57:51 DISPATCHER: Starting worker discovery
19:57:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:57:51 DISPATCHER: Finished worker discovery
19:58:51 DISPATCHER: Starting worker discovery
19:58:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:58:51 DISPATCHER: Finished worker discovery
19:59:51 DISPATCHER: Starting worker discovery
19:59:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:59:51 DISPATCHER: Finished worker discovery
20:00:30 WORKER: done with job (6, 0, 0), trying to register it.
20:00:30 WORKER: registered result for job (6, 0, 0) with dispatcher
20:00:30 DISPATCHER: job (6, 0, 0) finished
20:00:30 DISPATCHER: register_result: lock acquired
20:00:30 DISPATCHER: job (6, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
20:00:30 job_id: (6, 0, 0)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.014523603487352387, 'num_filters_1': 29, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.03331771584708089, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 30, 'num_filters_3': 75, 'num_filters_4': 68, 'num_filters_5': 83}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.014523603487352387, 'num_filters_1': 29, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.03331771584708089, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 30, 'num_filters_3': 75, 'num_filters_4': 68, 'num_filters_5': 83}"}}
exception: None

20:00:30 job_callback for (6, 0, 0) started
20:00:30 DISPATCHER: Trying to submit another job.
20:00:30 job_callback for (6, 0, 0) got condition
20:00:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:00:30 HBMASTER: Trying to run another job!
20:00:30 job_callback for (6, 0, 0) finished
20:00:30 start sampling a new configuration.
20:00:30 done sampling a new configuration.
20:00:30 HBMASTER: schedule new run for iteration 6
20:00:30 HBMASTER: trying submitting job (6, 0, 1) to dispatcher
20:00:30 HBMASTER: submitting job (6, 0, 1) to dispatcher
20:00:30 DISPATCHER: trying to submit job (6, 0, 1)
20:00:30 DISPATCHER: trying to notify the job_runner thread.
20:00:30 HBMASTER: job (6, 0, 1) submitted to dispatcher
20:00:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:00:30 DISPATCHER: Trying to submit another job.
20:00:30 DISPATCHER: starting job (6, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:00:30 DISPATCHER: job (6, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:00:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:00:30 WORKER: start processing job (6, 0, 1)
20:00:30 WORKER: args: ()
20:00:30 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001317991589413823, 'num_filters_1': 117, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.01414329156843697, 'kernel_size_2': 5, 'num_filters_2': 104}, 'budget': 400.0, 'working_directory': '.'}
20:00:51 DISPATCHER: Starting worker discovery
20:00:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:00:51 DISPATCHER: Finished worker discovery
20:01:51 DISPATCHER: Starting worker discovery
20:01:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:01:51 DISPATCHER: Finished worker discovery
20:02:51 DISPATCHER: Starting worker discovery
20:02:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:02:51 DISPATCHER: Finished worker discovery
20:03:51 DISPATCHER: Starting worker discovery
20:03:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:03:51 DISPATCHER: Finished worker discovery
20:04:51 DISPATCHER: Starting worker discovery
20:04:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:04:51 DISPATCHER: Finished worker discovery
20:05:51 DISPATCHER: Starting worker discovery
20:05:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:05:51 DISPATCHER: Finished worker discovery
20:06:51 DISPATCHER: Starting worker discovery
20:06:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:06:51 DISPATCHER: Finished worker discovery
20:07:40 WORKER: done with job (6, 0, 1), trying to register it.
20:07:40 WORKER: registered result for job (6, 0, 1) with dispatcher
20:07:40 DISPATCHER: job (6, 0, 1) finished
20:07:40 DISPATCHER: register_result: lock acquired
20:07:40 DISPATCHER: job (6, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
20:07:40 job_id: (6, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001317991589413823, 'num_filters_1': 117, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.01414329156843697, 'kernel_size_2': 5, 'num_filters_2': 104}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5911642924719892, 'info': {'data05': 0.5911642924719892, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001317991589413823, 'num_filters_1': 117, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.01414329156843697, 'kernel_size_2': 5, 'num_filters_2': 104}"}}
exception: None

20:07:40 job_callback for (6, 0, 1) started
20:07:40 job_callback for (6, 0, 1) got condition
20:07:40 DISPATCHER: Trying to submit another job.
20:07:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:07:40 HBMASTER: Trying to run another job!
20:07:40 job_callback for (6, 0, 1) finished
20:07:40 start sampling a new configuration.
20:07:41 best_vector: [0, 1, 0.5094598033444377, 0.6060356666665301, 0.6087996309644244, 1, 0.6793585614710644, 0.34929400704850205, 1, 2, 0, 1, 0.2516648456112156, 0.5039062124944517, 0.03053344329037129, 0.9066567495654388], 3.575806560938732e-29, 0.000279657185856686, -2.770115872782321e-06
20:07:41 done sampling a new configuration.
20:07:41 HBMASTER: schedule new run for iteration 6
20:07:41 HBMASTER: trying submitting job (6, 0, 2) to dispatcher
20:07:41 HBMASTER: submitting job (6, 0, 2) to dispatcher
20:07:41 DISPATCHER: trying to submit job (6, 0, 2)
20:07:41 DISPATCHER: trying to notify the job_runner thread.
20:07:41 HBMASTER: job (6, 0, 2) submitted to dispatcher
20:07:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:07:41 DISPATCHER: Trying to submit another job.
20:07:41 DISPATCHER: starting job (6, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:07:41 DISPATCHER: job (6, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:07:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:07:41 WORKER: start processing job (6, 0, 2)
20:07:41 WORKER: args: ()
20:07:41 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.010445268464105506, 'num_filters_1': 56, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.02847357382362529, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 26, 'num_filters_3': 45, 'num_filters_4': 17}, 'budget': 400.0, 'working_directory': '.'}
20:07:51 DISPATCHER: Starting worker discovery
20:07:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:07:51 DISPATCHER: Finished worker discovery
20:08:51 DISPATCHER: Starting worker discovery
20:08:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:08:51 DISPATCHER: Finished worker discovery
20:09:51 DISPATCHER: Starting worker discovery
20:09:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:09:51 DISPATCHER: Finished worker discovery
20:10:51 DISPATCHER: Starting worker discovery
20:10:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:10:51 DISPATCHER: Finished worker discovery
20:11:51 DISPATCHER: Starting worker discovery
20:11:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:11:51 DISPATCHER: Finished worker discovery
20:12:51 DISPATCHER: Starting worker discovery
20:12:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:12:51 DISPATCHER: Finished worker discovery
20:13:51 DISPATCHER: Starting worker discovery
20:13:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:13:51 DISPATCHER: Finished worker discovery
20:14:48 WORKER: done with job (6, 0, 2), trying to register it.
20:14:48 WORKER: registered result for job (6, 0, 2) with dispatcher
20:14:48 DISPATCHER: job (6, 0, 2) finished
20:14:48 DISPATCHER: register_result: lock acquired
20:14:48 DISPATCHER: job (6, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
20:14:48 job_id: (6, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.010445268464105506, 'num_filters_1': 56, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.02847357382362529, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 26, 'num_filters_3': 45, 'num_filters_4': 17}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.665560395507397, 'info': {'data05': 0.665560395507397, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.010445268464105506, 'num_filters_1': 56, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.02847357382362529, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 26, 'num_filters_3': 45, 'num_filters_4': 17}"}}
exception: None

20:14:48 job_callback for (6, 0, 2) started
20:14:48 job_callback for (6, 0, 2) got condition
20:14:48 DISPATCHER: Trying to submit another job.
20:14:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:14:48 HBMASTER: Trying to run another job!
20:14:48 job_callback for (6, 0, 2) finished
20:14:48 start sampling a new configuration.
20:14:49 best_vector: [0, 2, 0.0846721060746576, 0.46796286456246844, 0.4693460212260362, 0, 0.6526578387179638, 0.23280452702113819, 1, 2, 1, 0, 0.23210550279242514, 0.8028972756143692, 0.02351425315555794, 0.4734923964550565], 1.5194630626411133e-29, 0.0006581272191387209, -0.00012598069460383835
20:14:49 done sampling a new configuration.
20:14:49 HBMASTER: schedule new run for iteration 6
20:14:49 HBMASTER: trying submitting job (6, 0, 3) to dispatcher
20:14:49 HBMASTER: submitting job (6, 0, 3) to dispatcher
20:14:49 DISPATCHER: trying to submit job (6, 0, 3)
20:14:49 DISPATCHER: trying to notify the job_runner thread.
20:14:49 HBMASTER: job (6, 0, 3) submitted to dispatcher
20:14:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:14:49 DISPATCHER: Trying to submit another job.
20:14:49 DISPATCHER: starting job (6, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:14:49 DISPATCHER: job (6, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:14:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:14:49 WORKER: start processing job (6, 0, 3)
20:14:49 WORKER: args: ()
20:14:49 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0014768766090869068, 'num_filters_1': 42, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.020085639922501706, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 25, 'num_filters_3': 85}, 'budget': 400.0, 'working_directory': '.'}
20:14:51 DISPATCHER: Starting worker discovery
20:14:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:14:51 DISPATCHER: Finished worker discovery
20:15:51 DISPATCHER: Starting worker discovery
20:15:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:15:51 DISPATCHER: Finished worker discovery
20:16:51 DISPATCHER: Starting worker discovery
20:16:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:16:51 DISPATCHER: Finished worker discovery
20:17:51 DISPATCHER: Starting worker discovery
20:17:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:17:51 DISPATCHER: Finished worker discovery
20:18:51 DISPATCHER: Starting worker discovery
20:18:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:18:51 DISPATCHER: Finished worker discovery
20:19:51 DISPATCHER: Starting worker discovery
20:19:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:19:51 DISPATCHER: Finished worker discovery
20:20:51 DISPATCHER: Starting worker discovery
20:20:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:20:51 DISPATCHER: Finished worker discovery
20:21:51 DISPATCHER: Starting worker discovery
20:21:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:21:51 DISPATCHER: Finished worker discovery
20:21:54 WORKER: done with job (6, 0, 3), trying to register it.
20:21:54 WORKER: registered result for job (6, 0, 3) with dispatcher
20:21:54 DISPATCHER: job (6, 0, 3) finished
20:21:54 DISPATCHER: register_result: lock acquired
20:21:54 DISPATCHER: job (6, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
20:21:54 job_id: (6, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0014768766090869068, 'num_filters_1': 42, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.020085639922501706, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 25, 'num_filters_3': 85}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7125896076916028, 'info': {'data05': 0.7125896076916028, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0014768766090869068, 'num_filters_1': 42, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.020085639922501706, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 25, 'num_filters_3': 85}"}}
exception: None

20:21:54 job_callback for (6, 0, 3) started
20:21:54 DISPATCHER: Trying to submit another job.
20:21:54 job_callback for (6, 0, 3) got condition
20:21:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:21:54 HBMASTER: Trying to run another job!
20:21:54 job_callback for (6, 0, 3) finished
20:21:54 start sampling a new configuration.
20:21:54 done sampling a new configuration.
20:21:54 HBMASTER: schedule new run for iteration 6
20:21:54 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
20:21:54 HBMASTER: submitting job (6, 0, 4) to dispatcher
20:21:54 DISPATCHER: trying to submit job (6, 0, 4)
20:21:54 DISPATCHER: trying to notify the job_runner thread.
20:21:54 HBMASTER: job (6, 0, 4) submitted to dispatcher
20:21:54 DISPATCHER: Trying to submit another job.
20:21:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:21:54 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:21:54 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:21:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:21:54 WORKER: start processing job (6, 0, 4)
20:21:54 WORKER: args: ()
20:21:54 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.02048060343111065, 'num_filters_1': 31, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.038449931066724716, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 28, 'num_filters_3': 43, 'num_filters_4': 25}, 'budget': 400.0, 'working_directory': '.'}
20:22:51 DISPATCHER: Starting worker discovery
20:22:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:22:52 DISPATCHER: Finished worker discovery
20:23:52 DISPATCHER: Starting worker discovery
20:23:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:23:52 DISPATCHER: Finished worker discovery
20:24:52 DISPATCHER: Starting worker discovery
20:24:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:24:52 DISPATCHER: Finished worker discovery
20:25:52 DISPATCHER: Starting worker discovery
20:25:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:25:52 DISPATCHER: Finished worker discovery
20:26:52 DISPATCHER: Starting worker discovery
20:26:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:26:52 DISPATCHER: Finished worker discovery
20:27:52 DISPATCHER: Starting worker discovery
20:27:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:27:52 DISPATCHER: Finished worker discovery
20:28:52 DISPATCHER: Starting worker discovery
20:28:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:28:52 DISPATCHER: Finished worker discovery
20:28:59 WORKER: done with job (6, 0, 4), trying to register it.
20:28:59 WORKER: registered result for job (6, 0, 4) with dispatcher
20:28:59 DISPATCHER: job (6, 0, 4) finished
20:28:59 DISPATCHER: register_result: lock acquired
20:28:59 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
20:28:59 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.02048060343111065, 'num_filters_1': 31, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.038449931066724716, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 28, 'num_filters_3': 43, 'num_filters_4': 25}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.02048060343111065, 'num_filters_1': 31, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.038449931066724716, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 28, 'num_filters_3': 43, 'num_filters_4': 25}"}}
exception: None

20:28:59 job_callback for (6, 0, 4) started
20:28:59 job_callback for (6, 0, 4) got condition
20:28:59 DISPATCHER: Trying to submit another job.
20:28:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:28:59 HBMASTER: Trying to run another job!
20:28:59 job_callback for (6, 0, 4) finished
20:28:59 start sampling a new configuration.
20:28:59 best_vector: [2, 1, 0.43056433909273245, 0.11893577165566721, 0.19880626907206245, 1, 0.5576494837859508, 0.12284849182433191, 1, 0, 2, 2, 0.4404812117427004, 0.22025057663913017, 0.20241368429025058, 0.3636957192392736], 1.441033901204997e-29, 0.0006939462001301961, -0.00019138394564551813
20:28:59 done sampling a new configuration.
20:28:59 HBMASTER: schedule new run for iteration 6
20:28:59 HBMASTER: trying submitting job (6, 0, 5) to dispatcher
20:28:59 HBMASTER: submitting job (6, 0, 5) to dispatcher
20:28:59 DISPATCHER: trying to submit job (6, 0, 5)
20:28:59 DISPATCHER: trying to notify the job_runner thread.
20:28:59 HBMASTER: job (6, 0, 5) submitted to dispatcher
20:28:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:28:59 DISPATCHER: Trying to submit another job.
20:28:59 DISPATCHER: starting job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:28:59 DISPATCHER: job (6, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:28:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:28:59 WORKER: start processing job (6, 0, 5)
20:28:59 WORKER: args: ()
20:28:59 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.007263211290392487, 'num_filters_1': 20, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.014448726579798676}, 'budget': 400.0, 'working_directory': '.'}
20:29:52 DISPATCHER: Starting worker discovery
20:29:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:29:52 DISPATCHER: Finished worker discovery
20:30:52 DISPATCHER: Starting worker discovery
20:30:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:30:52 DISPATCHER: Finished worker discovery
20:31:52 DISPATCHER: Starting worker discovery
20:31:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:31:52 DISPATCHER: Finished worker discovery
20:32:52 DISPATCHER: Starting worker discovery
20:32:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:32:52 DISPATCHER: Finished worker discovery
20:33:52 DISPATCHER: Starting worker discovery
20:33:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:33:52 DISPATCHER: Finished worker discovery
20:34:52 DISPATCHER: Starting worker discovery
20:34:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:34:52 DISPATCHER: Finished worker discovery
20:35:52 DISPATCHER: Starting worker discovery
20:35:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:35:52 DISPATCHER: Finished worker discovery
20:36:05 WORKER: done with job (6, 0, 5), trying to register it.
20:36:05 WORKER: registered result for job (6, 0, 5) with dispatcher
20:36:05 DISPATCHER: job (6, 0, 5) finished
20:36:05 DISPATCHER: register_result: lock acquired
20:36:05 DISPATCHER: job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
20:36:05 job_id: (6, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.007263211290392487, 'num_filters_1': 20, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.014448726579798676}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.1431567480575537, 'info': {'data05': 0.1431567480575537, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.007263211290392487, 'num_filters_1': 20, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.014448726579798676}"}}
exception: None

20:36:05 job_callback for (6, 0, 5) started
20:36:05 DISPATCHER: Trying to submit another job.
20:36:05 job_callback for (6, 0, 5) got condition
20:36:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:36:05 HBMASTER: Trying to run another job!
20:36:05 job_callback for (6, 0, 5) finished
20:36:05 ITERATION: Advancing config (6, 0, 2) to next budget 1200.000000
20:36:05 ITERATION: Advancing config (6, 0, 3) to next budget 1200.000000
20:36:05 HBMASTER: schedule new run for iteration 6
20:36:05 HBMASTER: trying submitting job (6, 0, 2) to dispatcher
20:36:05 HBMASTER: submitting job (6, 0, 2) to dispatcher
20:36:05 DISPATCHER: trying to submit job (6, 0, 2)
20:36:05 DISPATCHER: trying to notify the job_runner thread.
20:36:05 HBMASTER: job (6, 0, 2) submitted to dispatcher
20:36:05 DISPATCHER: Trying to submit another job.
20:36:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:36:05 DISPATCHER: starting job (6, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:36:05 DISPATCHER: job (6, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:36:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:36:05 WORKER: start processing job (6, 0, 2)
20:36:05 WORKER: args: ()
20:36:05 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.010445268464105506, 'num_filters_1': 56, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.02847357382362529, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 26, 'num_filters_3': 45, 'num_filters_4': 17}, 'budget': 1200.0, 'working_directory': '.'}
20:36:52 DISPATCHER: Starting worker discovery
20:36:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:36:52 DISPATCHER: Finished worker discovery
20:37:52 DISPATCHER: Starting worker discovery
20:37:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:37:52 DISPATCHER: Finished worker discovery
20:38:52 DISPATCHER: Starting worker discovery
20:38:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:38:52 DISPATCHER: Finished worker discovery
20:39:52 DISPATCHER: Starting worker discovery
20:39:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:39:52 DISPATCHER: Finished worker discovery
20:40:52 DISPATCHER: Starting worker discovery
20:40:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:40:52 DISPATCHER: Finished worker discovery
20:41:52 DISPATCHER: Starting worker discovery
20:41:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:41:52 DISPATCHER: Finished worker discovery
20:42:52 DISPATCHER: Starting worker discovery
20:42:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:42:52 DISPATCHER: Finished worker discovery
20:43:52 DISPATCHER: Starting worker discovery
20:43:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:43:52 DISPATCHER: Finished worker discovery
20:44:52 DISPATCHER: Starting worker discovery
20:44:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:44:52 DISPATCHER: Finished worker discovery
20:45:52 DISPATCHER: Starting worker discovery
20:45:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:45:52 DISPATCHER: Finished worker discovery
20:46:52 DISPATCHER: Starting worker discovery
20:46:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:46:52 DISPATCHER: Finished worker discovery
20:47:52 DISPATCHER: Starting worker discovery
20:47:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:47:52 DISPATCHER: Finished worker discovery
20:48:52 DISPATCHER: Starting worker discovery
20:48:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:48:52 DISPATCHER: Finished worker discovery
20:49:52 DISPATCHER: Starting worker discovery
20:49:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:49:52 DISPATCHER: Finished worker discovery
20:50:52 DISPATCHER: Starting worker discovery
20:50:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:50:52 DISPATCHER: Finished worker discovery
20:51:52 DISPATCHER: Starting worker discovery
20:51:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:51:52 DISPATCHER: Finished worker discovery
20:52:52 DISPATCHER: Starting worker discovery
20:52:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:52:52 DISPATCHER: Finished worker discovery
20:53:52 DISPATCHER: Starting worker discovery
20:53:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:53:52 DISPATCHER: Finished worker discovery
20:54:52 DISPATCHER: Starting worker discovery
20:54:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:54:52 DISPATCHER: Finished worker discovery
20:55:52 DISPATCHER: Starting worker discovery
20:55:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:55:52 DISPATCHER: Finished worker discovery
20:56:52 DISPATCHER: Starting worker discovery
20:56:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:56:52 DISPATCHER: Finished worker discovery
20:57:02 WORKER: done with job (6, 0, 2), trying to register it.
20:57:02 WORKER: registered result for job (6, 0, 2) with dispatcher
20:57:02 DISPATCHER: job (6, 0, 2) finished
20:57:02 DISPATCHER: register_result: lock acquired
20:57:02 DISPATCHER: job (6, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
20:57:02 job_id: (6, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.010445268464105506, 'num_filters_1': 56, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.02847357382362529, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 26, 'num_filters_3': 45, 'num_filters_4': 17}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.7945627837446572, 'info': {'data05': 0.7945627837446572, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.010445268464105506, 'num_filters_1': 56, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.02847357382362529, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 26, 'num_filters_3': 45, 'num_filters_4': 17}"}}
exception: None

20:57:02 job_callback for (6, 0, 2) started
20:57:02 DISPATCHER: Trying to submit another job.
20:57:02 job_callback for (6, 0, 2) got condition
20:57:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:57:02 Only 11 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
20:57:02 HBMASTER: Trying to run another job!
20:57:02 job_callback for (6, 0, 2) finished
20:57:02 HBMASTER: schedule new run for iteration 6
20:57:02 HBMASTER: trying submitting job (6, 0, 3) to dispatcher
20:57:02 HBMASTER: submitting job (6, 0, 3) to dispatcher
20:57:02 DISPATCHER: trying to submit job (6, 0, 3)
20:57:02 DISPATCHER: trying to notify the job_runner thread.
20:57:02 HBMASTER: job (6, 0, 3) submitted to dispatcher
20:57:02 DISPATCHER: Trying to submit another job.
20:57:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:57:02 DISPATCHER: starting job (6, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:57:02 DISPATCHER: job (6, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:57:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:57:02 WORKER: start processing job (6, 0, 3)
20:57:02 WORKER: args: ()
20:57:02 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0014768766090869068, 'num_filters_1': 42, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.020085639922501706, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 25, 'num_filters_3': 85}, 'budget': 1200.0, 'working_directory': '.'}
20:57:52 DISPATCHER: Starting worker discovery
20:57:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:57:52 DISPATCHER: Finished worker discovery
20:58:52 DISPATCHER: Starting worker discovery
20:58:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:58:52 DISPATCHER: Finished worker discovery
20:59:52 DISPATCHER: Starting worker discovery
20:59:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:59:52 DISPATCHER: Finished worker discovery
21:00:52 DISPATCHER: Starting worker discovery
21:00:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:00:52 DISPATCHER: Finished worker discovery
21:01:52 DISPATCHER: Starting worker discovery
21:01:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:01:52 DISPATCHER: Finished worker discovery
21:02:52 DISPATCHER: Starting worker discovery
21:02:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:02:52 DISPATCHER: Finished worker discovery
21:03:52 DISPATCHER: Starting worker discovery
21:03:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:03:52 DISPATCHER: Finished worker discovery
21:04:52 DISPATCHER: Starting worker discovery
21:04:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:04:52 DISPATCHER: Finished worker discovery
21:05:52 DISPATCHER: Starting worker discovery
21:05:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:05:52 DISPATCHER: Finished worker discovery
21:06:52 DISPATCHER: Starting worker discovery
21:06:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:06:52 DISPATCHER: Finished worker discovery
21:07:52 DISPATCHER: Starting worker discovery
21:07:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:07:52 DISPATCHER: Finished worker discovery
21:08:52 DISPATCHER: Starting worker discovery
21:08:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:08:52 DISPATCHER: Finished worker discovery
21:09:52 DISPATCHER: Starting worker discovery
21:09:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:09:52 DISPATCHER: Finished worker discovery
21:10:52 DISPATCHER: Starting worker discovery
21:10:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:10:52 DISPATCHER: Finished worker discovery
21:11:52 DISPATCHER: Starting worker discovery
21:11:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:11:52 DISPATCHER: Finished worker discovery
21:12:52 DISPATCHER: Starting worker discovery
21:12:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:12:52 DISPATCHER: Finished worker discovery
21:13:52 DISPATCHER: Starting worker discovery
21:13:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:13:52 DISPATCHER: Finished worker discovery
21:14:52 DISPATCHER: Starting worker discovery
21:14:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:14:52 DISPATCHER: Finished worker discovery
21:15:52 DISPATCHER: Starting worker discovery
21:15:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:15:52 DISPATCHER: Finished worker discovery
21:16:52 DISPATCHER: Starting worker discovery
21:16:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:16:52 DISPATCHER: Finished worker discovery
21:17:52 DISPATCHER: Starting worker discovery
21:17:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:17:52 DISPATCHER: Finished worker discovery
21:17:57 WORKER: done with job (6, 0, 3), trying to register it.
21:17:57 WORKER: registered result for job (6, 0, 3) with dispatcher
21:17:57 DISPATCHER: job (6, 0, 3) finished
21:17:57 DISPATCHER: register_result: lock acquired
21:17:57 DISPATCHER: job (6, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
21:17:57 job_id: (6, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0014768766090869068, 'num_filters_1': 42, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.020085639922501706, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 25, 'num_filters_3': 85}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.7771539557398359, 'info': {'data05': 0.7771539557398359, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0014768766090869068, 'num_filters_1': 42, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.020085639922501706, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 25, 'num_filters_3': 85}"}}
exception: None

21:17:57 job_callback for (6, 0, 3) started
21:17:57 job_callback for (6, 0, 3) got condition
21:17:57 DISPATCHER: Trying to submit another job.
21:17:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:17:57 Only 12 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
21:17:57 HBMASTER: Trying to run another job!
21:17:57 job_callback for (6, 0, 3) finished
21:17:57 start sampling a new configuration.
21:17:57 best_vector: [1, 1, 0.3763225381863634, 0.6526051708963185, 0.8563811316769906, 1, 0.12212927438473967, 0.315650235631369, 1, 0, 1, 1, 0.5582700043958475, 0.5933380525591422, 0.02366652212080267, 0.682652285600848], 2.2042384073191306e-30, 0.004536714343963518, -7.571720974146517e-06
21:17:57 done sampling a new configuration.
21:17:57 HBMASTER: schedule new run for iteration 7
21:17:57 HBMASTER: trying submitting job (7, 0, 0) to dispatcher
21:17:57 HBMASTER: submitting job (7, 0, 0) to dispatcher
21:17:57 DISPATCHER: trying to submit job (7, 0, 0)
21:17:57 DISPATCHER: trying to notify the job_runner thread.
21:17:57 HBMASTER: job (7, 0, 0) submitted to dispatcher
21:17:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:17:57 DISPATCHER: Trying to submit another job.
21:17:57 DISPATCHER: starting job (7, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
21:17:57 DISPATCHER: job (7, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
21:17:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:17:57 WORKER: start processing job (7, 0, 0)
21:17:57 WORKER: args: ()
21:17:57 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0056577672363191285, 'num_filters_1': 62, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.025743667924617773, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 50, 'num_filters_3': 54, 'num_filters_4': 16, 'num_filters_5': 66}, 'budget': 1200.0, 'working_directory': '.'}
21:18:52 DISPATCHER: Starting worker discovery
21:18:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:18:52 DISPATCHER: Finished worker discovery
21:19:52 DISPATCHER: Starting worker discovery
21:19:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:19:52 DISPATCHER: Finished worker discovery
21:20:52 DISPATCHER: Starting worker discovery
21:20:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:20:52 DISPATCHER: Finished worker discovery
21:21:52 DISPATCHER: Starting worker discovery
21:21:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:21:52 DISPATCHER: Finished worker discovery
21:22:52 DISPATCHER: Starting worker discovery
21:22:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:22:52 DISPATCHER: Finished worker discovery
21:23:52 DISPATCHER: Starting worker discovery
21:23:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:23:52 DISPATCHER: Finished worker discovery
21:24:52 DISPATCHER: Starting worker discovery
21:24:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:24:52 DISPATCHER: Finished worker discovery
21:25:52 DISPATCHER: Starting worker discovery
21:25:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:25:52 DISPATCHER: Finished worker discovery
21:26:52 DISPATCHER: Starting worker discovery
21:26:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:26:52 DISPATCHER: Finished worker discovery
21:27:52 DISPATCHER: Starting worker discovery
21:27:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:27:52 DISPATCHER: Finished worker discovery
21:28:52 DISPATCHER: Starting worker discovery
21:28:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:28:52 DISPATCHER: Finished worker discovery
21:29:52 DISPATCHER: Starting worker discovery
21:29:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:29:52 DISPATCHER: Finished worker discovery
21:30:52 DISPATCHER: Starting worker discovery
21:30:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:30:52 DISPATCHER: Finished worker discovery
21:31:52 DISPATCHER: Starting worker discovery
21:31:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:31:52 DISPATCHER: Finished worker discovery
21:32:52 DISPATCHER: Starting worker discovery
21:32:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:32:52 DISPATCHER: Finished worker discovery
21:33:52 DISPATCHER: Starting worker discovery
21:33:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:33:52 DISPATCHER: Finished worker discovery
21:34:52 DISPATCHER: Starting worker discovery
21:34:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:34:52 DISPATCHER: Finished worker discovery
21:35:52 DISPATCHER: Starting worker discovery
21:35:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:35:52 DISPATCHER: Finished worker discovery
21:36:52 DISPATCHER: Starting worker discovery
21:36:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:36:52 DISPATCHER: Finished worker discovery
21:37:52 DISPATCHER: Starting worker discovery
21:37:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:37:52 DISPATCHER: Finished worker discovery
21:38:52 DISPATCHER: Starting worker discovery
21:38:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:38:52 DISPATCHER: Finished worker discovery
21:39:52 DISPATCHER: Starting worker discovery
21:39:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:39:52 DISPATCHER: Finished worker discovery
21:40:06 WORKER: done with job (7, 0, 0), trying to register it.
21:40:06 WORKER: registered result for job (7, 0, 0) with dispatcher
21:40:06 DISPATCHER: job (7, 0, 0) finished
21:40:06 DISPATCHER: register_result: lock acquired
21:40:06 DISPATCHER: job (7, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
21:40:06 job_id: (7, 0, 0)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0056577672363191285, 'num_filters_1': 62, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.025743667924617773, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 50, 'num_filters_3': 54, 'num_filters_4': 16, 'num_filters_5': 66}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.46905806016194884, 'info': {'data05': 0.46905806016194884, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0056577672363191285, 'num_filters_1': 62, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.025743667924617773, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 50, 'num_filters_3': 54, 'num_filters_4': 16, 'num_filters_5': 66}"}}
exception: None

21:40:06 job_callback for (7, 0, 0) started
21:40:06 DISPATCHER: Trying to submit another job.
21:40:06 job_callback for (7, 0, 0) got condition
21:40:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:40:06 Only 13 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
21:40:06 HBMASTER: Trying to run another job!
21:40:06 job_callback for (7, 0, 0) finished
21:40:06 start sampling a new configuration.
21:40:06 best_vector: [0, 1, 0.056438488857416425, 0.2563100265885846, 0.4237742869208256, 1, 0.8242490444666986, 0.14674963251945952, 0, 2, 2, 0, 0.8775488132021284, 0.3689032888012422, 0.4609106412170145, 0.3497663718315642], 8.109212452317574e-30, 0.0012331653731851666, -1.4139605646888208e-05
21:40:06 done sampling a new configuration.
21:40:06 HBMASTER: schedule new run for iteration 7
21:40:06 HBMASTER: trying submitting job (7, 0, 1) to dispatcher
21:40:06 HBMASTER: submitting job (7, 0, 1) to dispatcher
21:40:06 DISPATCHER: trying to submit job (7, 0, 1)
21:40:06 DISPATCHER: trying to notify the job_runner thread.
21:40:06 HBMASTER: job (7, 0, 1) submitted to dispatcher
21:40:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:40:06 DISPATCHER: Trying to submit another job.
21:40:06 DISPATCHER: starting job (7, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
21:40:06 DISPATCHER: job (7, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
21:40:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:40:06 WORKER: start processing job (7, 0, 1)
21:40:06 WORKER: args: ()
21:40:06 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0012968118719848035, 'num_filters_1': 27, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.015521213533112206, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 99, 'num_filters_3': 34}, 'budget': 1200.0, 'working_directory': '.'}
21:40:52 DISPATCHER: Starting worker discovery
21:40:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:40:52 DISPATCHER: Finished worker discovery
21:41:52 DISPATCHER: Starting worker discovery
21:41:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:41:52 DISPATCHER: Finished worker discovery
21:42:52 DISPATCHER: Starting worker discovery
21:42:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:42:52 DISPATCHER: Finished worker discovery
21:43:52 DISPATCHER: Starting worker discovery
21:43:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:43:52 DISPATCHER: Finished worker discovery
21:44:52 DISPATCHER: Starting worker discovery
21:44:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:44:52 DISPATCHER: Finished worker discovery
21:45:52 DISPATCHER: Starting worker discovery
21:45:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:45:52 DISPATCHER: Finished worker discovery
21:46:52 DISPATCHER: Starting worker discovery
21:46:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:46:52 DISPATCHER: Finished worker discovery
21:47:52 DISPATCHER: Starting worker discovery
21:47:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:47:52 DISPATCHER: Finished worker discovery
21:48:52 DISPATCHER: Starting worker discovery
21:48:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:48:52 DISPATCHER: Finished worker discovery
21:49:52 DISPATCHER: Starting worker discovery
21:49:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:49:52 DISPATCHER: Finished worker discovery
21:50:52 DISPATCHER: Starting worker discovery
21:50:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:50:53 DISPATCHER: Finished worker discovery
21:51:53 DISPATCHER: Starting worker discovery
21:51:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:51:53 DISPATCHER: Finished worker discovery
21:52:53 DISPATCHER: Starting worker discovery
21:52:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:52:53 DISPATCHER: Finished worker discovery
21:53:53 DISPATCHER: Starting worker discovery
21:53:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:53:53 DISPATCHER: Finished worker discovery
21:54:53 DISPATCHER: Starting worker discovery
21:54:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:54:53 DISPATCHER: Finished worker discovery
21:55:53 DISPATCHER: Starting worker discovery
21:55:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:55:53 DISPATCHER: Finished worker discovery
21:56:53 DISPATCHER: Starting worker discovery
21:56:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:56:53 DISPATCHER: Finished worker discovery
21:57:53 DISPATCHER: Starting worker discovery
21:57:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:57:53 DISPATCHER: Finished worker discovery
21:58:53 DISPATCHER: Starting worker discovery
21:58:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:58:53 DISPATCHER: Finished worker discovery
21:59:53 DISPATCHER: Starting worker discovery
21:59:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:59:53 DISPATCHER: Finished worker discovery
22:00:53 DISPATCHER: Starting worker discovery
22:00:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:00:53 DISPATCHER: Finished worker discovery
22:01:02 WORKER: done with job (7, 0, 1), trying to register it.
22:01:02 WORKER: registered result for job (7, 0, 1) with dispatcher
22:01:02 DISPATCHER: job (7, 0, 1) finished
22:01:02 DISPATCHER: register_result: lock acquired
22:01:02 DISPATCHER: job (7, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
22:01:02 job_id: (7, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0012968118719848035, 'num_filters_1': 27, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.015521213533112206, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 99, 'num_filters_3': 34}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.3556888559845903, 'info': {'data05': 0.3556888559845903, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0012968118719848035, 'num_filters_1': 27, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.015521213533112206, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 99, 'num_filters_3': 34}"}}
exception: None

22:01:02 job_callback for (7, 0, 1) started
22:01:02 DISPATCHER: Trying to submit another job.
22:01:02 job_callback for (7, 0, 1) got condition
22:01:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:01:02 Only 14 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
22:01:02 HBMASTER: Trying to run another job!
22:01:02 job_callback for (7, 0, 1) finished
22:01:02 start sampling a new configuration.
22:01:02 done sampling a new configuration.
22:01:02 HBMASTER: schedule new run for iteration 7
22:01:02 HBMASTER: trying submitting job (7, 0, 2) to dispatcher
22:01:02 HBMASTER: submitting job (7, 0, 2) to dispatcher
22:01:02 DISPATCHER: trying to submit job (7, 0, 2)
22:01:02 DISPATCHER: trying to notify the job_runner thread.
22:01:02 HBMASTER: job (7, 0, 2) submitted to dispatcher
22:01:02 DISPATCHER: Trying to submit another job.
22:01:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:01:02 DISPATCHER: starting job (7, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:01:02 DISPATCHER: job (7, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:01:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:01:02 WORKER: start processing job (7, 0, 2)
22:01:02 WORKER: args: ()
22:01:02 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.008957032528480985, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.1250641745072685, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 16, 'num_filters_3': 22, 'num_filters_4': 63}, 'budget': 1200.0, 'working_directory': '.'}
22:01:53 DISPATCHER: Starting worker discovery
22:01:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:01:53 DISPATCHER: Finished worker discovery
22:02:53 DISPATCHER: Starting worker discovery
22:02:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:02:53 DISPATCHER: Finished worker discovery
22:03:53 DISPATCHER: Starting worker discovery
22:03:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:03:53 DISPATCHER: Finished worker discovery
22:04:53 DISPATCHER: Starting worker discovery
22:04:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:04:53 DISPATCHER: Finished worker discovery
22:05:53 DISPATCHER: Starting worker discovery
22:05:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:05:53 DISPATCHER: Finished worker discovery
22:06:53 DISPATCHER: Starting worker discovery
22:06:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:06:53 DISPATCHER: Finished worker discovery
22:07:53 DISPATCHER: Starting worker discovery
22:07:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:07:53 DISPATCHER: Finished worker discovery
22:08:53 DISPATCHER: Starting worker discovery
22:08:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:08:53 DISPATCHER: Finished worker discovery
22:09:53 DISPATCHER: Starting worker discovery
22:09:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:09:53 DISPATCHER: Finished worker discovery
22:10:53 DISPATCHER: Starting worker discovery
22:10:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:10:53 DISPATCHER: Finished worker discovery
22:11:53 DISPATCHER: Starting worker discovery
22:11:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:11:53 DISPATCHER: Finished worker discovery
22:12:53 DISPATCHER: Starting worker discovery
22:12:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:12:53 DISPATCHER: Finished worker discovery
22:13:53 DISPATCHER: Starting worker discovery
22:13:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:13:53 DISPATCHER: Finished worker discovery
22:14:53 DISPATCHER: Starting worker discovery
22:14:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:14:53 DISPATCHER: Finished worker discovery
22:15:53 DISPATCHER: Starting worker discovery
22:15:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:15:53 DISPATCHER: Finished worker discovery
22:16:53 DISPATCHER: Starting worker discovery
22:16:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:16:53 DISPATCHER: Finished worker discovery
22:17:53 DISPATCHER: Starting worker discovery
22:17:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:17:53 DISPATCHER: Finished worker discovery
22:18:53 DISPATCHER: Starting worker discovery
22:18:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:18:53 DISPATCHER: Finished worker discovery
22:19:53 DISPATCHER: Starting worker discovery
22:19:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:19:53 DISPATCHER: Finished worker discovery
22:20:53 DISPATCHER: Starting worker discovery
22:20:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:20:53 DISPATCHER: Finished worker discovery
22:21:53 DISPATCHER: Starting worker discovery
22:21:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:21:53 DISPATCHER: Finished worker discovery
22:22:53 DISPATCHER: Starting worker discovery
22:22:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:22:53 DISPATCHER: Finished worker discovery
22:23:04 WORKER: done with job (7, 0, 2), trying to register it.
22:23:04 WORKER: registered result for job (7, 0, 2) with dispatcher
22:23:04 DISPATCHER: job (7, 0, 2) finished
22:23:04 DISPATCHER: register_result: lock acquired
22:23:04 DISPATCHER: job (7, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
22:23:04 job_id: (7, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.008957032528480985, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.1250641745072685, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 16, 'num_filters_3': 22, 'num_filters_4': 63}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.008957032528480985, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.1250641745072685, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 16, 'num_filters_3': 22, 'num_filters_4': 63}"}}
exception: None

22:23:04 job_callback for (7, 0, 2) started
22:23:04 DISPATCHER: Trying to submit another job.
22:23:04 job_callback for (7, 0, 2) got condition
22:23:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:23:04 Only 15 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
22:23:04 HBMASTER: Trying to run another job!
22:23:04 job_callback for (7, 0, 2) finished
22:23:04 start sampling a new configuration.
22:23:04 best_vector: [2, 2, 0.2639676409968491, 0.17088516994312208, 0.39008101752655633, 1, 0.424308114760671, 0.4092408753323139, 0, 0, 2, 1, 0.6675248863538993, 0.16763838243859136, 0.6782784924891618, 0.5632435452298845], 2.221845220113338e-29, 0.00045007635588089674, -0.00013602825411056978
22:23:04 done sampling a new configuration.
22:23:04 HBMASTER: schedule new run for iteration 7
22:23:04 HBMASTER: trying submitting job (7, 0, 3) to dispatcher
22:23:04 HBMASTER: submitting job (7, 0, 3) to dispatcher
22:23:04 DISPATCHER: trying to submit job (7, 0, 3)
22:23:04 DISPATCHER: trying to notify the job_runner thread.
22:23:04 HBMASTER: job (7, 0, 3) submitted to dispatcher
22:23:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:23:04 DISPATCHER: Trying to submit another job.
22:23:04 DISPATCHER: starting job (7, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:23:04 DISPATCHER: job (7, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:23:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:23:04 WORKER: start processing job (7, 0, 3)
22:23:04 WORKER: args: ()
22:23:04 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003372370502818335, 'num_filters_1': 22, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.03407490504339617, 'kernel_size_2': 3, 'num_filters_2': 64}, 'budget': 1200.0, 'working_directory': '.'}
22:23:53 DISPATCHER: Starting worker discovery
22:23:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:23:53 DISPATCHER: Finished worker discovery
22:24:53 DISPATCHER: Starting worker discovery
22:24:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:24:53 DISPATCHER: Finished worker discovery
22:25:53 DISPATCHER: Starting worker discovery
22:25:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:25:53 DISPATCHER: Finished worker discovery
22:26:53 DISPATCHER: Starting worker discovery
22:26:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:26:53 DISPATCHER: Finished worker discovery
22:27:53 DISPATCHER: Starting worker discovery
22:27:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:27:53 DISPATCHER: Finished worker discovery
22:28:53 DISPATCHER: Starting worker discovery
22:28:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:28:53 DISPATCHER: Finished worker discovery
22:29:53 DISPATCHER: Starting worker discovery
22:29:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:29:53 DISPATCHER: Finished worker discovery
22:30:53 DISPATCHER: Starting worker discovery
22:30:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:30:53 DISPATCHER: Finished worker discovery
22:31:53 DISPATCHER: Starting worker discovery
22:31:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:31:53 DISPATCHER: Finished worker discovery
22:32:53 DISPATCHER: Starting worker discovery
22:32:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:32:53 DISPATCHER: Finished worker discovery
22:33:53 DISPATCHER: Starting worker discovery
22:33:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:33:53 DISPATCHER: Finished worker discovery
22:34:53 DISPATCHER: Starting worker discovery
22:34:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:34:53 DISPATCHER: Finished worker discovery
22:35:53 DISPATCHER: Starting worker discovery
22:35:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:35:53 DISPATCHER: Finished worker discovery
22:36:53 DISPATCHER: Starting worker discovery
22:36:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:36:53 DISPATCHER: Finished worker discovery
22:37:53 DISPATCHER: Starting worker discovery
22:37:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:37:53 DISPATCHER: Finished worker discovery
22:38:53 DISPATCHER: Starting worker discovery
22:38:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:38:53 DISPATCHER: Finished worker discovery
22:39:53 DISPATCHER: Starting worker discovery
22:39:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:39:53 DISPATCHER: Finished worker discovery
22:40:53 DISPATCHER: Starting worker discovery
22:40:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:40:53 DISPATCHER: Finished worker discovery
22:41:53 DISPATCHER: Starting worker discovery
22:41:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:41:53 DISPATCHER: Finished worker discovery
22:42:53 DISPATCHER: Starting worker discovery
22:42:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:42:53 DISPATCHER: Finished worker discovery
22:43:53 DISPATCHER: Starting worker discovery
22:43:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:43:54 DISPATCHER: Finished worker discovery
22:44:12 WORKER: done with job (7, 0, 3), trying to register it.
22:44:12 WORKER: registered result for job (7, 0, 3) with dispatcher
22:44:12 DISPATCHER: job (7, 0, 3) finished
22:44:12 DISPATCHER: register_result: lock acquired
22:44:12 DISPATCHER: job (7, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
22:44:12 job_id: (7, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003372370502818335, 'num_filters_1': 22, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.03407490504339617, 'kernel_size_2': 3, 'num_filters_2': 64}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.24052875261915313, 'info': {'data05': 0.24052875261915313, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003372370502818335, 'num_filters_1': 22, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.03407490504339617, 'kernel_size_2': 3, 'num_filters_2': 64}"}}
exception: None

22:44:12 job_callback for (7, 0, 3) started
22:44:12 job_callback for (7, 0, 3) got condition
22:44:12 DISPATCHER: Trying to submit another job.
22:44:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:44:12 Only 16 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
22:44:12 HBMASTER: Trying to run another job!
22:44:12 job_callback for (7, 0, 3) finished
22:44:12 start sampling a new configuration.
22:44:12 done sampling a new configuration.
22:44:12 HBMASTER: schedule new run for iteration 8
22:44:12 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
22:44:12 HBMASTER: submitting job (8, 0, 0) to dispatcher
22:44:12 DISPATCHER: trying to submit job (8, 0, 0)
22:44:12 DISPATCHER: trying to notify the job_runner thread.
22:44:12 HBMASTER: job (8, 0, 0) submitted to dispatcher
22:44:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:44:12 DISPATCHER: Trying to submit another job.
22:44:12 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:44:12 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:44:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:44:12 WORKER: start processing job (8, 0, 0)
22:44:12 WORKER: args: ()
22:44:12 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.015750280679331832, 'num_filters_1': 54, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.07251460922480514, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 26, 'num_filters_3': 43}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:44:54 DISPATCHER: Starting worker discovery
22:44:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:44:54 DISPATCHER: Finished worker discovery
22:45:15 WORKER: done with job (8, 0, 0), trying to register it.
22:45:15 WORKER: registered result for job (8, 0, 0) with dispatcher
22:45:15 DISPATCHER: job (8, 0, 0) finished
22:45:15 DISPATCHER: register_result: lock acquired
22:45:15 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
22:45:15 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.015750280679331832, 'num_filters_1': 54, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.07251460922480514, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 26, 'num_filters_3': 43}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.23800689285275903, 'info': {'data05': 0.23800689285275903, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.015750280679331832, 'num_filters_1': 54, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.07251460922480514, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 26, 'num_filters_3': 43}"}}
exception: None

22:45:15 job_callback for (8, 0, 0) started
22:45:15 DISPATCHER: Trying to submit another job.
22:45:15 job_callback for (8, 0, 0) got condition
22:45:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:45:15 HBMASTER: Trying to run another job!
22:45:15 job_callback for (8, 0, 0) finished
22:45:15 start sampling a new configuration.
22:45:15 best_vector: [0, 0, 0.054631760493378756, 0.7485952798725493, 0.6266140961532715, 1, 0.23101256348228422, 0.175228159819914, 0, 0, 0, 0, 0.5051244792907933, 0.4442970128679021, 0.11147213934681696, 0.9825419059311707], 9.198829583389678e-30, 0.0010870948210690843, -2.311221550632139e-08
22:45:15 done sampling a new configuration.
22:45:15 HBMASTER: schedule new run for iteration 8
22:45:15 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
22:45:15 HBMASTER: submitting job (8, 0, 1) to dispatcher
22:45:15 DISPATCHER: trying to submit job (8, 0, 1)
22:45:15 DISPATCHER: trying to notify the job_runner thread.
22:45:15 HBMASTER: job (8, 0, 1) submitted to dispatcher
22:45:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:45:15 DISPATCHER: Trying to submit another job.
22:45:15 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:45:15 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:45:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:45:15 WORKER: start processing job (8, 0, 1)
22:45:15 WORKER: args: ()
22:45:15 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0012860667821922502, 'num_filters_1': 76, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.016903517673018467, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 45, 'num_filters_3': 40, 'num_filters_4': 20}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:45:54 DISPATCHER: Starting worker discovery
22:45:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:45:54 DISPATCHER: Finished worker discovery
22:46:15 WORKER: done with job (8, 0, 1), trying to register it.
22:46:15 WORKER: registered result for job (8, 0, 1) with dispatcher
22:46:15 DISPATCHER: job (8, 0, 1) finished
22:46:15 DISPATCHER: register_result: lock acquired
22:46:15 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
22:46:15 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0012860667821922502, 'num_filters_1': 76, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.016903517673018467, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 45, 'num_filters_3': 40, 'num_filters_4': 20}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6086333770533293, 'info': {'data05': 0.6086333770533293, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0012860667821922502, 'num_filters_1': 76, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.016903517673018467, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 45, 'num_filters_3': 40, 'num_filters_4': 20}"}}
exception: None

22:46:15 job_callback for (8, 0, 1) started
22:46:15 DISPATCHER: Trying to submit another job.
22:46:15 job_callback for (8, 0, 1) got condition
22:46:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:46:15 HBMASTER: Trying to run another job!
22:46:15 job_callback for (8, 0, 1) finished
22:46:15 start sampling a new configuration.
22:46:15 best_vector: [3, 1, 0.4314948076492078, 0.9421003477964853, 0.9563781838579214, 1, 0.25921997945079245, 0.35278212750578386, 1, 2, 1, 1, 0.7989325815547554, 0.24538759040165364, 0.9568422608535186, 0.5341331668622831], 9.94672127330828e-30, 0.001005356410944649, -3.7632193792763935e-06
22:46:15 done sampling a new configuration.
22:46:15 HBMASTER: schedule new run for iteration 8
22:46:15 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
22:46:15 HBMASTER: submitting job (8, 0, 2) to dispatcher
22:46:15 DISPATCHER: trying to submit job (8, 0, 2)
22:46:15 DISPATCHER: trying to notify the job_runner thread.
22:46:15 HBMASTER: job (8, 0, 2) submitted to dispatcher
22:46:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:46:15 DISPATCHER: Trying to submit another job.
22:46:15 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:46:15 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:46:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:46:15 WORKER: start processing job (8, 0, 2)
22:46:15 WORKER: args: ()
22:46:15 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.007294400679238209, 'num_filters_1': 114, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.028772667687644467, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 84, 'num_filters_3': 26, 'num_filters_4': 117, 'num_filters_5': 48}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:46:54 DISPATCHER: Starting worker discovery
22:46:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:46:54 DISPATCHER: Finished worker discovery
22:47:13 WORKER: done with job (8, 0, 2), trying to register it.
22:47:13 WORKER: registered result for job (8, 0, 2) with dispatcher
22:47:13 DISPATCHER: job (8, 0, 2) finished
22:47:13 DISPATCHER: register_result: lock acquired
22:47:13 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
22:47:13 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.007294400679238209, 'num_filters_1': 114, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.028772667687644467, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 84, 'num_filters_3': 26, 'num_filters_4': 117, 'num_filters_5': 48}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.874272905523825, 'info': {'data05': 0.874272905523825, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.007294400679238209, 'num_filters_1': 114, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.028772667687644467, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 84, 'num_filters_3': 26, 'num_filters_4': 117, 'num_filters_5': 48}"}}
exception: None

22:47:13 job_callback for (8, 0, 2) started
22:47:13 DISPATCHER: Trying to submit another job.
22:47:13 job_callback for (8, 0, 2) got condition
22:47:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:47:13 HBMASTER: Trying to run another job!
22:47:13 job_callback for (8, 0, 2) finished
22:47:13 start sampling a new configuration.
22:47:13 best_vector: [1, 2, 0.6265353502159033, 0.34031128679649836, 0.5816599283898174, 1, 0.3782535192315723, 0.3158648952253562, 0, 1, 1, 2, 0.7036280989724842, 0.5001695232242068, 0.5312103670810471, 0.9814218402999615], 1.9050100530741e-29, 0.0005249316130307595, -2.163748617705618e-06
22:47:13 done sampling a new configuration.
22:47:13 HBMASTER: schedule new run for iteration 8
22:47:13 HBMASTER: trying submitting job (8, 0, 3) to dispatcher
22:47:13 HBMASTER: submitting job (8, 0, 3) to dispatcher
22:47:13 DISPATCHER: trying to submit job (8, 0, 3)
22:47:13 DISPATCHER: trying to notify the job_runner thread.
22:47:13 HBMASTER: job (8, 0, 3) submitted to dispatcher
22:47:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:47:13 DISPATCHER: Trying to submit another job.
22:47:13 DISPATCHER: starting job (8, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:47:13 DISPATCHER: job (8, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:47:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:47:13 WORKER: start processing job (8, 0, 3)
22:47:13 WORKER: args: ()
22:47:13 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.01790897377224006, 'num_filters_1': 32, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.02576022804056553, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 69, 'num_filters_3': 45}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:47:54 DISPATCHER: Starting worker discovery
22:47:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:47:54 DISPATCHER: Finished worker discovery
22:48:11 WORKER: done with job (8, 0, 3), trying to register it.
22:48:11 WORKER: registered result for job (8, 0, 3) with dispatcher
22:48:11 DISPATCHER: job (8, 0, 3) finished
22:48:11 DISPATCHER: register_result: lock acquired
22:48:11 DISPATCHER: job (8, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
22:48:11 job_id: (8, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.01790897377224006, 'num_filters_1': 32, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.02576022804056553, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 69, 'num_filters_3': 45}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4727674855688323, 'info': {'data05': 0.4727674855688323, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.01790897377224006, 'num_filters_1': 32, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.02576022804056553, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 69, 'num_filters_3': 45}"}}
exception: None

22:48:11 job_callback for (8, 0, 3) started
22:48:11 DISPATCHER: Trying to submit another job.
22:48:11 job_callback for (8, 0, 3) got condition
22:48:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:48:11 HBMASTER: Trying to run another job!
22:48:11 job_callback for (8, 0, 3) finished
22:48:11 start sampling a new configuration.
22:48:11 best_vector: [0, 0, 0.07867437248402684, 0.5109497665577774, 0.30288723702837145, 1, 0.6100807978574032, 0.3726812508393818, 0, 0, 1, 1, 0.8334268342265212, 0.3570464677705557, 0.5130663068765755, 0.7826357986974829], 1.1597895624001089e-30, 0.008622253833105423, -4.76822272369993e-05
22:48:11 done sampling a new configuration.
22:48:11 HBMASTER: schedule new run for iteration 8
22:48:11 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
22:48:11 HBMASTER: submitting job (8, 0, 4) to dispatcher
22:48:11 DISPATCHER: trying to submit job (8, 0, 4)
22:48:11 DISPATCHER: trying to notify the job_runner thread.
22:48:11 HBMASTER: job (8, 0, 4) submitted to dispatcher
22:48:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:48:11 DISPATCHER: Trying to submit another job.
22:48:11 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:48:11 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:48:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:48:11 WORKER: start processing job (8, 0, 4)
22:48:11 WORKER: args: ()
22:48:11 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0014366426157997171, 'num_filters_1': 46, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.030540031886573074, 'kernel_size_2': 3, 'num_filters_2': 90}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:48:54 DISPATCHER: Starting worker discovery
22:48:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:48:54 DISPATCHER: Finished worker discovery
22:49:09 WORKER: done with job (8, 0, 4), trying to register it.
22:49:09 WORKER: registered result for job (8, 0, 4) with dispatcher
22:49:09 DISPATCHER: job (8, 0, 4) finished
22:49:09 DISPATCHER: register_result: lock acquired
22:49:09 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
22:49:09 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0014366426157997171, 'num_filters_1': 46, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.030540031886573074, 'kernel_size_2': 3, 'num_filters_2': 90}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5359925014045266, 'info': {'data05': 0.5359925014045266, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0014366426157997171, 'num_filters_1': 46, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.030540031886573074, 'kernel_size_2': 3, 'num_filters_2': 90}"}}
exception: None

22:49:09 job_callback for (8, 0, 4) started
22:49:09 job_callback for (8, 0, 4) got condition
22:49:09 DISPATCHER: Trying to submit another job.
22:49:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:49:09 HBMASTER: Trying to run another job!
22:49:09 job_callback for (8, 0, 4) finished
22:49:09 start sampling a new configuration.
22:49:10 best_vector: [1, 1, 0.9381992021827188, 0.7806863564041271, 0.909082995359616, 1, 0.4023728756759076, 0.382619504604333, 0, 2, 2, 0, 0.8269447287011501, 0.6411231064743652, 0.2846571728308079, 0.6602790039675075], 4.233741467088351e-30, 0.002361977007272777, -1.5254203754251031e-06
22:49:10 done sampling a new configuration.
22:49:10 HBMASTER: schedule new run for iteration 8
22:49:10 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
22:49:10 HBMASTER: submitting job (8, 0, 5) to dispatcher
22:49:10 DISPATCHER: trying to submit job (8, 0, 5)
22:49:10 DISPATCHER: trying to notify the job_runner thread.
22:49:10 HBMASTER: job (8, 0, 5) submitted to dispatcher
22:49:10 DISPATCHER: Trying to submit another job.
22:49:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:49:10 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:49:10 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:49:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:49:10 WORKER: start processing job (8, 0, 5)
22:49:10 WORKER: args: ()
22:49:10 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.07523127191214016, 'num_filters_1': 81, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.03146295089128172, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 89, 'num_filters_3': 60, 'num_filters_4': 28, 'num_filters_5': 63}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:49:54 DISPATCHER: Starting worker discovery
22:49:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:49:54 DISPATCHER: Finished worker discovery
22:50:08 WORKER: done with job (8, 0, 5), trying to register it.
22:50:08 WORKER: registered result for job (8, 0, 5) with dispatcher
22:50:08 DISPATCHER: job (8, 0, 5) finished
22:50:08 DISPATCHER: register_result: lock acquired
22:50:08 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
22:50:08 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.07523127191214016, 'num_filters_1': 81, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.03146295089128172, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 89, 'num_filters_3': 60, 'num_filters_4': 28, 'num_filters_5': 63}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.18105423146597976, 'info': {'data05': 0.18105423146597976, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.07523127191214016, 'num_filters_1': 81, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.03146295089128172, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 89, 'num_filters_3': 60, 'num_filters_4': 28, 'num_filters_5': 63}"}}
exception: None

22:50:08 job_callback for (8, 0, 5) started
22:50:08 DISPATCHER: Trying to submit another job.
22:50:08 job_callback for (8, 0, 5) got condition
22:50:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:50:08 HBMASTER: Trying to run another job!
22:50:08 job_callback for (8, 0, 5) finished
22:50:08 start sampling a new configuration.
22:50:08 best_vector: [1, 0, 0.09801402388681779, 0.043691343546404915, 0.8646471100208935, 1, 0.7363686646484219, 0.35464378091397886, 1, 2, 1, 0, 0.7450404535700603, 0.2994811671666302, 0.9231955610991052, 0.6260636574553433], 3.938458943496666e-29, 0.00025390641729330156, -2.363434323924899e-06
22:50:08 done sampling a new configuration.
22:50:08 HBMASTER: schedule new run for iteration 8
22:50:08 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
22:50:08 HBMASTER: submitting job (8, 0, 6) to dispatcher
22:50:08 DISPATCHER: trying to submit job (8, 0, 6)
22:50:08 DISPATCHER: trying to notify the job_runner thread.
22:50:08 HBMASTER: job (8, 0, 6) submitted to dispatcher
22:50:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:50:08 DISPATCHER: Trying to submit another job.
22:50:08 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:50:08 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:50:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:50:08 WORKER: start processing job (8, 0, 6)
22:50:08 WORKER: args: ()
22:50:08 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0015704642253844736, 'num_filters_1': 17, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.028933581585148985, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 75, 'num_filters_3': 29, 'num_filters_4': 109, 'num_filters_5': 58}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:50:54 DISPATCHER: Starting worker discovery
22:50:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:50:54 DISPATCHER: Finished worker discovery
22:51:06 WORKER: done with job (8, 0, 6), trying to register it.
22:51:06 WORKER: registered result for job (8, 0, 6) with dispatcher
22:51:06 DISPATCHER: job (8, 0, 6) finished
22:51:06 DISPATCHER: register_result: lock acquired
22:51:06 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
22:51:06 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0015704642253844736, 'num_filters_1': 17, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.028933581585148985, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 75, 'num_filters_3': 29, 'num_filters_4': 109, 'num_filters_5': 58}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7749688424675321, 'info': {'data05': 0.7749688424675321, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0015704642253844736, 'num_filters_1': 17, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.028933581585148985, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 75, 'num_filters_3': 29, 'num_filters_4': 109, 'num_filters_5': 58}"}}
exception: None

22:51:06 job_callback for (8, 0, 6) started
22:51:06 DISPATCHER: Trying to submit another job.
22:51:06 job_callback for (8, 0, 6) got condition
22:51:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:51:06 HBMASTER: Trying to run another job!
22:51:06 job_callback for (8, 0, 6) finished
22:51:06 start sampling a new configuration.
22:51:06 best_vector: [0, 1, 0.5408826482344827, 0.7785167355408472, 0.6151824365313958, 1, 0.556065181987638, 0.15223250475170313, 2, 2, 2, 1, 0.689182523472539, 0.9879695558213514, 0.6480367341966277, 0.5966985378765446], 7.294561549640624e-30, 0.001370884313189826, -6.14028755803369e-05
22:51:06 done sampling a new configuration.
22:51:06 HBMASTER: schedule new run for iteration 8
22:51:06 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
22:51:06 HBMASTER: submitting job (8, 0, 7) to dispatcher
22:51:06 DISPATCHER: trying to submit job (8, 0, 7)
22:51:06 DISPATCHER: trying to notify the job_runner thread.
22:51:06 HBMASTER: job (8, 0, 7) submitted to dispatcher
22:51:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:51:06 DISPATCHER: Trying to submit another job.
22:51:06 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:51:06 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:51:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:51:06 WORKER: start processing job (8, 0, 7)
22:51:06 WORKER: args: ()
22:51:06 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.012071612788385956, 'num_filters_1': 80, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.01577825806533949, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 67, 'num_filters_3': 125, 'num_filters_4': 61}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:51:54 DISPATCHER: Starting worker discovery
22:51:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:51:54 DISPATCHER: Finished worker discovery
22:52:03 WORKER: done with job (8, 0, 7), trying to register it.
22:52:03 WORKER: registered result for job (8, 0, 7) with dispatcher
22:52:03 DISPATCHER: job (8, 0, 7) finished
22:52:03 DISPATCHER: register_result: lock acquired
22:52:03 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
22:52:03 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.012071612788385956, 'num_filters_1': 80, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.01577825806533949, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 67, 'num_filters_3': 125, 'num_filters_4': 61}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8929020945001654, 'info': {'data05': 0.8929020945001654, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.012071612788385956, 'num_filters_1': 80, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.01577825806533949, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 67, 'num_filters_3': 125, 'num_filters_4': 61}"}}
exception: None

22:52:03 job_callback for (8, 0, 7) started
22:52:03 DISPATCHER: Trying to submit another job.
22:52:03 job_callback for (8, 0, 7) got condition
22:52:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:52:03 HBMASTER: Trying to run another job!
22:52:03 job_callback for (8, 0, 7) finished
22:52:03 start sampling a new configuration.
22:52:03 best_vector: [0, 1, 0.359135313894233, 0.40918192516787355, 0.7774542530280562, 1, 0.9932208341301805, 0.08349290253042521, 0, 0, 0, 1, 0.6321911708009929, 0.8084656423593952, 0.26607873515130587, 0.9147102683056678], 8.731343533554635e-30, 0.0011452991125099942, -3.2045663888942006e-06
22:52:03 done sampling a new configuration.
22:52:03 HBMASTER: schedule new run for iteration 8
22:52:03 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
22:52:03 HBMASTER: submitting job (8, 0, 8) to dispatcher
22:52:03 DISPATCHER: trying to submit job (8, 0, 8)
22:52:03 DISPATCHER: trying to notify the job_runner thread.
22:52:03 HBMASTER: job (8, 0, 8) submitted to dispatcher
22:52:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:52:03 DISPATCHER: Trying to submit another job.
22:52:03 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:52:03 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:52:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:52:03 WORKER: start processing job (8, 0, 8)
22:52:03 WORKER: args: ()
22:52:03 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.005227218182410499, 'num_filters_1': 37, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.012841825688309138, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 59, 'num_filters_3': 86, 'num_filters_4': 27}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:52:54 DISPATCHER: Starting worker discovery
22:52:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:52:54 DISPATCHER: Finished worker discovery
22:53:01 WORKER: done with job (8, 0, 8), trying to register it.
22:53:01 WORKER: registered result for job (8, 0, 8) with dispatcher
22:53:01 DISPATCHER: job (8, 0, 8) finished
22:53:01 DISPATCHER: register_result: lock acquired
22:53:01 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
22:53:01 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.005227218182410499, 'num_filters_1': 37, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.012841825688309138, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 59, 'num_filters_3': 86, 'num_filters_4': 27}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8108798368142895, 'info': {'data05': 0.8108798368142895, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.005227218182410499, 'num_filters_1': 37, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.012841825688309138, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 59, 'num_filters_3': 86, 'num_filters_4': 27}"}}
exception: None

22:53:01 job_callback for (8, 0, 8) started
22:53:01 DISPATCHER: Trying to submit another job.
22:53:01 job_callback for (8, 0, 8) got condition
22:53:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:53:01 HBMASTER: Trying to run another job!
22:53:01 job_callback for (8, 0, 8) finished
22:53:01 start sampling a new configuration.
22:53:01 best_vector: [0, 1, 0.1674441143482454, 0.3575666986530984, 0.5882923267706032, 1, 0.4345958429449507, 0.1516526553266704, 1, 0, 2, 1, 0.4399142448322039, 0.8346292841516145, 0.6182781224311915, 0.7397576081470204], 3.058918773045024e-30, 0.0032691289772449317, -2.21655735973344e-06
22:53:01 done sampling a new configuration.
22:53:01 HBMASTER: schedule new run for iteration 8
22:53:01 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
22:53:01 HBMASTER: submitting job (8, 0, 9) to dispatcher
22:53:01 DISPATCHER: trying to submit job (8, 0, 9)
22:53:01 DISPATCHER: trying to notify the job_runner thread.
22:53:01 HBMASTER: job (8, 0, 9) submitted to dispatcher
22:53:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:53:01 DISPATCHER: Trying to submit another job.
22:53:01 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:53:01 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:53:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:53:01 WORKER: start processing job (8, 0, 9)
22:53:01 WORKER: args: ()
22:53:01 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002162161991753658, 'num_filters_1': 33, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.015750873860302442, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 39, 'num_filters_3': 91}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:53:54 DISPATCHER: Starting worker discovery
22:53:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:53:54 DISPATCHER: Finished worker discovery
22:53:59 WORKER: done with job (8, 0, 9), trying to register it.
22:53:59 WORKER: registered result for job (8, 0, 9) with dispatcher
22:53:59 DISPATCHER: job (8, 0, 9) finished
22:53:59 DISPATCHER: register_result: lock acquired
22:53:59 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
22:53:59 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002162161991753658, 'num_filters_1': 33, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.015750873860302442, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 39, 'num_filters_3': 91}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7410977100363486, 'info': {'data05': 0.7410977100363486, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002162161991753658, 'num_filters_1': 33, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.015750873860302442, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 39, 'num_filters_3': 91}"}}
exception: None

22:53:59 job_callback for (8, 0, 9) started
22:53:59 job_callback for (8, 0, 9) got condition
22:53:59 DISPATCHER: Trying to submit another job.
22:53:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:53:59 HBMASTER: Trying to run another job!
22:53:59 job_callback for (8, 0, 9) finished
22:53:59 start sampling a new configuration.
22:54:00 best_vector: [0, 0, 5.045353463978275e-05, 0.16499832140291174, 0.010968228194787322, 1, 0.9161472249611664, 0.09770525031665384, 0, 1, 2, 1, 0.28438288223268454, 0.08604375577725777, 0.3127781220852093, 0.6599853550519967], 1.350339576040282e-29, 0.0007405544632946232, -1.1020421925350933e-06
22:54:00 done sampling a new configuration.
22:54:00 HBMASTER: schedule new run for iteration 8
22:54:00 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
22:54:00 HBMASTER: submitting job (8, 0, 10) to dispatcher
22:54:00 DISPATCHER: trying to submit job (8, 0, 10)
22:54:00 DISPATCHER: trying to notify the job_runner thread.
22:54:00 HBMASTER: job (8, 0, 10) submitted to dispatcher
22:54:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:54:00 DISPATCHER: Trying to submit another job.
22:54:00 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:54:00 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:54:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:54:00 WORKER: start processing job (8, 0, 10)
22:54:00 WORKER: args: ()
22:54:00 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0010002323741081826, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.01340039071896266}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:54:54 DISPATCHER: Starting worker discovery
22:54:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:54:54 DISPATCHER: Finished worker discovery
22:54:57 WORKER: done with job (8, 0, 10), trying to register it.
22:54:57 WORKER: registered result for job (8, 0, 10) with dispatcher
22:54:57 DISPATCHER: job (8, 0, 10) finished
22:54:57 DISPATCHER: register_result: lock acquired
22:54:57 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
22:54:57 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0010002323741081826, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.01340039071896266}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.521891488615628, 'info': {'data05': 0.521891488615628, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0010002323741081826, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.01340039071896266}"}}
exception: None

22:54:57 job_callback for (8, 0, 10) started
22:54:57 DISPATCHER: Trying to submit another job.
22:54:57 job_callback for (8, 0, 10) got condition
22:54:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:54:57 HBMASTER: Trying to run another job!
22:54:57 job_callback for (8, 0, 10) finished
22:54:57 start sampling a new configuration.
22:54:58 best_vector: [0, 1, 0.09417372717811308, 0.6148931393483774, 0.5043594246039875, 1, 0.9427572671209253, 0.6730470655794214, 1, 1, 0, 1, 0.8147208385224071, 0.3809185156418413, 0.56347681371871, 0.4546562383727098], 4.9281837138714476e-29, 0.00020291451335007702, -9.992290566026995e-05
22:54:58 done sampling a new configuration.
22:54:58 HBMASTER: schedule new run for iteration 8
22:54:58 HBMASTER: trying submitting job (8, 0, 11) to dispatcher
22:54:58 HBMASTER: submitting job (8, 0, 11) to dispatcher
22:54:58 DISPATCHER: trying to submit job (8, 0, 11)
22:54:58 DISPATCHER: trying to notify the job_runner thread.
22:54:58 HBMASTER: job (8, 0, 11) submitted to dispatcher
22:54:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:54:58 DISPATCHER: Trying to submit another job.
22:54:58 DISPATCHER: starting job (8, 0, 11) on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:54:58 DISPATCHER: job (8, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:54:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:54:58 WORKER: start processing job (8, 0, 11)
22:54:58 WORKER: args: ()
22:54:58 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001542934373475034, 'num_filters_1': 57, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.07510250464186292, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 87, 'num_filters_3': 35}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:55:54 DISPATCHER: Starting worker discovery
22:55:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:55:54 DISPATCHER: Finished worker discovery
22:55:55 WORKER: done with job (8, 0, 11), trying to register it.
22:55:55 WORKER: registered result for job (8, 0, 11) with dispatcher
22:55:55 DISPATCHER: job (8, 0, 11) finished
22:55:55 DISPATCHER: register_result: lock acquired
22:55:55 DISPATCHER: job (8, 0, 11) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
22:55:55 job_id: (8, 0, 11)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001542934373475034, 'num_filters_1': 57, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.07510250464186292, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 87, 'num_filters_3': 35}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6269775311836303, 'info': {'data05': 0.6269775311836303, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001542934373475034, 'num_filters_1': 57, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.07510250464186292, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 87, 'num_filters_3': 35}"}}
exception: None

22:55:55 job_callback for (8, 0, 11) started
22:55:55 job_callback for (8, 0, 11) got condition
22:55:55 DISPATCHER: Trying to submit another job.
22:55:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:55:55 HBMASTER: Trying to run another job!
22:55:55 job_callback for (8, 0, 11) finished
22:55:55 start sampling a new configuration.
22:55:55 best_vector: [1, 0, 0.49482135997757004, 0.053740037541397556, 0.927250538863233, 0, 0.9233564289566101, 0.45224033294585797, 0, 1, 2, 0, 0.5358022939688529, 0.6556622926595919, 0.7839778572672923, 0.7040202897038426], 1.067156751400041e-29, 0.0009370694592786527, -5.650462063894465e-06
22:55:55 done sampling a new configuration.
22:55:55 HBMASTER: schedule new run for iteration 8
22:55:55 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
22:55:55 HBMASTER: submitting job (8, 0, 12) to dispatcher
22:55:55 DISPATCHER: trying to submit job (8, 0, 12)
22:55:55 DISPATCHER: trying to notify the job_runner thread.
22:55:55 HBMASTER: job (8, 0, 12) submitted to dispatcher
22:55:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:55:55 DISPATCHER: Trying to submit another job.
22:55:55 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:55:55 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:55:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:55:55 WORKER: start processing job (8, 0, 12)
22:55:55 WORKER: args: ()
22:55:55 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.00976433610051387, 'num_filters_1': 17, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.038759506463542294, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 48, 'num_filters_3': 62, 'num_filters_4': 81, 'num_filters_5': 69}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:56:53 WORKER: done with job (8, 0, 12), trying to register it.
22:56:53 WORKER: registered result for job (8, 0, 12) with dispatcher
22:56:53 DISPATCHER: job (8, 0, 12) finished
22:56:53 DISPATCHER: register_result: lock acquired
22:56:53 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
22:56:53 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.00976433610051387, 'num_filters_1': 17, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.038759506463542294, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 48, 'num_filters_3': 62, 'num_filters_4': 81, 'num_filters_5': 69}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.00976433610051387, 'num_filters_1': 17, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.038759506463542294, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 48, 'num_filters_3': 62, 'num_filters_4': 81, 'num_filters_5': 69}"}}
exception: None

22:56:53 job_callback for (8, 0, 12) started
22:56:53 DISPATCHER: Trying to submit another job.
22:56:53 job_callback for (8, 0, 12) got condition
22:56:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:56:53 HBMASTER: Trying to run another job!
22:56:53 job_callback for (8, 0, 12) finished
22:56:53 start sampling a new configuration.
22:56:54 best_vector: [0, 2, 0.8349858691161127, 0.6266993059769861, 0.4126145745765828, 1, 0.3476511748482911, 0.04025920233109276, 1, 1, 1, 0, 0.39685292146360773, 0.22734374891778886, 0.4363421418041008, 0.6065556327047705], 3.0520122615913172e-30, 0.0032765268101465645, -2.6030545227196077e-05
22:56:54 done sampling a new configuration.
22:56:54 HBMASTER: schedule new run for iteration 8
22:56:54 HBMASTER: trying submitting job (8, 0, 13) to dispatcher
22:56:54 HBMASTER: submitting job (8, 0, 13) to dispatcher
22:56:54 DISPATCHER: trying to submit job (8, 0, 13)
22:56:54 DISPATCHER: trying to notify the job_runner thread.
22:56:54 HBMASTER: job (8, 0, 13) submitted to dispatcher
22:56:54 DISPATCHER: Trying to submit another job.
22:56:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:56:54 DISPATCHER: starting job (8, 0, 13) on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:56:54 DISPATCHER: job (8, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:56:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:56:54 WORKER: start processing job (8, 0, 13)
22:56:54 WORKER: args: ()
22:56:54 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.04677047043546827, 'num_filters_1': 58, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.011281800867767821, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 36, 'num_filters_3': 25}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:56:54 DISPATCHER: Starting worker discovery
22:56:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:56:54 DISPATCHER: Finished worker discovery
22:57:53 WORKER: done with job (8, 0, 13), trying to register it.
22:57:53 WORKER: registered result for job (8, 0, 13) with dispatcher
22:57:53 DISPATCHER: job (8, 0, 13) finished
22:57:53 DISPATCHER: register_result: lock acquired
22:57:53 DISPATCHER: job (8, 0, 13) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
22:57:53 job_id: (8, 0, 13)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.04677047043546827, 'num_filters_1': 58, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.011281800867767821, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 36, 'num_filters_3': 25}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.18174180453047842, 'info': {'data05': 0.18174180453047842, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.04677047043546827, 'num_filters_1': 58, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.011281800867767821, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 36, 'num_filters_3': 25}"}}
exception: None

22:57:53 job_callback for (8, 0, 13) started
22:57:53 job_callback for (8, 0, 13) got condition
22:57:53 DISPATCHER: Trying to submit another job.
22:57:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:57:53 HBMASTER: Trying to run another job!
22:57:53 job_callback for (8, 0, 13) finished
22:57:53 start sampling a new configuration.
22:57:53 done sampling a new configuration.
22:57:53 HBMASTER: schedule new run for iteration 8
22:57:53 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
22:57:53 HBMASTER: submitting job (8, 0, 14) to dispatcher
22:57:53 DISPATCHER: trying to submit job (8, 0, 14)
22:57:53 DISPATCHER: trying to notify the job_runner thread.
22:57:53 HBMASTER: job (8, 0, 14) submitted to dispatcher
22:57:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:57:53 DISPATCHER: Trying to submit another job.
22:57:53 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:57:53 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:57:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:57:53 WORKER: start processing job (8, 0, 14)
22:57:53 WORKER: args: ()
22:57:53 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0010986664108778837, 'num_filters_1': 45, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.027087402095232214, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 35, 'num_filters_3': 68, 'num_filters_4': 21}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:57:54 DISPATCHER: Starting worker discovery
22:57:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:57:54 DISPATCHER: Finished worker discovery
22:58:50 WORKER: done with job (8, 0, 14), trying to register it.
22:58:50 WORKER: registered result for job (8, 0, 14) with dispatcher
22:58:50 DISPATCHER: job (8, 0, 14) finished
22:58:50 DISPATCHER: register_result: lock acquired
22:58:50 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
22:58:50 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0010986664108778837, 'num_filters_1': 45, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.027087402095232214, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 35, 'num_filters_3': 68, 'num_filters_4': 21}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6076044797415024, 'info': {'data05': 0.6076044797415024, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0010986664108778837, 'num_filters_1': 45, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.027087402095232214, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 35, 'num_filters_3': 68, 'num_filters_4': 21}"}}
exception: None

22:58:50 job_callback for (8, 0, 14) started
22:58:50 DISPATCHER: Trying to submit another job.
22:58:50 job_callback for (8, 0, 14) got condition
22:58:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:58:50 HBMASTER: Trying to run another job!
22:58:50 job_callback for (8, 0, 14) finished
22:58:50 start sampling a new configuration.
22:58:50 best_vector: [1, 0, 0.6045134596079258, 0.23051585293702764, 0.8351607618963439, 0, 0.6373231019749953, 0.25564541030486115, 0, 2, 2, 0, 0.573582201024, 0.4499591182908751, 0.7345399844990622, 0.6530366775438792], 1.733545518481317e-30, 0.005768524618125148, -1.1596546744620986e-05
22:58:50 done sampling a new configuration.
22:58:50 HBMASTER: schedule new run for iteration 8
22:58:50 HBMASTER: trying submitting job (8, 0, 15) to dispatcher
22:58:50 HBMASTER: submitting job (8, 0, 15) to dispatcher
22:58:50 DISPATCHER: trying to submit job (8, 0, 15)
22:58:50 DISPATCHER: trying to notify the job_runner thread.
22:58:50 HBMASTER: job (8, 0, 15) submitted to dispatcher
22:58:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:58:50 DISPATCHER: Trying to submit another job.
22:58:50 DISPATCHER: starting job (8, 0, 15) on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:58:50 DISPATCHER: job (8, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:58:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:58:50 WORKER: start processing job (8, 0, 15)
22:58:50 WORKER: args: ()
22:58:50 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.016181803354768397, 'num_filters_1': 25, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.021508114859109983, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 52, 'num_filters_3': 40, 'num_filters_4': 73, 'num_filters_5': 62}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:58:54 DISPATCHER: Starting worker discovery
22:58:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:58:54 DISPATCHER: Finished worker discovery
22:59:47 WORKER: done with job (8, 0, 15), trying to register it.
22:59:47 WORKER: registered result for job (8, 0, 15) with dispatcher
22:59:47 DISPATCHER: job (8, 0, 15) finished
22:59:47 DISPATCHER: register_result: lock acquired
22:59:47 DISPATCHER: job (8, 0, 15) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
22:59:47 job_id: (8, 0, 15)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.016181803354768397, 'num_filters_1': 25, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.021508114859109983, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 52, 'num_filters_3': 40, 'num_filters_4': 73, 'num_filters_5': 62}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.016181803354768397, 'num_filters_1': 25, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.021508114859109983, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 52, 'num_filters_3': 40, 'num_filters_4': 73, 'num_filters_5': 62}"}}
exception: None

22:59:47 job_callback for (8, 0, 15) started
22:59:47 DISPATCHER: Trying to submit another job.
22:59:47 job_callback for (8, 0, 15) got condition
22:59:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:59:47 HBMASTER: Trying to run another job!
22:59:47 job_callback for (8, 0, 15) finished
22:59:47 start sampling a new configuration.
22:59:47 done sampling a new configuration.
22:59:47 HBMASTER: schedule new run for iteration 8
22:59:47 HBMASTER: trying submitting job (8, 0, 16) to dispatcher
22:59:47 HBMASTER: submitting job (8, 0, 16) to dispatcher
22:59:47 DISPATCHER: trying to submit job (8, 0, 16)
22:59:47 DISPATCHER: trying to notify the job_runner thread.
22:59:47 HBMASTER: job (8, 0, 16) submitted to dispatcher
22:59:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:59:47 DISPATCHER: Trying to submit another job.
22:59:47 DISPATCHER: starting job (8, 0, 16) on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:59:47 DISPATCHER: job (8, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:59:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:59:47 WORKER: start processing job (8, 0, 16)
22:59:47 WORKER: args: ()
22:59:47 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.030942575536933227, 'num_filters_1': 23, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.10597832929785897, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 74, 'num_filters_3': 122, 'num_filters_4': 43, 'num_filters_5': 71}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:59:54 DISPATCHER: Starting worker discovery
22:59:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:59:54 DISPATCHER: Finished worker discovery
23:00:45 WORKER: done with job (8, 0, 16), trying to register it.
23:00:45 WORKER: registered result for job (8, 0, 16) with dispatcher
23:00:45 DISPATCHER: job (8, 0, 16) finished
23:00:45 DISPATCHER: register_result: lock acquired
23:00:45 DISPATCHER: job (8, 0, 16) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:00:45 job_id: (8, 0, 16)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.030942575536933227, 'num_filters_1': 23, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.10597832929785897, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 74, 'num_filters_3': 122, 'num_filters_4': 43, 'num_filters_5': 71}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.030942575536933227, 'num_filters_1': 23, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.10597832929785897, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 74, 'num_filters_3': 122, 'num_filters_4': 43, 'num_filters_5': 71}"}}
exception: None

23:00:45 job_callback for (8, 0, 16) started
23:00:45 job_callback for (8, 0, 16) got condition
23:00:45 DISPATCHER: Trying to submit another job.
23:00:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:00:45 HBMASTER: Trying to run another job!
23:00:45 job_callback for (8, 0, 16) finished
23:00:45 start sampling a new configuration.
23:00:46 best_vector: [0, 0, 0.9080992731382242, 0.799728952623171, 0.8451053589043356, 1, 0.4405825674363384, 0.12141758148521636, 1, 0, 1, 0, 0.6399718531993415, 0.5406822052395, 0.8124280710294163, 0.5428221856140237], 4.443469015329682e-30, 0.0022504939193906033, -0.00016783509995910403
23:00:46 done sampling a new configuration.
23:00:46 HBMASTER: schedule new run for iteration 8
23:00:46 HBMASTER: trying submitting job (8, 0, 17) to dispatcher
23:00:46 HBMASTER: submitting job (8, 0, 17) to dispatcher
23:00:46 DISPATCHER: trying to submit job (8, 0, 17)
23:00:46 DISPATCHER: trying to notify the job_runner thread.
23:00:46 HBMASTER: job (8, 0, 17) submitted to dispatcher
23:00:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:00:46 DISPATCHER: Trying to submit another job.
23:00:46 DISPATCHER: starting job (8, 0, 17) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:00:46 DISPATCHER: job (8, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:00:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:00:46 WORKER: start processing job (8, 0, 17)
23:00:46 WORKER: args: ()
23:00:46 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.06549355223094976, 'num_filters_1': 84, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.014386922876841382, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 60, 'num_filters_3': 49, 'num_filters_4': 86, 'num_filters_5': 49}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:00:54 DISPATCHER: Starting worker discovery
23:00:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:00:54 DISPATCHER: Finished worker discovery
23:01:44 WORKER: done with job (8, 0, 17), trying to register it.
23:01:44 WORKER: registered result for job (8, 0, 17) with dispatcher
23:01:44 DISPATCHER: job (8, 0, 17) finished
23:01:44 DISPATCHER: register_result: lock acquired
23:01:44 DISPATCHER: job (8, 0, 17) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:01:44 job_id: (8, 0, 17)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.06549355223094976, 'num_filters_1': 84, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.014386922876841382, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 60, 'num_filters_3': 49, 'num_filters_4': 86, 'num_filters_5': 49}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.09933539208246123, 'info': {'data05': 0.09933539208246123, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.06549355223094976, 'num_filters_1': 84, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.014386922876841382, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 60, 'num_filters_3': 49, 'num_filters_4': 86, 'num_filters_5': 49}"}}
exception: None

23:01:44 job_callback for (8, 0, 17) started
23:01:44 job_callback for (8, 0, 17) got condition
23:01:44 DISPATCHER: Trying to submit another job.
23:01:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:01:44 HBMASTER: Trying to run another job!
23:01:44 job_callback for (8, 0, 17) finished
23:01:44 start sampling a new configuration.
23:01:44 done sampling a new configuration.
23:01:44 HBMASTER: schedule new run for iteration 8
23:01:44 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
23:01:44 HBMASTER: submitting job (8, 0, 18) to dispatcher
23:01:44 DISPATCHER: trying to submit job (8, 0, 18)
23:01:44 DISPATCHER: trying to notify the job_runner thread.
23:01:44 HBMASTER: job (8, 0, 18) submitted to dispatcher
23:01:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:01:44 DISPATCHER: Trying to submit another job.
23:01:44 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:01:44 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:01:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:01:44 WORKER: start processing job (8, 0, 18)
23:01:44 WORKER: args: ()
23:01:44 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.008989692520984744, 'num_filters_1': 28, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.09118996130464593, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 62, 'num_filters_3': 29, 'num_filters_4': 37}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:01:54 DISPATCHER: Starting worker discovery
23:01:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:01:54 DISPATCHER: Finished worker discovery
23:02:42 WORKER: done with job (8, 0, 18), trying to register it.
23:02:42 WORKER: registered result for job (8, 0, 18) with dispatcher
23:02:42 DISPATCHER: job (8, 0, 18) finished
23:02:42 DISPATCHER: register_result: lock acquired
23:02:42 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:02:42 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.008989692520984744, 'num_filters_1': 28, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.09118996130464593, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 62, 'num_filters_3': 29, 'num_filters_4': 37}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -4.0890045279706366e-05, 'info': {'data05': 4.0890045279706366e-05, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.008989692520984744, 'num_filters_1': 28, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.09118996130464593, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 62, 'num_filters_3': 29, 'num_filters_4': 37}"}}
exception: None

23:02:42 job_callback for (8, 0, 18) started
23:02:42 job_callback for (8, 0, 18) got condition
23:02:42 DISPATCHER: Trying to submit another job.
23:02:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:02:42 HBMASTER: Trying to run another job!
23:02:42 job_callback for (8, 0, 18) finished
23:02:42 start sampling a new configuration.
23:02:43 done sampling a new configuration.
23:02:43 HBMASTER: schedule new run for iteration 8
23:02:43 HBMASTER: trying submitting job (8, 0, 19) to dispatcher
23:02:43 HBMASTER: submitting job (8, 0, 19) to dispatcher
23:02:43 DISPATCHER: trying to submit job (8, 0, 19)
23:02:43 DISPATCHER: trying to notify the job_runner thread.
23:02:43 HBMASTER: job (8, 0, 19) submitted to dispatcher
23:02:43 DISPATCHER: Trying to submit another job.
23:02:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:02:43 DISPATCHER: starting job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:02:43 DISPATCHER: job (8, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:02:43 WORKER: start processing job (8, 0, 19)
23:02:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:02:43 WORKER: args: ()
23:02:43 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0576512849230076, 'num_filters_1': 35, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.021360842550517407}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:02:54 DISPATCHER: Starting worker discovery
23:02:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:02:54 DISPATCHER: Finished worker discovery
23:03:40 WORKER: done with job (8, 0, 19), trying to register it.
23:03:40 WORKER: registered result for job (8, 0, 19) with dispatcher
23:03:40 DISPATCHER: job (8, 0, 19) finished
23:03:40 DISPATCHER: register_result: lock acquired
23:03:40 DISPATCHER: job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:03:40 job_id: (8, 0, 19)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0576512849230076, 'num_filters_1': 35, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.021360842550517407}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.032289213604516455, 'info': {'data05': 0.032289213604516455, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0576512849230076, 'num_filters_1': 35, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.021360842550517407}"}}
exception: None

23:03:40 job_callback for (8, 0, 19) started
23:03:40 DISPATCHER: Trying to submit another job.
23:03:40 job_callback for (8, 0, 19) got condition
23:03:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:03:40 HBMASTER: Trying to run another job!
23:03:40 job_callback for (8, 0, 19) finished
23:03:40 start sampling a new configuration.
23:03:41 best_vector: [0, 2, 0.06867830137066705, 0.35564035738813143, 0.2548133004136478, 1, 0.6186674273787462, 0.18487640029151686, 0, 2, 0, 0, 0.808685432490528, 0.5489552059784187, 0.09746655109328406, 0.6100076819757276], 1.412332859820766e-30, 0.007080483846611813, -0.0009292198582862883
23:03:41 done sampling a new configuration.
23:03:41 HBMASTER: schedule new run for iteration 8
23:03:41 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
23:03:41 HBMASTER: submitting job (8, 0, 20) to dispatcher
23:03:41 DISPATCHER: trying to submit job (8, 0, 20)
23:03:41 DISPATCHER: trying to notify the job_runner thread.
23:03:41 HBMASTER: job (8, 0, 20) submitted to dispatcher
23:03:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:03:41 DISPATCHER: Trying to submit another job.
23:03:41 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:03:41 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:03:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:03:41 WORKER: start processing job (8, 0, 20)
23:03:41 WORKER: args: ()
23:03:41 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.001372007870627908, 'num_filters_1': 33, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.01739921850951918, 'kernel_size_2': 3, 'num_filters_2': 86}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:03:54 DISPATCHER: Starting worker discovery
23:03:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:03:54 DISPATCHER: Finished worker discovery
23:04:39 WORKER: done with job (8, 0, 20), trying to register it.
23:04:39 WORKER: registered result for job (8, 0, 20) with dispatcher
23:04:39 DISPATCHER: job (8, 0, 20) finished
23:04:39 DISPATCHER: register_result: lock acquired
23:04:39 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:04:39 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.001372007870627908, 'num_filters_1': 33, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.01739921850951918, 'kernel_size_2': 3, 'num_filters_2': 86}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5737865805225141, 'info': {'data05': 0.5737865805225141, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.001372007870627908, 'num_filters_1': 33, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.01739921850951918, 'kernel_size_2': 3, 'num_filters_2': 86}"}}
exception: None

23:04:39 job_callback for (8, 0, 20) started
23:04:39 job_callback for (8, 0, 20) got condition
23:04:39 DISPATCHER: Trying to submit another job.
23:04:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:04:39 HBMASTER: Trying to run another job!
23:04:39 job_callback for (8, 0, 20) finished
23:04:39 start sampling a new configuration.
23:04:39 done sampling a new configuration.
23:04:39 HBMASTER: schedule new run for iteration 8
23:04:39 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
23:04:39 HBMASTER: submitting job (8, 0, 21) to dispatcher
23:04:39 DISPATCHER: trying to submit job (8, 0, 21)
23:04:39 DISPATCHER: trying to notify the job_runner thread.
23:04:39 HBMASTER: job (8, 0, 21) submitted to dispatcher
23:04:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:04:39 DISPATCHER: Trying to submit another job.
23:04:39 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:04:39 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:04:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:04:39 WORKER: start processing job (8, 0, 21)
23:04:39 WORKER: args: ()
23:04:39 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0051581282119107265, 'num_filters_1': 37, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.03005616183795845, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 22, 'num_filters_3': 82, 'num_filters_4': 96, 'num_filters_5': 21}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:04:54 DISPATCHER: Starting worker discovery
23:04:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:04:54 DISPATCHER: Finished worker discovery
23:05:36 WORKER: done with job (8, 0, 21), trying to register it.
23:05:36 WORKER: registered result for job (8, 0, 21) with dispatcher
23:05:36 DISPATCHER: job (8, 0, 21) finished
23:05:36 DISPATCHER: register_result: lock acquired
23:05:36 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:05:36 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0051581282119107265, 'num_filters_1': 37, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.03005616183795845, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 22, 'num_filters_3': 82, 'num_filters_4': 96, 'num_filters_5': 21}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.44889004161522356, 'info': {'data05': 0.44889004161522356, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0051581282119107265, 'num_filters_1': 37, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.03005616183795845, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 22, 'num_filters_3': 82, 'num_filters_4': 96, 'num_filters_5': 21}"}}
exception: None

23:05:36 job_callback for (8, 0, 21) started
23:05:36 job_callback for (8, 0, 21) got condition
23:05:36 DISPATCHER: Trying to submit another job.
23:05:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:05:36 HBMASTER: Trying to run another job!
23:05:36 job_callback for (8, 0, 21) finished
23:05:36 start sampling a new configuration.
23:05:36 done sampling a new configuration.
23:05:36 HBMASTER: schedule new run for iteration 8
23:05:36 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
23:05:36 HBMASTER: submitting job (8, 0, 22) to dispatcher
23:05:36 DISPATCHER: trying to submit job (8, 0, 22)
23:05:36 DISPATCHER: trying to notify the job_runner thread.
23:05:36 HBMASTER: job (8, 0, 22) submitted to dispatcher
23:05:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:05:36 DISPATCHER: Trying to submit another job.
23:05:36 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:05:36 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:05:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:05:36 WORKER: start processing job (8, 0, 22)
23:05:36 WORKER: args: ()
23:05:36 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.003363920815586973, 'num_filters_1': 29, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 33, 'weight_decay': 0.06857803325747419, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 30, 'num_filters_3': 21, 'num_filters_4': 102}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:05:54 DISPATCHER: Starting worker discovery
23:05:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:05:54 DISPATCHER: Finished worker discovery
23:06:34 WORKER: done with job (8, 0, 22), trying to register it.
23:06:34 WORKER: registered result for job (8, 0, 22) with dispatcher
23:06:34 DISPATCHER: job (8, 0, 22) finished
23:06:34 DISPATCHER: register_result: lock acquired
23:06:34 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:06:34 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.003363920815586973, 'num_filters_1': 29, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 33, 'weight_decay': 0.06857803325747419, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 30, 'num_filters_3': 21, 'num_filters_4': 102}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5414721685478942, 'info': {'data05': 0.5414721685478942, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.003363920815586973, 'num_filters_1': 29, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 33, 'weight_decay': 0.06857803325747419, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 30, 'num_filters_3': 21, 'num_filters_4': 102}"}}
exception: None

23:06:34 job_callback for (8, 0, 22) started
23:06:34 job_callback for (8, 0, 22) got condition
23:06:34 DISPATCHER: Trying to submit another job.
23:06:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:06:34 HBMASTER: Trying to run another job!
23:06:34 job_callback for (8, 0, 22) finished
23:06:34 start sampling a new configuration.
23:06:34 best_vector: [2, 2, 0.3640217890295042, 0.8256378796610284, 0.7934461320214709, 0, 0.5806989834340235, 0.42613481516769314, 1, 2, 1, 0, 0.0025683776944158965, 0.8326516973220021, 0.3659221503016927, 0.5572060205353937], 2.8431782348839603e-29, 0.0003517190683758922, -1.7234821715486017e-05
23:06:34 done sampling a new configuration.
23:06:34 HBMASTER: schedule new run for iteration 8
23:06:34 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
23:06:34 HBMASTER: submitting job (8, 0, 23) to dispatcher
23:06:34 DISPATCHER: trying to submit job (8, 0, 23)
23:06:34 DISPATCHER: trying to notify the job_runner thread.
23:06:34 HBMASTER: job (8, 0, 23) submitted to dispatcher
23:06:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:06:34 DISPATCHER: Trying to submit another job.
23:06:34 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:06:34 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:06:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:06:34 WORKER: start processing job (8, 0, 23)
23:06:34 WORKER: args: ()
23:06:34 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0053461800144621935, 'num_filters_1': 89, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.03584381083934122, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 16, 'num_filters_3': 90, 'num_filters_4': 34}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:06:54 DISPATCHER: Starting worker discovery
23:06:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:06:54 DISPATCHER: Finished worker discovery
23:07:30 WORKER: done with job (8, 0, 23), trying to register it.
23:07:30 WORKER: registered result for job (8, 0, 23) with dispatcher
23:07:30 DISPATCHER: job (8, 0, 23) finished
23:07:30 DISPATCHER: register_result: lock acquired
23:07:30 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:07:30 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0053461800144621935, 'num_filters_1': 89, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.03584381083934122, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 16, 'num_filters_3': 90, 'num_filters_4': 34}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5804987602335766, 'info': {'data05': 0.5804987602335766, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0053461800144621935, 'num_filters_1': 89, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.03584381083934122, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 16, 'num_filters_3': 90, 'num_filters_4': 34}"}}
exception: None

23:07:30 job_callback for (8, 0, 23) started
23:07:30 job_callback for (8, 0, 23) got condition
23:07:30 DISPATCHER: Trying to submit another job.
23:07:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:07:30 HBMASTER: Trying to run another job!
23:07:30 job_callback for (8, 0, 23) finished
23:07:30 start sampling a new configuration.
23:07:31 best_vector: [1, 0, 0.7654937427168063, 0.8636685989020237, 0.9861605024732626, 0, 0.45163189522944386, 0.4341719288093467, 0, 2, 2, 0, 0.7465569360097849, 0.7744702169191239, 0.24712118450793524, 0.7524454928753432], 5.407922739207197e-30, 0.0018491388435527103, -2.801618733971988e-06
23:07:31 done sampling a new configuration.
23:07:31 HBMASTER: schedule new run for iteration 8
23:07:31 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
23:07:31 HBMASTER: submitting job (8, 0, 24) to dispatcher
23:07:31 DISPATCHER: trying to submit job (8, 0, 24)
23:07:31 DISPATCHER: trying to notify the job_runner thread.
23:07:31 HBMASTER: job (8, 0, 24) submitted to dispatcher
23:07:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:07:31 DISPATCHER: Trying to submit another job.
23:07:31 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:07:31 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:07:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:07:31 WORKER: start processing job (8, 0, 24)
23:07:31 WORKER: args: ()
23:07:31 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0339615486139139, 'num_filters_1': 96, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.0367172970171706, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 75, 'num_filters_3': 80, 'num_filters_4': 26, 'num_filters_5': 76}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:07:54 DISPATCHER: Starting worker discovery
23:07:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:07:54 DISPATCHER: Finished worker discovery
23:08:28 WORKER: done with job (8, 0, 24), trying to register it.
23:08:28 WORKER: registered result for job (8, 0, 24) with dispatcher
23:08:28 DISPATCHER: job (8, 0, 24) finished
23:08:28 DISPATCHER: register_result: lock acquired
23:08:28 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:08:28 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0339615486139139, 'num_filters_1': 96, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.0367172970171706, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 75, 'num_filters_3': 80, 'num_filters_4': 26, 'num_filters_5': 76}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0339615486139139, 'num_filters_1': 96, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.0367172970171706, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 75, 'num_filters_3': 80, 'num_filters_4': 26, 'num_filters_5': 76}"}}
exception: None

23:08:28 job_callback for (8, 0, 24) started
23:08:28 job_callback for (8, 0, 24) got condition
23:08:28 DISPATCHER: Trying to submit another job.
23:08:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:08:28 HBMASTER: Trying to run another job!
23:08:28 job_callback for (8, 0, 24) finished
23:08:28 start sampling a new configuration.
23:08:28 done sampling a new configuration.
23:08:28 HBMASTER: schedule new run for iteration 8
23:08:28 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
23:08:28 HBMASTER: submitting job (8, 0, 25) to dispatcher
23:08:28 DISPATCHER: trying to submit job (8, 0, 25)
23:08:28 DISPATCHER: trying to notify the job_runner thread.
23:08:28 HBMASTER: job (8, 0, 25) submitted to dispatcher
23:08:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:08:28 DISPATCHER: Trying to submit another job.
23:08:28 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:08:28 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:08:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:08:28 WORKER: start processing job (8, 0, 25)
23:08:28 WORKER: args: ()
23:08:28 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004331872917991717, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.08710332205530792, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 20, 'num_filters_3': 75, 'num_filters_4': 32, 'num_filters_5': 89}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:08:54 DISPATCHER: Starting worker discovery
23:08:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:08:54 DISPATCHER: Finished worker discovery
23:09:26 WORKER: done with job (8, 0, 25), trying to register it.
23:09:26 WORKER: registered result for job (8, 0, 25) with dispatcher
23:09:26 DISPATCHER: job (8, 0, 25) finished
23:09:26 DISPATCHER: register_result: lock acquired
23:09:26 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:09:26 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004331872917991717, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.08710332205530792, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 20, 'num_filters_3': 75, 'num_filters_4': 32, 'num_filters_5': 89}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.26942506255291665, 'info': {'data05': 0.26942506255291665, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004331872917991717, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.08710332205530792, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 20, 'num_filters_3': 75, 'num_filters_4': 32, 'num_filters_5': 89}"}}
exception: None

23:09:26 job_callback for (8, 0, 25) started
23:09:26 DISPATCHER: Trying to submit another job.
23:09:26 job_callback for (8, 0, 25) got condition
23:09:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:09:26 HBMASTER: Trying to run another job!
23:09:26 job_callback for (8, 0, 25) finished
23:09:26 start sampling a new configuration.
23:09:26 done sampling a new configuration.
23:09:26 HBMASTER: schedule new run for iteration 8
23:09:26 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
23:09:26 HBMASTER: submitting job (8, 0, 26) to dispatcher
23:09:26 DISPATCHER: trying to submit job (8, 0, 26)
23:09:26 DISPATCHER: trying to notify the job_runner thread.
23:09:26 HBMASTER: job (8, 0, 26) submitted to dispatcher
23:09:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:09:26 DISPATCHER: Trying to submit another job.
23:09:26 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:09:26 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:09:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:09:26 WORKER: start processing job (8, 0, 26)
23:09:26 WORKER: args: ()
23:09:26 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0041759380737774925, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.08699307913118093, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 22, 'num_filters_3': 38}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:09:54 DISPATCHER: Starting worker discovery
23:09:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:09:54 DISPATCHER: Finished worker discovery
23:10:24 WORKER: done with job (8, 0, 26), trying to register it.
23:10:24 WORKER: registered result for job (8, 0, 26) with dispatcher
23:10:24 DISPATCHER: job (8, 0, 26) finished
23:10:24 DISPATCHER: register_result: lock acquired
23:10:24 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:10:24 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0041759380737774925, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.08699307913118093, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 22, 'num_filters_3': 38}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.45661758893536697, 'info': {'data05': 0.45661758893536697, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0041759380737774925, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.08699307913118093, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 22, 'num_filters_3': 38}"}}
exception: None

23:10:24 job_callback for (8, 0, 26) started
23:10:24 job_callback for (8, 0, 26) got condition
23:10:24 DISPATCHER: Trying to submit another job.
23:10:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:10:24 HBMASTER: Trying to run another job!
23:10:24 job_callback for (8, 0, 26) finished
23:10:24 ITERATION: Advancing config (8, 0, 1) to next budget 133.333333
23:10:24 ITERATION: Advancing config (8, 0, 2) to next budget 133.333333
23:10:24 ITERATION: Advancing config (8, 0, 6) to next budget 133.333333
23:10:24 ITERATION: Advancing config (8, 0, 7) to next budget 133.333333
23:10:24 ITERATION: Advancing config (8, 0, 8) to next budget 133.333333
23:10:24 ITERATION: Advancing config (8, 0, 9) to next budget 133.333333
23:10:24 ITERATION: Advancing config (8, 0, 11) to next budget 133.333333
23:10:24 ITERATION: Advancing config (8, 0, 14) to next budget 133.333333
23:10:24 ITERATION: Advancing config (8, 0, 23) to next budget 133.333333
23:10:24 HBMASTER: schedule new run for iteration 8
23:10:24 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
23:10:24 HBMASTER: submitting job (8, 0, 1) to dispatcher
23:10:24 DISPATCHER: trying to submit job (8, 0, 1)
23:10:24 DISPATCHER: trying to notify the job_runner thread.
23:10:24 HBMASTER: job (8, 0, 1) submitted to dispatcher
23:10:24 DISPATCHER: Trying to submit another job.
23:10:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:10:24 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:10:24 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:10:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:10:24 WORKER: start processing job (8, 0, 1)
23:10:24 WORKER: args: ()
23:10:24 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0012860667821922502, 'num_filters_1': 76, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.016903517673018467, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 45, 'num_filters_3': 40, 'num_filters_4': 20}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:10:54 DISPATCHER: Starting worker discovery
23:10:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:10:54 DISPATCHER: Finished worker discovery
23:11:54 DISPATCHER: Starting worker discovery
23:11:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:11:54 DISPATCHER: Finished worker discovery
23:12:54 DISPATCHER: Starting worker discovery
23:12:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:12:54 DISPATCHER: Finished worker discovery
23:13:02 WORKER: done with job (8, 0, 1), trying to register it.
23:13:02 WORKER: registered result for job (8, 0, 1) with dispatcher
23:13:02 DISPATCHER: job (8, 0, 1) finished
23:13:02 DISPATCHER: register_result: lock acquired
23:13:02 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:13:02 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0012860667821922502, 'num_filters_1': 76, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.016903517673018467, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 45, 'num_filters_3': 40, 'num_filters_4': 20}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6832160954061913, 'info': {'data05': 0.6832160954061913, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0012860667821922502, 'num_filters_1': 76, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.016903517673018467, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 45, 'num_filters_3': 40, 'num_filters_4': 20}"}}
exception: None

23:13:02 job_callback for (8, 0, 1) started
23:13:02 job_callback for (8, 0, 1) got condition
23:13:02 DISPATCHER: Trying to submit another job.
23:13:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:13:02 done building a new model for budget 133.333333 based on 17/31 split
Best loss for this budget:-0.891177





23:13:02 HBMASTER: Trying to run another job!
23:13:02 job_callback for (8, 0, 1) finished
23:13:02 HBMASTER: schedule new run for iteration 8
23:13:02 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
23:13:02 HBMASTER: submitting job (8, 0, 2) to dispatcher
23:13:02 DISPATCHER: trying to submit job (8, 0, 2)
23:13:02 DISPATCHER: trying to notify the job_runner thread.
23:13:02 HBMASTER: job (8, 0, 2) submitted to dispatcher
23:13:02 DISPATCHER: Trying to submit another job.
23:13:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:13:02 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:13:02 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:13:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:13:02 WORKER: start processing job (8, 0, 2)
23:13:02 WORKER: args: ()
23:13:02 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.007294400679238209, 'num_filters_1': 114, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.028772667687644467, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 84, 'num_filters_3': 26, 'num_filters_4': 117, 'num_filters_5': 48}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:13:54 DISPATCHER: Starting worker discovery
23:13:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:13:54 DISPATCHER: Finished worker discovery
23:14:54 DISPATCHER: Starting worker discovery
23:14:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:14:54 DISPATCHER: Finished worker discovery
23:15:31 WORKER: done with job (8, 0, 2), trying to register it.
23:15:31 WORKER: registered result for job (8, 0, 2) with dispatcher
23:15:31 DISPATCHER: job (8, 0, 2) finished
23:15:31 DISPATCHER: register_result: lock acquired
23:15:31 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:15:31 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.007294400679238209, 'num_filters_1': 114, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.028772667687644467, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 84, 'num_filters_3': 26, 'num_filters_4': 117, 'num_filters_5': 48}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8648383139384167, 'info': {'data05': 0.8648383139384167, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.007294400679238209, 'num_filters_1': 114, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.028772667687644467, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 84, 'num_filters_3': 26, 'num_filters_4': 117, 'num_filters_5': 48}"}}
exception: None

23:15:31 job_callback for (8, 0, 2) started
23:15:31 DISPATCHER: Trying to submit another job.
23:15:31 job_callback for (8, 0, 2) got condition
23:15:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:15:31 done building a new model for budget 133.333333 based on 17/32 split
Best loss for this budget:-0.891177





23:15:31 HBMASTER: Trying to run another job!
23:15:31 job_callback for (8, 0, 2) finished
23:15:31 HBMASTER: schedule new run for iteration 8
23:15:31 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
23:15:31 HBMASTER: submitting job (8, 0, 6) to dispatcher
23:15:31 DISPATCHER: trying to submit job (8, 0, 6)
23:15:31 DISPATCHER: trying to notify the job_runner thread.
23:15:31 HBMASTER: job (8, 0, 6) submitted to dispatcher
23:15:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:15:31 DISPATCHER: Trying to submit another job.
23:15:31 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:15:31 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:15:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:15:31 WORKER: start processing job (8, 0, 6)
23:15:31 WORKER: args: ()
23:15:31 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0015704642253844736, 'num_filters_1': 17, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.028933581585148985, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 75, 'num_filters_3': 29, 'num_filters_4': 109, 'num_filters_5': 58}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:15:54 DISPATCHER: Starting worker discovery
23:15:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:15:54 DISPATCHER: Finished worker discovery
23:16:54 DISPATCHER: Starting worker discovery
23:16:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:16:54 DISPATCHER: Finished worker discovery
23:17:54 DISPATCHER: Starting worker discovery
23:17:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:17:54 DISPATCHER: Finished worker discovery
23:17:59 WORKER: done with job (8, 0, 6), trying to register it.
23:17:59 WORKER: registered result for job (8, 0, 6) with dispatcher
23:17:59 DISPATCHER: job (8, 0, 6) finished
23:17:59 DISPATCHER: register_result: lock acquired
23:17:59 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:17:59 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0015704642253844736, 'num_filters_1': 17, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.028933581585148985, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 75, 'num_filters_3': 29, 'num_filters_4': 109, 'num_filters_5': 58}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.796972503485021, 'info': {'data05': 0.796972503485021, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0015704642253844736, 'num_filters_1': 17, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.028933581585148985, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 75, 'num_filters_3': 29, 'num_filters_4': 109, 'num_filters_5': 58}"}}
exception: None

23:17:59 job_callback for (8, 0, 6) started
23:17:59 DISPATCHER: Trying to submit another job.
23:17:59 job_callback for (8, 0, 6) got condition
23:17:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:17:59 done building a new model for budget 133.333333 based on 17/33 split
Best loss for this budget:-0.891177





23:17:59 HBMASTER: Trying to run another job!
23:17:59 job_callback for (8, 0, 6) finished
23:17:59 HBMASTER: schedule new run for iteration 8
23:17:59 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
23:17:59 HBMASTER: submitting job (8, 0, 7) to dispatcher
23:17:59 DISPATCHER: trying to submit job (8, 0, 7)
23:17:59 DISPATCHER: trying to notify the job_runner thread.
23:17:59 HBMASTER: job (8, 0, 7) submitted to dispatcher
23:17:59 DISPATCHER: Trying to submit another job.
23:17:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:17:59 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:17:59 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:17:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:17:59 WORKER: start processing job (8, 0, 7)
23:17:59 WORKER: args: ()
23:17:59 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.012071612788385956, 'num_filters_1': 80, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.01577825806533949, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 67, 'num_filters_3': 125, 'num_filters_4': 61}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:18:54 DISPATCHER: Starting worker discovery
23:18:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:18:54 DISPATCHER: Finished worker discovery
23:19:54 DISPATCHER: Starting worker discovery
23:19:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:19:54 DISPATCHER: Finished worker discovery
23:20:29 WORKER: done with job (8, 0, 7), trying to register it.
23:20:29 WORKER: registered result for job (8, 0, 7) with dispatcher
23:20:29 DISPATCHER: job (8, 0, 7) finished
23:20:29 DISPATCHER: register_result: lock acquired
23:20:29 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:20:29 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.012071612788385956, 'num_filters_1': 80, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.01577825806533949, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 67, 'num_filters_3': 125, 'num_filters_4': 61}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8182210195706011, 'info': {'data05': 0.8182210195706011, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.012071612788385956, 'num_filters_1': 80, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.01577825806533949, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 67, 'num_filters_3': 125, 'num_filters_4': 61}"}}
exception: None

23:20:29 job_callback for (8, 0, 7) started
23:20:29 job_callback for (8, 0, 7) got condition
23:20:29 DISPATCHER: Trying to submit another job.
23:20:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:20:29 done building a new model for budget 133.333333 based on 17/34 split
Best loss for this budget:-0.891177





23:20:29 HBMASTER: Trying to run another job!
23:20:29 job_callback for (8, 0, 7) finished
23:20:29 HBMASTER: schedule new run for iteration 8
23:20:29 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
23:20:29 HBMASTER: submitting job (8, 0, 8) to dispatcher
23:20:29 DISPATCHER: trying to submit job (8, 0, 8)
23:20:29 DISPATCHER: trying to notify the job_runner thread.
23:20:29 HBMASTER: job (8, 0, 8) submitted to dispatcher
23:20:29 DISPATCHER: Trying to submit another job.
23:20:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:20:29 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:20:29 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:20:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:20:29 WORKER: start processing job (8, 0, 8)
23:20:29 WORKER: args: ()
23:20:29 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.005227218182410499, 'num_filters_1': 37, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.012841825688309138, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 59, 'num_filters_3': 86, 'num_filters_4': 27}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:20:54 DISPATCHER: Starting worker discovery
23:20:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:20:54 DISPATCHER: Finished worker discovery
23:21:54 DISPATCHER: Starting worker discovery
23:21:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:21:54 DISPATCHER: Finished worker discovery
23:22:54 DISPATCHER: Starting worker discovery
23:22:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:22:54 DISPATCHER: Finished worker discovery
23:22:57 WORKER: done with job (8, 0, 8), trying to register it.
23:22:57 WORKER: registered result for job (8, 0, 8) with dispatcher
23:22:57 DISPATCHER: job (8, 0, 8) finished
23:22:57 DISPATCHER: register_result: lock acquired
23:22:57 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:22:57 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.005227218182410499, 'num_filters_1': 37, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.012841825688309138, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 59, 'num_filters_3': 86, 'num_filters_4': 27}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8549372243522687, 'info': {'data05': 0.8549372243522687, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.005227218182410499, 'num_filters_1': 37, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.012841825688309138, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 59, 'num_filters_3': 86, 'num_filters_4': 27}"}}
exception: None

23:22:57 job_callback for (8, 0, 8) started
23:22:57 DISPATCHER: Trying to submit another job.
23:22:57 job_callback for (8, 0, 8) got condition
23:22:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:22:57 done building a new model for budget 133.333333 based on 17/34 split
Best loss for this budget:-0.891177





23:22:57 HBMASTER: Trying to run another job!
23:22:57 job_callback for (8, 0, 8) finished
23:22:57 HBMASTER: schedule new run for iteration 8
23:22:57 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
23:22:57 HBMASTER: submitting job (8, 0, 9) to dispatcher
23:22:57 DISPATCHER: trying to submit job (8, 0, 9)
23:22:57 DISPATCHER: trying to notify the job_runner thread.
23:22:57 HBMASTER: job (8, 0, 9) submitted to dispatcher
23:22:57 DISPATCHER: Trying to submit another job.
23:22:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:22:57 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:22:57 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:22:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:22:57 WORKER: start processing job (8, 0, 9)
23:22:57 WORKER: args: ()
23:22:57 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002162161991753658, 'num_filters_1': 33, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.015750873860302442, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 39, 'num_filters_3': 91}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:23:54 DISPATCHER: Starting worker discovery
23:23:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:23:54 DISPATCHER: Finished worker discovery
23:24:54 DISPATCHER: Starting worker discovery
23:24:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:24:54 DISPATCHER: Finished worker discovery
23:25:31 WORKER: done with job (8, 0, 9), trying to register it.
23:25:31 WORKER: registered result for job (8, 0, 9) with dispatcher
23:25:31 DISPATCHER: job (8, 0, 9) finished
23:25:31 DISPATCHER: register_result: lock acquired
23:25:31 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:25:31 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002162161991753658, 'num_filters_1': 33, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.015750873860302442, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 39, 'num_filters_3': 91}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.562820873928908, 'info': {'data05': 0.562820873928908, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002162161991753658, 'num_filters_1': 33, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.015750873860302442, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 39, 'num_filters_3': 91}"}}
exception: None

23:25:31 job_callback for (8, 0, 9) started
23:25:31 DISPATCHER: Trying to submit another job.
23:25:31 job_callback for (8, 0, 9) got condition
23:25:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:25:31 done building a new model for budget 133.333333 based on 17/35 split
Best loss for this budget:-0.891177





23:25:31 HBMASTER: Trying to run another job!
23:25:31 job_callback for (8, 0, 9) finished
23:25:31 HBMASTER: schedule new run for iteration 8
23:25:31 HBMASTER: trying submitting job (8, 0, 11) to dispatcher
23:25:31 HBMASTER: submitting job (8, 0, 11) to dispatcher
23:25:31 DISPATCHER: trying to submit job (8, 0, 11)
23:25:31 DISPATCHER: trying to notify the job_runner thread.
23:25:31 HBMASTER: job (8, 0, 11) submitted to dispatcher
23:25:31 DISPATCHER: Trying to submit another job.
23:25:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:25:31 DISPATCHER: starting job (8, 0, 11) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:25:31 DISPATCHER: job (8, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:25:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:25:31 WORKER: start processing job (8, 0, 11)
23:25:31 WORKER: args: ()
23:25:31 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001542934373475034, 'num_filters_1': 57, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.07510250464186292, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 87, 'num_filters_3': 35}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:25:54 DISPATCHER: Starting worker discovery
23:25:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:25:54 DISPATCHER: Finished worker discovery
23:26:54 DISPATCHER: Starting worker discovery
23:26:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:26:54 DISPATCHER: Finished worker discovery
23:27:54 DISPATCHER: Starting worker discovery
23:27:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:27:54 DISPATCHER: Finished worker discovery
23:28:01 WORKER: done with job (8, 0, 11), trying to register it.
23:28:01 WORKER: registered result for job (8, 0, 11) with dispatcher
23:28:01 DISPATCHER: job (8, 0, 11) finished
23:28:01 DISPATCHER: register_result: lock acquired
23:28:01 DISPATCHER: job (8, 0, 11) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:28:01 job_id: (8, 0, 11)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001542934373475034, 'num_filters_1': 57, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.07510250464186292, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 87, 'num_filters_3': 35}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4331442097308137, 'info': {'data05': 0.4331442097308137, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001542934373475034, 'num_filters_1': 57, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.07510250464186292, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 87, 'num_filters_3': 35}"}}
exception: None

23:28:01 job_callback for (8, 0, 11) started
23:28:01 job_callback for (8, 0, 11) got condition
23:28:01 DISPATCHER: Trying to submit another job.
23:28:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:28:01 done building a new model for budget 133.333333 based on 17/36 split
Best loss for this budget:-0.891177





23:28:01 HBMASTER: Trying to run another job!
23:28:01 job_callback for (8, 0, 11) finished
23:28:01 HBMASTER: schedule new run for iteration 8
23:28:01 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
23:28:01 HBMASTER: submitting job (8, 0, 14) to dispatcher
23:28:01 DISPATCHER: trying to submit job (8, 0, 14)
23:28:01 DISPATCHER: trying to notify the job_runner thread.
23:28:01 HBMASTER: job (8, 0, 14) submitted to dispatcher
23:28:01 DISPATCHER: Trying to submit another job.
23:28:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:28:01 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:28:01 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:28:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:28:01 WORKER: start processing job (8, 0, 14)
23:28:01 WORKER: args: ()
23:28:01 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0010986664108778837, 'num_filters_1': 45, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.027087402095232214, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 35, 'num_filters_3': 68, 'num_filters_4': 21}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:28:54 DISPATCHER: Starting worker discovery
23:28:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:28:54 DISPATCHER: Finished worker discovery
23:29:54 DISPATCHER: Starting worker discovery
23:29:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:29:54 DISPATCHER: Finished worker discovery
23:30:28 WORKER: done with job (8, 0, 14), trying to register it.
23:30:28 WORKER: registered result for job (8, 0, 14) with dispatcher
23:30:28 DISPATCHER: job (8, 0, 14) finished
23:30:28 DISPATCHER: register_result: lock acquired
23:30:28 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:30:28 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0010986664108778837, 'num_filters_1': 45, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.027087402095232214, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 35, 'num_filters_3': 68, 'num_filters_4': 21}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7354494162238947, 'info': {'data05': 0.7354494162238947, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0010986664108778837, 'num_filters_1': 45, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.027087402095232214, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 35, 'num_filters_3': 68, 'num_filters_4': 21}"}}
exception: None

23:30:28 job_callback for (8, 0, 14) started
23:30:28 job_callback for (8, 0, 14) got condition
23:30:28 DISPATCHER: Trying to submit another job.
23:30:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:30:28 done building a new model for budget 133.333333 based on 17/37 split
Best loss for this budget:-0.891177





23:30:28 HBMASTER: Trying to run another job!
23:30:28 job_callback for (8, 0, 14) finished
23:30:28 HBMASTER: schedule new run for iteration 8
23:30:28 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
23:30:28 HBMASTER: submitting job (8, 0, 23) to dispatcher
23:30:28 DISPATCHER: trying to submit job (8, 0, 23)
23:30:28 DISPATCHER: trying to notify the job_runner thread.
23:30:28 HBMASTER: job (8, 0, 23) submitted to dispatcher
23:30:28 DISPATCHER: Trying to submit another job.
23:30:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:30:28 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:30:28 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:30:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:30:28 WORKER: start processing job (8, 0, 23)
23:30:28 WORKER: args: ()
23:30:28 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0053461800144621935, 'num_filters_1': 89, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.03584381083934122, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 16, 'num_filters_3': 90, 'num_filters_4': 34}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:30:54 DISPATCHER: Starting worker discovery
23:30:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:30:54 DISPATCHER: Finished worker discovery
23:31:54 DISPATCHER: Starting worker discovery
23:31:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:31:54 DISPATCHER: Finished worker discovery
23:32:54 DISPATCHER: Starting worker discovery
23:32:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:32:54 DISPATCHER: Finished worker discovery
23:32:56 WORKER: done with job (8, 0, 23), trying to register it.
23:32:56 WORKER: registered result for job (8, 0, 23) with dispatcher
23:32:56 DISPATCHER: job (8, 0, 23) finished
23:32:56 DISPATCHER: register_result: lock acquired
23:32:56 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:32:56 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0053461800144621935, 'num_filters_1': 89, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.03584381083934122, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 16, 'num_filters_3': 90, 'num_filters_4': 34}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.24551394402548693, 'info': {'data05': 0.24551394402548693, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0053461800144621935, 'num_filters_1': 89, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.03584381083934122, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 16, 'num_filters_3': 90, 'num_filters_4': 34}"}}
exception: None

23:32:56 job_callback for (8, 0, 23) started
23:32:56 job_callback for (8, 0, 23) got condition
23:32:56 DISPATCHER: Trying to submit another job.
23:32:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:32:56 done building a new model for budget 133.333333 based on 17/38 split
Best loss for this budget:-0.891177





23:32:56 HBMASTER: Trying to run another job!
23:32:56 job_callback for (8, 0, 23) finished
23:32:56 ITERATION: Advancing config (8, 0, 2) to next budget 400.000000
23:32:56 ITERATION: Advancing config (8, 0, 7) to next budget 400.000000
23:32:56 ITERATION: Advancing config (8, 0, 8) to next budget 400.000000
23:32:56 HBMASTER: schedule new run for iteration 8
23:32:56 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
23:32:56 HBMASTER: submitting job (8, 0, 2) to dispatcher
23:32:56 DISPATCHER: trying to submit job (8, 0, 2)
23:32:56 DISPATCHER: trying to notify the job_runner thread.
23:32:56 HBMASTER: job (8, 0, 2) submitted to dispatcher
23:32:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:32:56 DISPATCHER: Trying to submit another job.
23:32:56 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:32:56 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:32:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:32:56 WORKER: start processing job (8, 0, 2)
23:32:56 WORKER: args: ()
23:32:56 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.007294400679238209, 'num_filters_1': 114, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.028772667687644467, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 84, 'num_filters_3': 26, 'num_filters_4': 117, 'num_filters_5': 48}, 'budget': 400.0, 'working_directory': '.'}
23:33:54 DISPATCHER: Starting worker discovery
23:33:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:33:54 DISPATCHER: Finished worker discovery
23:34:54 DISPATCHER: Starting worker discovery
23:34:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:34:54 DISPATCHER: Finished worker discovery
23:35:54 DISPATCHER: Starting worker discovery
23:35:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:35:54 DISPATCHER: Finished worker discovery
23:36:54 DISPATCHER: Starting worker discovery
23:36:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:36:54 DISPATCHER: Finished worker discovery
23:37:54 DISPATCHER: Starting worker discovery
23:37:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:37:54 DISPATCHER: Finished worker discovery
23:38:54 DISPATCHER: Starting worker discovery
23:38:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:38:54 DISPATCHER: Finished worker discovery
23:39:54 DISPATCHER: Starting worker discovery
23:39:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:39:54 DISPATCHER: Finished worker discovery
23:40:01 WORKER: done with job (8, 0, 2), trying to register it.
23:40:01 WORKER: registered result for job (8, 0, 2) with dispatcher
23:40:01 DISPATCHER: job (8, 0, 2) finished
23:40:01 DISPATCHER: register_result: lock acquired
23:40:01 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:40:01 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.007294400679238209, 'num_filters_1': 114, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.028772667687644467, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 84, 'num_filters_3': 26, 'num_filters_4': 117, 'num_filters_5': 48}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8403550310289514, 'info': {'data05': 0.8403550310289514, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.007294400679238209, 'num_filters_1': 114, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.028772667687644467, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 84, 'num_filters_3': 26, 'num_filters_4': 117, 'num_filters_5': 48}"}}
exception: None

23:40:01 job_callback for (8, 0, 2) started
23:40:01 DISPATCHER: Trying to submit another job.
23:40:01 job_callback for (8, 0, 2) got condition
23:40:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:40:01 HBMASTER: Trying to run another job!
23:40:01 job_callback for (8, 0, 2) finished
23:40:01 HBMASTER: schedule new run for iteration 8
23:40:01 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
23:40:01 HBMASTER: submitting job (8, 0, 7) to dispatcher
23:40:01 DISPATCHER: trying to submit job (8, 0, 7)
23:40:01 DISPATCHER: trying to notify the job_runner thread.
23:40:01 HBMASTER: job (8, 0, 7) submitted to dispatcher
23:40:01 DISPATCHER: Trying to submit another job.
23:40:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:40:01 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:40:01 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:40:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:40:01 WORKER: start processing job (8, 0, 7)
23:40:01 WORKER: args: ()
23:40:01 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.012071612788385956, 'num_filters_1': 80, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.01577825806533949, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 67, 'num_filters_3': 125, 'num_filters_4': 61}, 'budget': 400.0, 'working_directory': '.'}
23:40:54 DISPATCHER: Starting worker discovery
23:40:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:40:54 DISPATCHER: Finished worker discovery
23:41:54 DISPATCHER: Starting worker discovery
23:41:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:41:54 DISPATCHER: Finished worker discovery
23:42:54 DISPATCHER: Starting worker discovery
23:42:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:42:54 DISPATCHER: Finished worker discovery
23:43:54 DISPATCHER: Starting worker discovery
23:43:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:43:54 DISPATCHER: Finished worker discovery
23:44:54 DISPATCHER: Starting worker discovery
23:44:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:44:54 DISPATCHER: Finished worker discovery
23:45:54 DISPATCHER: Starting worker discovery
23:45:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:45:54 DISPATCHER: Finished worker discovery
23:46:54 DISPATCHER: Starting worker discovery
23:46:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:46:54 DISPATCHER: Finished worker discovery
23:47:10 WORKER: done with job (8, 0, 7), trying to register it.
23:47:10 WORKER: registered result for job (8, 0, 7) with dispatcher
23:47:10 DISPATCHER: job (8, 0, 7) finished
23:47:10 DISPATCHER: register_result: lock acquired
23:47:10 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:47:10 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.012071612788385956, 'num_filters_1': 80, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.01577825806533949, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 67, 'num_filters_3': 125, 'num_filters_4': 61}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8180959030181286, 'info': {'data05': 0.8180959030181286, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.012071612788385956, 'num_filters_1': 80, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.01577825806533949, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 67, 'num_filters_3': 125, 'num_filters_4': 61}"}}
exception: None

23:47:10 job_callback for (8, 0, 7) started
23:47:10 DISPATCHER: Trying to submit another job.
23:47:10 job_callback for (8, 0, 7) got condition
23:47:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:47:10 HBMASTER: Trying to run another job!
23:47:10 job_callback for (8, 0, 7) finished
23:47:10 HBMASTER: schedule new run for iteration 8
23:47:10 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
23:47:10 HBMASTER: submitting job (8, 0, 8) to dispatcher
23:47:10 DISPATCHER: trying to submit job (8, 0, 8)
23:47:10 DISPATCHER: trying to notify the job_runner thread.
23:47:10 HBMASTER: job (8, 0, 8) submitted to dispatcher
23:47:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:47:10 DISPATCHER: Trying to submit another job.
23:47:10 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:47:10 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:47:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:47:10 WORKER: start processing job (8, 0, 8)
23:47:10 WORKER: args: ()
23:47:10 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.005227218182410499, 'num_filters_1': 37, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.012841825688309138, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 59, 'num_filters_3': 86, 'num_filters_4': 27}, 'budget': 400.0, 'working_directory': '.'}
23:47:54 DISPATCHER: Starting worker discovery
23:47:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:47:54 DISPATCHER: Finished worker discovery
23:48:54 DISPATCHER: Starting worker discovery
23:48:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:48:54 DISPATCHER: Finished worker discovery
23:49:54 DISPATCHER: Starting worker discovery
23:49:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:49:54 DISPATCHER: Finished worker discovery
23:50:54 DISPATCHER: Starting worker discovery
23:50:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:50:54 DISPATCHER: Finished worker discovery
23:51:54 DISPATCHER: Starting worker discovery
23:51:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:51:54 DISPATCHER: Finished worker discovery
23:52:54 DISPATCHER: Starting worker discovery
23:52:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:52:54 DISPATCHER: Finished worker discovery
23:53:54 DISPATCHER: Starting worker discovery
23:53:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:53:54 DISPATCHER: Finished worker discovery
23:54:13 WORKER: done with job (8, 0, 8), trying to register it.
23:54:13 WORKER: registered result for job (8, 0, 8) with dispatcher
23:54:13 DISPATCHER: job (8, 0, 8) finished
23:54:13 DISPATCHER: register_result: lock acquired
23:54:13 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:54:13 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.005227218182410499, 'num_filters_1': 37, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.012841825688309138, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 59, 'num_filters_3': 86, 'num_filters_4': 27}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6851351423133389, 'info': {'data05': 0.6851351423133389, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.005227218182410499, 'num_filters_1': 37, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.012841825688309138, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 59, 'num_filters_3': 86, 'num_filters_4': 27}"}}
exception: None

23:54:13 job_callback for (8, 0, 8) started
23:54:13 job_callback for (8, 0, 8) got condition
23:54:13 DISPATCHER: Trying to submit another job.
23:54:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:54:13 HBMASTER: Trying to run another job!
23:54:13 job_callback for (8, 0, 8) finished
23:54:13 ITERATION: Advancing config (8, 0, 2) to next budget 1200.000000
23:54:13 HBMASTER: schedule new run for iteration 8
23:54:13 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
23:54:13 HBMASTER: submitting job (8, 0, 2) to dispatcher
23:54:13 DISPATCHER: trying to submit job (8, 0, 2)
23:54:13 DISPATCHER: trying to notify the job_runner thread.
23:54:13 HBMASTER: job (8, 0, 2) submitted to dispatcher
23:54:13 DISPATCHER: Trying to submit another job.
23:54:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:54:13 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:54:13 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:54:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:54:13 WORKER: start processing job (8, 0, 2)
23:54:13 WORKER: args: ()
23:54:13 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.007294400679238209, 'num_filters_1': 114, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.028772667687644467, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 84, 'num_filters_3': 26, 'num_filters_4': 117, 'num_filters_5': 48}, 'budget': 1200.0, 'working_directory': '.'}
23:54:54 DISPATCHER: Starting worker discovery
23:54:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:54:54 DISPATCHER: Finished worker discovery
23:55:54 DISPATCHER: Starting worker discovery
23:55:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:55:54 DISPATCHER: Finished worker discovery
23:56:54 DISPATCHER: Starting worker discovery
23:56:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:56:54 DISPATCHER: Finished worker discovery
23:57:54 DISPATCHER: Starting worker discovery
23:57:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:57:54 DISPATCHER: Finished worker discovery
23:58:54 DISPATCHER: Starting worker discovery
23:58:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:58:54 DISPATCHER: Finished worker discovery
23:59:54 DISPATCHER: Starting worker discovery
23:59:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:59:54 DISPATCHER: Finished worker discovery
00:00:54 DISPATCHER: Starting worker discovery
00:00:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:00:54 DISPATCHER: Finished worker discovery
00:01:54 DISPATCHER: Starting worker discovery
00:01:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:01:54 DISPATCHER: Finished worker discovery
00:02:54 DISPATCHER: Starting worker discovery
00:02:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:02:54 DISPATCHER: Finished worker discovery
00:03:54 DISPATCHER: Starting worker discovery
00:03:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:03:54 DISPATCHER: Finished worker discovery
00:04:54 DISPATCHER: Starting worker discovery
00:04:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:04:54 DISPATCHER: Finished worker discovery
00:05:54 DISPATCHER: Starting worker discovery
00:05:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:05:54 DISPATCHER: Finished worker discovery
00:06:54 DISPATCHER: Starting worker discovery
00:06:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:06:54 DISPATCHER: Finished worker discovery
00:07:54 DISPATCHER: Starting worker discovery
00:07:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:07:54 DISPATCHER: Finished worker discovery
00:08:54 DISPATCHER: Starting worker discovery
00:08:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:08:54 DISPATCHER: Finished worker discovery
00:09:54 DISPATCHER: Starting worker discovery
00:09:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:09:54 DISPATCHER: Finished worker discovery
00:10:54 DISPATCHER: Starting worker discovery
00:10:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:10:54 DISPATCHER: Finished worker discovery
00:11:54 DISPATCHER: Starting worker discovery
00:11:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:11:54 DISPATCHER: Finished worker discovery
00:12:54 DISPATCHER: Starting worker discovery
00:12:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:12:54 DISPATCHER: Finished worker discovery
00:13:54 DISPATCHER: Starting worker discovery
00:13:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:13:54 DISPATCHER: Finished worker discovery
00:14:54 DISPATCHER: Starting worker discovery
00:14:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:14:55 DISPATCHER: Finished worker discovery
00:15:04 WORKER: done with job (8, 0, 2), trying to register it.
00:15:04 WORKER: registered result for job (8, 0, 2) with dispatcher
00:15:04 DISPATCHER: job (8, 0, 2) finished
00:15:04 DISPATCHER: register_result: lock acquired
00:15:04 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
00:15:04 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.007294400679238209, 'num_filters_1': 114, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.028772667687644467, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 84, 'num_filters_3': 26, 'num_filters_4': 117, 'num_filters_5': 48}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.8574978335677755, 'info': {'data05': 0.8574978335677755, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.007294400679238209, 'num_filters_1': 114, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 33, 'weight_decay': 0.028772667687644467, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 84, 'num_filters_3': 26, 'num_filters_4': 117, 'num_filters_5': 48}"}}
exception: None

00:15:04 job_callback for (8, 0, 2) started
00:15:04 DISPATCHER: Trying to submit another job.
00:15:04 job_callback for (8, 0, 2) got condition
00:15:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:15:04 HBMASTER: Trying to run another job!
00:15:04 job_callback for (8, 0, 2) finished
00:15:04 start sampling a new configuration.
00:15:04 done sampling a new configuration.
00:15:04 HBMASTER: schedule new run for iteration 9
00:15:04 HBMASTER: trying submitting job (9, 0, 0) to dispatcher
00:15:04 HBMASTER: submitting job (9, 0, 0) to dispatcher
00:15:04 DISPATCHER: trying to submit job (9, 0, 0)
00:15:04 DISPATCHER: trying to notify the job_runner thread.
00:15:04 HBMASTER: job (9, 0, 0) submitted to dispatcher
00:15:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:15:04 DISPATCHER: Trying to submit another job.
00:15:04 DISPATCHER: starting job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:15:04 DISPATCHER: job (9, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:15:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:15:04 WORKER: start processing job (9, 0, 0)
00:15:04 WORKER: args: ()
00:15:04 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0062721868218531505, 'num_filters_1': 72, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.029324897536777923, 'kernel_size_2': 3, 'num_filters_2': 108}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:15:55 DISPATCHER: Starting worker discovery
00:15:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:15:55 DISPATCHER: Finished worker discovery
00:16:55 DISPATCHER: Starting worker discovery
00:16:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:16:55 DISPATCHER: Finished worker discovery
00:17:37 WORKER: done with job (9, 0, 0), trying to register it.
00:17:37 WORKER: registered result for job (9, 0, 0) with dispatcher
00:17:37 DISPATCHER: job (9, 0, 0) finished
00:17:37 DISPATCHER: register_result: lock acquired
00:17:37 DISPATCHER: job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
00:17:37 job_id: (9, 0, 0)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0062721868218531505, 'num_filters_1': 72, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.029324897536777923, 'kernel_size_2': 3, 'num_filters_2': 108}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.13239777865367355, 'info': {'data05': 0.13239777865367355, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0062721868218531505, 'num_filters_1': 72, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.029324897536777923, 'kernel_size_2': 3, 'num_filters_2': 108}"}}
exception: None

00:17:37 job_callback for (9, 0, 0) started
00:17:37 job_callback for (9, 0, 0) got condition
00:17:37 DISPATCHER: Trying to submit another job.
00:17:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:17:37 done building a new model for budget 133.333333 based on 17/39 split
Best loss for this budget:-0.891177





00:17:37 HBMASTER: Trying to run another job!
00:17:37 job_callback for (9, 0, 0) finished
00:17:37 start sampling a new configuration.
00:17:37 done sampling a new configuration.
00:17:37 HBMASTER: schedule new run for iteration 9
00:17:37 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
00:17:37 HBMASTER: submitting job (9, 0, 1) to dispatcher
00:17:37 DISPATCHER: trying to submit job (9, 0, 1)
00:17:37 DISPATCHER: trying to notify the job_runner thread.
00:17:37 HBMASTER: job (9, 0, 1) submitted to dispatcher
00:17:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:17:37 DISPATCHER: Trying to submit another job.
00:17:37 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:17:37 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:17:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:17:37 WORKER: start processing job (9, 0, 1)
00:17:37 WORKER: args: ()
00:17:37 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0010641529482503906, 'num_filters_1': 59, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.031682574940576295, 'kernel_size_2': 3, 'num_filters_2': 28}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:17:55 DISPATCHER: Starting worker discovery
00:17:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:17:55 DISPATCHER: Finished worker discovery
00:18:55 DISPATCHER: Starting worker discovery
00:18:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:18:55 DISPATCHER: Finished worker discovery
00:19:55 DISPATCHER: Starting worker discovery
00:19:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:19:55 DISPATCHER: Finished worker discovery
00:20:22 WORKER: done with job (9, 0, 1), trying to register it.
00:20:22 WORKER: registered result for job (9, 0, 1) with dispatcher
00:20:22 DISPATCHER: job (9, 0, 1) finished
00:20:22 DISPATCHER: register_result: lock acquired
00:20:22 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
00:20:22 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0010641529482503906, 'num_filters_1': 59, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.031682574940576295, 'kernel_size_2': 3, 'num_filters_2': 28}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.41535502448668105, 'info': {'data05': 0.41535502448668105, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0010641529482503906, 'num_filters_1': 59, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.031682574940576295, 'kernel_size_2': 3, 'num_filters_2': 28}"}}
exception: None

00:20:22 job_callback for (9, 0, 1) started
00:20:22 job_callback for (9, 0, 1) got condition
00:20:22 DISPATCHER: Trying to submit another job.
00:20:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:20:22 done building a new model for budget 133.333333 based on 17/39 split
Best loss for this budget:-0.891177





00:20:22 HBMASTER: Trying to run another job!
00:20:22 job_callback for (9, 0, 1) finished
00:20:22 start sampling a new configuration.
00:20:22 best_vector: [1, 1, 0.9871079485204544, 0.6677860776156834, 0.9770359692003026, 1, 0.3075413262469641, 0.6304637201734131, 1, 1, 0, 1, 0.8721679671281299, 0.5142385504927813, 0.18927512796494378, 0.7469761263083586], 3.913458359655632e-29, 0.0002555284630875684, -2.1391611147084905e-06
00:20:22 done sampling a new configuration.
00:20:22 HBMASTER: schedule new run for iteration 9
00:20:22 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
00:20:22 HBMASTER: submitting job (9, 0, 2) to dispatcher
00:20:22 DISPATCHER: trying to submit job (9, 0, 2)
00:20:22 DISPATCHER: trying to notify the job_runner thread.
00:20:22 HBMASTER: job (9, 0, 2) submitted to dispatcher
00:20:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:20:22 DISPATCHER: Trying to submit another job.
00:20:22 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:20:22 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:20:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:20:22 WORKER: start processing job (9, 0, 2)
00:20:22 WORKER: args: ()
00:20:22 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0942357946314759, 'num_filters_1': 64, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.06610772489503071, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 98, 'num_filters_3': 46, 'num_filters_4': 23, 'num_filters_5': 75}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:20:55 DISPATCHER: Starting worker discovery
00:20:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:20:55 DISPATCHER: Finished worker discovery
00:21:55 DISPATCHER: Starting worker discovery
00:21:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:21:55 DISPATCHER: Finished worker discovery
00:22:54 WORKER: done with job (9, 0, 2), trying to register it.
00:22:54 WORKER: registered result for job (9, 0, 2) with dispatcher
00:22:54 DISPATCHER: job (9, 0, 2) finished
00:22:54 DISPATCHER: register_result: lock acquired
00:22:54 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
00:22:54 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0942357946314759, 'num_filters_1': 64, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.06610772489503071, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 98, 'num_filters_3': 46, 'num_filters_4': 23, 'num_filters_5': 75}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.000737126297094349, 'info': {'data05': 0.000737126297094349, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0942357946314759, 'num_filters_1': 64, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.06610772489503071, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 98, 'num_filters_3': 46, 'num_filters_4': 23, 'num_filters_5': 75}"}}
exception: None

00:22:54 job_callback for (9, 0, 2) started
00:22:54 job_callback for (9, 0, 2) got condition
00:22:54 DISPATCHER: Trying to submit another job.
00:22:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:22:54 done building a new model for budget 133.333333 based on 17/40 split
Best loss for this budget:-0.891177





00:22:54 HBMASTER: Trying to run another job!
00:22:54 job_callback for (9, 0, 2) finished
00:22:54 start sampling a new configuration.
00:22:54 best_vector: [1, 1, 0.8900437335100129, 0.7527997111920974, 0.8999097368659433, 1, 0.3352626384976286, 0.2486524272706238, 1, 0, 2, 1, 0.9737013594480811, 0.007263824229021221, 0.5124804764794615, 0.5007776946308907], 8.797322545484595e-30, 0.0011367094872669758, -5.630168863056747e-06
00:22:54 done sampling a new configuration.
00:22:54 HBMASTER: schedule new run for iteration 9
00:22:54 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
00:22:54 HBMASTER: submitting job (9, 0, 3) to dispatcher
00:22:54 DISPATCHER: trying to submit job (9, 0, 3)
00:22:54 DISPATCHER: trying to notify the job_runner thread.
00:22:54 HBMASTER: job (9, 0, 3) submitted to dispatcher
00:22:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:22:54 DISPATCHER: Trying to submit another job.
00:22:54 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:22:54 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:22:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:22:54 WORKER: start processing job (9, 0, 3)
00:22:54 WORKER: args: ()
00:22:54 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.06026809539508641, 'num_filters_1': 76, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.021062225897643973, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 122, 'num_filters_3': 16, 'num_filters_4': 46, 'num_filters_5': 45}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:22:55 DISPATCHER: Starting worker discovery
00:22:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:22:55 DISPATCHER: Finished worker discovery
00:23:55 DISPATCHER: Starting worker discovery
00:23:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:23:55 DISPATCHER: Finished worker discovery
00:24:55 DISPATCHER: Starting worker discovery
00:24:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:24:55 DISPATCHER: Finished worker discovery
00:25:26 WORKER: done with job (9, 0, 3), trying to register it.
00:25:26 WORKER: registered result for job (9, 0, 3) with dispatcher
00:25:26 DISPATCHER: job (9, 0, 3) finished
00:25:26 DISPATCHER: register_result: lock acquired
00:25:26 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
00:25:26 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.06026809539508641, 'num_filters_1': 76, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.021062225897643973, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 122, 'num_filters_3': 16, 'num_filters_4': 46, 'num_filters_5': 45}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2793799157381832, 'info': {'data05': 0.2793799157381832, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.06026809539508641, 'num_filters_1': 76, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.021062225897643973, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 122, 'num_filters_3': 16, 'num_filters_4': 46, 'num_filters_5': 45}"}}
exception: None

00:25:26 job_callback for (9, 0, 3) started
00:25:26 DISPATCHER: Trying to submit another job.
00:25:26 job_callback for (9, 0, 3) got condition
00:25:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:25:26 done building a new model for budget 133.333333 based on 17/41 split
Best loss for this budget:-0.891177





00:25:26 HBMASTER: Trying to run another job!
00:25:26 job_callback for (9, 0, 3) finished
00:25:26 start sampling a new configuration.
00:25:26 done sampling a new configuration.
00:25:26 HBMASTER: schedule new run for iteration 9
00:25:26 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
00:25:26 HBMASTER: submitting job (9, 0, 4) to dispatcher
00:25:26 DISPATCHER: trying to submit job (9, 0, 4)
00:25:26 DISPATCHER: trying to notify the job_runner thread.
00:25:26 HBMASTER: job (9, 0, 4) submitted to dispatcher
00:25:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:25:26 DISPATCHER: Trying to submit another job.
00:25:26 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:25:26 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:25:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:25:26 WORKER: start processing job (9, 0, 4)
00:25:26 WORKER: args: ()
00:25:26 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.002406160086772347, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.04814642006802344, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 72, 'num_filters_3': 80, 'num_filters_4': 16}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:25:55 DISPATCHER: Starting worker discovery
00:25:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:25:55 DISPATCHER: Finished worker discovery
00:26:55 DISPATCHER: Starting worker discovery
00:26:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:26:55 DISPATCHER: Finished worker discovery
00:27:55 DISPATCHER: Starting worker discovery
00:27:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:27:55 DISPATCHER: Finished worker discovery
00:28:00 WORKER: done with job (9, 0, 4), trying to register it.
00:28:00 WORKER: registered result for job (9, 0, 4) with dispatcher
00:28:00 DISPATCHER: job (9, 0, 4) finished
00:28:00 DISPATCHER: register_result: lock acquired
00:28:00 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
00:28:00 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.002406160086772347, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.04814642006802344, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 72, 'num_filters_3': 80, 'num_filters_4': 16}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5009546992773461, 'info': {'data05': 0.5009546992773461, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.002406160086772347, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.04814642006802344, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 72, 'num_filters_3': 80, 'num_filters_4': 16}"}}
exception: None

00:28:00 job_callback for (9, 0, 4) started
00:28:00 job_callback for (9, 0, 4) got condition
00:28:00 DISPATCHER: Trying to submit another job.
00:28:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:28:00 done building a new model for budget 133.333333 based on 17/42 split
Best loss for this budget:-0.891177





00:28:00 HBMASTER: Trying to run another job!
00:28:00 job_callback for (9, 0, 4) finished
00:28:00 start sampling a new configuration.
00:28:00 best_vector: [2, 1, 0.6506006603558518, 0.3910504977190308, 0.6355868779165628, 1, 0.9889555033735349, 0.11394227881214242, 2, 0, 2, 0, 0.8256512174420025, 0.6946222011497248, 0.07616012008593653, 0.8674780823613316], 0.0003689948101326998, 0.01038616435444094, 3.832440743973949e-06
00:28:00 done sampling a new configuration.
00:28:00 HBMASTER: schedule new run for iteration 9
00:28:00 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
00:28:00 HBMASTER: submitting job (9, 0, 5) to dispatcher
00:28:00 DISPATCHER: trying to submit job (9, 0, 5)
00:28:00 DISPATCHER: trying to notify the job_runner thread.
00:28:00 HBMASTER: job (9, 0, 5) submitted to dispatcher
00:28:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:28:00 DISPATCHER: Trying to submit another job.
00:28:00 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:28:00 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:28:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:28:00 WORKER: start processing job (9, 0, 5)
00:28:00 WORKER: args: ()
00:28:00 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.020007891366451064, 'num_filters_1': 35, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.014068322728434857, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 89, 'num_filters_3': 67, 'num_filters_4': 18}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:28:55 DISPATCHER: Starting worker discovery
00:28:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:28:55 DISPATCHER: Finished worker discovery
00:29:55 DISPATCHER: Starting worker discovery
00:29:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:29:55 DISPATCHER: Finished worker discovery
00:30:28 WORKER: done with job (9, 0, 5), trying to register it.
00:30:28 WORKER: registered result for job (9, 0, 5) with dispatcher
00:30:28 DISPATCHER: job (9, 0, 5) finished
00:30:28 DISPATCHER: register_result: lock acquired
00:30:28 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
00:30:28 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.020007891366451064, 'num_filters_1': 35, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.014068322728434857, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 89, 'num_filters_3': 67, 'num_filters_4': 18}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6514508037037904, 'info': {'data05': 0.6514508037037904, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.020007891366451064, 'num_filters_1': 35, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.014068322728434857, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 89, 'num_filters_3': 67, 'num_filters_4': 18}"}}
exception: None

00:30:28 job_callback for (9, 0, 5) started
00:30:28 job_callback for (9, 0, 5) got condition
00:30:28 DISPATCHER: Trying to submit another job.
00:30:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:30:28 done building a new model for budget 133.333333 based on 17/43 split
Best loss for this budget:-0.891177





00:30:28 HBMASTER: Trying to run another job!
00:30:28 job_callback for (9, 0, 5) finished
00:30:28 start sampling a new configuration.
00:30:28 best_vector: [1, 1, 0.12836112922476478, 0.948897503386738, 0.6178109368179643, 1, 0.7975719139951558, 0.10727083417631622, 2, 1, 2, 0, 0.08805051901151822, 0.17714622198669727, 0.3221959629837683, 0.6803600508955743], 0.0012262657602489537, 0.01437448038921518, 1.7626933122664627e-05
00:30:28 done sampling a new configuration.
00:30:28 HBMASTER: schedule new run for iteration 9
00:30:28 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
00:30:28 HBMASTER: submitting job (9, 0, 6) to dispatcher
00:30:28 DISPATCHER: trying to submit job (9, 0, 6)
00:30:28 DISPATCHER: trying to notify the job_runner thread.
00:30:28 HBMASTER: job (9, 0, 6) submitted to dispatcher
00:30:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:30:28 DISPATCHER: Trying to submit another job.
00:30:28 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:30:28 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:30:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:30:28 WORKER: start processing job (9, 0, 6)
00:30:28 WORKER: args: ()
00:30:28 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0018060187650711381, 'num_filters_1': 115, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.013789946234851398, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 19, 'num_filters_3': 23, 'num_filters_4': 31}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:30:55 DISPATCHER: Starting worker discovery
00:30:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:30:55 DISPATCHER: Finished worker discovery
00:31:55 DISPATCHER: Starting worker discovery
00:31:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:31:55 DISPATCHER: Finished worker discovery
00:32:55 DISPATCHER: Starting worker discovery
00:32:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:32:55 DISPATCHER: Finished worker discovery
00:32:57 WORKER: done with job (9, 0, 6), trying to register it.
00:32:57 WORKER: registered result for job (9, 0, 6) with dispatcher
00:32:57 DISPATCHER: job (9, 0, 6) finished
00:32:57 DISPATCHER: register_result: lock acquired
00:32:57 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
00:32:57 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0018060187650711381, 'num_filters_1': 115, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.013789946234851398, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 19, 'num_filters_3': 23, 'num_filters_4': 31}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7794267530798495, 'info': {'data05': 0.7794267530798495, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0018060187650711381, 'num_filters_1': 115, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.013789946234851398, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 19, 'num_filters_3': 23, 'num_filters_4': 31}"}}
exception: None

00:32:57 job_callback for (9, 0, 6) started
00:32:57 job_callback for (9, 0, 6) got condition
00:32:57 DISPATCHER: Trying to submit another job.
00:32:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:32:57 done building a new model for budget 133.333333 based on 17/44 split
Best loss for this budget:-0.891177





00:32:57 HBMASTER: Trying to run another job!
00:32:57 job_callback for (9, 0, 6) finished
00:32:57 start sampling a new configuration.
00:32:57 best_vector: [1, 1, 0.551912813264372, 0.8559965892452788, 0.9269059777596398, 1, 0.3378898269819123, 0.23399790307599608, 0, 1, 1, 1, 0.7334978445314357, 0.015241092374793763, 0.2467694702425306, 0.6817689185499503], 0.005261226672116442, 0.010366574503054319, 5.454089827395164e-05
00:32:57 done sampling a new configuration.
00:32:57 HBMASTER: schedule new run for iteration 9
00:32:57 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
00:32:57 HBMASTER: submitting job (9, 0, 7) to dispatcher
00:32:57 DISPATCHER: trying to submit job (9, 0, 7)
00:32:57 DISPATCHER: trying to notify the job_runner thread.
00:32:57 HBMASTER: job (9, 0, 7) submitted to dispatcher
00:32:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:32:57 DISPATCHER: Trying to submit another job.
00:32:57 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:32:57 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:32:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:32:57 WORKER: start processing job (9, 0, 7)
00:32:57 WORKER: args: ()
00:32:57 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.012700640597111538, 'num_filters_1': 95, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.02015757530061307, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 73, 'num_filters_3': 16, 'num_filters_4': 26, 'num_filters_5': 66}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:33:55 DISPATCHER: Starting worker discovery
00:33:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:33:55 DISPATCHER: Finished worker discovery
00:34:55 DISPATCHER: Starting worker discovery
00:34:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:34:55 DISPATCHER: Finished worker discovery
00:35:28 WORKER: done with job (9, 0, 7), trying to register it.
00:35:28 WORKER: registered result for job (9, 0, 7) with dispatcher
00:35:28 DISPATCHER: job (9, 0, 7) finished
00:35:28 DISPATCHER: register_result: lock acquired
00:35:28 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
00:35:28 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.012700640597111538, 'num_filters_1': 95, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.02015757530061307, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 73, 'num_filters_3': 16, 'num_filters_4': 26, 'num_filters_5': 66}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8452504669173599, 'info': {'data05': 0.8452504669173599, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.012700640597111538, 'num_filters_1': 95, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.02015757530061307, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 73, 'num_filters_3': 16, 'num_filters_4': 26, 'num_filters_5': 66}"}}
exception: None

00:35:28 job_callback for (9, 0, 7) started
00:35:28 job_callback for (9, 0, 7) got condition
00:35:28 DISPATCHER: Trying to submit another job.
00:35:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:35:28 done building a new model for budget 133.333333 based on 17/45 split
Best loss for this budget:-0.891177





00:35:28 HBMASTER: Trying to run another job!
00:35:28 job_callback for (9, 0, 7) finished
00:35:28 start sampling a new configuration.
00:35:28 best_vector: [0, 1, 0.11058323317244738, 0.8733159726265414, 0.7782628922877393, 0, 0.979735585540286, 0.2490847368707752, 1, 2, 1, 1, 0.4166327542812404, 0.27332802463898875, 0.16911211909769044, 0.8804307664140762], 0.0008196923802725167, 0.00395692295950683, 3.2434595992331247e-06
00:35:28 done sampling a new configuration.
00:35:28 HBMASTER: schedule new run for iteration 9
00:35:28 HBMASTER: trying submitting job (9, 0, 8) to dispatcher
00:35:28 HBMASTER: submitting job (9, 0, 8) to dispatcher
00:35:28 DISPATCHER: trying to submit job (9, 0, 8)
00:35:28 DISPATCHER: trying to notify the job_runner thread.
00:35:28 HBMASTER: job (9, 0, 8) submitted to dispatcher
00:35:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:35:28 DISPATCHER: Trying to submit another job.
00:35:28 DISPATCHER: starting job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:35:28 DISPATCHER: job (9, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:35:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:35:28 WORKER: start processing job (9, 0, 8)
00:35:28 WORKER: args: ()
00:35:28 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0016640503635141234, 'num_filters_1': 98, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.02108952091649907, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 37, 'num_filters_3': 28, 'num_filters_4': 22}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:35:55 DISPATCHER: Starting worker discovery
00:35:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:35:55 DISPATCHER: Finished worker discovery
00:36:55 DISPATCHER: Starting worker discovery
00:36:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:36:55 DISPATCHER: Finished worker discovery
00:37:55 DISPATCHER: Starting worker discovery
00:37:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:37:55 DISPATCHER: Finished worker discovery
00:37:57 WORKER: done with job (9, 0, 8), trying to register it.
00:37:57 WORKER: registered result for job (9, 0, 8) with dispatcher
00:37:57 DISPATCHER: job (9, 0, 8) finished
00:37:57 DISPATCHER: register_result: lock acquired
00:37:57 DISPATCHER: job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
00:37:57 job_id: (9, 0, 8)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0016640503635141234, 'num_filters_1': 98, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.02108952091649907, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 37, 'num_filters_3': 28, 'num_filters_4': 22}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8741794448421105, 'info': {'data05': 0.8741794448421105, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0016640503635141234, 'num_filters_1': 98, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.02108952091649907, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 37, 'num_filters_3': 28, 'num_filters_4': 22}"}}
exception: None

00:37:57 job_callback for (9, 0, 8) started
00:37:57 DISPATCHER: Trying to submit another job.
00:37:57 job_callback for (9, 0, 8) got condition
00:37:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:37:57 done building a new model for budget 133.333333 based on 17/45 split
Best loss for this budget:-0.891177





00:37:57 HBMASTER: Trying to run another job!
00:37:57 job_callback for (9, 0, 8) finished
00:37:57 ITERATION: Advancing config (9, 0, 6) to next budget 400.000000
00:37:57 ITERATION: Advancing config (9, 0, 7) to next budget 400.000000
00:37:57 ITERATION: Advancing config (9, 0, 8) to next budget 400.000000
00:37:57 HBMASTER: schedule new run for iteration 9
00:37:57 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
00:37:57 HBMASTER: submitting job (9, 0, 6) to dispatcher
00:37:57 DISPATCHER: trying to submit job (9, 0, 6)
00:37:57 DISPATCHER: trying to notify the job_runner thread.
00:37:57 HBMASTER: job (9, 0, 6) submitted to dispatcher
00:37:57 DISPATCHER: Trying to submit another job.
00:37:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:37:57 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:37:57 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:37:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:37:57 WORKER: start processing job (9, 0, 6)
00:37:57 WORKER: args: ()
00:37:57 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0018060187650711381, 'num_filters_1': 115, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.013789946234851398, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 19, 'num_filters_3': 23, 'num_filters_4': 31}, 'budget': 400.0, 'working_directory': '.'}
00:38:55 DISPATCHER: Starting worker discovery
00:38:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:38:55 DISPATCHER: Finished worker discovery
00:39:55 DISPATCHER: Starting worker discovery
00:39:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:39:55 DISPATCHER: Finished worker discovery
00:40:55 DISPATCHER: Starting worker discovery
00:40:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:40:55 DISPATCHER: Finished worker discovery
00:41:55 DISPATCHER: Starting worker discovery
00:41:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:41:55 DISPATCHER: Finished worker discovery
00:42:55 DISPATCHER: Starting worker discovery
00:42:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:42:55 DISPATCHER: Finished worker discovery
00:43:55 DISPATCHER: Starting worker discovery
00:43:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:43:55 DISPATCHER: Finished worker discovery
00:44:55 DISPATCHER: Starting worker discovery
00:44:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:44:55 DISPATCHER: Finished worker discovery
00:45:00 WORKER: done with job (9, 0, 6), trying to register it.
00:45:00 WORKER: registered result for job (9, 0, 6) with dispatcher
00:45:00 DISPATCHER: job (9, 0, 6) finished
00:45:00 DISPATCHER: register_result: lock acquired
00:45:00 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
00:45:00 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0018060187650711381, 'num_filters_1': 115, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.013789946234851398, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 19, 'num_filters_3': 23, 'num_filters_4': 31}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8263218541822823, 'info': {'data05': 0.8263218541822823, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0018060187650711381, 'num_filters_1': 115, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.013789946234851398, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 19, 'num_filters_3': 23, 'num_filters_4': 31}"}}
exception: None

00:45:00 job_callback for (9, 0, 6) started
00:45:00 DISPATCHER: Trying to submit another job.
00:45:00 job_callback for (9, 0, 6) got condition
00:45:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:45:00 HBMASTER: Trying to run another job!
00:45:00 job_callback for (9, 0, 6) finished
00:45:00 HBMASTER: schedule new run for iteration 9
00:45:00 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
00:45:00 HBMASTER: submitting job (9, 0, 7) to dispatcher
00:45:00 DISPATCHER: trying to submit job (9, 0, 7)
00:45:00 DISPATCHER: trying to notify the job_runner thread.
00:45:00 HBMASTER: job (9, 0, 7) submitted to dispatcher
00:45:00 DISPATCHER: Trying to submit another job.
00:45:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:45:00 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:45:00 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:45:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:45:00 WORKER: start processing job (9, 0, 7)
00:45:00 WORKER: args: ()
00:45:00 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.012700640597111538, 'num_filters_1': 95, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.02015757530061307, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 73, 'num_filters_3': 16, 'num_filters_4': 26, 'num_filters_5': 66}, 'budget': 400.0, 'working_directory': '.'}
00:45:55 DISPATCHER: Starting worker discovery
00:45:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:45:55 DISPATCHER: Finished worker discovery
00:46:55 DISPATCHER: Starting worker discovery
00:46:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:46:55 DISPATCHER: Finished worker discovery
00:47:55 DISPATCHER: Starting worker discovery
00:47:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:47:55 DISPATCHER: Finished worker discovery
00:48:55 DISPATCHER: Starting worker discovery
00:48:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:48:55 DISPATCHER: Finished worker discovery
00:49:55 DISPATCHER: Starting worker discovery
00:49:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:49:55 DISPATCHER: Finished worker discovery
00:50:55 DISPATCHER: Starting worker discovery
00:50:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:50:55 DISPATCHER: Finished worker discovery
00:51:55 DISPATCHER: Starting worker discovery
00:51:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:51:55 DISPATCHER: Finished worker discovery
00:52:10 WORKER: done with job (9, 0, 7), trying to register it.
00:52:10 WORKER: registered result for job (9, 0, 7) with dispatcher
00:52:10 DISPATCHER: job (9, 0, 7) finished
00:52:10 DISPATCHER: register_result: lock acquired
00:52:10 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
00:52:10 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.012700640597111538, 'num_filters_1': 95, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.02015757530061307, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 73, 'num_filters_3': 16, 'num_filters_4': 26, 'num_filters_5': 66}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8558231370536932, 'info': {'data05': 0.8558231370536932, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.012700640597111538, 'num_filters_1': 95, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.02015757530061307, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 73, 'num_filters_3': 16, 'num_filters_4': 26, 'num_filters_5': 66}"}}
exception: None

00:52:10 job_callback for (9, 0, 7) started
00:52:10 DISPATCHER: Trying to submit another job.
00:52:10 job_callback for (9, 0, 7) got condition
00:52:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:52:10 HBMASTER: Trying to run another job!
00:52:10 job_callback for (9, 0, 7) finished
00:52:10 HBMASTER: schedule new run for iteration 9
00:52:10 HBMASTER: trying submitting job (9, 0, 8) to dispatcher
00:52:10 HBMASTER: submitting job (9, 0, 8) to dispatcher
00:52:10 DISPATCHER: trying to submit job (9, 0, 8)
00:52:10 DISPATCHER: trying to notify the job_runner thread.
00:52:10 HBMASTER: job (9, 0, 8) submitted to dispatcher
00:52:10 DISPATCHER: Trying to submit another job.
00:52:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:52:10 DISPATCHER: starting job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:52:10 DISPATCHER: job (9, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:52:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:52:10 WORKER: start processing job (9, 0, 8)
00:52:10 WORKER: args: ()
00:52:10 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0016640503635141234, 'num_filters_1': 98, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.02108952091649907, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 37, 'num_filters_3': 28, 'num_filters_4': 22}, 'budget': 400.0, 'working_directory': '.'}
00:52:55 DISPATCHER: Starting worker discovery
00:52:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:52:55 DISPATCHER: Finished worker discovery
00:53:55 DISPATCHER: Starting worker discovery
00:53:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:53:55 DISPATCHER: Finished worker discovery
00:54:55 DISPATCHER: Starting worker discovery
00:54:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:54:55 DISPATCHER: Finished worker discovery
00:55:55 DISPATCHER: Starting worker discovery
00:55:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:55:55 DISPATCHER: Finished worker discovery
00:56:55 DISPATCHER: Starting worker discovery
00:56:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:56:55 DISPATCHER: Finished worker discovery
00:57:55 DISPATCHER: Starting worker discovery
00:57:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:57:55 DISPATCHER: Finished worker discovery
00:58:55 DISPATCHER: Starting worker discovery
00:58:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:58:55 DISPATCHER: Finished worker discovery
00:59:10 WORKER: done with job (9, 0, 8), trying to register it.
00:59:10 WORKER: registered result for job (9, 0, 8) with dispatcher
00:59:10 DISPATCHER: job (9, 0, 8) finished
00:59:10 DISPATCHER: register_result: lock acquired
00:59:10 DISPATCHER: job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
00:59:10 job_id: (9, 0, 8)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0016640503635141234, 'num_filters_1': 98, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.02108952091649907, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 37, 'num_filters_3': 28, 'num_filters_4': 22}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8126205449670829, 'info': {'data05': 0.8126205449670829, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0016640503635141234, 'num_filters_1': 98, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.02108952091649907, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 37, 'num_filters_3': 28, 'num_filters_4': 22}"}}
exception: None

00:59:10 job_callback for (9, 0, 8) started
00:59:10 DISPATCHER: Trying to submit another job.
00:59:10 job_callback for (9, 0, 8) got condition
00:59:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:59:10 HBMASTER: Trying to run another job!
00:59:10 job_callback for (9, 0, 8) finished
00:59:10 ITERATION: Advancing config (9, 0, 7) to next budget 1200.000000
00:59:10 HBMASTER: schedule new run for iteration 9
00:59:10 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
00:59:10 HBMASTER: submitting job (9, 0, 7) to dispatcher
00:59:10 DISPATCHER: trying to submit job (9, 0, 7)
00:59:10 DISPATCHER: trying to notify the job_runner thread.
00:59:10 HBMASTER: job (9, 0, 7) submitted to dispatcher
00:59:10 DISPATCHER: Trying to submit another job.
00:59:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:59:10 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:59:10 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:59:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:59:10 WORKER: start processing job (9, 0, 7)
00:59:10 WORKER: args: ()
00:59:10 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.012700640597111538, 'num_filters_1': 95, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.02015757530061307, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 73, 'num_filters_3': 16, 'num_filters_4': 26, 'num_filters_5': 66}, 'budget': 1200.0, 'working_directory': '.'}
00:59:55 DISPATCHER: Starting worker discovery
00:59:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:59:55 DISPATCHER: Finished worker discovery
01:00:55 DISPATCHER: Starting worker discovery
01:00:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:00:55 DISPATCHER: Finished worker discovery
01:01:55 DISPATCHER: Starting worker discovery
01:01:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:01:55 DISPATCHER: Finished worker discovery
01:02:55 DISPATCHER: Starting worker discovery
01:02:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:02:55 DISPATCHER: Finished worker discovery
01:03:55 DISPATCHER: Starting worker discovery
01:03:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:03:55 DISPATCHER: Finished worker discovery
01:04:55 DISPATCHER: Starting worker discovery
01:04:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:04:55 DISPATCHER: Finished worker discovery
01:05:55 DISPATCHER: Starting worker discovery
01:05:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:05:55 DISPATCHER: Finished worker discovery
01:06:55 DISPATCHER: Starting worker discovery
01:06:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:06:55 DISPATCHER: Finished worker discovery
01:07:55 DISPATCHER: Starting worker discovery
01:07:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:07:55 DISPATCHER: Finished worker discovery
01:08:55 DISPATCHER: Starting worker discovery
01:08:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:08:55 DISPATCHER: Finished worker discovery
01:09:55 DISPATCHER: Starting worker discovery
01:09:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:09:55 DISPATCHER: Finished worker discovery
01:10:55 DISPATCHER: Starting worker discovery
01:10:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:10:55 DISPATCHER: Finished worker discovery
01:11:55 DISPATCHER: Starting worker discovery
01:11:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:11:55 DISPATCHER: Finished worker discovery
01:12:55 DISPATCHER: Starting worker discovery
01:12:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:12:55 DISPATCHER: Finished worker discovery
01:13:55 DISPATCHER: Starting worker discovery
01:13:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:13:55 DISPATCHER: Finished worker discovery
01:14:55 DISPATCHER: Starting worker discovery
01:14:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:14:55 DISPATCHER: Finished worker discovery
01:15:55 DISPATCHER: Starting worker discovery
01:15:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:15:55 DISPATCHER: Finished worker discovery
01:16:55 DISPATCHER: Starting worker discovery
01:16:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:16:55 DISPATCHER: Finished worker discovery
01:17:55 DISPATCHER: Starting worker discovery
01:17:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:17:55 DISPATCHER: Finished worker discovery
01:18:55 DISPATCHER: Starting worker discovery
01:18:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:18:55 DISPATCHER: Finished worker discovery
01:19:55 DISPATCHER: Starting worker discovery
01:19:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:19:55 DISPATCHER: Finished worker discovery
01:20:19 WORKER: done with job (9, 0, 7), trying to register it.
01:20:19 WORKER: registered result for job (9, 0, 7) with dispatcher
01:20:19 DISPATCHER: job (9, 0, 7) finished
01:20:19 DISPATCHER: register_result: lock acquired
01:20:19 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:20:19 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.012700640597111538, 'num_filters_1': 95, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.02015757530061307, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 73, 'num_filters_3': 16, 'num_filters_4': 26, 'num_filters_5': 66}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.8463348752978872, 'info': {'data05': 0.8463348752978872, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.012700640597111538, 'num_filters_1': 95, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.02015757530061307, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 73, 'num_filters_3': 16, 'num_filters_4': 26, 'num_filters_5': 66}"}}
exception: None

01:20:19 job_callback for (9, 0, 7) started
01:20:19 DISPATCHER: Trying to submit another job.
01:20:19 job_callback for (9, 0, 7) got condition
01:20:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:20:19 HBMASTER: Trying to run another job!
01:20:19 job_callback for (9, 0, 7) finished
01:20:19 HBMASTER: shutdown initiated, shutdown_workers = True
01:20:19 WORKER: shutting down now!
01:20:19 DISPATCHER: Dispatcher shutting down
01:20:19 DISPATCHER: Trying to submit another job.
01:20:19 DISPATCHER: job_runner shutting down
01:20:19 DISPATCHER: discover_workers shutting down
01:20:19 DISPATCHER: 'discover_worker' thread exited
01:20:19 DISPATCHER: 'job_runner' thread exited
01:20:19 DISPATCHER: shut down complete
01:20:20 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7f9ca410cba8; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:38238>
01:20:20 WORKER: No dispatcher found. Waiting for one to initiate contact.
01:20:20 WORKER: start listening for jobs
01:20:20 wait_for_workers trying to get the condition
01:20:20 DISPATCHER: started the 'discover_worker' thread
01:20:20 DISPATCHER: started the 'job_runner' thread
01:20:20 DISPATCHER: Pyro daemon running on localhost:42925
01:20:20 DISPATCHER: Starting worker discovery
01:20:20 DISPATCHER: Found 1 potential workers, 0 currently in the pool.
01:20:20 DISPATCHER: discovered new worker, hpbandster.run_0.worker.metagpuj.13101140314513094464
01:20:20 HBMASTER: number of workers changed to 1
01:20:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:20:20 HBMASTER: only 1 worker(s) available, waiting for at least 1.
01:20:20 adjust_queue_size: lock accquired
01:20:20 HBMASTER: adjusted queue size to (0, 1)
01:20:20 DISPATCHER: Finished worker discovery
01:20:20 DISPATCHER: A new worker triggered discover_worker
01:20:20 DISPATCHER: Trying to submit another job.
01:20:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:20:20 Enough workers to start this run!
01:20:20 DISPATCHER: Starting worker discovery
01:20:20 HBMASTER: starting run at 1583886020.1073153
01:20:20 start sampling a new configuration.
01:20:20 done sampling a new configuration.
01:20:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:20:20 HBMASTER: schedule new run for iteration 0
01:20:20 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
01:20:20 HBMASTER: submitting job (0, 0, 0) to dispatcher
01:20:20 DISPATCHER: trying to submit job (0, 0, 0)
01:20:20 DISPATCHER: Finished worker discovery
01:20:20 DISPATCHER: trying to notify the job_runner thread.
01:20:20 HBMASTER: job (0, 0, 0) submitted to dispatcher
01:20:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:20:20 DISPATCHER: Trying to submit another job.
01:20:20 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:20:20 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:20:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:20:20 WORKER: start processing job (0, 0, 0)
01:20:20 WORKER: args: ()
01:20:20 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 91, 'last_n_outputs': 19, 'lr': 0.0605546114152946, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.08296825582466716}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-406:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:21:15 WORKER: done with job (0, 0, 0), trying to register it.
01:21:15 WORKER: registered result for job (0, 0, 0) with dispatcher
01:21:15 DISPATCHER: job (0, 0, 0) finished
01:21:15 DISPATCHER: register_result: lock acquired
01:21:15 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:21:15 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 91, 'last_n_outputs': 19, 'lr': 0.0605546114152946, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.08296825582466716}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 91, 'last_n_outputs': 19, 'lr': 0.0605546114152946, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.08296825582466716}"}}
exception: None

01:21:15 job_callback for (0, 0, 0) started
01:21:15 job_callback for (0, 0, 0) got condition
01:21:15 DISPATCHER: Trying to submit another job.
01:21:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:21:15 Only 1 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
01:21:15 HBMASTER: Trying to run another job!
01:21:15 job_callback for (0, 0, 0) finished
01:21:15 start sampling a new configuration.
01:21:15 done sampling a new configuration.
01:21:15 HBMASTER: schedule new run for iteration 0
01:21:15 HBMASTER: trying submitting job (0, 0, 1) to dispatcher
01:21:15 HBMASTER: submitting job (0, 0, 1) to dispatcher
01:21:15 DISPATCHER: trying to submit job (0, 0, 1)
01:21:15 DISPATCHER: trying to notify the job_runner thread.
01:21:15 HBMASTER: job (0, 0, 1) submitted to dispatcher
01:21:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:21:15 DISPATCHER: Trying to submit another job.
01:21:15 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:21:15 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:21:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:21:15 WORKER: start processing job (0, 0, 1)
01:21:15 WORKER: args: ()
01:21:15 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 48, 'last_n_outputs': 19, 'lr': 0.0011134557328256532, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.08340347350818257}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:21:20 DISPATCHER: Starting worker discovery
01:21:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:21:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-407:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:22:10 WORKER: done with job (0, 0, 1), trying to register it.
01:22:10 WORKER: registered result for job (0, 0, 1) with dispatcher
01:22:10 DISPATCHER: job (0, 0, 1) finished
01:22:10 DISPATCHER: register_result: lock acquired
01:22:10 DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:22:10 job_id: (0, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 48, 'last_n_outputs': 19, 'lr': 0.0011134557328256532, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.08340347350818257}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.11388594529149108, 'info': {'data05': 0.11388594529149108, 'config': "{'batch_size': 64, 'hidden_dim': 48, 'last_n_outputs': 19, 'lr': 0.0011134557328256532, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.08340347350818257}"}}
exception: None

01:22:10 job_callback for (0, 0, 1) started
01:22:10 job_callback for (0, 0, 1) got condition
01:22:10 DISPATCHER: Trying to submit another job.
01:22:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:22:10 Only 2 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
01:22:10 HBMASTER: Trying to run another job!
01:22:10 job_callback for (0, 0, 1) finished
01:22:10 start sampling a new configuration.
01:22:10 done sampling a new configuration.
01:22:10 HBMASTER: schedule new run for iteration 0
01:22:10 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
01:22:10 HBMASTER: submitting job (0, 0, 2) to dispatcher
01:22:10 DISPATCHER: trying to submit job (0, 0, 2)
01:22:10 DISPATCHER: trying to notify the job_runner thread.
01:22:10 HBMASTER: job (0, 0, 2) submitted to dispatcher
01:22:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:22:10 DISPATCHER: Trying to submit another job.
01:22:10 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:22:10 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:22:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:22:10 WORKER: start processing job (0, 0, 2)
01:22:10 WORKER: args: ()
01:22:10 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 74, 'last_n_outputs': 38, 'lr': 0.0028126521638304107, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.013393726549415322}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:22:20 DISPATCHER: Starting worker discovery
01:22:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:22:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-408:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:23:06 WORKER: done with job (0, 0, 2), trying to register it.
01:23:06 WORKER: registered result for job (0, 0, 2) with dispatcher
01:23:06 DISPATCHER: job (0, 0, 2) finished
01:23:06 DISPATCHER: register_result: lock acquired
01:23:06 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:23:06 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 74, 'last_n_outputs': 38, 'lr': 0.0028126521638304107, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.013393726549415322}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.09339107315487201, 'info': {'data05': 0.09339107315487201, 'config': "{'batch_size': 16, 'hidden_dim': 74, 'last_n_outputs': 38, 'lr': 0.0028126521638304107, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.013393726549415322}"}}
exception: None

01:23:06 job_callback for (0, 0, 2) started
01:23:06 DISPATCHER: Trying to submit another job.
01:23:06 job_callback for (0, 0, 2) got condition
01:23:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:23:06 Only 3 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
01:23:06 HBMASTER: Trying to run another job!
01:23:06 job_callback for (0, 0, 2) finished
01:23:06 start sampling a new configuration.
01:23:06 done sampling a new configuration.
01:23:06 HBMASTER: schedule new run for iteration 0
01:23:06 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
01:23:06 HBMASTER: submitting job (0, 0, 3) to dispatcher
01:23:06 DISPATCHER: trying to submit job (0, 0, 3)
01:23:06 DISPATCHER: trying to notify the job_runner thread.
01:23:06 HBMASTER: job (0, 0, 3) submitted to dispatcher
01:23:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:23:06 DISPATCHER: Trying to submit another job.
01:23:06 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:23:06 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:23:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:23:06 WORKER: start processing job (0, 0, 3)
01:23:06 WORKER: args: ()
01:23:06 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 58, 'last_n_outputs': 6, 'lr': 0.04247231145106452, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.11193693506357288}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:23:20 DISPATCHER: Starting worker discovery
01:23:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:23:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-409:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:24:02 WORKER: done with job (0, 0, 3), trying to register it.
01:24:02 WORKER: registered result for job (0, 0, 3) with dispatcher
01:24:02 DISPATCHER: job (0, 0, 3) finished
01:24:02 DISPATCHER: register_result: lock acquired
01:24:02 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:24:02 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 58, 'last_n_outputs': 6, 'lr': 0.04247231145106452, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.11193693506357288}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 58, 'last_n_outputs': 6, 'lr': 0.04247231145106452, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.11193693506357288}"}}
exception: None

01:24:02 job_callback for (0, 0, 3) started
01:24:02 DISPATCHER: Trying to submit another job.
01:24:02 job_callback for (0, 0, 3) got condition
01:24:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:24:02 Only 4 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
01:24:02 HBMASTER: Trying to run another job!
01:24:02 job_callback for (0, 0, 3) finished
01:24:02 start sampling a new configuration.
01:24:02 done sampling a new configuration.
01:24:02 HBMASTER: schedule new run for iteration 0
01:24:02 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
01:24:02 HBMASTER: submitting job (0, 0, 4) to dispatcher
01:24:02 DISPATCHER: trying to submit job (0, 0, 4)
01:24:02 DISPATCHER: trying to notify the job_runner thread.
01:24:02 HBMASTER: job (0, 0, 4) submitted to dispatcher
01:24:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:24:02 DISPATCHER: Trying to submit another job.
01:24:02 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:24:02 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:24:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:24:02 WORKER: start processing job (0, 0, 4)
01:24:02 WORKER: args: ()
01:24:02 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 95, 'last_n_outputs': 2, 'lr': 0.08646266353463514, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.19498268646305933}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-410:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:24:20 DISPATCHER: Starting worker discovery
01:24:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:24:20 DISPATCHER: Finished worker discovery
01:24:57 WORKER: done with job (0, 0, 4), trying to register it.
01:24:57 WORKER: registered result for job (0, 0, 4) with dispatcher
01:24:57 DISPATCHER: job (0, 0, 4) finished
01:24:57 DISPATCHER: register_result: lock acquired
01:24:57 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:24:57 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 95, 'last_n_outputs': 2, 'lr': 0.08646266353463514, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.19498268646305933}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 95, 'last_n_outputs': 2, 'lr': 0.08646266353463514, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.19498268646305933}"}}
exception: None

01:24:57 job_callback for (0, 0, 4) started
01:24:57 DISPATCHER: Trying to submit another job.
01:24:57 job_callback for (0, 0, 4) got condition
01:24:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:24:57 Only 5 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
01:24:57 HBMASTER: Trying to run another job!
01:24:57 job_callback for (0, 0, 4) finished
01:24:57 start sampling a new configuration.
01:24:57 done sampling a new configuration.
01:24:57 HBMASTER: schedule new run for iteration 0
01:24:57 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
01:24:57 HBMASTER: submitting job (0, 0, 5) to dispatcher
01:24:57 DISPATCHER: trying to submit job (0, 0, 5)
01:24:57 DISPATCHER: trying to notify the job_runner thread.
01:24:57 HBMASTER: job (0, 0, 5) submitted to dispatcher
01:24:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:24:57 DISPATCHER: Trying to submit another job.
01:24:57 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:24:57 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:24:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:24:57 WORKER: start processing job (0, 0, 5)
01:24:57 WORKER: args: ()
01:24:57 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 86, 'last_n_outputs': 2, 'lr': 0.0011371366750163661, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.026621964380320016}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-411:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:25:20 DISPATCHER: Starting worker discovery
01:25:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:25:20 DISPATCHER: Finished worker discovery
01:25:52 WORKER: done with job (0, 0, 5), trying to register it.
01:25:52 WORKER: registered result for job (0, 0, 5) with dispatcher
01:25:52 DISPATCHER: job (0, 0, 5) finished
01:25:52 DISPATCHER: register_result: lock acquired
01:25:52 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:25:52 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 86, 'last_n_outputs': 2, 'lr': 0.0011371366750163661, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.026621964380320016}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.009498009428377746, 'info': {'data05': 0.009498009428377746, 'config': "{'batch_size': 16, 'hidden_dim': 86, 'last_n_outputs': 2, 'lr': 0.0011371366750163661, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.026621964380320016}"}}
exception: None

01:25:52 job_callback for (0, 0, 5) started
01:25:52 DISPATCHER: Trying to submit another job.
01:25:52 job_callback for (0, 0, 5) got condition
01:25:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:25:52 Only 6 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
01:25:52 HBMASTER: Trying to run another job!
01:25:52 job_callback for (0, 0, 5) finished
01:25:52 start sampling a new configuration.
01:25:52 done sampling a new configuration.
01:25:52 HBMASTER: schedule new run for iteration 0
01:25:52 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
01:25:52 HBMASTER: submitting job (0, 0, 6) to dispatcher
01:25:52 DISPATCHER: trying to submit job (0, 0, 6)
01:25:52 DISPATCHER: trying to notify the job_runner thread.
01:25:52 HBMASTER: job (0, 0, 6) submitted to dispatcher
01:25:52 DISPATCHER: Trying to submit another job.
01:25:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:25:52 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:25:52 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:25:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:25:52 WORKER: start processing job (0, 0, 6)
01:25:52 WORKER: args: ()
01:25:52 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 21, 'last_n_outputs': 41, 'lr': 0.02757705430448898, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.01563252778780445}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-412:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:26:20 DISPATCHER: Starting worker discovery
01:26:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:26:20 DISPATCHER: Finished worker discovery
01:26:47 WORKER: done with job (0, 0, 6), trying to register it.
01:26:47 WORKER: registered result for job (0, 0, 6) with dispatcher
01:26:47 DISPATCHER: job (0, 0, 6) finished
01:26:47 DISPATCHER: register_result: lock acquired
01:26:47 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:26:47 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 21, 'last_n_outputs': 41, 'lr': 0.02757705430448898, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.01563252778780445}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1097595303681975, 'info': {'data05': 0.1097595303681975, 'config': "{'batch_size': 128, 'hidden_dim': 21, 'last_n_outputs': 41, 'lr': 0.02757705430448898, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.01563252778780445}"}}
exception: None

01:26:47 job_callback for (0, 0, 6) started
01:26:47 DISPATCHER: Trying to submit another job.
01:26:47 job_callback for (0, 0, 6) got condition
01:26:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:26:47 Only 7 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
01:26:47 HBMASTER: Trying to run another job!
01:26:47 job_callback for (0, 0, 6) finished
01:26:47 start sampling a new configuration.
01:26:47 done sampling a new configuration.
01:26:47 HBMASTER: schedule new run for iteration 0
01:26:47 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
01:26:47 HBMASTER: submitting job (0, 0, 7) to dispatcher
01:26:47 DISPATCHER: trying to submit job (0, 0, 7)
01:26:47 DISPATCHER: trying to notify the job_runner thread.
01:26:47 HBMASTER: job (0, 0, 7) submitted to dispatcher
01:26:47 DISPATCHER: Trying to submit another job.
01:26:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:26:47 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:26:47 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:26:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:26:47 WORKER: start processing job (0, 0, 7)
01:26:47 WORKER: args: ()
01:26:47 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 94, 'last_n_outputs': 48, 'lr': 0.0011915608989555558, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.1209860054239423}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-413:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:27:20 DISPATCHER: Starting worker discovery
01:27:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:27:20 DISPATCHER: Finished worker discovery
01:27:43 WORKER: done with job (0, 0, 7), trying to register it.
01:27:43 WORKER: registered result for job (0, 0, 7) with dispatcher
01:27:43 DISPATCHER: job (0, 0, 7) finished
01:27:43 DISPATCHER: register_result: lock acquired
01:27:43 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:27:43 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 94, 'last_n_outputs': 48, 'lr': 0.0011915608989555558, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.1209860054239423}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.03888455342240387, 'info': {'data05': 0.03888455342240387, 'config': "{'batch_size': 64, 'hidden_dim': 94, 'last_n_outputs': 48, 'lr': 0.0011915608989555558, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.1209860054239423}"}}
exception: None

01:27:43 job_callback for (0, 0, 7) started
01:27:43 DISPATCHER: Trying to submit another job.
01:27:43 job_callback for (0, 0, 7) got condition
01:27:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:27:43 Only 8 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
01:27:43 HBMASTER: Trying to run another job!
01:27:43 job_callback for (0, 0, 7) finished
01:27:43 start sampling a new configuration.
01:27:43 done sampling a new configuration.
01:27:43 HBMASTER: schedule new run for iteration 0
01:27:43 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
01:27:43 HBMASTER: submitting job (0, 0, 8) to dispatcher
01:27:43 DISPATCHER: trying to submit job (0, 0, 8)
01:27:43 DISPATCHER: trying to notify the job_runner thread.
01:27:43 HBMASTER: job (0, 0, 8) submitted to dispatcher
01:27:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:27:43 DISPATCHER: Trying to submit another job.
01:27:43 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:27:43 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:27:43 WORKER: start processing job (0, 0, 8)
01:27:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:27:43 WORKER: args: ()
01:27:43 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 52, 'last_n_outputs': 18, 'lr': 0.007658874580663487, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.027467550180421785}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-414:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:28:20 DISPATCHER: Starting worker discovery
01:28:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:28:20 DISPATCHER: Finished worker discovery
01:28:38 WORKER: done with job (0, 0, 8), trying to register it.
01:28:38 WORKER: registered result for job (0, 0, 8) with dispatcher
01:28:38 DISPATCHER: job (0, 0, 8) finished
01:28:38 DISPATCHER: register_result: lock acquired
01:28:38 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:28:38 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 52, 'last_n_outputs': 18, 'lr': 0.007658874580663487, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.027467550180421785}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 52, 'last_n_outputs': 18, 'lr': 0.007658874580663487, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.027467550180421785}"}}
exception: None

01:28:38 job_callback for (0, 0, 8) started
01:28:38 DISPATCHER: Trying to submit another job.
01:28:38 job_callback for (0, 0, 8) got condition
01:28:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:28:38 HBMASTER: Trying to run another job!
01:28:38 job_callback for (0, 0, 8) finished
01:28:38 start sampling a new configuration.
01:28:38 done sampling a new configuration.
01:28:38 HBMASTER: schedule new run for iteration 0
01:28:38 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
01:28:38 HBMASTER: submitting job (0, 0, 9) to dispatcher
01:28:38 DISPATCHER: trying to submit job (0, 0, 9)
01:28:38 DISPATCHER: trying to notify the job_runner thread.
01:28:38 HBMASTER: job (0, 0, 9) submitted to dispatcher
01:28:38 DISPATCHER: Trying to submit another job.
01:28:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:28:38 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:28:38 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:28:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:28:38 WORKER: start processing job (0, 0, 9)
01:28:38 WORKER: args: ()
01:28:38 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 32, 'lr': 0.035910686129645104, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.08040275525170136}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-415:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:29:20 DISPATCHER: Starting worker discovery
01:29:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:29:20 DISPATCHER: Finished worker discovery
01:29:33 WORKER: done with job (0, 0, 9), trying to register it.
01:29:33 WORKER: registered result for job (0, 0, 9) with dispatcher
01:29:33 DISPATCHER: job (0, 0, 9) finished
01:29:33 DISPATCHER: register_result: lock acquired
01:29:33 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:29:33 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 32, 'lr': 0.035910686129645104, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.08040275525170136}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2894502883651564, 'info': {'data05': 0.2894502883651564, 'config': "{'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 32, 'lr': 0.035910686129645104, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.08040275525170136}"}}
exception: None

01:29:33 job_callback for (0, 0, 9) started
01:29:33 job_callback for (0, 0, 9) got condition
01:29:33 DISPATCHER: Trying to submit another job.
01:29:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:29:33 HBMASTER: Trying to run another job!
01:29:33 job_callback for (0, 0, 9) finished
01:29:33 start sampling a new configuration.
01:29:33 done sampling a new configuration.
01:29:33 HBMASTER: schedule new run for iteration 0
01:29:33 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
01:29:33 HBMASTER: submitting job (0, 0, 10) to dispatcher
01:29:33 DISPATCHER: trying to submit job (0, 0, 10)
01:29:33 DISPATCHER: trying to notify the job_runner thread.
01:29:33 HBMASTER: job (0, 0, 10) submitted to dispatcher
01:29:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:29:33 DISPATCHER: Trying to submit another job.
01:29:33 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:29:33 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:29:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:29:33 WORKER: start processing job (0, 0, 10)
01:29:33 WORKER: args: ()
01:29:33 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 56, 'last_n_outputs': 24, 'lr': 0.0016782523002515427, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.061294002961997385}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-416:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:30:20 DISPATCHER: Starting worker discovery
01:30:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:30:20 DISPATCHER: Finished worker discovery
01:30:29 WORKER: done with job (0, 0, 10), trying to register it.
01:30:29 WORKER: registered result for job (0, 0, 10) with dispatcher
01:30:29 DISPATCHER: job (0, 0, 10) finished
01:30:29 DISPATCHER: register_result: lock acquired
01:30:29 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:30:29 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 56, 'last_n_outputs': 24, 'lr': 0.0016782523002515427, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.061294002961997385}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 56, 'last_n_outputs': 24, 'lr': 0.0016782523002515427, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.061294002961997385}"}}
exception: None

01:30:29 job_callback for (0, 0, 10) started
01:30:29 DISPATCHER: Trying to submit another job.
01:30:29 job_callback for (0, 0, 10) got condition
01:30:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:30:29 HBMASTER: Trying to run another job!
01:30:29 job_callback for (0, 0, 10) finished
01:30:29 start sampling a new configuration.
01:30:29 done sampling a new configuration.
01:30:29 HBMASTER: schedule new run for iteration 0
01:30:29 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
01:30:29 HBMASTER: submitting job (0, 0, 11) to dispatcher
01:30:29 DISPATCHER: trying to submit job (0, 0, 11)
01:30:29 DISPATCHER: trying to notify the job_runner thread.
01:30:29 HBMASTER: job (0, 0, 11) submitted to dispatcher
01:30:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:30:29 DISPATCHER: Trying to submit another job.
01:30:29 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:30:29 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:30:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:30:29 WORKER: start processing job (0, 0, 11)
01:30:29 WORKER: args: ()
01:30:29 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 97, 'last_n_outputs': 30, 'lr': 0.0076438886641304144, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.0123942346652229}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-417:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:31:20 DISPATCHER: Starting worker discovery
01:31:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:31:20 DISPATCHER: Finished worker discovery
01:31:24 WORKER: done with job (0, 0, 11), trying to register it.
01:31:24 WORKER: registered result for job (0, 0, 11) with dispatcher
01:31:24 DISPATCHER: job (0, 0, 11) finished
01:31:24 DISPATCHER: register_result: lock acquired
01:31:24 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:31:24 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 97, 'last_n_outputs': 30, 'lr': 0.0076438886641304144, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.0123942346652229}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8986409157418135, 'info': {'data05': 0.8986409157418135, 'config': "{'batch_size': 64, 'hidden_dim': 97, 'last_n_outputs': 30, 'lr': 0.0076438886641304144, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.0123942346652229}"}}
exception: None

01:31:24 job_callback for (0, 0, 11) started
01:31:24 DISPATCHER: Trying to submit another job.
01:31:24 job_callback for (0, 0, 11) got condition
01:31:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:31:24 HBMASTER: Trying to run another job!
01:31:24 job_callback for (0, 0, 11) finished
01:31:24 start sampling a new configuration.
01:31:24 done sampling a new configuration.
01:31:24 HBMASTER: schedule new run for iteration 0
01:31:24 HBMASTER: trying submitting job (0, 0, 12) to dispatcher
01:31:24 HBMASTER: submitting job (0, 0, 12) to dispatcher
01:31:24 DISPATCHER: trying to submit job (0, 0, 12)
01:31:24 DISPATCHER: trying to notify the job_runner thread.
01:31:24 HBMASTER: job (0, 0, 12) submitted to dispatcher
01:31:24 DISPATCHER: Trying to submit another job.
01:31:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:31:24 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:31:24 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:31:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:31:24 WORKER: start processing job (0, 0, 12)
01:31:24 WORKER: args: ()
01:31:24 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 62, 'last_n_outputs': 44, 'lr': 0.002846055186436775, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.11854271287154138}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-418:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:32:19 WORKER: done with job (0, 0, 12), trying to register it.
01:32:19 WORKER: registered result for job (0, 0, 12) with dispatcher
01:32:19 DISPATCHER: job (0, 0, 12) finished
01:32:19 DISPATCHER: register_result: lock acquired
01:32:19 DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:32:19 job_id: (0, 0, 12)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 62, 'last_n_outputs': 44, 'lr': 0.002846055186436775, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.11854271287154138}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 62, 'last_n_outputs': 44, 'lr': 0.002846055186436775, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.11854271287154138}"}}
exception: None

01:32:19 job_callback for (0, 0, 12) started
01:32:19 job_callback for (0, 0, 12) got condition
01:32:19 DISPATCHER: Trying to submit another job.
01:32:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:32:19 HBMASTER: Trying to run another job!
01:32:19 job_callback for (0, 0, 12) finished
01:32:19 start sampling a new configuration.
01:32:19 done sampling a new configuration.
01:32:19 HBMASTER: schedule new run for iteration 0
01:32:19 HBMASTER: trying submitting job (0, 0, 13) to dispatcher
01:32:19 HBMASTER: submitting job (0, 0, 13) to dispatcher
01:32:19 DISPATCHER: trying to submit job (0, 0, 13)
01:32:19 DISPATCHER: trying to notify the job_runner thread.
01:32:19 HBMASTER: job (0, 0, 13) submitted to dispatcher
01:32:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:32:19 DISPATCHER: Trying to submit another job.
01:32:19 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:32:19 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:32:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:32:19 WORKER: start processing job (0, 0, 13)
01:32:19 WORKER: args: ()
01:32:19 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 48, 'last_n_outputs': 33, 'lr': 0.019834543915259958, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.15555047731428115}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:32:20 DISPATCHER: Starting worker discovery
01:32:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:32:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-419:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:33:15 WORKER: done with job (0, 0, 13), trying to register it.
01:33:15 WORKER: registered result for job (0, 0, 13) with dispatcher
01:33:15 DISPATCHER: job (0, 0, 13) finished
01:33:15 DISPATCHER: register_result: lock acquired
01:33:15 DISPATCHER: job (0, 0, 13) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:33:15 job_id: (0, 0, 13)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 48, 'last_n_outputs': 33, 'lr': 0.019834543915259958, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.15555047731428115}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 1.3605509725893145e-06, 'info': {'data05': -1.3605509725893145e-06, 'config': "{'batch_size': 64, 'hidden_dim': 48, 'last_n_outputs': 33, 'lr': 0.019834543915259958, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.15555047731428115}"}}
exception: None

01:33:15 job_callback for (0, 0, 13) started
01:33:15 job_callback for (0, 0, 13) got condition
01:33:15 DISPATCHER: Trying to submit another job.
01:33:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:33:15 HBMASTER: Trying to run another job!
01:33:15 job_callback for (0, 0, 13) finished
01:33:15 start sampling a new configuration.
01:33:15 done sampling a new configuration.
01:33:15 HBMASTER: schedule new run for iteration 0
01:33:15 HBMASTER: trying submitting job (0, 0, 14) to dispatcher
01:33:15 HBMASTER: submitting job (0, 0, 14) to dispatcher
01:33:15 DISPATCHER: trying to submit job (0, 0, 14)
01:33:15 DISPATCHER: trying to notify the job_runner thread.
01:33:15 HBMASTER: job (0, 0, 14) submitted to dispatcher
01:33:15 DISPATCHER: Trying to submit another job.
01:33:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:33:15 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:33:15 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:33:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:33:15 WORKER: start processing job (0, 0, 14)
01:33:15 WORKER: args: ()
01:33:15 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 36, 'last_n_outputs': 39, 'lr': 0.05036392428079775, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.024640785644886417}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:33:20 DISPATCHER: Starting worker discovery
01:33:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:33:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-420:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:34:10 WORKER: done with job (0, 0, 14), trying to register it.
01:34:10 WORKER: registered result for job (0, 0, 14) with dispatcher
01:34:10 DISPATCHER: job (0, 0, 14) finished
01:34:10 DISPATCHER: register_result: lock acquired
01:34:10 DISPATCHER: job (0, 0, 14) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:34:10 job_id: (0, 0, 14)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 36, 'last_n_outputs': 39, 'lr': 0.05036392428079775, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.024640785644886417}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 36, 'last_n_outputs': 39, 'lr': 0.05036392428079775, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.024640785644886417}"}}
exception: None

01:34:10 job_callback for (0, 0, 14) started
01:34:10 DISPATCHER: Trying to submit another job.
01:34:10 job_callback for (0, 0, 14) got condition
01:34:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:34:10 HBMASTER: Trying to run another job!
01:34:10 job_callback for (0, 0, 14) finished
01:34:10 start sampling a new configuration.
01:34:10 done sampling a new configuration.
01:34:10 HBMASTER: schedule new run for iteration 0
01:34:10 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
01:34:10 HBMASTER: submitting job (0, 0, 15) to dispatcher
01:34:10 DISPATCHER: trying to submit job (0, 0, 15)
01:34:10 DISPATCHER: trying to notify the job_runner thread.
01:34:10 HBMASTER: job (0, 0, 15) submitted to dispatcher
01:34:10 DISPATCHER: Trying to submit another job.
01:34:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:34:10 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:34:10 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:34:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:34:10 WORKER: start processing job (0, 0, 15)
01:34:10 WORKER: args: ()
01:34:10 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 21, 'last_n_outputs': 31, 'lr': 0.0010031030650815048, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.11512887093009953}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:34:20 DISPATCHER: Starting worker discovery
01:34:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:34:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-421:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:35:05 WORKER: done with job (0, 0, 15), trying to register it.
01:35:05 WORKER: registered result for job (0, 0, 15) with dispatcher
01:35:05 DISPATCHER: job (0, 0, 15) finished
01:35:05 DISPATCHER: register_result: lock acquired
01:35:05 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:35:05 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 21, 'last_n_outputs': 31, 'lr': 0.0010031030650815048, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.11512887093009953}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 21, 'last_n_outputs': 31, 'lr': 0.0010031030650815048, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.11512887093009953}"}}
exception: None

01:35:05 job_callback for (0, 0, 15) started
01:35:05 DISPATCHER: Trying to submit another job.
01:35:05 job_callback for (0, 0, 15) got condition
01:35:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:35:05 HBMASTER: Trying to run another job!
01:35:05 job_callback for (0, 0, 15) finished
01:35:05 start sampling a new configuration.
01:35:05 done sampling a new configuration.
01:35:05 HBMASTER: schedule new run for iteration 0
01:35:05 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
01:35:05 HBMASTER: submitting job (0, 0, 16) to dispatcher
01:35:05 DISPATCHER: trying to submit job (0, 0, 16)
01:35:05 DISPATCHER: trying to notify the job_runner thread.
01:35:05 HBMASTER: job (0, 0, 16) submitted to dispatcher
01:35:05 DISPATCHER: Trying to submit another job.
01:35:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:35:05 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:35:05 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:35:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:35:05 WORKER: start processing job (0, 0, 16)
01:35:05 WORKER: args: ()
01:35:05 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 49, 'last_n_outputs': 37, 'lr': 0.04328159554473261, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.013224063781917789}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-422:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:35:20 DISPATCHER: Starting worker discovery
01:35:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:35:20 DISPATCHER: Finished worker discovery
01:36:00 WORKER: done with job (0, 0, 16), trying to register it.
01:36:00 WORKER: registered result for job (0, 0, 16) with dispatcher
01:36:00 DISPATCHER: job (0, 0, 16) finished
01:36:00 DISPATCHER: register_result: lock acquired
01:36:00 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:36:00 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 49, 'last_n_outputs': 37, 'lr': 0.04328159554473261, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.013224063781917789}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.08969414718159371, 'info': {'data05': 0.08969414718159371, 'config': "{'batch_size': 32, 'hidden_dim': 49, 'last_n_outputs': 37, 'lr': 0.04328159554473261, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.013224063781917789}"}}
exception: None

01:36:00 job_callback for (0, 0, 16) started
01:36:00 job_callback for (0, 0, 16) got condition
01:36:00 DISPATCHER: Trying to submit another job.
01:36:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:36:00 HBMASTER: Trying to run another job!
01:36:00 job_callback for (0, 0, 16) finished
01:36:00 start sampling a new configuration.
01:36:00 done sampling a new configuration.
01:36:00 HBMASTER: schedule new run for iteration 0
01:36:00 HBMASTER: trying submitting job (0, 0, 17) to dispatcher
01:36:00 HBMASTER: submitting job (0, 0, 17) to dispatcher
01:36:00 DISPATCHER: trying to submit job (0, 0, 17)
01:36:00 DISPATCHER: trying to notify the job_runner thread.
01:36:00 HBMASTER: job (0, 0, 17) submitted to dispatcher
01:36:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:36:00 DISPATCHER: Trying to submit another job.
01:36:00 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:36:00 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:36:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:36:00 WORKER: start processing job (0, 0, 17)
01:36:00 WORKER: args: ()
01:36:00 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 35, 'last_n_outputs': 2, 'lr': 0.004216110259806783, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.014200525839348211}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-423:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:36:20 DISPATCHER: Starting worker discovery
01:36:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:36:20 DISPATCHER: Finished worker discovery
01:36:55 WORKER: done with job (0, 0, 17), trying to register it.
01:36:55 WORKER: registered result for job (0, 0, 17) with dispatcher
01:36:55 DISPATCHER: job (0, 0, 17) finished
01:36:55 DISPATCHER: register_result: lock acquired
01:36:55 DISPATCHER: job (0, 0, 17) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:36:55 job_id: (0, 0, 17)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 35, 'last_n_outputs': 2, 'lr': 0.004216110259806783, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.014200525839348211}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.06533927867399075, 'info': {'data05': -0.06533927867399075, 'config': "{'batch_size': 128, 'hidden_dim': 35, 'last_n_outputs': 2, 'lr': 0.004216110259806783, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.014200525839348211}"}}
exception: None

01:36:55 job_callback for (0, 0, 17) started
01:36:55 DISPATCHER: Trying to submit another job.
01:36:55 job_callback for (0, 0, 17) got condition
01:36:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:36:55 done building a new model for budget 44.444444 based on 9/15 split
Best loss for this budget:-0.898641





01:36:55 HBMASTER: Trying to run another job!
01:36:55 job_callback for (0, 0, 17) finished
01:36:55 start sampling a new configuration.
01:36:55 done sampling a new configuration.
01:36:55 HBMASTER: schedule new run for iteration 0
01:36:55 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
01:36:55 HBMASTER: submitting job (0, 0, 18) to dispatcher
01:36:55 DISPATCHER: trying to submit job (0, 0, 18)
01:36:55 DISPATCHER: trying to notify the job_runner thread.
01:36:55 HBMASTER: job (0, 0, 18) submitted to dispatcher
01:36:55 DISPATCHER: Trying to submit another job.
01:36:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:36:55 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:36:55 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:36:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:36:55 WORKER: start processing job (0, 0, 18)
01:36:55 WORKER: args: ()
01:36:55 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 83, 'last_n_outputs': 22, 'lr': 0.039685082396502695, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.1930742081309999}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-424:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:37:20 DISPATCHER: Starting worker discovery
01:37:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:37:20 DISPATCHER: Finished worker discovery
01:37:51 WORKER: done with job (0, 0, 18), trying to register it.
01:37:51 WORKER: registered result for job (0, 0, 18) with dispatcher
01:37:51 DISPATCHER: job (0, 0, 18) finished
01:37:51 DISPATCHER: register_result: lock acquired
01:37:51 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:37:51 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 83, 'last_n_outputs': 22, 'lr': 0.039685082396502695, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.1930742081309999}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 83, 'last_n_outputs': 22, 'lr': 0.039685082396502695, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.1930742081309999}"}}
exception: None

01:37:51 job_callback for (0, 0, 18) started
01:37:51 job_callback for (0, 0, 18) got condition
01:37:51 DISPATCHER: Trying to submit another job.
01:37:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:37:51 done building a new model for budget 44.444444 based on 9/16 split
Best loss for this budget:-0.898641





01:37:51 HBMASTER: Trying to run another job!
01:37:51 job_callback for (0, 0, 18) finished
01:37:51 start sampling a new configuration.
01:37:51 done sampling a new configuration.
01:37:51 HBMASTER: schedule new run for iteration 0
01:37:51 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
01:37:51 HBMASTER: submitting job (0, 0, 19) to dispatcher
01:37:51 DISPATCHER: trying to submit job (0, 0, 19)
01:37:51 DISPATCHER: trying to notify the job_runner thread.
01:37:51 HBMASTER: job (0, 0, 19) submitted to dispatcher
01:37:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:37:51 DISPATCHER: Trying to submit another job.
01:37:51 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:37:51 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:37:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:37:51 WORKER: start processing job (0, 0, 19)
01:37:51 WORKER: args: ()
01:37:51 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 4, 'lr': 0.007509952311010432, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.14982055175870432}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-425:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:38:20 DISPATCHER: Starting worker discovery
01:38:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:38:20 DISPATCHER: Finished worker discovery
01:38:46 WORKER: done with job (0, 0, 19), trying to register it.
01:38:46 WORKER: registered result for job (0, 0, 19) with dispatcher
01:38:46 DISPATCHER: job (0, 0, 19) finished
01:38:46 DISPATCHER: register_result: lock acquired
01:38:46 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:38:46 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 4, 'lr': 0.007509952311010432, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.14982055175870432}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.06904479710767872, 'info': {'data05': 0.06904479710767872, 'config': "{'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 4, 'lr': 0.007509952311010432, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.14982055175870432}"}}
exception: None

01:38:46 job_callback for (0, 0, 19) started
01:38:46 DISPATCHER: Trying to submit another job.
01:38:46 job_callback for (0, 0, 19) got condition
01:38:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:38:46 done building a new model for budget 44.444444 based on 9/17 split
Best loss for this budget:-0.898641





01:38:46 HBMASTER: Trying to run another job!
01:38:46 job_callback for (0, 0, 19) finished
01:38:46 start sampling a new configuration.
01:38:46 done sampling a new configuration.
01:38:46 HBMASTER: schedule new run for iteration 0
01:38:46 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
01:38:46 HBMASTER: submitting job (0, 0, 20) to dispatcher
01:38:46 DISPATCHER: trying to submit job (0, 0, 20)
01:38:46 DISPATCHER: trying to notify the job_runner thread.
01:38:46 HBMASTER: job (0, 0, 20) submitted to dispatcher
01:38:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:38:46 DISPATCHER: Trying to submit another job.
01:38:46 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:38:46 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:38:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:38:46 WORKER: start processing job (0, 0, 20)
01:38:46 WORKER: args: ()
01:38:46 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 42, 'last_n_outputs': 5, 'lr': 0.0010161433363813808, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.014193338421072184}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-426:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:39:20 DISPATCHER: Starting worker discovery
01:39:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:39:20 DISPATCHER: Finished worker discovery
01:39:41 WORKER: done with job (0, 0, 20), trying to register it.
01:39:41 WORKER: registered result for job (0, 0, 20) with dispatcher
01:39:41 DISPATCHER: job (0, 0, 20) finished
01:39:41 DISPATCHER: register_result: lock acquired
01:39:41 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:39:41 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 42, 'last_n_outputs': 5, 'lr': 0.0010161433363813808, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.014193338421072184}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.009819548860369029, 'info': {'data05': 0.009819548860369029, 'config': "{'batch_size': 16, 'hidden_dim': 42, 'last_n_outputs': 5, 'lr': 0.0010161433363813808, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.014193338421072184}"}}
exception: None

01:39:41 job_callback for (0, 0, 20) started
01:39:41 DISPATCHER: Trying to submit another job.
01:39:41 job_callback for (0, 0, 20) got condition
01:39:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:39:41 done building a new model for budget 44.444444 based on 9/17 split
Best loss for this budget:-0.898641





01:39:41 HBMASTER: Trying to run another job!
01:39:41 job_callback for (0, 0, 20) finished
01:39:41 start sampling a new configuration.
01:39:41 best_vector: [0, 0.9155703466894218, 0.7201239474691653, 0.9224084059698199, 0.002588851917682322, 0, 0.06819888445411863, 0.9115331089131614], 0.008488107098547644, 0.044683192707588554, 0.0003792757252070547
01:39:41 done sampling a new configuration.
01:39:41 HBMASTER: schedule new run for iteration 0
01:39:41 HBMASTER: trying submitting job (0, 0, 21) to dispatcher
01:39:41 HBMASTER: submitting job (0, 0, 21) to dispatcher
01:39:41 DISPATCHER: trying to submit job (0, 0, 21)
01:39:41 DISPATCHER: trying to notify the job_runner thread.
01:39:41 HBMASTER: job (0, 0, 21) submitted to dispatcher
01:39:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:39:41 DISPATCHER: Trying to submit another job.
01:39:41 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:39:41 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:39:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:39:41 WORKER: start processing job (0, 0, 21)
01:39:41 WORKER: args: ()
01:39:41 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 94, 'last_n_outputs': 37, 'lr': 0.06995468606307488, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.1534376423577473}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-427:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:40:20 DISPATCHER: Starting worker discovery
01:40:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:40:20 DISPATCHER: Finished worker discovery
01:40:37 WORKER: done with job (0, 0, 21), trying to register it.
01:40:37 WORKER: registered result for job (0, 0, 21) with dispatcher
01:40:37 DISPATCHER: job (0, 0, 21) finished
01:40:37 DISPATCHER: register_result: lock acquired
01:40:37 DISPATCHER: job (0, 0, 21) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:40:37 job_id: (0, 0, 21)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 94, 'last_n_outputs': 37, 'lr': 0.06995468606307488, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.1534376423577473}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 94, 'last_n_outputs': 37, 'lr': 0.06995468606307488, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.1534376423577473}"}}
exception: None

01:40:37 job_callback for (0, 0, 21) started
01:40:37 DISPATCHER: Trying to submit another job.
01:40:37 job_callback for (0, 0, 21) got condition
01:40:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:40:37 done building a new model for budget 44.444444 based on 9/18 split
Best loss for this budget:-0.898641





01:40:37 HBMASTER: Trying to run another job!
01:40:37 job_callback for (0, 0, 21) finished
01:40:37 start sampling a new configuration.
01:40:37 best_vector: [3, 0.19319406308418496, 0.8102510134884636, 0.905429626262925, 0.34908968514132105, 1, 0.5662295064335232, 0.01443538491554297], 0.01043892841295349, 0.24318242464089268, 0.0025385639221147355
01:40:37 done sampling a new configuration.
01:40:37 HBMASTER: schedule new run for iteration 0
01:40:37 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
01:40:37 HBMASTER: submitting job (0, 0, 22) to dispatcher
01:40:37 DISPATCHER: trying to submit job (0, 0, 22)
01:40:37 DISPATCHER: trying to notify the job_runner thread.
01:40:37 HBMASTER: job (0, 0, 22) submitted to dispatcher
01:40:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:40:37 DISPATCHER: Trying to submit another job.
01:40:37 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:40:37 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:40:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:40:37 WORKER: start processing job (0, 0, 22)
01:40:37 WORKER: args: ()
01:40:37 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 35, 'last_n_outputs': 41, 'lr': 0.06469329217860041, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.010441932194867103}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-428:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:41:20 DISPATCHER: Starting worker discovery
01:41:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:41:20 DISPATCHER: Finished worker discovery
01:41:32 WORKER: done with job (0, 0, 22), trying to register it.
01:41:32 WORKER: registered result for job (0, 0, 22) with dispatcher
01:41:32 DISPATCHER: job (0, 0, 22) finished
01:41:32 DISPATCHER: register_result: lock acquired
01:41:32 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:41:32 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 35, 'last_n_outputs': 41, 'lr': 0.06469329217860041, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.010441932194867103}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.029372916934918926, 'info': {'data05': 0.029372916934918926, 'config': "{'batch_size': 128, 'hidden_dim': 35, 'last_n_outputs': 41, 'lr': 0.06469329217860041, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.010441932194867103}"}}
exception: None

01:41:32 job_callback for (0, 0, 22) started
01:41:32 job_callback for (0, 0, 22) got condition
01:41:32 DISPATCHER: Trying to submit another job.
01:41:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:41:32 done building a new model for budget 44.444444 based on 9/19 split
Best loss for this budget:-0.898641





01:41:32 HBMASTER: Trying to run another job!
01:41:32 job_callback for (0, 0, 22) finished
01:41:32 start sampling a new configuration.
01:41:32 done sampling a new configuration.
01:41:32 HBMASTER: schedule new run for iteration 0
01:41:32 HBMASTER: trying submitting job (0, 0, 23) to dispatcher
01:41:32 HBMASTER: submitting job (0, 0, 23) to dispatcher
01:41:32 DISPATCHER: trying to submit job (0, 0, 23)
01:41:32 DISPATCHER: trying to notify the job_runner thread.
01:41:32 HBMASTER: job (0, 0, 23) submitted to dispatcher
01:41:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:41:32 DISPATCHER: Trying to submit another job.
01:41:32 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:41:32 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:41:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:41:32 WORKER: start processing job (0, 0, 23)
01:41:32 WORKER: args: ()
01:41:32 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 24, 'last_n_outputs': 26, 'lr': 0.003460686681877912, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.07853787363621233}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-429:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:42:20 DISPATCHER: Starting worker discovery
01:42:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:42:20 DISPATCHER: Finished worker discovery
01:42:28 WORKER: done with job (0, 0, 23), trying to register it.
01:42:28 WORKER: registered result for job (0, 0, 23) with dispatcher
01:42:28 DISPATCHER: job (0, 0, 23) finished
01:42:28 DISPATCHER: register_result: lock acquired
01:42:28 DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:42:28 job_id: (0, 0, 23)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 24, 'last_n_outputs': 26, 'lr': 0.003460686681877912, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.07853787363621233}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.022892080948909085, 'info': {'data05': -0.022892080948909085, 'config': "{'batch_size': 16, 'hidden_dim': 24, 'last_n_outputs': 26, 'lr': 0.003460686681877912, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.07853787363621233}"}}
exception: None

01:42:28 job_callback for (0, 0, 23) started
01:42:28 job_callback for (0, 0, 23) got condition
01:42:28 DISPATCHER: Trying to submit another job.
01:42:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:42:28 done building a new model for budget 44.444444 based on 9/20 split
Best loss for this budget:-0.898641





01:42:28 HBMASTER: Trying to run another job!
01:42:28 job_callback for (0, 0, 23) finished
01:42:28 start sampling a new configuration.
01:42:28 best_vector: [1, 0.9278104413455625, 0.9245563536127052, 0.11360978943473776, 0.3579121180602856, 1, 0.32690538760697563, 0.2730546932528362], 0.006243259552855166, 0.11315859889807338, 0.0007064785035581027
01:42:28 done sampling a new configuration.
01:42:28 HBMASTER: schedule new run for iteration 0
01:42:28 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
01:42:28 HBMASTER: submitting job (0, 0, 24) to dispatcher
01:42:28 DISPATCHER: trying to submit job (0, 0, 24)
01:42:28 DISPATCHER: trying to notify the job_runner thread.
01:42:28 HBMASTER: job (0, 0, 24) submitted to dispatcher
01:42:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:42:28 DISPATCHER: Trying to submit another job.
01:42:28 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:42:28 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:42:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:42:28 WORKER: start processing job (0, 0, 24)
01:42:28 WORKER: args: ()
01:42:28 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 95, 'last_n_outputs': 47, 'lr': 0.0016874059605685358, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.02265960559292376}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-430:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:43:20 DISPATCHER: Starting worker discovery
01:43:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:43:20 DISPATCHER: Finished worker discovery
01:43:23 WORKER: done with job (0, 0, 24), trying to register it.
01:43:23 WORKER: registered result for job (0, 0, 24) with dispatcher
01:43:23 DISPATCHER: job (0, 0, 24) finished
01:43:23 DISPATCHER: register_result: lock acquired
01:43:23 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:43:23 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 95, 'last_n_outputs': 47, 'lr': 0.0016874059605685358, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.02265960559292376}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.020453991448600002, 'info': {'data05': 0.020453991448600002, 'config': "{'batch_size': 32, 'hidden_dim': 95, 'last_n_outputs': 47, 'lr': 0.0016874059605685358, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.02265960559292376}"}}
exception: None

01:43:23 DISPATCHER: Trying to submit another job.
01:43:23 job_callback for (0, 0, 24) started
01:43:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:43:23 job_callback for (0, 0, 24) got condition
01:43:23 done building a new model for budget 44.444444 based on 9/21 split
Best loss for this budget:-0.898641





01:43:23 HBMASTER: Trying to run another job!
01:43:23 job_callback for (0, 0, 24) finished
01:43:23 start sampling a new configuration.
01:43:23 done sampling a new configuration.
01:43:23 HBMASTER: schedule new run for iteration 0
01:43:23 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
01:43:23 HBMASTER: submitting job (0, 0, 25) to dispatcher
01:43:23 DISPATCHER: trying to submit job (0, 0, 25)
01:43:23 DISPATCHER: trying to notify the job_runner thread.
01:43:23 HBMASTER: job (0, 0, 25) submitted to dispatcher
01:43:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:43:23 DISPATCHER: Trying to submit another job.
01:43:23 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:43:23 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:43:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:43:23 WORKER: start processing job (0, 0, 25)
01:43:23 WORKER: args: ()
01:43:23 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 46, 'last_n_outputs': 37, 'lr': 0.006121954398423043, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.06766475764452352}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-431:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:44:19 WORKER: done with job (0, 0, 25), trying to register it.
01:44:19 WORKER: registered result for job (0, 0, 25) with dispatcher
01:44:19 DISPATCHER: job (0, 0, 25) finished
01:44:19 DISPATCHER: register_result: lock acquired
01:44:19 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:44:19 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 46, 'last_n_outputs': 37, 'lr': 0.006121954398423043, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.06766475764452352}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.001778190508393603, 'info': {'data05': 0.001778190508393603, 'config': "{'batch_size': 32, 'hidden_dim': 46, 'last_n_outputs': 37, 'lr': 0.006121954398423043, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.06766475764452352}"}}
exception: None

01:44:19 job_callback for (0, 0, 25) started
01:44:19 job_callback for (0, 0, 25) got condition
01:44:19 DISPATCHER: Trying to submit another job.
01:44:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:44:19 done building a new model for budget 44.444444 based on 9/22 split
Best loss for this budget:-0.898641





01:44:19 HBMASTER: Trying to run another job!
01:44:19 job_callback for (0, 0, 25) finished
01:44:19 start sampling a new configuration.
01:44:19 best_vector: [3, 0.23069341775525426, 0.4863375587486379, 0.7148990679737446, 0.2130300276498689, 1, 0.8058839119579603, 0.07622734275654534], 0.06674390618914451, 0.12517420680330538, 0.00835461551618039
01:44:19 done sampling a new configuration.
01:44:19 HBMASTER: schedule new run for iteration 0
01:44:19 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
01:44:19 HBMASTER: submitting job (0, 0, 26) to dispatcher
01:44:19 DISPATCHER: trying to submit job (0, 0, 26)
01:44:19 DISPATCHER: trying to notify the job_runner thread.
01:44:19 HBMASTER: job (0, 0, 26) submitted to dispatcher
01:44:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:44:19 DISPATCHER: Trying to submit another job.
01:44:19 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:44:19 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:44:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:44:19 WORKER: start processing job (0, 0, 26)
01:44:19 WORKER: args: ()
01:44:19 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 38, 'last_n_outputs': 25, 'lr': 0.026902840446053577, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.012565334645858853}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:44:20 DISPATCHER: Starting worker discovery
01:44:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:44:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-432:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:45:15 WORKER: done with job (0, 0, 26), trying to register it.
01:45:15 WORKER: registered result for job (0, 0, 26) with dispatcher
01:45:15 DISPATCHER: job (0, 0, 26) finished
01:45:15 DISPATCHER: register_result: lock acquired
01:45:15 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:45:15 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 38, 'last_n_outputs': 25, 'lr': 0.026902840446053577, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.012565334645858853}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.02828521403373633, 'info': {'data05': 0.02828521403373633, 'config': "{'batch_size': 128, 'hidden_dim': 38, 'last_n_outputs': 25, 'lr': 0.026902840446053577, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.012565334645858853}"}}
exception: None

01:45:15 job_callback for (0, 0, 26) started
01:45:15 DISPATCHER: Trying to submit another job.
01:45:15 job_callback for (0, 0, 26) got condition
01:45:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:45:15 done building a new model for budget 44.444444 based on 9/22 split
Best loss for this budget:-0.898641





01:45:15 HBMASTER: Trying to run another job!
01:45:15 job_callback for (0, 0, 26) finished
01:45:15 ITERATION: Advancing config (0, 0, 1) to next budget 133.333333
01:45:15 ITERATION: Advancing config (0, 0, 2) to next budget 133.333333
01:45:15 ITERATION: Advancing config (0, 0, 6) to next budget 133.333333
01:45:15 ITERATION: Advancing config (0, 0, 7) to next budget 133.333333
01:45:15 ITERATION: Advancing config (0, 0, 9) to next budget 133.333333
01:45:15 ITERATION: Advancing config (0, 0, 11) to next budget 133.333333
01:45:15 ITERATION: Advancing config (0, 0, 16) to next budget 133.333333
01:45:15 ITERATION: Advancing config (0, 0, 19) to next budget 133.333333
01:45:15 ITERATION: Advancing config (0, 0, 22) to next budget 133.333333
01:45:15 HBMASTER: schedule new run for iteration 0
01:45:15 HBMASTER: trying submitting job (0, 0, 1) to dispatcher
01:45:15 HBMASTER: submitting job (0, 0, 1) to dispatcher
01:45:15 DISPATCHER: trying to submit job (0, 0, 1)
01:45:15 DISPATCHER: trying to notify the job_runner thread.
01:45:15 HBMASTER: job (0, 0, 1) submitted to dispatcher
01:45:15 DISPATCHER: Trying to submit another job.
01:45:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:45:15 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:45:15 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:45:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:45:15 WORKER: start processing job (0, 0, 1)
01:45:15 WORKER: args: ()
01:45:15 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 48, 'last_n_outputs': 19, 'lr': 0.0011134557328256532, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.08340347350818257}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:45:20 DISPATCHER: Starting worker discovery
01:45:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:45:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-433:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:46:20 DISPATCHER: Starting worker discovery
01:46:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:46:20 DISPATCHER: Finished worker discovery
01:47:20 DISPATCHER: Starting worker discovery
01:47:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:47:20 DISPATCHER: Finished worker discovery
01:47:39 WORKER: done with job (0, 0, 1), trying to register it.
01:47:39 WORKER: registered result for job (0, 0, 1) with dispatcher
01:47:39 DISPATCHER: job (0, 0, 1) finished
01:47:39 DISPATCHER: register_result: lock acquired
01:47:39 DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:47:39 job_id: (0, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 48, 'last_n_outputs': 19, 'lr': 0.0011134557328256532, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.08340347350818257}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.11196753937417107, 'info': {'data05': 0.11196753937417107, 'config': "{'batch_size': 64, 'hidden_dim': 48, 'last_n_outputs': 19, 'lr': 0.0011134557328256532, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.08340347350818257}"}}
exception: None

01:47:39 job_callback for (0, 0, 1) started
01:47:39 job_callback for (0, 0, 1) got condition
01:47:39 DISPATCHER: Trying to submit another job.
01:47:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:47:39 Only 1 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
01:47:39 HBMASTER: Trying to run another job!
01:47:39 job_callback for (0, 0, 1) finished
01:47:39 HBMASTER: schedule new run for iteration 0
01:47:39 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
01:47:39 HBMASTER: submitting job (0, 0, 2) to dispatcher
01:47:39 DISPATCHER: trying to submit job (0, 0, 2)
01:47:39 DISPATCHER: trying to notify the job_runner thread.
01:47:39 HBMASTER: job (0, 0, 2) submitted to dispatcher
01:47:39 DISPATCHER: Trying to submit another job.
01:47:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:47:39 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:47:39 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:47:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:47:39 WORKER: start processing job (0, 0, 2)
01:47:39 WORKER: args: ()
01:47:39 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 74, 'last_n_outputs': 38, 'lr': 0.0028126521638304107, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.013393726549415322}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-434:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:48:20 DISPATCHER: Starting worker discovery
01:48:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:48:20 DISPATCHER: Finished worker discovery
01:49:20 DISPATCHER: Starting worker discovery
01:49:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:49:20 DISPATCHER: Finished worker discovery
01:50:04 WORKER: done with job (0, 0, 2), trying to register it.
01:50:04 WORKER: registered result for job (0, 0, 2) with dispatcher
01:50:04 DISPATCHER: job (0, 0, 2) finished
01:50:04 DISPATCHER: register_result: lock acquired
01:50:04 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:50:04 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 74, 'last_n_outputs': 38, 'lr': 0.0028126521638304107, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.013393726549415322}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.007524921825966598, 'info': {'data05': 0.007524921825966598, 'config': "{'batch_size': 16, 'hidden_dim': 74, 'last_n_outputs': 38, 'lr': 0.0028126521638304107, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.013393726549415322}"}}
exception: None

01:50:04 job_callback for (0, 0, 2) started
01:50:04 DISPATCHER: Trying to submit another job.
01:50:04 job_callback for (0, 0, 2) got condition
01:50:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:50:04 Only 2 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
01:50:04 HBMASTER: Trying to run another job!
01:50:04 job_callback for (0, 0, 2) finished
01:50:04 HBMASTER: schedule new run for iteration 0
01:50:04 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
01:50:04 HBMASTER: submitting job (0, 0, 6) to dispatcher
01:50:04 DISPATCHER: trying to submit job (0, 0, 6)
01:50:04 DISPATCHER: trying to notify the job_runner thread.
01:50:04 HBMASTER: job (0, 0, 6) submitted to dispatcher
01:50:04 DISPATCHER: Trying to submit another job.
01:50:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:50:04 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:50:04 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:50:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:50:04 WORKER: start processing job (0, 0, 6)
01:50:04 WORKER: args: ()
01:50:04 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 21, 'last_n_outputs': 41, 'lr': 0.02757705430448898, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.01563252778780445}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-435:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:50:20 DISPATCHER: Starting worker discovery
01:50:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:50:20 DISPATCHER: Finished worker discovery
01:51:20 DISPATCHER: Starting worker discovery
01:51:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:51:20 DISPATCHER: Finished worker discovery
01:52:20 DISPATCHER: Starting worker discovery
01:52:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:52:20 DISPATCHER: Finished worker discovery
01:52:28 WORKER: done with job (0, 0, 6), trying to register it.
01:52:28 WORKER: registered result for job (0, 0, 6) with dispatcher
01:52:28 DISPATCHER: job (0, 0, 6) finished
01:52:28 DISPATCHER: register_result: lock acquired
01:52:28 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:52:28 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 21, 'last_n_outputs': 41, 'lr': 0.02757705430448898, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.01563252778780445}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.26879285771652195, 'info': {'data05': 0.26879285771652195, 'config': "{'batch_size': 128, 'hidden_dim': 21, 'last_n_outputs': 41, 'lr': 0.02757705430448898, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.01563252778780445}"}}
exception: None

01:52:28 job_callback for (0, 0, 6) started
01:52:28 job_callback for (0, 0, 6) got condition
01:52:28 DISPATCHER: Trying to submit another job.
01:52:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:52:28 Only 3 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
01:52:28 HBMASTER: Trying to run another job!
01:52:28 job_callback for (0, 0, 6) finished
01:52:28 HBMASTER: schedule new run for iteration 0
01:52:28 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
01:52:28 HBMASTER: submitting job (0, 0, 7) to dispatcher
01:52:28 DISPATCHER: trying to submit job (0, 0, 7)
01:52:28 DISPATCHER: trying to notify the job_runner thread.
01:52:28 HBMASTER: job (0, 0, 7) submitted to dispatcher
01:52:28 DISPATCHER: Trying to submit another job.
01:52:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:52:28 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:52:28 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:52:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:52:28 WORKER: start processing job (0, 0, 7)
01:52:28 WORKER: args: ()
01:52:28 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 94, 'last_n_outputs': 48, 'lr': 0.0011915608989555558, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.1209860054239423}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-436:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:53:20 DISPATCHER: Starting worker discovery
01:53:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:53:20 DISPATCHER: Finished worker discovery
01:54:20 DISPATCHER: Starting worker discovery
01:54:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:54:20 DISPATCHER: Finished worker discovery
01:54:53 WORKER: done with job (0, 0, 7), trying to register it.
01:54:53 WORKER: registered result for job (0, 0, 7) with dispatcher
01:54:53 DISPATCHER: job (0, 0, 7) finished
01:54:53 DISPATCHER: register_result: lock acquired
01:54:53 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:54:53 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 94, 'last_n_outputs': 48, 'lr': 0.0011915608989555558, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.1209860054239423}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.02303917646494015, 'info': {'data05': 0.02303917646494015, 'config': "{'batch_size': 64, 'hidden_dim': 94, 'last_n_outputs': 48, 'lr': 0.0011915608989555558, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.1209860054239423}"}}
exception: None

01:54:53 job_callback for (0, 0, 7) started
01:54:53 job_callback for (0, 0, 7) got condition
01:54:53 DISPATCHER: Trying to submit another job.
01:54:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:54:53 Only 4 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
01:54:53 HBMASTER: Trying to run another job!
01:54:53 job_callback for (0, 0, 7) finished
01:54:53 HBMASTER: schedule new run for iteration 0
01:54:53 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
01:54:53 HBMASTER: submitting job (0, 0, 9) to dispatcher
01:54:53 DISPATCHER: trying to submit job (0, 0, 9)
01:54:53 DISPATCHER: trying to notify the job_runner thread.
01:54:53 HBMASTER: job (0, 0, 9) submitted to dispatcher
01:54:53 DISPATCHER: Trying to submit another job.
01:54:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:54:53 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:54:53 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:54:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:54:53 WORKER: start processing job (0, 0, 9)
01:54:53 WORKER: args: ()
01:54:53 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 32, 'lr': 0.035910686129645104, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.08040275525170136}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-437:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:55:20 DISPATCHER: Starting worker discovery
01:55:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:55:20 DISPATCHER: Finished worker discovery
01:56:20 DISPATCHER: Starting worker discovery
01:56:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:56:20 DISPATCHER: Finished worker discovery
01:57:17 WORKER: done with job (0, 0, 9), trying to register it.
01:57:17 WORKER: registered result for job (0, 0, 9) with dispatcher
01:57:17 DISPATCHER: job (0, 0, 9) finished
01:57:17 DISPATCHER: register_result: lock acquired
01:57:17 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:57:17 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 32, 'lr': 0.035910686129645104, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.08040275525170136}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.28187992198652023, 'info': {'data05': 0.28187992198652023, 'config': "{'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 32, 'lr': 0.035910686129645104, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.08040275525170136}"}}
exception: None

01:57:17 job_callback for (0, 0, 9) started
01:57:17 job_callback for (0, 0, 9) got condition
01:57:17 DISPATCHER: Trying to submit another job.
01:57:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:57:17 Only 5 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
01:57:17 HBMASTER: Trying to run another job!
01:57:17 job_callback for (0, 0, 9) finished
01:57:17 HBMASTER: schedule new run for iteration 0
01:57:17 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
01:57:17 HBMASTER: submitting job (0, 0, 11) to dispatcher
01:57:17 DISPATCHER: trying to submit job (0, 0, 11)
01:57:17 DISPATCHER: trying to notify the job_runner thread.
01:57:17 HBMASTER: job (0, 0, 11) submitted to dispatcher
01:57:17 DISPATCHER: Trying to submit another job.
01:57:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:57:17 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:57:17 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:57:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:57:17 WORKER: start processing job (0, 0, 11)
01:57:17 WORKER: args: ()
01:57:17 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 97, 'last_n_outputs': 30, 'lr': 0.0076438886641304144, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.0123942346652229}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:57:20 DISPATCHER: Starting worker discovery
01:57:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:57:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-438:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:58:20 DISPATCHER: Starting worker discovery
01:58:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:58:20 DISPATCHER: Finished worker discovery
01:59:20 DISPATCHER: Starting worker discovery
01:59:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:59:20 DISPATCHER: Finished worker discovery
01:59:42 WORKER: done with job (0, 0, 11), trying to register it.
01:59:42 WORKER: registered result for job (0, 0, 11) with dispatcher
01:59:42 DISPATCHER: job (0, 0, 11) finished
01:59:42 DISPATCHER: register_result: lock acquired
01:59:42 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:59:42 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 97, 'last_n_outputs': 30, 'lr': 0.0076438886641304144, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.0123942346652229}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8639409685269381, 'info': {'data05': 0.8639409685269381, 'config': "{'batch_size': 64, 'hidden_dim': 97, 'last_n_outputs': 30, 'lr': 0.0076438886641304144, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.0123942346652229}"}}
exception: None

01:59:42 job_callback for (0, 0, 11) started
01:59:42 job_callback for (0, 0, 11) got condition
01:59:42 DISPATCHER: Trying to submit another job.
01:59:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:59:42 Only 6 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
01:59:42 HBMASTER: Trying to run another job!
01:59:42 job_callback for (0, 0, 11) finished
01:59:42 HBMASTER: schedule new run for iteration 0
01:59:42 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
01:59:42 HBMASTER: submitting job (0, 0, 16) to dispatcher
01:59:42 DISPATCHER: trying to submit job (0, 0, 16)
01:59:42 DISPATCHER: trying to notify the job_runner thread.
01:59:42 HBMASTER: job (0, 0, 16) submitted to dispatcher
01:59:42 DISPATCHER: Trying to submit another job.
01:59:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:59:42 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:59:42 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:59:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:59:42 WORKER: start processing job (0, 0, 16)
01:59:42 WORKER: args: ()
01:59:42 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 49, 'last_n_outputs': 37, 'lr': 0.04328159554473261, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.013224063781917789}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-439:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:00:20 DISPATCHER: Starting worker discovery
02:00:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:00:20 DISPATCHER: Finished worker discovery
02:01:20 DISPATCHER: Starting worker discovery
02:01:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:01:20 DISPATCHER: Finished worker discovery
02:02:07 WORKER: done with job (0, 0, 16), trying to register it.
02:02:07 WORKER: registered result for job (0, 0, 16) with dispatcher
02:02:07 DISPATCHER: job (0, 0, 16) finished
02:02:07 DISPATCHER: register_result: lock acquired
02:02:07 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
02:02:07 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 49, 'last_n_outputs': 37, 'lr': 0.04328159554473261, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.013224063781917789}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0019912974549048325, 'info': {'data05': 0.0019912974549048325, 'config': "{'batch_size': 32, 'hidden_dim': 49, 'last_n_outputs': 37, 'lr': 0.04328159554473261, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.013224063781917789}"}}
exception: None

02:02:07 job_callback for (0, 0, 16) started
02:02:07 DISPATCHER: Trying to submit another job.
02:02:07 job_callback for (0, 0, 16) got condition
02:02:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:02:07 Only 7 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
02:02:07 HBMASTER: Trying to run another job!
02:02:07 job_callback for (0, 0, 16) finished
02:02:07 HBMASTER: schedule new run for iteration 0
02:02:07 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
02:02:07 HBMASTER: submitting job (0, 0, 19) to dispatcher
02:02:07 DISPATCHER: trying to submit job (0, 0, 19)
02:02:07 DISPATCHER: trying to notify the job_runner thread.
02:02:07 HBMASTER: job (0, 0, 19) submitted to dispatcher
02:02:07 DISPATCHER: Trying to submit another job.
02:02:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:02:07 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:02:07 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:02:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:02:07 WORKER: start processing job (0, 0, 19)
02:02:07 WORKER: args: ()
02:02:07 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 4, 'lr': 0.007509952311010432, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.14982055175870432}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-440:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:02:20 DISPATCHER: Starting worker discovery
02:02:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:02:20 DISPATCHER: Finished worker discovery
02:03:20 DISPATCHER: Starting worker discovery
02:03:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:03:20 DISPATCHER: Finished worker discovery
02:04:20 DISPATCHER: Starting worker discovery
02:04:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:04:20 DISPATCHER: Finished worker discovery
02:04:31 WORKER: done with job (0, 0, 19), trying to register it.
02:04:31 WORKER: registered result for job (0, 0, 19) with dispatcher
02:04:31 DISPATCHER: job (0, 0, 19) finished
02:04:31 DISPATCHER: register_result: lock acquired
02:04:31 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
02:04:31 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 4, 'lr': 0.007509952311010432, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.14982055175870432}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.09544294137990078, 'info': {'data05': 0.09544294137990078, 'config': "{'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 4, 'lr': 0.007509952311010432, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.14982055175870432}"}}
exception: None

02:04:31 job_callback for (0, 0, 19) started
02:04:31 DISPATCHER: Trying to submit another job.
02:04:31 job_callback for (0, 0, 19) got condition
02:04:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:04:31 Only 8 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
02:04:31 HBMASTER: Trying to run another job!
02:04:31 job_callback for (0, 0, 19) finished
02:04:31 HBMASTER: schedule new run for iteration 0
02:04:31 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
02:04:31 HBMASTER: submitting job (0, 0, 22) to dispatcher
02:04:31 DISPATCHER: trying to submit job (0, 0, 22)
02:04:31 DISPATCHER: trying to notify the job_runner thread.
02:04:31 HBMASTER: job (0, 0, 22) submitted to dispatcher
02:04:31 DISPATCHER: Trying to submit another job.
02:04:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:04:31 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:04:31 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:04:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:04:31 WORKER: start processing job (0, 0, 22)
02:04:31 WORKER: args: ()
02:04:31 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 35, 'last_n_outputs': 41, 'lr': 0.06469329217860041, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.010441932194867103}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-441:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:05:20 DISPATCHER: Starting worker discovery
02:05:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:05:20 DISPATCHER: Finished worker discovery
02:06:20 DISPATCHER: Starting worker discovery
02:06:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:06:20 DISPATCHER: Finished worker discovery
02:06:56 WORKER: done with job (0, 0, 22), trying to register it.
02:06:56 WORKER: registered result for job (0, 0, 22) with dispatcher
02:06:56 DISPATCHER: job (0, 0, 22) finished
02:06:56 DISPATCHER: register_result: lock acquired
02:06:56 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
02:06:56 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 35, 'last_n_outputs': 41, 'lr': 0.06469329217860041, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.010441932194867103}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.01574496022341692, 'info': {'data05': 0.01574496022341692, 'config': "{'batch_size': 128, 'hidden_dim': 35, 'last_n_outputs': 41, 'lr': 0.06469329217860041, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.010441932194867103}"}}
exception: None

02:06:56 job_callback for (0, 0, 22) started
02:06:56 job_callback for (0, 0, 22) got condition
02:06:56 DISPATCHER: Trying to submit another job.
02:06:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:06:56 HBMASTER: Trying to run another job!
02:06:56 job_callback for (0, 0, 22) finished
02:06:56 ITERATION: Advancing config (0, 0, 6) to next budget 400.000000
02:06:56 ITERATION: Advancing config (0, 0, 9) to next budget 400.000000
02:06:56 ITERATION: Advancing config (0, 0, 11) to next budget 400.000000
02:06:56 HBMASTER: schedule new run for iteration 0
02:06:56 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
02:06:56 HBMASTER: submitting job (0, 0, 6) to dispatcher
02:06:56 DISPATCHER: trying to submit job (0, 0, 6)
02:06:56 DISPATCHER: trying to notify the job_runner thread.
02:06:56 HBMASTER: job (0, 0, 6) submitted to dispatcher
02:06:56 DISPATCHER: Trying to submit another job.
02:06:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:06:56 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:06:56 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:06:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:06:56 WORKER: start processing job (0, 0, 6)
02:06:56 WORKER: args: ()
02:06:56 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 21, 'last_n_outputs': 41, 'lr': 0.02757705430448898, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.01563252778780445}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-442:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:07:20 DISPATCHER: Starting worker discovery
02:07:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:07:20 DISPATCHER: Finished worker discovery
02:08:20 DISPATCHER: Starting worker discovery
02:08:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:08:20 DISPATCHER: Finished worker discovery
02:09:20 DISPATCHER: Starting worker discovery
02:09:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:09:20 DISPATCHER: Finished worker discovery
02:10:20 DISPATCHER: Starting worker discovery
02:10:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:10:20 DISPATCHER: Finished worker discovery
02:11:20 DISPATCHER: Starting worker discovery
02:11:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:11:20 DISPATCHER: Finished worker discovery
02:12:20 DISPATCHER: Starting worker discovery
02:12:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:12:20 DISPATCHER: Finished worker discovery
02:13:20 DISPATCHER: Starting worker discovery
02:13:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:13:20 DISPATCHER: Finished worker discovery
02:13:46 WORKER: done with job (0, 0, 6), trying to register it.
02:13:46 WORKER: registered result for job (0, 0, 6) with dispatcher
02:13:46 DISPATCHER: job (0, 0, 6) finished
02:13:46 DISPATCHER: register_result: lock acquired
02:13:46 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
02:13:46 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 21, 'last_n_outputs': 41, 'lr': 0.02757705430448898, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.01563252778780445}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.19496850201589114, 'info': {'data05': 0.19496850201589114, 'config': "{'batch_size': 128, 'hidden_dim': 21, 'last_n_outputs': 41, 'lr': 0.02757705430448898, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.01563252778780445}"}}
exception: None

02:13:46 job_callback for (0, 0, 6) started
02:13:46 DISPATCHER: Trying to submit another job.
02:13:46 job_callback for (0, 0, 6) got condition
02:13:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:13:46 Only 1 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
02:13:46 HBMASTER: Trying to run another job!
02:13:46 job_callback for (0, 0, 6) finished
02:13:46 HBMASTER: schedule new run for iteration 0
02:13:46 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
02:13:46 HBMASTER: submitting job (0, 0, 9) to dispatcher
02:13:46 DISPATCHER: trying to submit job (0, 0, 9)
02:13:46 DISPATCHER: trying to notify the job_runner thread.
02:13:46 HBMASTER: job (0, 0, 9) submitted to dispatcher
02:13:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:13:46 DISPATCHER: Trying to submit another job.
02:13:46 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:13:46 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:13:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:13:46 WORKER: start processing job (0, 0, 9)
02:13:46 WORKER: args: ()
02:13:46 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 32, 'lr': 0.035910686129645104, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.08040275525170136}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-443:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:14:20 DISPATCHER: Starting worker discovery
02:14:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:14:20 DISPATCHER: Finished worker discovery
02:15:20 DISPATCHER: Starting worker discovery
02:15:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:15:20 DISPATCHER: Finished worker discovery
02:16:20 DISPATCHER: Starting worker discovery
02:16:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:16:20 DISPATCHER: Finished worker discovery
02:17:20 DISPATCHER: Starting worker discovery
02:17:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:17:20 DISPATCHER: Finished worker discovery
02:18:20 DISPATCHER: Starting worker discovery
02:18:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:18:20 DISPATCHER: Finished worker discovery
02:19:20 DISPATCHER: Starting worker discovery
02:19:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:19:20 DISPATCHER: Finished worker discovery
02:20:20 DISPATCHER: Starting worker discovery
02:20:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:20:20 DISPATCHER: Finished worker discovery
02:20:37 WORKER: done with job (0, 0, 9), trying to register it.
02:20:37 WORKER: registered result for job (0, 0, 9) with dispatcher
02:20:37 DISPATCHER: job (0, 0, 9) finished
02:20:37 DISPATCHER: register_result: lock acquired
02:20:37 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
02:20:37 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 32, 'lr': 0.035910686129645104, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.08040275525170136}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.2031216539550013, 'info': {'data05': 0.2031216539550013, 'config': "{'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 32, 'lr': 0.035910686129645104, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.08040275525170136}"}}
exception: None

02:20:37 job_callback for (0, 0, 9) started
02:20:37 job_callback for (0, 0, 9) got condition
02:20:37 DISPATCHER: Trying to submit another job.
02:20:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:20:37 Only 2 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
02:20:37 HBMASTER: Trying to run another job!
02:20:37 job_callback for (0, 0, 9) finished
02:20:37 HBMASTER: schedule new run for iteration 0
02:20:37 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
02:20:37 HBMASTER: submitting job (0, 0, 11) to dispatcher
02:20:37 DISPATCHER: trying to submit job (0, 0, 11)
02:20:37 DISPATCHER: trying to notify the job_runner thread.
02:20:37 HBMASTER: job (0, 0, 11) submitted to dispatcher
02:20:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:20:37 DISPATCHER: Trying to submit another job.
02:20:37 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:20:37 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:20:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:20:37 WORKER: start processing job (0, 0, 11)
02:20:37 WORKER: args: ()
02:20:37 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 97, 'last_n_outputs': 30, 'lr': 0.0076438886641304144, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.0123942346652229}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-444:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:21:20 DISPATCHER: Starting worker discovery
02:21:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:21:20 DISPATCHER: Finished worker discovery
02:22:20 DISPATCHER: Starting worker discovery
02:22:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:22:20 DISPATCHER: Finished worker discovery
02:23:20 DISPATCHER: Starting worker discovery
02:23:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:23:20 DISPATCHER: Finished worker discovery
02:24:20 DISPATCHER: Starting worker discovery
02:24:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:24:20 DISPATCHER: Finished worker discovery
02:25:20 DISPATCHER: Starting worker discovery
02:25:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:25:20 DISPATCHER: Finished worker discovery
02:26:20 DISPATCHER: Starting worker discovery
02:26:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:26:20 DISPATCHER: Finished worker discovery
02:27:20 DISPATCHER: Starting worker discovery
02:27:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:27:20 DISPATCHER: Finished worker discovery
02:27:29 WORKER: done with job (0, 0, 11), trying to register it.
02:27:29 WORKER: registered result for job (0, 0, 11) with dispatcher
02:27:29 DISPATCHER: job (0, 0, 11) finished
02:27:29 DISPATCHER: register_result: lock acquired
02:27:29 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
02:27:29 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 97, 'last_n_outputs': 30, 'lr': 0.0076438886641304144, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.0123942346652229}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8570510350049457, 'info': {'data05': 0.8570510350049457, 'config': "{'batch_size': 64, 'hidden_dim': 97, 'last_n_outputs': 30, 'lr': 0.0076438886641304144, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.0123942346652229}"}}
exception: None

02:27:29 job_callback for (0, 0, 11) started
02:27:29 job_callback for (0, 0, 11) got condition
02:27:29 DISPATCHER: Trying to submit another job.
02:27:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:27:29 Only 3 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
02:27:29 HBMASTER: Trying to run another job!
02:27:29 job_callback for (0, 0, 11) finished
02:27:29 ITERATION: Advancing config (0, 0, 11) to next budget 1200.000000
02:27:29 HBMASTER: schedule new run for iteration 0
02:27:29 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
02:27:29 HBMASTER: submitting job (0, 0, 11) to dispatcher
02:27:29 DISPATCHER: trying to submit job (0, 0, 11)
02:27:29 DISPATCHER: trying to notify the job_runner thread.
02:27:29 HBMASTER: job (0, 0, 11) submitted to dispatcher
02:27:29 DISPATCHER: Trying to submit another job.
02:27:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:27:29 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:27:29 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:27:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:27:29 WORKER: start processing job (0, 0, 11)
02:27:29 WORKER: args: ()
02:27:29 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 97, 'last_n_outputs': 30, 'lr': 0.0076438886641304144, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.0123942346652229}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-445:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:28:20 DISPATCHER: Starting worker discovery
02:28:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:28:20 DISPATCHER: Finished worker discovery
02:29:20 DISPATCHER: Starting worker discovery
02:29:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:29:20 DISPATCHER: Finished worker discovery
02:30:20 DISPATCHER: Starting worker discovery
02:30:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:30:20 DISPATCHER: Finished worker discovery
02:31:20 DISPATCHER: Starting worker discovery
02:31:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:31:20 DISPATCHER: Finished worker discovery
02:32:20 DISPATCHER: Starting worker discovery
02:32:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:32:20 DISPATCHER: Finished worker discovery
02:33:20 DISPATCHER: Starting worker discovery
02:33:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:33:20 DISPATCHER: Finished worker discovery
02:34:20 DISPATCHER: Starting worker discovery
02:34:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:34:20 DISPATCHER: Finished worker discovery
02:35:20 DISPATCHER: Starting worker discovery
02:35:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:35:20 DISPATCHER: Finished worker discovery
02:36:20 DISPATCHER: Starting worker discovery
02:36:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:36:20 DISPATCHER: Finished worker discovery
02:37:20 DISPATCHER: Starting worker discovery
02:37:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:37:20 DISPATCHER: Finished worker discovery
02:38:20 DISPATCHER: Starting worker discovery
02:38:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:38:20 DISPATCHER: Finished worker discovery
02:39:20 DISPATCHER: Starting worker discovery
02:39:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:39:20 DISPATCHER: Finished worker discovery
02:40:20 DISPATCHER: Starting worker discovery
02:40:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:40:20 DISPATCHER: Finished worker discovery
02:41:20 DISPATCHER: Starting worker discovery
02:41:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:41:20 DISPATCHER: Finished worker discovery
02:42:20 DISPATCHER: Starting worker discovery
02:42:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:42:20 DISPATCHER: Finished worker discovery
02:43:20 DISPATCHER: Starting worker discovery
02:43:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:43:20 DISPATCHER: Finished worker discovery
02:44:20 DISPATCHER: Starting worker discovery
02:44:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:44:20 DISPATCHER: Finished worker discovery
02:45:20 DISPATCHER: Starting worker discovery
02:45:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:45:20 DISPATCHER: Finished worker discovery
02:46:20 DISPATCHER: Starting worker discovery
02:46:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:46:20 DISPATCHER: Finished worker discovery
02:47:20 DISPATCHER: Starting worker discovery
02:47:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:47:20 DISPATCHER: Finished worker discovery
02:47:39 WORKER: done with job (0, 0, 11), trying to register it.
02:47:39 WORKER: registered result for job (0, 0, 11) with dispatcher
02:47:39 DISPATCHER: job (0, 0, 11) finished
02:47:39 DISPATCHER: register_result: lock acquired
02:47:39 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
02:47:39 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 97, 'last_n_outputs': 30, 'lr': 0.0076438886641304144, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.0123942346652229}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.9221862808028161, 'info': {'data05': 0.9221862808028161, 'config': "{'batch_size': 64, 'hidden_dim': 97, 'last_n_outputs': 30, 'lr': 0.0076438886641304144, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.0123942346652229}"}}
exception: None

02:47:39 job_callback for (0, 0, 11) started
02:47:39 DISPATCHER: Trying to submit another job.
02:47:39 job_callback for (0, 0, 11) got condition
02:47:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:47:39 Only 1 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
02:47:39 HBMASTER: Trying to run another job!
02:47:39 job_callback for (0, 0, 11) finished
02:47:39 start sampling a new configuration.
02:47:39 best_vector: [3, 0.6637907470708049, 0.9458374932012797, 0.9285119644017664, 0.1294127758901897, 1, 0.9137410467431568, 0.026582277840426646], 0.020745414724722407, 0.040461504076629885, 0.0008393906824557334
02:47:39 done sampling a new configuration.
02:47:39 HBMASTER: schedule new run for iteration 1
02:47:39 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
02:47:39 HBMASTER: submitting job (1, 0, 0) to dispatcher
02:47:39 DISPATCHER: trying to submit job (1, 0, 0)
02:47:39 DISPATCHER: trying to notify the job_runner thread.
02:47:39 HBMASTER: job (1, 0, 0) submitted to dispatcher
02:47:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:47:39 DISPATCHER: Trying to submit another job.
02:47:39 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:47:39 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:47:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:47:39 WORKER: start processing job (1, 0, 0)
02:47:39 WORKER: args: ()
02:47:39 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 73, 'last_n_outputs': 48, 'lr': 0.07194886193720451, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.010828899940274316}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-446:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:48:20 DISPATCHER: Starting worker discovery
02:48:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:48:20 DISPATCHER: Finished worker discovery
02:49:20 DISPATCHER: Starting worker discovery
02:49:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:49:20 DISPATCHER: Finished worker discovery
02:50:04 WORKER: done with job (1, 0, 0), trying to register it.
02:50:04 WORKER: registered result for job (1, 0, 0) with dispatcher
02:50:04 DISPATCHER: job (1, 0, 0) finished
02:50:04 DISPATCHER: register_result: lock acquired
02:50:04 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
02:50:04 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 73, 'last_n_outputs': 48, 'lr': 0.07194886193720451, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.010828899940274316}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.781619288822661, 'info': {'data05': 0.781619288822661, 'config': "{'batch_size': 128, 'hidden_dim': 73, 'last_n_outputs': 48, 'lr': 0.07194886193720451, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.010828899940274316}"}}
exception: None

02:50:04 job_callback for (1, 0, 0) started
02:50:04 DISPATCHER: Trying to submit another job.
02:50:04 job_callback for (1, 0, 0) got condition
02:50:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:50:04 HBMASTER: Trying to run another job!
02:50:04 job_callback for (1, 0, 0) finished
02:50:04 start sampling a new configuration.
02:50:04 best_vector: [1, 0.4890123638842862, 0.90380830444113, 0.30977579552579654, 0.25848398760011415, 0, 0.1323327645534408, 0.11584381214611572], 0.04913563904831176, 0.14883717244419317, 0.0073132095821892085
02:50:04 done sampling a new configuration.
02:50:04 HBMASTER: schedule new run for iteration 1
02:50:04 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
02:50:04 HBMASTER: submitting job (1, 0, 1) to dispatcher
02:50:04 DISPATCHER: trying to submit job (1, 0, 1)
02:50:04 DISPATCHER: trying to notify the job_runner thread.
02:50:04 HBMASTER: job (1, 0, 1) submitted to dispatcher
02:50:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:50:04 DISPATCHER: Trying to submit another job.
02:50:04 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:50:04 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:50:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:50:04 WORKER: start processing job (1, 0, 1)
02:50:04 WORKER: args: ()
02:50:04 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 59, 'last_n_outputs': 46, 'lr': 0.00416439188058429, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.01414869140685371}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-447:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:50:20 DISPATCHER: Starting worker discovery
02:50:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:50:20 DISPATCHER: Finished worker discovery
02:51:20 DISPATCHER: Starting worker discovery
02:51:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:51:20 DISPATCHER: Finished worker discovery
02:52:20 DISPATCHER: Starting worker discovery
02:52:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:52:20 DISPATCHER: Finished worker discovery
02:52:28 WORKER: done with job (1, 0, 1), trying to register it.
02:52:28 WORKER: registered result for job (1, 0, 1) with dispatcher
02:52:28 DISPATCHER: job (1, 0, 1) finished
02:52:28 DISPATCHER: register_result: lock acquired
02:52:28 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
02:52:28 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 59, 'last_n_outputs': 46, 'lr': 0.00416439188058429, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.01414869140685371}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3875479991287042, 'info': {'data05': 0.3875479991287042, 'config': "{'batch_size': 32, 'hidden_dim': 59, 'last_n_outputs': 46, 'lr': 0.00416439188058429, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.01414869140685371}"}}
exception: None

02:52:28 job_callback for (1, 0, 1) started
02:52:28 DISPATCHER: Trying to submit another job.
02:52:28 job_callback for (1, 0, 1) got condition
02:52:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:52:28 HBMASTER: Trying to run another job!
02:52:28 job_callback for (1, 0, 1) finished
02:52:28 start sampling a new configuration.
02:52:28 done sampling a new configuration.
02:52:28 HBMASTER: schedule new run for iteration 1
02:52:28 HBMASTER: trying submitting job (1, 0, 2) to dispatcher
02:52:28 HBMASTER: submitting job (1, 0, 2) to dispatcher
02:52:28 DISPATCHER: trying to submit job (1, 0, 2)
02:52:28 DISPATCHER: trying to notify the job_runner thread.
02:52:28 HBMASTER: job (1, 0, 2) submitted to dispatcher
02:52:28 DISPATCHER: Trying to submit another job.
02:52:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:52:28 DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:52:28 DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:52:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:52:28 WORKER: start processing job (1, 0, 2)
02:52:28 WORKER: args: ()
02:52:28 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 89, 'last_n_outputs': 44, 'lr': 0.001031015076276225, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.024620234329705854}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-448:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:53:20 DISPATCHER: Starting worker discovery
02:53:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:53:20 DISPATCHER: Finished worker discovery
02:54:20 DISPATCHER: Starting worker discovery
02:54:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:54:20 DISPATCHER: Finished worker discovery
02:54:52 WORKER: done with job (1, 0, 2), trying to register it.
02:54:52 WORKER: registered result for job (1, 0, 2) with dispatcher
02:54:52 DISPATCHER: job (1, 0, 2) finished
02:54:52 DISPATCHER: register_result: lock acquired
02:54:52 DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
02:54:52 job_id: (1, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 89, 'last_n_outputs': 44, 'lr': 0.001031015076276225, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.024620234329705854}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': 0.021976417981605777, 'info': {'data05': -0.021976417981605777, 'config': "{'batch_size': 128, 'hidden_dim': 89, 'last_n_outputs': 44, 'lr': 0.001031015076276225, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.024620234329705854}"}}
exception: None

02:54:52 job_callback for (1, 0, 2) started
02:54:52 job_callback for (1, 0, 2) got condition
02:54:52 DISPATCHER: Trying to submit another job.
02:54:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:54:52 HBMASTER: Trying to run another job!
02:54:52 job_callback for (1, 0, 2) finished
02:54:52 start sampling a new configuration.
02:54:52 best_vector: [3, 0.7706903653722429, 0.3305496549450033, 0.7107271952291123, 0.1228730263507326, 1, 0.2306182352658812, 0.36813955566538387], 0.14696833424521305, 0.08513847768930687, 0.012512660246170666
02:54:52 done sampling a new configuration.
02:54:52 HBMASTER: schedule new run for iteration 1
02:54:52 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
02:54:52 HBMASTER: submitting job (1, 0, 3) to dispatcher
02:54:52 DISPATCHER: trying to submit job (1, 0, 3)
02:54:52 DISPATCHER: trying to notify the job_runner thread.
02:54:52 HBMASTER: job (1, 0, 3) submitted to dispatcher
02:54:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:54:52 DISPATCHER: Trying to submit another job.
02:54:52 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:54:52 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:54:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:54:52 WORKER: start processing job (1, 0, 3)
02:54:52 WORKER: args: ()
02:54:52 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 82, 'last_n_outputs': 17, 'lr': 0.026390911508523185, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.03012732722390003}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-449:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:55:20 DISPATCHER: Starting worker discovery
02:55:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:55:20 DISPATCHER: Finished worker discovery
02:56:20 DISPATCHER: Starting worker discovery
02:56:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:56:20 DISPATCHER: Finished worker discovery
02:57:17 WORKER: done with job (1, 0, 3), trying to register it.
02:57:17 WORKER: registered result for job (1, 0, 3) with dispatcher
02:57:17 DISPATCHER: job (1, 0, 3) finished
02:57:17 DISPATCHER: register_result: lock acquired
02:57:17 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
02:57:17 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 82, 'last_n_outputs': 17, 'lr': 0.026390911508523185, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.03012732722390003}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1746181754465075, 'info': {'data05': 0.1746181754465075, 'config': "{'batch_size': 128, 'hidden_dim': 82, 'last_n_outputs': 17, 'lr': 0.026390911508523185, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.03012732722390003}"}}
exception: None

02:57:17 job_callback for (1, 0, 3) started
02:57:17 DISPATCHER: Trying to submit another job.
02:57:17 job_callback for (1, 0, 3) got condition
02:57:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:57:17 HBMASTER: Trying to run another job!
02:57:17 job_callback for (1, 0, 3) finished
02:57:17 start sampling a new configuration.
02:57:17 done sampling a new configuration.
02:57:17 HBMASTER: schedule new run for iteration 1
02:57:17 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
02:57:17 HBMASTER: submitting job (1, 0, 4) to dispatcher
02:57:17 DISPATCHER: trying to submit job (1, 0, 4)
02:57:17 DISPATCHER: trying to notify the job_runner thread.
02:57:17 HBMASTER: job (1, 0, 4) submitted to dispatcher
02:57:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:57:17 DISPATCHER: Trying to submit another job.
02:57:17 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:57:17 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:57:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:57:17 WORKER: start processing job (1, 0, 4)
02:57:17 WORKER: args: ()
02:57:17 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 91, 'last_n_outputs': 9, 'lr': 0.0011265284520313797, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.034874384101235154}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:57:20 DISPATCHER: Starting worker discovery
02:57:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:57:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-450:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:58:20 DISPATCHER: Starting worker discovery
02:58:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:58:20 DISPATCHER: Finished worker discovery
02:59:20 DISPATCHER: Starting worker discovery
02:59:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:59:20 DISPATCHER: Finished worker discovery
02:59:41 WORKER: done with job (1, 0, 4), trying to register it.
02:59:41 WORKER: registered result for job (1, 0, 4) with dispatcher
02:59:41 DISPATCHER: job (1, 0, 4) finished
02:59:41 DISPATCHER: register_result: lock acquired
02:59:41 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
02:59:41 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 91, 'last_n_outputs': 9, 'lr': 0.0011265284520313797, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.034874384101235154}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.35618970579783105, 'info': {'data05': 0.35618970579783105, 'config': "{'batch_size': 16, 'hidden_dim': 91, 'last_n_outputs': 9, 'lr': 0.0011265284520313797, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.034874384101235154}"}}
exception: None

02:59:41 job_callback for (1, 0, 4) started
02:59:41 DISPATCHER: Trying to submit another job.
02:59:41 job_callback for (1, 0, 4) got condition
02:59:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:59:41 HBMASTER: Trying to run another job!
02:59:41 job_callback for (1, 0, 4) finished
02:59:41 start sampling a new configuration.
02:59:41 done sampling a new configuration.
02:59:41 HBMASTER: schedule new run for iteration 1
02:59:41 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
02:59:41 HBMASTER: submitting job (1, 0, 5) to dispatcher
02:59:41 DISPATCHER: trying to submit job (1, 0, 5)
02:59:41 DISPATCHER: trying to notify the job_runner thread.
02:59:41 HBMASTER: job (1, 0, 5) submitted to dispatcher
02:59:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:59:41 DISPATCHER: Trying to submit another job.
02:59:41 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:59:41 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:59:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:59:41 WORKER: start processing job (1, 0, 5)
02:59:41 WORKER: args: ()
02:59:41 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 34, 'last_n_outputs': 28, 'lr': 0.05371216768873216, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.11205875115407274}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-451:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:00:20 DISPATCHER: Starting worker discovery
03:00:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:00:20 DISPATCHER: Finished worker discovery
03:01:20 DISPATCHER: Starting worker discovery
03:01:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:01:20 DISPATCHER: Finished worker discovery
03:02:04 WORKER: done with job (1, 0, 5), trying to register it.
03:02:04 WORKER: registered result for job (1, 0, 5) with dispatcher
03:02:04 DISPATCHER: job (1, 0, 5) finished
03:02:04 DISPATCHER: register_result: lock acquired
03:02:04 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
03:02:04 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 34, 'last_n_outputs': 28, 'lr': 0.05371216768873216, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.11205875115407274}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.30826414458914175, 'info': {'data05': 0.30826414458914175, 'config': "{'batch_size': 128, 'hidden_dim': 34, 'last_n_outputs': 28, 'lr': 0.05371216768873216, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.11205875115407274}"}}
exception: None

03:02:04 job_callback for (1, 0, 5) started
03:02:04 job_callback for (1, 0, 5) got condition
03:02:04 DISPATCHER: Trying to submit another job.
03:02:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:02:04 HBMASTER: Trying to run another job!
03:02:04 job_callback for (1, 0, 5) finished
03:02:04 start sampling a new configuration.
03:02:04 best_vector: [3, 0.983734897479213, 0.01567897901234061, 0.5579640624346891, 0.1627244662336999, 1, 0.009245060442283293, 0.6971673749965007], 0.025268248579008105, 0.04235741079949931, 0.0010702975852449111
03:02:04 done sampling a new configuration.
03:02:04 HBMASTER: schedule new run for iteration 1
03:02:04 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
03:02:04 HBMASTER: submitting job (1, 0, 6) to dispatcher
03:02:04 DISPATCHER: trying to submit job (1, 0, 6)
03:02:04 DISPATCHER: trying to notify the job_runner thread.
03:02:04 HBMASTER: job (1, 0, 6) submitted to dispatcher
03:02:04 DISPATCHER: Trying to submit another job.
03:02:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:02:04 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464
03:02:04 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
03:02:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:02:04 WORKER: start processing job (1, 0, 6)
03:02:04 WORKER: args: ()
03:02:04 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 99, 'last_n_outputs': 1, 'lr': 0.013059547365597298, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.08073013279555488}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-452:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:02:20 DISPATCHER: Starting worker discovery
03:02:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:02:20 DISPATCHER: Finished worker discovery
03:03:20 DISPATCHER: Starting worker discovery
03:03:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:03:20 DISPATCHER: Finished worker discovery
03:04:20 DISPATCHER: Starting worker discovery
03:04:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:04:20 DISPATCHER: Finished worker discovery
03:04:28 WORKER: done with job (1, 0, 6), trying to register it.
03:04:28 WORKER: registered result for job (1, 0, 6) with dispatcher
03:04:28 DISPATCHER: job (1, 0, 6) finished
03:04:28 DISPATCHER: register_result: lock acquired
03:04:28 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
03:04:28 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 99, 'last_n_outputs': 1, 'lr': 0.013059547365597298, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.08073013279555488}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.003511751356205935, 'info': {'data05': 0.003511751356205935, 'config': "{'batch_size': 128, 'hidden_dim': 99, 'last_n_outputs': 1, 'lr': 0.013059547365597298, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.08073013279555488}"}}
exception: None

03:04:28 job_callback for (1, 0, 6) started
03:04:28 DISPATCHER: Trying to submit another job.
03:04:28 job_callback for (1, 0, 6) got condition
03:04:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:04:28 HBMASTER: Trying to run another job!
03:04:28 job_callback for (1, 0, 6) finished
03:04:28 start sampling a new configuration.
03:04:28 done sampling a new configuration.
03:04:28 HBMASTER: schedule new run for iteration 1
03:04:28 HBMASTER: trying submitting job (1, 0, 7) to dispatcher
03:04:28 HBMASTER: submitting job (1, 0, 7) to dispatcher
03:04:28 DISPATCHER: trying to submit job (1, 0, 7)
03:04:28 DISPATCHER: trying to notify the job_runner thread.
03:04:28 HBMASTER: job (1, 0, 7) submitted to dispatcher
03:04:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:04:28 DISPATCHER: Trying to submit another job.
03:04:28 DISPATCHER: starting job (1, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464
03:04:28 DISPATCHER: job (1, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
03:04:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:04:28 WORKER: start processing job (1, 0, 7)
03:04:28 WORKER: args: ()
03:04:28 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 62, 'last_n_outputs': 3, 'lr': 0.006340952774912213, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.01629478726816986}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-453:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:05:20 DISPATCHER: Starting worker discovery
03:05:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:05:20 DISPATCHER: Finished worker discovery
03:06:20 DISPATCHER: Starting worker discovery
03:06:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:06:20 DISPATCHER: Finished worker discovery
03:06:52 WORKER: done with job (1, 0, 7), trying to register it.
03:06:52 WORKER: registered result for job (1, 0, 7) with dispatcher
03:06:52 DISPATCHER: job (1, 0, 7) finished
03:06:52 DISPATCHER: register_result: lock acquired
03:06:52 DISPATCHER: job (1, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
03:06:52 job_id: (1, 0, 7)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 62, 'last_n_outputs': 3, 'lr': 0.006340952774912213, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.01629478726816986}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 62, 'last_n_outputs': 3, 'lr': 0.006340952774912213, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.01629478726816986}"}}
exception: None

03:06:52 job_callback for (1, 0, 7) started
03:06:52 DISPATCHER: Trying to submit another job.
03:06:52 job_callback for (1, 0, 7) got condition
03:06:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:06:52 HBMASTER: Trying to run another job!
03:06:52 job_callback for (1, 0, 7) finished
03:06:52 start sampling a new configuration.
03:06:52 best_vector: [2, 0.06730836984376526, 0.8334706017150577, 0.45713664973350365, 0.06461445114063233, 0, 0.11617044202541937, 0.05260000892057737], 0.06331311104737287, 0.05133200117449829, 0.0032499886906448856
03:06:52 done sampling a new configuration.
03:06:52 HBMASTER: schedule new run for iteration 1
03:06:52 HBMASTER: trying submitting job (1, 0, 8) to dispatcher
03:06:52 HBMASTER: submitting job (1, 0, 8) to dispatcher
03:06:52 DISPATCHER: trying to submit job (1, 0, 8)
03:06:52 DISPATCHER: trying to notify the job_runner thread.
03:06:52 HBMASTER: job (1, 0, 8) submitted to dispatcher
03:06:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:06:52 DISPATCHER: Trying to submit another job.
03:06:52 DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464
03:06:52 DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
03:06:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:06:52 WORKER: start processing job (1, 0, 8)
03:06:52 WORKER: args: ()
03:06:52 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 25, 'last_n_outputs': 42, 'lr': 0.00820867950152333, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.011706691920407037}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-454:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:07:20 DISPATCHER: Starting worker discovery
03:07:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:07:20 DISPATCHER: Finished worker discovery
03:08:20 DISPATCHER: Starting worker discovery
03:08:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:08:20 DISPATCHER: Finished worker discovery
03:09:16 WORKER: done with job (1, 0, 8), trying to register it.
03:09:16 WORKER: registered result for job (1, 0, 8) with dispatcher
03:09:16 DISPATCHER: job (1, 0, 8) finished
03:09:16 DISPATCHER: register_result: lock acquired
03:09:16 DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
03:09:16 job_id: (1, 0, 8)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 25, 'last_n_outputs': 42, 'lr': 0.00820867950152333, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.011706691920407037}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4013128496127215, 'info': {'data05': 0.4013128496127215, 'config': "{'batch_size': 64, 'hidden_dim': 25, 'last_n_outputs': 42, 'lr': 0.00820867950152333, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.011706691920407037}"}}
exception: None

03:09:16 job_callback for (1, 0, 8) started
03:09:16 DISPATCHER: Trying to submit another job.
03:09:16 job_callback for (1, 0, 8) got condition
03:09:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:09:16 done building a new model for budget 133.333333 based on 9/15 split
Best loss for this budget:-0.863941





03:09:16 HBMASTER: Trying to run another job!
03:09:16 job_callback for (1, 0, 8) finished
03:09:16 ITERATION: Advancing config (1, 0, 0) to next budget 400.000000
03:09:16 ITERATION: Advancing config (1, 0, 1) to next budget 400.000000
03:09:16 ITERATION: Advancing config (1, 0, 8) to next budget 400.000000
03:09:16 HBMASTER: schedule new run for iteration 1
03:09:16 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
03:09:16 HBMASTER: submitting job (1, 0, 0) to dispatcher
03:09:16 DISPATCHER: trying to submit job (1, 0, 0)
03:09:16 DISPATCHER: trying to notify the job_runner thread.
03:09:16 HBMASTER: job (1, 0, 0) submitted to dispatcher
03:09:16 DISPATCHER: Trying to submit another job.
03:09:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:09:16 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
03:09:16 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
03:09:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:09:16 WORKER: start processing job (1, 0, 0)
03:09:16 WORKER: args: ()
03:09:16 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 73, 'last_n_outputs': 48, 'lr': 0.07194886193720451, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.010828899940274316}, 'budget': 400.0, 'working_directory': '.'}
03:09:20 DISPATCHER: Starting worker discovery
03:09:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:09:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-455:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:10:20 DISPATCHER: Starting worker discovery
03:10:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:10:20 DISPATCHER: Finished worker discovery
03:11:20 DISPATCHER: Starting worker discovery
03:11:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:11:20 DISPATCHER: Finished worker discovery
03:12:20 DISPATCHER: Starting worker discovery
03:12:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:12:20 DISPATCHER: Finished worker discovery
03:13:20 DISPATCHER: Starting worker discovery
03:13:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:13:20 DISPATCHER: Finished worker discovery
03:14:20 DISPATCHER: Starting worker discovery
03:14:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:14:20 DISPATCHER: Finished worker discovery
03:15:20 DISPATCHER: Starting worker discovery
03:15:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:15:20 DISPATCHER: Finished worker discovery
03:16:06 WORKER: done with job (1, 0, 0), trying to register it.
03:16:06 WORKER: registered result for job (1, 0, 0) with dispatcher
03:16:06 DISPATCHER: job (1, 0, 0) finished
03:16:07 DISPATCHER: register_result: lock acquired
03:16:07 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
03:16:07 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 73, 'last_n_outputs': 48, 'lr': 0.07194886193720451, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.010828899940274316}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5010808604521639, 'info': {'data05': 0.5010808604521639, 'config': "{'batch_size': 128, 'hidden_dim': 73, 'last_n_outputs': 48, 'lr': 0.07194886193720451, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.010828899940274316}"}}
exception: None

03:16:07 job_callback for (1, 0, 0) started
03:16:07 job_callback for (1, 0, 0) got condition
03:16:07 DISPATCHER: Trying to submit another job.
03:16:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:16:07 Only 4 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
03:16:07 HBMASTER: Trying to run another job!
03:16:07 job_callback for (1, 0, 0) finished
03:16:07 HBMASTER: schedule new run for iteration 1
03:16:07 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
03:16:07 HBMASTER: submitting job (1, 0, 1) to dispatcher
03:16:07 DISPATCHER: trying to submit job (1, 0, 1)
03:16:07 DISPATCHER: trying to notify the job_runner thread.
03:16:07 HBMASTER: job (1, 0, 1) submitted to dispatcher
03:16:07 DISPATCHER: Trying to submit another job.
03:16:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:16:07 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
03:16:07 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
03:16:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:16:07 WORKER: start processing job (1, 0, 1)
03:16:07 WORKER: args: ()
03:16:07 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 59, 'last_n_outputs': 46, 'lr': 0.00416439188058429, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.01414869140685371}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-456:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:16:20 DISPATCHER: Starting worker discovery
03:16:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:16:20 DISPATCHER: Finished worker discovery
03:17:20 DISPATCHER: Starting worker discovery
03:17:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:17:20 DISPATCHER: Finished worker discovery
03:18:20 DISPATCHER: Starting worker discovery
03:18:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:18:20 DISPATCHER: Finished worker discovery
03:19:20 DISPATCHER: Starting worker discovery
03:19:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:19:20 DISPATCHER: Finished worker discovery
03:20:20 DISPATCHER: Starting worker discovery
03:20:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:20:20 DISPATCHER: Finished worker discovery
03:21:20 DISPATCHER: Starting worker discovery
03:21:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:21:20 DISPATCHER: Finished worker discovery
03:22:20 DISPATCHER: Starting worker discovery
03:22:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:22:20 DISPATCHER: Finished worker discovery
03:22:56 WORKER: done with job (1, 0, 1), trying to register it.
03:22:56 WORKER: registered result for job (1, 0, 1) with dispatcher
03:22:56 DISPATCHER: job (1, 0, 1) finished
03:22:56 DISPATCHER: register_result: lock acquired
03:22:56 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
03:22:56 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 59, 'last_n_outputs': 46, 'lr': 0.00416439188058429, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.01414869140685371}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6539316490928535, 'info': {'data05': 0.6539316490928535, 'config': "{'batch_size': 32, 'hidden_dim': 59, 'last_n_outputs': 46, 'lr': 0.00416439188058429, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.01414869140685371}"}}
exception: None

03:22:56 job_callback for (1, 0, 1) started
03:22:56 DISPATCHER: Trying to submit another job.
03:22:56 job_callback for (1, 0, 1) got condition
03:22:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:22:56 Only 5 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
03:22:56 HBMASTER: Trying to run another job!
03:22:56 job_callback for (1, 0, 1) finished
03:22:56 HBMASTER: schedule new run for iteration 1
03:22:56 HBMASTER: trying submitting job (1, 0, 8) to dispatcher
03:22:56 HBMASTER: submitting job (1, 0, 8) to dispatcher
03:22:56 DISPATCHER: trying to submit job (1, 0, 8)
03:22:56 DISPATCHER: trying to notify the job_runner thread.
03:22:56 HBMASTER: job (1, 0, 8) submitted to dispatcher
03:22:56 DISPATCHER: Trying to submit another job.
03:22:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:22:56 DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464
03:22:56 DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
03:22:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:22:56 WORKER: start processing job (1, 0, 8)
03:22:56 WORKER: args: ()
03:22:56 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 25, 'last_n_outputs': 42, 'lr': 0.00820867950152333, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.011706691920407037}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-457:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:23:20 DISPATCHER: Starting worker discovery
03:23:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:23:20 DISPATCHER: Finished worker discovery
03:24:20 DISPATCHER: Starting worker discovery
03:24:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:24:20 DISPATCHER: Finished worker discovery
03:25:20 DISPATCHER: Starting worker discovery
03:25:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:25:20 DISPATCHER: Finished worker discovery
03:26:20 DISPATCHER: Starting worker discovery
03:26:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:26:20 DISPATCHER: Finished worker discovery
03:27:20 DISPATCHER: Starting worker discovery
03:27:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:27:20 DISPATCHER: Finished worker discovery
03:28:20 DISPATCHER: Starting worker discovery
03:28:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:28:20 DISPATCHER: Finished worker discovery
03:29:20 DISPATCHER: Starting worker discovery
03:29:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:29:20 DISPATCHER: Finished worker discovery
03:29:46 WORKER: done with job (1, 0, 8), trying to register it.
03:29:46 WORKER: registered result for job (1, 0, 8) with dispatcher
03:29:46 DISPATCHER: job (1, 0, 8) finished
03:29:46 DISPATCHER: register_result: lock acquired
03:29:46 DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
03:29:46 job_id: (1, 0, 8)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 25, 'last_n_outputs': 42, 'lr': 0.00820867950152333, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.011706691920407037}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.38169210125878444, 'info': {'data05': 0.38169210125878444, 'config': "{'batch_size': 64, 'hidden_dim': 25, 'last_n_outputs': 42, 'lr': 0.00820867950152333, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.011706691920407037}"}}
exception: None

03:29:46 job_callback for (1, 0, 8) started
03:29:46 job_callback for (1, 0, 8) got condition
03:29:46 DISPATCHER: Trying to submit another job.
03:29:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:29:46 Only 6 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
03:29:46 HBMASTER: Trying to run another job!
03:29:46 job_callback for (1, 0, 8) finished
03:29:46 ITERATION: Advancing config (1, 0, 1) to next budget 1200.000000
03:29:46 HBMASTER: schedule new run for iteration 1
03:29:46 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
03:29:46 HBMASTER: submitting job (1, 0, 1) to dispatcher
03:29:46 DISPATCHER: trying to submit job (1, 0, 1)
03:29:46 DISPATCHER: trying to notify the job_runner thread.
03:29:46 HBMASTER: job (1, 0, 1) submitted to dispatcher
03:29:46 DISPATCHER: Trying to submit another job.
03:29:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:29:46 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
03:29:46 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
03:29:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:29:46 WORKER: start processing job (1, 0, 1)
03:29:46 WORKER: args: ()
03:29:46 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 59, 'last_n_outputs': 46, 'lr': 0.00416439188058429, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.01414869140685371}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-458:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:30:20 DISPATCHER: Starting worker discovery
03:30:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:30:20 DISPATCHER: Finished worker discovery
03:31:20 DISPATCHER: Starting worker discovery
03:31:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:31:20 DISPATCHER: Finished worker discovery
03:32:20 DISPATCHER: Starting worker discovery
03:32:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:32:20 DISPATCHER: Finished worker discovery
03:33:20 DISPATCHER: Starting worker discovery
03:33:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:33:20 DISPATCHER: Finished worker discovery
03:34:20 DISPATCHER: Starting worker discovery
03:34:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:34:20 DISPATCHER: Finished worker discovery
03:35:20 DISPATCHER: Starting worker discovery
03:35:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:35:20 DISPATCHER: Finished worker discovery
03:36:20 DISPATCHER: Starting worker discovery
03:36:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:36:21 DISPATCHER: Finished worker discovery
03:37:21 DISPATCHER: Starting worker discovery
03:37:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:37:21 DISPATCHER: Finished worker discovery
03:38:21 DISPATCHER: Starting worker discovery
03:38:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:38:21 DISPATCHER: Finished worker discovery
03:39:21 DISPATCHER: Starting worker discovery
03:39:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:39:21 DISPATCHER: Finished worker discovery
03:40:21 DISPATCHER: Starting worker discovery
03:40:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:40:21 DISPATCHER: Finished worker discovery
03:41:21 DISPATCHER: Starting worker discovery
03:41:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:41:21 DISPATCHER: Finished worker discovery
03:42:21 DISPATCHER: Starting worker discovery
03:42:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:42:21 DISPATCHER: Finished worker discovery
03:43:21 DISPATCHER: Starting worker discovery
03:43:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:43:21 DISPATCHER: Finished worker discovery
03:44:21 DISPATCHER: Starting worker discovery
03:44:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:44:21 DISPATCHER: Finished worker discovery
03:45:21 DISPATCHER: Starting worker discovery
03:45:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:45:21 DISPATCHER: Finished worker discovery
03:46:21 DISPATCHER: Starting worker discovery
03:46:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:46:21 DISPATCHER: Finished worker discovery
03:47:21 DISPATCHER: Starting worker discovery
03:47:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:47:21 DISPATCHER: Finished worker discovery
03:48:21 DISPATCHER: Starting worker discovery
03:48:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:48:21 DISPATCHER: Finished worker discovery
03:49:21 DISPATCHER: Starting worker discovery
03:49:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:49:21 DISPATCHER: Finished worker discovery
03:49:56 WORKER: done with job (1, 0, 1), trying to register it.
03:49:56 WORKER: registered result for job (1, 0, 1) with dispatcher
03:49:56 DISPATCHER: job (1, 0, 1) finished
03:49:56 DISPATCHER: register_result: lock acquired
03:49:56 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
03:49:56 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 59, 'last_n_outputs': 46, 'lr': 0.00416439188058429, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.01414869140685371}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.47005525133282305, 'info': {'data05': 0.47005525133282305, 'config': "{'batch_size': 32, 'hidden_dim': 59, 'last_n_outputs': 46, 'lr': 0.00416439188058429, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.01414869140685371}"}}
exception: None

03:49:56 job_callback for (1, 0, 1) started
03:49:56 DISPATCHER: Trying to submit another job.
03:49:56 job_callback for (1, 0, 1) got condition
03:49:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:49:56 Only 2 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
03:49:56 HBMASTER: Trying to run another job!
03:49:56 job_callback for (1, 0, 1) finished
03:49:56 start sampling a new configuration.
03:49:56 best_vector: [0, 0.5716959899166928, 0.6924053099866756, 0.7526336395227144, 0.08938612397077973, 0, 0.787636719041812, 0.7437300061082608], 0.013078103676782905, 0.33558299722771845, 0.004388789229909652
03:49:56 done sampling a new configuration.
03:49:56 HBMASTER: schedule new run for iteration 2
03:49:56 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
03:49:56 HBMASTER: submitting job (2, 0, 0) to dispatcher
03:49:56 DISPATCHER: trying to submit job (2, 0, 0)
03:49:56 DISPATCHER: trying to notify the job_runner thread.
03:49:56 HBMASTER: job (2, 0, 0) submitted to dispatcher
03:49:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:49:56 DISPATCHER: Trying to submit another job.
03:49:56 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
03:49:56 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
03:49:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:49:56 WORKER: start processing job (2, 0, 0)
03:49:56 WORKER: args: ()
03:49:56 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 66, 'last_n_outputs': 35, 'lr': 0.03200864420418877, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.09281433270356212}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-459:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:50:21 DISPATCHER: Starting worker discovery
03:50:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:50:21 DISPATCHER: Finished worker discovery
03:51:21 DISPATCHER: Starting worker discovery
03:51:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:51:21 DISPATCHER: Finished worker discovery
03:52:21 DISPATCHER: Starting worker discovery
03:52:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:52:21 DISPATCHER: Finished worker discovery
03:53:21 DISPATCHER: Starting worker discovery
03:53:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:53:21 DISPATCHER: Finished worker discovery
03:54:21 DISPATCHER: Starting worker discovery
03:54:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:54:21 DISPATCHER: Finished worker discovery
03:55:21 DISPATCHER: Starting worker discovery
03:55:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:55:21 DISPATCHER: Finished worker discovery
03:56:21 DISPATCHER: Starting worker discovery
03:56:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:56:21 DISPATCHER: Finished worker discovery
03:56:47 WORKER: done with job (2, 0, 0), trying to register it.
03:56:47 WORKER: registered result for job (2, 0, 0) with dispatcher
03:56:47 DISPATCHER: job (2, 0, 0) finished
03:56:47 DISPATCHER: register_result: lock acquired
03:56:47 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
03:56:47 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 66, 'last_n_outputs': 35, 'lr': 0.03200864420418877, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.09281433270356212}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.10768214553831006, 'info': {'data05': 0.10768214553831006, 'config': "{'batch_size': 16, 'hidden_dim': 66, 'last_n_outputs': 35, 'lr': 0.03200864420418877, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.09281433270356212}"}}
exception: None

03:56:47 job_callback for (2, 0, 0) started
03:56:47 job_callback for (2, 0, 0) got condition
03:56:47 DISPATCHER: Trying to submit another job.
03:56:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:56:47 Only 7 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
03:56:47 HBMASTER: Trying to run another job!
03:56:47 job_callback for (2, 0, 0) finished
03:56:47 start sampling a new configuration.
03:56:47 best_vector: [2, 0.15618012184671304, 0.6021017006101537, 0.9303883902543104, 0.03275633309686013, 1, 0.9457983220685133, 0.8955782966083194], 0.002542876915839906, 0.4876038498483676, 0.0012399165738540816
03:56:47 done sampling a new configuration.
03:56:47 HBMASTER: schedule new run for iteration 2
03:56:47 HBMASTER: trying submitting job (2, 0, 1) to dispatcher
03:56:47 HBMASTER: submitting job (2, 0, 1) to dispatcher
03:56:47 DISPATCHER: trying to submit job (2, 0, 1)
03:56:47 DISPATCHER: trying to notify the job_runner thread.
03:56:47 HBMASTER: job (2, 0, 1) submitted to dispatcher
03:56:47 DISPATCHER: Trying to submit another job.
03:56:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:56:47 DISPATCHER: starting job (2, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
03:56:47 DISPATCHER: job (2, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
03:56:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:56:47 WORKER: start processing job (2, 0, 1)
03:56:47 WORKER: args: ()
03:56:47 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 32, 'last_n_outputs': 31, 'lr': 0.07257328480288769, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.14627638785848837}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-460:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:57:21 DISPATCHER: Starting worker discovery
03:57:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:57:21 DISPATCHER: Finished worker discovery
03:58:21 DISPATCHER: Starting worker discovery
03:58:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:58:21 DISPATCHER: Finished worker discovery
03:59:21 DISPATCHER: Starting worker discovery
03:59:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:59:21 DISPATCHER: Finished worker discovery
04:00:21 DISPATCHER: Starting worker discovery
04:00:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:00:21 DISPATCHER: Finished worker discovery
04:01:21 DISPATCHER: Starting worker discovery
04:01:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:01:21 DISPATCHER: Finished worker discovery
04:02:21 DISPATCHER: Starting worker discovery
04:02:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:02:21 DISPATCHER: Finished worker discovery
04:03:21 DISPATCHER: Starting worker discovery
04:03:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:03:21 DISPATCHER: Finished worker discovery
04:03:37 WORKER: done with job (2, 0, 1), trying to register it.
04:03:37 WORKER: registered result for job (2, 0, 1) with dispatcher
04:03:37 DISPATCHER: job (2, 0, 1) finished
04:03:37 DISPATCHER: register_result: lock acquired
04:03:37 DISPATCHER: job (2, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
04:03:37 job_id: (2, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 32, 'last_n_outputs': 31, 'lr': 0.07257328480288769, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.14627638785848837}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.10362306174317774, 'info': {'data05': 0.10362306174317774, 'config': "{'batch_size': 64, 'hidden_dim': 32, 'last_n_outputs': 31, 'lr': 0.07257328480288769, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.14627638785848837}"}}
exception: None

04:03:37 job_callback for (2, 0, 1) started
04:03:37 DISPATCHER: Trying to submit another job.
04:03:37 job_callback for (2, 0, 1) got condition
04:03:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:03:37 Only 8 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
04:03:37 HBMASTER: Trying to run another job!
04:03:37 job_callback for (2, 0, 1) finished
04:03:37 start sampling a new configuration.
04:03:37 done sampling a new configuration.
04:03:37 HBMASTER: schedule new run for iteration 2
04:03:37 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
04:03:37 HBMASTER: submitting job (2, 0, 2) to dispatcher
04:03:37 DISPATCHER: trying to submit job (2, 0, 2)
04:03:37 DISPATCHER: trying to notify the job_runner thread.
04:03:37 HBMASTER: job (2, 0, 2) submitted to dispatcher
04:03:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:03:37 DISPATCHER: Trying to submit another job.
04:03:37 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:03:37 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:03:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:03:37 WORKER: start processing job (2, 0, 2)
04:03:37 WORKER: args: ()
04:03:37 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 78, 'last_n_outputs': 29, 'lr': 0.014072538940626773, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.11252542656818777}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-461:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:04:21 DISPATCHER: Starting worker discovery
04:04:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:04:21 DISPATCHER: Finished worker discovery
04:05:21 DISPATCHER: Starting worker discovery
04:05:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:05:21 DISPATCHER: Finished worker discovery
04:06:21 DISPATCHER: Starting worker discovery
04:06:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:06:21 DISPATCHER: Finished worker discovery
04:07:21 DISPATCHER: Starting worker discovery
04:07:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:07:21 DISPATCHER: Finished worker discovery
04:08:21 DISPATCHER: Starting worker discovery
04:08:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:08:21 DISPATCHER: Finished worker discovery
04:09:21 DISPATCHER: Starting worker discovery
04:09:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:09:21 DISPATCHER: Finished worker discovery
04:10:21 DISPATCHER: Starting worker discovery
04:10:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:10:21 DISPATCHER: Finished worker discovery
04:10:27 WORKER: done with job (2, 0, 2), trying to register it.
04:10:27 WORKER: registered result for job (2, 0, 2) with dispatcher
04:10:27 DISPATCHER: job (2, 0, 2) finished
04:10:27 DISPATCHER: register_result: lock acquired
04:10:27 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
04:10:27 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 78, 'last_n_outputs': 29, 'lr': 0.014072538940626773, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.11252542656818777}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 78, 'last_n_outputs': 29, 'lr': 0.014072538940626773, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.11252542656818777}"}}
exception: None

04:10:27 job_callback for (2, 0, 2) started
04:10:27 job_callback for (2, 0, 2) got condition
04:10:27 DISPATCHER: Trying to submit another job.
04:10:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:10:27 HBMASTER: Trying to run another job!
04:10:27 job_callback for (2, 0, 2) finished
04:10:27 start sampling a new configuration.
04:10:27 done sampling a new configuration.
04:10:27 HBMASTER: schedule new run for iteration 2
04:10:27 HBMASTER: trying submitting job (2, 0, 3) to dispatcher
04:10:27 HBMASTER: submitting job (2, 0, 3) to dispatcher
04:10:27 DISPATCHER: trying to submit job (2, 0, 3)
04:10:27 DISPATCHER: trying to notify the job_runner thread.
04:10:27 HBMASTER: job (2, 0, 3) submitted to dispatcher
04:10:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:10:27 DISPATCHER: Trying to submit another job.
04:10:27 DISPATCHER: starting job (2, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:10:27 DISPATCHER: job (2, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:10:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:10:27 WORKER: start processing job (2, 0, 3)
04:10:27 WORKER: args: ()
04:10:27 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 97, 'last_n_outputs': 50, 'lr': 0.010641725044906212, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.020923019963350754}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-462:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:11:21 DISPATCHER: Starting worker discovery
04:11:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:11:21 DISPATCHER: Finished worker discovery
04:12:21 DISPATCHER: Starting worker discovery
04:12:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:12:21 DISPATCHER: Finished worker discovery
04:13:21 DISPATCHER: Starting worker discovery
04:13:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:13:21 DISPATCHER: Finished worker discovery
04:14:21 DISPATCHER: Starting worker discovery
04:14:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:14:21 DISPATCHER: Finished worker discovery
04:15:21 DISPATCHER: Starting worker discovery
04:15:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:15:21 DISPATCHER: Finished worker discovery
04:16:21 DISPATCHER: Starting worker discovery
04:16:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:16:21 DISPATCHER: Finished worker discovery
04:17:17 WORKER: done with job (2, 0, 3), trying to register it.
04:17:17 WORKER: registered result for job (2, 0, 3) with dispatcher
04:17:17 DISPATCHER: job (2, 0, 3) finished
04:17:17 DISPATCHER: register_result: lock acquired
04:17:17 DISPATCHER: job (2, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
04:17:17 job_id: (2, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 97, 'last_n_outputs': 50, 'lr': 0.010641725044906212, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.020923019963350754}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 97, 'last_n_outputs': 50, 'lr': 0.010641725044906212, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.020923019963350754}"}}
exception: None

04:17:17 job_callback for (2, 0, 3) started
04:17:17 DISPATCHER: Trying to submit another job.
04:17:17 job_callback for (2, 0, 3) got condition
04:17:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:17:17 HBMASTER: Trying to run another job!
04:17:17 job_callback for (2, 0, 3) finished
04:17:17 start sampling a new configuration.
04:17:17 done sampling a new configuration.
04:17:17 HBMASTER: schedule new run for iteration 2
04:17:17 HBMASTER: trying submitting job (2, 0, 4) to dispatcher
04:17:17 HBMASTER: submitting job (2, 0, 4) to dispatcher
04:17:17 DISPATCHER: trying to submit job (2, 0, 4)
04:17:17 DISPATCHER: trying to notify the job_runner thread.
04:17:17 HBMASTER: job (2, 0, 4) submitted to dispatcher
04:17:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:17:17 DISPATCHER: Trying to submit another job.
04:17:17 DISPATCHER: starting job (2, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:17:17 DISPATCHER: job (2, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:17:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:17:17 WORKER: start processing job (2, 0, 4)
04:17:17 WORKER: args: ()
04:17:17 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 75, 'last_n_outputs': 40, 'lr': 0.002260360710409448, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.025069868209454206}, 'budget': 400.0, 'working_directory': '.'}
04:17:21 DISPATCHER: Starting worker discovery
04:17:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:17:21 DISPATCHER: Finished worker discovery
Exception in thread Thread-463:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:18:21 DISPATCHER: Starting worker discovery
04:18:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:18:21 DISPATCHER: Finished worker discovery
04:19:21 DISPATCHER: Starting worker discovery
04:19:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:19:21 DISPATCHER: Finished worker discovery
04:20:21 DISPATCHER: Starting worker discovery
04:20:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:20:21 DISPATCHER: Finished worker discovery
04:21:21 DISPATCHER: Starting worker discovery
04:21:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:21:21 DISPATCHER: Finished worker discovery
04:22:21 DISPATCHER: Starting worker discovery
04:22:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:22:21 DISPATCHER: Finished worker discovery
04:23:21 DISPATCHER: Starting worker discovery
04:23:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:23:21 DISPATCHER: Finished worker discovery
04:24:09 WORKER: done with job (2, 0, 4), trying to register it.
04:24:09 WORKER: registered result for job (2, 0, 4) with dispatcher
04:24:09 DISPATCHER: job (2, 0, 4) finished
04:24:09 DISPATCHER: register_result: lock acquired
04:24:09 DISPATCHER: job (2, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
04:24:09 job_id: (2, 0, 4)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 75, 'last_n_outputs': 40, 'lr': 0.002260360710409448, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.025069868209454206}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': 0.00302836639974297, 'info': {'data05': -0.00302836639974297, 'config': "{'batch_size': 64, 'hidden_dim': 75, 'last_n_outputs': 40, 'lr': 0.002260360710409448, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.025069868209454206}"}}
exception: None

04:24:09 job_callback for (2, 0, 4) started
04:24:09 DISPATCHER: Trying to submit another job.
04:24:09 job_callback for (2, 0, 4) got condition
04:24:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:24:09 HBMASTER: Trying to run another job!
04:24:09 job_callback for (2, 0, 4) finished
04:24:09 start sampling a new configuration.
04:24:09 best_vector: [0, 0.07306770225005467, 0.6155254291493224, 0.33840497904799016, 0.06088729974508217, 1, 0.0771971138171843, 0.07053971899908126], 0.025083367842488984, 0.37168810413925907, 0.009323189438802388
04:24:09 done sampling a new configuration.
04:24:09 HBMASTER: schedule new run for iteration 2
04:24:09 HBMASTER: trying submitting job (2, 0, 5) to dispatcher
04:24:09 HBMASTER: submitting job (2, 0, 5) to dispatcher
04:24:09 DISPATCHER: trying to submit job (2, 0, 5)
04:24:09 DISPATCHER: trying to notify the job_runner thread.
04:24:09 HBMASTER: job (2, 0, 5) submitted to dispatcher
04:24:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:24:09 DISPATCHER: Trying to submit another job.
04:24:09 DISPATCHER: starting job (2, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:24:09 DISPATCHER: job (2, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:24:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:24:09 WORKER: start processing job (2, 0, 5)
04:24:09 WORKER: args: ()
04:24:09 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 25, 'last_n_outputs': 31, 'lr': 0.00475127270618492, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.012353052589456058}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-464:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:24:21 DISPATCHER: Starting worker discovery
04:24:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:24:21 DISPATCHER: Finished worker discovery
04:25:21 DISPATCHER: Starting worker discovery
04:25:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:25:21 DISPATCHER: Finished worker discovery
04:26:21 DISPATCHER: Starting worker discovery
04:26:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:26:21 DISPATCHER: Finished worker discovery
04:27:21 DISPATCHER: Starting worker discovery
04:27:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:27:21 DISPATCHER: Finished worker discovery
04:28:21 DISPATCHER: Starting worker discovery
04:28:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:28:21 DISPATCHER: Finished worker discovery
04:29:21 DISPATCHER: Starting worker discovery
04:29:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:29:21 DISPATCHER: Finished worker discovery
04:30:21 DISPATCHER: Starting worker discovery
04:30:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:30:21 DISPATCHER: Finished worker discovery
04:31:00 WORKER: done with job (2, 0, 5), trying to register it.
04:31:00 WORKER: registered result for job (2, 0, 5) with dispatcher
04:31:00 DISPATCHER: job (2, 0, 5) finished
04:31:00 DISPATCHER: register_result: lock acquired
04:31:00 DISPATCHER: job (2, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
04:31:00 job_id: (2, 0, 5)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 25, 'last_n_outputs': 31, 'lr': 0.00475127270618492, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.012353052589456058}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': 0.0203594598173901, 'info': {'data05': -0.0203594598173901, 'config': "{'batch_size': 16, 'hidden_dim': 25, 'last_n_outputs': 31, 'lr': 0.00475127270618492, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.012353052589456058}"}}
exception: None

04:31:00 job_callback for (2, 0, 5) started
04:31:00 DISPATCHER: Trying to submit another job.
04:31:00 job_callback for (2, 0, 5) got condition
04:31:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:31:00 HBMASTER: Trying to run another job!
04:31:00 job_callback for (2, 0, 5) finished
04:31:00 ITERATION: Advancing config (2, 0, 0) to next budget 1200.000000
04:31:00 ITERATION: Advancing config (2, 0, 1) to next budget 1200.000000
04:31:00 HBMASTER: schedule new run for iteration 2
04:31:00 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
04:31:00 HBMASTER: submitting job (2, 0, 0) to dispatcher
04:31:00 DISPATCHER: trying to submit job (2, 0, 0)
04:31:00 DISPATCHER: trying to notify the job_runner thread.
04:31:00 HBMASTER: job (2, 0, 0) submitted to dispatcher
04:31:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:31:00 DISPATCHER: Trying to submit another job.
04:31:00 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:31:00 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:31:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:31:00 WORKER: start processing job (2, 0, 0)
04:31:00 WORKER: args: ()
04:31:00 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 66, 'last_n_outputs': 35, 'lr': 0.03200864420418877, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.09281433270356212}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-465:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:31:21 DISPATCHER: Starting worker discovery
04:31:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:31:21 DISPATCHER: Finished worker discovery
04:32:21 DISPATCHER: Starting worker discovery
04:32:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:32:21 DISPATCHER: Finished worker discovery
04:33:21 DISPATCHER: Starting worker discovery
04:33:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:33:21 DISPATCHER: Finished worker discovery
04:34:21 DISPATCHER: Starting worker discovery
04:34:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:34:21 DISPATCHER: Finished worker discovery
04:35:21 DISPATCHER: Starting worker discovery
04:35:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:35:21 DISPATCHER: Finished worker discovery
04:36:21 DISPATCHER: Starting worker discovery
04:36:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:36:21 DISPATCHER: Finished worker discovery
04:37:21 DISPATCHER: Starting worker discovery
04:37:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:37:21 DISPATCHER: Finished worker discovery
04:38:21 DISPATCHER: Starting worker discovery
04:38:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:38:21 DISPATCHER: Finished worker discovery
04:39:21 DISPATCHER: Starting worker discovery
04:39:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:39:21 DISPATCHER: Finished worker discovery
04:40:21 DISPATCHER: Starting worker discovery
04:40:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:40:21 DISPATCHER: Finished worker discovery
04:41:21 DISPATCHER: Starting worker discovery
04:41:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:41:21 DISPATCHER: Finished worker discovery
04:42:21 DISPATCHER: Starting worker discovery
04:42:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:42:21 DISPATCHER: Finished worker discovery
04:43:21 DISPATCHER: Starting worker discovery
04:43:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:43:21 DISPATCHER: Finished worker discovery
04:44:21 DISPATCHER: Starting worker discovery
04:44:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:44:21 DISPATCHER: Finished worker discovery
04:45:21 DISPATCHER: Starting worker discovery
04:45:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:45:21 DISPATCHER: Finished worker discovery
04:46:21 DISPATCHER: Starting worker discovery
04:46:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:46:21 DISPATCHER: Finished worker discovery
04:47:21 DISPATCHER: Starting worker discovery
04:47:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:47:21 DISPATCHER: Finished worker discovery
04:48:21 DISPATCHER: Starting worker discovery
04:48:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:48:21 DISPATCHER: Finished worker discovery
04:49:21 DISPATCHER: Starting worker discovery
04:49:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:49:21 DISPATCHER: Finished worker discovery
04:50:21 DISPATCHER: Starting worker discovery
04:50:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:50:21 DISPATCHER: Finished worker discovery
04:51:10 WORKER: done with job (2, 0, 0), trying to register it.
04:51:10 WORKER: registered result for job (2, 0, 0) with dispatcher
04:51:10 DISPATCHER: job (2, 0, 0) finished
04:51:10 DISPATCHER: register_result: lock acquired
04:51:10 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
04:51:10 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 66, 'last_n_outputs': 35, 'lr': 0.03200864420418877, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.09281433270356212}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.08770897689459797, 'info': {'data05': 0.08770897689459797, 'config': "{'batch_size': 16, 'hidden_dim': 66, 'last_n_outputs': 35, 'lr': 0.03200864420418877, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.09281433270356212}"}}
exception: None

04:51:10 job_callback for (2, 0, 0) started
04:51:10 job_callback for (2, 0, 0) got condition
04:51:10 DISPATCHER: Trying to submit another job.
04:51:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:51:10 Only 3 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
04:51:10 HBMASTER: Trying to run another job!
04:51:10 job_callback for (2, 0, 0) finished
04:51:10 HBMASTER: schedule new run for iteration 2
04:51:10 HBMASTER: trying submitting job (2, 0, 1) to dispatcher
04:51:10 HBMASTER: submitting job (2, 0, 1) to dispatcher
04:51:10 DISPATCHER: trying to submit job (2, 0, 1)
04:51:10 DISPATCHER: trying to notify the job_runner thread.
04:51:10 HBMASTER: job (2, 0, 1) submitted to dispatcher
04:51:10 DISPATCHER: Trying to submit another job.
04:51:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:51:10 DISPATCHER: starting job (2, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:51:10 DISPATCHER: job (2, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
04:51:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:51:10 WORKER: start processing job (2, 0, 1)
04:51:10 WORKER: args: ()
04:51:10 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 32, 'last_n_outputs': 31, 'lr': 0.07257328480288769, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.14627638785848837}, 'budget': 1200.0, 'working_directory': '.'}
04:51:21 DISPATCHER: Starting worker discovery
04:51:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:51:21 DISPATCHER: Finished worker discovery
Exception in thread Thread-466:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:52:21 DISPATCHER: Starting worker discovery
04:52:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:52:21 DISPATCHER: Finished worker discovery
04:53:21 DISPATCHER: Starting worker discovery
04:53:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:53:21 DISPATCHER: Finished worker discovery
04:54:21 DISPATCHER: Starting worker discovery
04:54:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:54:21 DISPATCHER: Finished worker discovery
04:55:21 DISPATCHER: Starting worker discovery
04:55:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:55:21 DISPATCHER: Finished worker discovery
04:56:21 DISPATCHER: Starting worker discovery
04:56:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:56:21 DISPATCHER: Finished worker discovery
04:57:21 DISPATCHER: Starting worker discovery
04:57:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:57:21 DISPATCHER: Finished worker discovery
04:58:21 DISPATCHER: Starting worker discovery
04:58:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:58:21 DISPATCHER: Finished worker discovery
04:59:21 DISPATCHER: Starting worker discovery
04:59:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:59:21 DISPATCHER: Finished worker discovery
05:00:21 DISPATCHER: Starting worker discovery
05:00:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:00:21 DISPATCHER: Finished worker discovery
05:01:21 DISPATCHER: Starting worker discovery
05:01:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:01:21 DISPATCHER: Finished worker discovery
05:02:21 DISPATCHER: Starting worker discovery
05:02:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:02:21 DISPATCHER: Finished worker discovery
05:03:21 DISPATCHER: Starting worker discovery
05:03:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:03:21 DISPATCHER: Finished worker discovery
05:04:21 DISPATCHER: Starting worker discovery
05:04:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:04:21 DISPATCHER: Finished worker discovery
05:05:21 DISPATCHER: Starting worker discovery
05:05:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:05:21 DISPATCHER: Finished worker discovery
05:06:21 DISPATCHER: Starting worker discovery
05:06:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:06:21 DISPATCHER: Finished worker discovery
05:07:21 DISPATCHER: Starting worker discovery
05:07:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:07:21 DISPATCHER: Finished worker discovery
05:08:21 DISPATCHER: Starting worker discovery
05:08:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:08:21 DISPATCHER: Finished worker discovery
05:09:21 DISPATCHER: Starting worker discovery
05:09:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:09:21 DISPATCHER: Finished worker discovery
05:10:21 DISPATCHER: Starting worker discovery
05:10:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:10:21 DISPATCHER: Finished worker discovery
05:11:20 WORKER: done with job (2, 0, 1), trying to register it.
05:11:20 WORKER: registered result for job (2, 0, 1) with dispatcher
05:11:20 DISPATCHER: job (2, 0, 1) finished
05:11:20 DISPATCHER: register_result: lock acquired
05:11:20 DISPATCHER: job (2, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
05:11:20 job_id: (2, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 32, 'last_n_outputs': 31, 'lr': 0.07257328480288769, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.14627638785848837}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.1605086200043409, 'info': {'data05': 0.1605086200043409, 'config': "{'batch_size': 64, 'hidden_dim': 32, 'last_n_outputs': 31, 'lr': 0.07257328480288769, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.14627638785848837}"}}
exception: None

05:11:20 job_callback for (2, 0, 1) started
05:11:20 job_callback for (2, 0, 1) got condition
05:11:20 DISPATCHER: Trying to submit another job.
05:11:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:11:20 Only 4 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
05:11:20 HBMASTER: Trying to run another job!
05:11:20 job_callback for (2, 0, 1) finished
05:11:20 start sampling a new configuration.
05:11:20 best_vector: [1, 0.5143837734487972, 0.6748646885098238, 0.8674411789143466, 0.19957506684938778, 1, 0.17863520021248258, 0.8935957586656422], 0.013831099912667877, 0.24804860415140595, 0.0034307850272158997
05:11:20 done sampling a new configuration.
05:11:20 HBMASTER: schedule new run for iteration 3
05:11:20 HBMASTER: trying submitting job (3, 0, 0) to dispatcher
05:11:20 HBMASTER: submitting job (3, 0, 0) to dispatcher
05:11:20 DISPATCHER: trying to submit job (3, 0, 0)
05:11:20 DISPATCHER: trying to notify the job_runner thread.
05:11:20 HBMASTER: job (3, 0, 0) submitted to dispatcher
05:11:20 DISPATCHER: Trying to submit another job.
05:11:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:11:20 DISPATCHER: starting job (3, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
05:11:20 DISPATCHER: job (3, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
05:11:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:11:20 WORKER: start processing job (3, 0, 0)
05:11:20 WORKER: args: ()
05:11:20 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 61, 'last_n_outputs': 34, 'lr': 0.05431031951687786, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.1454102047685825}, 'budget': 1200.0, 'working_directory': '.'}
05:11:21 DISPATCHER: Starting worker discovery
05:11:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:11:21 DISPATCHER: Finished worker discovery
Exception in thread Thread-467:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:12:21 DISPATCHER: Starting worker discovery
05:12:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:12:21 DISPATCHER: Finished worker discovery
05:13:21 DISPATCHER: Starting worker discovery
05:13:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:13:21 DISPATCHER: Finished worker discovery
05:14:21 DISPATCHER: Starting worker discovery
05:14:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:14:21 DISPATCHER: Finished worker discovery
05:15:21 DISPATCHER: Starting worker discovery
05:15:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:15:21 DISPATCHER: Finished worker discovery
05:16:21 DISPATCHER: Starting worker discovery
05:16:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:16:21 DISPATCHER: Finished worker discovery
05:17:21 DISPATCHER: Starting worker discovery
05:17:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:17:21 DISPATCHER: Finished worker discovery
05:18:21 DISPATCHER: Starting worker discovery
05:18:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:18:21 DISPATCHER: Finished worker discovery
05:19:21 DISPATCHER: Starting worker discovery
05:19:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:19:21 DISPATCHER: Finished worker discovery
05:20:21 DISPATCHER: Starting worker discovery
05:20:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:20:21 DISPATCHER: Finished worker discovery
05:21:21 DISPATCHER: Starting worker discovery
05:21:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:21:21 DISPATCHER: Finished worker discovery
05:22:21 DISPATCHER: Starting worker discovery
05:22:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:22:21 DISPATCHER: Finished worker discovery
05:23:21 DISPATCHER: Starting worker discovery
05:23:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:23:21 DISPATCHER: Finished worker discovery
05:24:21 DISPATCHER: Starting worker discovery
05:24:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:24:21 DISPATCHER: Finished worker discovery
05:25:21 DISPATCHER: Starting worker discovery
05:25:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:25:21 DISPATCHER: Finished worker discovery
05:26:21 DISPATCHER: Starting worker discovery
05:26:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:26:21 DISPATCHER: Finished worker discovery
05:27:21 DISPATCHER: Starting worker discovery
05:27:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:27:21 DISPATCHER: Finished worker discovery
05:28:21 DISPATCHER: Starting worker discovery
05:28:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:28:21 DISPATCHER: Finished worker discovery
05:29:21 DISPATCHER: Starting worker discovery
05:29:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:29:21 DISPATCHER: Finished worker discovery
05:30:21 DISPATCHER: Starting worker discovery
05:30:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:30:21 DISPATCHER: Finished worker discovery
05:31:21 DISPATCHER: Starting worker discovery
05:31:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:31:21 DISPATCHER: Finished worker discovery
05:31:30 WORKER: done with job (3, 0, 0), trying to register it.
05:31:30 WORKER: registered result for job (3, 0, 0) with dispatcher
05:31:30 DISPATCHER: job (3, 0, 0) finished
05:31:30 DISPATCHER: register_result: lock acquired
05:31:30 DISPATCHER: job (3, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
05:31:30 job_id: (3, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 61, 'last_n_outputs': 34, 'lr': 0.05431031951687786, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.1454102047685825}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.18508708949201105, 'info': {'data05': 0.18508708949201105, 'config': "{'batch_size': 32, 'hidden_dim': 61, 'last_n_outputs': 34, 'lr': 0.05431031951687786, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.1454102047685825}"}}
exception: None

05:31:30 job_callback for (3, 0, 0) started
05:31:30 job_callback for (3, 0, 0) got condition
05:31:30 DISPATCHER: Trying to submit another job.
05:31:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:31:30 Only 5 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
05:31:30 HBMASTER: Trying to run another job!
05:31:30 job_callback for (3, 0, 0) finished
05:31:30 start sampling a new configuration.
05:31:30 best_vector: [2, 0.7659420565573323, 0.6385971348663166, 0.9991744411071936, 0.07883578023916174, 0, 0.04577885808452198, 0.16804749529297122], 0.04159412153904857, 0.09315506663108325, 0.0038747031634314443
05:31:30 done sampling a new configuration.
05:31:30 HBMASTER: schedule new run for iteration 3
05:31:30 HBMASTER: trying submitting job (3, 0, 1) to dispatcher
05:31:30 HBMASTER: submitting job (3, 0, 1) to dispatcher
05:31:30 DISPATCHER: trying to submit job (3, 0, 1)
05:31:30 DISPATCHER: trying to notify the job_runner thread.
05:31:30 HBMASTER: job (3, 0, 1) submitted to dispatcher
05:31:30 DISPATCHER: Trying to submit another job.
05:31:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:31:30 DISPATCHER: starting job (3, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
05:31:30 DISPATCHER: job (3, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
05:31:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:31:30 WORKER: start processing job (3, 0, 1)
05:31:30 WORKER: args: ()
05:31:30 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 82, 'last_n_outputs': 32, 'lr': 0.09962053786408019, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.01654378327182815}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-468:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:32:21 DISPATCHER: Starting worker discovery
05:32:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:32:21 DISPATCHER: Finished worker discovery
05:33:21 DISPATCHER: Starting worker discovery
05:33:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:33:21 DISPATCHER: Finished worker discovery
05:34:21 DISPATCHER: Starting worker discovery
05:34:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:34:21 DISPATCHER: Finished worker discovery
05:35:21 DISPATCHER: Starting worker discovery
05:35:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:35:21 DISPATCHER: Finished worker discovery
05:36:21 DISPATCHER: Starting worker discovery
05:36:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:36:21 DISPATCHER: Finished worker discovery
05:37:21 DISPATCHER: Starting worker discovery
05:37:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:37:21 DISPATCHER: Finished worker discovery
05:38:21 DISPATCHER: Starting worker discovery
05:38:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:38:21 DISPATCHER: Finished worker discovery
05:39:21 DISPATCHER: Starting worker discovery
05:39:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:39:21 DISPATCHER: Finished worker discovery
05:40:21 DISPATCHER: Starting worker discovery
05:40:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:40:21 DISPATCHER: Finished worker discovery
05:41:21 DISPATCHER: Starting worker discovery
05:41:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:41:21 DISPATCHER: Finished worker discovery
05:42:21 DISPATCHER: Starting worker discovery
05:42:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:42:21 DISPATCHER: Finished worker discovery
05:43:21 DISPATCHER: Starting worker discovery
05:43:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:43:21 DISPATCHER: Finished worker discovery
05:44:21 DISPATCHER: Starting worker discovery
05:44:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:44:21 DISPATCHER: Finished worker discovery
05:45:21 DISPATCHER: Starting worker discovery
05:45:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:45:21 DISPATCHER: Finished worker discovery
05:46:21 DISPATCHER: Starting worker discovery
05:46:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:46:21 DISPATCHER: Finished worker discovery
05:47:21 DISPATCHER: Starting worker discovery
05:47:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:47:21 DISPATCHER: Finished worker discovery
05:48:21 DISPATCHER: Starting worker discovery
05:48:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:48:21 DISPATCHER: Finished worker discovery
05:49:21 DISPATCHER: Starting worker discovery
05:49:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:49:21 DISPATCHER: Finished worker discovery
05:50:21 DISPATCHER: Starting worker discovery
05:50:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:50:21 DISPATCHER: Finished worker discovery
05:51:21 DISPATCHER: Starting worker discovery
05:51:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:51:21 DISPATCHER: Finished worker discovery
05:51:40 WORKER: done with job (3, 0, 1), trying to register it.
05:51:40 WORKER: registered result for job (3, 0, 1) with dispatcher
05:51:40 DISPATCHER: job (3, 0, 1) finished
05:51:40 DISPATCHER: register_result: lock acquired
05:51:40 DISPATCHER: job (3, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
05:51:40 job_id: (3, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 82, 'last_n_outputs': 32, 'lr': 0.09962053786408019, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.01654378327182815}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 82, 'last_n_outputs': 32, 'lr': 0.09962053786408019, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.01654378327182815}"}}
exception: None

05:51:40 job_callback for (3, 0, 1) started
05:51:40 job_callback for (3, 0, 1) got condition
05:51:40 DISPATCHER: Trying to submit another job.
05:51:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:51:40 Only 6 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
05:51:40 HBMASTER: Trying to run another job!
05:51:40 job_callback for (3, 0, 1) finished
05:51:40 start sampling a new configuration.
05:51:40 best_vector: [0, 0.016664201162580716, 0.4806265675726155, 0.6474437201296197, 0.024186038953990782, 1, 0.848368021435141, 0.8152333361875899], 0.0045857091987192905, 0.3172482787021327, 0.001454808349922231
05:51:40 done sampling a new configuration.
05:51:40 HBMASTER: schedule new run for iteration 3
05:51:40 HBMASTER: trying submitting job (3, 0, 2) to dispatcher
05:51:40 HBMASTER: submitting job (3, 0, 2) to dispatcher
05:51:40 DISPATCHER: trying to submit job (3, 0, 2)
05:51:40 DISPATCHER: trying to notify the job_runner thread.
05:51:40 HBMASTER: job (3, 0, 2) submitted to dispatcher
05:51:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:51:40 DISPATCHER: Trying to submit another job.
05:51:40 DISPATCHER: starting job (3, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
05:51:40 DISPATCHER: job (3, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
05:51:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:51:40 WORKER: start processing job (3, 0, 2)
05:51:40 WORKER: args: ()
05:51:40 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 21, 'last_n_outputs': 25, 'lr': 0.01971911593024652, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.114985485653398}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-469:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:52:21 DISPATCHER: Starting worker discovery
05:52:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:52:21 DISPATCHER: Finished worker discovery
05:53:21 DISPATCHER: Starting worker discovery
05:53:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:53:21 DISPATCHER: Finished worker discovery
05:54:21 DISPATCHER: Starting worker discovery
05:54:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:54:21 DISPATCHER: Finished worker discovery
05:55:21 DISPATCHER: Starting worker discovery
05:55:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:55:21 DISPATCHER: Finished worker discovery
05:56:21 DISPATCHER: Starting worker discovery
05:56:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:56:21 DISPATCHER: Finished worker discovery
05:57:21 DISPATCHER: Starting worker discovery
05:57:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:57:21 DISPATCHER: Finished worker discovery
05:58:21 DISPATCHER: Starting worker discovery
05:58:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:58:21 DISPATCHER: Finished worker discovery
05:59:21 DISPATCHER: Starting worker discovery
05:59:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:59:21 DISPATCHER: Finished worker discovery
06:00:21 DISPATCHER: Starting worker discovery
06:00:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:00:21 DISPATCHER: Finished worker discovery
06:01:21 DISPATCHER: Starting worker discovery
06:01:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:01:21 DISPATCHER: Finished worker discovery
06:02:21 DISPATCHER: Starting worker discovery
06:02:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:02:21 DISPATCHER: Finished worker discovery
06:03:21 DISPATCHER: Starting worker discovery
06:03:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:03:21 DISPATCHER: Finished worker discovery
06:04:21 DISPATCHER: Starting worker discovery
06:04:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:04:21 DISPATCHER: Finished worker discovery
06:05:21 DISPATCHER: Starting worker discovery
06:05:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:05:22 DISPATCHER: Finished worker discovery
06:06:22 DISPATCHER: Starting worker discovery
06:06:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:06:22 DISPATCHER: Finished worker discovery
06:07:22 DISPATCHER: Starting worker discovery
06:07:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:07:22 DISPATCHER: Finished worker discovery
06:08:22 DISPATCHER: Starting worker discovery
06:08:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:08:22 DISPATCHER: Finished worker discovery
06:09:22 DISPATCHER: Starting worker discovery
06:09:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:09:22 DISPATCHER: Finished worker discovery
06:10:22 DISPATCHER: Starting worker discovery
06:10:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:10:22 DISPATCHER: Finished worker discovery
06:11:22 DISPATCHER: Starting worker discovery
06:11:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:11:22 DISPATCHER: Finished worker discovery
06:11:51 WORKER: done with job (3, 0, 2), trying to register it.
06:11:51 WORKER: registered result for job (3, 0, 2) with dispatcher
06:11:51 DISPATCHER: job (3, 0, 2) finished
06:11:51 DISPATCHER: register_result: lock acquired
06:11:51 DISPATCHER: job (3, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
06:11:51 job_id: (3, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 21, 'last_n_outputs': 25, 'lr': 0.01971911593024652, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.114985485653398}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.010160441424065768, 'info': {'data05': 0.010160441424065768, 'config': "{'batch_size': 16, 'hidden_dim': 21, 'last_n_outputs': 25, 'lr': 0.01971911593024652, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.114985485653398}"}}
exception: None

06:11:51 job_callback for (3, 0, 2) started
06:11:51 job_callback for (3, 0, 2) got condition
06:11:51 DISPATCHER: Trying to submit another job.
06:11:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:11:51 Only 7 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
06:11:51 HBMASTER: Trying to run another job!
06:11:51 job_callback for (3, 0, 2) finished
06:11:51 start sampling a new configuration.
06:11:51 best_vector: [1, 0.3111012889264981, 0.9360766119981624, 0.7348109533000641, 0.09097811323246782, 1, 0.13727206061038066, 0.9176512823724041], 0.00978978749558349, 0.13421493011955882, 0.001313935644605069
06:11:51 done sampling a new configuration.
06:11:51 HBMASTER: schedule new run for iteration 3
06:11:51 HBMASTER: trying submitting job (3, 0, 3) to dispatcher
06:11:51 HBMASTER: submitting job (3, 0, 3) to dispatcher
06:11:51 DISPATCHER: trying to submit job (3, 0, 3)
06:11:51 DISPATCHER: trying to notify the job_runner thread.
06:11:51 HBMASTER: job (3, 0, 3) submitted to dispatcher
06:11:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:11:51 DISPATCHER: Trying to submit another job.
06:11:51 DISPATCHER: starting job (3, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:11:51 DISPATCHER: job (3, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:11:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:11:51 WORKER: start processing job (3, 0, 3)
06:11:51 WORKER: args: ()
06:11:51 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 45, 'last_n_outputs': 47, 'lr': 0.029486410449371867, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.1562758407066568}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-470:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:12:22 DISPATCHER: Starting worker discovery
06:12:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:12:22 DISPATCHER: Finished worker discovery
06:13:22 DISPATCHER: Starting worker discovery
06:13:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:13:22 DISPATCHER: Finished worker discovery
06:14:22 DISPATCHER: Starting worker discovery
06:14:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:14:22 DISPATCHER: Finished worker discovery
06:15:22 DISPATCHER: Starting worker discovery
06:15:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:15:22 DISPATCHER: Finished worker discovery
06:16:22 DISPATCHER: Starting worker discovery
06:16:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:16:22 DISPATCHER: Finished worker discovery
06:17:22 DISPATCHER: Starting worker discovery
06:17:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:17:22 DISPATCHER: Finished worker discovery
06:18:22 DISPATCHER: Starting worker discovery
06:18:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:18:22 DISPATCHER: Finished worker discovery
06:19:22 DISPATCHER: Starting worker discovery
06:19:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:19:22 DISPATCHER: Finished worker discovery
06:20:22 DISPATCHER: Starting worker discovery
06:20:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:20:22 DISPATCHER: Finished worker discovery
06:21:22 DISPATCHER: Starting worker discovery
06:21:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:21:22 DISPATCHER: Finished worker discovery
06:22:22 DISPATCHER: Starting worker discovery
06:22:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:22:22 DISPATCHER: Finished worker discovery
06:23:22 DISPATCHER: Starting worker discovery
06:23:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:23:22 DISPATCHER: Finished worker discovery
06:24:22 DISPATCHER: Starting worker discovery
06:24:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:24:22 DISPATCHER: Finished worker discovery
06:25:22 DISPATCHER: Starting worker discovery
06:25:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:25:22 DISPATCHER: Finished worker discovery
06:26:22 DISPATCHER: Starting worker discovery
06:26:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:26:22 DISPATCHER: Finished worker discovery
06:27:22 DISPATCHER: Starting worker discovery
06:27:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:27:22 DISPATCHER: Finished worker discovery
06:28:22 DISPATCHER: Starting worker discovery
06:28:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:28:22 DISPATCHER: Finished worker discovery
06:29:22 DISPATCHER: Starting worker discovery
06:29:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:29:22 DISPATCHER: Finished worker discovery
06:30:22 DISPATCHER: Starting worker discovery
06:30:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:30:22 DISPATCHER: Finished worker discovery
06:31:22 DISPATCHER: Starting worker discovery
06:31:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:31:22 DISPATCHER: Finished worker discovery
06:32:03 WORKER: done with job (3, 0, 3), trying to register it.
06:32:03 WORKER: registered result for job (3, 0, 3) with dispatcher
06:32:03 DISPATCHER: job (3, 0, 3) finished
06:32:03 DISPATCHER: register_result: lock acquired
06:32:03 DISPATCHER: job (3, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
06:32:03 job_id: (3, 0, 3)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 45, 'last_n_outputs': 47, 'lr': 0.029486410449371867, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.1562758407066568}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.09852010147739533, 'info': {'data05': 0.09852010147739533, 'config': "{'batch_size': 32, 'hidden_dim': 45, 'last_n_outputs': 47, 'lr': 0.029486410449371867, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.1562758407066568}"}}
exception: None

06:32:03 job_callback for (3, 0, 3) started
06:32:03 DISPATCHER: Trying to submit another job.
06:32:03 job_callback for (3, 0, 3) got condition
06:32:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:32:03 Only 8 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
06:32:03 HBMASTER: Trying to run another job!
06:32:03 job_callback for (3, 0, 3) finished
06:32:03 start sampling a new configuration.
06:32:03 done sampling a new configuration.
06:32:03 HBMASTER: schedule new run for iteration 4
06:32:03 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
06:32:03 HBMASTER: submitting job (4, 0, 0) to dispatcher
06:32:03 DISPATCHER: trying to submit job (4, 0, 0)
06:32:03 DISPATCHER: trying to notify the job_runner thread.
06:32:03 HBMASTER: job (4, 0, 0) submitted to dispatcher
06:32:03 DISPATCHER: Trying to submit another job.
06:32:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:32:03 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:32:03 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:32:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:32:03 WORKER: start processing job (4, 0, 0)
06:32:03 WORKER: args: ()
06:32:03 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 51, 'last_n_outputs': 46, 'lr': 0.0010507432424931497, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.06935975832758498}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-471:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:32:22 DISPATCHER: Starting worker discovery
06:32:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:32:22 DISPATCHER: Finished worker discovery
06:32:57 WORKER: done with job (4, 0, 0), trying to register it.
06:32:57 WORKER: registered result for job (4, 0, 0) with dispatcher
06:32:57 DISPATCHER: job (4, 0, 0) finished
06:32:57 DISPATCHER: register_result: lock acquired
06:32:57 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
06:32:57 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 51, 'last_n_outputs': 46, 'lr': 0.0010507432424931497, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.06935975832758498}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 51, 'last_n_outputs': 46, 'lr': 0.0010507432424931497, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.06935975832758498}"}}
exception: None

06:32:57 job_callback for (4, 0, 0) started
06:32:57 DISPATCHER: Trying to submit another job.
06:32:57 job_callback for (4, 0, 0) got condition
06:32:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:32:57 HBMASTER: Trying to run another job!
06:32:57 job_callback for (4, 0, 0) finished
06:32:57 start sampling a new configuration.
06:32:57 done sampling a new configuration.
06:32:57 HBMASTER: schedule new run for iteration 4
06:32:57 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
06:32:57 HBMASTER: submitting job (4, 0, 1) to dispatcher
06:32:57 DISPATCHER: trying to submit job (4, 0, 1)
06:32:57 DISPATCHER: trying to notify the job_runner thread.
06:32:57 HBMASTER: job (4, 0, 1) submitted to dispatcher
06:32:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:32:57 DISPATCHER: Trying to submit another job.
06:32:57 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:32:57 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:32:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:32:57 WORKER: start processing job (4, 0, 1)
06:32:57 WORKER: args: ()
06:32:57 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 1, 'lr': 0.08480265435504351, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.07928291765424869}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-472:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:33:22 DISPATCHER: Starting worker discovery
06:33:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:33:22 DISPATCHER: Finished worker discovery
06:33:53 WORKER: done with job (4, 0, 1), trying to register it.
06:33:53 WORKER: registered result for job (4, 0, 1) with dispatcher
06:33:53 DISPATCHER: job (4, 0, 1) finished
06:33:53 DISPATCHER: register_result: lock acquired
06:33:53 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
06:33:53 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 1, 'lr': 0.08480265435504351, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.07928291765424869}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 1, 'lr': 0.08480265435504351, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.07928291765424869}"}}
exception: None

06:33:53 job_callback for (4, 0, 1) started
06:33:53 DISPATCHER: Trying to submit another job.
06:33:53 job_callback for (4, 0, 1) got condition
06:33:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:33:53 HBMASTER: Trying to run another job!
06:33:53 job_callback for (4, 0, 1) finished
06:33:53 start sampling a new configuration.
06:33:53 done sampling a new configuration.
06:33:53 HBMASTER: schedule new run for iteration 4
06:33:53 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
06:33:53 HBMASTER: submitting job (4, 0, 2) to dispatcher
06:33:53 DISPATCHER: trying to submit job (4, 0, 2)
06:33:53 DISPATCHER: trying to notify the job_runner thread.
06:33:53 HBMASTER: job (4, 0, 2) submitted to dispatcher
06:33:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:33:53 DISPATCHER: Trying to submit another job.
06:33:53 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:33:53 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:33:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:33:53 WORKER: start processing job (4, 0, 2)
06:33:53 WORKER: args: ()
06:33:53 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 45, 'last_n_outputs': 30, 'lr': 0.005553363574057995, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.11524094473833806}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-473:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:34:22 DISPATCHER: Starting worker discovery
06:34:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:34:22 DISPATCHER: Finished worker discovery
06:34:47 WORKER: done with job (4, 0, 2), trying to register it.
06:34:47 WORKER: registered result for job (4, 0, 2) with dispatcher
06:34:47 DISPATCHER: job (4, 0, 2) finished
06:34:47 DISPATCHER: register_result: lock acquired
06:34:47 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
06:34:47 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 45, 'last_n_outputs': 30, 'lr': 0.005553363574057995, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.11524094473833806}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 45, 'last_n_outputs': 30, 'lr': 0.005553363574057995, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.11524094473833806}"}}
exception: None

06:34:47 job_callback for (4, 0, 2) started
06:34:47 DISPATCHER: Trying to submit another job.
06:34:47 job_callback for (4, 0, 2) got condition
06:34:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:34:47 HBMASTER: Trying to run another job!
06:34:47 job_callback for (4, 0, 2) finished
06:34:47 start sampling a new configuration.
06:34:47 best_vector: [2, 0.1039789375265131, 0.624946034843619, 0.6078184828216139, 0.05051419373755813, 1, 0.5950859959558864, 0.9327560649507891], 0.005894095999269339, 0.28858266366775465, 0.001700933923382602
06:34:47 done sampling a new configuration.
06:34:47 HBMASTER: schedule new run for iteration 4
06:34:47 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
06:34:47 HBMASTER: submitting job (4, 0, 3) to dispatcher
06:34:47 DISPATCHER: trying to submit job (4, 0, 3)
06:34:47 DISPATCHER: trying to notify the job_runner thread.
06:34:47 HBMASTER: job (4, 0, 3) submitted to dispatcher
06:34:47 DISPATCHER: Trying to submit another job.
06:34:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:34:47 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:34:47 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:34:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:34:47 WORKER: start processing job (4, 0, 3)
06:34:47 WORKER: args: ()
06:34:47 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 28, 'last_n_outputs': 32, 'lr': 0.0164299773846699, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.16350973667943258}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-474:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:35:22 DISPATCHER: Starting worker discovery
06:35:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:35:22 DISPATCHER: Finished worker discovery
06:35:42 WORKER: done with job (4, 0, 3), trying to register it.
06:35:42 WORKER: registered result for job (4, 0, 3) with dispatcher
06:35:42 DISPATCHER: job (4, 0, 3) finished
06:35:42 DISPATCHER: register_result: lock acquired
06:35:42 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
06:35:42 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 28, 'last_n_outputs': 32, 'lr': 0.0164299773846699, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.16350973667943258}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.005061412541263026, 'info': {'data05': -0.005061412541263026, 'config': "{'batch_size': 64, 'hidden_dim': 28, 'last_n_outputs': 32, 'lr': 0.0164299773846699, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.16350973667943258}"}}
exception: None

06:35:42 job_callback for (4, 0, 3) started
06:35:42 job_callback for (4, 0, 3) got condition
06:35:42 DISPATCHER: Trying to submit another job.
06:35:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:35:42 HBMASTER: Trying to run another job!
06:35:42 job_callback for (4, 0, 3) finished
06:35:42 start sampling a new configuration.
06:35:42 best_vector: [1, 0.32317799678798254, 0.6496927862269706, 0.8586724100307344, 0.2285955915889651, 1, 0.7062355007658834, 0.831187641582191], 0.031219490297393866, 0.18941126368125275, 0.005913323108713981
06:35:42 done sampling a new configuration.
06:35:42 HBMASTER: schedule new run for iteration 4
06:35:42 HBMASTER: trying submitting job (4, 0, 4) to dispatcher
06:35:42 HBMASTER: submitting job (4, 0, 4) to dispatcher
06:35:42 DISPATCHER: trying to submit job (4, 0, 4)
06:35:42 DISPATCHER: trying to notify the job_runner thread.
06:35:42 HBMASTER: job (4, 0, 4) submitted to dispatcher
06:35:42 DISPATCHER: Trying to submit another job.
06:35:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:35:42 DISPATCHER: starting job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:35:42 DISPATCHER: job (4, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:35:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:35:42 WORKER: start processing job (4, 0, 4)
06:35:42 WORKER: args: ()
06:35:42 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 46, 'last_n_outputs': 33, 'lr': 0.052160869232031885, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.12061464799683172}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-475:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:36:22 DISPATCHER: Starting worker discovery
06:36:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:36:22 DISPATCHER: Finished worker discovery
06:36:37 WORKER: done with job (4, 0, 4), trying to register it.
06:36:37 WORKER: registered result for job (4, 0, 4) with dispatcher
06:36:37 DISPATCHER: job (4, 0, 4) finished
06:36:37 DISPATCHER: register_result: lock acquired
06:36:37 DISPATCHER: job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
06:36:37 job_id: (4, 0, 4)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 46, 'last_n_outputs': 33, 'lr': 0.052160869232031885, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.12061464799683172}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 46, 'last_n_outputs': 33, 'lr': 0.052160869232031885, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.12061464799683172}"}}
exception: None

06:36:37 job_callback for (4, 0, 4) started
06:36:37 DISPATCHER: Trying to submit another job.
06:36:37 job_callback for (4, 0, 4) got condition
06:36:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:36:37 HBMASTER: Trying to run another job!
06:36:37 job_callback for (4, 0, 4) finished
06:36:37 start sampling a new configuration.
06:36:37 done sampling a new configuration.
06:36:37 HBMASTER: schedule new run for iteration 4
06:36:37 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
06:36:37 HBMASTER: submitting job (4, 0, 5) to dispatcher
06:36:37 DISPATCHER: trying to submit job (4, 0, 5)
06:36:37 DISPATCHER: trying to notify the job_runner thread.
06:36:37 HBMASTER: job (4, 0, 5) submitted to dispatcher
06:36:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:36:37 DISPATCHER: Trying to submit another job.
06:36:37 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:36:37 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:36:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:36:37 WORKER: start processing job (4, 0, 5)
06:36:37 WORKER: args: ()
06:36:37 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 22, 'last_n_outputs': 36, 'lr': 0.0011714661637246002, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.03422854448771682}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-476:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:37:22 DISPATCHER: Starting worker discovery
06:37:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:37:22 DISPATCHER: Finished worker discovery
06:37:31 WORKER: done with job (4, 0, 5), trying to register it.
06:37:31 WORKER: registered result for job (4, 0, 5) with dispatcher
06:37:31 DISPATCHER: job (4, 0, 5) finished
06:37:31 DISPATCHER: register_result: lock acquired
06:37:31 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
06:37:31 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 22, 'last_n_outputs': 36, 'lr': 0.0011714661637246002, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.03422854448771682}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7543470111220776, 'info': {'data05': 0.7543470111220776, 'config': "{'batch_size': 128, 'hidden_dim': 22, 'last_n_outputs': 36, 'lr': 0.0011714661637246002, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.03422854448771682}"}}
exception: None

06:37:31 job_callback for (4, 0, 5) started
06:37:31 DISPATCHER: Trying to submit another job.
06:37:31 job_callback for (4, 0, 5) got condition
06:37:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:37:31 HBMASTER: Trying to run another job!
06:37:31 job_callback for (4, 0, 5) finished
06:37:31 start sampling a new configuration.
06:37:31 done sampling a new configuration.
06:37:31 HBMASTER: schedule new run for iteration 4
06:37:31 HBMASTER: trying submitting job (4, 0, 6) to dispatcher
06:37:31 HBMASTER: submitting job (4, 0, 6) to dispatcher
06:37:31 DISPATCHER: trying to submit job (4, 0, 6)
06:37:31 DISPATCHER: trying to notify the job_runner thread.
06:37:31 HBMASTER: job (4, 0, 6) submitted to dispatcher
06:37:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:37:31 DISPATCHER: Trying to submit another job.
06:37:31 DISPATCHER: starting job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:37:31 DISPATCHER: job (4, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:37:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:37:31 WORKER: start processing job (4, 0, 6)
06:37:31 WORKER: args: ()
06:37:31 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 30, 'last_n_outputs': 45, 'lr': 0.007889440956594133, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.15657865978230348}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-477:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:38:22 DISPATCHER: Starting worker discovery
06:38:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:38:22 DISPATCHER: Finished worker discovery
06:38:26 WORKER: done with job (4, 0, 6), trying to register it.
06:38:26 WORKER: registered result for job (4, 0, 6) with dispatcher
06:38:26 DISPATCHER: job (4, 0, 6) finished
06:38:26 DISPATCHER: register_result: lock acquired
06:38:26 DISPATCHER: job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
06:38:26 job_id: (4, 0, 6)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 30, 'last_n_outputs': 45, 'lr': 0.007889440956594133, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.15657865978230348}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.018932305785879955, 'info': {'data05': -0.018932305785879955, 'config': "{'batch_size': 64, 'hidden_dim': 30, 'last_n_outputs': 45, 'lr': 0.007889440956594133, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.15657865978230348}"}}
exception: None

06:38:26 job_callback for (4, 0, 6) started
06:38:26 DISPATCHER: Trying to submit another job.
06:38:26 job_callback for (4, 0, 6) got condition
06:38:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:38:26 HBMASTER: Trying to run another job!
06:38:26 job_callback for (4, 0, 6) finished
06:38:26 start sampling a new configuration.
06:38:26 done sampling a new configuration.
06:38:26 HBMASTER: schedule new run for iteration 4
06:38:26 HBMASTER: trying submitting job (4, 0, 7) to dispatcher
06:38:26 HBMASTER: submitting job (4, 0, 7) to dispatcher
06:38:26 DISPATCHER: trying to submit job (4, 0, 7)
06:38:26 DISPATCHER: trying to notify the job_runner thread.
06:38:26 HBMASTER: job (4, 0, 7) submitted to dispatcher
06:38:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:38:26 DISPATCHER: Trying to submit another job.
06:38:26 DISPATCHER: starting job (4, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:38:26 DISPATCHER: job (4, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:38:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:38:26 WORKER: start processing job (4, 0, 7)
06:38:26 WORKER: args: ()
06:38:26 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 53, 'last_n_outputs': 28, 'lr': 0.0011239525861246936, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.013991639538552352}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-478:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:39:20 WORKER: done with job (4, 0, 7), trying to register it.
06:39:20 WORKER: registered result for job (4, 0, 7) with dispatcher
06:39:20 DISPATCHER: job (4, 0, 7) finished
06:39:20 DISPATCHER: register_result: lock acquired
06:39:20 DISPATCHER: job (4, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
06:39:20 job_id: (4, 0, 7)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 53, 'last_n_outputs': 28, 'lr': 0.0011239525861246936, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.013991639538552352}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 53, 'last_n_outputs': 28, 'lr': 0.0011239525861246936, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.013991639538552352}"}}
exception: None

06:39:20 job_callback for (4, 0, 7) started
06:39:20 job_callback for (4, 0, 7) got condition
06:39:20 DISPATCHER: Trying to submit another job.
06:39:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:39:20 HBMASTER: Trying to run another job!
06:39:20 job_callback for (4, 0, 7) finished
06:39:20 start sampling a new configuration.
06:39:20 best_vector: [3, 0.8936736469209958, 0.1086355828006263, 0.6914678751188996, 0.13625828624169867, 0, 0.9493498974486712, 0.06959464422990769], 0.019978246365037138, 0.03873706194911988, 0.0007738985670772227
06:39:20 done sampling a new configuration.
06:39:20 HBMASTER: schedule new run for iteration 4
06:39:20 HBMASTER: trying submitting job (4, 0, 8) to dispatcher
06:39:20 HBMASTER: submitting job (4, 0, 8) to dispatcher
06:39:20 DISPATCHER: trying to submit job (4, 0, 8)
06:39:20 DISPATCHER: trying to notify the job_runner thread.
06:39:20 HBMASTER: job (4, 0, 8) submitted to dispatcher
06:39:20 DISPATCHER: Trying to submit another job.
06:39:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:39:20 DISPATCHER: starting job (4, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:39:20 DISPATCHER: job (4, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:39:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:39:20 WORKER: start processing job (4, 0, 8)
06:39:20 WORKER: args: ()
06:39:20 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 92, 'last_n_outputs': 6, 'lr': 0.024151035162850335, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.012318128200439817}, 'budget': 44.44444444444444, 'working_directory': '.'}
06:39:22 DISPATCHER: Starting worker discovery
06:39:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:39:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-479:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:40:15 WORKER: done with job (4, 0, 8), trying to register it.
06:40:15 WORKER: registered result for job (4, 0, 8) with dispatcher
06:40:15 DISPATCHER: job (4, 0, 8) finished
06:40:15 DISPATCHER: register_result: lock acquired
06:40:15 DISPATCHER: job (4, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
06:40:15 job_id: (4, 0, 8)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 92, 'last_n_outputs': 6, 'lr': 0.024151035162850335, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.012318128200439817}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8945857319495109, 'info': {'data05': 0.8945857319495109, 'config': "{'batch_size': 128, 'hidden_dim': 92, 'last_n_outputs': 6, 'lr': 0.024151035162850335, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.012318128200439817}"}}
exception: None

06:40:15 job_callback for (4, 0, 8) started
06:40:15 job_callback for (4, 0, 8) got condition
06:40:15 DISPATCHER: Trying to submit another job.
06:40:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:40:15 HBMASTER: Trying to run another job!
06:40:15 job_callback for (4, 0, 8) finished
06:40:15 start sampling a new configuration.
06:40:15 done sampling a new configuration.
06:40:15 HBMASTER: schedule new run for iteration 4
06:40:15 HBMASTER: trying submitting job (4, 0, 9) to dispatcher
06:40:15 HBMASTER: submitting job (4, 0, 9) to dispatcher
06:40:15 DISPATCHER: trying to submit job (4, 0, 9)
06:40:15 DISPATCHER: trying to notify the job_runner thread.
06:40:15 HBMASTER: job (4, 0, 9) submitted to dispatcher
06:40:15 DISPATCHER: Trying to submit another job.
06:40:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:40:15 DISPATCHER: starting job (4, 0, 9) on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:40:15 DISPATCHER: job (4, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:40:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:40:15 WORKER: start processing job (4, 0, 9)
06:40:15 WORKER: args: ()
06:40:15 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 47, 'last_n_outputs': 41, 'lr': 0.0047248722505816385, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.0824788375334805}, 'budget': 44.44444444444444, 'working_directory': '.'}
06:40:22 DISPATCHER: Starting worker discovery
06:40:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:40:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-480:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:41:09 WORKER: done with job (4, 0, 9), trying to register it.
06:41:09 WORKER: registered result for job (4, 0, 9) with dispatcher
06:41:09 DISPATCHER: job (4, 0, 9) finished
06:41:09 DISPATCHER: register_result: lock acquired
06:41:09 DISPATCHER: job (4, 0, 9) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
06:41:09 job_id: (4, 0, 9)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 47, 'last_n_outputs': 41, 'lr': 0.0047248722505816385, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.0824788375334805}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 47, 'last_n_outputs': 41, 'lr': 0.0047248722505816385, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.0824788375334805}"}}
exception: None

06:41:09 job_callback for (4, 0, 9) started
06:41:09 job_callback for (4, 0, 9) got condition
06:41:09 DISPATCHER: Trying to submit another job.
06:41:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:41:09 HBMASTER: Trying to run another job!
06:41:09 job_callback for (4, 0, 9) finished
06:41:09 start sampling a new configuration.
06:41:09 best_vector: [0, 0.2422466384731703, 0.3610668830215635, 0.43557096573198795, 0.024454161846870187, 0, 0.8556412941000654, 0.9552402105054456], 0.02106544636962101, 0.05545263336829472, 0.001168134474274069
06:41:09 done sampling a new configuration.
06:41:09 HBMASTER: schedule new run for iteration 4
06:41:09 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
06:41:09 HBMASTER: submitting job (4, 0, 10) to dispatcher
06:41:09 DISPATCHER: trying to submit job (4, 0, 10)
06:41:09 DISPATCHER: trying to notify the job_runner thread.
06:41:09 HBMASTER: job (4, 0, 10) submitted to dispatcher
06:41:09 DISPATCHER: Trying to submit another job.
06:41:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:41:09 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:41:09 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:41:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:41:09 WORKER: start processing job (4, 0, 10)
06:41:09 WORKER: args: ()
06:41:09 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 39, 'last_n_outputs': 19, 'lr': 0.007432620031242576, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.174902560305885}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-481:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:41:22 DISPATCHER: Starting worker discovery
06:41:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:41:22 DISPATCHER: Finished worker discovery
06:42:03 WORKER: done with job (4, 0, 10), trying to register it.
06:42:03 WORKER: registered result for job (4, 0, 10) with dispatcher
06:42:03 DISPATCHER: job (4, 0, 10) finished
06:42:03 DISPATCHER: register_result: lock acquired
06:42:03 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
06:42:03 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 39, 'last_n_outputs': 19, 'lr': 0.007432620031242576, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.174902560305885}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3501243994274317, 'info': {'data05': 0.3501243994274317, 'config': "{'batch_size': 16, 'hidden_dim': 39, 'last_n_outputs': 19, 'lr': 0.007432620031242576, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.174902560305885}"}}
exception: None

06:42:03 job_callback for (4, 0, 10) started
06:42:03 DISPATCHER: Trying to submit another job.
06:42:03 job_callback for (4, 0, 10) got condition
06:42:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:42:03 HBMASTER: Trying to run another job!
06:42:03 job_callback for (4, 0, 10) finished
06:42:03 start sampling a new configuration.
06:42:03 done sampling a new configuration.
06:42:03 HBMASTER: schedule new run for iteration 4
06:42:03 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
06:42:03 HBMASTER: submitting job (4, 0, 11) to dispatcher
06:42:03 DISPATCHER: trying to submit job (4, 0, 11)
06:42:03 DISPATCHER: trying to notify the job_runner thread.
06:42:03 HBMASTER: job (4, 0, 11) submitted to dispatcher
06:42:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:42:03 DISPATCHER: Trying to submit another job.
06:42:03 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:42:03 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:42:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:42:03 WORKER: start processing job (4, 0, 11)
06:42:03 WORKER: args: ()
06:42:03 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 45, 'last_n_outputs': 13, 'lr': 0.00394073963568403, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.045985662603367033}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-482:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:42:22 DISPATCHER: Starting worker discovery
06:42:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:42:22 DISPATCHER: Finished worker discovery
06:42:57 WORKER: done with job (4, 0, 11), trying to register it.
06:42:57 WORKER: registered result for job (4, 0, 11) with dispatcher
06:42:57 DISPATCHER: job (4, 0, 11) finished
06:42:57 DISPATCHER: register_result: lock acquired
06:42:57 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
06:42:57 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 45, 'last_n_outputs': 13, 'lr': 0.00394073963568403, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.045985662603367033}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 45, 'last_n_outputs': 13, 'lr': 0.00394073963568403, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.045985662603367033}"}}
exception: None

06:42:57 job_callback for (4, 0, 11) started
06:42:57 DISPATCHER: Trying to submit another job.
06:42:57 job_callback for (4, 0, 11) got condition
06:42:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:42:57 HBMASTER: Trying to run another job!
06:42:57 job_callback for (4, 0, 11) finished
06:42:57 start sampling a new configuration.
06:42:57 best_vector: [3, 0.007932198596119155, 0.7731519771642105, 0.8263484591504313, 0.13289201571418055, 1, 0.018528059404608777, 0.708806346137323], 0.02760671986663614, 0.062390142412280074, 0.0017223871840153504
06:42:57 done sampling a new configuration.
06:42:57 HBMASTER: schedule new run for iteration 4
06:42:57 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
06:42:57 HBMASTER: submitting job (4, 0, 12) to dispatcher
06:42:57 DISPATCHER: trying to submit job (4, 0, 12)
06:42:57 DISPATCHER: trying to notify the job_runner thread.
06:42:57 HBMASTER: job (4, 0, 12) submitted to dispatcher
06:42:57 DISPATCHER: Trying to submit another job.
06:42:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:42:57 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:42:57 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:42:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:42:57 WORKER: start processing job (4, 0, 12)
06:42:57 WORKER: args: ()
06:42:57 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 20, 'last_n_outputs': 39, 'lr': 0.044946607589661486, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.08359461798241434}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-483:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:43:22 DISPATCHER: Starting worker discovery
06:43:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:43:22 DISPATCHER: Finished worker discovery
06:43:52 WORKER: done with job (4, 0, 12), trying to register it.
06:43:52 WORKER: registered result for job (4, 0, 12) with dispatcher
06:43:52 DISPATCHER: job (4, 0, 12) finished
06:43:52 DISPATCHER: register_result: lock acquired
06:43:52 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
06:43:52 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 20, 'last_n_outputs': 39, 'lr': 0.044946607589661486, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.08359461798241434}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.012006911506659177, 'info': {'data05': 0.012006911506659177, 'config': "{'batch_size': 128, 'hidden_dim': 20, 'last_n_outputs': 39, 'lr': 0.044946607589661486, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.08359461798241434}"}}
exception: None

06:43:52 job_callback for (4, 0, 12) started
06:43:52 DISPATCHER: Trying to submit another job.
06:43:52 job_callback for (4, 0, 12) got condition
06:43:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:43:52 HBMASTER: Trying to run another job!
06:43:52 job_callback for (4, 0, 12) finished
06:43:52 start sampling a new configuration.
06:43:52 best_vector: [3, 0.15559878302631475, 0.36926495630289863, 0.6998432894061222, 0.16393739494351625, 0, 0.9594176816127422, 0.781205382915216], 0.007983949142681515, 0.1064430357012082, 0.000849835783631079
06:43:52 done sampling a new configuration.
06:43:52 HBMASTER: schedule new run for iteration 4
06:43:52 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
06:43:52 HBMASTER: submitting job (4, 0, 13) to dispatcher
06:43:52 DISPATCHER: trying to submit job (4, 0, 13)
06:43:52 DISPATCHER: trying to notify the job_runner thread.
06:43:52 HBMASTER: job (4, 0, 13) submitted to dispatcher
06:43:52 DISPATCHER: Trying to submit another job.
06:43:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:43:52 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:43:52 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:43:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:43:52 WORKER: start processing job (4, 0, 13)
06:43:52 WORKER: args: ()
06:43:52 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 32, 'last_n_outputs': 19, 'lr': 0.025100743098988916, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.10384166331324968}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-484:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:44:22 DISPATCHER: Starting worker discovery
06:44:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:44:22 DISPATCHER: Finished worker discovery
06:44:46 WORKER: done with job (4, 0, 13), trying to register it.
06:44:46 WORKER: registered result for job (4, 0, 13) with dispatcher
06:44:46 DISPATCHER: job (4, 0, 13) finished
06:44:46 DISPATCHER: register_result: lock acquired
06:44:46 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
06:44:46 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 32, 'last_n_outputs': 19, 'lr': 0.025100743098988916, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.10384166331324968}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6962711072600114, 'info': {'data05': 0.6962711072600114, 'config': "{'batch_size': 128, 'hidden_dim': 32, 'last_n_outputs': 19, 'lr': 0.025100743098988916, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.10384166331324968}"}}
exception: None

06:44:46 job_callback for (4, 0, 13) started
06:44:46 DISPATCHER: Trying to submit another job.
06:44:46 job_callback for (4, 0, 13) got condition
06:44:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:44:46 HBMASTER: Trying to run another job!
06:44:46 job_callback for (4, 0, 13) finished
06:44:46 start sampling a new configuration.
06:44:46 best_vector: [2, 0.17974449774581844, 0.5697216941739082, 0.8549917389938209, 0.02294658702880671, 1, 0.9696816645895594, 0.9257788085171567], 0.002054730159968825, 0.4079512990523318, 0.0008382298379612877
06:44:46 done sampling a new configuration.
06:44:46 HBMASTER: schedule new run for iteration 4
06:44:46 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
06:44:46 HBMASTER: submitting job (4, 0, 14) to dispatcher
06:44:46 DISPATCHER: trying to submit job (4, 0, 14)
06:44:46 DISPATCHER: trying to notify the job_runner thread.
06:44:46 HBMASTER: job (4, 0, 14) submitted to dispatcher
06:44:46 DISPATCHER: Trying to submit another job.
06:44:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:44:46 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:44:46 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:44:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:44:46 WORKER: start processing job (4, 0, 14)
06:44:46 WORKER: args: ()
06:44:46 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 34, 'last_n_outputs': 29, 'lr': 0.05128418734028144, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.16012752801330524}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-485:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:45:22 DISPATCHER: Starting worker discovery
06:45:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:45:22 DISPATCHER: Finished worker discovery
06:45:40 WORKER: done with job (4, 0, 14), trying to register it.
06:45:40 WORKER: registered result for job (4, 0, 14) with dispatcher
06:45:40 DISPATCHER: job (4, 0, 14) finished
06:45:40 DISPATCHER: register_result: lock acquired
06:45:40 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
06:45:40 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 34, 'last_n_outputs': 29, 'lr': 0.05128418734028144, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.16012752801330524}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.22584153575809174, 'info': {'data05': 0.22584153575809174, 'config': "{'batch_size': 64, 'hidden_dim': 34, 'last_n_outputs': 29, 'lr': 0.05128418734028144, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.16012752801330524}"}}
exception: None

06:45:40 job_callback for (4, 0, 14) started
06:45:40 job_callback for (4, 0, 14) got condition
06:45:40 DISPATCHER: Trying to submit another job.
06:45:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:45:40 HBMASTER: Trying to run another job!
06:45:40 job_callback for (4, 0, 14) finished
06:45:40 start sampling a new configuration.
06:45:41 best_vector: [0, 0.12872986762606786, 0.26875312244836075, 0.49010779415140815, 0.15050317211706898, 1, 0.7132125051101008, 0.9323791549546018], 0.0162038291806719, 0.09245124623092006, 0.0014980642014660655
06:45:41 done sampling a new configuration.
06:45:41 HBMASTER: schedule new run for iteration 4
06:45:41 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
06:45:41 HBMASTER: submitting job (4, 0, 15) to dispatcher
06:45:41 DISPATCHER: trying to submit job (4, 0, 15)
06:45:41 DISPATCHER: trying to notify the job_runner thread.
06:45:41 HBMASTER: job (4, 0, 15) submitted to dispatcher
06:45:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:45:41 DISPATCHER: Trying to submit another job.
06:45:41 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:45:41 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:45:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:45:41 WORKER: start processing job (4, 0, 15)
06:45:41 WORKER: args: ()
06:45:41 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 30, 'last_n_outputs': 14, 'lr': 0.009554667719704793, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.16332521852143905}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-486:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:46:22 DISPATCHER: Starting worker discovery
06:46:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:46:22 DISPATCHER: Finished worker discovery
06:46:35 WORKER: done with job (4, 0, 15), trying to register it.
06:46:35 WORKER: registered result for job (4, 0, 15) with dispatcher
06:46:35 DISPATCHER: job (4, 0, 15) finished
06:46:35 DISPATCHER: register_result: lock acquired
06:46:35 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
06:46:35 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 30, 'last_n_outputs': 14, 'lr': 0.009554667719704793, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.16332521852143905}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.10837572421040799, 'info': {'data05': 0.10837572421040799, 'config': "{'batch_size': 16, 'hidden_dim': 30, 'last_n_outputs': 14, 'lr': 0.009554667719704793, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.16332521852143905}"}}
exception: None

06:46:35 job_callback for (4, 0, 15) started
06:46:35 DISPATCHER: Trying to submit another job.
06:46:35 job_callback for (4, 0, 15) got condition
06:46:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:46:35 HBMASTER: Trying to run another job!
06:46:35 job_callback for (4, 0, 15) finished
06:46:35 start sampling a new configuration.
06:46:35 best_vector: [1, 0.32063919694153525, 0.8802130280148002, 0.7957798854891579, 0.05462978633030444, 0, 0.5137451212672783, 0.8275948766368879], 0.008783694950283428, 0.21683531747777296, 0.0019046152831726183
06:46:35 done sampling a new configuration.
06:46:35 HBMASTER: schedule new run for iteration 4
06:46:35 HBMASTER: trying submitting job (4, 0, 16) to dispatcher
06:46:35 HBMASTER: submitting job (4, 0, 16) to dispatcher
06:46:35 DISPATCHER: trying to submit job (4, 0, 16)
06:46:35 DISPATCHER: trying to notify the job_runner thread.
06:46:35 HBMASTER: job (4, 0, 16) submitted to dispatcher
06:46:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:46:35 DISPATCHER: Trying to submit another job.
06:46:35 DISPATCHER: starting job (4, 0, 16) on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:46:35 DISPATCHER: job (4, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:46:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:46:35 WORKER: start processing job (4, 0, 16)
06:46:35 WORKER: args: ()
06:46:35 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 45, 'last_n_outputs': 45, 'lr': 0.03904449148705104, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.11932343822151499}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-487:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:47:22 DISPATCHER: Starting worker discovery
06:47:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:47:22 DISPATCHER: Finished worker discovery
06:47:29 WORKER: done with job (4, 0, 16), trying to register it.
06:47:29 WORKER: registered result for job (4, 0, 16) with dispatcher
06:47:29 DISPATCHER: job (4, 0, 16) finished
06:47:29 DISPATCHER: register_result: lock acquired
06:47:29 DISPATCHER: job (4, 0, 16) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
06:47:29 job_id: (4, 0, 16)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 45, 'last_n_outputs': 45, 'lr': 0.03904449148705104, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.11932343822151499}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.02596605066623311, 'info': {'data05': 0.02596605066623311, 'config': "{'batch_size': 32, 'hidden_dim': 45, 'last_n_outputs': 45, 'lr': 0.03904449148705104, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.11932343822151499}"}}
exception: None

06:47:29 job_callback for (4, 0, 16) started
06:47:29 job_callback for (4, 0, 16) got condition
06:47:29 DISPATCHER: Trying to submit another job.
06:47:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:47:29 HBMASTER: Trying to run another job!
06:47:29 job_callback for (4, 0, 16) finished
06:47:29 start sampling a new configuration.
06:47:30 best_vector: [0, 0.896356366770383, 0.19778666287287433, 0.9039591173801647, 0.0155203054531807, 0, 0.44903026441438354, 0.20841870670291301], 0.03251343198096451, 0.13642609182831314, 0.004435680457088678
06:47:30 done sampling a new configuration.
06:47:30 HBMASTER: schedule new run for iteration 4
06:47:30 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
06:47:30 HBMASTER: submitting job (4, 0, 17) to dispatcher
06:47:30 DISPATCHER: trying to submit job (4, 0, 17)
06:47:30 DISPATCHER: trying to notify the job_runner thread.
06:47:30 HBMASTER: job (4, 0, 17) submitted to dispatcher
06:47:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:47:30 DISPATCHER: Trying to submit another job.
06:47:30 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:47:30 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:47:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:47:30 WORKER: start processing job (4, 0, 17)
06:47:30 WORKER: args: ()
06:47:30 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 92, 'last_n_outputs': 10, 'lr': 0.06425667289762657, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.018670630711682224}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-488:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:48:22 DISPATCHER: Starting worker discovery
06:48:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:48:22 DISPATCHER: Finished worker discovery
06:48:24 WORKER: done with job (4, 0, 17), trying to register it.
06:48:24 WORKER: registered result for job (4, 0, 17) with dispatcher
06:48:24 DISPATCHER: job (4, 0, 17) finished
06:48:24 DISPATCHER: register_result: lock acquired
06:48:24 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
06:48:24 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 92, 'last_n_outputs': 10, 'lr': 0.06425667289762657, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.018670630711682224}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.19029827786469936, 'info': {'data05': 0.19029827786469936, 'config': "{'batch_size': 16, 'hidden_dim': 92, 'last_n_outputs': 10, 'lr': 0.06425667289762657, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.018670630711682224}"}}
exception: None

06:48:24 job_callback for (4, 0, 17) started
06:48:24 job_callback for (4, 0, 17) got condition
06:48:24 DISPATCHER: Trying to submit another job.
06:48:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:48:24 HBMASTER: Trying to run another job!
06:48:24 job_callback for (4, 0, 17) finished
06:48:24 start sampling a new configuration.
06:48:24 done sampling a new configuration.
06:48:24 HBMASTER: schedule new run for iteration 4
06:48:24 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
06:48:24 HBMASTER: submitting job (4, 0, 18) to dispatcher
06:48:24 DISPATCHER: trying to submit job (4, 0, 18)
06:48:24 DISPATCHER: trying to notify the job_runner thread.
06:48:24 HBMASTER: job (4, 0, 18) submitted to dispatcher
06:48:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:48:24 DISPATCHER: Trying to submit another job.
06:48:24 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:48:24 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:48:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:48:24 WORKER: start processing job (4, 0, 18)
06:48:24 WORKER: args: ()
06:48:24 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 38, 'last_n_outputs': 43, 'lr': 0.08109421992612903, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.1835682877943579}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-489:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:49:18 WORKER: done with job (4, 0, 18), trying to register it.
06:49:18 WORKER: registered result for job (4, 0, 18) with dispatcher
06:49:18 DISPATCHER: job (4, 0, 18) finished
06:49:18 DISPATCHER: register_result: lock acquired
06:49:18 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
06:49:18 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 38, 'last_n_outputs': 43, 'lr': 0.08109421992612903, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.1835682877943579}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 38, 'last_n_outputs': 43, 'lr': 0.08109421992612903, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.1835682877943579}"}}
exception: None

06:49:18 job_callback for (4, 0, 18) started
06:49:18 DISPATCHER: Trying to submit another job.
06:49:18 job_callback for (4, 0, 18) got condition
06:49:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:49:18 HBMASTER: Trying to run another job!
06:49:18 job_callback for (4, 0, 18) finished
06:49:18 start sampling a new configuration.
06:49:18 best_vector: [1, 0.16375858146401745, 0.588172398006149, 0.9682765022754639, 0.024296291670953332, 0, 0.4456349576772671, 0.7648002933841967], 0.007557226043895269, 0.24920425281838096, 0.0018832928696485296
06:49:18 done sampling a new configuration.
06:49:18 HBMASTER: schedule new run for iteration 4
06:49:18 HBMASTER: trying submitting job (4, 0, 19) to dispatcher
06:49:18 HBMASTER: submitting job (4, 0, 19) to dispatcher
06:49:18 DISPATCHER: trying to submit job (4, 0, 19)
06:49:18 DISPATCHER: trying to notify the job_runner thread.
06:49:18 HBMASTER: job (4, 0, 19) submitted to dispatcher
06:49:18 DISPATCHER: Trying to submit another job.
06:49:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:49:18 DISPATCHER: starting job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:49:18 DISPATCHER: job (4, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:49:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:49:18 WORKER: start processing job (4, 0, 19)
06:49:18 WORKER: args: ()
06:49:18 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 33, 'last_n_outputs': 30, 'lr': 0.08640781128129967, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.09886171096800282}, 'budget': 44.44444444444444, 'working_directory': '.'}
06:49:22 DISPATCHER: Starting worker discovery
06:49:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:49:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-490:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:50:13 WORKER: done with job (4, 0, 19), trying to register it.
06:50:13 WORKER: registered result for job (4, 0, 19) with dispatcher
06:50:13 DISPATCHER: job (4, 0, 19) finished
06:50:13 DISPATCHER: register_result: lock acquired
06:50:13 DISPATCHER: job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
06:50:13 job_id: (4, 0, 19)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 33, 'last_n_outputs': 30, 'lr': 0.08640781128129967, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.09886171096800282}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 33, 'last_n_outputs': 30, 'lr': 0.08640781128129967, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.09886171096800282}"}}
exception: None

06:50:13 job_callback for (4, 0, 19) started
06:50:13 DISPATCHER: Trying to submit another job.
06:50:13 job_callback for (4, 0, 19) got condition
06:50:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:50:13 HBMASTER: Trying to run another job!
06:50:13 job_callback for (4, 0, 19) finished
06:50:13 start sampling a new configuration.
06:50:13 best_vector: [1, 0.49665681996885835, 0.45196761628156196, 0.6430210363471142, 0.12716779671329548, 0, 0.962199598982687, 0.5804277619451016], 0.01555524975043788, 0.16024571603180893, 0.002492662134312535
06:50:13 done sampling a new configuration.
06:50:13 HBMASTER: schedule new run for iteration 4
06:50:13 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
06:50:13 HBMASTER: submitting job (4, 0, 20) to dispatcher
06:50:13 DISPATCHER: trying to submit job (4, 0, 20)
06:50:13 DISPATCHER: trying to notify the job_runner thread.
06:50:13 HBMASTER: job (4, 0, 20) submitted to dispatcher
06:50:13 DISPATCHER: Trying to submit another job.
06:50:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:50:13 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:50:13 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:50:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:50:13 WORKER: start processing job (4, 0, 20)
06:50:13 WORKER: args: ()
06:50:13 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 60, 'last_n_outputs': 23, 'lr': 0.019321554873655354, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.05690545872362951}, 'budget': 44.44444444444444, 'working_directory': '.'}
06:50:22 DISPATCHER: Starting worker discovery
06:50:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:50:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-491:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:51:07 WORKER: done with job (4, 0, 20), trying to register it.
06:51:07 WORKER: registered result for job (4, 0, 20) with dispatcher
06:51:07 DISPATCHER: job (4, 0, 20) finished
06:51:07 DISPATCHER: register_result: lock acquired
06:51:07 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
06:51:07 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 60, 'last_n_outputs': 23, 'lr': 0.019321554873655354, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.05690545872362951}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.44939425608252476, 'info': {'data05': 0.44939425608252476, 'config': "{'batch_size': 32, 'hidden_dim': 60, 'last_n_outputs': 23, 'lr': 0.019321554873655354, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.05690545872362951}"}}
exception: None

06:51:07 job_callback for (4, 0, 20) started
06:51:07 DISPATCHER: Trying to submit another job.
06:51:07 job_callback for (4, 0, 20) got condition
06:51:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:51:07 HBMASTER: Trying to run another job!
06:51:07 job_callback for (4, 0, 20) finished
06:51:07 start sampling a new configuration.
06:51:07 best_vector: [2, 0.45801413788700673, 0.47296015753730936, 0.7976269108842569, 0.07324124869956121, 1, 0.8585308214474284, 0.8217055137456403], 0.009770571695739989, 0.5403873721484785, 0.0052798935630492365
06:51:07 done sampling a new configuration.
06:51:07 HBMASTER: schedule new run for iteration 4
06:51:07 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
06:51:07 HBMASTER: submitting job (4, 0, 21) to dispatcher
06:51:07 DISPATCHER: trying to submit job (4, 0, 21)
06:51:07 DISPATCHER: trying to notify the job_runner thread.
06:51:07 HBMASTER: job (4, 0, 21) submitted to dispatcher
06:51:07 DISPATCHER: Trying to submit another job.
06:51:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:51:07 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:51:07 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:51:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:51:07 WORKER: start processing job (4, 0, 21)
06:51:07 WORKER: args: ()
06:51:07 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 57, 'last_n_outputs': 24, 'lr': 0.039378015153693734, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.11723668262816553}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-492:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:51:22 DISPATCHER: Starting worker discovery
06:51:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:51:22 DISPATCHER: Finished worker discovery
06:52:02 WORKER: done with job (4, 0, 21), trying to register it.
06:52:02 WORKER: registered result for job (4, 0, 21) with dispatcher
06:52:02 DISPATCHER: job (4, 0, 21) finished
06:52:02 DISPATCHER: register_result: lock acquired
06:52:02 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
06:52:02 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 57, 'last_n_outputs': 24, 'lr': 0.039378015153693734, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.11723668262816553}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.333146530657591, 'info': {'data05': 0.333146530657591, 'config': "{'batch_size': 64, 'hidden_dim': 57, 'last_n_outputs': 24, 'lr': 0.039378015153693734, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.11723668262816553}"}}
exception: None

06:52:02 job_callback for (4, 0, 21) started
06:52:02 DISPATCHER: Trying to submit another job.
06:52:02 job_callback for (4, 0, 21) got condition
06:52:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:52:02 HBMASTER: Trying to run another job!
06:52:02 job_callback for (4, 0, 21) finished
06:52:02 start sampling a new configuration.
06:52:02 best_vector: [0, 0.3013242416729751, 0.3799192318225781, 0.795834308796651, 0.20356890866949423, 0, 0.9301222343730577, 0.7636170299683296], 0.01296556941675969, 0.16648454574840493, 0.0021585669347186486
06:52:02 done sampling a new configuration.
06:52:02 HBMASTER: schedule new run for iteration 4
06:52:02 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
06:52:02 HBMASTER: submitting job (4, 0, 22) to dispatcher
06:52:02 DISPATCHER: trying to submit job (4, 0, 22)
06:52:02 DISPATCHER: trying to notify the job_runner thread.
06:52:02 HBMASTER: job (4, 0, 22) submitted to dispatcher
06:52:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:52:02 DISPATCHER: Trying to submit another job.
06:52:02 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:52:02 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:52:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:52:02 WORKER: start processing job (4, 0, 22)
06:52:02 WORKER: args: ()
06:52:02 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 44, 'last_n_outputs': 19, 'lr': 0.03905427837940665, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.0985118922414036}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-493:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:52:22 DISPATCHER: Starting worker discovery
06:52:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:52:22 DISPATCHER: Finished worker discovery
06:52:56 WORKER: done with job (4, 0, 22), trying to register it.
06:52:56 WORKER: registered result for job (4, 0, 22) with dispatcher
06:52:56 DISPATCHER: job (4, 0, 22) finished
06:52:56 DISPATCHER: register_result: lock acquired
06:52:56 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
06:52:56 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 44, 'last_n_outputs': 19, 'lr': 0.03905427837940665, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.0985118922414036}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 44, 'last_n_outputs': 19, 'lr': 0.03905427837940665, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.0985118922414036}"}}
exception: None

06:52:56 job_callback for (4, 0, 22) started
06:52:56 job_callback for (4, 0, 22) got condition
06:52:56 DISPATCHER: Trying to submit another job.
06:52:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:52:56 HBMASTER: Trying to run another job!
06:52:56 job_callback for (4, 0, 22) finished
06:52:56 start sampling a new configuration.
06:52:56 done sampling a new configuration.
06:52:56 HBMASTER: schedule new run for iteration 4
06:52:56 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
06:52:56 HBMASTER: submitting job (4, 0, 23) to dispatcher
06:52:56 DISPATCHER: trying to submit job (4, 0, 23)
06:52:56 DISPATCHER: trying to notify the job_runner thread.
06:52:56 HBMASTER: job (4, 0, 23) submitted to dispatcher
06:52:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:52:56 DISPATCHER: Trying to submit another job.
06:52:56 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:52:56 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:52:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:52:56 WORKER: start processing job (4, 0, 23)
06:52:56 WORKER: args: ()
06:52:56 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 60, 'last_n_outputs': 3, 'lr': 0.004859005875944797, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.13534007658099448}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-494:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:53:22 DISPATCHER: Starting worker discovery
06:53:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:53:22 DISPATCHER: Finished worker discovery
06:53:51 WORKER: done with job (4, 0, 23), trying to register it.
06:53:51 WORKER: registered result for job (4, 0, 23) with dispatcher
06:53:51 DISPATCHER: job (4, 0, 23) finished
06:53:51 DISPATCHER: register_result: lock acquired
06:53:51 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
06:53:51 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 60, 'last_n_outputs': 3, 'lr': 0.004859005875944797, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.13534007658099448}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 60, 'last_n_outputs': 3, 'lr': 0.004859005875944797, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.13534007658099448}"}}
exception: None

06:53:51 job_callback for (4, 0, 23) started
06:53:51 job_callback for (4, 0, 23) got condition
06:53:51 DISPATCHER: Trying to submit another job.
06:53:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:53:51 HBMASTER: Trying to run another job!
06:53:51 job_callback for (4, 0, 23) finished
06:53:51 start sampling a new configuration.
06:53:51 best_vector: [1, 0.5381743289172648, 0.9252040512767763, 0.9958491797730065, 0.17598861079701628, 1, 0.6635246475761765, 0.9814085100736409], 0.011436684568129709, 0.06327600743855269, 0.0007236677378053562
06:53:51 done sampling a new configuration.
06:53:51 HBMASTER: schedule new run for iteration 4
06:53:51 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
06:53:51 HBMASTER: submitting job (4, 0, 24) to dispatcher
06:53:51 DISPATCHER: trying to submit job (4, 0, 24)
06:53:51 DISPATCHER: trying to notify the job_runner thread.
06:53:51 HBMASTER: job (4, 0, 24) submitted to dispatcher
06:53:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:53:51 DISPATCHER: Trying to submit another job.
06:53:51 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:53:51 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:53:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:53:51 WORKER: start processing job (4, 0, 24)
06:53:51 WORKER: args: ()
06:53:51 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 63, 'last_n_outputs': 47, 'lr': 0.09810663039692677, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.18916548995429838}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-495:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:54:22 DISPATCHER: Starting worker discovery
06:54:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:54:22 DISPATCHER: Finished worker discovery
06:54:47 WORKER: done with job (4, 0, 24), trying to register it.
06:54:47 WORKER: registered result for job (4, 0, 24) with dispatcher
06:54:47 DISPATCHER: job (4, 0, 24) finished
06:54:47 DISPATCHER: register_result: lock acquired
06:54:47 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
06:54:47 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 63, 'last_n_outputs': 47, 'lr': 0.09810663039692677, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.18916548995429838}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.03707823148091544, 'info': {'data05': 0.03707823148091544, 'config': "{'batch_size': 32, 'hidden_dim': 63, 'last_n_outputs': 47, 'lr': 0.09810663039692677, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.18916548995429838}"}}
exception: None

06:54:47 job_callback for (4, 0, 24) started
06:54:47 DISPATCHER: Trying to submit another job.
06:54:47 job_callback for (4, 0, 24) got condition
06:54:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:54:47 HBMASTER: Trying to run another job!
06:54:47 job_callback for (4, 0, 24) finished
06:54:47 start sampling a new configuration.
06:54:47 best_vector: [1, 0.8851910798775751, 0.4729855106713799, 0.35676199746642123, 0.05219185991661872, 0, 0.7596871046786426, 8.442409683383917e-05], 0.015289748285444361, 0.6201824686582174, 0.00948243383682963
06:54:47 done sampling a new configuration.
06:54:47 HBMASTER: schedule new run for iteration 4
06:54:47 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
06:54:47 HBMASTER: submitting job (4, 0, 25) to dispatcher
06:54:47 DISPATCHER: trying to submit job (4, 0, 25)
06:54:47 DISPATCHER: trying to notify the job_runner thread.
06:54:47 HBMASTER: job (4, 0, 25) submitted to dispatcher
06:54:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:54:47 DISPATCHER: Trying to submit another job.
06:54:47 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:54:47 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:54:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:54:47 WORKER: start processing job (4, 0, 25)
06:54:47 WORKER: args: ()
06:54:47 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 91, 'last_n_outputs': 24, 'lr': 0.005170398238234969, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.01000252943976485}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-496:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:55:22 DISPATCHER: Starting worker discovery
06:55:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:55:22 DISPATCHER: Finished worker discovery
06:55:41 WORKER: done with job (4, 0, 25), trying to register it.
06:55:41 WORKER: registered result for job (4, 0, 25) with dispatcher
06:55:41 DISPATCHER: job (4, 0, 25) finished
06:55:41 DISPATCHER: register_result: lock acquired
06:55:41 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
06:55:41 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 91, 'last_n_outputs': 24, 'lr': 0.005170398238234969, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.01000252943976485}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9494221731316045, 'info': {'data05': 0.9494221731316045, 'config': "{'batch_size': 32, 'hidden_dim': 91, 'last_n_outputs': 24, 'lr': 0.005170398238234969, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.01000252943976485}"}}
exception: None

06:55:41 job_callback for (4, 0, 25) started
06:55:41 job_callback for (4, 0, 25) got condition
06:55:41 DISPATCHER: Trying to submit another job.
06:55:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:55:41 HBMASTER: Trying to run another job!
06:55:41 job_callback for (4, 0, 25) finished
06:55:41 start sampling a new configuration.
06:55:41 best_vector: [2, 0.2616629143104423, 0.3330172530684314, 0.7683097603599094, 0.15636277027424325, 1, 0.8385799312824673, 0.9974379881127271], 0.003816140428433616, 0.29528840481938246, 0.001126862019678917
06:55:41 done sampling a new configuration.
06:55:41 HBMASTER: schedule new run for iteration 4
06:55:41 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
06:55:41 HBMASTER: submitting job (4, 0, 26) to dispatcher
06:55:41 DISPATCHER: trying to submit job (4, 0, 26)
06:55:41 DISPATCHER: trying to notify the job_runner thread.
06:55:41 HBMASTER: job (4, 0, 26) submitted to dispatcher
06:55:41 DISPATCHER: Trying to submit another job.
06:55:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:55:41 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:55:41 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:55:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:55:41 WORKER: start processing job (4, 0, 26)
06:55:41 WORKER: args: ()
06:55:41 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 41, 'last_n_outputs': 17, 'lr': 0.034404838274815046, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.19847085533766914}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-497:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:56:22 DISPATCHER: Starting worker discovery
06:56:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:56:22 DISPATCHER: Finished worker discovery
06:56:36 WORKER: done with job (4, 0, 26), trying to register it.
06:56:36 WORKER: registered result for job (4, 0, 26) with dispatcher
06:56:36 DISPATCHER: job (4, 0, 26) finished
06:56:36 DISPATCHER: register_result: lock acquired
06:56:36 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
06:56:36 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 41, 'last_n_outputs': 17, 'lr': 0.034404838274815046, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.19847085533766914}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1240445577344146, 'info': {'data05': 0.1240445577344146, 'config': "{'batch_size': 64, 'hidden_dim': 41, 'last_n_outputs': 17, 'lr': 0.034404838274815046, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.19847085533766914}"}}
exception: None

06:56:36 job_callback for (4, 0, 26) started
06:56:36 DISPATCHER: Trying to submit another job.
06:56:36 job_callback for (4, 0, 26) got condition
06:56:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:56:36 HBMASTER: Trying to run another job!
06:56:36 job_callback for (4, 0, 26) finished
06:56:36 ITERATION: Advancing config (4, 0, 5) to next budget 133.333333
06:56:36 ITERATION: Advancing config (4, 0, 8) to next budget 133.333333
06:56:36 ITERATION: Advancing config (4, 0, 10) to next budget 133.333333
06:56:36 ITERATION: Advancing config (4, 0, 13) to next budget 133.333333
06:56:36 ITERATION: Advancing config (4, 0, 14) to next budget 133.333333
06:56:36 ITERATION: Advancing config (4, 0, 17) to next budget 133.333333
06:56:36 ITERATION: Advancing config (4, 0, 20) to next budget 133.333333
06:56:36 ITERATION: Advancing config (4, 0, 21) to next budget 133.333333
06:56:36 ITERATION: Advancing config (4, 0, 25) to next budget 133.333333
06:56:36 HBMASTER: schedule new run for iteration 4
06:56:36 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
06:56:36 HBMASTER: submitting job (4, 0, 5) to dispatcher
06:56:36 DISPATCHER: trying to submit job (4, 0, 5)
06:56:36 DISPATCHER: trying to notify the job_runner thread.
06:56:36 HBMASTER: job (4, 0, 5) submitted to dispatcher
06:56:36 DISPATCHER: Trying to submit another job.
06:56:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:56:36 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:56:36 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:56:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:56:36 WORKER: start processing job (4, 0, 5)
06:56:36 WORKER: args: ()
06:56:36 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 22, 'last_n_outputs': 36, 'lr': 0.0011714661637246002, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.03422854448771682}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-498:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:57:22 DISPATCHER: Starting worker discovery
06:57:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:57:22 DISPATCHER: Finished worker discovery
06:58:22 DISPATCHER: Starting worker discovery
06:58:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:58:22 DISPATCHER: Finished worker discovery
06:58:59 WORKER: done with job (4, 0, 5), trying to register it.
06:58:59 WORKER: registered result for job (4, 0, 5) with dispatcher
06:58:59 DISPATCHER: job (4, 0, 5) finished
06:58:59 DISPATCHER: register_result: lock acquired
06:58:59 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
06:58:59 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 22, 'last_n_outputs': 36, 'lr': 0.0011714661637246002, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.03422854448771682}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7295409440366128, 'info': {'data05': 0.7295409440366128, 'config': "{'batch_size': 128, 'hidden_dim': 22, 'last_n_outputs': 36, 'lr': 0.0011714661637246002, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.03422854448771682}"}}
exception: None

06:58:59 job_callback for (4, 0, 5) started
06:58:59 job_callback for (4, 0, 5) got condition
06:58:59 DISPATCHER: Trying to submit another job.
06:58:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:58:59 done building a new model for budget 133.333333 based on 9/16 split
Best loss for this budget:-0.863941





06:58:59 HBMASTER: Trying to run another job!
06:58:59 job_callback for (4, 0, 5) finished
06:58:59 HBMASTER: schedule new run for iteration 4
06:58:59 HBMASTER: trying submitting job (4, 0, 8) to dispatcher
06:58:59 HBMASTER: submitting job (4, 0, 8) to dispatcher
06:58:59 DISPATCHER: trying to submit job (4, 0, 8)
06:58:59 DISPATCHER: trying to notify the job_runner thread.
06:58:59 HBMASTER: job (4, 0, 8) submitted to dispatcher
06:58:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:58:59 DISPATCHER: Trying to submit another job.
06:58:59 DISPATCHER: starting job (4, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:58:59 DISPATCHER: job (4, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
06:58:59 WORKER: start processing job (4, 0, 8)
06:58:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:58:59 WORKER: args: ()
06:58:59 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 92, 'last_n_outputs': 6, 'lr': 0.024151035162850335, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.012318128200439817}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-499:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:59:22 DISPATCHER: Starting worker discovery
06:59:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:59:22 DISPATCHER: Finished worker discovery
07:00:22 DISPATCHER: Starting worker discovery
07:00:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:00:22 DISPATCHER: Finished worker discovery
07:01:22 DISPATCHER: Starting worker discovery
07:01:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:01:22 DISPATCHER: Finished worker discovery
07:01:22 WORKER: done with job (4, 0, 8), trying to register it.
07:01:22 WORKER: registered result for job (4, 0, 8) with dispatcher
07:01:22 DISPATCHER: job (4, 0, 8) finished
07:01:22 DISPATCHER: register_result: lock acquired
07:01:22 DISPATCHER: job (4, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
07:01:22 job_id: (4, 0, 8)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 92, 'last_n_outputs': 6, 'lr': 0.024151035162850335, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.012318128200439817}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9206263774232084, 'info': {'data05': 0.9206263774232084, 'config': "{'batch_size': 128, 'hidden_dim': 92, 'last_n_outputs': 6, 'lr': 0.024151035162850335, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.012318128200439817}"}}
exception: None

07:01:22 job_callback for (4, 0, 8) started
07:01:22 job_callback for (4, 0, 8) got condition
07:01:22 DISPATCHER: Trying to submit another job.
07:01:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:01:22 done building a new model for budget 133.333333 based on 9/17 split
Best loss for this budget:-0.920626





07:01:22 HBMASTER: Trying to run another job!
07:01:22 job_callback for (4, 0, 8) finished
07:01:22 HBMASTER: schedule new run for iteration 4
07:01:22 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
07:01:22 HBMASTER: submitting job (4, 0, 10) to dispatcher
07:01:22 DISPATCHER: trying to submit job (4, 0, 10)
07:01:22 DISPATCHER: trying to notify the job_runner thread.
07:01:22 HBMASTER: job (4, 0, 10) submitted to dispatcher
07:01:22 DISPATCHER: Trying to submit another job.
07:01:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:01:22 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.13101140314513094464
07:01:22 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
07:01:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:01:22 WORKER: start processing job (4, 0, 10)
07:01:22 WORKER: args: ()
07:01:22 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 39, 'last_n_outputs': 19, 'lr': 0.007432620031242576, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.174902560305885}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-500:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:02:22 DISPATCHER: Starting worker discovery
07:02:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:02:22 DISPATCHER: Finished worker discovery
07:03:22 DISPATCHER: Starting worker discovery
07:03:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:03:22 DISPATCHER: Finished worker discovery
07:03:46 WORKER: done with job (4, 0, 10), trying to register it.
07:03:46 WORKER: registered result for job (4, 0, 10) with dispatcher
07:03:46 DISPATCHER: job (4, 0, 10) finished
07:03:46 DISPATCHER: register_result: lock acquired
07:03:46 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
07:03:46 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 39, 'last_n_outputs': 19, 'lr': 0.007432620031242576, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.174902560305885}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2797581311049466, 'info': {'data05': 0.2797581311049466, 'config': "{'batch_size': 16, 'hidden_dim': 39, 'last_n_outputs': 19, 'lr': 0.007432620031242576, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.174902560305885}"}}
exception: None

07:03:46 job_callback for (4, 0, 10) started
07:03:46 job_callback for (4, 0, 10) got condition
07:03:46 DISPATCHER: Trying to submit another job.
07:03:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:03:46 done building a new model for budget 133.333333 based on 9/17 split
Best loss for this budget:-0.920626





07:03:46 HBMASTER: Trying to run another job!
07:03:46 job_callback for (4, 0, 10) finished
07:03:46 HBMASTER: schedule new run for iteration 4
07:03:46 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
07:03:46 HBMASTER: submitting job (4, 0, 13) to dispatcher
07:03:46 DISPATCHER: trying to submit job (4, 0, 13)
07:03:46 DISPATCHER: trying to notify the job_runner thread.
07:03:46 HBMASTER: job (4, 0, 13) submitted to dispatcher
07:03:46 DISPATCHER: Trying to submit another job.
07:03:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:03:46 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.13101140314513094464
07:03:46 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
07:03:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:03:46 WORKER: start processing job (4, 0, 13)
07:03:46 WORKER: args: ()
07:03:46 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 32, 'last_n_outputs': 19, 'lr': 0.025100743098988916, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.10384166331324968}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-501:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:04:22 DISPATCHER: Starting worker discovery
07:04:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:04:22 DISPATCHER: Finished worker discovery
07:05:22 DISPATCHER: Starting worker discovery
07:05:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:05:22 DISPATCHER: Finished worker discovery
07:06:09 WORKER: done with job (4, 0, 13), trying to register it.
07:06:09 WORKER: registered result for job (4, 0, 13) with dispatcher
07:06:09 DISPATCHER: job (4, 0, 13) finished
07:06:09 DISPATCHER: register_result: lock acquired
07:06:09 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
07:06:09 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 32, 'last_n_outputs': 19, 'lr': 0.025100743098988916, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.10384166331324968}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7283255858542569, 'info': {'data05': 0.7283255858542569, 'config': "{'batch_size': 128, 'hidden_dim': 32, 'last_n_outputs': 19, 'lr': 0.025100743098988916, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.10384166331324968}"}}
exception: None

07:06:09 job_callback for (4, 0, 13) started
07:06:09 job_callback for (4, 0, 13) got condition
07:06:09 DISPATCHER: Trying to submit another job.
07:06:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:06:09 done building a new model for budget 133.333333 based on 9/18 split
Best loss for this budget:-0.920626





07:06:09 HBMASTER: Trying to run another job!
07:06:09 job_callback for (4, 0, 13) finished
07:06:09 HBMASTER: schedule new run for iteration 4
07:06:09 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
07:06:09 HBMASTER: submitting job (4, 0, 14) to dispatcher
07:06:09 DISPATCHER: trying to submit job (4, 0, 14)
07:06:09 DISPATCHER: trying to notify the job_runner thread.
07:06:09 HBMASTER: job (4, 0, 14) submitted to dispatcher
07:06:09 DISPATCHER: Trying to submit another job.
07:06:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:06:09 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpuj.13101140314513094464
07:06:09 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
07:06:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:06:09 WORKER: start processing job (4, 0, 14)
07:06:09 WORKER: args: ()
07:06:09 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 34, 'last_n_outputs': 29, 'lr': 0.05128418734028144, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.16012752801330524}, 'budget': 133.33333333333331, 'working_directory': '.'}
07:06:22 DISPATCHER: Starting worker discovery
07:06:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:06:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-502:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:07:22 DISPATCHER: Starting worker discovery
07:07:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:07:22 DISPATCHER: Finished worker discovery
07:08:22 DISPATCHER: Starting worker discovery
07:08:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:08:22 DISPATCHER: Finished worker discovery
07:08:33 WORKER: done with job (4, 0, 14), trying to register it.
07:08:33 WORKER: registered result for job (4, 0, 14) with dispatcher
07:08:33 DISPATCHER: job (4, 0, 14) finished
07:08:33 DISPATCHER: register_result: lock acquired
07:08:33 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
07:08:33 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 34, 'last_n_outputs': 29, 'lr': 0.05128418734028144, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.16012752801330524}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.26859679084368177, 'info': {'data05': 0.26859679084368177, 'config': "{'batch_size': 64, 'hidden_dim': 34, 'last_n_outputs': 29, 'lr': 0.05128418734028144, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.16012752801330524}"}}
exception: None

07:08:33 job_callback for (4, 0, 14) started
07:08:33 job_callback for (4, 0, 14) got condition
07:08:33 DISPATCHER: Trying to submit another job.
07:08:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:08:33 done building a new model for budget 133.333333 based on 9/19 split
Best loss for this budget:-0.920626





07:08:33 HBMASTER: Trying to run another job!
07:08:33 job_callback for (4, 0, 14) finished
07:08:33 HBMASTER: schedule new run for iteration 4
07:08:33 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
07:08:33 HBMASTER: submitting job (4, 0, 17) to dispatcher
07:08:33 DISPATCHER: trying to submit job (4, 0, 17)
07:08:33 DISPATCHER: trying to notify the job_runner thread.
07:08:33 HBMASTER: job (4, 0, 17) submitted to dispatcher
07:08:33 DISPATCHER: Trying to submit another job.
07:08:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:08:33 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.13101140314513094464
07:08:33 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
07:08:33 WORKER: start processing job (4, 0, 17)
07:08:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:08:33 WORKER: args: ()
07:08:33 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 92, 'last_n_outputs': 10, 'lr': 0.06425667289762657, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.018670630711682224}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-503:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:09:22 DISPATCHER: Starting worker discovery
07:09:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:09:22 DISPATCHER: Finished worker discovery
07:10:22 DISPATCHER: Starting worker discovery
07:10:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:10:22 DISPATCHER: Finished worker discovery
07:10:56 WORKER: done with job (4, 0, 17), trying to register it.
07:10:56 WORKER: registered result for job (4, 0, 17) with dispatcher
07:10:56 DISPATCHER: job (4, 0, 17) finished
07:10:56 DISPATCHER: register_result: lock acquired
07:10:56 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
07:10:56 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 92, 'last_n_outputs': 10, 'lr': 0.06425667289762657, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.018670630711682224}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 92, 'last_n_outputs': 10, 'lr': 0.06425667289762657, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.018670630711682224}"}}
exception: None

07:10:56 job_callback for (4, 0, 17) started
07:10:56 job_callback for (4, 0, 17) got condition
07:10:56 DISPATCHER: Trying to submit another job.
07:10:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:10:56 done building a new model for budget 133.333333 based on 9/20 split
Best loss for this budget:-0.920626





07:10:56 HBMASTER: Trying to run another job!
07:10:56 job_callback for (4, 0, 17) finished
07:10:56 HBMASTER: schedule new run for iteration 4
07:10:56 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
07:10:56 HBMASTER: submitting job (4, 0, 20) to dispatcher
07:10:56 DISPATCHER: trying to submit job (4, 0, 20)
07:10:56 DISPATCHER: trying to notify the job_runner thread.
07:10:56 HBMASTER: job (4, 0, 20) submitted to dispatcher
07:10:56 DISPATCHER: Trying to submit another job.
07:10:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:10:56 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.13101140314513094464
07:10:56 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
07:10:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:10:56 WORKER: start processing job (4, 0, 20)
07:10:56 WORKER: args: ()
07:10:56 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 60, 'last_n_outputs': 23, 'lr': 0.019321554873655354, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.05690545872362951}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-504:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:11:22 DISPATCHER: Starting worker discovery
07:11:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:11:22 DISPATCHER: Finished worker discovery
07:12:22 DISPATCHER: Starting worker discovery
07:12:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:12:22 DISPATCHER: Finished worker discovery
07:13:19 WORKER: done with job (4, 0, 20), trying to register it.
07:13:19 WORKER: registered result for job (4, 0, 20) with dispatcher
07:13:19 DISPATCHER: job (4, 0, 20) finished
07:13:19 DISPATCHER: register_result: lock acquired
07:13:19 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
07:13:19 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 60, 'last_n_outputs': 23, 'lr': 0.019321554873655354, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.05690545872362951}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2539008398849531, 'info': {'data05': 0.2539008398849531, 'config': "{'batch_size': 32, 'hidden_dim': 60, 'last_n_outputs': 23, 'lr': 0.019321554873655354, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.05690545872362951}"}}
exception: None

07:13:19 job_callback for (4, 0, 20) started
07:13:19 DISPATCHER: Trying to submit another job.
07:13:19 job_callback for (4, 0, 20) got condition
07:13:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:13:19 done building a new model for budget 133.333333 based on 9/21 split
Best loss for this budget:-0.920626





07:13:19 HBMASTER: Trying to run another job!
07:13:19 job_callback for (4, 0, 20) finished
07:13:19 HBMASTER: schedule new run for iteration 4
07:13:19 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
07:13:19 HBMASTER: submitting job (4, 0, 21) to dispatcher
07:13:19 DISPATCHER: trying to submit job (4, 0, 21)
07:13:19 DISPATCHER: trying to notify the job_runner thread.
07:13:19 HBMASTER: job (4, 0, 21) submitted to dispatcher
07:13:19 DISPATCHER: Trying to submit another job.
07:13:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:13:19 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.13101140314513094464
07:13:19 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
07:13:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:13:19 WORKER: start processing job (4, 0, 21)
07:13:19 WORKER: args: ()
07:13:19 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 57, 'last_n_outputs': 24, 'lr': 0.039378015153693734, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.11723668262816553}, 'budget': 133.33333333333331, 'working_directory': '.'}
07:13:22 DISPATCHER: Starting worker discovery
07:13:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:13:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-505:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:14:22 DISPATCHER: Starting worker discovery
07:14:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:14:22 DISPATCHER: Finished worker discovery
07:15:22 DISPATCHER: Starting worker discovery
07:15:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:15:22 DISPATCHER: Finished worker discovery
07:15:42 WORKER: done with job (4, 0, 21), trying to register it.
07:15:42 WORKER: registered result for job (4, 0, 21) with dispatcher
07:15:42 DISPATCHER: job (4, 0, 21) finished
07:15:42 DISPATCHER: register_result: lock acquired
07:15:42 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
07:15:42 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 57, 'last_n_outputs': 24, 'lr': 0.039378015153693734, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.11723668262816553}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3494429918579347, 'info': {'data05': 0.3494429918579347, 'config': "{'batch_size': 64, 'hidden_dim': 57, 'last_n_outputs': 24, 'lr': 0.039378015153693734, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.11723668262816553}"}}
exception: None

07:15:42 job_callback for (4, 0, 21) started
07:15:42 DISPATCHER: Trying to submit another job.
07:15:42 job_callback for (4, 0, 21) got condition
07:15:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:15:42 done building a new model for budget 133.333333 based on 9/22 split
Best loss for this budget:-0.920626





07:15:42 HBMASTER: Trying to run another job!
07:15:42 job_callback for (4, 0, 21) finished
07:15:42 HBMASTER: schedule new run for iteration 4
07:15:42 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
07:15:42 HBMASTER: submitting job (4, 0, 25) to dispatcher
07:15:42 DISPATCHER: trying to submit job (4, 0, 25)
07:15:42 DISPATCHER: trying to notify the job_runner thread.
07:15:42 HBMASTER: job (4, 0, 25) submitted to dispatcher
07:15:42 DISPATCHER: Trying to submit another job.
07:15:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:15:42 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.13101140314513094464
07:15:42 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
07:15:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:15:42 WORKER: start processing job (4, 0, 25)
07:15:42 WORKER: args: ()
07:15:42 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 91, 'last_n_outputs': 24, 'lr': 0.005170398238234969, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.01000252943976485}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-506:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:16:22 DISPATCHER: Starting worker discovery
07:16:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:16:22 DISPATCHER: Finished worker discovery
07:17:22 DISPATCHER: Starting worker discovery
07:17:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:17:22 DISPATCHER: Finished worker discovery
07:18:06 WORKER: done with job (4, 0, 25), trying to register it.
07:18:06 WORKER: registered result for job (4, 0, 25) with dispatcher
07:18:06 DISPATCHER: job (4, 0, 25) finished
07:18:06 DISPATCHER: register_result: lock acquired
07:18:06 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
07:18:06 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 91, 'last_n_outputs': 24, 'lr': 0.005170398238234969, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.01000252943976485}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.936429499160832, 'info': {'data05': 0.936429499160832, 'config': "{'batch_size': 32, 'hidden_dim': 91, 'last_n_outputs': 24, 'lr': 0.005170398238234969, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.01000252943976485}"}}
exception: None

07:18:06 job_callback for (4, 0, 25) started
07:18:06 job_callback for (4, 0, 25) got condition
07:18:06 DISPATCHER: Trying to submit another job.
07:18:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:18:06 done building a new model for budget 133.333333 based on 9/22 split
Best loss for this budget:-0.936429





07:18:06 HBMASTER: Trying to run another job!
07:18:06 job_callback for (4, 0, 25) finished
07:18:06 ITERATION: Advancing config (4, 0, 5) to next budget 400.000000
07:18:06 ITERATION: Advancing config (4, 0, 8) to next budget 400.000000
07:18:06 ITERATION: Advancing config (4, 0, 25) to next budget 400.000000
07:18:06 HBMASTER: schedule new run for iteration 4
07:18:06 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
07:18:06 HBMASTER: submitting job (4, 0, 5) to dispatcher
07:18:06 DISPATCHER: trying to submit job (4, 0, 5)
07:18:06 DISPATCHER: trying to notify the job_runner thread.
07:18:06 HBMASTER: job (4, 0, 5) submitted to dispatcher
07:18:06 DISPATCHER: Trying to submit another job.
07:18:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:18:06 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
07:18:06 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
07:18:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:18:06 WORKER: start processing job (4, 0, 5)
07:18:06 WORKER: args: ()
07:18:06 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 22, 'last_n_outputs': 36, 'lr': 0.0011714661637246002, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.03422854448771682}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-507:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:18:22 DISPATCHER: Starting worker discovery
07:18:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:18:22 DISPATCHER: Finished worker discovery
07:19:22 DISPATCHER: Starting worker discovery
07:19:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:19:22 DISPATCHER: Finished worker discovery
07:20:22 DISPATCHER: Starting worker discovery
07:20:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:20:22 DISPATCHER: Finished worker discovery
07:21:22 DISPATCHER: Starting worker discovery
07:21:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:21:22 DISPATCHER: Finished worker discovery
07:22:22 DISPATCHER: Starting worker discovery
07:22:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:22:22 DISPATCHER: Finished worker discovery
07:23:22 DISPATCHER: Starting worker discovery
07:23:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:23:22 DISPATCHER: Finished worker discovery
07:24:22 DISPATCHER: Starting worker discovery
07:24:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:24:22 DISPATCHER: Finished worker discovery
07:24:56 WORKER: done with job (4, 0, 5), trying to register it.
07:24:56 WORKER: registered result for job (4, 0, 5) with dispatcher
07:24:56 DISPATCHER: job (4, 0, 5) finished
07:24:56 DISPATCHER: register_result: lock acquired
07:24:56 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
07:24:56 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 22, 'last_n_outputs': 36, 'lr': 0.0011714661637246002, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.03422854448771682}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7392688022472322, 'info': {'data05': 0.7392688022472322, 'config': "{'batch_size': 128, 'hidden_dim': 22, 'last_n_outputs': 36, 'lr': 0.0011714661637246002, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.03422854448771682}"}}
exception: None

07:24:56 job_callback for (4, 0, 5) started
07:24:56 DISPATCHER: Trying to submit another job.
07:24:56 job_callback for (4, 0, 5) got condition
07:24:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:24:56 HBMASTER: Trying to run another job!
07:24:56 job_callback for (4, 0, 5) finished
07:24:56 HBMASTER: schedule new run for iteration 4
07:24:56 HBMASTER: trying submitting job (4, 0, 8) to dispatcher
07:24:56 HBMASTER: submitting job (4, 0, 8) to dispatcher
07:24:56 DISPATCHER: trying to submit job (4, 0, 8)
07:24:56 DISPATCHER: trying to notify the job_runner thread.
07:24:56 HBMASTER: job (4, 0, 8) submitted to dispatcher
07:24:56 DISPATCHER: Trying to submit another job.
07:24:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:24:56 DISPATCHER: starting job (4, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464
07:24:56 DISPATCHER: job (4, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
07:24:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:24:56 WORKER: start processing job (4, 0, 8)
07:24:56 WORKER: args: ()
07:24:56 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 92, 'last_n_outputs': 6, 'lr': 0.024151035162850335, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.012318128200439817}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-508:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:25:22 DISPATCHER: Starting worker discovery
07:25:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:25:22 DISPATCHER: Finished worker discovery
07:26:22 DISPATCHER: Starting worker discovery
07:26:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:26:22 DISPATCHER: Finished worker discovery
07:27:22 DISPATCHER: Starting worker discovery
07:27:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:27:22 DISPATCHER: Finished worker discovery
07:28:22 DISPATCHER: Starting worker discovery
07:28:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:28:22 DISPATCHER: Finished worker discovery
07:29:22 DISPATCHER: Starting worker discovery
07:29:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:29:22 DISPATCHER: Finished worker discovery
07:30:22 DISPATCHER: Starting worker discovery
07:30:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:30:22 DISPATCHER: Finished worker discovery
07:31:22 DISPATCHER: Starting worker discovery
07:31:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:31:22 DISPATCHER: Finished worker discovery
07:31:46 WORKER: done with job (4, 0, 8), trying to register it.
07:31:46 WORKER: registered result for job (4, 0, 8) with dispatcher
07:31:46 DISPATCHER: job (4, 0, 8) finished
07:31:46 DISPATCHER: register_result: lock acquired
07:31:46 DISPATCHER: job (4, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
07:31:46 job_id: (4, 0, 8)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 92, 'last_n_outputs': 6, 'lr': 0.024151035162850335, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.012318128200439817}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8508952940564625, 'info': {'data05': 0.8508952940564625, 'config': "{'batch_size': 128, 'hidden_dim': 92, 'last_n_outputs': 6, 'lr': 0.024151035162850335, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.012318128200439817}"}}
exception: None

07:31:46 job_callback for (4, 0, 8) started
07:31:46 DISPATCHER: Trying to submit another job.
07:31:46 job_callback for (4, 0, 8) got condition
07:31:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:31:46 HBMASTER: Trying to run another job!
07:31:46 job_callback for (4, 0, 8) finished
07:31:46 HBMASTER: schedule new run for iteration 4
07:31:46 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
07:31:46 HBMASTER: submitting job (4, 0, 25) to dispatcher
07:31:46 DISPATCHER: trying to submit job (4, 0, 25)
07:31:46 DISPATCHER: trying to notify the job_runner thread.
07:31:46 HBMASTER: job (4, 0, 25) submitted to dispatcher
07:31:46 DISPATCHER: Trying to submit another job.
07:31:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:31:46 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.13101140314513094464
07:31:46 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
07:31:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:31:46 WORKER: start processing job (4, 0, 25)
07:31:46 WORKER: args: ()
07:31:46 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 91, 'last_n_outputs': 24, 'lr': 0.005170398238234969, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.01000252943976485}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-509:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:32:22 DISPATCHER: Starting worker discovery
07:32:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:32:22 DISPATCHER: Finished worker discovery
07:33:22 DISPATCHER: Starting worker discovery
07:33:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:33:22 DISPATCHER: Finished worker discovery
07:34:22 DISPATCHER: Starting worker discovery
07:34:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:34:22 DISPATCHER: Finished worker discovery
07:35:22 DISPATCHER: Starting worker discovery
07:35:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:35:22 DISPATCHER: Finished worker discovery
07:36:22 DISPATCHER: Starting worker discovery
07:36:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:36:22 DISPATCHER: Finished worker discovery
07:37:22 DISPATCHER: Starting worker discovery
07:37:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:37:22 DISPATCHER: Finished worker discovery
07:38:22 DISPATCHER: Starting worker discovery
07:38:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:38:22 DISPATCHER: Finished worker discovery
07:38:36 WORKER: done with job (4, 0, 25), trying to register it.
07:38:36 WORKER: registered result for job (4, 0, 25) with dispatcher
07:38:36 DISPATCHER: job (4, 0, 25) finished
07:38:36 DISPATCHER: register_result: lock acquired
07:38:36 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
07:38:36 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 91, 'last_n_outputs': 24, 'lr': 0.005170398238234969, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.01000252943976485}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.931804466913036, 'info': {'data05': 0.931804466913036, 'config': "{'batch_size': 32, 'hidden_dim': 91, 'last_n_outputs': 24, 'lr': 0.005170398238234969, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.01000252943976485}"}}
exception: None

07:38:36 job_callback for (4, 0, 25) started
07:38:36 job_callback for (4, 0, 25) got condition
07:38:36 DISPATCHER: Trying to submit another job.
07:38:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:38:36 HBMASTER: Trying to run another job!
07:38:36 job_callback for (4, 0, 25) finished
07:38:36 ITERATION: Advancing config (4, 0, 25) to next budget 1200.000000
07:38:36 HBMASTER: schedule new run for iteration 4
07:38:36 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
07:38:36 HBMASTER: submitting job (4, 0, 25) to dispatcher
07:38:36 DISPATCHER: trying to submit job (4, 0, 25)
07:38:36 DISPATCHER: trying to notify the job_runner thread.
07:38:36 HBMASTER: job (4, 0, 25) submitted to dispatcher
07:38:36 DISPATCHER: Trying to submit another job.
07:38:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:38:36 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.13101140314513094464
07:38:36 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
07:38:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:38:36 WORKER: start processing job (4, 0, 25)
07:38:36 WORKER: args: ()
07:38:36 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 91, 'last_n_outputs': 24, 'lr': 0.005170398238234969, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.01000252943976485}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-510:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:39:22 DISPATCHER: Starting worker discovery
07:39:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:39:22 DISPATCHER: Finished worker discovery
07:40:22 DISPATCHER: Starting worker discovery
07:40:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:40:22 DISPATCHER: Finished worker discovery
07:41:22 DISPATCHER: Starting worker discovery
07:41:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:41:22 DISPATCHER: Finished worker discovery
07:42:22 DISPATCHER: Starting worker discovery
07:42:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:42:22 DISPATCHER: Finished worker discovery
07:43:22 DISPATCHER: Starting worker discovery
07:43:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:43:22 DISPATCHER: Finished worker discovery
07:44:22 DISPATCHER: Starting worker discovery
07:44:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:44:22 DISPATCHER: Finished worker discovery
07:45:22 DISPATCHER: Starting worker discovery
07:45:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:45:22 DISPATCHER: Finished worker discovery
07:46:22 DISPATCHER: Starting worker discovery
07:46:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:46:22 DISPATCHER: Finished worker discovery
07:47:22 DISPATCHER: Starting worker discovery
07:47:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:47:22 DISPATCHER: Finished worker discovery
07:48:22 DISPATCHER: Starting worker discovery
07:48:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:48:22 DISPATCHER: Finished worker discovery
07:49:22 DISPATCHER: Starting worker discovery
07:49:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:49:22 DISPATCHER: Finished worker discovery
07:50:22 DISPATCHER: Starting worker discovery
07:50:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:50:22 DISPATCHER: Finished worker discovery
07:51:22 DISPATCHER: Starting worker discovery
07:51:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:51:22 DISPATCHER: Finished worker discovery
07:52:22 DISPATCHER: Starting worker discovery
07:52:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:52:22 DISPATCHER: Finished worker discovery
07:53:22 DISPATCHER: Starting worker discovery
07:53:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:53:22 DISPATCHER: Finished worker discovery
07:54:22 DISPATCHER: Starting worker discovery
07:54:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:54:22 DISPATCHER: Finished worker discovery
07:55:22 DISPATCHER: Starting worker discovery
07:55:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:55:22 DISPATCHER: Finished worker discovery
07:56:22 DISPATCHER: Starting worker discovery
07:56:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:56:22 DISPATCHER: Finished worker discovery
07:57:22 DISPATCHER: Starting worker discovery
07:57:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:57:22 DISPATCHER: Finished worker discovery
07:58:22 DISPATCHER: Starting worker discovery
07:58:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:58:22 DISPATCHER: Finished worker discovery
07:58:47 WORKER: done with job (4, 0, 25), trying to register it.
07:58:47 WORKER: registered result for job (4, 0, 25) with dispatcher
07:58:47 DISPATCHER: job (4, 0, 25) finished
07:58:47 DISPATCHER: register_result: lock acquired
07:58:47 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
07:58:47 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 91, 'last_n_outputs': 24, 'lr': 0.005170398238234969, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.01000252943976485}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.8971314343131744, 'info': {'data05': 0.8971314343131744, 'config': "{'batch_size': 32, 'hidden_dim': 91, 'last_n_outputs': 24, 'lr': 0.005170398238234969, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.01000252943976485}"}}
exception: None

07:58:47 job_callback for (4, 0, 25) started
07:58:47 job_callback for (4, 0, 25) got condition
07:58:47 DISPATCHER: Trying to submit another job.
07:58:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:58:47 HBMASTER: Trying to run another job!
07:58:47 job_callback for (4, 0, 25) finished
07:58:47 start sampling a new configuration.
07:58:47 done sampling a new configuration.
07:58:47 HBMASTER: schedule new run for iteration 5
07:58:47 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
07:58:47 HBMASTER: submitting job (5, 0, 0) to dispatcher
07:58:47 DISPATCHER: trying to submit job (5, 0, 0)
07:58:47 DISPATCHER: trying to notify the job_runner thread.
07:58:47 HBMASTER: job (5, 0, 0) submitted to dispatcher
07:58:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:58:47 DISPATCHER: Trying to submit another job.
07:58:47 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
07:58:47 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
07:58:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:58:47 WORKER: start processing job (5, 0, 0)
07:58:47 WORKER: args: ()
07:58:47 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 30, 'last_n_outputs': 4, 'lr': 0.0020594444015920904, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.0347682541247514}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-511:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:59:22 DISPATCHER: Starting worker discovery
07:59:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:59:22 DISPATCHER: Finished worker discovery
08:00:22 DISPATCHER: Starting worker discovery
08:00:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:00:22 DISPATCHER: Finished worker discovery
08:01:11 WORKER: done with job (5, 0, 0), trying to register it.
08:01:11 WORKER: registered result for job (5, 0, 0) with dispatcher
08:01:11 DISPATCHER: job (5, 0, 0) finished
08:01:11 DISPATCHER: register_result: lock acquired
08:01:11 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
08:01:11 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 30, 'last_n_outputs': 4, 'lr': 0.0020594444015920904, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.0347682541247514}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 30, 'last_n_outputs': 4, 'lr': 0.0020594444015920904, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.0347682541247514}"}}
exception: None

08:01:11 job_callback for (5, 0, 0) started
08:01:11 DISPATCHER: Trying to submit another job.
08:01:11 job_callback for (5, 0, 0) got condition
08:01:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:01:11 done building a new model for budget 133.333333 based on 9/23 split
Best loss for this budget:-0.936429





08:01:11 HBMASTER: Trying to run another job!
08:01:11 job_callback for (5, 0, 0) finished
08:01:11 start sampling a new configuration.
08:01:11 done sampling a new configuration.
08:01:11 HBMASTER: schedule new run for iteration 5
08:01:11 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
08:01:11 HBMASTER: submitting job (5, 0, 1) to dispatcher
08:01:11 DISPATCHER: trying to submit job (5, 0, 1)
08:01:11 DISPATCHER: trying to notify the job_runner thread.
08:01:11 HBMASTER: job (5, 0, 1) submitted to dispatcher
08:01:11 DISPATCHER: Trying to submit another job.
08:01:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:01:11 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
08:01:11 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
08:01:11 WORKER: start processing job (5, 0, 1)
08:01:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:01:11 WORKER: args: ()
08:01:11 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 42, 'last_n_outputs': 48, 'lr': 0.03782501948001183, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.013595520872533438}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:01:22 DISPATCHER: Starting worker discovery
08:01:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:01:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-512:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:02:22 DISPATCHER: Starting worker discovery
08:02:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:02:22 DISPATCHER: Finished worker discovery
08:03:22 DISPATCHER: Starting worker discovery
08:03:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:03:22 DISPATCHER: Finished worker discovery
08:03:36 WORKER: done with job (5, 0, 1), trying to register it.
08:03:36 WORKER: registered result for job (5, 0, 1) with dispatcher
08:03:36 DISPATCHER: job (5, 0, 1) finished
08:03:36 DISPATCHER: register_result: lock acquired
08:03:36 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
08:03:36 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 42, 'last_n_outputs': 48, 'lr': 0.03782501948001183, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.013595520872533438}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.03471906014062443, 'info': {'data05': 0.03471906014062443, 'config': "{'batch_size': 64, 'hidden_dim': 42, 'last_n_outputs': 48, 'lr': 0.03782501948001183, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.013595520872533438}"}}
exception: None

08:03:36 job_callback for (5, 0, 1) started
08:03:36 job_callback for (5, 0, 1) got condition
08:03:36 DISPATCHER: Trying to submit another job.
08:03:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:03:36 done building a new model for budget 133.333333 based on 9/24 split
Best loss for this budget:-0.936429





08:03:36 HBMASTER: Trying to run another job!
08:03:36 job_callback for (5, 0, 1) finished
08:03:36 start sampling a new configuration.
08:03:36 best_vector: [2, 0.8009780377307647, 0.25774454324922447, 0.32994462382698486, 0.11002854234200912, 0, 0.7458580424317435, 0.018831959848303048], 0.008218327503451016, 1.2588681326217008, 0.010345790597542944
08:03:36 done sampling a new configuration.
08:03:36 HBMASTER: schedule new run for iteration 5
08:03:36 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
08:03:36 HBMASTER: submitting job (5, 0, 2) to dispatcher
08:03:36 DISPATCHER: trying to submit job (5, 0, 2)
08:03:36 DISPATCHER: trying to notify the job_runner thread.
08:03:36 HBMASTER: job (5, 0, 2) submitted to dispatcher
08:03:36 DISPATCHER: Trying to submit another job.
08:03:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:03:36 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
08:03:36 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
08:03:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:03:36 WORKER: start processing job (5, 0, 2)
08:03:36 WORKER: args: ()
08:03:36 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 84, 'last_n_outputs': 13, 'lr': 0.004569716393544644, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.010580372173447422}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-513:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:04:22 DISPATCHER: Starting worker discovery
08:04:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:04:22 DISPATCHER: Finished worker discovery
08:05:22 DISPATCHER: Starting worker discovery
08:05:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:05:22 DISPATCHER: Finished worker discovery
08:05:59 WORKER: done with job (5, 0, 2), trying to register it.
08:05:59 WORKER: registered result for job (5, 0, 2) with dispatcher
08:05:59 DISPATCHER: job (5, 0, 2) finished
08:05:59 DISPATCHER: register_result: lock acquired
08:05:59 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
08:05:59 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 84, 'last_n_outputs': 13, 'lr': 0.004569716393544644, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.010580372173447422}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9583962521778266, 'info': {'data05': 0.9583962521778266, 'config': "{'batch_size': 64, 'hidden_dim': 84, 'last_n_outputs': 13, 'lr': 0.004569716393544644, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.010580372173447422}"}}
exception: None

08:05:59 job_callback for (5, 0, 2) started
08:05:59 job_callback for (5, 0, 2) got condition
08:05:59 DISPATCHER: Trying to submit another job.
08:05:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:05:59 done building a new model for budget 133.333333 based on 9/25 split
Best loss for this budget:-0.958396





08:05:59 HBMASTER: Trying to run another job!
08:05:59 job_callback for (5, 0, 2) finished
08:05:59 start sampling a new configuration.
08:05:59 done sampling a new configuration.
08:05:59 HBMASTER: schedule new run for iteration 5
08:05:59 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
08:05:59 HBMASTER: submitting job (5, 0, 3) to dispatcher
08:05:59 DISPATCHER: trying to submit job (5, 0, 3)
08:05:59 DISPATCHER: trying to notify the job_runner thread.
08:05:59 HBMASTER: job (5, 0, 3) submitted to dispatcher
08:05:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:05:59 DISPATCHER: Trying to submit another job.
08:05:59 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
08:05:59 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
08:05:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:05:59 WORKER: start processing job (5, 0, 3)
08:05:59 WORKER: args: ()
08:05:59 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 80, 'last_n_outputs': 36, 'lr': 0.02228918108639953, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.15803674724069705}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-514:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:06:22 DISPATCHER: Starting worker discovery
08:06:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:06:22 DISPATCHER: Finished worker discovery
08:07:22 DISPATCHER: Starting worker discovery
08:07:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:07:22 DISPATCHER: Finished worker discovery
08:08:22 DISPATCHER: Starting worker discovery
08:08:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:08:22 DISPATCHER: Finished worker discovery
08:08:24 WORKER: done with job (5, 0, 3), trying to register it.
08:08:24 WORKER: registered result for job (5, 0, 3) with dispatcher
08:08:24 DISPATCHER: job (5, 0, 3) finished
08:08:24 DISPATCHER: register_result: lock acquired
08:08:24 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
08:08:24 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 80, 'last_n_outputs': 36, 'lr': 0.02228918108639953, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.15803674724069705}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 80, 'last_n_outputs': 36, 'lr': 0.02228918108639953, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.15803674724069705}"}}
exception: None

08:08:24 job_callback for (5, 0, 3) started
08:08:24 job_callback for (5, 0, 3) got condition
08:08:24 DISPATCHER: Trying to submit another job.
08:08:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:08:24 done building a new model for budget 133.333333 based on 9/26 split
Best loss for this budget:-0.958396





08:08:24 HBMASTER: Trying to run another job!
08:08:24 job_callback for (5, 0, 3) finished
08:08:24 start sampling a new configuration.
08:08:24 best_vector: [0, 0.5936331631762632, 0.008187749657836696, 0.5367261466127284, 0.13237248896377077, 0, 0.7342993835463685, 0.15953258436630932], 0.00985061151316333, 1.1041352880777453, 0.010876407780828547
08:08:24 done sampling a new configuration.
08:08:24 HBMASTER: schedule new run for iteration 5
08:08:24 HBMASTER: trying submitting job (5, 0, 4) to dispatcher
08:08:24 HBMASTER: submitting job (5, 0, 4) to dispatcher
08:08:24 DISPATCHER: trying to submit job (5, 0, 4)
08:08:24 DISPATCHER: trying to notify the job_runner thread.
08:08:24 HBMASTER: job (5, 0, 4) submitted to dispatcher
08:08:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:08:24 DISPATCHER: Trying to submit another job.
08:08:24 DISPATCHER: starting job (5, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464
08:08:24 DISPATCHER: job (5, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
08:08:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:08:24 WORKER: start processing job (5, 0, 4)
08:08:24 WORKER: args: ()
08:08:24 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 68, 'last_n_outputs': 1, 'lr': 0.011842742686166561, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.016127114803123833}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-515:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:09:22 DISPATCHER: Starting worker discovery
08:09:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:09:22 DISPATCHER: Finished worker discovery
08:10:22 DISPATCHER: Starting worker discovery
08:10:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:10:22 DISPATCHER: Finished worker discovery
08:10:47 WORKER: done with job (5, 0, 4), trying to register it.
08:10:47 WORKER: registered result for job (5, 0, 4) with dispatcher
08:10:47 DISPATCHER: job (5, 0, 4) finished
08:10:47 DISPATCHER: register_result: lock acquired
08:10:47 DISPATCHER: job (5, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
08:10:47 job_id: (5, 0, 4)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 68, 'last_n_outputs': 1, 'lr': 0.011842742686166561, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.016127114803123833}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.36080412102271736, 'info': {'data05': 0.36080412102271736, 'config': "{'batch_size': 16, 'hidden_dim': 68, 'last_n_outputs': 1, 'lr': 0.011842742686166561, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.016127114803123833}"}}
exception: None

08:10:47 job_callback for (5, 0, 4) started
08:10:47 job_callback for (5, 0, 4) got condition
08:10:47 DISPATCHER: Trying to submit another job.
08:10:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:10:47 done building a new model for budget 133.333333 based on 9/27 split
Best loss for this budget:-0.958396





08:10:47 HBMASTER: Trying to run another job!
08:10:47 job_callback for (5, 0, 4) finished
08:10:47 start sampling a new configuration.
08:10:47 done sampling a new configuration.
08:10:47 HBMASTER: schedule new run for iteration 5
08:10:47 HBMASTER: trying submitting job (5, 0, 5) to dispatcher
08:10:47 HBMASTER: submitting job (5, 0, 5) to dispatcher
08:10:47 DISPATCHER: trying to submit job (5, 0, 5)
08:10:47 DISPATCHER: trying to notify the job_runner thread.
08:10:47 HBMASTER: job (5, 0, 5) submitted to dispatcher
08:10:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:10:48 DISPATCHER: Trying to submit another job.
08:10:48 DISPATCHER: starting job (5, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
08:10:48 DISPATCHER: job (5, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
08:10:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:10:48 WORKER: start processing job (5, 0, 5)
08:10:48 WORKER: args: ()
08:10:48 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 74, 'last_n_outputs': 34, 'lr': 0.021068647973772156, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.04106498387909418}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-516:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:11:22 DISPATCHER: Starting worker discovery
08:11:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:11:22 DISPATCHER: Finished worker discovery
08:12:22 DISPATCHER: Starting worker discovery
08:12:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:12:22 DISPATCHER: Finished worker discovery
08:13:12 WORKER: done with job (5, 0, 5), trying to register it.
08:13:12 WORKER: registered result for job (5, 0, 5) with dispatcher
08:13:12 DISPATCHER: job (5, 0, 5) finished
08:13:12 DISPATCHER: register_result: lock acquired
08:13:12 DISPATCHER: job (5, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
08:13:12 job_id: (5, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 74, 'last_n_outputs': 34, 'lr': 0.021068647973772156, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.04106498387909418}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 74, 'last_n_outputs': 34, 'lr': 0.021068647973772156, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.04106498387909418}"}}
exception: None

08:13:12 job_callback for (5, 0, 5) started
08:13:12 job_callback for (5, 0, 5) got condition
08:13:12 DISPATCHER: Trying to submit another job.
08:13:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:13:12 done building a new model for budget 133.333333 based on 9/28 split
Best loss for this budget:-0.958396





08:13:12 HBMASTER: Trying to run another job!
08:13:12 job_callback for (5, 0, 5) finished
08:13:12 start sampling a new configuration.
08:13:12 done sampling a new configuration.
08:13:12 HBMASTER: schedule new run for iteration 5
08:13:12 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
08:13:12 HBMASTER: submitting job (5, 0, 6) to dispatcher
08:13:12 DISPATCHER: trying to submit job (5, 0, 6)
08:13:12 DISPATCHER: trying to notify the job_runner thread.
08:13:12 HBMASTER: job (5, 0, 6) submitted to dispatcher
08:13:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:13:12 DISPATCHER: Trying to submit another job.
08:13:12 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464
08:13:12 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
08:13:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:13:12 WORKER: start processing job (5, 0, 6)
08:13:12 WORKER: args: ()
08:13:12 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 42, 'last_n_outputs': 4, 'lr': 0.024277442422100007, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.010526393133412644}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:13:22 DISPATCHER: Starting worker discovery
08:13:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:13:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-517:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:14:22 DISPATCHER: Starting worker discovery
08:14:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:14:22 DISPATCHER: Finished worker discovery
08:15:22 DISPATCHER: Starting worker discovery
08:15:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:15:22 DISPATCHER: Finished worker discovery
08:15:35 WORKER: done with job (5, 0, 6), trying to register it.
08:15:35 WORKER: registered result for job (5, 0, 6) with dispatcher
08:15:35 DISPATCHER: job (5, 0, 6) finished
08:15:35 DISPATCHER: register_result: lock acquired
08:15:35 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
08:15:35 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 42, 'last_n_outputs': 4, 'lr': 0.024277442422100007, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.010526393133412644}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 42, 'last_n_outputs': 4, 'lr': 0.024277442422100007, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.010526393133412644}"}}
exception: None

08:15:35 job_callback for (5, 0, 6) started
08:15:35 DISPATCHER: Trying to submit another job.
08:15:35 job_callback for (5, 0, 6) got condition
08:15:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:15:35 done building a new model for budget 133.333333 based on 9/28 split
Best loss for this budget:-0.958396





08:15:35 HBMASTER: Trying to run another job!
08:15:35 job_callback for (5, 0, 6) finished
08:15:35 start sampling a new configuration.
08:15:35 done sampling a new configuration.
08:15:35 HBMASTER: schedule new run for iteration 5
08:15:35 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
08:15:35 HBMASTER: submitting job (5, 0, 7) to dispatcher
08:15:35 DISPATCHER: trying to submit job (5, 0, 7)
08:15:35 DISPATCHER: trying to notify the job_runner thread.
08:15:35 HBMASTER: job (5, 0, 7) submitted to dispatcher
08:15:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:15:35 DISPATCHER: Trying to submit another job.
08:15:35 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464
08:15:35 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
08:15:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:15:35 WORKER: start processing job (5, 0, 7)
08:15:35 WORKER: args: ()
08:15:35 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 39, 'last_n_outputs': 22, 'lr': 0.012915953219980474, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 10, 'weight_decay': 0.0900684737993063}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-518:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:16:22 DISPATCHER: Starting worker discovery
08:16:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:16:22 DISPATCHER: Finished worker discovery
08:17:22 DISPATCHER: Starting worker discovery
08:17:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:17:22 DISPATCHER: Finished worker discovery
08:18:00 WORKER: done with job (5, 0, 7), trying to register it.
08:18:00 WORKER: registered result for job (5, 0, 7) with dispatcher
08:18:00 DISPATCHER: job (5, 0, 7) finished
08:18:00 DISPATCHER: register_result: lock acquired
08:18:00 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
08:18:00 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 39, 'last_n_outputs': 22, 'lr': 0.012915953219980474, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 10, 'weight_decay': 0.0900684737993063}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 39, 'last_n_outputs': 22, 'lr': 0.012915953219980474, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 10, 'weight_decay': 0.0900684737993063}"}}
exception: None

08:18:00 job_callback for (5, 0, 7) started
08:18:00 DISPATCHER: Trying to submit another job.
08:18:00 job_callback for (5, 0, 7) got condition
08:18:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:18:00 done building a new model for budget 133.333333 based on 9/29 split
Best loss for this budget:-0.958396





08:18:00 HBMASTER: Trying to run another job!
08:18:00 job_callback for (5, 0, 7) finished
08:18:00 start sampling a new configuration.
08:18:00 done sampling a new configuration.
08:18:00 HBMASTER: schedule new run for iteration 5
08:18:00 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
08:18:00 HBMASTER: submitting job (5, 0, 8) to dispatcher
08:18:00 DISPATCHER: trying to submit job (5, 0, 8)
08:18:00 DISPATCHER: trying to notify the job_runner thread.
08:18:00 HBMASTER: job (5, 0, 8) submitted to dispatcher
08:18:00 DISPATCHER: Trying to submit another job.
08:18:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:18:00 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464
08:18:00 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
08:18:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:18:00 WORKER: start processing job (5, 0, 8)
08:18:00 WORKER: args: ()
08:18:00 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 73, 'last_n_outputs': 24, 'lr': 0.007760628702533342, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.010747342340281966}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-519:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:18:22 DISPATCHER: Starting worker discovery
08:18:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:18:22 DISPATCHER: Finished worker discovery
08:19:22 DISPATCHER: Starting worker discovery
08:19:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:19:22 DISPATCHER: Finished worker discovery
08:20:22 DISPATCHER: Starting worker discovery
08:20:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:20:22 DISPATCHER: Finished worker discovery
08:20:23 WORKER: done with job (5, 0, 8), trying to register it.
08:20:23 WORKER: registered result for job (5, 0, 8) with dispatcher
08:20:23 DISPATCHER: job (5, 0, 8) finished
08:20:23 DISPATCHER: register_result: lock acquired
08:20:23 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
08:20:23 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 73, 'last_n_outputs': 24, 'lr': 0.007760628702533342, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.010747342340281966}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.022082269990675613, 'info': {'data05': 0.022082269990675613, 'config': "{'batch_size': 128, 'hidden_dim': 73, 'last_n_outputs': 24, 'lr': 0.007760628702533342, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.010747342340281966}"}}
exception: None

08:20:23 job_callback for (5, 0, 8) started
08:20:23 job_callback for (5, 0, 8) got condition
08:20:23 DISPATCHER: Trying to submit another job.
08:20:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:20:23 done building a new model for budget 133.333333 based on 9/30 split
Best loss for this budget:-0.958396





08:20:23 HBMASTER: Trying to run another job!
08:20:23 job_callback for (5, 0, 8) finished
08:20:23 ITERATION: Advancing config (5, 0, 1) to next budget 400.000000
08:20:23 ITERATION: Advancing config (5, 0, 2) to next budget 400.000000
08:20:23 ITERATION: Advancing config (5, 0, 4) to next budget 400.000000
08:20:23 HBMASTER: schedule new run for iteration 5
08:20:23 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
08:20:23 HBMASTER: submitting job (5, 0, 1) to dispatcher
08:20:23 DISPATCHER: trying to submit job (5, 0, 1)
08:20:23 DISPATCHER: trying to notify the job_runner thread.
08:20:23 HBMASTER: job (5, 0, 1) submitted to dispatcher
08:20:23 DISPATCHER: Trying to submit another job.
08:20:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:20:23 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
08:20:23 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
08:20:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:20:23 WORKER: start processing job (5, 0, 1)
08:20:23 WORKER: args: ()
08:20:23 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 42, 'last_n_outputs': 48, 'lr': 0.03782501948001183, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.013595520872533438}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-520:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:21:22 DISPATCHER: Starting worker discovery
08:21:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:21:22 DISPATCHER: Finished worker discovery
08:22:22 DISPATCHER: Starting worker discovery
08:22:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:22:22 DISPATCHER: Finished worker discovery
08:23:22 DISPATCHER: Starting worker discovery
08:23:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:23:22 DISPATCHER: Finished worker discovery
08:24:22 DISPATCHER: Starting worker discovery
08:24:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:24:22 DISPATCHER: Finished worker discovery
08:25:22 DISPATCHER: Starting worker discovery
08:25:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:25:22 DISPATCHER: Finished worker discovery
08:26:22 DISPATCHER: Starting worker discovery
08:26:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:26:22 DISPATCHER: Finished worker discovery
08:27:14 WORKER: done with job (5, 0, 1), trying to register it.
08:27:14 WORKER: registered result for job (5, 0, 1) with dispatcher
08:27:14 DISPATCHER: job (5, 0, 1) finished
08:27:14 DISPATCHER: register_result: lock acquired
08:27:14 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
08:27:14 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 42, 'last_n_outputs': 48, 'lr': 0.03782501948001183, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.013595520872533438}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.05363455334682013, 'info': {'data05': 0.05363455334682013, 'config': "{'batch_size': 64, 'hidden_dim': 42, 'last_n_outputs': 48, 'lr': 0.03782501948001183, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.013595520872533438}"}}
exception: None

08:27:14 job_callback for (5, 0, 1) started
08:27:14 DISPATCHER: Trying to submit another job.
08:27:14 job_callback for (5, 0, 1) got condition
08:27:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:27:14 HBMASTER: Trying to run another job!
08:27:14 job_callback for (5, 0, 1) finished
08:27:14 HBMASTER: schedule new run for iteration 5
08:27:14 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
08:27:14 HBMASTER: submitting job (5, 0, 2) to dispatcher
08:27:14 DISPATCHER: trying to submit job (5, 0, 2)
08:27:14 DISPATCHER: trying to notify the job_runner thread.
08:27:14 HBMASTER: job (5, 0, 2) submitted to dispatcher
08:27:14 DISPATCHER: Trying to submit another job.
08:27:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:27:14 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
08:27:14 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
08:27:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:27:14 WORKER: start processing job (5, 0, 2)
08:27:14 WORKER: args: ()
08:27:14 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 84, 'last_n_outputs': 13, 'lr': 0.004569716393544644, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.010580372173447422}, 'budget': 400.0, 'working_directory': '.'}
08:27:22 DISPATCHER: Starting worker discovery
08:27:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:27:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-521:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:28:22 DISPATCHER: Starting worker discovery
08:28:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:28:23 DISPATCHER: Finished worker discovery
08:29:23 DISPATCHER: Starting worker discovery
08:29:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:29:23 DISPATCHER: Finished worker discovery
08:30:23 DISPATCHER: Starting worker discovery
08:30:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:30:23 DISPATCHER: Finished worker discovery
08:31:23 DISPATCHER: Starting worker discovery
08:31:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:31:23 DISPATCHER: Finished worker discovery
08:32:23 DISPATCHER: Starting worker discovery
08:32:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:32:23 DISPATCHER: Finished worker discovery
08:33:23 DISPATCHER: Starting worker discovery
08:33:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:33:23 DISPATCHER: Finished worker discovery
08:34:03 WORKER: done with job (5, 0, 2), trying to register it.
08:34:03 WORKER: registered result for job (5, 0, 2) with dispatcher
08:34:03 DISPATCHER: job (5, 0, 2) finished
08:34:03 DISPATCHER: register_result: lock acquired
08:34:03 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
08:34:03 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 84, 'last_n_outputs': 13, 'lr': 0.004569716393544644, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.010580372173447422}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9462872672525575, 'info': {'data05': 0.9462872672525575, 'config': "{'batch_size': 64, 'hidden_dim': 84, 'last_n_outputs': 13, 'lr': 0.004569716393544644, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.010580372173447422}"}}
exception: None

08:34:03 job_callback for (5, 0, 2) started
08:34:03 DISPATCHER: Trying to submit another job.
08:34:03 job_callback for (5, 0, 2) got condition
08:34:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:34:03 HBMASTER: Trying to run another job!
08:34:03 job_callback for (5, 0, 2) finished
08:34:03 HBMASTER: schedule new run for iteration 5
08:34:03 HBMASTER: trying submitting job (5, 0, 4) to dispatcher
08:34:03 HBMASTER: submitting job (5, 0, 4) to dispatcher
08:34:03 DISPATCHER: trying to submit job (5, 0, 4)
08:34:03 DISPATCHER: trying to notify the job_runner thread.
08:34:03 HBMASTER: job (5, 0, 4) submitted to dispatcher
08:34:03 DISPATCHER: Trying to submit another job.
08:34:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:34:03 DISPATCHER: starting job (5, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464
08:34:03 DISPATCHER: job (5, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
08:34:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:34:03 WORKER: start processing job (5, 0, 4)
08:34:03 WORKER: args: ()
08:34:03 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 68, 'last_n_outputs': 1, 'lr': 0.011842742686166561, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.016127114803123833}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-522:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:34:23 DISPATCHER: Starting worker discovery
08:34:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:34:23 DISPATCHER: Finished worker discovery
08:35:23 DISPATCHER: Starting worker discovery
08:35:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:35:23 DISPATCHER: Finished worker discovery
08:36:23 DISPATCHER: Starting worker discovery
08:36:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:36:23 DISPATCHER: Finished worker discovery
08:37:23 DISPATCHER: Starting worker discovery
08:37:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:37:23 DISPATCHER: Finished worker discovery
08:38:23 DISPATCHER: Starting worker discovery
08:38:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:38:23 DISPATCHER: Finished worker discovery
08:39:23 DISPATCHER: Starting worker discovery
08:39:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:39:23 DISPATCHER: Finished worker discovery
08:40:23 DISPATCHER: Starting worker discovery
08:40:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:40:23 DISPATCHER: Finished worker discovery
08:40:55 WORKER: done with job (5, 0, 4), trying to register it.
08:40:55 WORKER: registered result for job (5, 0, 4) with dispatcher
08:40:55 DISPATCHER: job (5, 0, 4) finished
08:40:55 DISPATCHER: register_result: lock acquired
08:40:55 DISPATCHER: job (5, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
08:40:55 job_id: (5, 0, 4)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 68, 'last_n_outputs': 1, 'lr': 0.011842742686166561, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.016127114803123833}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.4662568281004296, 'info': {'data05': 0.4662568281004296, 'config': "{'batch_size': 16, 'hidden_dim': 68, 'last_n_outputs': 1, 'lr': 0.011842742686166561, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.016127114803123833}"}}
exception: None

08:40:55 job_callback for (5, 0, 4) started
08:40:55 DISPATCHER: Trying to submit another job.
08:40:55 job_callback for (5, 0, 4) got condition
08:40:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:40:55 done building a new model for budget 400.000000 based on 9/15 split
Best loss for this budget:-0.946287





08:40:55 HBMASTER: Trying to run another job!
08:40:55 job_callback for (5, 0, 4) finished
08:40:55 ITERATION: Advancing config (5, 0, 2) to next budget 1200.000000
08:40:55 HBMASTER: schedule new run for iteration 5
08:40:55 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
08:40:55 HBMASTER: submitting job (5, 0, 2) to dispatcher
08:40:55 DISPATCHER: trying to submit job (5, 0, 2)
08:40:55 DISPATCHER: trying to notify the job_runner thread.
08:40:55 HBMASTER: job (5, 0, 2) submitted to dispatcher
08:40:55 DISPATCHER: Trying to submit another job.
08:40:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:40:55 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
08:40:55 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
08:40:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:40:55 WORKER: start processing job (5, 0, 2)
08:40:55 WORKER: args: ()
08:40:55 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 84, 'last_n_outputs': 13, 'lr': 0.004569716393544644, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.010580372173447422}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-523:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:41:23 DISPATCHER: Starting worker discovery
08:41:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:41:23 DISPATCHER: Finished worker discovery
08:42:23 DISPATCHER: Starting worker discovery
08:42:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:42:23 DISPATCHER: Finished worker discovery
08:43:23 DISPATCHER: Starting worker discovery
08:43:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:43:23 DISPATCHER: Finished worker discovery
08:44:23 DISPATCHER: Starting worker discovery
08:44:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:44:23 DISPATCHER: Finished worker discovery
08:45:23 DISPATCHER: Starting worker discovery
08:45:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:45:23 DISPATCHER: Finished worker discovery
08:46:23 DISPATCHER: Starting worker discovery
08:46:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:46:23 DISPATCHER: Finished worker discovery
08:47:23 DISPATCHER: Starting worker discovery
08:47:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:47:23 DISPATCHER: Finished worker discovery
08:48:23 DISPATCHER: Starting worker discovery
08:48:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:48:23 DISPATCHER: Finished worker discovery
08:49:23 DISPATCHER: Starting worker discovery
08:49:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:49:23 DISPATCHER: Finished worker discovery
08:50:23 DISPATCHER: Starting worker discovery
08:50:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:50:23 DISPATCHER: Finished worker discovery
08:51:23 DISPATCHER: Starting worker discovery
08:51:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:51:23 DISPATCHER: Finished worker discovery
08:52:23 DISPATCHER: Starting worker discovery
08:52:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:52:23 DISPATCHER: Finished worker discovery
08:53:23 DISPATCHER: Starting worker discovery
08:53:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:53:23 DISPATCHER: Finished worker discovery
08:54:23 DISPATCHER: Starting worker discovery
08:54:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:54:23 DISPATCHER: Finished worker discovery
08:55:23 DISPATCHER: Starting worker discovery
08:55:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:55:23 DISPATCHER: Finished worker discovery
08:56:23 DISPATCHER: Starting worker discovery
08:56:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:56:23 DISPATCHER: Finished worker discovery
08:57:23 DISPATCHER: Starting worker discovery
08:57:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:57:23 DISPATCHER: Finished worker discovery
08:58:23 DISPATCHER: Starting worker discovery
08:58:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:58:23 DISPATCHER: Finished worker discovery
08:59:23 DISPATCHER: Starting worker discovery
08:59:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:59:23 DISPATCHER: Finished worker discovery
09:00:23 DISPATCHER: Starting worker discovery
09:00:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:00:23 DISPATCHER: Finished worker discovery
09:01:06 WORKER: done with job (5, 0, 2), trying to register it.
09:01:06 WORKER: registered result for job (5, 0, 2) with dispatcher
09:01:06 DISPATCHER: job (5, 0, 2) finished
09:01:06 DISPATCHER: register_result: lock acquired
09:01:06 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
09:01:06 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 84, 'last_n_outputs': 13, 'lr': 0.004569716393544644, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.010580372173447422}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.8143154039909316, 'info': {'data05': 0.8143154039909316, 'config': "{'batch_size': 64, 'hidden_dim': 84, 'last_n_outputs': 13, 'lr': 0.004569716393544644, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.010580372173447422}"}}
exception: None

09:01:06 job_callback for (5, 0, 2) started
09:01:06 job_callback for (5, 0, 2) got condition
09:01:06 DISPATCHER: Trying to submit another job.
09:01:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:01:06 HBMASTER: Trying to run another job!
09:01:06 job_callback for (5, 0, 2) finished
09:01:06 start sampling a new configuration.
09:01:06 best_vector: [1, 0.9675976364055576, 0.019812629446918306, 0.5854490091173171, 0.04405620953275683, 0, 0.7740770206707368, 0.032011666197541616], 1.889012804641404e-08, 2.699962408392451, 5.1002635615037846e-08
09:01:06 done sampling a new configuration.
09:01:06 HBMASTER: schedule new run for iteration 6
09:01:06 HBMASTER: trying submitting job (6, 0, 0) to dispatcher
09:01:06 HBMASTER: submitting job (6, 0, 0) to dispatcher
09:01:06 DISPATCHER: trying to submit job (6, 0, 0)
09:01:06 DISPATCHER: trying to notify the job_runner thread.
09:01:06 HBMASTER: job (6, 0, 0) submitted to dispatcher
09:01:06 DISPATCHER: Trying to submit another job.
09:01:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:01:06 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:01:06 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:01:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:01:06 WORKER: start processing job (6, 0, 0)
09:01:06 WORKER: args: ()
09:01:06 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 98, 'last_n_outputs': 1, 'lr': 0.01482169998610494, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.01100647212256309}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-524:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:01:23 DISPATCHER: Starting worker discovery
09:01:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:01:23 DISPATCHER: Finished worker discovery
09:02:23 DISPATCHER: Starting worker discovery
09:02:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:02:23 DISPATCHER: Finished worker discovery
09:03:23 DISPATCHER: Starting worker discovery
09:03:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:03:23 DISPATCHER: Finished worker discovery
09:04:23 DISPATCHER: Starting worker discovery
09:04:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:04:23 DISPATCHER: Finished worker discovery
09:05:23 DISPATCHER: Starting worker discovery
09:05:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:05:23 DISPATCHER: Finished worker discovery
09:06:23 DISPATCHER: Starting worker discovery
09:06:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:06:23 DISPATCHER: Finished worker discovery
09:07:23 DISPATCHER: Starting worker discovery
09:07:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:07:23 DISPATCHER: Finished worker discovery
09:07:56 WORKER: done with job (6, 0, 0), trying to register it.
09:07:56 WORKER: registered result for job (6, 0, 0) with dispatcher
09:07:56 DISPATCHER: job (6, 0, 0) finished
09:07:56 DISPATCHER: register_result: lock acquired
09:07:56 DISPATCHER: job (6, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
09:07:56 job_id: (6, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 98, 'last_n_outputs': 1, 'lr': 0.01482169998610494, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.01100647212256309}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6458480954945177, 'info': {'data05': 0.6458480954945177, 'config': "{'batch_size': 32, 'hidden_dim': 98, 'last_n_outputs': 1, 'lr': 0.01482169998610494, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.01100647212256309}"}}
exception: None

09:07:56 job_callback for (6, 0, 0) started
09:07:56 job_callback for (6, 0, 0) got condition
09:07:56 DISPATCHER: Trying to submit another job.
09:07:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:07:56 done building a new model for budget 400.000000 based on 9/16 split
Best loss for this budget:-0.946287





09:07:56 HBMASTER: Trying to run another job!
09:07:56 job_callback for (6, 0, 0) finished
09:07:56 start sampling a new configuration.
09:07:57 best_vector: [1, 0.11124140103307445, 0.20268951457544854, 0.04899083638607804, 0.06797976155597922, 0, 0.9257653385305384, 0.3264216719523375], 2.3179427578885997e-05, 0.7370596680416786, 1.7084621196689842e-05
09:07:57 done sampling a new configuration.
09:07:57 HBMASTER: schedule new run for iteration 6
09:07:57 HBMASTER: trying submitting job (6, 0, 1) to dispatcher
09:07:57 HBMASTER: submitting job (6, 0, 1) to dispatcher
09:07:57 DISPATCHER: trying to submit job (6, 0, 1)
09:07:57 DISPATCHER: trying to notify the job_runner thread.
09:07:57 HBMASTER: job (6, 0, 1) submitted to dispatcher
09:07:57 DISPATCHER: Trying to submit another job.
09:07:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:07:57 DISPATCHER: starting job (6, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:07:57 DISPATCHER: job (6, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:07:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:07:57 WORKER: start processing job (6, 0, 1)
09:07:57 WORKER: args: ()
09:07:57 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 29, 'last_n_outputs': 11, 'lr': 0.0012530882934975978, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.026587921413161093}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-525:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:08:23 DISPATCHER: Starting worker discovery
09:08:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:08:23 DISPATCHER: Finished worker discovery
09:09:23 DISPATCHER: Starting worker discovery
09:09:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:09:23 DISPATCHER: Finished worker discovery
09:10:23 DISPATCHER: Starting worker discovery
09:10:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:10:23 DISPATCHER: Finished worker discovery
09:11:23 DISPATCHER: Starting worker discovery
09:11:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:11:23 DISPATCHER: Finished worker discovery
09:12:23 DISPATCHER: Starting worker discovery
09:12:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:12:23 DISPATCHER: Finished worker discovery
09:13:23 DISPATCHER: Starting worker discovery
09:13:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:13:23 DISPATCHER: Finished worker discovery
09:14:23 DISPATCHER: Starting worker discovery
09:14:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:14:23 DISPATCHER: Finished worker discovery
09:14:47 WORKER: done with job (6, 0, 1), trying to register it.
09:14:47 WORKER: registered result for job (6, 0, 1) with dispatcher
09:14:47 DISPATCHER: job (6, 0, 1) finished
09:14:47 DISPATCHER: register_result: lock acquired
09:14:47 DISPATCHER: job (6, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
09:14:47 job_id: (6, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 29, 'last_n_outputs': 11, 'lr': 0.0012530882934975978, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.026587921413161093}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3458620325831683, 'info': {'data05': 0.3458620325831683, 'config': "{'batch_size': 32, 'hidden_dim': 29, 'last_n_outputs': 11, 'lr': 0.0012530882934975978, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.026587921413161093}"}}
exception: None

09:14:47 job_callback for (6, 0, 1) started
09:14:47 DISPATCHER: Trying to submit another job.
09:14:47 job_callback for (6, 0, 1) got condition
09:14:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:14:47 done building a new model for budget 400.000000 based on 9/17 split
Best loss for this budget:-0.946287





09:14:47 HBMASTER: Trying to run another job!
09:14:47 job_callback for (6, 0, 1) finished
09:14:47 start sampling a new configuration.
09:14:47 done sampling a new configuration.
09:14:47 HBMASTER: schedule new run for iteration 6
09:14:47 HBMASTER: trying submitting job (6, 0, 2) to dispatcher
09:14:47 HBMASTER: submitting job (6, 0, 2) to dispatcher
09:14:47 DISPATCHER: trying to submit job (6, 0, 2)
09:14:47 DISPATCHER: trying to notify the job_runner thread.
09:14:47 HBMASTER: job (6, 0, 2) submitted to dispatcher
09:14:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:14:47 DISPATCHER: Trying to submit another job.
09:14:47 DISPATCHER: starting job (6, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:14:47 DISPATCHER: job (6, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:14:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:14:47 WORKER: start processing job (6, 0, 2)
09:14:47 WORKER: args: ()
09:14:47 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 51, 'last_n_outputs': 42, 'lr': 0.001326417023803302, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.026940464946449964}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-526:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:15:23 DISPATCHER: Starting worker discovery
09:15:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:15:23 DISPATCHER: Finished worker discovery
09:16:23 DISPATCHER: Starting worker discovery
09:16:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:16:23 DISPATCHER: Finished worker discovery
09:17:23 DISPATCHER: Starting worker discovery
09:17:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:17:23 DISPATCHER: Finished worker discovery
09:18:23 DISPATCHER: Starting worker discovery
09:18:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:18:23 DISPATCHER: Finished worker discovery
09:19:23 DISPATCHER: Starting worker discovery
09:19:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:19:23 DISPATCHER: Finished worker discovery
09:20:23 DISPATCHER: Starting worker discovery
09:20:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:20:23 DISPATCHER: Finished worker discovery
09:21:23 DISPATCHER: Starting worker discovery
09:21:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:21:23 DISPATCHER: Finished worker discovery
09:21:37 WORKER: done with job (6, 0, 2), trying to register it.
09:21:37 WORKER: registered result for job (6, 0, 2) with dispatcher
09:21:37 DISPATCHER: job (6, 0, 2) finished
09:21:37 DISPATCHER: register_result: lock acquired
09:21:37 DISPATCHER: job (6, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
09:21:37 job_id: (6, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 51, 'last_n_outputs': 42, 'lr': 0.001326417023803302, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.026940464946449964}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5882352549227884, 'info': {'data05': 0.5882352549227884, 'config': "{'batch_size': 128, 'hidden_dim': 51, 'last_n_outputs': 42, 'lr': 0.001326417023803302, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.026940464946449964}"}}
exception: None

09:21:37 job_callback for (6, 0, 2) started
09:21:37 job_callback for (6, 0, 2) got condition
09:21:37 DISPATCHER: Trying to submit another job.
09:21:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:21:37 done building a new model for budget 400.000000 based on 9/17 split
Best loss for this budget:-0.946287





09:21:37 HBMASTER: Trying to run another job!
09:21:37 job_callback for (6, 0, 2) finished
09:21:37 start sampling a new configuration.
09:21:37 best_vector: [2, 0.7388479232474264, 0.40962925933113425, 0.975875024045693, 0.042754829937313735, 0, 0.6626270285070607, 0.015258921607725467], 0.011089455318147813, 0.6517472483085309, 0.0072275219888432414
09:21:37 done sampling a new configuration.
09:21:37 HBMASTER: schedule new run for iteration 6
09:21:37 HBMASTER: trying submitting job (6, 0, 3) to dispatcher
09:21:37 HBMASTER: submitting job (6, 0, 3) to dispatcher
09:21:37 DISPATCHER: trying to submit job (6, 0, 3)
09:21:37 DISPATCHER: trying to notify the job_runner thread.
09:21:37 HBMASTER: job (6, 0, 3) submitted to dispatcher
09:21:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:21:37 DISPATCHER: Trying to submit another job.
09:21:37 DISPATCHER: starting job (6, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:21:37 DISPATCHER: job (6, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:21:37 WORKER: start processing job (6, 0, 3)
09:21:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:21:37 WORKER: args: ()
09:21:37 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 79, 'last_n_outputs': 21, 'lr': 0.08948495995692704, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.01046772524211745}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-527:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:22:23 DISPATCHER: Starting worker discovery
09:22:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:22:23 DISPATCHER: Finished worker discovery
09:23:23 DISPATCHER: Starting worker discovery
09:23:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:23:23 DISPATCHER: Finished worker discovery
09:24:23 DISPATCHER: Starting worker discovery
09:24:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:24:23 DISPATCHER: Finished worker discovery
09:25:23 DISPATCHER: Starting worker discovery
09:25:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:25:23 DISPATCHER: Finished worker discovery
09:26:23 DISPATCHER: Starting worker discovery
09:26:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:26:23 DISPATCHER: Finished worker discovery
09:27:23 DISPATCHER: Starting worker discovery
09:27:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:27:23 DISPATCHER: Finished worker discovery
09:28:23 DISPATCHER: Starting worker discovery
09:28:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:28:23 DISPATCHER: Finished worker discovery
09:28:27 WORKER: done with job (6, 0, 3), trying to register it.
09:28:27 WORKER: registered result for job (6, 0, 3) with dispatcher
09:28:27 DISPATCHER: job (6, 0, 3) finished
09:28:27 DISPATCHER: register_result: lock acquired
09:28:27 DISPATCHER: job (6, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
09:28:27 job_id: (6, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 79, 'last_n_outputs': 21, 'lr': 0.08948495995692704, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.01046772524211745}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.11111534176428584, 'info': {'data05': 0.11111534176428584, 'config': "{'batch_size': 64, 'hidden_dim': 79, 'last_n_outputs': 21, 'lr': 0.08948495995692704, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.01046772524211745}"}}
exception: None

09:28:27 job_callback for (6, 0, 3) started
09:28:27 DISPATCHER: Trying to submit another job.
09:28:27 job_callback for (6, 0, 3) got condition
09:28:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:28:27 done building a new model for budget 400.000000 based on 9/18 split
Best loss for this budget:-0.946287





09:28:27 HBMASTER: Trying to run another job!
09:28:27 job_callback for (6, 0, 3) finished
09:28:27 start sampling a new configuration.
09:28:27 best_vector: [0, 0.8740586101696866, 0.1772872960525652, 0.3373240898521082, 0.10852188570991818, 0, 0.7001691760524384, 0.226724454792038], 0.009504030983302375, 2.6948697133143025, 0.025612125251302322
09:28:27 done sampling a new configuration.
09:28:27 HBMASTER: schedule new run for iteration 6
09:28:27 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
09:28:27 HBMASTER: submitting job (6, 0, 4) to dispatcher
09:28:27 DISPATCHER: trying to submit job (6, 0, 4)
09:28:27 DISPATCHER: trying to notify the job_runner thread.
09:28:27 HBMASTER: job (6, 0, 4) submitted to dispatcher
09:28:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:28:27 DISPATCHER: Trying to submit another job.
09:28:27 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:28:27 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:28:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:28:27 WORKER: start processing job (6, 0, 4)
09:28:27 WORKER: args: ()
09:28:27 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 90, 'last_n_outputs': 9, 'lr': 0.004727681161516971, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.01972310634664592}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-528:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:29:23 DISPATCHER: Starting worker discovery
09:29:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:29:23 DISPATCHER: Finished worker discovery
09:30:23 DISPATCHER: Starting worker discovery
09:30:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:30:23 DISPATCHER: Finished worker discovery
09:31:23 DISPATCHER: Starting worker discovery
09:31:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:31:23 DISPATCHER: Finished worker discovery
09:32:23 DISPATCHER: Starting worker discovery
09:32:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:32:23 DISPATCHER: Finished worker discovery
09:33:23 DISPATCHER: Starting worker discovery
09:33:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:33:23 DISPATCHER: Finished worker discovery
09:34:23 DISPATCHER: Starting worker discovery
09:34:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:34:23 DISPATCHER: Finished worker discovery
09:35:16 WORKER: done with job (6, 0, 4), trying to register it.
09:35:16 WORKER: registered result for job (6, 0, 4) with dispatcher
09:35:16 DISPATCHER: job (6, 0, 4) finished
09:35:16 DISPATCHER: register_result: lock acquired
09:35:16 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
09:35:16 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 90, 'last_n_outputs': 9, 'lr': 0.004727681161516971, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.01972310634664592}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8818663348272814, 'info': {'data05': 0.8818663348272814, 'config': "{'batch_size': 16, 'hidden_dim': 90, 'last_n_outputs': 9, 'lr': 0.004727681161516971, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.01972310634664592}"}}
exception: None

09:35:17 job_callback for (6, 0, 4) started
09:35:17 DISPATCHER: Trying to submit another job.
09:35:17 job_callback for (6, 0, 4) got condition
09:35:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:35:17 done building a new model for budget 400.000000 based on 9/19 split
Best loss for this budget:-0.946287





09:35:17 HBMASTER: Trying to run another job!
09:35:17 job_callback for (6, 0, 4) finished
09:35:17 start sampling a new configuration.
09:35:17 done sampling a new configuration.
09:35:17 HBMASTER: schedule new run for iteration 6
09:35:17 HBMASTER: trying submitting job (6, 0, 5) to dispatcher
09:35:17 HBMASTER: submitting job (6, 0, 5) to dispatcher
09:35:17 DISPATCHER: trying to submit job (6, 0, 5)
09:35:17 DISPATCHER: trying to notify the job_runner thread.
09:35:17 HBMASTER: job (6, 0, 5) submitted to dispatcher
09:35:17 DISPATCHER: Trying to submit another job.
09:35:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:35:17 DISPATCHER: starting job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:35:17 DISPATCHER: job (6, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:35:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:35:17 WORKER: start processing job (6, 0, 5)
09:35:17 WORKER: args: ()
09:35:17 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 89, 'last_n_outputs': 44, 'lr': 0.011356492485258315, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.012236538078229607}, 'budget': 400.0, 'working_directory': '.'}
09:35:23 DISPATCHER: Starting worker discovery
09:35:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:35:23 DISPATCHER: Finished worker discovery
Exception in thread Thread-529:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:36:23 DISPATCHER: Starting worker discovery
09:36:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:36:23 DISPATCHER: Finished worker discovery
09:37:23 DISPATCHER: Starting worker discovery
09:37:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:37:23 DISPATCHER: Finished worker discovery
09:38:23 DISPATCHER: Starting worker discovery
09:38:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:38:23 DISPATCHER: Finished worker discovery
09:39:23 DISPATCHER: Starting worker discovery
09:39:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:39:23 DISPATCHER: Finished worker discovery
09:40:23 DISPATCHER: Starting worker discovery
09:40:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:40:23 DISPATCHER: Finished worker discovery
09:41:23 DISPATCHER: Starting worker discovery
09:41:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:41:23 DISPATCHER: Finished worker discovery
09:42:07 WORKER: done with job (6, 0, 5), trying to register it.
09:42:07 WORKER: registered result for job (6, 0, 5) with dispatcher
09:42:07 DISPATCHER: job (6, 0, 5) finished
09:42:07 DISPATCHER: register_result: lock acquired
09:42:07 DISPATCHER: job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
09:42:07 job_id: (6, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 89, 'last_n_outputs': 44, 'lr': 0.011356492485258315, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.012236538078229607}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': 0.00207700740223893, 'info': {'data05': -0.00207700740223893, 'config': "{'batch_size': 64, 'hidden_dim': 89, 'last_n_outputs': 44, 'lr': 0.011356492485258315, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.012236538078229607}"}}
exception: None

09:42:07 job_callback for (6, 0, 5) started
09:42:07 job_callback for (6, 0, 5) got condition
09:42:07 DISPATCHER: Trying to submit another job.
09:42:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:42:07 done building a new model for budget 400.000000 based on 9/20 split
Best loss for this budget:-0.946287





09:42:07 HBMASTER: Trying to run another job!
09:42:07 job_callback for (6, 0, 5) finished
09:42:07 ITERATION: Advancing config (6, 0, 0) to next budget 1200.000000
09:42:07 ITERATION: Advancing config (6, 0, 4) to next budget 1200.000000
09:42:07 HBMASTER: schedule new run for iteration 6
09:42:07 HBMASTER: trying submitting job (6, 0, 0) to dispatcher
09:42:07 HBMASTER: submitting job (6, 0, 0) to dispatcher
09:42:07 DISPATCHER: trying to submit job (6, 0, 0)
09:42:07 DISPATCHER: trying to notify the job_runner thread.
09:42:07 HBMASTER: job (6, 0, 0) submitted to dispatcher
09:42:07 DISPATCHER: Trying to submit another job.
09:42:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:42:07 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:42:07 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
09:42:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:42:07 WORKER: start processing job (6, 0, 0)
09:42:07 WORKER: args: ()
09:42:07 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 98, 'last_n_outputs': 1, 'lr': 0.01482169998610494, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.01100647212256309}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-530:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:42:23 DISPATCHER: Starting worker discovery
09:42:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:42:23 DISPATCHER: Finished worker discovery
09:43:23 DISPATCHER: Starting worker discovery
09:43:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:43:23 DISPATCHER: Finished worker discovery
09:44:23 DISPATCHER: Starting worker discovery
09:44:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:44:23 DISPATCHER: Finished worker discovery
09:45:23 DISPATCHER: Starting worker discovery
09:45:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:45:23 DISPATCHER: Finished worker discovery
09:46:23 DISPATCHER: Starting worker discovery
09:46:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:46:23 DISPATCHER: Finished worker discovery
09:47:23 DISPATCHER: Starting worker discovery
09:47:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:47:23 DISPATCHER: Finished worker discovery
09:48:23 DISPATCHER: Starting worker discovery
09:48:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:48:23 DISPATCHER: Finished worker discovery
09:49:23 DISPATCHER: Starting worker discovery
09:49:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:49:23 DISPATCHER: Finished worker discovery
09:50:23 DISPATCHER: Starting worker discovery
09:50:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:50:23 DISPATCHER: Finished worker discovery
09:51:23 DISPATCHER: Starting worker discovery
09:51:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:51:23 DISPATCHER: Finished worker discovery
09:52:23 DISPATCHER: Starting worker discovery
09:52:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:52:23 DISPATCHER: Finished worker discovery
09:53:23 DISPATCHER: Starting worker discovery
09:53:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:53:23 DISPATCHER: Finished worker discovery
09:54:23 DISPATCHER: Starting worker discovery
09:54:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:54:23 DISPATCHER: Finished worker discovery
09:55:23 DISPATCHER: Starting worker discovery
09:55:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:55:23 DISPATCHER: Finished worker discovery
09:56:23 DISPATCHER: Starting worker discovery
09:56:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:56:23 DISPATCHER: Finished worker discovery
09:57:23 DISPATCHER: Starting worker discovery
09:57:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:57:23 DISPATCHER: Finished worker discovery
09:58:23 DISPATCHER: Starting worker discovery
09:58:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:58:23 DISPATCHER: Finished worker discovery
09:59:23 DISPATCHER: Starting worker discovery
09:59:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:59:23 DISPATCHER: Finished worker discovery
10:00:23 DISPATCHER: Starting worker discovery
10:00:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:00:23 DISPATCHER: Finished worker discovery
10:01:23 DISPATCHER: Starting worker discovery
10:01:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:01:23 DISPATCHER: Finished worker discovery
10:02:18 WORKER: done with job (6, 0, 0), trying to register it.
10:02:18 WORKER: registered result for job (6, 0, 0) with dispatcher
10:02:18 DISPATCHER: job (6, 0, 0) finished
10:02:18 DISPATCHER: register_result: lock acquired
10:02:18 DISPATCHER: job (6, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
10:02:18 job_id: (6, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 98, 'last_n_outputs': 1, 'lr': 0.01482169998610494, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.01100647212256309}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.7746501684381251, 'info': {'data05': 0.7746501684381251, 'config': "{'batch_size': 32, 'hidden_dim': 98, 'last_n_outputs': 1, 'lr': 0.01482169998610494, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.01100647212256309}"}}
exception: None

10:02:18 job_callback for (6, 0, 0) started
10:02:18 DISPATCHER: Trying to submit another job.
10:02:18 job_callback for (6, 0, 0) got condition
10:02:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:02:18 HBMASTER: Trying to run another job!
10:02:18 job_callback for (6, 0, 0) finished
10:02:18 HBMASTER: schedule new run for iteration 6
10:02:18 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
10:02:18 HBMASTER: submitting job (6, 0, 4) to dispatcher
10:02:18 DISPATCHER: trying to submit job (6, 0, 4)
10:02:18 DISPATCHER: trying to notify the job_runner thread.
10:02:18 HBMASTER: job (6, 0, 4) submitted to dispatcher
10:02:18 DISPATCHER: Trying to submit another job.
10:02:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:02:18 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464
10:02:18 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
10:02:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:02:18 WORKER: start processing job (6, 0, 4)
10:02:18 WORKER: args: ()
10:02:18 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 90, 'last_n_outputs': 9, 'lr': 0.004727681161516971, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.01972310634664592}, 'budget': 1200.0, 'working_directory': '.'}
10:02:23 DISPATCHER: Starting worker discovery
10:02:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:02:23 DISPATCHER: Finished worker discovery
Exception in thread Thread-531:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:03:23 DISPATCHER: Starting worker discovery
10:03:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:03:23 DISPATCHER: Finished worker discovery
10:04:23 DISPATCHER: Starting worker discovery
10:04:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:04:23 DISPATCHER: Finished worker discovery
10:05:23 DISPATCHER: Starting worker discovery
10:05:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:05:23 DISPATCHER: Finished worker discovery
10:06:23 DISPATCHER: Starting worker discovery
10:06:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:06:23 DISPATCHER: Finished worker discovery
10:07:23 DISPATCHER: Starting worker discovery
10:07:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:07:23 DISPATCHER: Finished worker discovery
10:08:23 DISPATCHER: Starting worker discovery
10:08:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:08:23 DISPATCHER: Finished worker discovery
10:09:23 DISPATCHER: Starting worker discovery
10:09:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:09:23 DISPATCHER: Finished worker discovery
10:10:23 DISPATCHER: Starting worker discovery
10:10:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:10:23 DISPATCHER: Finished worker discovery
10:11:23 DISPATCHER: Starting worker discovery
10:11:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:11:23 DISPATCHER: Finished worker discovery
10:12:23 DISPATCHER: Starting worker discovery
10:12:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:12:23 DISPATCHER: Finished worker discovery
10:13:23 DISPATCHER: Starting worker discovery
10:13:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:13:23 DISPATCHER: Finished worker discovery
10:14:23 DISPATCHER: Starting worker discovery
10:14:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:14:23 DISPATCHER: Finished worker discovery
10:15:23 DISPATCHER: Starting worker discovery
10:15:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:15:23 DISPATCHER: Finished worker discovery
10:16:23 DISPATCHER: Starting worker discovery
10:16:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:16:23 DISPATCHER: Finished worker discovery
10:17:23 DISPATCHER: Starting worker discovery
10:17:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:17:23 DISPATCHER: Finished worker discovery
10:18:23 DISPATCHER: Starting worker discovery
10:18:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:18:23 DISPATCHER: Finished worker discovery
10:19:23 DISPATCHER: Starting worker discovery
10:19:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:19:23 DISPATCHER: Finished worker discovery
10:20:23 DISPATCHER: Starting worker discovery
10:20:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:20:23 DISPATCHER: Finished worker discovery
10:21:23 DISPATCHER: Starting worker discovery
10:21:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:21:23 DISPATCHER: Finished worker discovery
10:22:23 DISPATCHER: Starting worker discovery
10:22:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:22:23 DISPATCHER: Finished worker discovery
10:22:28 WORKER: done with job (6, 0, 4), trying to register it.
10:22:28 WORKER: registered result for job (6, 0, 4) with dispatcher
10:22:28 DISPATCHER: job (6, 0, 4) finished
10:22:28 DISPATCHER: register_result: lock acquired
10:22:28 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
10:22:28 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 90, 'last_n_outputs': 9, 'lr': 0.004727681161516971, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.01972310634664592}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.926925032588395, 'info': {'data05': 0.926925032588395, 'config': "{'batch_size': 16, 'hidden_dim': 90, 'last_n_outputs': 9, 'lr': 0.004727681161516971, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.01972310634664592}"}}
exception: None

10:22:28 job_callback for (6, 0, 4) started
10:22:28 job_callback for (6, 0, 4) got condition
10:22:28 DISPATCHER: Trying to submit another job.
10:22:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:22:28 HBMASTER: Trying to run another job!
10:22:28 job_callback for (6, 0, 4) finished
10:22:28 start sampling a new configuration.
10:22:28 best_vector: [1, 0.8760209849739108, 0.3121804228329387, 0.40626586113121743, 0.043236201706113676, 0, 0.959491167848279, 0.056397003892781586], 0.005348853896292726, 5.7957313223624505, 0.031000520065484184
10:22:28 done sampling a new configuration.
10:22:28 HBMASTER: schedule new run for iteration 7
10:22:28 HBMASTER: trying submitting job (7, 0, 0) to dispatcher
10:22:28 HBMASTER: submitting job (7, 0, 0) to dispatcher
10:22:28 DISPATCHER: trying to submit job (7, 0, 0)
10:22:28 DISPATCHER: trying to notify the job_runner thread.
10:22:28 HBMASTER: job (7, 0, 0) submitted to dispatcher
10:22:28 DISPATCHER: Trying to submit another job.
10:22:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:22:28 DISPATCHER: starting job (7, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
10:22:28 DISPATCHER: job (7, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
10:22:28 WORKER: start processing job (7, 0, 0)
10:22:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:22:28 WORKER: args: ()
10:22:28 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 90, 'last_n_outputs': 16, 'lr': 0.0064942906622655555, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.011840613188539295}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-532:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:23:23 DISPATCHER: Starting worker discovery
10:23:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:23:23 DISPATCHER: Finished worker discovery
10:24:23 DISPATCHER: Starting worker discovery
10:24:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:24:23 DISPATCHER: Finished worker discovery
10:25:23 DISPATCHER: Starting worker discovery
10:25:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:25:23 DISPATCHER: Finished worker discovery
10:26:23 DISPATCHER: Starting worker discovery
10:26:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:26:23 DISPATCHER: Finished worker discovery
10:27:23 DISPATCHER: Starting worker discovery
10:27:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:27:23 DISPATCHER: Finished worker discovery
10:28:23 DISPATCHER: Starting worker discovery
10:28:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:28:23 DISPATCHER: Finished worker discovery
10:29:23 DISPATCHER: Starting worker discovery
10:29:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:29:23 DISPATCHER: Finished worker discovery
10:30:23 DISPATCHER: Starting worker discovery
10:30:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:30:23 DISPATCHER: Finished worker discovery
10:31:23 DISPATCHER: Starting worker discovery
10:31:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:31:23 DISPATCHER: Finished worker discovery
10:32:23 DISPATCHER: Starting worker discovery
10:32:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:32:23 DISPATCHER: Finished worker discovery
10:33:23 DISPATCHER: Starting worker discovery
10:33:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:33:23 DISPATCHER: Finished worker discovery
10:34:23 DISPATCHER: Starting worker discovery
10:34:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:34:23 DISPATCHER: Finished worker discovery
10:35:23 DISPATCHER: Starting worker discovery
10:35:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:35:23 DISPATCHER: Finished worker discovery
10:36:23 DISPATCHER: Starting worker discovery
10:36:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:36:23 DISPATCHER: Finished worker discovery
10:37:23 DISPATCHER: Starting worker discovery
10:37:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:37:23 DISPATCHER: Finished worker discovery
10:38:23 DISPATCHER: Starting worker discovery
10:38:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:38:23 DISPATCHER: Finished worker discovery
10:39:23 DISPATCHER: Starting worker discovery
10:39:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:39:23 DISPATCHER: Finished worker discovery
10:40:23 DISPATCHER: Starting worker discovery
10:40:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:40:23 DISPATCHER: Finished worker discovery
10:41:23 DISPATCHER: Starting worker discovery
10:41:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:41:23 DISPATCHER: Finished worker discovery
10:42:23 DISPATCHER: Starting worker discovery
10:42:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:42:23 DISPATCHER: Finished worker discovery
10:42:38 WORKER: done with job (7, 0, 0), trying to register it.
10:42:38 WORKER: registered result for job (7, 0, 0) with dispatcher
10:42:38 DISPATCHER: job (7, 0, 0) finished
10:42:38 DISPATCHER: register_result: lock acquired
10:42:38 DISPATCHER: job (7, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
10:42:38 job_id: (7, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 90, 'last_n_outputs': 16, 'lr': 0.0064942906622655555, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.011840613188539295}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.9651082946449123, 'info': {'data05': 0.9651082946449123, 'config': "{'batch_size': 32, 'hidden_dim': 90, 'last_n_outputs': 16, 'lr': 0.0064942906622655555, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.011840613188539295}"}}
exception: None

10:42:38 job_callback for (7, 0, 0) started
10:42:38 job_callback for (7, 0, 0) got condition
10:42:38 DISPATCHER: Trying to submit another job.
10:42:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:42:38 HBMASTER: Trying to run another job!
10:42:38 job_callback for (7, 0, 0) finished
10:42:38 start sampling a new configuration.
10:42:38 best_vector: [0, 0.6861734353635992, 0.44580199346432076, 0.4368298212188141, 0.09966761339323646, 0, 0.8262216498722567, 0.007923327234198665], 0.002375049693896811, 12.114594188872996, 0.02877276321996689
10:42:38 done sampling a new configuration.
10:42:38 HBMASTER: schedule new run for iteration 7
10:42:38 HBMASTER: trying submitting job (7, 0, 1) to dispatcher
10:42:38 HBMASTER: submitting job (7, 0, 1) to dispatcher
10:42:38 DISPATCHER: trying to submit job (7, 0, 1)
10:42:38 DISPATCHER: trying to notify the job_runner thread.
10:42:38 HBMASTER: job (7, 0, 1) submitted to dispatcher
10:42:38 DISPATCHER: Trying to submit another job.
10:42:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:42:38 DISPATCHER: starting job (7, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
10:42:38 DISPATCHER: job (7, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
10:42:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:42:38 WORKER: start processing job (7, 0, 1)
10:42:38 WORKER: args: ()
10:42:38 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 75, 'last_n_outputs': 23, 'lr': 0.007475833880894782, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.01024020112061418}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-533:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:43:23 DISPATCHER: Starting worker discovery
10:43:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:43:23 DISPATCHER: Finished worker discovery
10:44:23 DISPATCHER: Starting worker discovery
10:44:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:44:23 DISPATCHER: Finished worker discovery
10:45:23 DISPATCHER: Starting worker discovery
10:45:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:45:23 DISPATCHER: Finished worker discovery
10:46:23 DISPATCHER: Starting worker discovery
10:46:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:46:23 DISPATCHER: Finished worker discovery
10:47:23 DISPATCHER: Starting worker discovery
10:47:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:47:23 DISPATCHER: Finished worker discovery
10:48:23 DISPATCHER: Starting worker discovery
10:48:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:48:23 DISPATCHER: Finished worker discovery
10:49:23 DISPATCHER: Starting worker discovery
10:49:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:49:23 DISPATCHER: Finished worker discovery
10:50:23 DISPATCHER: Starting worker discovery
10:50:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:50:23 DISPATCHER: Finished worker discovery
10:51:23 DISPATCHER: Starting worker discovery
10:51:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:51:23 DISPATCHER: Finished worker discovery
10:52:23 DISPATCHER: Starting worker discovery
10:52:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:52:23 DISPATCHER: Finished worker discovery
10:53:23 DISPATCHER: Starting worker discovery
10:53:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:53:23 DISPATCHER: Finished worker discovery
10:54:23 DISPATCHER: Starting worker discovery
10:54:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:54:23 DISPATCHER: Finished worker discovery
10:55:23 DISPATCHER: Starting worker discovery
10:55:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:55:23 DISPATCHER: Finished worker discovery
10:56:23 DISPATCHER: Starting worker discovery
10:56:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:56:23 DISPATCHER: Finished worker discovery
10:57:23 DISPATCHER: Starting worker discovery
10:57:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:57:23 DISPATCHER: Finished worker discovery
10:58:23 DISPATCHER: Starting worker discovery
10:58:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:58:24 DISPATCHER: Finished worker discovery
10:59:24 DISPATCHER: Starting worker discovery
10:59:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:59:24 DISPATCHER: Finished worker discovery
11:00:24 DISPATCHER: Starting worker discovery
11:00:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:00:24 DISPATCHER: Finished worker discovery
11:01:24 DISPATCHER: Starting worker discovery
11:01:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:01:24 DISPATCHER: Finished worker discovery
11:02:24 DISPATCHER: Starting worker discovery
11:02:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:02:24 DISPATCHER: Finished worker discovery
11:02:48 WORKER: done with job (7, 0, 1), trying to register it.
11:02:48 WORKER: registered result for job (7, 0, 1) with dispatcher
11:02:48 DISPATCHER: job (7, 0, 1) finished
11:02:48 DISPATCHER: register_result: lock acquired
11:02:48 DISPATCHER: job (7, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
11:02:48 job_id: (7, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 75, 'last_n_outputs': 23, 'lr': 0.007475833880894782, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.01024020112061418}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.9270851125496782, 'info': {'data05': 0.9270851125496782, 'config': "{'batch_size': 16, 'hidden_dim': 75, 'last_n_outputs': 23, 'lr': 0.007475833880894782, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.01024020112061418}"}}
exception: None

11:02:48 job_callback for (7, 0, 1) started
11:02:48 DISPATCHER: Trying to submit another job.
11:02:48 job_callback for (7, 0, 1) got condition
11:02:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:02:48 HBMASTER: Trying to run another job!
11:02:48 job_callback for (7, 0, 1) finished
11:02:48 start sampling a new configuration.
11:02:48 done sampling a new configuration.
11:02:48 HBMASTER: schedule new run for iteration 7
11:02:48 HBMASTER: trying submitting job (7, 0, 2) to dispatcher
11:02:48 HBMASTER: submitting job (7, 0, 2) to dispatcher
11:02:48 DISPATCHER: trying to submit job (7, 0, 2)
11:02:48 DISPATCHER: trying to notify the job_runner thread.
11:02:48 HBMASTER: job (7, 0, 2) submitted to dispatcher
11:02:48 DISPATCHER: Trying to submit another job.
11:02:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:02:48 DISPATCHER: starting job (7, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:02:48 DISPATCHER: job (7, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:02:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:02:48 WORKER: start processing job (7, 0, 2)
11:02:48 WORKER: args: ()
11:02:48 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 27, 'last_n_outputs': 16, 'lr': 0.0019622457485461674, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.1074454711817485}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-534:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:03:24 DISPATCHER: Starting worker discovery
11:03:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:03:24 DISPATCHER: Finished worker discovery
11:04:24 DISPATCHER: Starting worker discovery
11:04:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:04:24 DISPATCHER: Finished worker discovery
11:05:24 DISPATCHER: Starting worker discovery
11:05:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:05:24 DISPATCHER: Finished worker discovery
11:06:24 DISPATCHER: Starting worker discovery
11:06:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:06:24 DISPATCHER: Finished worker discovery
11:07:24 DISPATCHER: Starting worker discovery
11:07:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:07:24 DISPATCHER: Finished worker discovery
11:08:24 DISPATCHER: Starting worker discovery
11:08:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:08:24 DISPATCHER: Finished worker discovery
11:09:24 DISPATCHER: Starting worker discovery
11:09:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:09:24 DISPATCHER: Finished worker discovery
11:10:24 DISPATCHER: Starting worker discovery
11:10:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:10:24 DISPATCHER: Finished worker discovery
11:11:24 DISPATCHER: Starting worker discovery
11:11:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:11:24 DISPATCHER: Finished worker discovery
11:12:24 DISPATCHER: Starting worker discovery
11:12:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:12:24 DISPATCHER: Finished worker discovery
11:13:24 DISPATCHER: Starting worker discovery
11:13:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:13:24 DISPATCHER: Finished worker discovery
11:14:24 DISPATCHER: Starting worker discovery
11:14:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:14:24 DISPATCHER: Finished worker discovery
11:15:24 DISPATCHER: Starting worker discovery
11:15:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:15:24 DISPATCHER: Finished worker discovery
11:16:24 DISPATCHER: Starting worker discovery
11:16:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:16:24 DISPATCHER: Finished worker discovery
11:17:24 DISPATCHER: Starting worker discovery
11:17:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:17:24 DISPATCHER: Finished worker discovery
11:18:24 DISPATCHER: Starting worker discovery
11:18:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:18:24 DISPATCHER: Finished worker discovery
11:19:24 DISPATCHER: Starting worker discovery
11:19:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:19:24 DISPATCHER: Finished worker discovery
11:20:24 DISPATCHER: Starting worker discovery
11:20:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:20:24 DISPATCHER: Finished worker discovery
11:21:24 DISPATCHER: Starting worker discovery
11:21:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:21:24 DISPATCHER: Finished worker discovery
11:22:24 DISPATCHER: Starting worker discovery
11:22:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:22:24 DISPATCHER: Finished worker discovery
11:22:58 WORKER: done with job (7, 0, 2), trying to register it.
11:22:58 WORKER: registered result for job (7, 0, 2) with dispatcher
11:22:58 DISPATCHER: job (7, 0, 2) finished
11:22:58 DISPATCHER: register_result: lock acquired
11:22:58 DISPATCHER: job (7, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
11:22:58 job_id: (7, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 27, 'last_n_outputs': 16, 'lr': 0.0019622457485461674, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.1074454711817485}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.008322238664674199, 'info': {'data05': 0.008322238664674199, 'config': "{'batch_size': 32, 'hidden_dim': 27, 'last_n_outputs': 16, 'lr': 0.0019622457485461674, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.1074454711817485}"}}
exception: None

11:22:58 job_callback for (7, 0, 2) started
11:22:58 DISPATCHER: Trying to submit another job.
11:22:58 job_callback for (7, 0, 2) got condition
11:22:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:22:58 HBMASTER: Trying to run another job!
11:22:58 job_callback for (7, 0, 2) finished
11:22:58 start sampling a new configuration.
11:22:58 done sampling a new configuration.
11:22:58 HBMASTER: schedule new run for iteration 7
11:22:58 HBMASTER: trying submitting job (7, 0, 3) to dispatcher
11:22:58 HBMASTER: submitting job (7, 0, 3) to dispatcher
11:22:58 DISPATCHER: trying to submit job (7, 0, 3)
11:22:58 DISPATCHER: trying to notify the job_runner thread.
11:22:58 HBMASTER: job (7, 0, 3) submitted to dispatcher
11:22:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:22:58 DISPATCHER: Trying to submit another job.
11:22:58 DISPATCHER: starting job (7, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:22:58 DISPATCHER: job (7, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:22:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:22:58 WORKER: start processing job (7, 0, 3)
11:22:58 WORKER: args: ()
11:22:58 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 98, 'last_n_outputs': 38, 'lr': 0.03248823589627589, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.0424348581815783}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-535:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:23:24 DISPATCHER: Starting worker discovery
11:23:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:23:24 DISPATCHER: Finished worker discovery
11:24:24 DISPATCHER: Starting worker discovery
11:24:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:24:24 DISPATCHER: Finished worker discovery
11:25:24 DISPATCHER: Starting worker discovery
11:25:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:25:24 DISPATCHER: Finished worker discovery
11:26:24 DISPATCHER: Starting worker discovery
11:26:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:26:24 DISPATCHER: Finished worker discovery
11:27:24 DISPATCHER: Starting worker discovery
11:27:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:27:24 DISPATCHER: Finished worker discovery
11:28:24 DISPATCHER: Starting worker discovery
11:28:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:28:24 DISPATCHER: Finished worker discovery
11:29:24 DISPATCHER: Starting worker discovery
11:29:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:29:24 DISPATCHER: Finished worker discovery
11:30:24 DISPATCHER: Starting worker discovery
11:30:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:30:24 DISPATCHER: Finished worker discovery
11:31:24 DISPATCHER: Starting worker discovery
11:31:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:31:24 DISPATCHER: Finished worker discovery
11:32:24 DISPATCHER: Starting worker discovery
11:32:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:32:24 DISPATCHER: Finished worker discovery
11:33:24 DISPATCHER: Starting worker discovery
11:33:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:33:24 DISPATCHER: Finished worker discovery
11:34:24 DISPATCHER: Starting worker discovery
11:34:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:34:24 DISPATCHER: Finished worker discovery
11:35:24 DISPATCHER: Starting worker discovery
11:35:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:35:24 DISPATCHER: Finished worker discovery
11:36:24 DISPATCHER: Starting worker discovery
11:36:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:36:24 DISPATCHER: Finished worker discovery
11:37:24 DISPATCHER: Starting worker discovery
11:37:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:37:24 DISPATCHER: Finished worker discovery
11:38:24 DISPATCHER: Starting worker discovery
11:38:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:38:24 DISPATCHER: Finished worker discovery
11:39:24 DISPATCHER: Starting worker discovery
11:39:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:39:24 DISPATCHER: Finished worker discovery
11:40:24 DISPATCHER: Starting worker discovery
11:40:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:40:24 DISPATCHER: Finished worker discovery
11:41:24 DISPATCHER: Starting worker discovery
11:41:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:41:24 DISPATCHER: Finished worker discovery
11:42:24 DISPATCHER: Starting worker discovery
11:42:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:42:24 DISPATCHER: Finished worker discovery
11:43:08 WORKER: done with job (7, 0, 3), trying to register it.
11:43:08 WORKER: registered result for job (7, 0, 3) with dispatcher
11:43:08 DISPATCHER: job (7, 0, 3) finished
11:43:08 DISPATCHER: register_result: lock acquired
11:43:08 DISPATCHER: job (7, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
11:43:08 job_id: (7, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 98, 'last_n_outputs': 38, 'lr': 0.03248823589627589, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.0424348581815783}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.22137298123947094, 'info': {'data05': 0.22137298123947094, 'config': "{'batch_size': 64, 'hidden_dim': 98, 'last_n_outputs': 38, 'lr': 0.03248823589627589, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.0424348581815783}"}}
exception: None

11:43:08 job_callback for (7, 0, 3) started
11:43:08 DISPATCHER: Trying to submit another job.
11:43:08 job_callback for (7, 0, 3) got condition
11:43:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:43:08 HBMASTER: Trying to run another job!
11:43:08 job_callback for (7, 0, 3) finished
11:43:08 start sampling a new configuration.
11:43:08 done sampling a new configuration.
11:43:08 HBMASTER: schedule new run for iteration 8
11:43:08 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
11:43:08 HBMASTER: submitting job (8, 0, 0) to dispatcher
11:43:08 DISPATCHER: trying to submit job (8, 0, 0)
11:43:08 DISPATCHER: trying to notify the job_runner thread.
11:43:08 HBMASTER: job (8, 0, 0) submitted to dispatcher
11:43:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:43:08 DISPATCHER: Trying to submit another job.
11:43:08 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:43:08 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:43:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:43:08 WORKER: start processing job (8, 0, 0)
11:43:08 WORKER: args: ()
11:43:08 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 94, 'last_n_outputs': 25, 'lr': 0.024948702242627355, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.010521272421718622}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-536:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:43:24 DISPATCHER: Starting worker discovery
11:43:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:43:24 DISPATCHER: Finished worker discovery
11:44:03 WORKER: done with job (8, 0, 0), trying to register it.
11:44:03 WORKER: registered result for job (8, 0, 0) with dispatcher
11:44:03 DISPATCHER: job (8, 0, 0) finished
11:44:03 DISPATCHER: register_result: lock acquired
11:44:03 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
11:44:03 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 94, 'last_n_outputs': 25, 'lr': 0.024948702242627355, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.010521272421718622}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3233957583663004, 'info': {'data05': 0.3233957583663004, 'config': "{'batch_size': 32, 'hidden_dim': 94, 'last_n_outputs': 25, 'lr': 0.024948702242627355, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.010521272421718622}"}}
exception: None

11:44:03 job_callback for (8, 0, 0) started
11:44:03 DISPATCHER: Trying to submit another job.
11:44:03 job_callback for (8, 0, 0) got condition
11:44:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:44:03 HBMASTER: Trying to run another job!
11:44:03 job_callback for (8, 0, 0) finished
11:44:03 start sampling a new configuration.
11:44:03 done sampling a new configuration.
11:44:03 HBMASTER: schedule new run for iteration 8
11:44:03 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
11:44:03 HBMASTER: submitting job (8, 0, 1) to dispatcher
11:44:03 DISPATCHER: trying to submit job (8, 0, 1)
11:44:03 DISPATCHER: trying to notify the job_runner thread.
11:44:03 HBMASTER: job (8, 0, 1) submitted to dispatcher
11:44:03 DISPATCHER: Trying to submit another job.
11:44:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:44:03 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:44:03 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:44:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:44:03 WORKER: start processing job (8, 0, 1)
11:44:03 WORKER: args: ()
11:44:03 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 99, 'last_n_outputs': 36, 'lr': 0.011423684845966973, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.032204759063155744}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-537:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:44:24 DISPATCHER: Starting worker discovery
11:44:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:44:24 DISPATCHER: Finished worker discovery
11:44:57 WORKER: done with job (8, 0, 1), trying to register it.
11:44:57 WORKER: registered result for job (8, 0, 1) with dispatcher
11:44:57 DISPATCHER: job (8, 0, 1) finished
11:44:57 DISPATCHER: register_result: lock acquired
11:44:57 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
11:44:57 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 99, 'last_n_outputs': 36, 'lr': 0.011423684845966973, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.032204759063155744}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.016790989536548378, 'info': {'data05': 0.016790989536548378, 'config': "{'batch_size': 128, 'hidden_dim': 99, 'last_n_outputs': 36, 'lr': 0.011423684845966973, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.032204759063155744}"}}
exception: None

11:44:57 job_callback for (8, 0, 1) started
11:44:57 DISPATCHER: Trying to submit another job.
11:44:57 job_callback for (8, 0, 1) got condition
11:44:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:44:57 HBMASTER: Trying to run another job!
11:44:57 job_callback for (8, 0, 1) finished
11:44:57 start sampling a new configuration.
11:44:57 best_vector: [0, 0.8611404195498049, 0.24205712858009049, 0.27207794683098674, 0.09097247090413808, 0, 0.6113335466109374, 0.10624235144706297], 0.0018153256825473856, 9.09027499881635, 0.016501809666769725
11:44:57 done sampling a new configuration.
11:44:57 HBMASTER: schedule new run for iteration 8
11:44:57 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
11:44:57 HBMASTER: submitting job (8, 0, 2) to dispatcher
11:44:57 DISPATCHER: trying to submit job (8, 0, 2)
11:44:57 DISPATCHER: trying to notify the job_runner thread.
11:44:57 HBMASTER: job (8, 0, 2) submitted to dispatcher
11:44:57 DISPATCHER: Trying to submit another job.
11:44:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:44:57 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:44:57 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:44:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:44:57 WORKER: start processing job (8, 0, 2)
11:44:57 WORKER: args: ()
11:44:57 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 89, 'last_n_outputs': 13, 'lr': 0.0035007080534146984, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.013747523984492938}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-538:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:45:24 DISPATCHER: Starting worker discovery
11:45:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:45:24 DISPATCHER: Finished worker discovery
11:45:52 WORKER: done with job (8, 0, 2), trying to register it.
11:45:52 WORKER: registered result for job (8, 0, 2) with dispatcher
11:45:52 DISPATCHER: job (8, 0, 2) finished
11:45:52 DISPATCHER: register_result: lock acquired
11:45:52 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
11:45:52 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 89, 'last_n_outputs': 13, 'lr': 0.0035007080534146984, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.013747523984492938}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7601272656540986, 'info': {'data05': 0.7601272656540986, 'config': "{'batch_size': 16, 'hidden_dim': 89, 'last_n_outputs': 13, 'lr': 0.0035007080534146984, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.013747523984492938}"}}
exception: None

11:45:52 job_callback for (8, 0, 2) started
11:45:52 DISPATCHER: Trying to submit another job.
11:45:52 job_callback for (8, 0, 2) got condition
11:45:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:45:52 HBMASTER: Trying to run another job!
11:45:52 job_callback for (8, 0, 2) finished
11:45:52 start sampling a new configuration.
11:45:52 best_vector: [0, 0.5562384197758597, 0.14333385105331364, 0.7812402609548879, 0.29647984788025156, 1, 0.2903474174439128, 0.374357603404015], 0.0, inf, 0.015158283550688224
11:45:52 done sampling a new configuration.
11:45:52 HBMASTER: schedule new run for iteration 8
11:45:52 HBMASTER: trying submitting job (8, 0, 3) to dispatcher
11:45:52 HBMASTER: submitting job (8, 0, 3) to dispatcher
11:45:52 DISPATCHER: trying to submit job (8, 0, 3)
11:45:52 DISPATCHER: trying to notify the job_runner thread.
11:45:52 HBMASTER: job (8, 0, 3) submitted to dispatcher
11:45:52 DISPATCHER: Trying to submit another job.
11:45:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:45:52 DISPATCHER: starting job (8, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:45:52 DISPATCHER: job (8, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:45:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:45:52 WORKER: start processing job (8, 0, 3)
11:45:52 WORKER: args: ()
11:45:52 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 65, 'last_n_outputs': 8, 'lr': 0.036515774957703986, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.030693786726823793}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-539:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:46:24 DISPATCHER: Starting worker discovery
11:46:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:46:24 DISPATCHER: Finished worker discovery
11:46:47 WORKER: done with job (8, 0, 3), trying to register it.
11:46:47 WORKER: registered result for job (8, 0, 3) with dispatcher
11:46:47 DISPATCHER: job (8, 0, 3) finished
11:46:47 DISPATCHER: register_result: lock acquired
11:46:47 DISPATCHER: job (8, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
11:46:47 job_id: (8, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 65, 'last_n_outputs': 8, 'lr': 0.036515774957703986, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.030693786726823793}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 65, 'last_n_outputs': 8, 'lr': 0.036515774957703986, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.030693786726823793}"}}
exception: None

11:46:47 job_callback for (8, 0, 3) started
11:46:47 DISPATCHER: Trying to submit another job.
11:46:47 job_callback for (8, 0, 3) got condition
11:46:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:46:47 HBMASTER: Trying to run another job!
11:46:47 job_callback for (8, 0, 3) finished
11:46:47 start sampling a new configuration.
11:46:47 best_vector: [0, 0.7106568011793823, 0.3860919858005439, 0.28770413738788914, 0.06048478027829105, 0, 0.7073157934334899, 0.01866955603509471], 0.0021824047168799857, 9.565177606042187, 0.02087508872522128
11:46:47 done sampling a new configuration.
11:46:47 HBMASTER: schedule new run for iteration 8
11:46:47 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
11:46:47 HBMASTER: submitting job (8, 0, 4) to dispatcher
11:46:47 DISPATCHER: trying to submit job (8, 0, 4)
11:46:47 DISPATCHER: trying to notify the job_runner thread.
11:46:47 HBMASTER: job (8, 0, 4) submitted to dispatcher
11:46:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:46:47 DISPATCHER: Trying to submit another job.
11:46:47 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:46:47 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:46:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:46:47 WORKER: start processing job (8, 0, 4)
11:46:47 WORKER: args: ()
11:46:47 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 77, 'last_n_outputs': 20, 'lr': 0.003761908904292848, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.01057522588027713}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-540:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:47:24 DISPATCHER: Starting worker discovery
11:47:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:47:24 DISPATCHER: Finished worker discovery
11:47:43 WORKER: done with job (8, 0, 4), trying to register it.
11:47:43 WORKER: registered result for job (8, 0, 4) with dispatcher
11:47:43 DISPATCHER: job (8, 0, 4) finished
11:47:43 DISPATCHER: register_result: lock acquired
11:47:43 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
11:47:43 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 77, 'last_n_outputs': 20, 'lr': 0.003761908904292848, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.01057522588027713}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9166474500501175, 'info': {'data05': 0.9166474500501175, 'config': "{'batch_size': 16, 'hidden_dim': 77, 'last_n_outputs': 20, 'lr': 0.003761908904292848, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.01057522588027713}"}}
exception: None

11:47:43 job_callback for (8, 0, 4) started
11:47:43 DISPATCHER: Trying to submit another job.
11:47:43 job_callback for (8, 0, 4) got condition
11:47:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:47:43 HBMASTER: Trying to run another job!
11:47:43 job_callback for (8, 0, 4) finished
11:47:43 start sampling a new configuration.
11:47:43 done sampling a new configuration.
11:47:43 HBMASTER: schedule new run for iteration 8
11:47:43 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
11:47:43 HBMASTER: submitting job (8, 0, 5) to dispatcher
11:47:43 DISPATCHER: trying to submit job (8, 0, 5)
11:47:43 DISPATCHER: trying to notify the job_runner thread.
11:47:43 HBMASTER: job (8, 0, 5) submitted to dispatcher
11:47:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:47:43 DISPATCHER: Trying to submit another job.
11:47:43 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:47:43 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:47:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:47:43 WORKER: start processing job (8, 0, 5)
11:47:43 WORKER: args: ()
11:47:43 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 61, 'last_n_outputs': 9, 'lr': 0.001665374152197445, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.015459083421421797}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-541:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:48:24 DISPATCHER: Starting worker discovery
11:48:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:48:24 DISPATCHER: Finished worker discovery
11:48:37 WORKER: done with job (8, 0, 5), trying to register it.
11:48:37 WORKER: registered result for job (8, 0, 5) with dispatcher
11:48:37 DISPATCHER: job (8, 0, 5) finished
11:48:37 DISPATCHER: register_result: lock acquired
11:48:37 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
11:48:37 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 61, 'last_n_outputs': 9, 'lr': 0.001665374152197445, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.015459083421421797}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.021081550173669337, 'info': {'data05': -0.021081550173669337, 'config': "{'batch_size': 64, 'hidden_dim': 61, 'last_n_outputs': 9, 'lr': 0.001665374152197445, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.015459083421421797}"}}
exception: None

11:48:37 job_callback for (8, 0, 5) started
11:48:37 DISPATCHER: Trying to submit another job.
11:48:37 job_callback for (8, 0, 5) got condition
11:48:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:48:37 HBMASTER: Trying to run another job!
11:48:37 job_callback for (8, 0, 5) finished
11:48:37 start sampling a new configuration.
11:48:37 best_vector: [3, 0.7078780948925956, 0.47927559914151874, 0.2590364162013332, 0.14409737211749937, 0, 0.8521032164004532, 0.07643914046851072], 0.005497699622875818, 7.201718169040062, 0.039592883261989474
11:48:37 done sampling a new configuration.
11:48:37 HBMASTER: schedule new run for iteration 8
11:48:37 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
11:48:37 HBMASTER: submitting job (8, 0, 6) to dispatcher
11:48:37 DISPATCHER: trying to submit job (8, 0, 6)
11:48:37 DISPATCHER: trying to notify the job_runner thread.
11:48:37 HBMASTER: job (8, 0, 6) submitted to dispatcher
11:48:37 DISPATCHER: Trying to submit another job.
11:48:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:48:37 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:48:37 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:48:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:48:37 WORKER: start processing job (8, 0, 6)
11:48:37 WORKER: args: ()
11:48:37 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 77, 'last_n_outputs': 24, 'lr': 0.003296649932859044, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.012573309745293566}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-542:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:49:24 DISPATCHER: Starting worker discovery
11:49:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:49:24 DISPATCHER: Finished worker discovery
11:49:31 WORKER: done with job (8, 0, 6), trying to register it.
11:49:31 WORKER: registered result for job (8, 0, 6) with dispatcher
11:49:31 DISPATCHER: job (8, 0, 6) finished
11:49:31 DISPATCHER: register_result: lock acquired
11:49:31 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
11:49:31 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 77, 'last_n_outputs': 24, 'lr': 0.003296649932859044, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.012573309745293566}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9668556580921842, 'info': {'data05': 0.9668556580921842, 'config': "{'batch_size': 128, 'hidden_dim': 77, 'last_n_outputs': 24, 'lr': 0.003296649932859044, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.012573309745293566}"}}
exception: None

11:49:31 job_callback for (8, 0, 6) started
11:49:31 DISPATCHER: Trying to submit another job.
11:49:31 job_callback for (8, 0, 6) got condition
11:49:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:49:31 HBMASTER: Trying to run another job!
11:49:31 job_callback for (8, 0, 6) finished
11:49:31 start sampling a new configuration.
11:49:31 best_vector: [1, 0.958084796159506, 0.47029187831075614, 0.24774642530461438, 0.14084048220422035, 0, 0.815689630848098, 0.10093008019302088], 0.0033337420375025156, 6.445405135196336, 0.02148731804793861
11:49:31 done sampling a new configuration.
11:49:31 HBMASTER: schedule new run for iteration 8
11:49:31 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
11:49:31 HBMASTER: submitting job (8, 0, 7) to dispatcher
11:49:31 DISPATCHER: trying to submit job (8, 0, 7)
11:49:31 DISPATCHER: trying to notify the job_runner thread.
11:49:31 HBMASTER: job (8, 0, 7) submitted to dispatcher
11:49:31 DISPATCHER: Trying to submit another job.
11:49:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:49:31 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:49:31 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:49:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:49:31 WORKER: start processing job (8, 0, 7)
11:49:31 WORKER: args: ()
11:49:31 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 97, 'last_n_outputs': 24, 'lr': 0.0031296289509355224, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.01353047557998333}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-543:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:50:24 DISPATCHER: Starting worker discovery
11:50:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:50:24 DISPATCHER: Finished worker discovery
11:50:26 WORKER: done with job (8, 0, 7), trying to register it.
11:50:26 WORKER: registered result for job (8, 0, 7) with dispatcher
11:50:26 DISPATCHER: job (8, 0, 7) finished
11:50:26 DISPATCHER: register_result: lock acquired
11:50:26 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
11:50:26 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 97, 'last_n_outputs': 24, 'lr': 0.0031296289509355224, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.01353047557998333}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9549983327469942, 'info': {'data05': 0.9549983327469942, 'config': "{'batch_size': 32, 'hidden_dim': 97, 'last_n_outputs': 24, 'lr': 0.0031296289509355224, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.01353047557998333}"}}
exception: None

11:50:26 job_callback for (8, 0, 7) started
11:50:26 job_callback for (8, 0, 7) got condition
11:50:26 DISPATCHER: Trying to submit another job.
11:50:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:50:26 HBMASTER: Trying to run another job!
11:50:26 job_callback for (8, 0, 7) finished
11:50:26 start sampling a new configuration.
11:50:26 best_vector: [2, 0.979711670165652, 0.41525438873216025, 0.3153098364620177, 0.12346192874722658, 0, 0.40075889130232234, 0.1266202968324513], 0.002423714191581633, 2.8761301152008465, 0.0069709173770476085
11:50:26 done sampling a new configuration.
11:50:26 HBMASTER: schedule new run for iteration 8
11:50:26 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
11:50:26 HBMASTER: submitting job (8, 0, 8) to dispatcher
11:50:26 DISPATCHER: trying to submit job (8, 0, 8)
11:50:26 DISPATCHER: trying to notify the job_runner thread.
11:50:26 HBMASTER: job (8, 0, 8) submitted to dispatcher
11:50:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:50:26 DISPATCHER: Trying to submit another job.
11:50:26 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:50:26 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:50:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:50:26 WORKER: start processing job (8, 0, 8)
11:50:26 WORKER: args: ()
11:50:26 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 99, 'last_n_outputs': 21, 'lr': 0.00427188618076525, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.01461291318748616}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-544:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:51:20 WORKER: done with job (8, 0, 8), trying to register it.
11:51:20 WORKER: registered result for job (8, 0, 8) with dispatcher
11:51:20 DISPATCHER: job (8, 0, 8) finished
11:51:20 DISPATCHER: register_result: lock acquired
11:51:20 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
11:51:20 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 99, 'last_n_outputs': 21, 'lr': 0.00427188618076525, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.01461291318748616}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8115419521713398, 'info': {'data05': 0.8115419521713398, 'config': "{'batch_size': 64, 'hidden_dim': 99, 'last_n_outputs': 21, 'lr': 0.00427188618076525, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.01461291318748616}"}}
exception: None

11:51:20 job_callback for (8, 0, 8) started
11:51:20 job_callback for (8, 0, 8) got condition
11:51:20 DISPATCHER: Trying to submit another job.
11:51:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:51:20 HBMASTER: Trying to run another job!
11:51:20 job_callback for (8, 0, 8) finished
11:51:20 start sampling a new configuration.
11:51:20 best_vector: [0, 0.8710427810402184, 0.5127830774043108, 0.34704598806470044, 0.11829945122828406, 0, 0.395545239565615, 0.15207116445803442], 0.005390198245564098, 3.131384561785653, 0.01687878357112353
11:51:20 done sampling a new configuration.
11:51:20 HBMASTER: schedule new run for iteration 8
11:51:20 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
11:51:20 HBMASTER: submitting job (8, 0, 9) to dispatcher
11:51:20 DISPATCHER: trying to submit job (8, 0, 9)
11:51:20 DISPATCHER: trying to notify the job_runner thread.
11:51:20 HBMASTER: job (8, 0, 9) submitted to dispatcher
11:51:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:51:20 DISPATCHER: Trying to submit another job.
11:51:20 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:51:20 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:51:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:51:20 WORKER: start processing job (8, 0, 9)
11:51:20 WORKER: args: ()
11:51:20 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 90, 'last_n_outputs': 26, 'lr': 0.004944153846062533, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.015770633765871605}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:51:24 DISPATCHER: Starting worker discovery
11:51:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:51:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-545:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:52:14 WORKER: done with job (8, 0, 9), trying to register it.
11:52:14 WORKER: registered result for job (8, 0, 9) with dispatcher
11:52:14 DISPATCHER: job (8, 0, 9) finished
11:52:14 DISPATCHER: register_result: lock acquired
11:52:14 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
11:52:14 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 90, 'last_n_outputs': 26, 'lr': 0.004944153846062533, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.015770633765871605}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8700861018028804, 'info': {'data05': 0.8700861018028804, 'config': "{'batch_size': 16, 'hidden_dim': 90, 'last_n_outputs': 26, 'lr': 0.004944153846062533, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.015770633765871605}"}}
exception: None

11:52:14 job_callback for (8, 0, 9) started
11:52:14 job_callback for (8, 0, 9) got condition
11:52:14 DISPATCHER: Trying to submit another job.
11:52:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:52:14 HBMASTER: Trying to run another job!
11:52:14 job_callback for (8, 0, 9) finished
11:52:14 start sampling a new configuration.
11:52:14 done sampling a new configuration.
11:52:14 HBMASTER: schedule new run for iteration 8
11:52:14 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
11:52:14 HBMASTER: submitting job (8, 0, 10) to dispatcher
11:52:14 DISPATCHER: trying to submit job (8, 0, 10)
11:52:14 DISPATCHER: trying to notify the job_runner thread.
11:52:14 HBMASTER: job (8, 0, 10) submitted to dispatcher
11:52:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:52:14 DISPATCHER: Trying to submit another job.
11:52:14 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:52:14 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:52:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:52:14 WORKER: start processing job (8, 0, 10)
11:52:14 WORKER: args: ()
11:52:14 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 32, 'lr': 0.02209709208765721, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.0820673861232142}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:52:24 DISPATCHER: Starting worker discovery
11:52:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:52:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-546:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:53:09 WORKER: done with job (8, 0, 10), trying to register it.
11:53:09 WORKER: registered result for job (8, 0, 10) with dispatcher
11:53:09 DISPATCHER: job (8, 0, 10) finished
11:53:09 DISPATCHER: register_result: lock acquired
11:53:09 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
11:53:09 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 32, 'lr': 0.02209709208765721, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.0820673861232142}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.003989466378217296, 'info': {'data05': 0.003989466378217296, 'config': "{'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 32, 'lr': 0.02209709208765721, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.0820673861232142}"}}
exception: None

11:53:09 job_callback for (8, 0, 10) started
11:53:09 DISPATCHER: Trying to submit another job.
11:53:09 job_callback for (8, 0, 10) got condition
11:53:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:53:09 HBMASTER: Trying to run another job!
11:53:09 job_callback for (8, 0, 10) finished
11:53:09 start sampling a new configuration.
11:53:09 done sampling a new configuration.
11:53:09 HBMASTER: schedule new run for iteration 8
11:53:09 HBMASTER: trying submitting job (8, 0, 11) to dispatcher
11:53:09 HBMASTER: submitting job (8, 0, 11) to dispatcher
11:53:09 DISPATCHER: trying to submit job (8, 0, 11)
11:53:09 DISPATCHER: trying to notify the job_runner thread.
11:53:09 HBMASTER: job (8, 0, 11) submitted to dispatcher
11:53:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:53:09 DISPATCHER: Trying to submit another job.
11:53:09 DISPATCHER: starting job (8, 0, 11) on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:53:09 DISPATCHER: job (8, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:53:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:53:09 WORKER: start processing job (8, 0, 11)
11:53:09 WORKER: args: ()
11:53:09 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 98, 'last_n_outputs': 11, 'lr': 0.0011650860272040676, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.11787141160386393}, 'budget': 44.44444444444444, 'working_directory': '.'}
11:53:24 DISPATCHER: Starting worker discovery
11:53:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:53:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-547:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:54:03 WORKER: done with job (8, 0, 11), trying to register it.
11:54:03 WORKER: registered result for job (8, 0, 11) with dispatcher
11:54:03 DISPATCHER: job (8, 0, 11) finished
11:54:03 DISPATCHER: register_result: lock acquired
11:54:03 DISPATCHER: job (8, 0, 11) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
11:54:03 job_id: (8, 0, 11)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 98, 'last_n_outputs': 11, 'lr': 0.0011650860272040676, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.11787141160386393}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 98, 'last_n_outputs': 11, 'lr': 0.0011650860272040676, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.11787141160386393}"}}
exception: None

11:54:03 job_callback for (8, 0, 11) started
11:54:03 job_callback for (8, 0, 11) got condition
11:54:03 DISPATCHER: Trying to submit another job.
11:54:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:54:03 HBMASTER: Trying to run another job!
11:54:03 job_callback for (8, 0, 11) finished
11:54:03 start sampling a new configuration.
11:54:03 done sampling a new configuration.
11:54:03 HBMASTER: schedule new run for iteration 8
11:54:03 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
11:54:03 HBMASTER: submitting job (8, 0, 12) to dispatcher
11:54:03 DISPATCHER: trying to submit job (8, 0, 12)
11:54:03 DISPATCHER: trying to notify the job_runner thread.
11:54:03 HBMASTER: job (8, 0, 12) submitted to dispatcher
11:54:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:54:03 DISPATCHER: Trying to submit another job.
11:54:03 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:54:03 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:54:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:54:03 WORKER: start processing job (8, 0, 12)
11:54:03 WORKER: args: ()
11:54:03 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 77, 'last_n_outputs': 11, 'lr': 0.002109542012418602, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.11858136403388224}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-548:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:54:24 DISPATCHER: Starting worker discovery
11:54:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:54:24 DISPATCHER: Finished worker discovery
11:54:57 WORKER: done with job (8, 0, 12), trying to register it.
11:54:57 WORKER: registered result for job (8, 0, 12) with dispatcher
11:54:57 DISPATCHER: job (8, 0, 12) finished
11:54:57 DISPATCHER: register_result: lock acquired
11:54:57 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
11:54:57 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 77, 'last_n_outputs': 11, 'lr': 0.002109542012418602, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.11858136403388224}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 77, 'last_n_outputs': 11, 'lr': 0.002109542012418602, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.11858136403388224}"}}
exception: None

11:54:57 job_callback for (8, 0, 12) started
11:54:57 DISPATCHER: Trying to submit another job.
11:54:57 job_callback for (8, 0, 12) got condition
11:54:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:54:57 HBMASTER: Trying to run another job!
11:54:57 job_callback for (8, 0, 12) finished
11:54:57 start sampling a new configuration.
11:54:57 best_vector: [2, 0.3506356149960889, 0.8400841618308221, 0.05051012749601237, 0.14428927906955874, 0, 0.7509266713453164, 0.47466342641061615], 0.009392764584480075, 1.7598601476496993, 0.01652995206848197
11:54:57 done sampling a new configuration.
11:54:57 HBMASTER: schedule new run for iteration 8
11:54:57 HBMASTER: trying submitting job (8, 0, 13) to dispatcher
11:54:57 HBMASTER: submitting job (8, 0, 13) to dispatcher
11:54:57 DISPATCHER: trying to submit job (8, 0, 13)
11:54:57 DISPATCHER: trying to notify the job_runner thread.
11:54:57 HBMASTER: job (8, 0, 13) submitted to dispatcher
11:54:57 DISPATCHER: Trying to submit another job.
11:54:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:54:57 DISPATCHER: starting job (8, 0, 13) on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:54:57 DISPATCHER: job (8, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:54:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:54:57 WORKER: start processing job (8, 0, 13)
11:54:57 WORKER: args: ()
11:54:57 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 48, 'last_n_outputs': 43, 'lr': 0.0012618863861389386, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.0414525599061458}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-549:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:55:24 DISPATCHER: Starting worker discovery
11:55:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:55:24 DISPATCHER: Finished worker discovery
11:55:52 WORKER: done with job (8, 0, 13), trying to register it.
11:55:52 WORKER: registered result for job (8, 0, 13) with dispatcher
11:55:52 DISPATCHER: job (8, 0, 13) finished
11:55:52 DISPATCHER: register_result: lock acquired
11:55:52 DISPATCHER: job (8, 0, 13) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
11:55:52 job_id: (8, 0, 13)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 48, 'last_n_outputs': 43, 'lr': 0.0012618863861389386, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.0414525599061458}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9295245793406752, 'info': {'data05': 0.9295245793406752, 'config': "{'batch_size': 64, 'hidden_dim': 48, 'last_n_outputs': 43, 'lr': 0.0012618863861389386, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.0414525599061458}"}}
exception: None

11:55:52 job_callback for (8, 0, 13) started
11:55:52 job_callback for (8, 0, 13) got condition
11:55:52 DISPATCHER: Trying to submit another job.
11:55:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:55:52 HBMASTER: Trying to run another job!
11:55:52 job_callback for (8, 0, 13) finished
11:55:52 start sampling a new configuration.
11:55:52 done sampling a new configuration.
11:55:52 HBMASTER: schedule new run for iteration 8
11:55:52 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
11:55:52 HBMASTER: submitting job (8, 0, 14) to dispatcher
11:55:52 DISPATCHER: trying to submit job (8, 0, 14)
11:55:52 DISPATCHER: trying to notify the job_runner thread.
11:55:52 HBMASTER: job (8, 0, 14) submitted to dispatcher
11:55:52 DISPATCHER: Trying to submit another job.
11:55:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:55:52 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:55:52 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:55:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:55:52 WORKER: start processing job (8, 0, 14)
11:55:52 WORKER: args: ()
11:55:52 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 73, 'last_n_outputs': 27, 'lr': 0.030104207279160584, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.0520237929787867}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-550:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:56:24 DISPATCHER: Starting worker discovery
11:56:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:56:24 DISPATCHER: Finished worker discovery
11:56:46 WORKER: done with job (8, 0, 14), trying to register it.
11:56:46 WORKER: registered result for job (8, 0, 14) with dispatcher
11:56:46 DISPATCHER: job (8, 0, 14) finished
11:56:46 DISPATCHER: register_result: lock acquired
11:56:46 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
11:56:46 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 73, 'last_n_outputs': 27, 'lr': 0.030104207279160584, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.0520237929787867}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2909120936505317, 'info': {'data05': 0.2909120936505317, 'config': "{'batch_size': 32, 'hidden_dim': 73, 'last_n_outputs': 27, 'lr': 0.030104207279160584, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.0520237929787867}"}}
exception: None

11:56:46 job_callback for (8, 0, 14) started
11:56:46 job_callback for (8, 0, 14) got condition
11:56:46 DISPATCHER: Trying to submit another job.
11:56:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:56:46 HBMASTER: Trying to run another job!
11:56:46 job_callback for (8, 0, 14) finished
11:56:46 start sampling a new configuration.
11:56:46 best_vector: [2, 0.9302152589892014, 0.36663235139742256, 0.16724039674633506, 0.047607847851664976, 0, 0.02600589754805327, 0.2616173196508421], 0.006718698371318307, 0.10813716801075171, 0.0007265410145928117
11:56:46 done sampling a new configuration.
11:56:46 HBMASTER: schedule new run for iteration 8
11:56:46 HBMASTER: trying submitting job (8, 0, 15) to dispatcher
11:56:46 HBMASTER: submitting job (8, 0, 15) to dispatcher
11:56:46 DISPATCHER: trying to submit job (8, 0, 15)
11:56:46 DISPATCHER: trying to notify the job_runner thread.
11:56:46 HBMASTER: job (8, 0, 15) submitted to dispatcher
11:56:46 DISPATCHER: Trying to submit another job.
11:56:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:56:46 DISPATCHER: starting job (8, 0, 15) on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:56:46 DISPATCHER: job (8, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:56:46 WORKER: start processing job (8, 0, 15)
11:56:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:56:46 WORKER: args: ()
11:56:46 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 95, 'last_n_outputs': 19, 'lr': 0.002160134501540293, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.021896362799020453}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-551:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:57:24 DISPATCHER: Starting worker discovery
11:57:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:57:24 DISPATCHER: Finished worker discovery
11:57:41 WORKER: done with job (8, 0, 15), trying to register it.
11:57:41 WORKER: registered result for job (8, 0, 15) with dispatcher
11:57:41 DISPATCHER: job (8, 0, 15) finished
11:57:41 DISPATCHER: register_result: lock acquired
11:57:41 DISPATCHER: job (8, 0, 15) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
11:57:41 job_id: (8, 0, 15)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 95, 'last_n_outputs': 19, 'lr': 0.002160134501540293, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.021896362799020453}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.18831047902904405, 'info': {'data05': 0.18831047902904405, 'config': "{'batch_size': 64, 'hidden_dim': 95, 'last_n_outputs': 19, 'lr': 0.002160134501540293, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.021896362799020453}"}}
exception: None

11:57:41 job_callback for (8, 0, 15) started
11:57:41 job_callback for (8, 0, 15) got condition
11:57:41 DISPATCHER: Trying to submit another job.
11:57:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:57:41 HBMASTER: Trying to run another job!
11:57:41 job_callback for (8, 0, 15) finished
11:57:41 start sampling a new configuration.
11:57:41 done sampling a new configuration.
11:57:41 HBMASTER: schedule new run for iteration 8
11:57:41 HBMASTER: trying submitting job (8, 0, 16) to dispatcher
11:57:41 HBMASTER: submitting job (8, 0, 16) to dispatcher
11:57:41 DISPATCHER: trying to submit job (8, 0, 16)
11:57:41 DISPATCHER: trying to notify the job_runner thread.
11:57:41 HBMASTER: job (8, 0, 16) submitted to dispatcher
11:57:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:57:41 DISPATCHER: Trying to submit another job.
11:57:41 DISPATCHER: starting job (8, 0, 16) on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:57:41 DISPATCHER: job (8, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:57:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:57:41 WORKER: start processing job (8, 0, 16)
11:57:41 WORKER: args: ()
11:57:41 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 33, 'last_n_outputs': 15, 'lr': 0.0018745302282371175, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.01064218811045782}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-552:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:58:24 DISPATCHER: Starting worker discovery
11:58:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:58:24 DISPATCHER: Finished worker discovery
11:58:35 WORKER: done with job (8, 0, 16), trying to register it.
11:58:35 WORKER: registered result for job (8, 0, 16) with dispatcher
11:58:35 DISPATCHER: job (8, 0, 16) finished
11:58:35 DISPATCHER: register_result: lock acquired
11:58:35 DISPATCHER: job (8, 0, 16) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
11:58:35 job_id: (8, 0, 16)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 33, 'last_n_outputs': 15, 'lr': 0.0018745302282371175, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.01064218811045782}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 33, 'last_n_outputs': 15, 'lr': 0.0018745302282371175, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.01064218811045782}"}}
exception: None

11:58:35 job_callback for (8, 0, 16) started
11:58:35 job_callback for (8, 0, 16) got condition
11:58:35 DISPATCHER: Trying to submit another job.
11:58:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:58:35 HBMASTER: Trying to run another job!
11:58:35 job_callback for (8, 0, 16) finished
11:58:35 start sampling a new configuration.
11:58:35 best_vector: [2, 0.40400672230435214, 0.9411673501402014, 0.04263173908086906, 0.1117587235844126, 0, 0.4141843945106323, 0.5366560888079767], 0.006295307502503757, 1.1050259201121062, 0.0069564779653428594
11:58:35 done sampling a new configuration.
11:58:35 HBMASTER: schedule new run for iteration 8
11:58:35 HBMASTER: trying submitting job (8, 0, 17) to dispatcher
11:58:35 HBMASTER: submitting job (8, 0, 17) to dispatcher
11:58:35 DISPATCHER: trying to submit job (8, 0, 17)
11:58:35 DISPATCHER: trying to notify the job_runner thread.
11:58:35 HBMASTER: job (8, 0, 17) submitted to dispatcher
11:58:35 DISPATCHER: Trying to submit another job.
11:58:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:58:35 DISPATCHER: starting job (8, 0, 17) on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:58:35 DISPATCHER: job (8, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:58:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:58:35 WORKER: start processing job (8, 0, 17)
11:58:35 WORKER: args: ()
11:58:35 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 52, 'last_n_outputs': 48, 'lr': 0.0012169240613096749, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.04991208002032385}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-553:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:59:24 DISPATCHER: Starting worker discovery
11:59:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:59:24 DISPATCHER: Finished worker discovery
11:59:29 WORKER: done with job (8, 0, 17), trying to register it.
11:59:29 WORKER: registered result for job (8, 0, 17) with dispatcher
11:59:29 DISPATCHER: job (8, 0, 17) finished
11:59:29 DISPATCHER: register_result: lock acquired
11:59:29 DISPATCHER: job (8, 0, 17) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
11:59:29 job_id: (8, 0, 17)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 52, 'last_n_outputs': 48, 'lr': 0.0012169240613096749, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.04991208002032385}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8300089140690923, 'info': {'data05': 0.8300089140690923, 'config': "{'batch_size': 64, 'hidden_dim': 52, 'last_n_outputs': 48, 'lr': 0.0012169240613096749, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.04991208002032385}"}}
exception: None

11:59:29 job_callback for (8, 0, 17) started
11:59:29 job_callback for (8, 0, 17) got condition
11:59:29 DISPATCHER: Trying to submit another job.
11:59:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:59:29 HBMASTER: Trying to run another job!
11:59:29 job_callback for (8, 0, 17) finished
11:59:29 start sampling a new configuration.
11:59:30 best_vector: [0, 0.11220303115772062, 0.6073670328197115, 0.11787865774564846, 0.09572121927542712, 0, 0.6902417592615028, 0.3753572750531429], 0.009648111504922282, 4.045779953676238, 0.039034136117447646
11:59:30 done sampling a new configuration.
11:59:30 HBMASTER: schedule new run for iteration 8
11:59:30 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
11:59:30 HBMASTER: submitting job (8, 0, 18) to dispatcher
11:59:30 DISPATCHER: trying to submit job (8, 0, 18)
11:59:30 DISPATCHER: trying to notify the job_runner thread.
11:59:30 HBMASTER: job (8, 0, 18) submitted to dispatcher
11:59:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:59:30 DISPATCHER: Trying to submit another job.
11:59:30 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:59:30 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
11:59:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:59:30 WORKER: start processing job (8, 0, 18)
11:59:30 WORKER: args: ()
11:59:30 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 29, 'last_n_outputs': 31, 'lr': 0.0017209066606286945, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 72, 'weight_decay': 0.030785844678745955}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-554:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

12:00:24 WORKER: done with job (8, 0, 18), trying to register it.
12:00:24 WORKER: registered result for job (8, 0, 18) with dispatcher
12:00:24 DISPATCHER: job (8, 0, 18) finished
12:00:24 DISPATCHER: register_result: lock acquired
12:00:24 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:00:24 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 29, 'last_n_outputs': 31, 'lr': 0.0017209066606286945, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 72, 'weight_decay': 0.030785844678745955}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5565262299062271, 'info': {'data05': 0.5565262299062271, 'config': "{'batch_size': 16, 'hidden_dim': 29, 'last_n_outputs': 31, 'lr': 0.0017209066606286945, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 72, 'weight_decay': 0.030785844678745955}"}}
exception: None

12:00:24 job_callback for (8, 0, 18) started
12:00:24 DISPATCHER: Trying to submit another job.
12:00:24 job_callback for (8, 0, 18) got condition
12:00:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:00:24 HBMASTER: Trying to run another job!
12:00:24 job_callback for (8, 0, 18) finished
12:00:24 start sampling a new configuration.
12:00:24 best_vector: [0, 0.9036968180111589, 0.8511187263297548, 0.3245497072067492, 0.25552688636448007, 0, 0.2835244831169728, 0.019413663019960725], 0.026005319996652818, 0.8465414384869359, 0.022014580998279555
12:00:24 done sampling a new configuration.
12:00:24 HBMASTER: schedule new run for iteration 8
12:00:24 HBMASTER: trying submitting job (8, 0, 19) to dispatcher
12:00:24 HBMASTER: submitting job (8, 0, 19) to dispatcher
12:00:24 DISPATCHER: trying to submit job (8, 0, 19)
12:00:24 DISPATCHER: trying to notify the job_runner thread.
12:00:24 HBMASTER: job (8, 0, 19) submitted to dispatcher
12:00:24 DISPATCHER: Trying to submit another job.
12:00:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:00:24 DISPATCHER: starting job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:00:24 DISPATCHER: job (8, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:00:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:00:24 WORKER: start processing job (8, 0, 19)
12:00:24 WORKER: args: ()
12:00:24 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 93, 'last_n_outputs': 43, 'lr': 0.004457582753116875, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.010598825889597966}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:00:24 DISPATCHER: Starting worker discovery
12:00:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:00:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-555:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

12:01:19 WORKER: done with job (8, 0, 19), trying to register it.
12:01:19 WORKER: registered result for job (8, 0, 19) with dispatcher
12:01:19 DISPATCHER: job (8, 0, 19) finished
12:01:19 DISPATCHER: register_result: lock acquired
12:01:19 DISPATCHER: job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:01:19 job_id: (8, 0, 19)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 93, 'last_n_outputs': 43, 'lr': 0.004457582753116875, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.010598825889597966}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7693781370476646, 'info': {'data05': 0.7693781370476646, 'config': "{'batch_size': 16, 'hidden_dim': 93, 'last_n_outputs': 43, 'lr': 0.004457582753116875, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.010598825889597966}"}}
exception: None

12:01:19 job_callback for (8, 0, 19) started
12:01:19 job_callback for (8, 0, 19) got condition
12:01:19 DISPATCHER: Trying to submit another job.
12:01:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:01:19 HBMASTER: Trying to run another job!
12:01:19 job_callback for (8, 0, 19) finished
12:01:19 start sampling a new configuration.
12:01:19 best_vector: [3, 0.7155590614659625, 0.2095163329707959, 0.13996022119868282, 0.09622386820212789, 0, 0.6749744448220036, 0.18807233672486826], 0.007427149976835201, 4.759093968613116, 0.03534650465874145
12:01:19 done sampling a new configuration.
12:01:19 HBMASTER: schedule new run for iteration 8
12:01:19 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
12:01:19 HBMASTER: submitting job (8, 0, 20) to dispatcher
12:01:19 DISPATCHER: trying to submit job (8, 0, 20)
12:01:19 DISPATCHER: trying to notify the job_runner thread.
12:01:19 HBMASTER: job (8, 0, 20) submitted to dispatcher
12:01:19 DISPATCHER: Trying to submit another job.
12:01:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:01:19 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:01:19 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:01:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:01:19 WORKER: start processing job (8, 0, 20)
12:01:19 WORKER: args: ()
12:01:19 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 77, 'last_n_outputs': 11, 'lr': 0.0019051116921093693, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.01756660158236173}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:01:24 DISPATCHER: Starting worker discovery
12:01:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:01:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-556:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

12:02:13 WORKER: done with job (8, 0, 20), trying to register it.
12:02:13 WORKER: registered result for job (8, 0, 20) with dispatcher
12:02:13 DISPATCHER: job (8, 0, 20) finished
12:02:13 DISPATCHER: register_result: lock acquired
12:02:13 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:02:13 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 77, 'last_n_outputs': 11, 'lr': 0.0019051116921093693, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.01756660158236173}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9279819896174765, 'info': {'data05': 0.9279819896174765, 'config': "{'batch_size': 128, 'hidden_dim': 77, 'last_n_outputs': 11, 'lr': 0.0019051116921093693, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.01756660158236173}"}}
exception: None

12:02:13 job_callback for (8, 0, 20) started
12:02:13 DISPATCHER: Trying to submit another job.
12:02:13 job_callback for (8, 0, 20) got condition
12:02:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:02:13 HBMASTER: Trying to run another job!
12:02:13 job_callback for (8, 0, 20) finished
12:02:13 start sampling a new configuration.
12:02:13 done sampling a new configuration.
12:02:13 HBMASTER: schedule new run for iteration 8
12:02:13 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
12:02:13 HBMASTER: submitting job (8, 0, 21) to dispatcher
12:02:13 DISPATCHER: trying to submit job (8, 0, 21)
12:02:13 DISPATCHER: trying to notify the job_runner thread.
12:02:13 HBMASTER: job (8, 0, 21) submitted to dispatcher
12:02:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:02:13 DISPATCHER: Trying to submit another job.
12:02:13 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:02:13 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:02:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:02:13 WORKER: start processing job (8, 0, 21)
12:02:13 WORKER: args: ()
12:02:13 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 45, 'lr': 0.010202020050553354, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.029969896028242012}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:02:24 DISPATCHER: Starting worker discovery
12:02:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:02:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-557:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

12:03:07 WORKER: done with job (8, 0, 21), trying to register it.
12:03:07 WORKER: registered result for job (8, 0, 21) with dispatcher
12:03:07 DISPATCHER: job (8, 0, 21) finished
12:03:07 DISPATCHER: register_result: lock acquired
12:03:07 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:03:07 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 45, 'lr': 0.010202020050553354, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.029969896028242012}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.01866568453319269, 'info': {'data05': -0.01866568453319269, 'config': "{'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 45, 'lr': 0.010202020050553354, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.029969896028242012}"}}
exception: None

12:03:07 job_callback for (8, 0, 21) started
12:03:07 job_callback for (8, 0, 21) got condition
12:03:07 DISPATCHER: Trying to submit another job.
12:03:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:03:07 HBMASTER: Trying to run another job!
12:03:07 job_callback for (8, 0, 21) finished
12:03:07 start sampling a new configuration.
12:03:07 best_vector: [3, 0.9095929485687063, 0.22891752240503757, 0.033441838806156476, 0.16061737792845826, 0, 0.9048249151994129, 0.04457955464798762], 0.004952744014904978, 1.260822294425667, 0.0062445300725754846
12:03:07 done sampling a new configuration.
12:03:07 HBMASTER: schedule new run for iteration 8
12:03:07 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
12:03:07 HBMASTER: submitting job (8, 0, 22) to dispatcher
12:03:07 DISPATCHER: trying to submit job (8, 0, 22)
12:03:07 DISPATCHER: trying to notify the job_runner thread.
12:03:07 HBMASTER: job (8, 0, 22) submitted to dispatcher
12:03:07 DISPATCHER: Trying to submit another job.
12:03:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:03:07 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:03:07 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:03:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:03:07 WORKER: start processing job (8, 0, 22)
12:03:07 WORKER: args: ()
12:03:07 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 12, 'lr': 0.0011664971380603664, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.011428765921370572}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-558:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

12:03:24 DISPATCHER: Starting worker discovery
12:03:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:03:24 DISPATCHER: Finished worker discovery
12:04:02 WORKER: done with job (8, 0, 22), trying to register it.
12:04:02 WORKER: registered result for job (8, 0, 22) with dispatcher
12:04:02 DISPATCHER: job (8, 0, 22) finished
12:04:02 DISPATCHER: register_result: lock acquired
12:04:02 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:04:02 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 12, 'lr': 0.0011664971380603664, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.011428765921370572}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9422013593864604, 'info': {'data05': 0.9422013593864604, 'config': "{'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 12, 'lr': 0.0011664971380603664, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.011428765921370572}"}}
exception: None

12:04:02 job_callback for (8, 0, 22) started
12:04:02 DISPATCHER: Trying to submit another job.
12:04:02 job_callback for (8, 0, 22) got condition
12:04:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:04:02 HBMASTER: Trying to run another job!
12:04:02 job_callback for (8, 0, 22) finished
12:04:02 start sampling a new configuration.
12:04:02 best_vector: [0, 0.8712614681166562, 0.6907833588441222, 0.199212912064049, 0.1547542807241987, 0, 0.5742029169854477, 0.027176643064538243], 0.013039454854101967, 2.980598860730635, 0.03886538428268487
12:04:02 done sampling a new configuration.
12:04:02 HBMASTER: schedule new run for iteration 8
12:04:02 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
12:04:02 HBMASTER: submitting job (8, 0, 23) to dispatcher
12:04:02 DISPATCHER: trying to submit job (8, 0, 23)
12:04:02 DISPATCHER: trying to notify the job_runner thread.
12:04:02 HBMASTER: job (8, 0, 23) submitted to dispatcher
12:04:02 DISPATCHER: Trying to submit another job.
12:04:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:04:02 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:04:02 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:04:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:04:02 WORKER: start processing job (8, 0, 23)
12:04:02 WORKER: args: ()
12:04:02 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 90, 'last_n_outputs': 35, 'lr': 0.002502798143321421, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.010848198612548732}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-559:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

12:04:24 DISPATCHER: Starting worker discovery
12:04:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:04:24 DISPATCHER: Finished worker discovery
12:04:56 WORKER: done with job (8, 0, 23), trying to register it.
12:04:56 WORKER: registered result for job (8, 0, 23) with dispatcher
12:04:56 DISPATCHER: job (8, 0, 23) finished
12:04:56 DISPATCHER: register_result: lock acquired
12:04:56 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:04:56 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 90, 'last_n_outputs': 35, 'lr': 0.002502798143321421, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.010848198612548732}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9069812989228426, 'info': {'data05': 0.9069812989228426, 'config': "{'batch_size': 16, 'hidden_dim': 90, 'last_n_outputs': 35, 'lr': 0.002502798143321421, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.010848198612548732}"}}
exception: None

12:04:56 job_callback for (8, 0, 23) started
12:04:56 DISPATCHER: Trying to submit another job.
12:04:56 job_callback for (8, 0, 23) got condition
12:04:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:04:56 HBMASTER: Trying to run another job!
12:04:56 job_callback for (8, 0, 23) finished
12:04:56 start sampling a new configuration.
12:04:56 done sampling a new configuration.
12:04:56 HBMASTER: schedule new run for iteration 8
12:04:56 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
12:04:56 HBMASTER: submitting job (8, 0, 24) to dispatcher
12:04:56 DISPATCHER: trying to submit job (8, 0, 24)
12:04:56 DISPATCHER: trying to notify the job_runner thread.
12:04:56 HBMASTER: job (8, 0, 24) submitted to dispatcher
12:04:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:04:56 DISPATCHER: Trying to submit another job.
12:04:56 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:04:56 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:04:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:04:56 WORKER: start processing job (8, 0, 24)
12:04:56 WORKER: args: ()
12:04:56 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 45, 'last_n_outputs': 10, 'lr': 0.04528062001652626, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.0733951196248498}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-560:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

12:05:24 DISPATCHER: Starting worker discovery
12:05:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:05:24 DISPATCHER: Finished worker discovery
12:05:50 WORKER: done with job (8, 0, 24), trying to register it.
12:05:50 WORKER: registered result for job (8, 0, 24) with dispatcher
12:05:50 DISPATCHER: job (8, 0, 24) finished
12:05:50 DISPATCHER: register_result: lock acquired
12:05:50 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:05:50 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 45, 'last_n_outputs': 10, 'lr': 0.04528062001652626, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.0733951196248498}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 45, 'last_n_outputs': 10, 'lr': 0.04528062001652626, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.0733951196248498}"}}
exception: None

12:05:50 job_callback for (8, 0, 24) started
12:05:50 DISPATCHER: Trying to submit another job.
12:05:50 job_callback for (8, 0, 24) got condition
12:05:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:05:50 HBMASTER: Trying to run another job!
12:05:50 job_callback for (8, 0, 24) finished
12:05:50 start sampling a new configuration.
12:05:50 done sampling a new configuration.
12:05:50 HBMASTER: schedule new run for iteration 8
12:05:50 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
12:05:50 HBMASTER: submitting job (8, 0, 25) to dispatcher
12:05:50 DISPATCHER: trying to submit job (8, 0, 25)
12:05:50 DISPATCHER: trying to notify the job_runner thread.
12:05:50 HBMASTER: job (8, 0, 25) submitted to dispatcher
12:05:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:05:50 DISPATCHER: Trying to submit another job.
12:05:50 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:05:50 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:05:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:05:50 WORKER: start processing job (8, 0, 25)
12:05:50 WORKER: args: ()
12:05:50 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 34, 'last_n_outputs': 41, 'lr': 0.04544113837498637, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.13280796894905622}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-561:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

12:06:24 DISPATCHER: Starting worker discovery
12:06:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:06:24 DISPATCHER: Finished worker discovery
12:06:45 WORKER: done with job (8, 0, 25), trying to register it.
12:06:45 WORKER: registered result for job (8, 0, 25) with dispatcher
12:06:45 DISPATCHER: job (8, 0, 25) finished
12:06:45 DISPATCHER: register_result: lock acquired
12:06:45 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:06:45 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 34, 'last_n_outputs': 41, 'lr': 0.04544113837498637, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.13280796894905622}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.156321526459683, 'info': {'data05': 0.156321526459683, 'config': "{'batch_size': 16, 'hidden_dim': 34, 'last_n_outputs': 41, 'lr': 0.04544113837498637, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.13280796894905622}"}}
exception: None

12:06:45 job_callback for (8, 0, 25) started
12:06:45 job_callback for (8, 0, 25) got condition
12:06:45 DISPATCHER: Trying to submit another job.
12:06:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:06:45 HBMASTER: Trying to run another job!
12:06:45 job_callback for (8, 0, 25) finished
12:06:45 start sampling a new configuration.
12:06:45 done sampling a new configuration.
12:06:45 HBMASTER: schedule new run for iteration 8
12:06:45 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
12:06:45 HBMASTER: submitting job (8, 0, 26) to dispatcher
12:06:45 DISPATCHER: trying to submit job (8, 0, 26)
12:06:45 DISPATCHER: trying to notify the job_runner thread.
12:06:45 HBMASTER: job (8, 0, 26) submitted to dispatcher
12:06:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:06:45 DISPATCHER: Trying to submit another job.
12:06:45 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:06:45 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:06:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:06:45 WORKER: start processing job (8, 0, 26)
12:06:45 WORKER: args: ()
12:06:45 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 80, 'last_n_outputs': 41, 'lr': 0.06401780567184337, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.17747405673784247}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-562:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

12:07:24 DISPATCHER: Starting worker discovery
12:07:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:07:24 DISPATCHER: Finished worker discovery
12:07:39 WORKER: done with job (8, 0, 26), trying to register it.
12:07:39 WORKER: registered result for job (8, 0, 26) with dispatcher
12:07:39 DISPATCHER: job (8, 0, 26) finished
12:07:39 DISPATCHER: register_result: lock acquired
12:07:39 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:07:39 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 80, 'last_n_outputs': 41, 'lr': 0.06401780567184337, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.17747405673784247}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 80, 'last_n_outputs': 41, 'lr': 0.06401780567184337, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.17747405673784247}"}}
exception: None

12:07:39 job_callback for (8, 0, 26) started
12:07:39 DISPATCHER: Trying to submit another job.
12:07:39 job_callback for (8, 0, 26) got condition
12:07:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:07:39 HBMASTER: Trying to run another job!
12:07:39 job_callback for (8, 0, 26) finished
12:07:39 ITERATION: Advancing config (8, 0, 4) to next budget 133.333333
12:07:39 ITERATION: Advancing config (8, 0, 6) to next budget 133.333333
12:07:39 ITERATION: Advancing config (8, 0, 7) to next budget 133.333333
12:07:39 ITERATION: Advancing config (8, 0, 9) to next budget 133.333333
12:07:39 ITERATION: Advancing config (8, 0, 13) to next budget 133.333333
12:07:39 ITERATION: Advancing config (8, 0, 17) to next budget 133.333333
12:07:39 ITERATION: Advancing config (8, 0, 20) to next budget 133.333333
12:07:39 ITERATION: Advancing config (8, 0, 22) to next budget 133.333333
12:07:39 ITERATION: Advancing config (8, 0, 23) to next budget 133.333333
12:07:39 HBMASTER: schedule new run for iteration 8
12:07:39 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
12:07:39 HBMASTER: submitting job (8, 0, 4) to dispatcher
12:07:39 DISPATCHER: trying to submit job (8, 0, 4)
12:07:39 DISPATCHER: trying to notify the job_runner thread.
12:07:39 HBMASTER: job (8, 0, 4) submitted to dispatcher
12:07:39 DISPATCHER: Trying to submit another job.
12:07:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:07:39 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:07:39 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:07:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:07:39 WORKER: start processing job (8, 0, 4)
12:07:39 WORKER: args: ()
12:07:39 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 77, 'last_n_outputs': 20, 'lr': 0.003761908904292848, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.01057522588027713}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-563:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

12:08:24 DISPATCHER: Starting worker discovery
12:08:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:08:24 DISPATCHER: Finished worker discovery
12:09:24 DISPATCHER: Starting worker discovery
12:09:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:09:24 DISPATCHER: Finished worker discovery
12:10:04 WORKER: done with job (8, 0, 4), trying to register it.
12:10:04 WORKER: registered result for job (8, 0, 4) with dispatcher
12:10:04 DISPATCHER: job (8, 0, 4) finished
12:10:04 DISPATCHER: register_result: lock acquired
12:10:04 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:10:04 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 77, 'last_n_outputs': 20, 'lr': 0.003761908904292848, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.01057522588027713}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8090582933461121, 'info': {'data05': 0.8090582933461121, 'config': "{'batch_size': 16, 'hidden_dim': 77, 'last_n_outputs': 20, 'lr': 0.003761908904292848, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.01057522588027713}"}}
exception: None

12:10:04 job_callback for (8, 0, 4) started
12:10:04 DISPATCHER: Trying to submit another job.
12:10:04 job_callback for (8, 0, 4) got condition
12:10:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:10:04 HBMASTER: Trying to run another job!
12:10:04 job_callback for (8, 0, 4) finished
12:10:04 HBMASTER: schedule new run for iteration 8
12:10:04 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
12:10:04 HBMASTER: submitting job (8, 0, 6) to dispatcher
12:10:04 DISPATCHER: trying to submit job (8, 0, 6)
12:10:04 DISPATCHER: trying to notify the job_runner thread.
12:10:04 HBMASTER: job (8, 0, 6) submitted to dispatcher
12:10:04 DISPATCHER: Trying to submit another job.
12:10:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:10:04 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:10:04 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:10:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:10:04 WORKER: start processing job (8, 0, 6)
12:10:04 WORKER: args: ()
12:10:04 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 77, 'last_n_outputs': 24, 'lr': 0.003296649932859044, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.012573309745293566}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-564:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

12:10:24 DISPATCHER: Starting worker discovery
12:10:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:10:24 DISPATCHER: Finished worker discovery
12:11:24 DISPATCHER: Starting worker discovery
12:11:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:11:24 DISPATCHER: Finished worker discovery
12:12:24 DISPATCHER: Starting worker discovery
12:12:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:12:24 DISPATCHER: Finished worker discovery
12:12:27 WORKER: done with job (8, 0, 6), trying to register it.
12:12:27 WORKER: registered result for job (8, 0, 6) with dispatcher
12:12:27 DISPATCHER: job (8, 0, 6) finished
12:12:27 DISPATCHER: register_result: lock acquired
12:12:27 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:12:27 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 77, 'last_n_outputs': 24, 'lr': 0.003296649932859044, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.012573309745293566}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9342193387846303, 'info': {'data05': 0.9342193387846303, 'config': "{'batch_size': 128, 'hidden_dim': 77, 'last_n_outputs': 24, 'lr': 0.003296649932859044, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.012573309745293566}"}}
exception: None

12:12:27 job_callback for (8, 0, 6) started
12:12:27 job_callback for (8, 0, 6) got condition
12:12:27 DISPATCHER: Trying to submit another job.
12:12:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:12:27 HBMASTER: Trying to run another job!
12:12:27 job_callback for (8, 0, 6) finished
12:12:27 HBMASTER: schedule new run for iteration 8
12:12:27 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
12:12:27 HBMASTER: submitting job (8, 0, 7) to dispatcher
12:12:27 DISPATCHER: trying to submit job (8, 0, 7)
12:12:27 DISPATCHER: trying to notify the job_runner thread.
12:12:27 HBMASTER: job (8, 0, 7) submitted to dispatcher
12:12:27 DISPATCHER: Trying to submit another job.
12:12:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:12:27 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:12:27 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:12:27 WORKER: start processing job (8, 0, 7)
12:12:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:12:27 WORKER: args: ()
12:12:27 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 97, 'last_n_outputs': 24, 'lr': 0.0031296289509355224, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.01353047557998333}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-565:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

12:13:24 DISPATCHER: Starting worker discovery
12:13:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:13:24 DISPATCHER: Finished worker discovery
12:14:24 DISPATCHER: Starting worker discovery
12:14:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:14:24 DISPATCHER: Finished worker discovery
12:14:50 WORKER: done with job (8, 0, 7), trying to register it.
12:14:50 WORKER: registered result for job (8, 0, 7) with dispatcher
12:14:50 DISPATCHER: job (8, 0, 7) finished
12:14:50 DISPATCHER: register_result: lock acquired
12:14:50 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:14:50 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 97, 'last_n_outputs': 24, 'lr': 0.0031296289509355224, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.01353047557998333}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9273599152224639, 'info': {'data05': 0.9273599152224639, 'config': "{'batch_size': 32, 'hidden_dim': 97, 'last_n_outputs': 24, 'lr': 0.0031296289509355224, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.01353047557998333}"}}
exception: None

12:14:50 job_callback for (8, 0, 7) started
12:14:50 DISPATCHER: Trying to submit another job.
12:14:50 job_callback for (8, 0, 7) got condition
12:14:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:14:50 HBMASTER: Trying to run another job!
12:14:50 job_callback for (8, 0, 7) finished
12:14:50 HBMASTER: schedule new run for iteration 8
12:14:50 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
12:14:50 HBMASTER: submitting job (8, 0, 9) to dispatcher
12:14:50 DISPATCHER: trying to submit job (8, 0, 9)
12:14:50 DISPATCHER: trying to notify the job_runner thread.
12:14:50 HBMASTER: job (8, 0, 9) submitted to dispatcher
12:14:50 DISPATCHER: Trying to submit another job.
12:14:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:14:50 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:14:50 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:14:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:14:50 WORKER: start processing job (8, 0, 9)
12:14:50 WORKER: args: ()
12:14:50 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 90, 'last_n_outputs': 26, 'lr': 0.004944153846062533, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.015770633765871605}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-566:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

12:15:24 DISPATCHER: Starting worker discovery
12:15:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:15:24 DISPATCHER: Finished worker discovery
12:16:24 DISPATCHER: Starting worker discovery
12:16:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:16:24 DISPATCHER: Finished worker discovery
12:17:14 WORKER: done with job (8, 0, 9), trying to register it.
12:17:14 WORKER: registered result for job (8, 0, 9) with dispatcher
12:17:14 DISPATCHER: job (8, 0, 9) finished
12:17:14 DISPATCHER: register_result: lock acquired
12:17:14 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:17:14 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 90, 'last_n_outputs': 26, 'lr': 0.004944153846062533, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.015770633765871605}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7786145583684758, 'info': {'data05': 0.7786145583684758, 'config': "{'batch_size': 16, 'hidden_dim': 90, 'last_n_outputs': 26, 'lr': 0.004944153846062533, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.015770633765871605}"}}
exception: None

12:17:14 job_callback for (8, 0, 9) started
12:17:14 DISPATCHER: Trying to submit another job.
12:17:14 job_callback for (8, 0, 9) got condition
12:17:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:17:14 HBMASTER: Trying to run another job!
12:17:14 job_callback for (8, 0, 9) finished
12:17:14 HBMASTER: schedule new run for iteration 8
12:17:14 HBMASTER: trying submitting job (8, 0, 13) to dispatcher
12:17:14 HBMASTER: submitting job (8, 0, 13) to dispatcher
12:17:14 DISPATCHER: trying to submit job (8, 0, 13)
12:17:14 DISPATCHER: trying to notify the job_runner thread.
12:17:14 HBMASTER: job (8, 0, 13) submitted to dispatcher
12:17:14 DISPATCHER: Trying to submit another job.
12:17:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:17:14 DISPATCHER: starting job (8, 0, 13) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:17:14 DISPATCHER: job (8, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:17:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:17:14 WORKER: start processing job (8, 0, 13)
12:17:14 WORKER: args: ()
12:17:14 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 48, 'last_n_outputs': 43, 'lr': 0.0012618863861389386, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.0414525599061458}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:17:24 DISPATCHER: Starting worker discovery
12:17:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:17:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-567:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

12:18:24 DISPATCHER: Starting worker discovery
12:18:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:18:24 DISPATCHER: Finished worker discovery
12:19:24 DISPATCHER: Starting worker discovery
12:19:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:19:24 DISPATCHER: Finished worker discovery
12:19:37 WORKER: done with job (8, 0, 13), trying to register it.
12:19:37 WORKER: registered result for job (8, 0, 13) with dispatcher
12:19:37 DISPATCHER: job (8, 0, 13) finished
12:19:37 DISPATCHER: register_result: lock acquired
12:19:37 DISPATCHER: job (8, 0, 13) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:19:37 job_id: (8, 0, 13)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 48, 'last_n_outputs': 43, 'lr': 0.0012618863861389386, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.0414525599061458}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8985255180828127, 'info': {'data05': 0.8985255180828127, 'config': "{'batch_size': 64, 'hidden_dim': 48, 'last_n_outputs': 43, 'lr': 0.0012618863861389386, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.0414525599061458}"}}
exception: None

12:19:37 job_callback for (8, 0, 13) started
12:19:37 job_callback for (8, 0, 13) got condition
12:19:37 DISPATCHER: Trying to submit another job.
12:19:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:19:37 HBMASTER: Trying to run another job!
12:19:37 job_callback for (8, 0, 13) finished
12:19:37 HBMASTER: schedule new run for iteration 8
12:19:37 HBMASTER: trying submitting job (8, 0, 17) to dispatcher
12:19:37 HBMASTER: submitting job (8, 0, 17) to dispatcher
12:19:37 DISPATCHER: trying to submit job (8, 0, 17)
12:19:37 DISPATCHER: trying to notify the job_runner thread.
12:19:37 HBMASTER: job (8, 0, 17) submitted to dispatcher
12:19:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:19:37 DISPATCHER: Trying to submit another job.
12:19:37 DISPATCHER: starting job (8, 0, 17) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:19:37 DISPATCHER: job (8, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:19:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:19:37 WORKER: start processing job (8, 0, 17)
12:19:37 WORKER: args: ()
12:19:37 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 52, 'last_n_outputs': 48, 'lr': 0.0012169240613096749, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.04991208002032385}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-568:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

12:20:24 DISPATCHER: Starting worker discovery
12:20:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:20:24 DISPATCHER: Finished worker discovery
12:21:24 DISPATCHER: Starting worker discovery
12:21:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:21:24 DISPATCHER: Finished worker discovery
12:22:00 WORKER: done with job (8, 0, 17), trying to register it.
12:22:00 WORKER: registered result for job (8, 0, 17) with dispatcher
12:22:00 DISPATCHER: job (8, 0, 17) finished
12:22:00 DISPATCHER: register_result: lock acquired
12:22:00 DISPATCHER: job (8, 0, 17) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:22:00 job_id: (8, 0, 17)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 52, 'last_n_outputs': 48, 'lr': 0.0012169240613096749, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.04991208002032385}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.708112842973079, 'info': {'data05': 0.708112842973079, 'config': "{'batch_size': 64, 'hidden_dim': 52, 'last_n_outputs': 48, 'lr': 0.0012169240613096749, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.04991208002032385}"}}
exception: None

12:22:00 job_callback for (8, 0, 17) started
12:22:00 job_callback for (8, 0, 17) got condition
12:22:00 DISPATCHER: Trying to submit another job.
12:22:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:22:00 HBMASTER: Trying to run another job!
12:22:00 job_callback for (8, 0, 17) finished
12:22:00 HBMASTER: schedule new run for iteration 8
12:22:00 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
12:22:00 HBMASTER: submitting job (8, 0, 20) to dispatcher
12:22:00 DISPATCHER: trying to submit job (8, 0, 20)
12:22:00 DISPATCHER: trying to notify the job_runner thread.
12:22:00 HBMASTER: job (8, 0, 20) submitted to dispatcher
12:22:00 DISPATCHER: Trying to submit another job.
12:22:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:22:00 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:22:00 WORKER: start processing job (8, 0, 20)
12:22:00 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:22:00 WORKER: args: ()
12:22:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:22:00 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 77, 'last_n_outputs': 11, 'lr': 0.0019051116921093693, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.01756660158236173}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-569:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

12:22:24 DISPATCHER: Starting worker discovery
12:22:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:22:24 DISPATCHER: Finished worker discovery
12:23:24 DISPATCHER: Starting worker discovery
12:23:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:23:24 DISPATCHER: Finished worker discovery
12:24:23 WORKER: done with job (8, 0, 20), trying to register it.
12:24:23 WORKER: registered result for job (8, 0, 20) with dispatcher
12:24:23 DISPATCHER: job (8, 0, 20) finished
12:24:23 DISPATCHER: register_result: lock acquired
12:24:23 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:24:23 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 77, 'last_n_outputs': 11, 'lr': 0.0019051116921093693, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.01756660158236173}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9282605861738937, 'info': {'data05': 0.9282605861738937, 'config': "{'batch_size': 128, 'hidden_dim': 77, 'last_n_outputs': 11, 'lr': 0.0019051116921093693, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.01756660158236173}"}}
exception: None

12:24:23 job_callback for (8, 0, 20) started
12:24:23 job_callback for (8, 0, 20) got condition
12:24:23 DISPATCHER: Trying to submit another job.
12:24:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:24:23 HBMASTER: Trying to run another job!
12:24:23 job_callback for (8, 0, 20) finished
12:24:23 HBMASTER: schedule new run for iteration 8
12:24:23 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
12:24:23 HBMASTER: submitting job (8, 0, 22) to dispatcher
12:24:23 DISPATCHER: trying to submit job (8, 0, 22)
12:24:23 DISPATCHER: trying to notify the job_runner thread.
12:24:23 HBMASTER: job (8, 0, 22) submitted to dispatcher
12:24:23 DISPATCHER: Trying to submit another job.
12:24:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:24:23 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:24:23 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:24:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:24:23 WORKER: start processing job (8, 0, 22)
12:24:23 WORKER: args: ()
12:24:23 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 12, 'lr': 0.0011664971380603664, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.011428765921370572}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:24:24 DISPATCHER: Starting worker discovery
12:24:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:24:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-570:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

12:25:24 DISPATCHER: Starting worker discovery
12:25:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:25:24 DISPATCHER: Finished worker discovery
12:26:24 DISPATCHER: Starting worker discovery
12:26:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:26:24 DISPATCHER: Finished worker discovery
12:26:47 WORKER: done with job (8, 0, 22), trying to register it.
12:26:47 WORKER: registered result for job (8, 0, 22) with dispatcher
12:26:47 DISPATCHER: job (8, 0, 22) finished
12:26:47 DISPATCHER: register_result: lock acquired
12:26:47 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:26:47 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 12, 'lr': 0.0011664971380603664, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.011428765921370572}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9601110830729563, 'info': {'data05': 0.9601110830729563, 'config': "{'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 12, 'lr': 0.0011664971380603664, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.011428765921370572}"}}
exception: None

12:26:47 job_callback for (8, 0, 22) started
12:26:47 job_callback for (8, 0, 22) got condition
12:26:47 DISPATCHER: Trying to submit another job.
12:26:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:26:47 HBMASTER: Trying to run another job!
12:26:47 job_callback for (8, 0, 22) finished
12:26:47 HBMASTER: schedule new run for iteration 8
12:26:47 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
12:26:47 HBMASTER: submitting job (8, 0, 23) to dispatcher
12:26:47 DISPATCHER: trying to submit job (8, 0, 23)
12:26:47 DISPATCHER: trying to notify the job_runner thread.
12:26:47 HBMASTER: job (8, 0, 23) submitted to dispatcher
12:26:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:26:47 DISPATCHER: Trying to submit another job.
12:26:47 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:26:47 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:26:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:26:47 WORKER: start processing job (8, 0, 23)
12:26:47 WORKER: args: ()
12:26:47 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 90, 'last_n_outputs': 35, 'lr': 0.002502798143321421, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.010848198612548732}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-571:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

12:27:24 DISPATCHER: Starting worker discovery
12:27:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:27:24 DISPATCHER: Finished worker discovery
12:28:24 DISPATCHER: Starting worker discovery
12:28:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:28:24 DISPATCHER: Finished worker discovery
12:29:10 WORKER: done with job (8, 0, 23), trying to register it.
12:29:10 WORKER: registered result for job (8, 0, 23) with dispatcher
12:29:10 DISPATCHER: job (8, 0, 23) finished
12:29:10 DISPATCHER: register_result: lock acquired
12:29:10 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:29:10 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 90, 'last_n_outputs': 35, 'lr': 0.002502798143321421, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.010848198612548732}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8617315154172369, 'info': {'data05': 0.8617315154172369, 'config': "{'batch_size': 16, 'hidden_dim': 90, 'last_n_outputs': 35, 'lr': 0.002502798143321421, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.010848198612548732}"}}
exception: None

12:29:10 job_callback for (8, 0, 23) started
12:29:10 job_callback for (8, 0, 23) got condition
12:29:10 DISPATCHER: Trying to submit another job.
12:29:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:29:10 HBMASTER: Trying to run another job!
12:29:10 job_callback for (8, 0, 23) finished
12:29:10 ITERATION: Advancing config (8, 0, 6) to next budget 400.000000
12:29:10 ITERATION: Advancing config (8, 0, 20) to next budget 400.000000
12:29:10 ITERATION: Advancing config (8, 0, 22) to next budget 400.000000
12:29:10 HBMASTER: schedule new run for iteration 8
12:29:10 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
12:29:10 HBMASTER: submitting job (8, 0, 6) to dispatcher
12:29:10 DISPATCHER: trying to submit job (8, 0, 6)
12:29:10 DISPATCHER: trying to notify the job_runner thread.
12:29:10 HBMASTER: job (8, 0, 6) submitted to dispatcher
12:29:10 DISPATCHER: Trying to submit another job.
12:29:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:29:10 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:29:10 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:29:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:29:10 WORKER: start processing job (8, 0, 6)
12:29:10 WORKER: args: ()
12:29:10 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 77, 'last_n_outputs': 24, 'lr': 0.003296649932859044, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.012573309745293566}, 'budget': 400.0, 'working_directory': '.'}
12:29:24 DISPATCHER: Starting worker discovery
12:29:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:29:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-572:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

12:30:24 DISPATCHER: Starting worker discovery
12:30:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:30:24 DISPATCHER: Finished worker discovery
12:31:24 DISPATCHER: Starting worker discovery
12:31:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:31:24 DISPATCHER: Finished worker discovery
12:32:24 DISPATCHER: Starting worker discovery
12:32:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:32:24 DISPATCHER: Finished worker discovery
12:33:24 DISPATCHER: Starting worker discovery
12:33:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:33:24 DISPATCHER: Finished worker discovery
12:34:24 DISPATCHER: Starting worker discovery
12:34:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:34:24 DISPATCHER: Finished worker discovery
12:35:24 DISPATCHER: Starting worker discovery
12:35:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:35:24 DISPATCHER: Finished worker discovery
12:36:01 WORKER: done with job (8, 0, 6), trying to register it.
12:36:01 WORKER: registered result for job (8, 0, 6) with dispatcher
12:36:01 DISPATCHER: job (8, 0, 6) finished
12:36:01 DISPATCHER: register_result: lock acquired
12:36:01 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:36:01 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 77, 'last_n_outputs': 24, 'lr': 0.003296649932859044, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.012573309745293566}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.964995426286601, 'info': {'data05': 0.964995426286601, 'config': "{'batch_size': 128, 'hidden_dim': 77, 'last_n_outputs': 24, 'lr': 0.003296649932859044, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.012573309745293566}"}}
exception: None

12:36:01 job_callback for (8, 0, 6) started
12:36:01 DISPATCHER: Trying to submit another job.
12:36:01 job_callback for (8, 0, 6) got condition
12:36:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:36:01 done building a new model for budget 400.000000 based on 9/21 split
Best loss for this budget:-0.964995





12:36:01 HBMASTER: Trying to run another job!
12:36:01 job_callback for (8, 0, 6) finished
12:36:01 HBMASTER: schedule new run for iteration 8
12:36:01 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
12:36:01 HBMASTER: submitting job (8, 0, 20) to dispatcher
12:36:01 DISPATCHER: trying to submit job (8, 0, 20)
12:36:01 DISPATCHER: trying to notify the job_runner thread.
12:36:01 HBMASTER: job (8, 0, 20) submitted to dispatcher
12:36:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:36:01 DISPATCHER: Trying to submit another job.
12:36:01 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:36:01 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:36:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:36:01 WORKER: start processing job (8, 0, 20)
12:36:01 WORKER: args: ()
12:36:01 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 77, 'last_n_outputs': 11, 'lr': 0.0019051116921093693, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.01756660158236173}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-573:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

12:36:24 DISPATCHER: Starting worker discovery
12:36:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:36:24 DISPATCHER: Finished worker discovery
12:37:24 DISPATCHER: Starting worker discovery
12:37:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:37:24 DISPATCHER: Finished worker discovery
12:38:24 DISPATCHER: Starting worker discovery
12:38:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:38:24 DISPATCHER: Finished worker discovery
12:39:24 DISPATCHER: Starting worker discovery
12:39:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:39:24 DISPATCHER: Finished worker discovery
12:40:24 DISPATCHER: Starting worker discovery
12:40:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:40:24 DISPATCHER: Finished worker discovery
12:41:24 DISPATCHER: Starting worker discovery
12:41:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:41:24 DISPATCHER: Finished worker discovery
12:42:24 DISPATCHER: Starting worker discovery
12:42:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:42:24 DISPATCHER: Finished worker discovery
12:42:51 WORKER: done with job (8, 0, 20), trying to register it.
12:42:51 WORKER: registered result for job (8, 0, 20) with dispatcher
12:42:51 DISPATCHER: job (8, 0, 20) finished
12:42:51 DISPATCHER: register_result: lock acquired
12:42:51 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:42:51 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 77, 'last_n_outputs': 11, 'lr': 0.0019051116921093693, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.01756660158236173}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9043378563771495, 'info': {'data05': 0.9043378563771495, 'config': "{'batch_size': 128, 'hidden_dim': 77, 'last_n_outputs': 11, 'lr': 0.0019051116921093693, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.01756660158236173}"}}
exception: None

12:42:51 job_callback for (8, 0, 20) started
12:42:51 DISPATCHER: Trying to submit another job.
12:42:51 job_callback for (8, 0, 20) got condition
12:42:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:42:51 done building a new model for budget 400.000000 based on 9/22 split
Best loss for this budget:-0.964995





12:42:51 HBMASTER: Trying to run another job!
12:42:51 job_callback for (8, 0, 20) finished
12:42:51 HBMASTER: schedule new run for iteration 8
12:42:51 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
12:42:51 HBMASTER: submitting job (8, 0, 22) to dispatcher
12:42:51 DISPATCHER: trying to submit job (8, 0, 22)
12:42:51 DISPATCHER: trying to notify the job_runner thread.
12:42:51 HBMASTER: job (8, 0, 22) submitted to dispatcher
12:42:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:42:51 DISPATCHER: Trying to submit another job.
12:42:51 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:42:51 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:42:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:42:51 WORKER: start processing job (8, 0, 22)
12:42:51 WORKER: args: ()
12:42:51 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 12, 'lr': 0.0011664971380603664, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.011428765921370572}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-574:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

12:43:24 DISPATCHER: Starting worker discovery
12:43:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:43:24 DISPATCHER: Finished worker discovery
12:44:24 DISPATCHER: Starting worker discovery
12:44:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:44:24 DISPATCHER: Finished worker discovery
12:45:24 DISPATCHER: Starting worker discovery
12:45:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:45:24 DISPATCHER: Finished worker discovery
12:46:24 DISPATCHER: Starting worker discovery
12:46:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:46:24 DISPATCHER: Finished worker discovery
12:47:24 DISPATCHER: Starting worker discovery
12:47:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:47:24 DISPATCHER: Finished worker discovery
12:48:24 DISPATCHER: Starting worker discovery
12:48:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:48:24 DISPATCHER: Finished worker discovery
12:49:24 DISPATCHER: Starting worker discovery
12:49:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:49:24 DISPATCHER: Finished worker discovery
12:49:41 WORKER: done with job (8, 0, 22), trying to register it.
12:49:41 WORKER: registered result for job (8, 0, 22) with dispatcher
12:49:41 DISPATCHER: job (8, 0, 22) finished
12:49:41 DISPATCHER: register_result: lock acquired
12:49:41 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
12:49:41 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 12, 'lr': 0.0011664971380603664, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.011428765921370572}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9442584147803305, 'info': {'data05': 0.9442584147803305, 'config': "{'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 12, 'lr': 0.0011664971380603664, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.011428765921370572}"}}
exception: None

12:49:41 job_callback for (8, 0, 22) started
12:49:41 job_callback for (8, 0, 22) got condition
12:49:41 DISPATCHER: Trying to submit another job.
12:49:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:49:41 done building a new model for budget 400.000000 based on 9/22 split
Best loss for this budget:-0.964995





12:49:41 HBMASTER: Trying to run another job!
12:49:41 job_callback for (8, 0, 22) finished
12:49:41 ITERATION: Advancing config (8, 0, 6) to next budget 1200.000000
12:49:41 HBMASTER: schedule new run for iteration 8
12:49:41 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
12:49:41 HBMASTER: submitting job (8, 0, 6) to dispatcher
12:49:41 DISPATCHER: trying to submit job (8, 0, 6)
12:49:41 DISPATCHER: trying to notify the job_runner thread.
12:49:41 HBMASTER: job (8, 0, 6) submitted to dispatcher
12:49:41 DISPATCHER: Trying to submit another job.
12:49:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:49:41 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:49:41 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
12:49:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:49:41 WORKER: start processing job (8, 0, 6)
12:49:41 WORKER: args: ()
12:49:41 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 77, 'last_n_outputs': 24, 'lr': 0.003296649932859044, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.012573309745293566}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-575:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

12:50:24 DISPATCHER: Starting worker discovery
12:50:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:50:24 DISPATCHER: Finished worker discovery
12:51:24 DISPATCHER: Starting worker discovery
12:51:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:51:24 DISPATCHER: Finished worker discovery
12:52:24 DISPATCHER: Starting worker discovery
12:52:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:52:24 DISPATCHER: Finished worker discovery
12:53:24 DISPATCHER: Starting worker discovery
12:53:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:53:24 DISPATCHER: Finished worker discovery
12:54:24 DISPATCHER: Starting worker discovery
12:54:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:54:24 DISPATCHER: Finished worker discovery
12:55:24 DISPATCHER: Starting worker discovery
12:55:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:55:24 DISPATCHER: Finished worker discovery
12:56:24 DISPATCHER: Starting worker discovery
12:56:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:56:24 DISPATCHER: Finished worker discovery
12:57:24 DISPATCHER: Starting worker discovery
12:57:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:57:24 DISPATCHER: Finished worker discovery
12:58:24 DISPATCHER: Starting worker discovery
12:58:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:58:24 DISPATCHER: Finished worker discovery
12:59:24 DISPATCHER: Starting worker discovery
12:59:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:59:24 DISPATCHER: Finished worker discovery
13:00:24 DISPATCHER: Starting worker discovery
13:00:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:00:24 DISPATCHER: Finished worker discovery
13:01:24 DISPATCHER: Starting worker discovery
13:01:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:01:24 DISPATCHER: Finished worker discovery
13:02:24 DISPATCHER: Starting worker discovery
13:02:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:02:24 DISPATCHER: Finished worker discovery
13:03:24 DISPATCHER: Starting worker discovery
13:03:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:03:24 DISPATCHER: Finished worker discovery
13:04:24 DISPATCHER: Starting worker discovery
13:04:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:04:24 DISPATCHER: Finished worker discovery
13:05:24 DISPATCHER: Starting worker discovery
13:05:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:05:24 DISPATCHER: Finished worker discovery
13:06:24 DISPATCHER: Starting worker discovery
13:06:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:06:24 DISPATCHER: Finished worker discovery
13:07:24 DISPATCHER: Starting worker discovery
13:07:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:07:24 DISPATCHER: Finished worker discovery
13:08:24 DISPATCHER: Starting worker discovery
13:08:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:08:24 DISPATCHER: Finished worker discovery
13:09:24 DISPATCHER: Starting worker discovery
13:09:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:09:24 DISPATCHER: Finished worker discovery
13:09:52 WORKER: done with job (8, 0, 6), trying to register it.
13:09:52 WORKER: registered result for job (8, 0, 6) with dispatcher
13:09:52 DISPATCHER: job (8, 0, 6) finished
13:09:52 DISPATCHER: register_result: lock acquired
13:09:52 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
13:09:52 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 77, 'last_n_outputs': 24, 'lr': 0.003296649932859044, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.012573309745293566}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.966694529230155, 'info': {'data05': 0.966694529230155, 'config': "{'batch_size': 128, 'hidden_dim': 77, 'last_n_outputs': 24, 'lr': 0.003296649932859044, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.012573309745293566}"}}
exception: None

13:09:52 job_callback for (8, 0, 6) started
13:09:52 job_callback for (8, 0, 6) got condition
13:09:52 DISPATCHER: Trying to submit another job.
13:09:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:09:52 HBMASTER: Trying to run another job!
13:09:52 job_callback for (8, 0, 6) finished
13:09:52 start sampling a new configuration.
13:09:52 best_vector: [0, 0.7170834962040286, 0.16524834805441743, 0.1421808451836098, 0.09846392690123373, 0, 0.8479710431542814, 0.04454654657265569], 5.4702116063015704e-05, 584.7996005286309, 0.03198977562172239
13:09:52 done sampling a new configuration.
13:09:52 HBMASTER: schedule new run for iteration 9
13:09:52 HBMASTER: trying submitting job (9, 0, 0) to dispatcher
13:09:52 HBMASTER: submitting job (9, 0, 0) to dispatcher
13:09:52 DISPATCHER: trying to submit job (9, 0, 0)
13:09:52 DISPATCHER: trying to notify the job_runner thread.
13:09:52 HBMASTER: job (9, 0, 0) submitted to dispatcher
13:09:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:09:52 DISPATCHER: Trying to submit another job.
13:09:52 DISPATCHER: starting job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:09:52 DISPATCHER: job (9, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:09:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:09:52 WORKER: start processing job (9, 0, 0)
13:09:52 WORKER: args: ()
13:09:52 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 78, 'last_n_outputs': 9, 'lr': 0.0019246939907480102, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.011427635862507859}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-576:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:10:24 DISPATCHER: Starting worker discovery
13:10:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:10:24 DISPATCHER: Finished worker discovery
13:11:24 DISPATCHER: Starting worker discovery
13:11:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:11:24 DISPATCHER: Finished worker discovery
13:12:16 WORKER: done with job (9, 0, 0), trying to register it.
13:12:16 WORKER: registered result for job (9, 0, 0) with dispatcher
13:12:16 DISPATCHER: job (9, 0, 0) finished
13:12:16 DISPATCHER: register_result: lock acquired
13:12:16 DISPATCHER: job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
13:12:16 job_id: (9, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 78, 'last_n_outputs': 9, 'lr': 0.0019246939907480102, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.011427635862507859}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8182726092406432, 'info': {'data05': 0.8182726092406432, 'config': "{'batch_size': 16, 'hidden_dim': 78, 'last_n_outputs': 9, 'lr': 0.0019246939907480102, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.011427635862507859}"}}
exception: None

13:12:16 job_callback for (9, 0, 0) started
13:12:16 DISPATCHER: Trying to submit another job.
13:12:16 job_callback for (9, 0, 0) got condition
13:12:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:12:16 HBMASTER: Trying to run another job!
13:12:16 job_callback for (9, 0, 0) finished
13:12:16 start sampling a new configuration.
13:12:16 done sampling a new configuration.
13:12:16 HBMASTER: schedule new run for iteration 9
13:12:16 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
13:12:16 HBMASTER: submitting job (9, 0, 1) to dispatcher
13:12:16 DISPATCHER: trying to submit job (9, 0, 1)
13:12:16 DISPATCHER: trying to notify the job_runner thread.
13:12:16 HBMASTER: job (9, 0, 1) submitted to dispatcher
13:12:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:12:16 DISPATCHER: Trying to submit another job.
13:12:16 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:12:16 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:12:16 WORKER: start processing job (9, 0, 1)
13:12:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:12:16 WORKER: args: ()
13:12:16 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 69, 'last_n_outputs': 18, 'lr': 0.003951118222523556, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.0677119480633583}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:12:24 DISPATCHER: Starting worker discovery
13:12:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:12:24 DISPATCHER: Finished worker discovery
Exception in thread Thread-577:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:13:24 DISPATCHER: Starting worker discovery
13:13:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:13:24 DISPATCHER: Finished worker discovery
13:14:24 DISPATCHER: Starting worker discovery
13:14:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:14:24 DISPATCHER: Finished worker discovery
13:14:39 WORKER: done with job (9, 0, 1), trying to register it.
13:14:39 WORKER: registered result for job (9, 0, 1) with dispatcher
13:14:39 DISPATCHER: job (9, 0, 1) finished
13:14:39 DISPATCHER: register_result: lock acquired
13:14:39 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
13:14:39 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 69, 'last_n_outputs': 18, 'lr': 0.003951118222523556, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.0677119480633583}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': 0.011712189852287157, 'info': {'data05': -0.011712189852287157, 'config': "{'batch_size': 32, 'hidden_dim': 69, 'last_n_outputs': 18, 'lr': 0.003951118222523556, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.0677119480633583}"}}
exception: None

13:14:39 job_callback for (9, 0, 1) started
13:14:39 DISPATCHER: Trying to submit another job.
13:14:39 job_callback for (9, 0, 1) got condition
13:14:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:14:39 HBMASTER: Trying to run another job!
13:14:39 job_callback for (9, 0, 1) finished
13:14:39 start sampling a new configuration.
13:14:39 best_vector: [3, 0.6920258784317673, 0.10368927756080809, 0.14417656219342356, 0.10035707920878024, 0, 0.7823758569653985, 0.376073985653396], 0.0001777238235298583, 224.0487025810678, 0.039818792079611406
13:14:39 done sampling a new configuration.
13:14:39 HBMASTER: schedule new run for iteration 9
13:14:39 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
13:14:39 HBMASTER: submitting job (9, 0, 2) to dispatcher
13:14:39 DISPATCHER: trying to submit job (9, 0, 2)
13:14:39 DISPATCHER: trying to notify the job_runner thread.
13:14:39 HBMASTER: job (9, 0, 2) submitted to dispatcher
13:14:39 DISPATCHER: Trying to submit another job.
13:14:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:14:39 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:14:39 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:14:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:14:39 WORKER: start processing job (9, 0, 2)
13:14:39 WORKER: args: ()
13:14:39 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 76, 'last_n_outputs': 6, 'lr': 0.0019424646516229948, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.030852015147973283}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-578:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:15:24 DISPATCHER: Starting worker discovery
13:15:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:15:24 DISPATCHER: Finished worker discovery
13:16:24 DISPATCHER: Starting worker discovery
13:16:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:16:24 DISPATCHER: Finished worker discovery
13:17:02 WORKER: done with job (9, 0, 2), trying to register it.
13:17:02 WORKER: registered result for job (9, 0, 2) with dispatcher
13:17:02 DISPATCHER: job (9, 0, 2) finished
13:17:02 DISPATCHER: register_result: lock acquired
13:17:02 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
13:17:02 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 76, 'last_n_outputs': 6, 'lr': 0.0019424646516229948, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.030852015147973283}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9386777491955587, 'info': {'data05': 0.9386777491955587, 'config': "{'batch_size': 128, 'hidden_dim': 76, 'last_n_outputs': 6, 'lr': 0.0019424646516229948, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.030852015147973283}"}}
exception: None

13:17:02 job_callback for (9, 0, 2) started
13:17:02 job_callback for (9, 0, 2) got condition
13:17:02 DISPATCHER: Trying to submit another job.
13:17:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:17:02 HBMASTER: Trying to run another job!
13:17:02 job_callback for (9, 0, 2) finished
13:17:02 start sampling a new configuration.
13:17:02 best_vector: [1, 0.5548790630756509, 0.2535262028026093, 0.11087352656474928, 0.10043104744863, 0, 0.635699213245416, 0.3289027020731477], 4.743291882047412e-05, 744.8653515732128, 0.03533113775335612
13:17:02 done sampling a new configuration.
13:17:02 HBMASTER: schedule new run for iteration 9
13:17:02 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
13:17:02 HBMASTER: submitting job (9, 0, 3) to dispatcher
13:17:02 DISPATCHER: trying to submit job (9, 0, 3)
13:17:02 DISPATCHER: trying to notify the job_runner thread.
13:17:02 HBMASTER: job (9, 0, 3) submitted to dispatcher
13:17:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:17:02 DISPATCHER: Trying to submit another job.
13:17:02 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:17:02 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:17:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:17:02 WORKER: start processing job (9, 0, 3)
13:17:02 WORKER: args: ()
13:17:02 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 64, 'last_n_outputs': 13, 'lr': 0.0016662764376663207, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.026786272401310936}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-579:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:17:24 DISPATCHER: Starting worker discovery
13:17:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:17:24 DISPATCHER: Finished worker discovery
13:18:24 DISPATCHER: Starting worker discovery
13:18:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:18:24 DISPATCHER: Finished worker discovery
13:19:24 DISPATCHER: Starting worker discovery
13:19:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:19:24 DISPATCHER: Finished worker discovery
13:19:26 WORKER: done with job (9, 0, 3), trying to register it.
13:19:26 WORKER: registered result for job (9, 0, 3) with dispatcher
13:19:26 DISPATCHER: job (9, 0, 3) finished
13:19:26 DISPATCHER: register_result: lock acquired
13:19:26 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
13:19:26 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 64, 'last_n_outputs': 13, 'lr': 0.0016662764376663207, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.026786272401310936}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8656073204156254, 'info': {'data05': 0.8656073204156254, 'config': "{'batch_size': 32, 'hidden_dim': 64, 'last_n_outputs': 13, 'lr': 0.0016662764376663207, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.026786272401310936}"}}
exception: None

13:19:26 job_callback for (9, 0, 3) started
13:19:26 DISPATCHER: Trying to submit another job.
13:19:26 job_callback for (9, 0, 3) got condition
13:19:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:19:26 HBMASTER: Trying to run another job!
13:19:26 job_callback for (9, 0, 3) finished
13:19:26 start sampling a new configuration.
13:19:26 done sampling a new configuration.
13:19:26 HBMASTER: schedule new run for iteration 9
13:19:26 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
13:19:26 HBMASTER: submitting job (9, 0, 4) to dispatcher
13:19:26 DISPATCHER: trying to submit job (9, 0, 4)
13:19:26 DISPATCHER: trying to notify the job_runner thread.
13:19:26 HBMASTER: job (9, 0, 4) submitted to dispatcher
13:19:26 DISPATCHER: Trying to submit another job.
13:19:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:19:26 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:19:26 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:19:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:19:26 WORKER: start processing job (9, 0, 4)
13:19:26 WORKER: args: ()
13:19:26 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 74, 'last_n_outputs': 19, 'lr': 0.0017914011873395017, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.12459991681255979}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-580:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:20:24 DISPATCHER: Starting worker discovery
13:20:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:20:24 DISPATCHER: Finished worker discovery
13:21:24 DISPATCHER: Starting worker discovery
13:21:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:21:24 DISPATCHER: Finished worker discovery
13:21:49 WORKER: done with job (9, 0, 4), trying to register it.
13:21:49 WORKER: registered result for job (9, 0, 4) with dispatcher
13:21:49 DISPATCHER: job (9, 0, 4) finished
13:21:49 DISPATCHER: register_result: lock acquired
13:21:49 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
13:21:49 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 74, 'last_n_outputs': 19, 'lr': 0.0017914011873395017, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.12459991681255979}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -1.2045250445933468e-05, 'info': {'data05': 1.2045250445933468e-05, 'config': "{'batch_size': 32, 'hidden_dim': 74, 'last_n_outputs': 19, 'lr': 0.0017914011873395017, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.12459991681255979}"}}
exception: None

13:21:49 job_callback for (9, 0, 4) started
13:21:49 DISPATCHER: Trying to submit another job.
13:21:49 job_callback for (9, 0, 4) got condition
13:21:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:21:49 HBMASTER: Trying to run another job!
13:21:49 job_callback for (9, 0, 4) finished
13:21:49 start sampling a new configuration.
13:21:50 best_vector: [1, 0.8970250793907286, 0.6235782687537409, 0.19420812161324613, 0.10005464541982793, 0, 0.7509810302829609, 0.13529213586849292], 2.9870090769900548e-05, 1327.0252334267561, 0.03963836417640567
13:21:50 done sampling a new configuration.
13:21:50 HBMASTER: schedule new run for iteration 9
13:21:50 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
13:21:50 HBMASTER: submitting job (9, 0, 5) to dispatcher
13:21:50 DISPATCHER: trying to submit job (9, 0, 5)
13:21:50 DISPATCHER: trying to notify the job_runner thread.
13:21:50 HBMASTER: job (9, 0, 5) submitted to dispatcher
13:21:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:21:50 DISPATCHER: Trying to submit another job.
13:21:50 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:21:50 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:21:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:21:50 WORKER: start processing job (9, 0, 5)
13:21:50 WORKER: args: ()
13:21:50 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 92, 'last_n_outputs': 32, 'lr': 0.002445773545775787, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.014997508851950503}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-581:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:22:24 DISPATCHER: Starting worker discovery
13:22:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:22:25 DISPATCHER: Finished worker discovery
13:23:25 DISPATCHER: Starting worker discovery
13:23:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:23:25 DISPATCHER: Finished worker discovery
13:24:13 WORKER: done with job (9, 0, 5), trying to register it.
13:24:13 WORKER: registered result for job (9, 0, 5) with dispatcher
13:24:13 DISPATCHER: job (9, 0, 5) finished
13:24:13 DISPATCHER: register_result: lock acquired
13:24:13 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
13:24:13 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 92, 'last_n_outputs': 32, 'lr': 0.002445773545775787, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.014997508851950503}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9369071499451382, 'info': {'data05': 0.9369071499451382, 'config': "{'batch_size': 32, 'hidden_dim': 92, 'last_n_outputs': 32, 'lr': 0.002445773545775787, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.014997508851950503}"}}
exception: None

13:24:13 job_callback for (9, 0, 5) started
13:24:13 job_callback for (9, 0, 5) got condition
13:24:13 DISPATCHER: Trying to submit another job.
13:24:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:24:13 HBMASTER: Trying to run another job!
13:24:13 job_callback for (9, 0, 5) finished
13:24:13 start sampling a new configuration.
13:24:13 best_vector: [1, 0.7453419241678901, 0.11693086903436323, 0.007645877466968265, 0.09984206051360793, 0, 0.7476275389607053, 0.2191022878305809], 1.2351650695600833e-05, 1253.5227911448583, 0.015483075655195886
13:24:13 done sampling a new configuration.
13:24:13 HBMASTER: schedule new run for iteration 9
13:24:13 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
13:24:13 HBMASTER: submitting job (9, 0, 6) to dispatcher
13:24:13 DISPATCHER: trying to submit job (9, 0, 6)
13:24:13 DISPATCHER: trying to notify the job_runner thread.
13:24:13 HBMASTER: job (9, 0, 6) submitted to dispatcher
13:24:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:24:13 DISPATCHER: Trying to submit another job.
13:24:13 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:24:13 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:24:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:24:13 WORKER: start processing job (9, 0, 6)
13:24:13 WORKER: args: ()
13:24:13 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 80, 'last_n_outputs': 6, 'lr': 0.0010358377990503948, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.01927785230208892}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:24:25 DISPATCHER: Starting worker discovery
13:24:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:24:25 DISPATCHER: Finished worker discovery
Exception in thread Thread-582:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:25:25 DISPATCHER: Starting worker discovery
13:25:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:25:25 DISPATCHER: Finished worker discovery
13:26:25 DISPATCHER: Starting worker discovery
13:26:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:26:25 DISPATCHER: Finished worker discovery
13:26:36 WORKER: done with job (9, 0, 6), trying to register it.
13:26:36 WORKER: registered result for job (9, 0, 6) with dispatcher
13:26:36 DISPATCHER: job (9, 0, 6) finished
13:26:36 DISPATCHER: register_result: lock acquired
13:26:36 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
13:26:36 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 80, 'last_n_outputs': 6, 'lr': 0.0010358377990503948, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.01927785230208892}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7493835512962492, 'info': {'data05': 0.7493835512962492, 'config': "{'batch_size': 32, 'hidden_dim': 80, 'last_n_outputs': 6, 'lr': 0.0010358377990503948, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.01927785230208892}"}}
exception: None

13:26:36 job_callback for (9, 0, 6) started
13:26:36 job_callback for (9, 0, 6) got condition
13:26:36 DISPATCHER: Trying to submit another job.
13:26:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:26:36 HBMASTER: Trying to run another job!
13:26:36 job_callback for (9, 0, 6) finished
13:26:36 start sampling a new configuration.
13:26:37 best_vector: [0, 0.43764832794401476, 0.24263163954654776, 0.08348631821335711, 0.09998441721790738, 0, 0.8695147432416386, 0.13865875415015733], 0.0001259405067557603, 517.7245309360301, 0.06520248978597193
13:26:37 done sampling a new configuration.
13:26:37 HBMASTER: schedule new run for iteration 9
13:26:37 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
13:26:37 HBMASTER: submitting job (9, 0, 7) to dispatcher
13:26:37 DISPATCHER: trying to submit job (9, 0, 7)
13:26:37 DISPATCHER: trying to notify the job_runner thread.
13:26:37 HBMASTER: job (9, 0, 7) submitted to dispatcher
13:26:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:26:37 DISPATCHER: Trying to submit another job.
13:26:37 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:26:37 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:26:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:26:37 WORKER: start processing job (9, 0, 7)
13:26:37 WORKER: args: ()
13:26:37 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 55, 'last_n_outputs': 13, 'lr': 0.0014688337279862808, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.015149531354983412}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-583:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:27:25 DISPATCHER: Starting worker discovery
13:27:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:27:25 DISPATCHER: Finished worker discovery
13:28:25 DISPATCHER: Starting worker discovery
13:28:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:28:25 DISPATCHER: Finished worker discovery
13:29:00 WORKER: done with job (9, 0, 7), trying to register it.
13:29:00 WORKER: registered result for job (9, 0, 7) with dispatcher
13:29:00 DISPATCHER: job (9, 0, 7) finished
13:29:00 DISPATCHER: register_result: lock acquired
13:29:00 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
13:29:00 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 55, 'last_n_outputs': 13, 'lr': 0.0014688337279862808, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.015149531354983412}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8440899909915136, 'info': {'data05': 0.8440899909915136, 'config': "{'batch_size': 16, 'hidden_dim': 55, 'last_n_outputs': 13, 'lr': 0.0014688337279862808, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.015149531354983412}"}}
exception: None

13:29:00 job_callback for (9, 0, 7) started
13:29:00 DISPATCHER: Trying to submit another job.
13:29:00 job_callback for (9, 0, 7) got condition
13:29:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:29:00 HBMASTER: Trying to run another job!
13:29:00 job_callback for (9, 0, 7) finished
13:29:00 start sampling a new configuration.
13:29:00 done sampling a new configuration.
13:29:00 HBMASTER: schedule new run for iteration 9
13:29:00 HBMASTER: trying submitting job (9, 0, 8) to dispatcher
13:29:00 HBMASTER: submitting job (9, 0, 8) to dispatcher
13:29:00 DISPATCHER: trying to submit job (9, 0, 8)
13:29:00 DISPATCHER: trying to notify the job_runner thread.
13:29:00 HBMASTER: job (9, 0, 8) submitted to dispatcher
13:29:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:29:00 DISPATCHER: Trying to submit another job.
13:29:00 DISPATCHER: starting job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:29:00 DISPATCHER: job (9, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:29:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:29:00 WORKER: start processing job (9, 0, 8)
13:29:00 WORKER: args: ()
13:29:00 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 73, 'last_n_outputs': 40, 'lr': 0.0808436238508687, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.11865428380155511}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-584:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:29:25 DISPATCHER: Starting worker discovery
13:29:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:29:25 DISPATCHER: Finished worker discovery
13:30:25 DISPATCHER: Starting worker discovery
13:30:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:30:25 DISPATCHER: Finished worker discovery
13:31:24 WORKER: done with job (9, 0, 8), trying to register it.
13:31:24 WORKER: registered result for job (9, 0, 8) with dispatcher
13:31:24 DISPATCHER: job (9, 0, 8) finished
13:31:24 DISPATCHER: register_result: lock acquired
13:31:24 DISPATCHER: job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
13:31:24 job_id: (9, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 73, 'last_n_outputs': 40, 'lr': 0.0808436238508687, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.11865428380155511}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.22646300989444373, 'info': {'data05': 0.22646300989444373, 'config': "{'batch_size': 16, 'hidden_dim': 73, 'last_n_outputs': 40, 'lr': 0.0808436238508687, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.11865428380155511}"}}
exception: None

13:31:24 job_callback for (9, 0, 8) started
13:31:24 job_callback for (9, 0, 8) got condition
13:31:24 DISPATCHER: Trying to submit another job.
13:31:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:31:24 HBMASTER: Trying to run another job!
13:31:24 job_callback for (9, 0, 8) finished
13:31:24 ITERATION: Advancing config (9, 0, 2) to next budget 400.000000
13:31:24 ITERATION: Advancing config (9, 0, 3) to next budget 400.000000
13:31:24 ITERATION: Advancing config (9, 0, 5) to next budget 400.000000
13:31:24 HBMASTER: schedule new run for iteration 9
13:31:24 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
13:31:24 HBMASTER: submitting job (9, 0, 2) to dispatcher
13:31:24 DISPATCHER: trying to submit job (9, 0, 2)
13:31:24 DISPATCHER: trying to notify the job_runner thread.
13:31:24 HBMASTER: job (9, 0, 2) submitted to dispatcher
13:31:24 DISPATCHER: Trying to submit another job.
13:31:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:31:24 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:31:24 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:31:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:31:24 WORKER: start processing job (9, 0, 2)
13:31:24 WORKER: args: ()
13:31:24 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 76, 'last_n_outputs': 6, 'lr': 0.0019424646516229948, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.030852015147973283}, 'budget': 400.0, 'working_directory': '.'}
13:31:25 DISPATCHER: Starting worker discovery
13:31:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:31:25 DISPATCHER: Finished worker discovery
Exception in thread Thread-585:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:32:25 DISPATCHER: Starting worker discovery
13:32:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:32:25 DISPATCHER: Finished worker discovery
13:33:25 DISPATCHER: Starting worker discovery
13:33:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:33:25 DISPATCHER: Finished worker discovery
13:34:25 DISPATCHER: Starting worker discovery
13:34:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:34:25 DISPATCHER: Finished worker discovery
13:35:25 DISPATCHER: Starting worker discovery
13:35:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:35:25 DISPATCHER: Finished worker discovery
13:36:25 DISPATCHER: Starting worker discovery
13:36:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:36:25 DISPATCHER: Finished worker discovery
13:37:25 DISPATCHER: Starting worker discovery
13:37:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:37:25 DISPATCHER: Finished worker discovery
13:38:15 WORKER: done with job (9, 0, 2), trying to register it.
13:38:15 WORKER: registered result for job (9, 0, 2) with dispatcher
13:38:15 DISPATCHER: job (9, 0, 2) finished
13:38:15 DISPATCHER: register_result: lock acquired
13:38:15 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
13:38:15 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 76, 'last_n_outputs': 6, 'lr': 0.0019424646516229948, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.030852015147973283}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9379069046717313, 'info': {'data05': 0.9379069046717313, 'config': "{'batch_size': 128, 'hidden_dim': 76, 'last_n_outputs': 6, 'lr': 0.0019424646516229948, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.030852015147973283}"}}
exception: None

13:38:15 job_callback for (9, 0, 2) started
13:38:15 job_callback for (9, 0, 2) got condition
13:38:15 DISPATCHER: Trying to submit another job.
13:38:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:38:15 done building a new model for budget 400.000000 based on 9/23 split
Best loss for this budget:-0.964995





13:38:15 HBMASTER: Trying to run another job!
13:38:15 job_callback for (9, 0, 2) finished
13:38:15 HBMASTER: schedule new run for iteration 9
13:38:15 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
13:38:15 HBMASTER: submitting job (9, 0, 3) to dispatcher
13:38:15 DISPATCHER: trying to submit job (9, 0, 3)
13:38:15 DISPATCHER: trying to notify the job_runner thread.
13:38:15 HBMASTER: job (9, 0, 3) submitted to dispatcher
13:38:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:38:15 DISPATCHER: Trying to submit another job.
13:38:15 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:38:15 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:38:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:38:15 WORKER: start processing job (9, 0, 3)
13:38:15 WORKER: args: ()
13:38:15 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 64, 'last_n_outputs': 13, 'lr': 0.0016662764376663207, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.026786272401310936}, 'budget': 400.0, 'working_directory': '.'}
13:38:25 DISPATCHER: Starting worker discovery
13:38:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:38:25 DISPATCHER: Finished worker discovery
Exception in thread Thread-586:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:39:25 DISPATCHER: Starting worker discovery
13:39:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:39:25 DISPATCHER: Finished worker discovery
13:40:25 DISPATCHER: Starting worker discovery
13:40:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:40:25 DISPATCHER: Finished worker discovery
13:41:25 DISPATCHER: Starting worker discovery
13:41:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:41:25 DISPATCHER: Finished worker discovery
13:42:25 DISPATCHER: Starting worker discovery
13:42:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:42:25 DISPATCHER: Finished worker discovery
13:43:25 DISPATCHER: Starting worker discovery
13:43:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:43:25 DISPATCHER: Finished worker discovery
13:44:25 DISPATCHER: Starting worker discovery
13:44:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:44:25 DISPATCHER: Finished worker discovery
13:45:06 WORKER: done with job (9, 0, 3), trying to register it.
13:45:06 WORKER: registered result for job (9, 0, 3) with dispatcher
13:45:06 DISPATCHER: job (9, 0, 3) finished
13:45:06 DISPATCHER: register_result: lock acquired
13:45:06 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
13:45:06 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 64, 'last_n_outputs': 13, 'lr': 0.0016662764376663207, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.026786272401310936}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6635749564628332, 'info': {'data05': 0.6635749564628332, 'config': "{'batch_size': 32, 'hidden_dim': 64, 'last_n_outputs': 13, 'lr': 0.0016662764376663207, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.026786272401310936}"}}
exception: None

13:45:06 job_callback for (9, 0, 3) started
13:45:06 DISPATCHER: Trying to submit another job.
13:45:06 job_callback for (9, 0, 3) got condition
13:45:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:45:06 done building a new model for budget 400.000000 based on 9/24 split
Best loss for this budget:-0.964995





13:45:06 HBMASTER: Trying to run another job!
13:45:06 job_callback for (9, 0, 3) finished
13:45:06 HBMASTER: schedule new run for iteration 9
13:45:06 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
13:45:06 HBMASTER: submitting job (9, 0, 5) to dispatcher
13:45:06 DISPATCHER: trying to submit job (9, 0, 5)
13:45:06 DISPATCHER: trying to notify the job_runner thread.
13:45:06 HBMASTER: job (9, 0, 5) submitted to dispatcher
13:45:06 DISPATCHER: Trying to submit another job.
13:45:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:45:06 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:45:06 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:45:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:45:06 WORKER: start processing job (9, 0, 5)
13:45:06 WORKER: args: ()
13:45:06 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 92, 'last_n_outputs': 32, 'lr': 0.002445773545775787, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.014997508851950503}, 'budget': 400.0, 'working_directory': '.'}
13:45:25 DISPATCHER: Starting worker discovery
13:45:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:45:25 DISPATCHER: Finished worker discovery
Exception in thread Thread-587:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:46:25 DISPATCHER: Starting worker discovery
13:46:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:46:25 DISPATCHER: Finished worker discovery
13:47:25 DISPATCHER: Starting worker discovery
13:47:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:47:25 DISPATCHER: Finished worker discovery
13:48:25 DISPATCHER: Starting worker discovery
13:48:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:48:25 DISPATCHER: Finished worker discovery
13:49:25 DISPATCHER: Starting worker discovery
13:49:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:49:25 DISPATCHER: Finished worker discovery
13:50:25 DISPATCHER: Starting worker discovery
13:50:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:50:25 DISPATCHER: Finished worker discovery
13:51:25 DISPATCHER: Starting worker discovery
13:51:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:51:25 DISPATCHER: Finished worker discovery
13:51:58 WORKER: done with job (9, 0, 5), trying to register it.
13:51:58 WORKER: registered result for job (9, 0, 5) with dispatcher
13:51:58 DISPATCHER: job (9, 0, 5) finished
13:51:58 DISPATCHER: register_result: lock acquired
13:51:58 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
13:51:58 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 92, 'last_n_outputs': 32, 'lr': 0.002445773545775787, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.014997508851950503}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9219896845520438, 'info': {'data05': 0.9219896845520438, 'config': "{'batch_size': 32, 'hidden_dim': 92, 'last_n_outputs': 32, 'lr': 0.002445773545775787, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.014997508851950503}"}}
exception: None

13:51:58 job_callback for (9, 0, 5) started
13:51:58 DISPATCHER: Trying to submit another job.
13:51:58 job_callback for (9, 0, 5) got condition
13:51:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:51:58 done building a new model for budget 400.000000 based on 9/25 split
Best loss for this budget:-0.964995





13:51:58 HBMASTER: Trying to run another job!
13:51:58 job_callback for (9, 0, 5) finished
13:51:58 ITERATION: Advancing config (9, 0, 2) to next budget 1200.000000
13:51:58 HBMASTER: schedule new run for iteration 9
13:51:58 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
13:51:58 HBMASTER: submitting job (9, 0, 2) to dispatcher
13:51:58 DISPATCHER: trying to submit job (9, 0, 2)
13:51:58 DISPATCHER: trying to notify the job_runner thread.
13:51:58 HBMASTER: job (9, 0, 2) submitted to dispatcher
13:51:58 DISPATCHER: Trying to submit another job.
13:51:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:51:58 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:51:58 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
13:51:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:51:58 WORKER: start processing job (9, 0, 2)
13:51:58 WORKER: args: ()
13:51:58 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 76, 'last_n_outputs': 6, 'lr': 0.0019424646516229948, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.030852015147973283}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-588:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:52:25 DISPATCHER: Starting worker discovery
13:52:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:52:25 DISPATCHER: Finished worker discovery
13:53:25 DISPATCHER: Starting worker discovery
13:53:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:53:25 DISPATCHER: Finished worker discovery
13:54:25 DISPATCHER: Starting worker discovery
13:54:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:54:25 DISPATCHER: Finished worker discovery
13:55:25 DISPATCHER: Starting worker discovery
13:55:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:55:25 DISPATCHER: Finished worker discovery
13:56:25 DISPATCHER: Starting worker discovery
13:56:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:56:25 DISPATCHER: Finished worker discovery
13:57:25 DISPATCHER: Starting worker discovery
13:57:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:57:25 DISPATCHER: Finished worker discovery
13:58:25 DISPATCHER: Starting worker discovery
13:58:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:58:25 DISPATCHER: Finished worker discovery
13:59:25 DISPATCHER: Starting worker discovery
13:59:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:59:25 DISPATCHER: Finished worker discovery
14:00:25 DISPATCHER: Starting worker discovery
14:00:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:00:25 DISPATCHER: Finished worker discovery
14:01:25 DISPATCHER: Starting worker discovery
14:01:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:01:25 DISPATCHER: Finished worker discovery
14:02:25 DISPATCHER: Starting worker discovery
14:02:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:02:25 DISPATCHER: Finished worker discovery
14:03:25 DISPATCHER: Starting worker discovery
14:03:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:03:25 DISPATCHER: Finished worker discovery
14:04:25 DISPATCHER: Starting worker discovery
14:04:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:04:25 DISPATCHER: Finished worker discovery
14:05:25 DISPATCHER: Starting worker discovery
14:05:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:05:25 DISPATCHER: Finished worker discovery
14:06:25 DISPATCHER: Starting worker discovery
14:06:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:06:25 DISPATCHER: Finished worker discovery
14:07:25 DISPATCHER: Starting worker discovery
14:07:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:07:25 DISPATCHER: Finished worker discovery
14:08:25 DISPATCHER: Starting worker discovery
14:08:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:08:25 DISPATCHER: Finished worker discovery
14:09:25 DISPATCHER: Starting worker discovery
14:09:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:09:25 DISPATCHER: Finished worker discovery
14:10:25 DISPATCHER: Starting worker discovery
14:10:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:10:25 DISPATCHER: Finished worker discovery
14:11:25 DISPATCHER: Starting worker discovery
14:11:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:11:25 DISPATCHER: Finished worker discovery
14:12:10 WORKER: done with job (9, 0, 2), trying to register it.
14:12:10 WORKER: registered result for job (9, 0, 2) with dispatcher
14:12:10 DISPATCHER: job (9, 0, 2) finished
14:12:10 DISPATCHER: register_result: lock acquired
14:12:10 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
14:12:10 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 76, 'last_n_outputs': 6, 'lr': 0.0019424646516229948, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.030852015147973283}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.923732179345018, 'info': {'data05': 0.923732179345018, 'config': "{'batch_size': 128, 'hidden_dim': 76, 'last_n_outputs': 6, 'lr': 0.0019424646516229948, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.030852015147973283}"}}
exception: None

14:12:10 job_callback for (9, 0, 2) started
14:12:10 job_callback for (9, 0, 2) got condition
14:12:10 DISPATCHER: Trying to submit another job.
14:12:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:12:10 done building a new model for budget 1200.000000 based on 9/15 split
Best loss for this budget:-0.966695





14:12:10 HBMASTER: Trying to run another job!
14:12:10 job_callback for (9, 0, 2) finished
14:12:10 HBMASTER: shutdown initiated, shutdown_workers = True
14:12:10 WORKER: shutting down now!
14:12:10 DISPATCHER: Dispatcher shutting down
14:12:10 DISPATCHER: discover_workers shutting down
14:12:10 DISPATCHER: Trying to submit another job.
14:12:10 DISPATCHER: 'discover_worker' thread exited
14:12:10 DISPATCHER: job_runner shutting down
14:12:10 DISPATCHER: 'job_runner' thread exited
14:12:10 DISPATCHER: shut down complete
14:12:10 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7f9ca44d09b0; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:36819>
14:12:10 WORKER: No dispatcher found. Waiting for one to initiate contact.
14:12:10 WORKER: start listening for jobs
14:12:10 wait_for_workers trying to get the condition
14:12:10 DISPATCHER: started the 'discover_worker' thread
14:12:10 DISPATCHER: started the 'job_runner' thread
14:12:10 DISPATCHER: Pyro daemon running on localhost:34855
14:12:10 DISPATCHER: Starting worker discovery
14:12:10 DISPATCHER: Found 1 potential workers, 0 currently in the pool.
14:12:10 DISPATCHER: discovered new worker, hpbandster.run_0.worker.metagpuj.13101140314513094464
14:12:10 HBMASTER: number of workers changed to 1
14:12:10 Enough workers to start this run!
14:12:10 adjust_queue_size: lock accquired
14:12:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:12:10 HBMASTER: starting run at 1583932330.5369506
14:12:10 HBMASTER: adjusted queue size to (0, 1)
14:12:10 DISPATCHER: Finished worker discovery
14:12:10 start sampling a new configuration.
14:12:10 DISPATCHER: Trying to submit another job.
14:12:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:12:10 done sampling a new configuration.
14:12:10 HBMASTER: schedule new run for iteration 0
14:12:10 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
14:12:10 HBMASTER: submitting job (0, 0, 0) to dispatcher
14:12:10 DISPATCHER: trying to submit job (0, 0, 0)
14:12:10 DISPATCHER: trying to notify the job_runner thread.
14:12:10 HBMASTER: job (0, 0, 0) submitted to dispatcher
14:12:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:12:10 DISPATCHER: Trying to submit another job.
14:12:10 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:12:10 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:12:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:12:10 WORKER: start processing job (0, 0, 0)
14:12:10 WORKER: args: ()
14:12:10 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.05420618099678462, 'num_filters_1': 102, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.011843535874024034, 'kernel_size_2': 5, 'num_filters_2': 91}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-602:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 4607182418800017408 is out of bounds for axis 0 with size 10

14:13:04 WORKER: done with job (0, 0, 0), trying to register it.
14:13:04 WORKER: registered result for job (0, 0, 0) with dispatcher
14:13:04 DISPATCHER: job (0, 0, 0) finished
14:13:04 DISPATCHER: register_result: lock acquired
14:13:04 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
14:13:04 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.05420618099678462, 'num_filters_1': 102, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.011843535874024034, 'kernel_size_2': 5, 'num_filters_2': 91}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7940452020848209, 'info': {'data05': 0.7940452020848209, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.05420618099678462, 'num_filters_1': 102, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.011843535874024034, 'kernel_size_2': 5, 'num_filters_2': 91}"}}
exception: None

14:13:04 job_callback for (0, 0, 0) started
14:13:04 job_callback for (0, 0, 0) got condition
14:13:04 DISPATCHER: Trying to submit another job.
14:13:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:13:04 Only 1 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
14:13:04 HBMASTER: Trying to run another job!
14:13:04 job_callback for (0, 0, 0) finished
14:13:04 start sampling a new configuration.
14:13:04 done sampling a new configuration.
14:13:04 HBMASTER: schedule new run for iteration 0
14:13:04 HBMASTER: trying submitting job (0, 0, 1) to dispatcher
14:13:04 HBMASTER: submitting job (0, 0, 1) to dispatcher
14:13:04 DISPATCHER: trying to submit job (0, 0, 1)
14:13:04 DISPATCHER: trying to notify the job_runner thread.
14:13:04 HBMASTER: job (0, 0, 1) submitted to dispatcher
14:13:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:13:04 DISPATCHER: Trying to submit another job.
14:13:04 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:13:04 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:13:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:13:04 WORKER: start processing job (0, 0, 1)
14:13:04 WORKER: args: ()
14:13:04 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.002044040220071127, 'num_filters_1': 47, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 72, 'weight_decay': 0.022379567335050355, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 52, 'num_filters_3': 16, 'num_filters_4': 91, 'num_filters_5': 120}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:13:10 DISPATCHER: Starting worker discovery
14:13:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:13:10 DISPATCHER: Finished worker discovery
14:14:02 WORKER: done with job (0, 0, 1), trying to register it.
14:14:02 WORKER: registered result for job (0, 0, 1) with dispatcher
14:14:02 DISPATCHER: job (0, 0, 1) finished
14:14:02 DISPATCHER: register_result: lock acquired
14:14:02 DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
14:14:02 job_id: (0, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.002044040220071127, 'num_filters_1': 47, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 72, 'weight_decay': 0.022379567335050355, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 52, 'num_filters_3': 16, 'num_filters_4': 91, 'num_filters_5': 120}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.017379887644711878, 'info': {'data05': 0.017379887644711878, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.002044040220071127, 'num_filters_1': 47, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 72, 'weight_decay': 0.022379567335050355, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 52, 'num_filters_3': 16, 'num_filters_4': 91, 'num_filters_5': 120}"}}
exception: None

14:14:02 job_callback for (0, 0, 1) started
14:14:02 DISPATCHER: Trying to submit another job.
14:14:02 job_callback for (0, 0, 1) got condition
14:14:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:14:02 Only 2 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
14:14:02 HBMASTER: Trying to run another job!
14:14:02 job_callback for (0, 0, 1) finished
14:14:02 start sampling a new configuration.
14:14:02 done sampling a new configuration.
14:14:02 HBMASTER: schedule new run for iteration 0
14:14:02 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
14:14:02 HBMASTER: submitting job (0, 0, 2) to dispatcher
14:14:02 DISPATCHER: trying to submit job (0, 0, 2)
14:14:02 DISPATCHER: trying to notify the job_runner thread.
14:14:02 HBMASTER: job (0, 0, 2) submitted to dispatcher
14:14:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:14:02 DISPATCHER: Trying to submit another job.
14:14:02 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:14:02 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:14:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:14:02 WORKER: start processing job (0, 0, 2)
14:14:02 WORKER: args: ()
14:14:02 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.010669869705686263, 'num_filters_1': 59, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.08886550874585054}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:14:10 DISPATCHER: Starting worker discovery
14:14:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:14:10 DISPATCHER: Finished worker discovery
14:15:00 WORKER: done with job (0, 0, 2), trying to register it.
14:15:00 WORKER: registered result for job (0, 0, 2) with dispatcher
14:15:00 DISPATCHER: job (0, 0, 2) finished
14:15:00 DISPATCHER: register_result: lock acquired
14:15:00 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
14:15:00 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.010669869705686263, 'num_filters_1': 59, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.08886550874585054}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.012735737672982835, 'info': {'data05': 0.012735737672982835, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.010669869705686263, 'num_filters_1': 59, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.08886550874585054}"}}
exception: None

14:15:00 job_callback for (0, 0, 2) started
14:15:00 job_callback for (0, 0, 2) got condition
14:15:00 DISPATCHER: Trying to submit another job.
14:15:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:15:00 Only 3 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
14:15:00 HBMASTER: Trying to run another job!
14:15:00 job_callback for (0, 0, 2) finished
14:15:00 start sampling a new configuration.
14:15:00 done sampling a new configuration.
14:15:00 HBMASTER: schedule new run for iteration 0
14:15:00 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
14:15:00 HBMASTER: submitting job (0, 0, 3) to dispatcher
14:15:00 DISPATCHER: trying to submit job (0, 0, 3)
14:15:00 DISPATCHER: trying to notify the job_runner thread.
14:15:00 HBMASTER: job (0, 0, 3) submitted to dispatcher
14:15:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:15:00 DISPATCHER: Trying to submit another job.
14:15:00 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:15:00 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:15:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:15:00 WORKER: start processing job (0, 0, 3)
14:15:00 WORKER: args: ()
14:15:00 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0029243182673189816, 'num_filters_1': 127, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.030412158895594663, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 51, 'num_filters_3': 100}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:15:10 DISPATCHER: Starting worker discovery
14:15:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:15:10 DISPATCHER: Finished worker discovery
14:16:00 WORKER: done with job (0, 0, 3), trying to register it.
14:16:00 WORKER: registered result for job (0, 0, 3) with dispatcher
14:16:00 DISPATCHER: job (0, 0, 3) finished
14:16:00 DISPATCHER: register_result: lock acquired
14:16:00 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
14:16:00 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0029243182673189816, 'num_filters_1': 127, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.030412158895594663, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 51, 'num_filters_3': 100}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5459669361588799, 'info': {'data05': 0.5459669361588799, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0029243182673189816, 'num_filters_1': 127, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.030412158895594663, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 51, 'num_filters_3': 100}"}}
exception: None

14:16:00 job_callback for (0, 0, 3) started
14:16:00 DISPATCHER: Trying to submit another job.
14:16:00 job_callback for (0, 0, 3) got condition
14:16:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:16:00 Only 4 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
14:16:00 HBMASTER: Trying to run another job!
14:16:00 job_callback for (0, 0, 3) finished
14:16:00 start sampling a new configuration.
14:16:00 done sampling a new configuration.
14:16:00 HBMASTER: schedule new run for iteration 0
14:16:00 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
14:16:00 HBMASTER: submitting job (0, 0, 4) to dispatcher
14:16:00 DISPATCHER: trying to submit job (0, 0, 4)
14:16:00 DISPATCHER: trying to notify the job_runner thread.
14:16:00 HBMASTER: job (0, 0, 4) submitted to dispatcher
14:16:00 DISPATCHER: Trying to submit another job.
14:16:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:16:00 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:16:00 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:16:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:16:00 WORKER: start processing job (0, 0, 4)
14:16:00 WORKER: args: ()
14:16:00 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.002140601643804871, 'num_filters_1': 30, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.03235759003071163}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:16:10 DISPATCHER: Starting worker discovery
14:16:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:16:10 DISPATCHER: Finished worker discovery
14:16:59 WORKER: done with job (0, 0, 4), trying to register it.
14:16:59 WORKER: registered result for job (0, 0, 4) with dispatcher
14:16:59 DISPATCHER: job (0, 0, 4) finished
14:16:59 DISPATCHER: register_result: lock acquired
14:16:59 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
14:16:59 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.002140601643804871, 'num_filters_1': 30, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.03235759003071163}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5130057003461715, 'info': {'data05': 0.5130057003461715, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.002140601643804871, 'num_filters_1': 30, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.03235759003071163}"}}
exception: None

14:16:59 job_callback for (0, 0, 4) started
14:16:59 job_callback for (0, 0, 4) got condition
14:16:59 DISPATCHER: Trying to submit another job.
14:16:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:16:59 Only 5 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
14:16:59 HBMASTER: Trying to run another job!
14:16:59 job_callback for (0, 0, 4) finished
14:16:59 start sampling a new configuration.
14:16:59 done sampling a new configuration.
14:16:59 HBMASTER: schedule new run for iteration 0
14:16:59 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
14:16:59 HBMASTER: submitting job (0, 0, 5) to dispatcher
14:16:59 DISPATCHER: trying to submit job (0, 0, 5)
14:16:59 DISPATCHER: trying to notify the job_runner thread.
14:16:59 HBMASTER: job (0, 0, 5) submitted to dispatcher
14:16:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:16:59 DISPATCHER: Trying to submit another job.
14:16:59 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:16:59 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:16:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:16:59 WORKER: start processing job (0, 0, 5)
14:16:59 WORKER: args: ()
14:16:59 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.010930911747665991, 'num_filters_1': 51, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.01348991263302075, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 88, 'num_filters_3': 47, 'num_filters_4': 30}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:17:10 DISPATCHER: Starting worker discovery
14:17:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:17:10 DISPATCHER: Finished worker discovery
14:17:56 WORKER: done with job (0, 0, 5), trying to register it.
14:17:56 WORKER: registered result for job (0, 0, 5) with dispatcher
14:17:56 DISPATCHER: job (0, 0, 5) finished
14:17:56 DISPATCHER: register_result: lock acquired
14:17:56 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
14:17:56 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.010930911747665991, 'num_filters_1': 51, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.01348991263302075, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 88, 'num_filters_3': 47, 'num_filters_4': 30}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5329332008603093, 'info': {'data05': 0.5329332008603093, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.010930911747665991, 'num_filters_1': 51, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.01348991263302075, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 88, 'num_filters_3': 47, 'num_filters_4': 30}"}}
exception: None

14:17:56 job_callback for (0, 0, 5) started
14:17:56 job_callback for (0, 0, 5) got condition
14:17:56 DISPATCHER: Trying to submit another job.
14:17:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:17:56 Only 6 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
14:17:56 HBMASTER: Trying to run another job!
14:17:56 job_callback for (0, 0, 5) finished
14:17:56 start sampling a new configuration.
14:17:56 done sampling a new configuration.
14:17:56 HBMASTER: schedule new run for iteration 0
14:17:56 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
14:17:56 HBMASTER: submitting job (0, 0, 6) to dispatcher
14:17:56 DISPATCHER: trying to submit job (0, 0, 6)
14:17:56 DISPATCHER: trying to notify the job_runner thread.
14:17:56 HBMASTER: job (0, 0, 6) submitted to dispatcher
14:17:56 DISPATCHER: Trying to submit another job.
14:17:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:17:56 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:17:56 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:17:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:17:56 WORKER: start processing job (0, 0, 6)
14:17:56 WORKER: args: ()
14:17:56 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0019799393890766745, 'num_filters_1': 49, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.02841254204672343}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:18:10 DISPATCHER: Starting worker discovery
14:18:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:18:10 DISPATCHER: Finished worker discovery
14:18:54 WORKER: done with job (0, 0, 6), trying to register it.
14:18:54 WORKER: registered result for job (0, 0, 6) with dispatcher
14:18:54 DISPATCHER: job (0, 0, 6) finished
14:18:54 DISPATCHER: register_result: lock acquired
14:18:54 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
14:18:54 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0019799393890766745, 'num_filters_1': 49, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.02841254204672343}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.37598408448807985, 'info': {'data05': 0.37598408448807985, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0019799393890766745, 'num_filters_1': 49, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.02841254204672343}"}}
exception: None

14:18:54 job_callback for (0, 0, 6) started
14:18:54 DISPATCHER: Trying to submit another job.
14:18:54 job_callback for (0, 0, 6) got condition
14:18:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:18:54 Only 7 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
14:18:54 HBMASTER: Trying to run another job!
14:18:54 job_callback for (0, 0, 6) finished
14:18:54 start sampling a new configuration.
14:18:54 done sampling a new configuration.
14:18:54 HBMASTER: schedule new run for iteration 0
14:18:54 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
14:18:54 HBMASTER: submitting job (0, 0, 7) to dispatcher
14:18:54 DISPATCHER: trying to submit job (0, 0, 7)
14:18:54 DISPATCHER: trying to notify the job_runner thread.
14:18:54 HBMASTER: job (0, 0, 7) submitted to dispatcher
14:18:54 DISPATCHER: Trying to submit another job.
14:18:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:18:54 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:18:54 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:18:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:18:54 WORKER: start processing job (0, 0, 7)
14:18:54 WORKER: args: ()
14:18:54 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.08445842788410723, 'num_filters_1': 23, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.010265367779656063, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 88, 'num_filters_3': 23, 'num_filters_4': 48, 'num_filters_5': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:19:10 DISPATCHER: Starting worker discovery
14:19:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:19:10 DISPATCHER: Finished worker discovery
14:19:52 WORKER: done with job (0, 0, 7), trying to register it.
14:19:52 WORKER: registered result for job (0, 0, 7) with dispatcher
14:19:52 DISPATCHER: job (0, 0, 7) finished
14:19:52 DISPATCHER: register_result: lock acquired
14:19:52 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
14:19:52 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.08445842788410723, 'num_filters_1': 23, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.010265367779656063, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 88, 'num_filters_3': 23, 'num_filters_4': 48, 'num_filters_5': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.08445842788410723, 'num_filters_1': 23, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.010265367779656063, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 88, 'num_filters_3': 23, 'num_filters_4': 48, 'num_filters_5': 18}"}}
exception: None

14:19:52 job_callback for (0, 0, 7) started
14:19:52 job_callback for (0, 0, 7) got condition
14:19:52 DISPATCHER: Trying to submit another job.
14:19:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:19:52 Only 8 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
14:19:52 HBMASTER: Trying to run another job!
14:19:52 job_callback for (0, 0, 7) finished
14:19:52 start sampling a new configuration.
14:19:52 done sampling a new configuration.
14:19:52 HBMASTER: schedule new run for iteration 0
14:19:52 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
14:19:52 HBMASTER: submitting job (0, 0, 8) to dispatcher
14:19:52 DISPATCHER: trying to submit job (0, 0, 8)
14:19:52 DISPATCHER: trying to notify the job_runner thread.
14:19:52 HBMASTER: job (0, 0, 8) submitted to dispatcher
14:19:52 DISPATCHER: Trying to submit another job.
14:19:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:19:52 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:19:52 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:19:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:19:52 WORKER: start processing job (0, 0, 8)
14:19:52 WORKER: args: ()
14:19:52 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.006672255565280443, 'num_filters_1': 62, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.02827698916365454, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 25, 'num_filters_3': 22, 'num_filters_4': 90}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:20:10 DISPATCHER: Starting worker discovery
14:20:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:20:10 DISPATCHER: Finished worker discovery
14:20:50 WORKER: done with job (0, 0, 8), trying to register it.
14:20:50 WORKER: registered result for job (0, 0, 8) with dispatcher
14:20:50 DISPATCHER: job (0, 0, 8) finished
14:20:50 DISPATCHER: register_result: lock acquired
14:20:50 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
14:20:50 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.006672255565280443, 'num_filters_1': 62, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.02827698916365454, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 25, 'num_filters_3': 22, 'num_filters_4': 90}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4041355555621825, 'info': {'data05': 0.4041355555621825, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.006672255565280443, 'num_filters_1': 62, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.02827698916365454, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 25, 'num_filters_3': 22, 'num_filters_4': 90}"}}
exception: None

14:20:50 job_callback for (0, 0, 8) started
14:20:50 job_callback for (0, 0, 8) got condition
14:20:50 DISPATCHER: Trying to submit another job.
14:20:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:20:50 Only 9 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
14:20:50 HBMASTER: Trying to run another job!
14:20:50 job_callback for (0, 0, 8) finished
14:20:50 start sampling a new configuration.
14:20:50 done sampling a new configuration.
14:20:50 HBMASTER: schedule new run for iteration 0
14:20:50 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
14:20:50 HBMASTER: submitting job (0, 0, 9) to dispatcher
14:20:50 DISPATCHER: trying to submit job (0, 0, 9)
14:20:50 DISPATCHER: trying to notify the job_runner thread.
14:20:50 HBMASTER: job (0, 0, 9) submitted to dispatcher
14:20:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:20:50 DISPATCHER: Trying to submit another job.
14:20:50 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:20:50 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:20:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:20:50 WORKER: start processing job (0, 0, 9)
14:20:50 WORKER: args: ()
14:20:50 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.07074804172241408, 'num_filters_1': 20, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.03828782325868142, 'kernel_size_2': 3, 'num_filters_2': 108}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:21:10 DISPATCHER: Starting worker discovery
14:21:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:21:10 DISPATCHER: Finished worker discovery
14:21:52 WORKER: done with job (0, 0, 9), trying to register it.
14:21:52 WORKER: registered result for job (0, 0, 9) with dispatcher
14:21:52 DISPATCHER: job (0, 0, 9) finished
14:21:52 DISPATCHER: register_result: lock acquired
14:21:52 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
14:21:52 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.07074804172241408, 'num_filters_1': 20, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.03828782325868142, 'kernel_size_2': 3, 'num_filters_2': 108}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1344157330960283, 'info': {'data05': 0.1344157330960283, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.07074804172241408, 'num_filters_1': 20, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.03828782325868142, 'kernel_size_2': 3, 'num_filters_2': 108}"}}
exception: None

14:21:52 job_callback for (0, 0, 9) started
14:21:52 job_callback for (0, 0, 9) got condition
14:21:52 DISPATCHER: Trying to submit another job.
14:21:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:21:52 Only 10 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
14:21:52 HBMASTER: Trying to run another job!
14:21:52 job_callback for (0, 0, 9) finished
14:21:52 start sampling a new configuration.
14:21:52 done sampling a new configuration.
14:21:52 HBMASTER: schedule new run for iteration 0
14:21:52 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
14:21:52 HBMASTER: submitting job (0, 0, 10) to dispatcher
14:21:52 DISPATCHER: trying to submit job (0, 0, 10)
14:21:52 DISPATCHER: trying to notify the job_runner thread.
14:21:52 HBMASTER: job (0, 0, 10) submitted to dispatcher
14:21:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:21:52 DISPATCHER: Trying to submit another job.
14:21:52 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:21:52 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:21:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:21:52 WORKER: start processing job (0, 0, 10)
14:21:52 WORKER: args: ()
14:21:52 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.007373324503619039, 'num_filters_1': 109, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.033594556114968484, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 35, 'num_filters_3': 20, 'num_filters_4': 94}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:22:10 DISPATCHER: Starting worker discovery
14:22:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:22:10 DISPATCHER: Finished worker discovery
14:22:48 WORKER: done with job (0, 0, 10), trying to register it.
14:22:48 WORKER: registered result for job (0, 0, 10) with dispatcher
14:22:48 DISPATCHER: job (0, 0, 10) finished
14:22:48 DISPATCHER: register_result: lock acquired
14:22:48 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
14:22:48 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.007373324503619039, 'num_filters_1': 109, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.033594556114968484, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 35, 'num_filters_3': 20, 'num_filters_4': 94}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5480406824666677, 'info': {'data05': 0.5480406824666677, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.007373324503619039, 'num_filters_1': 109, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.033594556114968484, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 35, 'num_filters_3': 20, 'num_filters_4': 94}"}}
exception: None

14:22:48 job_callback for (0, 0, 10) started
14:22:48 DISPATCHER: Trying to submit another job.
14:22:48 job_callback for (0, 0, 10) got condition
14:22:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:22:48 Only 11 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
14:22:48 HBMASTER: Trying to run another job!
14:22:48 job_callback for (0, 0, 10) finished
14:22:48 start sampling a new configuration.
14:22:48 done sampling a new configuration.
14:22:48 HBMASTER: schedule new run for iteration 0
14:22:48 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
14:22:48 HBMASTER: submitting job (0, 0, 11) to dispatcher
14:22:48 DISPATCHER: trying to submit job (0, 0, 11)
14:22:48 DISPATCHER: trying to notify the job_runner thread.
14:22:48 HBMASTER: job (0, 0, 11) submitted to dispatcher
14:22:48 DISPATCHER: Trying to submit another job.
14:22:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:22:48 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:22:48 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:22:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:22:48 WORKER: start processing job (0, 0, 11)
14:22:48 WORKER: args: ()
14:22:48 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.043427750216002925, 'num_filters_1': 104, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.0691360572370212, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 18, 'num_filters_3': 16, 'num_filters_4': 60, 'num_filters_5': 105}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-613:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 4607182418800017408 is out of bounds for axis 0 with size 10

14:23:10 DISPATCHER: Starting worker discovery
14:23:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:23:10 DISPATCHER: Finished worker discovery
14:23:42 WORKER: done with job (0, 0, 11), trying to register it.
14:23:42 WORKER: registered result for job (0, 0, 11) with dispatcher
14:23:42 DISPATCHER: job (0, 0, 11) finished
14:23:42 DISPATCHER: register_result: lock acquired
14:23:42 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
14:23:42 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.043427750216002925, 'num_filters_1': 104, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.0691360572370212, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 18, 'num_filters_3': 16, 'num_filters_4': 60, 'num_filters_5': 105}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.35749274537798975, 'info': {'data05': 0.35749274537798975, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.043427750216002925, 'num_filters_1': 104, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.0691360572370212, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 18, 'num_filters_3': 16, 'num_filters_4': 60, 'num_filters_5': 105}"}}
exception: None

14:23:42 job_callback for (0, 0, 11) started
14:23:42 DISPATCHER: Trying to submit another job.
14:23:42 job_callback for (0, 0, 11) got condition
14:23:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:23:42 Only 12 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
14:23:42 HBMASTER: Trying to run another job!
14:23:42 job_callback for (0, 0, 11) finished
14:23:42 start sampling a new configuration.
14:23:42 done sampling a new configuration.
14:23:42 HBMASTER: schedule new run for iteration 0
14:23:42 HBMASTER: trying submitting job (0, 0, 12) to dispatcher
14:23:42 HBMASTER: submitting job (0, 0, 12) to dispatcher
14:23:42 DISPATCHER: trying to submit job (0, 0, 12)
14:23:42 DISPATCHER: trying to notify the job_runner thread.
14:23:42 HBMASTER: job (0, 0, 12) submitted to dispatcher
14:23:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:23:42 DISPATCHER: Trying to submit another job.
14:23:42 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:23:42 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:23:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:23:42 WORKER: start processing job (0, 0, 12)
14:23:42 WORKER: args: ()
14:23:42 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0011008501345414485, 'num_filters_1': 30, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.15107846922804435, 'kernel_size_2': 7, 'num_filters_2': 21}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:24:10 DISPATCHER: Starting worker discovery
14:24:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:24:10 DISPATCHER: Finished worker discovery
14:24:40 WORKER: done with job (0, 0, 12), trying to register it.
14:24:40 WORKER: registered result for job (0, 0, 12) with dispatcher
14:24:40 DISPATCHER: job (0, 0, 12) finished
14:24:40 DISPATCHER: register_result: lock acquired
14:24:40 DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
14:24:40 job_id: (0, 0, 12)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0011008501345414485, 'num_filters_1': 30, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.15107846922804435, 'kernel_size_2': 7, 'num_filters_2': 21}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.12453726582998575, 'info': {'data05': 0.12453726582998575, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0011008501345414485, 'num_filters_1': 30, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.15107846922804435, 'kernel_size_2': 7, 'num_filters_2': 21}"}}
exception: None

14:24:40 job_callback for (0, 0, 12) started
14:24:40 DISPATCHER: Trying to submit another job.
14:24:40 job_callback for (0, 0, 12) got condition
14:24:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:24:40 Only 13 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
14:24:40 HBMASTER: Trying to run another job!
14:24:40 job_callback for (0, 0, 12) finished
14:24:40 start sampling a new configuration.
14:24:40 done sampling a new configuration.
14:24:40 HBMASTER: schedule new run for iteration 0
14:24:40 HBMASTER: trying submitting job (0, 0, 13) to dispatcher
14:24:40 HBMASTER: submitting job (0, 0, 13) to dispatcher
14:24:40 DISPATCHER: trying to submit job (0, 0, 13)
14:24:40 DISPATCHER: trying to notify the job_runner thread.
14:24:40 HBMASTER: job (0, 0, 13) submitted to dispatcher
14:24:40 DISPATCHER: Trying to submit another job.
14:24:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:24:40 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:24:40 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:24:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:24:40 WORKER: start processing job (0, 0, 13)
14:24:40 WORKER: args: ()
14:24:40 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.005436579175796379, 'num_filters_1': 17, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.010814548987718279}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:25:10 DISPATCHER: Starting worker discovery
14:25:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:25:10 DISPATCHER: Finished worker discovery
14:25:38 WORKER: done with job (0, 0, 13), trying to register it.
14:25:38 WORKER: registered result for job (0, 0, 13) with dispatcher
14:25:38 DISPATCHER: job (0, 0, 13) finished
14:25:38 DISPATCHER: register_result: lock acquired
14:25:38 DISPATCHER: job (0, 0, 13) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
14:25:38 job_id: (0, 0, 13)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.005436579175796379, 'num_filters_1': 17, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.010814548987718279}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.14395286757823894, 'info': {'data05': 0.14395286757823894, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.005436579175796379, 'num_filters_1': 17, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.010814548987718279}"}}
exception: None

14:25:38 job_callback for (0, 0, 13) started
14:25:38 DISPATCHER: Trying to submit another job.
14:25:38 job_callback for (0, 0, 13) got condition
14:25:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:25:38 Only 14 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
14:25:38 HBMASTER: Trying to run another job!
14:25:38 job_callback for (0, 0, 13) finished
14:25:38 start sampling a new configuration.
14:25:38 done sampling a new configuration.
14:25:38 HBMASTER: schedule new run for iteration 0
14:25:38 HBMASTER: trying submitting job (0, 0, 14) to dispatcher
14:25:38 HBMASTER: submitting job (0, 0, 14) to dispatcher
14:25:38 DISPATCHER: trying to submit job (0, 0, 14)
14:25:38 DISPATCHER: trying to notify the job_runner thread.
14:25:38 HBMASTER: job (0, 0, 14) submitted to dispatcher
14:25:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:25:38 DISPATCHER: Trying to submit another job.
14:25:38 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:25:38 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:25:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:25:38 WORKER: start processing job (0, 0, 14)
14:25:38 WORKER: args: ()
14:25:38 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.00308563320295989, 'num_filters_1': 28, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.1089419010721721}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:26:10 DISPATCHER: Starting worker discovery
14:26:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:26:10 DISPATCHER: Finished worker discovery
14:26:42 WORKER: done with job (0, 0, 14), trying to register it.
14:26:42 WORKER: registered result for job (0, 0, 14) with dispatcher
14:26:42 DISPATCHER: job (0, 0, 14) finished
14:26:42 DISPATCHER: register_result: lock acquired
14:26:42 DISPATCHER: job (0, 0, 14) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
14:26:42 job_id: (0, 0, 14)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.00308563320295989, 'num_filters_1': 28, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.1089419010721721}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3725708978485487, 'info': {'data05': 0.3725708978485487, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.00308563320295989, 'num_filters_1': 28, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.1089419010721721}"}}
exception: None

14:26:42 job_callback for (0, 0, 14) started
14:26:42 DISPATCHER: Trying to submit another job.
14:26:42 job_callback for (0, 0, 14) got condition
14:26:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:26:42 Only 15 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
14:26:42 HBMASTER: Trying to run another job!
14:26:42 job_callback for (0, 0, 14) finished
14:26:42 start sampling a new configuration.
14:26:42 done sampling a new configuration.
14:26:42 HBMASTER: schedule new run for iteration 0
14:26:42 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
14:26:42 HBMASTER: submitting job (0, 0, 15) to dispatcher
14:26:42 DISPATCHER: trying to submit job (0, 0, 15)
14:26:42 DISPATCHER: trying to notify the job_runner thread.
14:26:42 HBMASTER: job (0, 0, 15) submitted to dispatcher
14:26:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:26:42 DISPATCHER: Trying to submit another job.
14:26:42 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:26:42 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:26:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:26:42 WORKER: start processing job (0, 0, 15)
14:26:42 WORKER: args: ()
14:26:42 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0021100370062913905, 'num_filters_1': 106, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.09124003970169095, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 71, 'num_filters_3': 21}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:27:10 DISPATCHER: Starting worker discovery
14:27:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:27:10 DISPATCHER: Finished worker discovery
14:27:37 WORKER: done with job (0, 0, 15), trying to register it.
14:27:37 WORKER: registered result for job (0, 0, 15) with dispatcher
14:27:37 DISPATCHER: job (0, 0, 15) finished
14:27:37 DISPATCHER: register_result: lock acquired
14:27:37 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
14:27:37 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0021100370062913905, 'num_filters_1': 106, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.09124003970169095, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 71, 'num_filters_3': 21}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3636802489902913, 'info': {'data05': 0.3636802489902913, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0021100370062913905, 'num_filters_1': 106, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.09124003970169095, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 71, 'num_filters_3': 21}"}}
exception: None

14:27:37 job_callback for (0, 0, 15) started
14:27:37 DISPATCHER: Trying to submit another job.
14:27:37 job_callback for (0, 0, 15) got condition
14:27:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:27:37 Only 16 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
14:27:37 HBMASTER: Trying to run another job!
14:27:37 job_callback for (0, 0, 15) finished
14:27:37 start sampling a new configuration.
14:27:37 done sampling a new configuration.
14:27:37 HBMASTER: schedule new run for iteration 0
14:27:37 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
14:27:37 HBMASTER: submitting job (0, 0, 16) to dispatcher
14:27:37 DISPATCHER: trying to submit job (0, 0, 16)
14:27:37 DISPATCHER: trying to notify the job_runner thread.
14:27:37 HBMASTER: job (0, 0, 16) submitted to dispatcher
14:27:37 DISPATCHER: Trying to submit another job.
14:27:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:27:37 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:27:37 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:27:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:27:37 WORKER: start processing job (0, 0, 16)
14:27:37 WORKER: args: ()
14:27:37 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.008677872370567715, 'num_filters_1': 126, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.17203110211584363, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 25, 'num_filters_3': 88, 'num_filters_4': 44}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:28:10 DISPATCHER: Starting worker discovery
14:28:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:28:10 DISPATCHER: Finished worker discovery
14:28:35 WORKER: done with job (0, 0, 16), trying to register it.
14:28:35 WORKER: registered result for job (0, 0, 16) with dispatcher
14:28:35 DISPATCHER: job (0, 0, 16) finished
14:28:35 DISPATCHER: register_result: lock acquired
14:28:35 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
14:28:35 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.008677872370567715, 'num_filters_1': 126, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.17203110211584363, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 25, 'num_filters_3': 88, 'num_filters_4': 44}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.24556334483645006, 'info': {'data05': 0.24556334483645006, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.008677872370567715, 'num_filters_1': 126, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.17203110211584363, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 25, 'num_filters_3': 88, 'num_filters_4': 44}"}}
exception: None

14:28:35 job_callback for (0, 0, 16) started
14:28:35 job_callback for (0, 0, 16) got condition
14:28:35 DISPATCHER: Trying to submit another job.
14:28:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:28:35 HBMASTER: Trying to run another job!
14:28:35 job_callback for (0, 0, 16) finished
14:28:35 start sampling a new configuration.
14:28:35 done sampling a new configuration.
14:28:35 HBMASTER: schedule new run for iteration 0
14:28:35 HBMASTER: trying submitting job (0, 0, 17) to dispatcher
14:28:35 HBMASTER: submitting job (0, 0, 17) to dispatcher
14:28:35 DISPATCHER: trying to submit job (0, 0, 17)
14:28:35 DISPATCHER: trying to notify the job_runner thread.
14:28:35 HBMASTER: job (0, 0, 17) submitted to dispatcher
14:28:35 DISPATCHER: Trying to submit another job.
14:28:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:28:35 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:28:35 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:28:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:28:35 WORKER: start processing job (0, 0, 17)
14:28:35 WORKER: args: ()
14:28:35 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0758255517011993, 'num_filters_1': 97, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.06393238379579316, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 20, 'num_filters_3': 48, 'num_filters_4': 63}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:29:10 DISPATCHER: Starting worker discovery
14:29:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:29:10 DISPATCHER: Finished worker discovery
14:29:32 WORKER: done with job (0, 0, 17), trying to register it.
14:29:32 WORKER: registered result for job (0, 0, 17) with dispatcher
14:29:32 DISPATCHER: job (0, 0, 17) finished
14:29:32 DISPATCHER: register_result: lock acquired
14:29:32 DISPATCHER: job (0, 0, 17) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
14:29:32 job_id: (0, 0, 17)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0758255517011993, 'num_filters_1': 97, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.06393238379579316, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 20, 'num_filters_3': 48, 'num_filters_4': 63}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0033814849725701092, 'info': {'data05': 0.0033814849725701092, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0758255517011993, 'num_filters_1': 97, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.06393238379579316, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 20, 'num_filters_3': 48, 'num_filters_4': 63}"}}
exception: None

14:29:32 job_callback for (0, 0, 17) started
14:29:32 job_callback for (0, 0, 17) got condition
14:29:32 DISPATCHER: Trying to submit another job.
14:29:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:29:32 HBMASTER: Trying to run another job!
14:29:32 job_callback for (0, 0, 17) finished
14:29:32 start sampling a new configuration.
14:29:32 done sampling a new configuration.
14:29:32 HBMASTER: schedule new run for iteration 0
14:29:32 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
14:29:32 HBMASTER: submitting job (0, 0, 18) to dispatcher
14:29:32 DISPATCHER: trying to submit job (0, 0, 18)
14:29:32 DISPATCHER: trying to notify the job_runner thread.
14:29:32 HBMASTER: job (0, 0, 18) submitted to dispatcher
14:29:32 DISPATCHER: Trying to submit another job.
14:29:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:29:32 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:29:32 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:29:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:29:32 WORKER: start processing job (0, 0, 18)
14:29:32 WORKER: args: ()
14:29:32 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0013679195385740955, 'num_filters_1': 73, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.02241184286916222}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:30:10 DISPATCHER: Starting worker discovery
14:30:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:30:10 DISPATCHER: Finished worker discovery
14:30:29 WORKER: done with job (0, 0, 18), trying to register it.
14:30:29 WORKER: registered result for job (0, 0, 18) with dispatcher
14:30:29 DISPATCHER: job (0, 0, 18) finished
14:30:29 DISPATCHER: register_result: lock acquired
14:30:29 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
14:30:29 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0013679195385740955, 'num_filters_1': 73, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.02241184286916222}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6173162900395717, 'info': {'data05': 0.6173162900395717, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0013679195385740955, 'num_filters_1': 73, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.02241184286916222}"}}
exception: None

14:30:29 job_callback for (0, 0, 18) started
14:30:29 DISPATCHER: Trying to submit another job.
14:30:29 job_callback for (0, 0, 18) got condition
14:30:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:30:29 HBMASTER: Trying to run another job!
14:30:29 job_callback for (0, 0, 18) finished
14:30:29 start sampling a new configuration.
14:30:29 done sampling a new configuration.
14:30:29 HBMASTER: schedule new run for iteration 0
14:30:29 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
14:30:29 HBMASTER: submitting job (0, 0, 19) to dispatcher
14:30:29 DISPATCHER: trying to submit job (0, 0, 19)
14:30:29 DISPATCHER: trying to notify the job_runner thread.
14:30:29 HBMASTER: job (0, 0, 19) submitted to dispatcher
14:30:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:30:29 DISPATCHER: Trying to submit another job.
14:30:29 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:30:29 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:30:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:30:29 WORKER: start processing job (0, 0, 19)
14:30:29 WORKER: args: ()
14:30:29 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.00932466692692504, 'num_filters_1': 85, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.06505332832053114, 'kernel_size_2': 7, 'num_filters_2': 31}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:31:10 DISPATCHER: Starting worker discovery
14:31:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:31:10 DISPATCHER: Finished worker discovery
14:31:27 WORKER: done with job (0, 0, 19), trying to register it.
14:31:27 WORKER: registered result for job (0, 0, 19) with dispatcher
14:31:27 DISPATCHER: job (0, 0, 19) finished
14:31:27 DISPATCHER: register_result: lock acquired
14:31:27 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
14:31:27 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.00932466692692504, 'num_filters_1': 85, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.06505332832053114, 'kernel_size_2': 7, 'num_filters_2': 31}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1785070443057723, 'info': {'data05': 0.1785070443057723, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.00932466692692504, 'num_filters_1': 85, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.06505332832053114, 'kernel_size_2': 7, 'num_filters_2': 31}"}}
exception: None

14:31:27 job_callback for (0, 0, 19) started
14:31:27 job_callback for (0, 0, 19) got condition
14:31:27 DISPATCHER: Trying to submit another job.
14:31:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:31:27 HBMASTER: Trying to run another job!
14:31:27 job_callback for (0, 0, 19) finished
14:31:27 start sampling a new configuration.
14:31:27 done sampling a new configuration.
14:31:27 HBMASTER: schedule new run for iteration 0
14:31:27 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
14:31:27 HBMASTER: submitting job (0, 0, 20) to dispatcher
14:31:27 DISPATCHER: trying to submit job (0, 0, 20)
14:31:27 DISPATCHER: trying to notify the job_runner thread.
14:31:27 HBMASTER: job (0, 0, 20) submitted to dispatcher
14:31:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:31:27 DISPATCHER: Trying to submit another job.
14:31:27 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:31:27 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:31:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:31:27 WORKER: start processing job (0, 0, 20)
14:31:27 WORKER: args: ()
14:31:27 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0023322900293797624, 'num_filters_1': 40, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.07855078656727679, 'kernel_size_2': 7, 'num_filters_2': 51}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:32:10 DISPATCHER: Starting worker discovery
14:32:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:32:10 DISPATCHER: Finished worker discovery
14:32:22 WORKER: done with job (0, 0, 20), trying to register it.
14:32:22 WORKER: registered result for job (0, 0, 20) with dispatcher
14:32:22 DISPATCHER: job (0, 0, 20) finished
14:32:22 DISPATCHER: register_result: lock acquired
14:32:22 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
14:32:22 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0023322900293797624, 'num_filters_1': 40, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.07855078656727679, 'kernel_size_2': 7, 'num_filters_2': 51}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.09473224479908719, 'info': {'data05': 0.09473224479908719, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0023322900293797624, 'num_filters_1': 40, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.07855078656727679, 'kernel_size_2': 7, 'num_filters_2': 51}"}}
exception: None

14:32:22 job_callback for (0, 0, 20) started
14:32:22 job_callback for (0, 0, 20) got condition
14:32:22 DISPATCHER: Trying to submit another job.
14:32:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:32:22 HBMASTER: Trying to run another job!
14:32:22 job_callback for (0, 0, 20) finished
14:32:22 start sampling a new configuration.
14:32:22 done sampling a new configuration.
14:32:22 HBMASTER: schedule new run for iteration 0
14:32:22 HBMASTER: trying submitting job (0, 0, 21) to dispatcher
14:32:22 HBMASTER: submitting job (0, 0, 21) to dispatcher
14:32:22 DISPATCHER: trying to submit job (0, 0, 21)
14:32:22 DISPATCHER: trying to notify the job_runner thread.
14:32:22 HBMASTER: job (0, 0, 21) submitted to dispatcher
14:32:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:32:22 DISPATCHER: Trying to submit another job.
14:32:22 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:32:22 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:32:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:32:22 WORKER: start processing job (0, 0, 21)
14:32:22 WORKER: args: ()
14:32:22 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.025207666071345437, 'num_filters_1': 25, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.012563652962027948, 'kernel_size_2': 7, 'num_filters_2': 40}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:33:10 DISPATCHER: Starting worker discovery
14:33:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:33:10 DISPATCHER: Finished worker discovery
14:33:19 WORKER: done with job (0, 0, 21), trying to register it.
14:33:19 WORKER: registered result for job (0, 0, 21) with dispatcher
14:33:19 DISPATCHER: job (0, 0, 21) finished
14:33:19 DISPATCHER: register_result: lock acquired
14:33:19 DISPATCHER: job (0, 0, 21) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
14:33:19 job_id: (0, 0, 21)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.025207666071345437, 'num_filters_1': 25, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.012563652962027948, 'kernel_size_2': 7, 'num_filters_2': 40}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3538452875827245, 'info': {'data05': 0.3538452875827245, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.025207666071345437, 'num_filters_1': 25, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.012563652962027948, 'kernel_size_2': 7, 'num_filters_2': 40}"}}
exception: None

14:33:19 job_callback for (0, 0, 21) started
14:33:19 job_callback for (0, 0, 21) got condition
14:33:19 DISPATCHER: Trying to submit another job.
14:33:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:33:19 HBMASTER: Trying to run another job!
14:33:19 job_callback for (0, 0, 21) finished
14:33:19 start sampling a new configuration.
14:33:19 done sampling a new configuration.
14:33:19 HBMASTER: schedule new run for iteration 0
14:33:19 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
14:33:19 HBMASTER: submitting job (0, 0, 22) to dispatcher
14:33:19 DISPATCHER: trying to submit job (0, 0, 22)
14:33:19 DISPATCHER: trying to notify the job_runner thread.
14:33:19 HBMASTER: job (0, 0, 22) submitted to dispatcher
14:33:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:33:19 DISPATCHER: Trying to submit another job.
14:33:19 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:33:19 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:33:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:33:19 WORKER: start processing job (0, 0, 22)
14:33:19 WORKER: args: ()
14:33:19 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.006112324305636798, 'num_filters_1': 47, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.06388859351865582, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 56, 'num_filters_3': 114, 'num_filters_4': 50, 'num_filters_5': 36}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:34:10 DISPATCHER: Starting worker discovery
14:34:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:34:10 DISPATCHER: Finished worker discovery
14:34:16 WORKER: done with job (0, 0, 22), trying to register it.
14:34:16 WORKER: registered result for job (0, 0, 22) with dispatcher
14:34:16 DISPATCHER: job (0, 0, 22) finished
14:34:16 DISPATCHER: register_result: lock acquired
14:34:16 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
14:34:16 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.006112324305636798, 'num_filters_1': 47, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.06388859351865582, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 56, 'num_filters_3': 114, 'num_filters_4': 50, 'num_filters_5': 36}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0022689815578128313, 'info': {'data05': 0.0022689815578128313, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.006112324305636798, 'num_filters_1': 47, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.06388859351865582, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 56, 'num_filters_3': 114, 'num_filters_4': 50, 'num_filters_5': 36}"}}
exception: None

14:34:16 job_callback for (0, 0, 22) started
14:34:16 DISPATCHER: Trying to submit another job.
14:34:16 job_callback for (0, 0, 22) got condition
14:34:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:34:16 HBMASTER: Trying to run another job!
14:34:16 job_callback for (0, 0, 22) finished
14:34:16 start sampling a new configuration.
14:34:16 done sampling a new configuration.
14:34:16 HBMASTER: schedule new run for iteration 0
14:34:16 HBMASTER: trying submitting job (0, 0, 23) to dispatcher
14:34:16 HBMASTER: submitting job (0, 0, 23) to dispatcher
14:34:16 DISPATCHER: trying to submit job (0, 0, 23)
14:34:16 DISPATCHER: trying to notify the job_runner thread.
14:34:16 HBMASTER: job (0, 0, 23) submitted to dispatcher
14:34:16 DISPATCHER: Trying to submit another job.
14:34:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:34:16 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:34:16 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:34:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:34:16 WORKER: start processing job (0, 0, 23)
14:34:16 WORKER: args: ()
14:34:16 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.03126798624920879, 'num_filters_1': 25, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.10939931825082745}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:35:10 DISPATCHER: Starting worker discovery
14:35:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:35:10 DISPATCHER: Finished worker discovery
14:35:19 WORKER: done with job (0, 0, 23), trying to register it.
14:35:19 WORKER: registered result for job (0, 0, 23) with dispatcher
14:35:19 DISPATCHER: job (0, 0, 23) finished
14:35:19 DISPATCHER: register_result: lock acquired
14:35:19 DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
14:35:19 job_id: (0, 0, 23)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.03126798624920879, 'num_filters_1': 25, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.10939931825082745}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.03662144970827985, 'info': {'data05': 0.03662144970827985, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.03126798624920879, 'num_filters_1': 25, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.10939931825082745}"}}
exception: None

14:35:19 job_callback for (0, 0, 23) started
14:35:19 job_callback for (0, 0, 23) got condition
14:35:19 DISPATCHER: Trying to submit another job.
14:35:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:35:19 HBMASTER: Trying to run another job!
14:35:19 job_callback for (0, 0, 23) finished
14:35:19 start sampling a new configuration.
14:35:19 done sampling a new configuration.
14:35:19 HBMASTER: schedule new run for iteration 0
14:35:19 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
14:35:19 HBMASTER: submitting job (0, 0, 24) to dispatcher
14:35:19 DISPATCHER: trying to submit job (0, 0, 24)
14:35:19 DISPATCHER: trying to notify the job_runner thread.
14:35:19 HBMASTER: job (0, 0, 24) submitted to dispatcher
14:35:19 DISPATCHER: Trying to submit another job.
14:35:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:35:19 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:35:19 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:35:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:35:19 WORKER: start processing job (0, 0, 24)
14:35:19 WORKER: args: ()
14:35:19 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0010562599617774727, 'num_filters_1': 16, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.03494743622112351, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 17, 'num_filters_3': 91}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:36:10 DISPATCHER: Starting worker discovery
14:36:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:36:10 DISPATCHER: Finished worker discovery
14:36:16 WORKER: done with job (0, 0, 24), trying to register it.
14:36:16 WORKER: registered result for job (0, 0, 24) with dispatcher
14:36:16 DISPATCHER: job (0, 0, 24) finished
14:36:16 DISPATCHER: register_result: lock acquired
14:36:16 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
14:36:16 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0010562599617774727, 'num_filters_1': 16, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.03494743622112351, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 17, 'num_filters_3': 91}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.37113515961491383, 'info': {'data05': 0.37113515961491383, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0010562599617774727, 'num_filters_1': 16, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.03494743622112351, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 17, 'num_filters_3': 91}"}}
exception: None

14:36:16 job_callback for (0, 0, 24) started
14:36:16 job_callback for (0, 0, 24) got condition
14:36:16 DISPATCHER: Trying to submit another job.
14:36:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:36:16 HBMASTER: Trying to run another job!
14:36:16 job_callback for (0, 0, 24) finished
14:36:16 start sampling a new configuration.
14:36:16 done sampling a new configuration.
14:36:16 HBMASTER: schedule new run for iteration 0
14:36:16 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
14:36:16 HBMASTER: submitting job (0, 0, 25) to dispatcher
14:36:16 DISPATCHER: trying to submit job (0, 0, 25)
14:36:16 DISPATCHER: trying to notify the job_runner thread.
14:36:16 HBMASTER: job (0, 0, 25) submitted to dispatcher
14:36:16 DISPATCHER: Trying to submit another job.
14:36:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:36:16 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:36:16 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:36:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:36:16 WORKER: start processing job (0, 0, 25)
14:36:16 WORKER: args: ()
14:36:16 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.005599926666742528, 'num_filters_1': 118, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.1542474364893694}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:37:10 DISPATCHER: Starting worker discovery
14:37:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:37:10 DISPATCHER: Finished worker discovery
14:37:12 WORKER: done with job (0, 0, 25), trying to register it.
14:37:12 WORKER: registered result for job (0, 0, 25) with dispatcher
14:37:12 DISPATCHER: job (0, 0, 25) finished
14:37:12 DISPATCHER: register_result: lock acquired
14:37:12 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
14:37:12 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.005599926666742528, 'num_filters_1': 118, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.1542474364893694}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.31683702828795746, 'info': {'data05': 0.31683702828795746, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.005599926666742528, 'num_filters_1': 118, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.1542474364893694}"}}
exception: None

14:37:12 job_callback for (0, 0, 25) started
14:37:12 job_callback for (0, 0, 25) got condition
14:37:12 DISPATCHER: Trying to submit another job.
14:37:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:37:12 HBMASTER: Trying to run another job!
14:37:12 job_callback for (0, 0, 25) finished
14:37:12 start sampling a new configuration.
14:37:12 done sampling a new configuration.
14:37:12 HBMASTER: schedule new run for iteration 0
14:37:12 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
14:37:12 HBMASTER: submitting job (0, 0, 26) to dispatcher
14:37:12 DISPATCHER: trying to submit job (0, 0, 26)
14:37:12 DISPATCHER: trying to notify the job_runner thread.
14:37:12 HBMASTER: job (0, 0, 26) submitted to dispatcher
14:37:12 DISPATCHER: Trying to submit another job.
14:37:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:37:12 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:37:12 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:37:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:37:12 WORKER: start processing job (0, 0, 26)
14:37:12 WORKER: args: ()
14:37:12 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0129196205562883, 'num_filters_1': 24, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.16217639802623698}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:38:10 WORKER: done with job (0, 0, 26), trying to register it.
14:38:10 WORKER: registered result for job (0, 0, 26) with dispatcher
14:38:10 DISPATCHER: job (0, 0, 26) finished
14:38:10 DISPATCHER: register_result: lock acquired
14:38:10 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
14:38:10 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0129196205562883, 'num_filters_1': 24, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.16217639802623698}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.13794194798081966, 'info': {'data05': 0.13794194798081966, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0129196205562883, 'num_filters_1': 24, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.16217639802623698}"}}
exception: None

14:38:10 job_callback for (0, 0, 26) started
14:38:10 job_callback for (0, 0, 26) got condition
14:38:10 DISPATCHER: Trying to submit another job.
14:38:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:38:10 HBMASTER: Trying to run another job!
14:38:10 job_callback for (0, 0, 26) finished
14:38:10 ITERATION: Advancing config (0, 0, 0) to next budget 133.333333
14:38:10 ITERATION: Advancing config (0, 0, 3) to next budget 133.333333
14:38:10 ITERATION: Advancing config (0, 0, 4) to next budget 133.333333
14:38:10 ITERATION: Advancing config (0, 0, 5) to next budget 133.333333
14:38:10 ITERATION: Advancing config (0, 0, 6) to next budget 133.333333
14:38:10 ITERATION: Advancing config (0, 0, 8) to next budget 133.333333
14:38:10 ITERATION: Advancing config (0, 0, 10) to next budget 133.333333
14:38:10 ITERATION: Advancing config (0, 0, 14) to next budget 133.333333
14:38:10 ITERATION: Advancing config (0, 0, 18) to next budget 133.333333
14:38:10 HBMASTER: schedule new run for iteration 0
14:38:10 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
14:38:10 HBMASTER: submitting job (0, 0, 0) to dispatcher
14:38:10 DISPATCHER: trying to submit job (0, 0, 0)
14:38:10 DISPATCHER: trying to notify the job_runner thread.
14:38:10 HBMASTER: job (0, 0, 0) submitted to dispatcher
14:38:10 DISPATCHER: Trying to submit another job.
14:38:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:38:10 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:38:10 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:38:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:38:10 WORKER: start processing job (0, 0, 0)
14:38:10 WORKER: args: ()
14:38:10 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.05420618099678462, 'num_filters_1': 102, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.011843535874024034, 'kernel_size_2': 5, 'num_filters_2': 91}, 'budget': 133.33333333333331, 'working_directory': '.'}
14:38:10 DISPATCHER: Starting worker discovery
14:38:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:38:10 DISPATCHER: Finished worker discovery
14:39:10 DISPATCHER: Starting worker discovery
14:39:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:39:10 DISPATCHER: Finished worker discovery
14:40:10 DISPATCHER: Starting worker discovery
14:40:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:40:10 DISPATCHER: Finished worker discovery
14:40:36 WORKER: done with job (0, 0, 0), trying to register it.
14:40:36 WORKER: registered result for job (0, 0, 0) with dispatcher
14:40:36 DISPATCHER: job (0, 0, 0) finished
14:40:36 DISPATCHER: register_result: lock acquired
14:40:36 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
14:40:36 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.05420618099678462, 'num_filters_1': 102, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.011843535874024034, 'kernel_size_2': 5, 'num_filters_2': 91}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.019325307928917013, 'info': {'data05': 0.019325307928917013, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.05420618099678462, 'num_filters_1': 102, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.011843535874024034, 'kernel_size_2': 5, 'num_filters_2': 91}"}}
exception: None

14:40:36 job_callback for (0, 0, 0) started
14:40:36 job_callback for (0, 0, 0) got condition
14:40:36 DISPATCHER: Trying to submit another job.
14:40:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:40:36 Only 1 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
14:40:36 HBMASTER: Trying to run another job!
14:40:36 job_callback for (0, 0, 0) finished
14:40:36 HBMASTER: schedule new run for iteration 0
14:40:36 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
14:40:36 HBMASTER: submitting job (0, 0, 3) to dispatcher
14:40:36 DISPATCHER: trying to submit job (0, 0, 3)
14:40:36 DISPATCHER: trying to notify the job_runner thread.
14:40:36 HBMASTER: job (0, 0, 3) submitted to dispatcher
14:40:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:40:36 DISPATCHER: Trying to submit another job.
14:40:36 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:40:36 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:40:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:40:36 WORKER: start processing job (0, 0, 3)
14:40:36 WORKER: args: ()
14:40:36 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0029243182673189816, 'num_filters_1': 127, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.030412158895594663, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 51, 'num_filters_3': 100}, 'budget': 133.33333333333331, 'working_directory': '.'}
14:41:10 DISPATCHER: Starting worker discovery
14:41:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:41:10 DISPATCHER: Finished worker discovery
14:42:10 DISPATCHER: Starting worker discovery
14:42:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:42:10 DISPATCHER: Finished worker discovery
14:43:10 DISPATCHER: Starting worker discovery
14:43:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:43:10 DISPATCHER: Finished worker discovery
14:43:12 WORKER: done with job (0, 0, 3), trying to register it.
14:43:12 WORKER: registered result for job (0, 0, 3) with dispatcher
14:43:12 DISPATCHER: job (0, 0, 3) finished
14:43:12 DISPATCHER: register_result: lock acquired
14:43:12 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
14:43:12 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0029243182673189816, 'num_filters_1': 127, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.030412158895594663, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 51, 'num_filters_3': 100}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3953563745449517, 'info': {'data05': 0.3953563745449517, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0029243182673189816, 'num_filters_1': 127, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.030412158895594663, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 51, 'num_filters_3': 100}"}}
exception: None

14:43:12 job_callback for (0, 0, 3) started
14:43:12 DISPATCHER: Trying to submit another job.
14:43:12 job_callback for (0, 0, 3) got condition
14:43:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:43:12 Only 2 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
14:43:12 HBMASTER: Trying to run another job!
14:43:12 job_callback for (0, 0, 3) finished
14:43:12 HBMASTER: schedule new run for iteration 0
14:43:12 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
14:43:12 HBMASTER: submitting job (0, 0, 4) to dispatcher
14:43:12 DISPATCHER: trying to submit job (0, 0, 4)
14:43:12 DISPATCHER: trying to notify the job_runner thread.
14:43:12 HBMASTER: job (0, 0, 4) submitted to dispatcher
14:43:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:43:12 DISPATCHER: Trying to submit another job.
14:43:12 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:43:12 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:43:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:43:12 WORKER: start processing job (0, 0, 4)
14:43:12 WORKER: args: ()
14:43:12 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.002140601643804871, 'num_filters_1': 30, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.03235759003071163}, 'budget': 133.33333333333331, 'working_directory': '.'}
14:44:10 DISPATCHER: Starting worker discovery
14:44:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:44:10 DISPATCHER: Finished worker discovery
14:45:10 DISPATCHER: Starting worker discovery
14:45:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:45:10 DISPATCHER: Finished worker discovery
14:45:49 WORKER: done with job (0, 0, 4), trying to register it.
14:45:49 WORKER: registered result for job (0, 0, 4) with dispatcher
14:45:49 DISPATCHER: job (0, 0, 4) finished
14:45:49 DISPATCHER: register_result: lock acquired
14:45:49 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
14:45:49 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.002140601643804871, 'num_filters_1': 30, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.03235759003071163}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.34569732370881767, 'info': {'data05': 0.34569732370881767, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.002140601643804871, 'num_filters_1': 30, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.03235759003071163}"}}
exception: None

14:45:49 job_callback for (0, 0, 4) started
14:45:49 job_callback for (0, 0, 4) got condition
14:45:49 DISPATCHER: Trying to submit another job.
14:45:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:45:49 Only 3 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
14:45:49 HBMASTER: Trying to run another job!
14:45:49 job_callback for (0, 0, 4) finished
14:45:49 HBMASTER: schedule new run for iteration 0
14:45:49 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
14:45:49 HBMASTER: submitting job (0, 0, 5) to dispatcher
14:45:49 DISPATCHER: trying to submit job (0, 0, 5)
14:45:49 DISPATCHER: trying to notify the job_runner thread.
14:45:49 HBMASTER: job (0, 0, 5) submitted to dispatcher
14:45:49 DISPATCHER: Trying to submit another job.
14:45:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:45:49 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:45:49 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:45:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:45:49 WORKER: start processing job (0, 0, 5)
14:45:49 WORKER: args: ()
14:45:49 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.010930911747665991, 'num_filters_1': 51, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.01348991263302075, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 88, 'num_filters_3': 47, 'num_filters_4': 30}, 'budget': 133.33333333333331, 'working_directory': '.'}
14:46:10 DISPATCHER: Starting worker discovery
14:46:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:46:10 DISPATCHER: Finished worker discovery
14:47:10 DISPATCHER: Starting worker discovery
14:47:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:47:10 DISPATCHER: Finished worker discovery
14:48:10 DISPATCHER: Starting worker discovery
14:48:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:48:10 DISPATCHER: Finished worker discovery
14:48:18 WORKER: done with job (0, 0, 5), trying to register it.
14:48:18 WORKER: registered result for job (0, 0, 5) with dispatcher
14:48:18 DISPATCHER: job (0, 0, 5) finished
14:48:18 DISPATCHER: register_result: lock acquired
14:48:18 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
14:48:18 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.010930911747665991, 'num_filters_1': 51, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.01348991263302075, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 88, 'num_filters_3': 47, 'num_filters_4': 30}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.18025907713756237, 'info': {'data05': 0.18025907713756237, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.010930911747665991, 'num_filters_1': 51, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.01348991263302075, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 88, 'num_filters_3': 47, 'num_filters_4': 30}"}}
exception: None

14:48:18 job_callback for (0, 0, 5) started
14:48:18 DISPATCHER: Trying to submit another job.
14:48:18 job_callback for (0, 0, 5) got condition
14:48:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:48:18 Only 4 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
14:48:18 HBMASTER: Trying to run another job!
14:48:18 job_callback for (0, 0, 5) finished
14:48:18 HBMASTER: schedule new run for iteration 0
14:48:18 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
14:48:18 HBMASTER: submitting job (0, 0, 6) to dispatcher
14:48:18 DISPATCHER: trying to submit job (0, 0, 6)
14:48:18 DISPATCHER: trying to notify the job_runner thread.
14:48:18 HBMASTER: job (0, 0, 6) submitted to dispatcher
14:48:18 DISPATCHER: Trying to submit another job.
14:48:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:48:18 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:48:18 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:48:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:48:18 WORKER: start processing job (0, 0, 6)
14:48:18 WORKER: args: ()
14:48:18 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0019799393890766745, 'num_filters_1': 49, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.02841254204672343}, 'budget': 133.33333333333331, 'working_directory': '.'}
14:49:10 DISPATCHER: Starting worker discovery
14:49:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:49:10 DISPATCHER: Finished worker discovery
14:50:10 DISPATCHER: Starting worker discovery
14:50:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:50:10 DISPATCHER: Finished worker discovery
14:50:51 WORKER: done with job (0, 0, 6), trying to register it.
14:50:51 WORKER: registered result for job (0, 0, 6) with dispatcher
14:50:51 DISPATCHER: job (0, 0, 6) finished
14:50:51 DISPATCHER: register_result: lock acquired
14:50:51 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
14:50:51 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0019799393890766745, 'num_filters_1': 49, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.02841254204672343}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.32192006532289374, 'info': {'data05': 0.32192006532289374, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0019799393890766745, 'num_filters_1': 49, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.02841254204672343}"}}
exception: None

14:50:51 job_callback for (0, 0, 6) started
14:50:51 DISPATCHER: Trying to submit another job.
14:50:51 job_callback for (0, 0, 6) got condition
14:50:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:50:51 Only 5 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
14:50:51 HBMASTER: Trying to run another job!
14:50:51 job_callback for (0, 0, 6) finished
14:50:51 HBMASTER: schedule new run for iteration 0
14:50:51 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
14:50:51 HBMASTER: submitting job (0, 0, 8) to dispatcher
14:50:51 DISPATCHER: trying to submit job (0, 0, 8)
14:50:51 DISPATCHER: trying to notify the job_runner thread.
14:50:51 HBMASTER: job (0, 0, 8) submitted to dispatcher
14:50:51 DISPATCHER: Trying to submit another job.
14:50:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:50:51 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:50:51 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:50:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:50:51 WORKER: start processing job (0, 0, 8)
14:50:51 WORKER: args: ()
14:50:51 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.006672255565280443, 'num_filters_1': 62, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.02827698916365454, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 25, 'num_filters_3': 22, 'num_filters_4': 90}, 'budget': 133.33333333333331, 'working_directory': '.'}
14:51:10 DISPATCHER: Starting worker discovery
14:51:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:51:10 DISPATCHER: Finished worker discovery
14:52:10 DISPATCHER: Starting worker discovery
14:52:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:52:10 DISPATCHER: Finished worker discovery
14:53:10 DISPATCHER: Starting worker discovery
14:53:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:53:10 DISPATCHER: Finished worker discovery
14:53:25 WORKER: done with job (0, 0, 8), trying to register it.
14:53:25 WORKER: registered result for job (0, 0, 8) with dispatcher
14:53:25 DISPATCHER: job (0, 0, 8) finished
14:53:25 DISPATCHER: register_result: lock acquired
14:53:25 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
14:53:25 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.006672255565280443, 'num_filters_1': 62, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.02827698916365454, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 25, 'num_filters_3': 22, 'num_filters_4': 90}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.091446346855761, 'info': {'data05': 0.091446346855761, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.006672255565280443, 'num_filters_1': 62, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.02827698916365454, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 25, 'num_filters_3': 22, 'num_filters_4': 90}"}}
exception: None

14:53:25 job_callback for (0, 0, 8) started
14:53:25 job_callback for (0, 0, 8) got condition
14:53:25 DISPATCHER: Trying to submit another job.
14:53:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:53:25 Only 6 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
14:53:25 HBMASTER: Trying to run another job!
14:53:25 job_callback for (0, 0, 8) finished
14:53:25 HBMASTER: schedule new run for iteration 0
14:53:25 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
14:53:25 HBMASTER: submitting job (0, 0, 10) to dispatcher
14:53:25 DISPATCHER: trying to submit job (0, 0, 10)
14:53:25 DISPATCHER: trying to notify the job_runner thread.
14:53:25 HBMASTER: job (0, 0, 10) submitted to dispatcher
14:53:25 DISPATCHER: Trying to submit another job.
14:53:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:53:25 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:53:25 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:53:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:53:25 WORKER: start processing job (0, 0, 10)
14:53:25 WORKER: args: ()
14:53:25 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.007373324503619039, 'num_filters_1': 109, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.033594556114968484, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 35, 'num_filters_3': 20, 'num_filters_4': 94}, 'budget': 133.33333333333331, 'working_directory': '.'}
14:54:10 DISPATCHER: Starting worker discovery
14:54:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:54:10 DISPATCHER: Finished worker discovery
14:55:10 DISPATCHER: Starting worker discovery
14:55:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:55:10 DISPATCHER: Finished worker discovery
14:55:52 WORKER: done with job (0, 0, 10), trying to register it.
14:55:52 WORKER: registered result for job (0, 0, 10) with dispatcher
14:55:52 DISPATCHER: job (0, 0, 10) finished
14:55:52 DISPATCHER: register_result: lock acquired
14:55:52 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
14:55:52 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.007373324503619039, 'num_filters_1': 109, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.033594556114968484, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 35, 'num_filters_3': 20, 'num_filters_4': 94}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3383903895503403, 'info': {'data05': 0.3383903895503403, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.007373324503619039, 'num_filters_1': 109, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.033594556114968484, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 35, 'num_filters_3': 20, 'num_filters_4': 94}"}}
exception: None

14:55:52 job_callback for (0, 0, 10) started
14:55:52 job_callback for (0, 0, 10) got condition
14:55:52 DISPATCHER: Trying to submit another job.
14:55:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:55:52 Only 7 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
14:55:52 HBMASTER: Trying to run another job!
14:55:52 job_callback for (0, 0, 10) finished
14:55:52 HBMASTER: schedule new run for iteration 0
14:55:52 HBMASTER: trying submitting job (0, 0, 14) to dispatcher
14:55:52 HBMASTER: submitting job (0, 0, 14) to dispatcher
14:55:52 DISPATCHER: trying to submit job (0, 0, 14)
14:55:52 DISPATCHER: trying to notify the job_runner thread.
14:55:52 HBMASTER: job (0, 0, 14) submitted to dispatcher
14:55:52 DISPATCHER: Trying to submit another job.
14:55:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:55:52 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:55:52 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:55:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:55:52 WORKER: start processing job (0, 0, 14)
14:55:52 WORKER: args: ()
14:55:52 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.00308563320295989, 'num_filters_1': 28, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.1089419010721721}, 'budget': 133.33333333333331, 'working_directory': '.'}
14:56:10 DISPATCHER: Starting worker discovery
14:56:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:56:10 DISPATCHER: Finished worker discovery
14:57:10 DISPATCHER: Starting worker discovery
14:57:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:57:10 DISPATCHER: Finished worker discovery
14:58:10 DISPATCHER: Starting worker discovery
14:58:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:58:11 DISPATCHER: Finished worker discovery
14:58:47 WORKER: done with job (0, 0, 14), trying to register it.
14:58:47 WORKER: registered result for job (0, 0, 14) with dispatcher
14:58:47 DISPATCHER: job (0, 0, 14) finished
14:58:47 DISPATCHER: register_result: lock acquired
14:58:47 DISPATCHER: job (0, 0, 14) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
14:58:47 job_id: (0, 0, 14)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.00308563320295989, 'num_filters_1': 28, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.1089419010721721}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.09836761200590774, 'info': {'data05': 0.09836761200590774, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.00308563320295989, 'num_filters_1': 28, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.1089419010721721}"}}
exception: None

14:58:47 job_callback for (0, 0, 14) started
14:58:47 DISPATCHER: Trying to submit another job.
14:58:47 job_callback for (0, 0, 14) got condition
14:58:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:58:47 Only 8 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
14:58:47 HBMASTER: Trying to run another job!
14:58:47 job_callback for (0, 0, 14) finished
14:58:47 HBMASTER: schedule new run for iteration 0
14:58:47 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
14:58:47 HBMASTER: submitting job (0, 0, 18) to dispatcher
14:58:47 DISPATCHER: trying to submit job (0, 0, 18)
14:58:47 DISPATCHER: trying to notify the job_runner thread.
14:58:47 HBMASTER: job (0, 0, 18) submitted to dispatcher
14:58:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:58:47 DISPATCHER: Trying to submit another job.
14:58:47 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:58:47 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
14:58:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:58:47 WORKER: start processing job (0, 0, 18)
14:58:47 WORKER: args: ()
14:58:47 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0013679195385740955, 'num_filters_1': 73, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.02241184286916222}, 'budget': 133.33333333333331, 'working_directory': '.'}
14:59:11 DISPATCHER: Starting worker discovery
14:59:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:59:11 DISPATCHER: Finished worker discovery
15:00:11 DISPATCHER: Starting worker discovery
15:00:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:00:11 DISPATCHER: Finished worker discovery
15:01:11 DISPATCHER: Starting worker discovery
15:01:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:01:11 DISPATCHER: Finished worker discovery
15:01:16 WORKER: done with job (0, 0, 18), trying to register it.
15:01:16 WORKER: registered result for job (0, 0, 18) with dispatcher
15:01:16 DISPATCHER: job (0, 0, 18) finished
15:01:16 DISPATCHER: register_result: lock acquired
15:01:16 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
15:01:16 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0013679195385740955, 'num_filters_1': 73, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.02241184286916222}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5836634333658975, 'info': {'data05': 0.5836634333658975, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0013679195385740955, 'num_filters_1': 73, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.02241184286916222}"}}
exception: None

15:01:16 job_callback for (0, 0, 18) started
15:01:16 job_callback for (0, 0, 18) got condition
15:01:16 DISPATCHER: Trying to submit another job.
15:01:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:01:16 Only 9 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
15:01:16 HBMASTER: Trying to run another job!
15:01:16 job_callback for (0, 0, 18) finished
15:01:16 ITERATION: Advancing config (0, 0, 3) to next budget 400.000000
15:01:16 ITERATION: Advancing config (0, 0, 4) to next budget 400.000000
15:01:16 ITERATION: Advancing config (0, 0, 18) to next budget 400.000000
15:01:16 HBMASTER: schedule new run for iteration 0
15:01:16 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
15:01:16 HBMASTER: submitting job (0, 0, 3) to dispatcher
15:01:16 DISPATCHER: trying to submit job (0, 0, 3)
15:01:16 DISPATCHER: trying to notify the job_runner thread.
15:01:16 HBMASTER: job (0, 0, 3) submitted to dispatcher
15:01:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:01:16 DISPATCHER: Trying to submit another job.
15:01:16 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
15:01:16 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
15:01:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:01:16 WORKER: start processing job (0, 0, 3)
15:01:16 WORKER: args: ()
15:01:16 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0029243182673189816, 'num_filters_1': 127, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.030412158895594663, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 51, 'num_filters_3': 100}, 'budget': 400.0, 'working_directory': '.'}
15:02:11 DISPATCHER: Starting worker discovery
15:02:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:02:11 DISPATCHER: Finished worker discovery
15:03:11 DISPATCHER: Starting worker discovery
15:03:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:03:11 DISPATCHER: Finished worker discovery
15:04:11 DISPATCHER: Starting worker discovery
15:04:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:04:11 DISPATCHER: Finished worker discovery
15:05:11 DISPATCHER: Starting worker discovery
15:05:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:05:11 DISPATCHER: Finished worker discovery
15:06:11 DISPATCHER: Starting worker discovery
15:06:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:06:11 DISPATCHER: Finished worker discovery
15:07:11 DISPATCHER: Starting worker discovery
15:07:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:07:11 DISPATCHER: Finished worker discovery
15:08:11 DISPATCHER: Starting worker discovery
15:08:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:08:11 DISPATCHER: Finished worker discovery
15:08:41 WORKER: done with job (0, 0, 3), trying to register it.
15:08:41 WORKER: registered result for job (0, 0, 3) with dispatcher
15:08:41 DISPATCHER: job (0, 0, 3) finished
15:08:41 DISPATCHER: register_result: lock acquired
15:08:41 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
15:08:41 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0029243182673189816, 'num_filters_1': 127, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.030412158895594663, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 51, 'num_filters_3': 100}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.17239504655827664, 'info': {'data05': 0.17239504655827664, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0029243182673189816, 'num_filters_1': 127, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.030412158895594663, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 51, 'num_filters_3': 100}"}}
exception: None

15:08:41 job_callback for (0, 0, 3) started
15:08:41 DISPATCHER: Trying to submit another job.
15:08:41 job_callback for (0, 0, 3) got condition
15:08:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:08:41 Only 1 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
15:08:41 HBMASTER: Trying to run another job!
15:08:41 job_callback for (0, 0, 3) finished
15:08:41 HBMASTER: schedule new run for iteration 0
15:08:41 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
15:08:41 HBMASTER: submitting job (0, 0, 4) to dispatcher
15:08:41 DISPATCHER: trying to submit job (0, 0, 4)
15:08:41 DISPATCHER: trying to notify the job_runner thread.
15:08:41 HBMASTER: job (0, 0, 4) submitted to dispatcher
15:08:41 DISPATCHER: Trying to submit another job.
15:08:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:08:41 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464
15:08:41 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
15:08:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:08:41 WORKER: start processing job (0, 0, 4)
15:08:41 WORKER: args: ()
15:08:41 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.002140601643804871, 'num_filters_1': 30, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.03235759003071163}, 'budget': 400.0, 'working_directory': '.'}
15:09:11 DISPATCHER: Starting worker discovery
15:09:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:09:11 DISPATCHER: Finished worker discovery
15:10:11 DISPATCHER: Starting worker discovery
15:10:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:10:11 DISPATCHER: Finished worker discovery
15:11:11 DISPATCHER: Starting worker discovery
15:11:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:11:11 DISPATCHER: Finished worker discovery
15:12:11 DISPATCHER: Starting worker discovery
15:12:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:12:11 DISPATCHER: Finished worker discovery
15:13:11 DISPATCHER: Starting worker discovery
15:13:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:13:11 DISPATCHER: Finished worker discovery
15:14:11 DISPATCHER: Starting worker discovery
15:14:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:14:11 DISPATCHER: Finished worker discovery
15:15:11 DISPATCHER: Starting worker discovery
15:15:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:15:11 DISPATCHER: Finished worker discovery
15:16:09 WORKER: done with job (0, 0, 4), trying to register it.
15:16:09 WORKER: registered result for job (0, 0, 4) with dispatcher
15:16:09 DISPATCHER: job (0, 0, 4) finished
15:16:09 DISPATCHER: register_result: lock acquired
15:16:09 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
15:16:09 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.002140601643804871, 'num_filters_1': 30, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.03235759003071163}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.4247392817186191, 'info': {'data05': 0.4247392817186191, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.002140601643804871, 'num_filters_1': 30, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.03235759003071163}"}}
exception: None

15:16:09 job_callback for (0, 0, 4) started
15:16:09 DISPATCHER: Trying to submit another job.
15:16:09 job_callback for (0, 0, 4) got condition
15:16:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:16:09 Only 2 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
15:16:09 HBMASTER: Trying to run another job!
15:16:09 job_callback for (0, 0, 4) finished
15:16:09 HBMASTER: schedule new run for iteration 0
15:16:09 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
15:16:09 HBMASTER: submitting job (0, 0, 18) to dispatcher
15:16:09 DISPATCHER: trying to submit job (0, 0, 18)
15:16:09 DISPATCHER: trying to notify the job_runner thread.
15:16:09 HBMASTER: job (0, 0, 18) submitted to dispatcher
15:16:09 DISPATCHER: Trying to submit another job.
15:16:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:16:09 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpuj.13101140314513094464
15:16:09 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
15:16:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:16:09 WORKER: start processing job (0, 0, 18)
15:16:09 WORKER: args: ()
15:16:09 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0013679195385740955, 'num_filters_1': 73, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.02241184286916222}, 'budget': 400.0, 'working_directory': '.'}
15:16:11 DISPATCHER: Starting worker discovery
15:16:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:16:11 DISPATCHER: Finished worker discovery
15:17:11 DISPATCHER: Starting worker discovery
15:17:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:17:11 DISPATCHER: Finished worker discovery
15:18:11 DISPATCHER: Starting worker discovery
15:18:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:18:11 DISPATCHER: Finished worker discovery
15:19:11 DISPATCHER: Starting worker discovery
15:19:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:19:11 DISPATCHER: Finished worker discovery
15:20:11 DISPATCHER: Starting worker discovery
15:20:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:20:11 DISPATCHER: Finished worker discovery
15:21:11 DISPATCHER: Starting worker discovery
15:21:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:21:11 DISPATCHER: Finished worker discovery
15:22:11 DISPATCHER: Starting worker discovery
15:22:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:22:11 DISPATCHER: Finished worker discovery
15:23:11 DISPATCHER: Starting worker discovery
15:23:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:23:11 DISPATCHER: Finished worker discovery
15:23:14 WORKER: done with job (0, 0, 18), trying to register it.
15:23:14 WORKER: registered result for job (0, 0, 18) with dispatcher
15:23:14 DISPATCHER: job (0, 0, 18) finished
15:23:14 DISPATCHER: register_result: lock acquired
15:23:14 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
15:23:14 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0013679195385740955, 'num_filters_1': 73, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.02241184286916222}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.46194522812145955, 'info': {'data05': 0.46194522812145955, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0013679195385740955, 'num_filters_1': 73, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.02241184286916222}"}}
exception: None

15:23:14 job_callback for (0, 0, 18) started
15:23:14 job_callback for (0, 0, 18) got condition
15:23:14 DISPATCHER: Trying to submit another job.
15:23:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:23:14 Only 3 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
15:23:14 HBMASTER: Trying to run another job!
15:23:14 job_callback for (0, 0, 18) finished
15:23:14 ITERATION: Advancing config (0, 0, 18) to next budget 1200.000000
15:23:14 HBMASTER: schedule new run for iteration 0
15:23:14 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
15:23:14 HBMASTER: submitting job (0, 0, 18) to dispatcher
15:23:14 DISPATCHER: trying to submit job (0, 0, 18)
15:23:14 DISPATCHER: trying to notify the job_runner thread.
15:23:14 HBMASTER: job (0, 0, 18) submitted to dispatcher
15:23:14 DISPATCHER: Trying to submit another job.
15:23:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:23:14 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpuj.13101140314513094464
15:23:14 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
15:23:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:23:14 WORKER: start processing job (0, 0, 18)
15:23:14 WORKER: args: ()
15:23:14 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0013679195385740955, 'num_filters_1': 73, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.02241184286916222}, 'budget': 1200.0, 'working_directory': '.'}
15:24:11 DISPATCHER: Starting worker discovery
15:24:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:24:11 DISPATCHER: Finished worker discovery
15:25:11 DISPATCHER: Starting worker discovery
15:25:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:25:11 DISPATCHER: Finished worker discovery
15:26:11 DISPATCHER: Starting worker discovery
15:26:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:26:11 DISPATCHER: Finished worker discovery
15:27:11 DISPATCHER: Starting worker discovery
15:27:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:27:11 DISPATCHER: Finished worker discovery
15:28:11 DISPATCHER: Starting worker discovery
15:28:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:28:11 DISPATCHER: Finished worker discovery
15:29:11 DISPATCHER: Starting worker discovery
15:29:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:29:11 DISPATCHER: Finished worker discovery
15:30:11 DISPATCHER: Starting worker discovery
15:30:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:30:11 DISPATCHER: Finished worker discovery
15:31:11 DISPATCHER: Starting worker discovery
15:31:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:31:11 DISPATCHER: Finished worker discovery
15:32:11 DISPATCHER: Starting worker discovery
15:32:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:32:11 DISPATCHER: Finished worker discovery
15:33:11 DISPATCHER: Starting worker discovery
15:33:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:33:11 DISPATCHER: Finished worker discovery
15:34:11 DISPATCHER: Starting worker discovery
15:34:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:34:11 DISPATCHER: Finished worker discovery
15:35:11 DISPATCHER: Starting worker discovery
15:35:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:35:11 DISPATCHER: Finished worker discovery
15:36:11 DISPATCHER: Starting worker discovery
15:36:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:36:11 DISPATCHER: Finished worker discovery
15:37:11 DISPATCHER: Starting worker discovery
15:37:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:37:11 DISPATCHER: Finished worker discovery
15:38:11 DISPATCHER: Starting worker discovery
15:38:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:38:11 DISPATCHER: Finished worker discovery
15:39:11 DISPATCHER: Starting worker discovery
15:39:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:39:11 DISPATCHER: Finished worker discovery
15:40:11 DISPATCHER: Starting worker discovery
15:40:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:40:11 DISPATCHER: Finished worker discovery
15:41:11 DISPATCHER: Starting worker discovery
15:41:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:41:11 DISPATCHER: Finished worker discovery
15:42:11 DISPATCHER: Starting worker discovery
15:42:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:42:11 DISPATCHER: Finished worker discovery
15:43:11 DISPATCHER: Starting worker discovery
15:43:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:43:11 DISPATCHER: Finished worker discovery
15:44:06 WORKER: done with job (0, 0, 18), trying to register it.
15:44:06 WORKER: registered result for job (0, 0, 18) with dispatcher
15:44:06 DISPATCHER: job (0, 0, 18) finished
15:44:06 DISPATCHER: register_result: lock acquired
15:44:06 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
15:44:06 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0013679195385740955, 'num_filters_1': 73, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.02241184286916222}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.3619616523081152, 'info': {'data05': 0.3619616523081152, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0013679195385740955, 'num_filters_1': 73, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.02241184286916222}"}}
exception: None

15:44:06 job_callback for (0, 0, 18) started
15:44:06 job_callback for (0, 0, 18) got condition
15:44:06 DISPATCHER: Trying to submit another job.
15:44:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:44:06 Only 1 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
15:44:06 HBMASTER: Trying to run another job!
15:44:06 job_callback for (0, 0, 18) finished
15:44:06 start sampling a new configuration.
15:44:06 done sampling a new configuration.
15:44:06 HBMASTER: schedule new run for iteration 1
15:44:06 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
15:44:06 HBMASTER: submitting job (1, 0, 0) to dispatcher
15:44:06 DISPATCHER: trying to submit job (1, 0, 0)
15:44:06 DISPATCHER: trying to notify the job_runner thread.
15:44:06 HBMASTER: job (1, 0, 0) submitted to dispatcher
15:44:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:44:06 DISPATCHER: Trying to submit another job.
15:44:06 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
15:44:06 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
15:44:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:44:06 WORKER: start processing job (1, 0, 0)
15:44:06 WORKER: args: ()
15:44:06 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0021553492717993703, 'num_filters_1': 49, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.14009458606740066, 'kernel_size_2': 5, 'num_filters_2': 59}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:44:11 DISPATCHER: Starting worker discovery
15:44:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:44:11 DISPATCHER: Finished worker discovery
15:45:11 DISPATCHER: Starting worker discovery
15:45:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:45:11 DISPATCHER: Finished worker discovery
15:46:11 DISPATCHER: Starting worker discovery
15:46:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:46:11 DISPATCHER: Finished worker discovery
15:46:40 WORKER: done with job (1, 0, 0), trying to register it.
15:46:40 WORKER: registered result for job (1, 0, 0) with dispatcher
15:46:40 DISPATCHER: job (1, 0, 0) finished
15:46:40 DISPATCHER: register_result: lock acquired
15:46:40 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
15:46:40 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0021553492717993703, 'num_filters_1': 49, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.14009458606740066, 'kernel_size_2': 5, 'num_filters_2': 59}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1311227939626492, 'info': {'data05': 0.1311227939626492, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0021553492717993703, 'num_filters_1': 49, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.14009458606740066, 'kernel_size_2': 5, 'num_filters_2': 59}"}}
exception: None

15:46:40 job_callback for (1, 0, 0) started
15:46:40 job_callback for (1, 0, 0) got condition
15:46:40 DISPATCHER: Trying to submit another job.
15:46:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:46:40 Only 10 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
15:46:40 HBMASTER: Trying to run another job!
15:46:40 job_callback for (1, 0, 0) finished
15:46:40 start sampling a new configuration.
15:46:40 done sampling a new configuration.
15:46:40 HBMASTER: schedule new run for iteration 1
15:46:40 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
15:46:40 HBMASTER: submitting job (1, 0, 1) to dispatcher
15:46:40 DISPATCHER: trying to submit job (1, 0, 1)
15:46:40 DISPATCHER: trying to notify the job_runner thread.
15:46:40 HBMASTER: job (1, 0, 1) submitted to dispatcher
15:46:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:46:40 DISPATCHER: Trying to submit another job.
15:46:40 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
15:46:40 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
15:46:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:46:40 WORKER: start processing job (1, 0, 1)
15:46:40 WORKER: args: ()
15:46:40 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.043419580375562546, 'num_filters_1': 32, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.05767604675620487, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 50, 'num_filters_3': 62, 'num_filters_4': 62}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:47:11 DISPATCHER: Starting worker discovery
15:47:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:47:11 DISPATCHER: Finished worker discovery
15:48:11 DISPATCHER: Starting worker discovery
15:48:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:48:11 DISPATCHER: Finished worker discovery
15:49:11 DISPATCHER: Starting worker discovery
15:49:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:49:11 DISPATCHER: Finished worker discovery
15:49:13 WORKER: done with job (1, 0, 1), trying to register it.
15:49:13 WORKER: registered result for job (1, 0, 1) with dispatcher
15:49:13 DISPATCHER: job (1, 0, 1) finished
15:49:13 DISPATCHER: register_result: lock acquired
15:49:13 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
15:49:13 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.043419580375562546, 'num_filters_1': 32, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.05767604675620487, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 50, 'num_filters_3': 62, 'num_filters_4': 62}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.010567912227294824, 'info': {'data05': 0.010567912227294824, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.043419580375562546, 'num_filters_1': 32, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.05767604675620487, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 50, 'num_filters_3': 62, 'num_filters_4': 62}"}}
exception: None

15:49:13 job_callback for (1, 0, 1) started
15:49:13 DISPATCHER: Trying to submit another job.
15:49:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:49:13 job_callback for (1, 0, 1) got condition
15:49:13 Only 11 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
15:49:13 HBMASTER: Trying to run another job!
15:49:13 job_callback for (1, 0, 1) finished
15:49:13 start sampling a new configuration.
15:49:13 done sampling a new configuration.
15:49:13 HBMASTER: schedule new run for iteration 1
15:49:13 HBMASTER: trying submitting job (1, 0, 2) to dispatcher
15:49:13 HBMASTER: submitting job (1, 0, 2) to dispatcher
15:49:13 DISPATCHER: trying to submit job (1, 0, 2)
15:49:13 DISPATCHER: trying to notify the job_runner thread.
15:49:13 HBMASTER: job (1, 0, 2) submitted to dispatcher
15:49:13 DISPATCHER: Trying to submit another job.
15:49:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:49:13 DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
15:49:13 DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
15:49:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:49:13 WORKER: start processing job (1, 0, 2)
15:49:13 WORKER: args: ()
15:49:13 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.05718052535200816, 'num_filters_1': 73, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.13715254331097967, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 27, 'num_filters_3': 48, 'num_filters_4': 59, 'num_filters_5': 107}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:50:11 DISPATCHER: Starting worker discovery
15:50:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:50:11 DISPATCHER: Finished worker discovery
15:51:11 DISPATCHER: Starting worker discovery
15:51:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:51:11 DISPATCHER: Finished worker discovery
15:51:40 WORKER: done with job (1, 0, 2), trying to register it.
15:51:40 WORKER: registered result for job (1, 0, 2) with dispatcher
15:51:40 DISPATCHER: job (1, 0, 2) finished
15:51:40 DISPATCHER: register_result: lock acquired
15:51:40 DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
15:51:40 job_id: (1, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.05718052535200816, 'num_filters_1': 73, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.13715254331097967, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 27, 'num_filters_3': 48, 'num_filters_4': 59, 'num_filters_5': 107}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': 0.0035356175368992685, 'info': {'data05': -0.0035356175368992685, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.05718052535200816, 'num_filters_1': 73, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.13715254331097967, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 27, 'num_filters_3': 48, 'num_filters_4': 59, 'num_filters_5': 107}"}}
exception: None

15:51:40 job_callback for (1, 0, 2) started
15:51:40 DISPATCHER: Trying to submit another job.
15:51:40 job_callback for (1, 0, 2) got condition
15:51:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:51:40 Only 12 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
15:51:40 HBMASTER: Trying to run another job!
15:51:40 job_callback for (1, 0, 2) finished
15:51:40 start sampling a new configuration.
15:51:40 done sampling a new configuration.
15:51:40 HBMASTER: schedule new run for iteration 1
15:51:40 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
15:51:40 HBMASTER: submitting job (1, 0, 3) to dispatcher
15:51:40 DISPATCHER: trying to submit job (1, 0, 3)
15:51:40 DISPATCHER: trying to notify the job_runner thread.
15:51:40 HBMASTER: job (1, 0, 3) submitted to dispatcher
15:51:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:51:40 DISPATCHER: Trying to submit another job.
15:51:40 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
15:51:40 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
15:51:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:51:40 WORKER: start processing job (1, 0, 3)
15:51:40 WORKER: args: ()
15:51:40 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.019853110445275376, 'num_filters_1': 22, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.073984896342721, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 33, 'num_filters_3': 119}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:52:11 DISPATCHER: Starting worker discovery
15:52:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:52:11 DISPATCHER: Finished worker discovery
15:53:11 DISPATCHER: Starting worker discovery
15:53:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:53:11 DISPATCHER: Finished worker discovery
15:54:11 DISPATCHER: Starting worker discovery
15:54:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:54:11 DISPATCHER: Finished worker discovery
15:54:19 WORKER: done with job (1, 0, 3), trying to register it.
15:54:19 WORKER: registered result for job (1, 0, 3) with dispatcher
15:54:19 DISPATCHER: job (1, 0, 3) finished
15:54:19 DISPATCHER: register_result: lock acquired
15:54:19 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
15:54:19 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.019853110445275376, 'num_filters_1': 22, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.073984896342721, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 33, 'num_filters_3': 119}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -5.474361232004011e-06, 'info': {'data05': 5.474361232004011e-06, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.019853110445275376, 'num_filters_1': 22, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.073984896342721, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 33, 'num_filters_3': 119}"}}
exception: None

15:54:19 job_callback for (1, 0, 3) started
15:54:19 job_callback for (1, 0, 3) got condition
15:54:19 DISPATCHER: Trying to submit another job.
15:54:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:54:19 Only 13 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
15:54:19 HBMASTER: Trying to run another job!
15:54:19 job_callback for (1, 0, 3) finished
15:54:19 start sampling a new configuration.
15:54:19 done sampling a new configuration.
15:54:19 HBMASTER: schedule new run for iteration 1
15:54:19 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
15:54:19 HBMASTER: submitting job (1, 0, 4) to dispatcher
15:54:19 DISPATCHER: trying to submit job (1, 0, 4)
15:54:19 DISPATCHER: trying to notify the job_runner thread.
15:54:19 HBMASTER: job (1, 0, 4) submitted to dispatcher
15:54:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:54:19 DISPATCHER: Trying to submit another job.
15:54:19 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464
15:54:19 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
15:54:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:54:19 WORKER: start processing job (1, 0, 4)
15:54:19 WORKER: args: ()
15:54:19 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.012874298616800757, 'num_filters_1': 78, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.04484871379347336, 'kernel_size_2': 5, 'num_filters_2': 105}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:55:11 DISPATCHER: Starting worker discovery
15:55:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:55:11 DISPATCHER: Finished worker discovery
15:56:11 DISPATCHER: Starting worker discovery
15:56:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:56:11 DISPATCHER: Finished worker discovery
15:56:56 WORKER: done with job (1, 0, 4), trying to register it.
15:56:56 WORKER: registered result for job (1, 0, 4) with dispatcher
15:56:56 DISPATCHER: job (1, 0, 4) finished
15:56:56 DISPATCHER: register_result: lock acquired
15:56:56 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
15:56:56 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.012874298616800757, 'num_filters_1': 78, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.04484871379347336, 'kernel_size_2': 5, 'num_filters_2': 105}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -2.3517273692294853e-05, 'info': {'data05': 2.3517273692294853e-05, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.012874298616800757, 'num_filters_1': 78, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.04484871379347336, 'kernel_size_2': 5, 'num_filters_2': 105}"}}
exception: None

15:56:56 job_callback for (1, 0, 4) started
15:56:56 job_callback for (1, 0, 4) got condition
15:56:56 DISPATCHER: Trying to submit another job.
15:56:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:56:56 Only 14 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
15:56:56 HBMASTER: Trying to run another job!
15:56:56 job_callback for (1, 0, 4) finished
15:56:56 start sampling a new configuration.
15:56:56 done sampling a new configuration.
15:56:56 HBMASTER: schedule new run for iteration 1
15:56:56 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
15:56:56 HBMASTER: submitting job (1, 0, 5) to dispatcher
15:56:56 DISPATCHER: trying to submit job (1, 0, 5)
15:56:56 DISPATCHER: trying to notify the job_runner thread.
15:56:56 HBMASTER: job (1, 0, 5) submitted to dispatcher
15:56:56 DISPATCHER: Trying to submit another job.
15:56:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:56:56 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
15:56:56 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
15:56:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:56:56 WORKER: start processing job (1, 0, 5)
15:56:56 WORKER: args: ()
15:56:56 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.03040059407346808, 'num_filters_1': 101, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.03182654755822253}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:57:11 DISPATCHER: Starting worker discovery
15:57:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:57:11 DISPATCHER: Finished worker discovery
15:58:11 DISPATCHER: Starting worker discovery
15:58:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:58:11 DISPATCHER: Finished worker discovery
15:59:11 DISPATCHER: Starting worker discovery
15:59:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:59:11 DISPATCHER: Finished worker discovery
15:59:31 WORKER: done with job (1, 0, 5), trying to register it.
15:59:31 WORKER: registered result for job (1, 0, 5) with dispatcher
15:59:31 DISPATCHER: job (1, 0, 5) finished
15:59:31 DISPATCHER: register_result: lock acquired
15:59:31 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
15:59:31 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.03040059407346808, 'num_filters_1': 101, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.03182654755822253}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.023148654634373354, 'info': {'data05': 0.023148654634373354, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.03040059407346808, 'num_filters_1': 101, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.03182654755822253}"}}
exception: None

15:59:31 job_callback for (1, 0, 5) started
15:59:31 DISPATCHER: Trying to submit another job.
15:59:31 job_callback for (1, 0, 5) got condition
15:59:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:59:31 Only 15 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
15:59:31 HBMASTER: Trying to run another job!
15:59:31 job_callback for (1, 0, 5) finished
15:59:31 start sampling a new configuration.
15:59:31 done sampling a new configuration.
15:59:31 HBMASTER: schedule new run for iteration 1
15:59:31 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
15:59:31 HBMASTER: submitting job (1, 0, 6) to dispatcher
15:59:31 DISPATCHER: trying to submit job (1, 0, 6)
15:59:31 DISPATCHER: trying to notify the job_runner thread.
15:59:31 HBMASTER: job (1, 0, 6) submitted to dispatcher
15:59:31 DISPATCHER: Trying to submit another job.
15:59:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:59:31 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464
15:59:31 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
15:59:31 WORKER: start processing job (1, 0, 6)
15:59:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:59:31 WORKER: args: ()
15:59:31 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0012306083618553393, 'num_filters_1': 74, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.08905809283353083, 'kernel_size_2': 3, 'num_filters_2': 25}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:00:11 DISPATCHER: Starting worker discovery
16:00:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:00:11 DISPATCHER: Finished worker discovery
16:01:11 DISPATCHER: Starting worker discovery
16:01:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:01:11 DISPATCHER: Finished worker discovery
16:02:01 WORKER: done with job (1, 0, 6), trying to register it.
16:02:01 WORKER: registered result for job (1, 0, 6) with dispatcher
16:02:01 DISPATCHER: job (1, 0, 6) finished
16:02:01 DISPATCHER: register_result: lock acquired
16:02:01 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
16:02:01 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0012306083618553393, 'num_filters_1': 74, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.08905809283353083, 'kernel_size_2': 3, 'num_filters_2': 25}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.35800125822835027, 'info': {'data05': 0.35800125822835027, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0012306083618553393, 'num_filters_1': 74, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.08905809283353083, 'kernel_size_2': 3, 'num_filters_2': 25}"}}
exception: None

16:02:01 job_callback for (1, 0, 6) started
16:02:01 DISPATCHER: Trying to submit another job.
16:02:01 job_callback for (1, 0, 6) got condition
16:02:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:02:01 Only 16 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
16:02:01 HBMASTER: Trying to run another job!
16:02:01 job_callback for (1, 0, 6) finished
16:02:01 start sampling a new configuration.
16:02:01 done sampling a new configuration.
16:02:01 HBMASTER: schedule new run for iteration 1
16:02:01 HBMASTER: trying submitting job (1, 0, 7) to dispatcher
16:02:01 HBMASTER: submitting job (1, 0, 7) to dispatcher
16:02:01 DISPATCHER: trying to submit job (1, 0, 7)
16:02:01 DISPATCHER: trying to notify the job_runner thread.
16:02:01 HBMASTER: job (1, 0, 7) submitted to dispatcher
16:02:01 DISPATCHER: Trying to submit another job.
16:02:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:02:01 DISPATCHER: starting job (1, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464
16:02:01 DISPATCHER: job (1, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
16:02:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:02:01 WORKER: start processing job (1, 0, 7)
16:02:01 WORKER: args: ()
16:02:01 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.09403202241356355, 'num_filters_1': 49, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.016926754108734482, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 19, 'num_filters_3': 48, 'num_filters_4': 24, 'num_filters_5': 58}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:02:11 DISPATCHER: Starting worker discovery
16:02:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:02:11 DISPATCHER: Finished worker discovery
16:03:11 DISPATCHER: Starting worker discovery
16:03:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:03:11 DISPATCHER: Finished worker discovery
16:04:11 DISPATCHER: Starting worker discovery
16:04:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:04:11 DISPATCHER: Finished worker discovery
16:04:27 WORKER: done with job (1, 0, 7), trying to register it.
16:04:27 WORKER: registered result for job (1, 0, 7) with dispatcher
16:04:27 DISPATCHER: job (1, 0, 7) finished
16:04:27 DISPATCHER: register_result: lock acquired
16:04:27 DISPATCHER: job (1, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
16:04:27 job_id: (1, 0, 7)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.09403202241356355, 'num_filters_1': 49, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.016926754108734482, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 19, 'num_filters_3': 48, 'num_filters_4': 24, 'num_filters_5': 58}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.09403202241356355, 'num_filters_1': 49, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.016926754108734482, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 19, 'num_filters_3': 48, 'num_filters_4': 24, 'num_filters_5': 58}"}}
exception: None

16:04:27 job_callback for (1, 0, 7) started
16:04:27 DISPATCHER: Trying to submit another job.
16:04:27 job_callback for (1, 0, 7) got condition
16:04:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:04:27 HBMASTER: Trying to run another job!
16:04:27 job_callback for (1, 0, 7) finished
16:04:27 start sampling a new configuration.
16:04:27 done sampling a new configuration.
16:04:27 HBMASTER: schedule new run for iteration 1
16:04:27 HBMASTER: trying submitting job (1, 0, 8) to dispatcher
16:04:27 HBMASTER: submitting job (1, 0, 8) to dispatcher
16:04:27 DISPATCHER: trying to submit job (1, 0, 8)
16:04:27 DISPATCHER: trying to notify the job_runner thread.
16:04:27 HBMASTER: job (1, 0, 8) submitted to dispatcher
16:04:27 DISPATCHER: Trying to submit another job.
16:04:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:04:27 DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464
16:04:27 DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
16:04:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:04:27 WORKER: start processing job (1, 0, 8)
16:04:27 WORKER: args: ()
16:04:27 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.003506583165066148, 'num_filters_1': 18, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.05298718183550586, 'kernel_size_2': 7, 'num_filters_2': 43}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:05:11 DISPATCHER: Starting worker discovery
16:05:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:05:11 DISPATCHER: Finished worker discovery
16:06:11 DISPATCHER: Starting worker discovery
16:06:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:06:11 DISPATCHER: Finished worker discovery
16:06:54 WORKER: done with job (1, 0, 8), trying to register it.
16:06:54 WORKER: registered result for job (1, 0, 8) with dispatcher
16:06:54 DISPATCHER: job (1, 0, 8) finished
16:06:54 DISPATCHER: register_result: lock acquired
16:06:54 DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
16:06:54 job_id: (1, 0, 8)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.003506583165066148, 'num_filters_1': 18, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.05298718183550586, 'kernel_size_2': 7, 'num_filters_2': 43}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.15151937468523824, 'info': {'data05': 0.15151937468523824, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.003506583165066148, 'num_filters_1': 18, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.05298718183550586, 'kernel_size_2': 7, 'num_filters_2': 43}"}}
exception: None

16:06:54 job_callback for (1, 0, 8) started
16:06:54 DISPATCHER: Trying to submit another job.
16:06:54 job_callback for (1, 0, 8) got condition
16:06:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:06:54 HBMASTER: Trying to run another job!
16:06:54 job_callback for (1, 0, 8) finished
16:06:54 ITERATION: Advancing config (1, 0, 0) to next budget 400.000000
16:06:54 ITERATION: Advancing config (1, 0, 6) to next budget 400.000000
16:06:54 ITERATION: Advancing config (1, 0, 8) to next budget 400.000000
16:06:54 HBMASTER: schedule new run for iteration 1
16:06:54 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
16:06:54 HBMASTER: submitting job (1, 0, 0) to dispatcher
16:06:54 DISPATCHER: trying to submit job (1, 0, 0)
16:06:54 DISPATCHER: trying to notify the job_runner thread.
16:06:54 HBMASTER: job (1, 0, 0) submitted to dispatcher
16:06:54 DISPATCHER: Trying to submit another job.
16:06:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:06:54 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
16:06:54 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
16:06:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:06:54 WORKER: start processing job (1, 0, 0)
16:06:54 WORKER: args: ()
16:06:54 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0021553492717993703, 'num_filters_1': 49, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.14009458606740066, 'kernel_size_2': 5, 'num_filters_2': 59}, 'budget': 400.0, 'working_directory': '.'}
16:07:11 DISPATCHER: Starting worker discovery
16:07:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:07:11 DISPATCHER: Finished worker discovery
16:08:11 DISPATCHER: Starting worker discovery
16:08:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:08:11 DISPATCHER: Finished worker discovery
16:09:11 DISPATCHER: Starting worker discovery
16:09:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:09:11 DISPATCHER: Finished worker discovery
16:10:11 DISPATCHER: Starting worker discovery
16:10:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:10:11 DISPATCHER: Finished worker discovery
16:11:11 DISPATCHER: Starting worker discovery
16:11:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:11:11 DISPATCHER: Finished worker discovery
16:12:11 DISPATCHER: Starting worker discovery
16:12:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:12:11 DISPATCHER: Finished worker discovery
16:13:11 DISPATCHER: Starting worker discovery
16:13:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:13:11 DISPATCHER: Finished worker discovery
16:14:11 DISPATCHER: Starting worker discovery
16:14:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:14:11 DISPATCHER: Finished worker discovery
16:14:18 WORKER: done with job (1, 0, 0), trying to register it.
16:14:18 WORKER: registered result for job (1, 0, 0) with dispatcher
16:14:18 DISPATCHER: job (1, 0, 0) finished
16:14:18 DISPATCHER: register_result: lock acquired
16:14:18 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
16:14:18 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0021553492717993703, 'num_filters_1': 49, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.14009458606740066, 'kernel_size_2': 5, 'num_filters_2': 59}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.04988052157477925, 'info': {'data05': 0.04988052157477925, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0021553492717993703, 'num_filters_1': 49, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.14009458606740066, 'kernel_size_2': 5, 'num_filters_2': 59}"}}
exception: None

16:14:18 job_callback for (1, 0, 0) started
16:14:18 job_callback for (1, 0, 0) got condition
16:14:18 DISPATCHER: Trying to submit another job.
16:14:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:14:18 Only 4 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
16:14:18 HBMASTER: Trying to run another job!
16:14:18 job_callback for (1, 0, 0) finished
16:14:18 HBMASTER: schedule new run for iteration 1
16:14:18 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
16:14:18 HBMASTER: submitting job (1, 0, 6) to dispatcher
16:14:18 DISPATCHER: trying to submit job (1, 0, 6)
16:14:18 DISPATCHER: trying to notify the job_runner thread.
16:14:18 HBMASTER: job (1, 0, 6) submitted to dispatcher
16:14:18 DISPATCHER: Trying to submit another job.
16:14:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:14:18 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464
16:14:18 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
16:14:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:14:18 WORKER: start processing job (1, 0, 6)
16:14:18 WORKER: args: ()
16:14:18 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0012306083618553393, 'num_filters_1': 74, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.08905809283353083, 'kernel_size_2': 3, 'num_filters_2': 25}, 'budget': 400.0, 'working_directory': '.'}
16:15:11 DISPATCHER: Starting worker discovery
16:15:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:15:11 DISPATCHER: Finished worker discovery
16:16:11 DISPATCHER: Starting worker discovery
16:16:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:16:11 DISPATCHER: Finished worker discovery
16:17:11 DISPATCHER: Starting worker discovery
16:17:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:17:11 DISPATCHER: Finished worker discovery
16:18:11 DISPATCHER: Starting worker discovery
16:18:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:18:11 DISPATCHER: Finished worker discovery
16:19:11 DISPATCHER: Starting worker discovery
16:19:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:19:11 DISPATCHER: Finished worker discovery
16:20:11 DISPATCHER: Starting worker discovery
16:20:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:20:11 DISPATCHER: Finished worker discovery
16:21:11 DISPATCHER: Starting worker discovery
16:21:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:21:11 DISPATCHER: Finished worker discovery
16:21:27 WORKER: done with job (1, 0, 6), trying to register it.
16:21:27 WORKER: registered result for job (1, 0, 6) with dispatcher
16:21:27 DISPATCHER: job (1, 0, 6) finished
16:21:27 DISPATCHER: register_result: lock acquired
16:21:27 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
16:21:27 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0012306083618553393, 'num_filters_1': 74, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.08905809283353083, 'kernel_size_2': 3, 'num_filters_2': 25}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.1295509539571777, 'info': {'data05': 0.1295509539571777, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0012306083618553393, 'num_filters_1': 74, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.08905809283353083, 'kernel_size_2': 3, 'num_filters_2': 25}"}}
exception: None

16:21:27 job_callback for (1, 0, 6) started
16:21:27 job_callback for (1, 0, 6) got condition
16:21:27 DISPATCHER: Trying to submit another job.
16:21:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:21:27 Only 5 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
16:21:27 HBMASTER: Trying to run another job!
16:21:27 job_callback for (1, 0, 6) finished
16:21:27 HBMASTER: schedule new run for iteration 1
16:21:27 HBMASTER: trying submitting job (1, 0, 8) to dispatcher
16:21:27 HBMASTER: submitting job (1, 0, 8) to dispatcher
16:21:27 DISPATCHER: trying to submit job (1, 0, 8)
16:21:27 DISPATCHER: trying to notify the job_runner thread.
16:21:27 HBMASTER: job (1, 0, 8) submitted to dispatcher
16:21:27 DISPATCHER: Trying to submit another job.
16:21:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:21:27 DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464
16:21:27 DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
16:21:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:21:27 WORKER: start processing job (1, 0, 8)
16:21:27 WORKER: args: ()
16:21:27 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.003506583165066148, 'num_filters_1': 18, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.05298718183550586, 'kernel_size_2': 7, 'num_filters_2': 43}, 'budget': 400.0, 'working_directory': '.'}
16:22:11 DISPATCHER: Starting worker discovery
16:22:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:22:11 DISPATCHER: Finished worker discovery
16:23:11 DISPATCHER: Starting worker discovery
16:23:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:23:12 DISPATCHER: Finished worker discovery
16:24:12 DISPATCHER: Starting worker discovery
16:24:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:24:12 DISPATCHER: Finished worker discovery
16:25:12 DISPATCHER: Starting worker discovery
16:25:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:25:12 DISPATCHER: Finished worker discovery
16:26:12 DISPATCHER: Starting worker discovery
16:26:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:26:12 DISPATCHER: Finished worker discovery
16:27:12 DISPATCHER: Starting worker discovery
16:27:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:27:12 DISPATCHER: Finished worker discovery
16:28:12 DISPATCHER: Starting worker discovery
16:28:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:28:12 DISPATCHER: Finished worker discovery
16:28:31 WORKER: done with job (1, 0, 8), trying to register it.
16:28:31 WORKER: registered result for job (1, 0, 8) with dispatcher
16:28:31 DISPATCHER: job (1, 0, 8) finished
16:28:31 DISPATCHER: register_result: lock acquired
16:28:31 DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
16:28:31 job_id: (1, 0, 8)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.003506583165066148, 'num_filters_1': 18, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.05298718183550586, 'kernel_size_2': 7, 'num_filters_2': 43}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.12483032518678602, 'info': {'data05': 0.12483032518678602, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.003506583165066148, 'num_filters_1': 18, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.05298718183550586, 'kernel_size_2': 7, 'num_filters_2': 43}"}}
exception: None

16:28:31 job_callback for (1, 0, 8) started
16:28:31 DISPATCHER: Trying to submit another job.
16:28:31 job_callback for (1, 0, 8) got condition
16:28:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:28:31 Only 6 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
16:28:31 HBMASTER: Trying to run another job!
16:28:31 job_callback for (1, 0, 8) finished
16:28:31 ITERATION: Advancing config (1, 0, 6) to next budget 1200.000000
16:28:31 HBMASTER: schedule new run for iteration 1
16:28:31 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
16:28:31 HBMASTER: submitting job (1, 0, 6) to dispatcher
16:28:31 DISPATCHER: trying to submit job (1, 0, 6)
16:28:31 DISPATCHER: trying to notify the job_runner thread.
16:28:31 HBMASTER: job (1, 0, 6) submitted to dispatcher
16:28:31 DISPATCHER: Trying to submit another job.
16:28:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:28:31 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464
16:28:31 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
16:28:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:28:31 WORKER: start processing job (1, 0, 6)
16:28:31 WORKER: args: ()
16:28:31 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0012306083618553393, 'num_filters_1': 74, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.08905809283353083, 'kernel_size_2': 3, 'num_filters_2': 25}, 'budget': 1200.0, 'working_directory': '.'}
16:29:12 DISPATCHER: Starting worker discovery
16:29:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:29:12 DISPATCHER: Finished worker discovery
16:30:12 DISPATCHER: Starting worker discovery
16:30:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:30:12 DISPATCHER: Finished worker discovery
16:31:12 DISPATCHER: Starting worker discovery
16:31:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:31:12 DISPATCHER: Finished worker discovery
16:32:12 DISPATCHER: Starting worker discovery
16:32:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:32:12 DISPATCHER: Finished worker discovery
16:33:12 DISPATCHER: Starting worker discovery
16:33:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:33:12 DISPATCHER: Finished worker discovery
16:34:12 DISPATCHER: Starting worker discovery
16:34:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:34:12 DISPATCHER: Finished worker discovery
16:35:12 DISPATCHER: Starting worker discovery
16:35:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:35:12 DISPATCHER: Finished worker discovery
16:36:12 DISPATCHER: Starting worker discovery
16:36:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:36:12 DISPATCHER: Finished worker discovery
16:37:12 DISPATCHER: Starting worker discovery
16:37:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:37:12 DISPATCHER: Finished worker discovery
16:38:12 DISPATCHER: Starting worker discovery
16:38:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:38:12 DISPATCHER: Finished worker discovery
16:39:12 DISPATCHER: Starting worker discovery
16:39:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:39:12 DISPATCHER: Finished worker discovery
16:40:12 DISPATCHER: Starting worker discovery
16:40:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:40:12 DISPATCHER: Finished worker discovery
16:41:12 DISPATCHER: Starting worker discovery
16:41:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:41:12 DISPATCHER: Finished worker discovery
16:42:12 DISPATCHER: Starting worker discovery
16:42:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:42:12 DISPATCHER: Finished worker discovery
16:43:12 DISPATCHER: Starting worker discovery
16:43:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:43:12 DISPATCHER: Finished worker discovery
16:44:12 DISPATCHER: Starting worker discovery
16:44:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:44:12 DISPATCHER: Finished worker discovery
16:45:12 DISPATCHER: Starting worker discovery
16:45:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:45:12 DISPATCHER: Finished worker discovery
16:46:12 DISPATCHER: Starting worker discovery
16:46:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:46:12 DISPATCHER: Finished worker discovery
16:47:12 DISPATCHER: Starting worker discovery
16:47:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:47:12 DISPATCHER: Finished worker discovery
16:48:12 DISPATCHER: Starting worker discovery
16:48:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:48:12 DISPATCHER: Finished worker discovery
16:49:12 DISPATCHER: Starting worker discovery
16:49:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:49:12 DISPATCHER: Finished worker discovery
16:49:44 WORKER: done with job (1, 0, 6), trying to register it.
16:49:44 WORKER: registered result for job (1, 0, 6) with dispatcher
16:49:44 DISPATCHER: job (1, 0, 6) finished
16:49:44 DISPATCHER: register_result: lock acquired
16:49:44 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
16:49:44 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0012306083618553393, 'num_filters_1': 74, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.08905809283353083, 'kernel_size_2': 3, 'num_filters_2': 25}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.12404467146259479, 'info': {'data05': 0.12404467146259479, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0012306083618553393, 'num_filters_1': 74, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.08905809283353083, 'kernel_size_2': 3, 'num_filters_2': 25}"}}
exception: None

16:49:44 job_callback for (1, 0, 6) started
16:49:44 job_callback for (1, 0, 6) got condition
16:49:44 DISPATCHER: Trying to submit another job.
16:49:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:49:44 Only 2 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
16:49:44 HBMASTER: Trying to run another job!
16:49:44 job_callback for (1, 0, 6) finished
16:49:44 start sampling a new configuration.
16:49:44 done sampling a new configuration.
16:49:44 HBMASTER: schedule new run for iteration 2
16:49:44 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
16:49:44 HBMASTER: submitting job (2, 0, 0) to dispatcher
16:49:44 DISPATCHER: trying to submit job (2, 0, 0)
16:49:44 DISPATCHER: trying to notify the job_runner thread.
16:49:44 HBMASTER: job (2, 0, 0) submitted to dispatcher
16:49:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:49:44 DISPATCHER: Trying to submit another job.
16:49:44 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
16:49:44 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
16:49:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:49:44 WORKER: start processing job (2, 0, 0)
16:49:44 WORKER: args: ()
16:49:44 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.003246746157941562, 'num_filters_1': 92, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.06946820178407544}, 'budget': 400.0, 'working_directory': '.'}
16:50:12 DISPATCHER: Starting worker discovery
16:50:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:50:12 DISPATCHER: Finished worker discovery
16:51:12 DISPATCHER: Starting worker discovery
16:51:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:51:12 DISPATCHER: Finished worker discovery
16:52:12 DISPATCHER: Starting worker discovery
16:52:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:52:12 DISPATCHER: Finished worker discovery
16:53:12 DISPATCHER: Starting worker discovery
16:53:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:53:12 DISPATCHER: Finished worker discovery
16:54:12 DISPATCHER: Starting worker discovery
16:54:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:54:12 DISPATCHER: Finished worker discovery
16:55:12 DISPATCHER: Starting worker discovery
16:55:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:55:12 DISPATCHER: Finished worker discovery
16:56:12 DISPATCHER: Starting worker discovery
16:56:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:56:12 DISPATCHER: Finished worker discovery
16:56:54 WORKER: done with job (2, 0, 0), trying to register it.
16:56:54 WORKER: registered result for job (2, 0, 0) with dispatcher
16:56:54 DISPATCHER: job (2, 0, 0) finished
16:56:54 DISPATCHER: register_result: lock acquired
16:56:54 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
16:56:54 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.003246746157941562, 'num_filters_1': 92, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.06946820178407544}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.17752348723379238, 'info': {'data05': 0.17752348723379238, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.003246746157941562, 'num_filters_1': 92, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.06946820178407544}"}}
exception: None

16:56:54 job_callback for (2, 0, 0) started
16:56:54 DISPATCHER: Trying to submit another job.
16:56:54 job_callback for (2, 0, 0) got condition
16:56:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:56:54 Only 7 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
16:56:54 HBMASTER: Trying to run another job!
16:56:54 job_callback for (2, 0, 0) finished
16:56:54 start sampling a new configuration.
16:56:54 done sampling a new configuration.
16:56:54 HBMASTER: schedule new run for iteration 2
16:56:54 HBMASTER: trying submitting job (2, 0, 1) to dispatcher
16:56:54 HBMASTER: submitting job (2, 0, 1) to dispatcher
16:56:54 DISPATCHER: trying to submit job (2, 0, 1)
16:56:54 DISPATCHER: trying to notify the job_runner thread.
16:56:54 HBMASTER: job (2, 0, 1) submitted to dispatcher
16:56:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:56:54 DISPATCHER: Trying to submit another job.
16:56:54 DISPATCHER: starting job (2, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
16:56:54 DISPATCHER: job (2, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
16:56:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:56:54 WORKER: start processing job (2, 0, 1)
16:56:54 WORKER: args: ()
16:56:54 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.01908959417691153, 'num_filters_1': 21, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.09533265793928447, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 66, 'num_filters_3': 17, 'num_filters_4': 67, 'num_filters_5': 17}, 'budget': 400.0, 'working_directory': '.'}
16:57:12 DISPATCHER: Starting worker discovery
16:57:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:57:12 DISPATCHER: Finished worker discovery
16:58:12 DISPATCHER: Starting worker discovery
16:58:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:58:12 DISPATCHER: Finished worker discovery
16:59:12 DISPATCHER: Starting worker discovery
16:59:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:59:12 DISPATCHER: Finished worker discovery
17:00:12 DISPATCHER: Starting worker discovery
17:00:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:00:12 DISPATCHER: Finished worker discovery
17:01:12 DISPATCHER: Starting worker discovery
17:01:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:01:12 DISPATCHER: Finished worker discovery
17:02:12 DISPATCHER: Starting worker discovery
17:02:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:02:12 DISPATCHER: Finished worker discovery
17:03:12 DISPATCHER: Starting worker discovery
17:03:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:03:12 DISPATCHER: Finished worker discovery
17:03:52 WORKER: done with job (2, 0, 1), trying to register it.
17:03:52 WORKER: registered result for job (2, 0, 1) with dispatcher
17:03:52 DISPATCHER: job (2, 0, 1) finished
17:03:52 DISPATCHER: register_result: lock acquired
17:03:52 DISPATCHER: job (2, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
17:03:52 job_id: (2, 0, 1)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.01908959417691153, 'num_filters_1': 21, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.09533265793928447, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 66, 'num_filters_3': 17, 'num_filters_4': 67, 'num_filters_5': 17}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.01908959417691153, 'num_filters_1': 21, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.09533265793928447, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 66, 'num_filters_3': 17, 'num_filters_4': 67, 'num_filters_5': 17}"}}
exception: None

17:03:52 job_callback for (2, 0, 1) started
17:03:52 DISPATCHER: Trying to submit another job.
17:03:52 job_callback for (2, 0, 1) got condition
17:03:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:03:52 Only 8 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
17:03:52 HBMASTER: Trying to run another job!
17:03:52 job_callback for (2, 0, 1) finished
17:03:52 start sampling a new configuration.
17:03:52 done sampling a new configuration.
17:03:52 HBMASTER: schedule new run for iteration 2
17:03:52 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
17:03:52 HBMASTER: submitting job (2, 0, 2) to dispatcher
17:03:52 DISPATCHER: trying to submit job (2, 0, 2)
17:03:52 DISPATCHER: trying to notify the job_runner thread.
17:03:52 HBMASTER: job (2, 0, 2) submitted to dispatcher
17:03:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:03:52 DISPATCHER: Trying to submit another job.
17:03:52 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:03:52 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:03:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:03:52 WORKER: start processing job (2, 0, 2)
17:03:52 WORKER: args: ()
17:03:52 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0012685929056154134, 'num_filters_1': 23, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.011335762723385306, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 29, 'num_filters_3': 90}, 'budget': 400.0, 'working_directory': '.'}
17:04:12 DISPATCHER: Starting worker discovery
17:04:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:04:12 DISPATCHER: Finished worker discovery
17:05:12 DISPATCHER: Starting worker discovery
17:05:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:05:12 DISPATCHER: Finished worker discovery
17:06:12 DISPATCHER: Starting worker discovery
17:06:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:06:12 DISPATCHER: Finished worker discovery
17:07:12 DISPATCHER: Starting worker discovery
17:07:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:07:12 DISPATCHER: Finished worker discovery
17:08:12 DISPATCHER: Starting worker discovery
17:08:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:08:12 DISPATCHER: Finished worker discovery
17:09:12 DISPATCHER: Starting worker discovery
17:09:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:09:12 DISPATCHER: Finished worker discovery
17:10:12 DISPATCHER: Starting worker discovery
17:10:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:10:12 DISPATCHER: Finished worker discovery
17:11:12 DISPATCHER: Starting worker discovery
17:11:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:11:12 DISPATCHER: Finished worker discovery
17:11:28 WORKER: done with job (2, 0, 2), trying to register it.
17:11:28 WORKER: registered result for job (2, 0, 2) with dispatcher
17:11:28 DISPATCHER: job (2, 0, 2) finished
17:11:28 DISPATCHER: register_result: lock acquired
17:11:28 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
17:11:28 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0012685929056154134, 'num_filters_1': 23, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.011335762723385306, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 29, 'num_filters_3': 90}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.50602292073287, 'info': {'data05': 0.50602292073287, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0012685929056154134, 'num_filters_1': 23, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.011335762723385306, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 29, 'num_filters_3': 90}"}}
exception: None

17:11:28 job_callback for (2, 0, 2) started
17:11:28 job_callback for (2, 0, 2) got condition
17:11:28 DISPATCHER: Trying to submit another job.
17:11:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:11:28 Only 9 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
17:11:28 HBMASTER: Trying to run another job!
17:11:28 job_callback for (2, 0, 2) finished
17:11:28 start sampling a new configuration.
17:11:28 done sampling a new configuration.
17:11:28 HBMASTER: schedule new run for iteration 2
17:11:28 HBMASTER: trying submitting job (2, 0, 3) to dispatcher
17:11:28 HBMASTER: submitting job (2, 0, 3) to dispatcher
17:11:28 DISPATCHER: trying to submit job (2, 0, 3)
17:11:28 DISPATCHER: trying to notify the job_runner thread.
17:11:28 HBMASTER: job (2, 0, 3) submitted to dispatcher
17:11:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:11:28 DISPATCHER: Trying to submit another job.
17:11:28 DISPATCHER: starting job (2, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:11:28 DISPATCHER: job (2, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:11:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:11:28 WORKER: start processing job (2, 0, 3)
17:11:28 WORKER: args: ()
17:11:28 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.012591086920043704, 'num_filters_1': 124, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.032245157242973735, 'kernel_size_2': 3, 'num_filters_2': 24}, 'budget': 400.0, 'working_directory': '.'}
17:12:12 DISPATCHER: Starting worker discovery
17:12:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:12:12 DISPATCHER: Finished worker discovery
17:13:12 DISPATCHER: Starting worker discovery
17:13:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:13:12 DISPATCHER: Finished worker discovery
17:14:12 DISPATCHER: Starting worker discovery
17:14:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:14:12 DISPATCHER: Finished worker discovery
17:15:12 DISPATCHER: Starting worker discovery
17:15:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:15:12 DISPATCHER: Finished worker discovery
17:16:12 DISPATCHER: Starting worker discovery
17:16:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:16:12 DISPATCHER: Finished worker discovery
17:17:12 DISPATCHER: Starting worker discovery
17:17:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:17:12 DISPATCHER: Finished worker discovery
17:18:12 DISPATCHER: Starting worker discovery
17:18:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:18:12 DISPATCHER: Finished worker discovery
17:18:54 WORKER: done with job (2, 0, 3), trying to register it.
17:18:54 WORKER: registered result for job (2, 0, 3) with dispatcher
17:18:54 DISPATCHER: job (2, 0, 3) finished
17:18:54 DISPATCHER: register_result: lock acquired
17:18:54 DISPATCHER: job (2, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
17:18:54 job_id: (2, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.012591086920043704, 'num_filters_1': 124, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.032245157242973735, 'kernel_size_2': 3, 'num_filters_2': 24}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': 3.098919843980249e-05, 'info': {'data05': -3.098919843980249e-05, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.012591086920043704, 'num_filters_1': 124, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.032245157242973735, 'kernel_size_2': 3, 'num_filters_2': 24}"}}
exception: None

17:18:54 job_callback for (2, 0, 3) started
17:18:54 job_callback for (2, 0, 3) got condition
17:18:54 DISPATCHER: Trying to submit another job.
17:18:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:18:54 Only 10 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
17:18:54 HBMASTER: Trying to run another job!
17:18:54 job_callback for (2, 0, 3) finished
17:18:54 start sampling a new configuration.
17:18:54 done sampling a new configuration.
17:18:54 HBMASTER: schedule new run for iteration 2
17:18:54 HBMASTER: trying submitting job (2, 0, 4) to dispatcher
17:18:54 HBMASTER: submitting job (2, 0, 4) to dispatcher
17:18:54 DISPATCHER: trying to submit job (2, 0, 4)
17:18:54 DISPATCHER: trying to notify the job_runner thread.
17:18:54 HBMASTER: job (2, 0, 4) submitted to dispatcher
17:18:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:18:54 DISPATCHER: Trying to submit another job.
17:18:54 DISPATCHER: starting job (2, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:18:54 DISPATCHER: job (2, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:18:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:18:54 WORKER: start processing job (2, 0, 4)
17:18:54 WORKER: args: ()
17:18:54 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002337820158539495, 'num_filters_1': 16, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.11708727160420247}, 'budget': 400.0, 'working_directory': '.'}
17:19:12 DISPATCHER: Starting worker discovery
17:19:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:19:12 DISPATCHER: Finished worker discovery
17:20:12 DISPATCHER: Starting worker discovery
17:20:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:20:12 DISPATCHER: Finished worker discovery
17:21:12 DISPATCHER: Starting worker discovery
17:21:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:21:12 DISPATCHER: Finished worker discovery
17:22:12 DISPATCHER: Starting worker discovery
17:22:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:22:12 DISPATCHER: Finished worker discovery
17:23:12 DISPATCHER: Starting worker discovery
17:23:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:23:12 DISPATCHER: Finished worker discovery
17:24:12 DISPATCHER: Starting worker discovery
17:24:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:24:12 DISPATCHER: Finished worker discovery
17:25:12 DISPATCHER: Starting worker discovery
17:25:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:25:12 DISPATCHER: Finished worker discovery
17:26:04 WORKER: done with job (2, 0, 4), trying to register it.
17:26:04 WORKER: registered result for job (2, 0, 4) with dispatcher
17:26:04 DISPATCHER: job (2, 0, 4) finished
17:26:04 DISPATCHER: register_result: lock acquired
17:26:04 DISPATCHER: job (2, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
17:26:04 job_id: (2, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002337820158539495, 'num_filters_1': 16, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.11708727160420247}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.15231789583479377, 'info': {'data05': 0.15231789583479377, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002337820158539495, 'num_filters_1': 16, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.11708727160420247}"}}
exception: None

17:26:04 job_callback for (2, 0, 4) started
17:26:04 DISPATCHER: Trying to submit another job.
17:26:04 job_callback for (2, 0, 4) got condition
17:26:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:26:04 Only 11 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
17:26:04 HBMASTER: Trying to run another job!
17:26:04 job_callback for (2, 0, 4) finished
17:26:04 start sampling a new configuration.
17:26:04 done sampling a new configuration.
17:26:04 HBMASTER: schedule new run for iteration 2
17:26:04 HBMASTER: trying submitting job (2, 0, 5) to dispatcher
17:26:04 HBMASTER: submitting job (2, 0, 5) to dispatcher
17:26:04 DISPATCHER: trying to submit job (2, 0, 5)
17:26:04 DISPATCHER: trying to notify the job_runner thread.
17:26:04 HBMASTER: job (2, 0, 5) submitted to dispatcher
17:26:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:26:04 DISPATCHER: Trying to submit another job.
17:26:04 DISPATCHER: starting job (2, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:26:04 DISPATCHER: job (2, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:26:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:26:04 WORKER: start processing job (2, 0, 5)
17:26:04 WORKER: args: ()
17:26:04 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0447046691281877, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.015095443958663437}, 'budget': 400.0, 'working_directory': '.'}
17:26:12 DISPATCHER: Starting worker discovery
17:26:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:26:12 DISPATCHER: Finished worker discovery
17:27:12 DISPATCHER: Starting worker discovery
17:27:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:27:12 DISPATCHER: Finished worker discovery
17:28:12 DISPATCHER: Starting worker discovery
17:28:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:28:12 DISPATCHER: Finished worker discovery
17:29:12 DISPATCHER: Starting worker discovery
17:29:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:29:12 DISPATCHER: Finished worker discovery
17:30:12 DISPATCHER: Starting worker discovery
17:30:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:30:12 DISPATCHER: Finished worker discovery
17:31:12 DISPATCHER: Starting worker discovery
17:31:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:31:12 DISPATCHER: Finished worker discovery
17:32:12 DISPATCHER: Starting worker discovery
17:32:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:32:12 DISPATCHER: Finished worker discovery
17:33:12 DISPATCHER: Starting worker discovery
17:33:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:33:12 DISPATCHER: Finished worker discovery
17:33:27 WORKER: done with job (2, 0, 5), trying to register it.
17:33:27 WORKER: registered result for job (2, 0, 5) with dispatcher
17:33:27 DISPATCHER: job (2, 0, 5) finished
17:33:27 DISPATCHER: register_result: lock acquired
17:33:27 DISPATCHER: job (2, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
17:33:27 job_id: (2, 0, 5)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0447046691281877, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.015095443958663437}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.005010578711099943, 'info': {'data05': 0.005010578711099943, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0447046691281877, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.015095443958663437}"}}
exception: None

17:33:27 job_callback for (2, 0, 5) started
17:33:27 DISPATCHER: Trying to submit another job.
17:33:27 job_callback for (2, 0, 5) got condition
17:33:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:33:27 Only 12 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
17:33:27 HBMASTER: Trying to run another job!
17:33:27 job_callback for (2, 0, 5) finished
17:33:27 ITERATION: Advancing config (2, 0, 0) to next budget 1200.000000
17:33:27 ITERATION: Advancing config (2, 0, 2) to next budget 1200.000000
17:33:27 HBMASTER: schedule new run for iteration 2
17:33:27 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
17:33:27 HBMASTER: submitting job (2, 0, 0) to dispatcher
17:33:27 DISPATCHER: trying to submit job (2, 0, 0)
17:33:27 DISPATCHER: trying to notify the job_runner thread.
17:33:27 HBMASTER: job (2, 0, 0) submitted to dispatcher
17:33:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:33:27 DISPATCHER: Trying to submit another job.
17:33:27 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:33:27 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:33:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:33:27 WORKER: start processing job (2, 0, 0)
17:33:27 WORKER: args: ()
17:33:27 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.003246746157941562, 'num_filters_1': 92, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.06946820178407544}, 'budget': 1200.0, 'working_directory': '.'}
17:34:12 DISPATCHER: Starting worker discovery
17:34:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:34:12 DISPATCHER: Finished worker discovery
17:35:12 DISPATCHER: Starting worker discovery
17:35:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:35:12 DISPATCHER: Finished worker discovery
17:36:12 DISPATCHER: Starting worker discovery
17:36:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:36:12 DISPATCHER: Finished worker discovery
17:37:12 DISPATCHER: Starting worker discovery
17:37:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:37:12 DISPATCHER: Finished worker discovery
17:38:12 DISPATCHER: Starting worker discovery
17:38:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:38:12 DISPATCHER: Finished worker discovery
17:39:12 DISPATCHER: Starting worker discovery
17:39:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:39:12 DISPATCHER: Finished worker discovery
17:40:12 DISPATCHER: Starting worker discovery
17:40:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:40:12 DISPATCHER: Finished worker discovery
17:41:12 DISPATCHER: Starting worker discovery
17:41:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:41:12 DISPATCHER: Finished worker discovery
17:42:12 DISPATCHER: Starting worker discovery
17:42:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:42:12 DISPATCHER: Finished worker discovery
17:43:12 DISPATCHER: Starting worker discovery
17:43:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:43:12 DISPATCHER: Finished worker discovery
17:44:12 DISPATCHER: Starting worker discovery
17:44:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:44:12 DISPATCHER: Finished worker discovery
17:45:12 DISPATCHER: Starting worker discovery
17:45:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:45:12 DISPATCHER: Finished worker discovery
17:46:12 DISPATCHER: Starting worker discovery
17:46:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:46:12 DISPATCHER: Finished worker discovery
17:47:12 DISPATCHER: Starting worker discovery
17:47:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:47:12 DISPATCHER: Finished worker discovery
17:48:12 DISPATCHER: Starting worker discovery
17:48:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:48:12 DISPATCHER: Finished worker discovery
17:49:12 DISPATCHER: Starting worker discovery
17:49:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:49:12 DISPATCHER: Finished worker discovery
17:50:12 DISPATCHER: Starting worker discovery
17:50:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:50:12 DISPATCHER: Finished worker discovery
17:51:12 DISPATCHER: Starting worker discovery
17:51:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:51:12 DISPATCHER: Finished worker discovery
17:52:12 DISPATCHER: Starting worker discovery
17:52:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:52:12 DISPATCHER: Finished worker discovery
17:53:12 DISPATCHER: Starting worker discovery
17:53:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:53:12 DISPATCHER: Finished worker discovery
17:54:12 DISPATCHER: Starting worker discovery
17:54:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:54:12 DISPATCHER: Finished worker discovery
17:54:38 WORKER: done with job (2, 0, 0), trying to register it.
17:54:38 WORKER: registered result for job (2, 0, 0) with dispatcher
17:54:38 DISPATCHER: job (2, 0, 0) finished
17:54:38 DISPATCHER: register_result: lock acquired
17:54:38 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
17:54:38 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.003246746157941562, 'num_filters_1': 92, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.06946820178407544}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.13688036513441076, 'info': {'data05': 0.13688036513441076, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.003246746157941562, 'num_filters_1': 92, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.06946820178407544}"}}
exception: None

17:54:38 job_callback for (2, 0, 0) started
17:54:38 DISPATCHER: Trying to submit another job.
17:54:38 job_callback for (2, 0, 0) got condition
17:54:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:54:38 Only 3 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
17:54:38 HBMASTER: Trying to run another job!
17:54:38 job_callback for (2, 0, 0) finished
17:54:38 HBMASTER: schedule new run for iteration 2
17:54:38 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
17:54:38 HBMASTER: submitting job (2, 0, 2) to dispatcher
17:54:38 DISPATCHER: trying to submit job (2, 0, 2)
17:54:38 DISPATCHER: trying to notify the job_runner thread.
17:54:38 HBMASTER: job (2, 0, 2) submitted to dispatcher
17:54:38 DISPATCHER: Trying to submit another job.
17:54:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:54:38 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:54:38 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
17:54:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:54:38 WORKER: start processing job (2, 0, 2)
17:54:38 WORKER: args: ()
17:54:38 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0012685929056154134, 'num_filters_1': 23, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.011335762723385306, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 29, 'num_filters_3': 90}, 'budget': 1200.0, 'working_directory': '.'}
17:55:12 DISPATCHER: Starting worker discovery
17:55:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:55:12 DISPATCHER: Finished worker discovery
17:56:12 DISPATCHER: Starting worker discovery
17:56:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:56:12 DISPATCHER: Finished worker discovery
17:57:12 DISPATCHER: Starting worker discovery
17:57:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:57:12 DISPATCHER: Finished worker discovery
17:58:12 DISPATCHER: Starting worker discovery
17:58:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:58:12 DISPATCHER: Finished worker discovery
17:59:12 DISPATCHER: Starting worker discovery
17:59:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:59:12 DISPATCHER: Finished worker discovery
18:00:12 DISPATCHER: Starting worker discovery
18:00:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:00:12 DISPATCHER: Finished worker discovery
18:01:12 DISPATCHER: Starting worker discovery
18:01:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:01:12 DISPATCHER: Finished worker discovery
18:02:12 DISPATCHER: Starting worker discovery
18:02:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:02:13 DISPATCHER: Finished worker discovery
18:03:13 DISPATCHER: Starting worker discovery
18:03:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:03:13 DISPATCHER: Finished worker discovery
18:04:13 DISPATCHER: Starting worker discovery
18:04:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:04:13 DISPATCHER: Finished worker discovery
18:05:13 DISPATCHER: Starting worker discovery
18:05:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:05:13 DISPATCHER: Finished worker discovery
18:06:13 DISPATCHER: Starting worker discovery
18:06:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:06:13 DISPATCHER: Finished worker discovery
18:07:13 DISPATCHER: Starting worker discovery
18:07:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:07:13 DISPATCHER: Finished worker discovery
18:08:13 DISPATCHER: Starting worker discovery
18:08:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:08:13 DISPATCHER: Finished worker discovery
18:09:13 DISPATCHER: Starting worker discovery
18:09:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:09:13 DISPATCHER: Finished worker discovery
18:10:13 DISPATCHER: Starting worker discovery
18:10:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:10:13 DISPATCHER: Finished worker discovery
18:11:13 DISPATCHER: Starting worker discovery
18:11:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:11:13 DISPATCHER: Finished worker discovery
18:12:13 DISPATCHER: Starting worker discovery
18:12:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:12:13 DISPATCHER: Finished worker discovery
18:13:13 DISPATCHER: Starting worker discovery
18:13:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:13:13 DISPATCHER: Finished worker discovery
18:14:13 DISPATCHER: Starting worker discovery
18:14:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:14:13 DISPATCHER: Finished worker discovery
18:15:13 DISPATCHER: Starting worker discovery
18:15:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:15:13 DISPATCHER: Finished worker discovery
18:16:13 DISPATCHER: Starting worker discovery
18:16:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:16:13 DISPATCHER: Finished worker discovery
18:16:48 WORKER: done with job (2, 0, 2), trying to register it.
18:16:48 WORKER: registered result for job (2, 0, 2) with dispatcher
18:16:48 DISPATCHER: job (2, 0, 2) finished
18:16:48 DISPATCHER: register_result: lock acquired
18:16:48 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
18:16:48 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0012685929056154134, 'num_filters_1': 23, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.011335762723385306, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 29, 'num_filters_3': 90}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.396044449311048, 'info': {'data05': 0.396044449311048, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0012685929056154134, 'num_filters_1': 23, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.011335762723385306, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 29, 'num_filters_3': 90}"}}
exception: None

18:16:48 job_callback for (2, 0, 2) started
18:16:48 job_callback for (2, 0, 2) got condition
18:16:48 DISPATCHER: Trying to submit another job.
18:16:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:16:48 Only 4 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
18:16:48 HBMASTER: Trying to run another job!
18:16:48 job_callback for (2, 0, 2) finished
18:16:48 start sampling a new configuration.
18:16:48 done sampling a new configuration.
18:16:48 HBMASTER: schedule new run for iteration 3
18:16:48 HBMASTER: trying submitting job (3, 0, 0) to dispatcher
18:16:48 HBMASTER: submitting job (3, 0, 0) to dispatcher
18:16:48 DISPATCHER: trying to submit job (3, 0, 0)
18:16:48 DISPATCHER: trying to notify the job_runner thread.
18:16:48 HBMASTER: job (3, 0, 0) submitted to dispatcher
18:16:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:16:48 DISPATCHER: Trying to submit another job.
18:16:48 DISPATCHER: starting job (3, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
18:16:48 DISPATCHER: job (3, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
18:16:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:16:48 WORKER: start processing job (3, 0, 0)
18:16:48 WORKER: args: ()
18:16:48 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0019226503079264445, 'num_filters_1': 83, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.14900708868904164, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 43, 'num_filters_3': 44}, 'budget': 1200.0, 'working_directory': '.'}
18:17:13 DISPATCHER: Starting worker discovery
18:17:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:17:13 DISPATCHER: Finished worker discovery
18:18:13 DISPATCHER: Starting worker discovery
18:18:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:18:13 DISPATCHER: Finished worker discovery
18:19:13 DISPATCHER: Starting worker discovery
18:19:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:19:13 DISPATCHER: Finished worker discovery
18:20:13 DISPATCHER: Starting worker discovery
18:20:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:20:13 DISPATCHER: Finished worker discovery
18:21:13 DISPATCHER: Starting worker discovery
18:21:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:21:13 DISPATCHER: Finished worker discovery
18:22:13 DISPATCHER: Starting worker discovery
18:22:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:22:13 DISPATCHER: Finished worker discovery
18:23:13 DISPATCHER: Starting worker discovery
18:23:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:23:13 DISPATCHER: Finished worker discovery
18:24:13 DISPATCHER: Starting worker discovery
18:24:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:24:13 DISPATCHER: Finished worker discovery
18:25:13 DISPATCHER: Starting worker discovery
18:25:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:25:13 DISPATCHER: Finished worker discovery
18:26:13 DISPATCHER: Starting worker discovery
18:26:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:26:13 DISPATCHER: Finished worker discovery
18:27:13 DISPATCHER: Starting worker discovery
18:27:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:27:13 DISPATCHER: Finished worker discovery
18:28:13 DISPATCHER: Starting worker discovery
18:28:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:28:13 DISPATCHER: Finished worker discovery
18:29:13 DISPATCHER: Starting worker discovery
18:29:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:29:13 DISPATCHER: Finished worker discovery
18:30:13 DISPATCHER: Starting worker discovery
18:30:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:30:13 DISPATCHER: Finished worker discovery
18:31:13 DISPATCHER: Starting worker discovery
18:31:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:31:13 DISPATCHER: Finished worker discovery
18:32:13 DISPATCHER: Starting worker discovery
18:32:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:32:13 DISPATCHER: Finished worker discovery
18:33:13 DISPATCHER: Starting worker discovery
18:33:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:33:13 DISPATCHER: Finished worker discovery
18:34:13 DISPATCHER: Starting worker discovery
18:34:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:34:13 DISPATCHER: Finished worker discovery
18:35:13 DISPATCHER: Starting worker discovery
18:35:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:35:13 DISPATCHER: Finished worker discovery
18:36:13 DISPATCHER: Starting worker discovery
18:36:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:36:13 DISPATCHER: Finished worker discovery
18:37:13 DISPATCHER: Starting worker discovery
18:37:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:37:13 DISPATCHER: Finished worker discovery
18:38:13 DISPATCHER: Starting worker discovery
18:38:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:38:13 DISPATCHER: Finished worker discovery
18:38:15 WORKER: done with job (3, 0, 0), trying to register it.
18:38:15 WORKER: registered result for job (3, 0, 0) with dispatcher
18:38:15 DISPATCHER: job (3, 0, 0) finished
18:38:15 DISPATCHER: register_result: lock acquired
18:38:15 DISPATCHER: job (3, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
18:38:15 job_id: (3, 0, 0)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0019226503079264445, 'num_filters_1': 83, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.14900708868904164, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 43, 'num_filters_3': 44}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.09853655821523499, 'info': {'data05': 0.09853655821523499, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0019226503079264445, 'num_filters_1': 83, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.14900708868904164, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 43, 'num_filters_3': 44}"}}
exception: None

18:38:15 job_callback for (3, 0, 0) started
18:38:15 job_callback for (3, 0, 0) got condition
18:38:15 DISPATCHER: Trying to submit another job.
18:38:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:38:15 Only 5 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
18:38:15 HBMASTER: Trying to run another job!
18:38:15 job_callback for (3, 0, 0) finished
18:38:15 start sampling a new configuration.
18:38:15 done sampling a new configuration.
18:38:15 HBMASTER: schedule new run for iteration 3
18:38:15 HBMASTER: trying submitting job (3, 0, 1) to dispatcher
18:38:15 HBMASTER: submitting job (3, 0, 1) to dispatcher
18:38:15 DISPATCHER: trying to submit job (3, 0, 1)
18:38:15 DISPATCHER: trying to notify the job_runner thread.
18:38:15 HBMASTER: job (3, 0, 1) submitted to dispatcher
18:38:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:38:15 DISPATCHER: Trying to submit another job.
18:38:15 DISPATCHER: starting job (3, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
18:38:15 DISPATCHER: job (3, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
18:38:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:38:15 WORKER: start processing job (3, 0, 1)
18:38:15 WORKER: args: ()
18:38:15 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004637678109907519, 'num_filters_1': 94, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.07335803141028707, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 49, 'num_filters_3': 75, 'num_filters_4': 77, 'num_filters_5': 50}, 'budget': 1200.0, 'working_directory': '.'}
18:39:13 DISPATCHER: Starting worker discovery
18:39:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:39:13 DISPATCHER: Finished worker discovery
18:40:13 DISPATCHER: Starting worker discovery
18:40:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:40:13 DISPATCHER: Finished worker discovery
18:41:13 DISPATCHER: Starting worker discovery
18:41:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:41:13 DISPATCHER: Finished worker discovery
18:42:13 DISPATCHER: Starting worker discovery
18:42:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:42:13 DISPATCHER: Finished worker discovery
18:43:13 DISPATCHER: Starting worker discovery
18:43:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:43:13 DISPATCHER: Finished worker discovery
18:44:13 DISPATCHER: Starting worker discovery
18:44:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:44:13 DISPATCHER: Finished worker discovery
18:45:13 DISPATCHER: Starting worker discovery
18:45:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:45:13 DISPATCHER: Finished worker discovery
18:46:13 DISPATCHER: Starting worker discovery
18:46:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:46:13 DISPATCHER: Finished worker discovery
18:47:13 DISPATCHER: Starting worker discovery
18:47:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:47:13 DISPATCHER: Finished worker discovery
18:48:13 DISPATCHER: Starting worker discovery
18:48:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:48:13 DISPATCHER: Finished worker discovery
18:49:13 DISPATCHER: Starting worker discovery
18:49:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:49:13 DISPATCHER: Finished worker discovery
18:50:13 DISPATCHER: Starting worker discovery
18:50:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:50:13 DISPATCHER: Finished worker discovery
18:51:13 DISPATCHER: Starting worker discovery
18:51:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:51:13 DISPATCHER: Finished worker discovery
18:52:13 DISPATCHER: Starting worker discovery
18:52:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:52:13 DISPATCHER: Finished worker discovery
18:53:13 DISPATCHER: Starting worker discovery
18:53:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:53:13 DISPATCHER: Finished worker discovery
18:54:13 DISPATCHER: Starting worker discovery
18:54:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:54:13 DISPATCHER: Finished worker discovery
18:55:13 DISPATCHER: Starting worker discovery
18:55:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:55:13 DISPATCHER: Finished worker discovery
18:56:13 DISPATCHER: Starting worker discovery
18:56:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:56:13 DISPATCHER: Finished worker discovery
18:57:13 DISPATCHER: Starting worker discovery
18:57:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:57:13 DISPATCHER: Finished worker discovery
18:58:13 DISPATCHER: Starting worker discovery
18:58:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:58:13 DISPATCHER: Finished worker discovery
18:59:13 DISPATCHER: Starting worker discovery
18:59:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:59:13 DISPATCHER: Finished worker discovery
18:59:22 WORKER: done with job (3, 0, 1), trying to register it.
18:59:22 WORKER: registered result for job (3, 0, 1) with dispatcher
18:59:22 DISPATCHER: job (3, 0, 1) finished
18:59:22 DISPATCHER: register_result: lock acquired
18:59:22 DISPATCHER: job (3, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
18:59:22 job_id: (3, 0, 1)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004637678109907519, 'num_filters_1': 94, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.07335803141028707, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 49, 'num_filters_3': 75, 'num_filters_4': 77, 'num_filters_5': 50}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -2.0599747230004452e-05, 'info': {'data05': 2.0599747230004452e-05, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004637678109907519, 'num_filters_1': 94, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.07335803141028707, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 49, 'num_filters_3': 75, 'num_filters_4': 77, 'num_filters_5': 50}"}}
exception: None

18:59:22 job_callback for (3, 0, 1) started
18:59:22 DISPATCHER: Trying to submit another job.
18:59:22 job_callback for (3, 0, 1) got condition
18:59:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:59:22 Only 6 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
18:59:22 HBMASTER: Trying to run another job!
18:59:22 job_callback for (3, 0, 1) finished
18:59:22 start sampling a new configuration.
18:59:22 done sampling a new configuration.
18:59:22 HBMASTER: schedule new run for iteration 3
18:59:22 HBMASTER: trying submitting job (3, 0, 2) to dispatcher
18:59:22 HBMASTER: submitting job (3, 0, 2) to dispatcher
18:59:22 DISPATCHER: trying to submit job (3, 0, 2)
18:59:22 DISPATCHER: trying to notify the job_runner thread.
18:59:22 HBMASTER: job (3, 0, 2) submitted to dispatcher
18:59:22 DISPATCHER: Trying to submit another job.
18:59:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:59:22 DISPATCHER: starting job (3, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
18:59:22 DISPATCHER: job (3, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
18:59:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:59:22 WORKER: start processing job (3, 0, 2)
18:59:22 WORKER: args: ()
18:59:22 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.09335374036619475, 'num_filters_1': 30, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.04488849181213438, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 32, 'num_filters_3': 28}, 'budget': 1200.0, 'working_directory': '.'}
19:00:13 DISPATCHER: Starting worker discovery
19:00:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:00:13 DISPATCHER: Finished worker discovery
19:01:13 DISPATCHER: Starting worker discovery
19:01:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:01:13 DISPATCHER: Finished worker discovery
19:02:13 DISPATCHER: Starting worker discovery
19:02:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:02:13 DISPATCHER: Finished worker discovery
19:03:13 DISPATCHER: Starting worker discovery
19:03:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:03:13 DISPATCHER: Finished worker discovery
19:04:13 DISPATCHER: Starting worker discovery
19:04:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:04:13 DISPATCHER: Finished worker discovery
19:05:13 DISPATCHER: Starting worker discovery
19:05:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:05:14 DISPATCHER: Finished worker discovery
19:06:14 DISPATCHER: Starting worker discovery
19:06:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:06:14 DISPATCHER: Finished worker discovery
19:07:14 DISPATCHER: Starting worker discovery
19:07:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:07:14 DISPATCHER: Finished worker discovery
19:08:14 DISPATCHER: Starting worker discovery
19:08:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:08:14 DISPATCHER: Finished worker discovery
19:09:14 DISPATCHER: Starting worker discovery
19:09:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:09:14 DISPATCHER: Finished worker discovery
19:10:14 DISPATCHER: Starting worker discovery
19:10:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:10:14 DISPATCHER: Finished worker discovery
19:11:14 DISPATCHER: Starting worker discovery
19:11:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:11:14 DISPATCHER: Finished worker discovery
19:12:14 DISPATCHER: Starting worker discovery
19:12:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:12:14 DISPATCHER: Finished worker discovery
19:13:14 DISPATCHER: Starting worker discovery
19:13:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:13:14 DISPATCHER: Finished worker discovery
19:14:14 DISPATCHER: Starting worker discovery
19:14:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:14:14 DISPATCHER: Finished worker discovery
19:15:14 DISPATCHER: Starting worker discovery
19:15:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:15:14 DISPATCHER: Finished worker discovery
19:16:14 DISPATCHER: Starting worker discovery
19:16:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:16:14 DISPATCHER: Finished worker discovery
19:17:14 DISPATCHER: Starting worker discovery
19:17:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:17:14 DISPATCHER: Finished worker discovery
19:18:14 DISPATCHER: Starting worker discovery
19:18:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:18:14 DISPATCHER: Finished worker discovery
19:19:14 DISPATCHER: Starting worker discovery
19:19:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:19:14 DISPATCHER: Finished worker discovery
19:20:14 WORKER: done with job (3, 0, 2), trying to register it.
19:20:14 WORKER: registered result for job (3, 0, 2) with dispatcher
19:20:14 DISPATCHER: job (3, 0, 2) finished
19:20:14 DISPATCHER: register_result: lock acquired
19:20:14 DISPATCHER: job (3, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
19:20:14 job_id: (3, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.09335374036619475, 'num_filters_1': 30, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.04488849181213438, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 32, 'num_filters_3': 28}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -6.221777100875434e-05, 'info': {'data05': 6.221777100875434e-05, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.09335374036619475, 'num_filters_1': 30, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.04488849181213438, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 32, 'num_filters_3': 28}"}}
exception: None

19:20:14 job_callback for (3, 0, 2) started
19:20:14 job_callback for (3, 0, 2) got condition
19:20:14 DISPATCHER: Trying to submit another job.
19:20:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:20:14 Only 7 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
19:20:14 HBMASTER: Trying to run another job!
19:20:14 job_callback for (3, 0, 2) finished
19:20:14 start sampling a new configuration.
19:20:14 done sampling a new configuration.
19:20:14 DISPATCHER: Starting worker discovery
19:20:14 HBMASTER: schedule new run for iteration 3
19:20:14 HBMASTER: trying submitting job (3, 0, 3) to dispatcher
19:20:14 HBMASTER: submitting job (3, 0, 3) to dispatcher
19:20:14 DISPATCHER: trying to submit job (3, 0, 3)
19:20:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:20:14 DISPATCHER: Finished worker discovery
19:20:14 DISPATCHER: trying to notify the job_runner thread.
19:20:14 HBMASTER: job (3, 0, 3) submitted to dispatcher
19:20:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:20:14 DISPATCHER: Trying to submit another job.
19:20:14 DISPATCHER: starting job (3, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:20:14 DISPATCHER: job (3, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:20:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:20:14 WORKER: start processing job (3, 0, 3)
19:20:14 WORKER: args: ()
19:20:14 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.009285761169013269, 'num_filters_1': 26, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.04739338247207031}, 'budget': 1200.0, 'working_directory': '.'}
19:21:14 DISPATCHER: Starting worker discovery
19:21:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:21:14 DISPATCHER: Finished worker discovery
19:22:14 DISPATCHER: Starting worker discovery
19:22:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:22:14 DISPATCHER: Finished worker discovery
19:23:14 DISPATCHER: Starting worker discovery
19:23:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:23:14 DISPATCHER: Finished worker discovery
19:24:14 DISPATCHER: Starting worker discovery
19:24:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:24:14 DISPATCHER: Finished worker discovery
19:25:14 DISPATCHER: Starting worker discovery
19:25:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:25:14 DISPATCHER: Finished worker discovery
19:26:14 DISPATCHER: Starting worker discovery
19:26:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:26:14 DISPATCHER: Finished worker discovery
19:27:14 DISPATCHER: Starting worker discovery
19:27:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:27:14 DISPATCHER: Finished worker discovery
19:28:14 DISPATCHER: Starting worker discovery
19:28:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:28:14 DISPATCHER: Finished worker discovery
19:29:14 DISPATCHER: Starting worker discovery
19:29:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:29:14 DISPATCHER: Finished worker discovery
19:30:14 DISPATCHER: Starting worker discovery
19:30:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:30:14 DISPATCHER: Finished worker discovery
19:31:14 DISPATCHER: Starting worker discovery
19:31:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:31:14 DISPATCHER: Finished worker discovery
19:32:14 DISPATCHER: Starting worker discovery
19:32:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:32:14 DISPATCHER: Finished worker discovery
19:33:14 DISPATCHER: Starting worker discovery
19:33:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:33:14 DISPATCHER: Finished worker discovery
19:34:14 DISPATCHER: Starting worker discovery
19:34:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:34:14 DISPATCHER: Finished worker discovery
19:35:14 DISPATCHER: Starting worker discovery
19:35:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:35:14 DISPATCHER: Finished worker discovery
19:36:14 DISPATCHER: Starting worker discovery
19:36:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:36:14 DISPATCHER: Finished worker discovery
19:37:14 DISPATCHER: Starting worker discovery
19:37:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:37:14 DISPATCHER: Finished worker discovery
19:38:14 DISPATCHER: Starting worker discovery
19:38:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:38:14 DISPATCHER: Finished worker discovery
19:39:14 DISPATCHER: Starting worker discovery
19:39:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:39:14 DISPATCHER: Finished worker discovery
19:40:14 DISPATCHER: Starting worker discovery
19:40:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:40:14 DISPATCHER: Finished worker discovery
19:41:14 DISPATCHER: Starting worker discovery
19:41:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:41:14 DISPATCHER: Finished worker discovery
19:41:51 WORKER: done with job (3, 0, 3), trying to register it.
19:41:51 WORKER: registered result for job (3, 0, 3) with dispatcher
19:41:51 DISPATCHER: job (3, 0, 3) finished
19:41:51 DISPATCHER: register_result: lock acquired
19:41:51 DISPATCHER: job (3, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
19:41:51 job_id: (3, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.009285761169013269, 'num_filters_1': 26, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.04739338247207031}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.20860442899035164, 'info': {'data05': 0.20860442899035164, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.009285761169013269, 'num_filters_1': 26, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.04739338247207031}"}}
exception: None

19:41:51 job_callback for (3, 0, 3) started
19:41:51 job_callback for (3, 0, 3) got condition
19:41:51 DISPATCHER: Trying to submit another job.
19:41:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:41:51 Only 8 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
19:41:51 HBMASTER: Trying to run another job!
19:41:51 job_callback for (3, 0, 3) finished
19:41:51 start sampling a new configuration.
19:41:51 done sampling a new configuration.
19:41:51 HBMASTER: schedule new run for iteration 4
19:41:51 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
19:41:51 HBMASTER: submitting job (4, 0, 0) to dispatcher
19:41:51 DISPATCHER: trying to submit job (4, 0, 0)
19:41:51 DISPATCHER: trying to notify the job_runner thread.
19:41:51 HBMASTER: job (4, 0, 0) submitted to dispatcher
19:41:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:41:51 DISPATCHER: Trying to submit another job.
19:41:51 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:41:51 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:41:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:41:51 WORKER: start processing job (4, 0, 0)
19:41:51 WORKER: args: ()
19:41:51 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.027437260962560543, 'num_filters_1': 51, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.01536570371299221, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 96, 'num_filters_3': 28}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:42:14 DISPATCHER: Starting worker discovery
19:42:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:42:14 DISPATCHER: Finished worker discovery
19:42:48 WORKER: done with job (4, 0, 0), trying to register it.
19:42:48 WORKER: registered result for job (4, 0, 0) with dispatcher
19:42:48 DISPATCHER: job (4, 0, 0) finished
19:42:48 DISPATCHER: register_result: lock acquired
19:42:48 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
19:42:48 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.027437260962560543, 'num_filters_1': 51, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.01536570371299221, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 96, 'num_filters_3': 28}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.03053327118390848, 'info': {'data05': 0.03053327118390848, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.027437260962560543, 'num_filters_1': 51, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.01536570371299221, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 96, 'num_filters_3': 28}"}}
exception: None

19:42:48 job_callback for (4, 0, 0) started
19:42:48 job_callback for (4, 0, 0) got condition
19:42:48 DISPATCHER: Trying to submit another job.
19:42:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:42:48 HBMASTER: Trying to run another job!
19:42:48 job_callback for (4, 0, 0) finished
19:42:48 start sampling a new configuration.
19:42:48 done sampling a new configuration.
19:42:48 HBMASTER: schedule new run for iteration 4
19:42:48 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
19:42:48 HBMASTER: submitting job (4, 0, 1) to dispatcher
19:42:48 DISPATCHER: trying to submit job (4, 0, 1)
19:42:48 DISPATCHER: trying to notify the job_runner thread.
19:42:48 HBMASTER: job (4, 0, 1) submitted to dispatcher
19:42:48 DISPATCHER: Trying to submit another job.
19:42:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:42:48 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:42:48 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:42:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:42:48 WORKER: start processing job (4, 0, 1)
19:42:48 WORKER: args: ()
19:42:48 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0071985418116446275, 'num_filters_1': 88, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.015446579014935883}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:43:14 DISPATCHER: Starting worker discovery
19:43:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:43:14 DISPATCHER: Finished worker discovery
19:43:45 WORKER: done with job (4, 0, 1), trying to register it.
19:43:45 WORKER: registered result for job (4, 0, 1) with dispatcher
19:43:45 DISPATCHER: job (4, 0, 1) finished
19:43:45 DISPATCHER: register_result: lock acquired
19:43:45 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
19:43:45 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0071985418116446275, 'num_filters_1': 88, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.015446579014935883}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5767628066345989, 'info': {'data05': 0.5767628066345989, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0071985418116446275, 'num_filters_1': 88, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.015446579014935883}"}}
exception: None

19:43:45 job_callback for (4, 0, 1) started
19:43:45 DISPATCHER: Trying to submit another job.
19:43:45 job_callback for (4, 0, 1) got condition
19:43:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:43:45 HBMASTER: Trying to run another job!
19:43:45 job_callback for (4, 0, 1) finished
19:43:45 start sampling a new configuration.
19:43:45 done sampling a new configuration.
19:43:45 HBMASTER: schedule new run for iteration 4
19:43:45 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
19:43:45 HBMASTER: submitting job (4, 0, 2) to dispatcher
19:43:45 DISPATCHER: trying to submit job (4, 0, 2)
19:43:45 DISPATCHER: trying to notify the job_runner thread.
19:43:45 HBMASTER: job (4, 0, 2) submitted to dispatcher
19:43:45 DISPATCHER: Trying to submit another job.
19:43:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:43:45 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:43:45 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:43:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:43:45 WORKER: start processing job (4, 0, 2)
19:43:45 WORKER: args: ()
19:43:45 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0025030989153563615, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.05118533265414948, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 38, 'num_filters_3': 76}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:44:14 DISPATCHER: Starting worker discovery
19:44:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:44:14 DISPATCHER: Finished worker discovery
19:44:44 WORKER: done with job (4, 0, 2), trying to register it.
19:44:44 WORKER: registered result for job (4, 0, 2) with dispatcher
19:44:44 DISPATCHER: job (4, 0, 2) finished
19:44:44 DISPATCHER: register_result: lock acquired
19:44:44 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
19:44:44 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0025030989153563615, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.05118533265414948, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 38, 'num_filters_3': 76}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.16346872032579146, 'info': {'data05': 0.16346872032579146, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0025030989153563615, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.05118533265414948, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 38, 'num_filters_3': 76}"}}
exception: None

19:44:44 job_callback for (4, 0, 2) started
19:44:44 DISPATCHER: Trying to submit another job.
19:44:44 job_callback for (4, 0, 2) got condition
19:44:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:44:44 HBMASTER: Trying to run another job!
19:44:44 job_callback for (4, 0, 2) finished
19:44:44 start sampling a new configuration.
19:44:44 done sampling a new configuration.
19:44:44 HBMASTER: schedule new run for iteration 4
19:44:44 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
19:44:44 HBMASTER: submitting job (4, 0, 3) to dispatcher
19:44:44 DISPATCHER: trying to submit job (4, 0, 3)
19:44:44 DISPATCHER: trying to notify the job_runner thread.
19:44:44 HBMASTER: job (4, 0, 3) submitted to dispatcher
19:44:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:44:44 DISPATCHER: Trying to submit another job.
19:44:44 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:44:44 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:44:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:44:44 WORKER: start processing job (4, 0, 3)
19:44:44 WORKER: args: ()
19:44:44 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0067061078340037135, 'num_filters_1': 68, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.15957656067364737, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 64, 'num_filters_3': 78, 'num_filters_4': 64, 'num_filters_5': 61}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:45:14 DISPATCHER: Starting worker discovery
19:45:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:45:14 DISPATCHER: Finished worker discovery
19:45:40 WORKER: done with job (4, 0, 3), trying to register it.
19:45:40 WORKER: registered result for job (4, 0, 3) with dispatcher
19:45:40 DISPATCHER: job (4, 0, 3) finished
19:45:40 DISPATCHER: register_result: lock acquired
19:45:40 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
19:45:40 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0067061078340037135, 'num_filters_1': 68, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.15957656067364737, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 64, 'num_filters_3': 78, 'num_filters_4': 64, 'num_filters_5': 61}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 4.712408863039017e-05, 'info': {'data05': -4.712408863039017e-05, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0067061078340037135, 'num_filters_1': 68, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.15957656067364737, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 64, 'num_filters_3': 78, 'num_filters_4': 64, 'num_filters_5': 61}"}}
exception: None

19:45:40 job_callback for (4, 0, 3) started
19:45:40 job_callback for (4, 0, 3) got condition
19:45:40 DISPATCHER: Trying to submit another job.
19:45:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:45:40 HBMASTER: Trying to run another job!
19:45:40 job_callback for (4, 0, 3) finished
19:45:40 start sampling a new configuration.
19:45:40 done sampling a new configuration.
19:45:40 HBMASTER: schedule new run for iteration 4
19:45:40 HBMASTER: trying submitting job (4, 0, 4) to dispatcher
19:45:40 HBMASTER: submitting job (4, 0, 4) to dispatcher
19:45:40 DISPATCHER: trying to submit job (4, 0, 4)
19:45:40 DISPATCHER: trying to notify the job_runner thread.
19:45:40 HBMASTER: job (4, 0, 4) submitted to dispatcher
19:45:40 DISPATCHER: Trying to submit another job.
19:45:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:45:40 DISPATCHER: starting job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:45:40 DISPATCHER: job (4, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:45:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:45:40 WORKER: start processing job (4, 0, 4)
19:45:40 WORKER: args: ()
19:45:40 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0016785950516619418, 'num_filters_1': 78, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.011881675433017037}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:46:14 DISPATCHER: Starting worker discovery
19:46:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:46:14 DISPATCHER: Finished worker discovery
19:46:36 WORKER: done with job (4, 0, 4), trying to register it.
19:46:36 WORKER: registered result for job (4, 0, 4) with dispatcher
19:46:36 DISPATCHER: job (4, 0, 4) finished
19:46:36 DISPATCHER: register_result: lock acquired
19:46:36 DISPATCHER: job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
19:46:36 job_id: (4, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0016785950516619418, 'num_filters_1': 78, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.011881675433017037}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5121220548931363, 'info': {'data05': 0.5121220548931363, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0016785950516619418, 'num_filters_1': 78, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.011881675433017037}"}}
exception: None

19:46:36 job_callback for (4, 0, 4) started
19:46:36 job_callback for (4, 0, 4) got condition
19:46:36 DISPATCHER: Trying to submit another job.
19:46:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:46:36 HBMASTER: Trying to run another job!
19:46:36 job_callback for (4, 0, 4) finished
19:46:36 start sampling a new configuration.
19:46:36 done sampling a new configuration.
19:46:36 HBMASTER: schedule new run for iteration 4
19:46:36 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
19:46:36 HBMASTER: submitting job (4, 0, 5) to dispatcher
19:46:36 DISPATCHER: trying to submit job (4, 0, 5)
19:46:36 DISPATCHER: trying to notify the job_runner thread.
19:46:36 HBMASTER: job (4, 0, 5) submitted to dispatcher
19:46:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:46:36 DISPATCHER: Trying to submit another job.
19:46:36 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:46:36 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:46:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:46:36 WORKER: start processing job (4, 0, 5)
19:46:36 WORKER: args: ()
19:46:36 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00615442476146411, 'num_filters_1': 101, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.051532519019768006, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 26, 'num_filters_3': 30, 'num_filters_4': 45, 'num_filters_5': 41}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:47:14 DISPATCHER: Starting worker discovery
19:47:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:47:14 DISPATCHER: Finished worker discovery
19:47:35 WORKER: done with job (4, 0, 5), trying to register it.
19:47:35 WORKER: registered result for job (4, 0, 5) with dispatcher
19:47:35 DISPATCHER: job (4, 0, 5) finished
19:47:35 DISPATCHER: register_result: lock acquired
19:47:35 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
19:47:35 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00615442476146411, 'num_filters_1': 101, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.051532519019768006, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 26, 'num_filters_3': 30, 'num_filters_4': 45, 'num_filters_5': 41}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00615442476146411, 'num_filters_1': 101, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.051532519019768006, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 26, 'num_filters_3': 30, 'num_filters_4': 45, 'num_filters_5': 41}"}}
exception: None

19:47:35 job_callback for (4, 0, 5) started
19:47:35 DISPATCHER: Trying to submit another job.
19:47:35 job_callback for (4, 0, 5) got condition
19:47:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:47:35 HBMASTER: Trying to run another job!
19:47:35 job_callback for (4, 0, 5) finished
19:47:35 start sampling a new configuration.
19:47:35 done sampling a new configuration.
19:47:35 HBMASTER: schedule new run for iteration 4
19:47:35 HBMASTER: trying submitting job (4, 0, 6) to dispatcher
19:47:35 HBMASTER: submitting job (4, 0, 6) to dispatcher
19:47:35 DISPATCHER: trying to submit job (4, 0, 6)
19:47:35 DISPATCHER: trying to notify the job_runner thread.
19:47:35 HBMASTER: job (4, 0, 6) submitted to dispatcher
19:47:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:47:35 DISPATCHER: Trying to submit another job.
19:47:35 DISPATCHER: starting job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:47:35 DISPATCHER: job (4, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:47:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:47:35 WORKER: start processing job (4, 0, 6)
19:47:35 WORKER: args: ()
19:47:35 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.05298222747912706, 'num_filters_1': 98, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.029814592133456063, 'kernel_size_2': 3, 'num_filters_2': 86}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-673:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 4607182418800017408 is out of bounds for axis 0 with size 10

19:48:14 DISPATCHER: Starting worker discovery
19:48:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:48:14 DISPATCHER: Finished worker discovery
19:48:29 WORKER: done with job (4, 0, 6), trying to register it.
19:48:29 WORKER: registered result for job (4, 0, 6) with dispatcher
19:48:29 DISPATCHER: job (4, 0, 6) finished
19:48:29 DISPATCHER: register_result: lock acquired
19:48:29 DISPATCHER: job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
19:48:29 job_id: (4, 0, 6)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.05298222747912706, 'num_filters_1': 98, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.029814592133456063, 'kernel_size_2': 3, 'num_filters_2': 86}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7931831906801882, 'info': {'data05': 0.7931831906801882, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.05298222747912706, 'num_filters_1': 98, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.029814592133456063, 'kernel_size_2': 3, 'num_filters_2': 86}"}}
exception: None

19:48:29 job_callback for (4, 0, 6) started
19:48:29 job_callback for (4, 0, 6) got condition
19:48:29 DISPATCHER: Trying to submit another job.
19:48:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:48:29 done building a new model for budget 44.444444 based on 17/28 split
Best loss for this budget:-0.794045





19:48:29 HBMASTER: Trying to run another job!
19:48:29 job_callback for (4, 0, 6) finished
19:48:29 start sampling a new configuration.
19:48:30 best_vector: [0, 1, 0.5987739372703376, 0.8918492067461212, 0.525667748862975, 0, 0.7498576018909973, 0.1765859911753084, 1, 1, 2, 0, 0.4497076806581493, 0.10897159462623274, 0.348383372420657, 0.9036597460325639], 1.0572597360940547e-31, 0.09458413726171061, -2.1640526191213493e-06
19:48:30 done sampling a new configuration.
19:48:30 HBMASTER: schedule new run for iteration 4
19:48:30 HBMASTER: trying submitting job (4, 0, 7) to dispatcher
19:48:30 HBMASTER: submitting job (4, 0, 7) to dispatcher
19:48:30 DISPATCHER: trying to submit job (4, 0, 7)
19:48:30 DISPATCHER: trying to notify the job_runner thread.
19:48:30 HBMASTER: job (4, 0, 7) submitted to dispatcher
19:48:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:48:30 DISPATCHER: Trying to submit another job.
19:48:30 DISPATCHER: starting job (4, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:48:30 DISPATCHER: job (4, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:48:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:48:30 WORKER: start processing job (4, 0, 7)
19:48:30 WORKER: args: ()
19:48:30 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.01575969740514202, 'num_filters_1': 102, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.01697241613266524, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 40, 'num_filters_3': 20}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:49:14 DISPATCHER: Starting worker discovery
19:49:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:49:14 DISPATCHER: Finished worker discovery
19:49:26 WORKER: done with job (4, 0, 7), trying to register it.
19:49:26 WORKER: registered result for job (4, 0, 7) with dispatcher
19:49:26 DISPATCHER: job (4, 0, 7) finished
19:49:26 DISPATCHER: register_result: lock acquired
19:49:26 DISPATCHER: job (4, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
19:49:26 job_id: (4, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.01575969740514202, 'num_filters_1': 102, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.01697241613266524, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 40, 'num_filters_3': 20}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1352037689639117, 'info': {'data05': 0.1352037689639117, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.01575969740514202, 'num_filters_1': 102, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.01697241613266524, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 40, 'num_filters_3': 20}"}}
exception: None

19:49:26 job_callback for (4, 0, 7) started
19:49:26 DISPATCHER: Trying to submit another job.
19:49:26 job_callback for (4, 0, 7) got condition
19:49:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:49:26 done building a new model for budget 44.444444 based on 17/29 split
Best loss for this budget:-0.794045





19:49:26 HBMASTER: Trying to run another job!
19:49:26 job_callback for (4, 0, 7) finished
19:49:26 start sampling a new configuration.
19:49:26 done sampling a new configuration.
19:49:26 HBMASTER: schedule new run for iteration 4
19:49:26 HBMASTER: trying submitting job (4, 0, 8) to dispatcher
19:49:26 HBMASTER: submitting job (4, 0, 8) to dispatcher
19:49:26 DISPATCHER: trying to submit job (4, 0, 8)
19:49:26 DISPATCHER: trying to notify the job_runner thread.
19:49:26 HBMASTER: job (4, 0, 8) submitted to dispatcher
19:49:26 DISPATCHER: Trying to submit another job.
19:49:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:49:26 DISPATCHER: starting job (4, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:49:26 DISPATCHER: job (4, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:49:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:49:26 WORKER: start processing job (4, 0, 8)
19:49:26 WORKER: args: ()
19:49:26 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.002586932646496607, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.017519427282262662, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 20, 'num_filters_3': 21, 'num_filters_4': 126}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:50:14 DISPATCHER: Starting worker discovery
19:50:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:50:14 DISPATCHER: Finished worker discovery
19:50:22 WORKER: done with job (4, 0, 8), trying to register it.
19:50:22 WORKER: registered result for job (4, 0, 8) with dispatcher
19:50:22 DISPATCHER: job (4, 0, 8) finished
19:50:22 DISPATCHER: register_result: lock acquired
19:50:22 DISPATCHER: job (4, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
19:50:22 job_id: (4, 0, 8)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.002586932646496607, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.017519427282262662, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 20, 'num_filters_3': 21, 'num_filters_4': 126}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.04026014952997635, 'info': {'data05': 0.04026014952997635, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.002586932646496607, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.017519427282262662, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 20, 'num_filters_3': 21, 'num_filters_4': 126}"}}
exception: None

19:50:22 job_callback for (4, 0, 8) started
19:50:22 job_callback for (4, 0, 8) got condition
19:50:22 DISPATCHER: Trying to submit another job.
19:50:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:50:22 done building a new model for budget 44.444444 based on 17/30 split
Best loss for this budget:-0.794045





19:50:22 HBMASTER: Trying to run another job!
19:50:22 job_callback for (4, 0, 8) finished
19:50:22 start sampling a new configuration.
19:50:22 best_vector: [3, 1, 0.24683259101439672, 0.010473016366602028, 0.671290063822818, 0, 0.1458449815018113, 0.4531422235707877, 1, 0, 2, 0, 0.18213468063561372, 0.6105321132569577, 0.34850087608885133, 0.9058706304826437], 4.114340358689316e-32, 0.24305232742547456, -3.738269834426171e-08
19:50:23 done sampling a new configuration.
19:50:23 HBMASTER: schedule new run for iteration 4
19:50:23 HBMASTER: trying submitting job (4, 0, 9) to dispatcher
19:50:23 HBMASTER: submitting job (4, 0, 9) to dispatcher
19:50:23 DISPATCHER: trying to submit job (4, 0, 9)
19:50:23 DISPATCHER: trying to notify the job_runner thread.
19:50:23 HBMASTER: job (4, 0, 9) submitted to dispatcher
19:50:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:50:23 DISPATCHER: Trying to submit another job.
19:50:23 DISPATCHER: starting job (4, 0, 9) on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:50:23 DISPATCHER: job (4, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:50:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:50:23 WORKER: start processing job (4, 0, 9)
19:50:23 WORKER: args: ()
19:50:23 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0031164860125652027, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.03886436938057259, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 23, 'num_filters_3': 56, 'num_filters_4': 32}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:51:14 DISPATCHER: Starting worker discovery
19:51:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:51:14 DISPATCHER: Finished worker discovery
19:51:21 WORKER: done with job (4, 0, 9), trying to register it.
19:51:21 WORKER: registered result for job (4, 0, 9) with dispatcher
19:51:21 DISPATCHER: job (4, 0, 9) finished
19:51:21 DISPATCHER: register_result: lock acquired
19:51:21 DISPATCHER: job (4, 0, 9) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
19:51:21 job_id: (4, 0, 9)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0031164860125652027, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.03886436938057259, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 23, 'num_filters_3': 56, 'num_filters_4': 32}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.005047425005632249, 'info': {'data05': -0.005047425005632249, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0031164860125652027, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.03886436938057259, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 23, 'num_filters_3': 56, 'num_filters_4': 32}"}}
exception: None

19:51:21 job_callback for (4, 0, 9) started
19:51:21 DISPATCHER: Trying to submit another job.
19:51:21 job_callback for (4, 0, 9) got condition
19:51:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:51:21 done building a new model for budget 44.444444 based on 17/31 split
Best loss for this budget:-0.794045





19:51:21 HBMASTER: Trying to run another job!
19:51:21 job_callback for (4, 0, 9) finished
19:51:21 start sampling a new configuration.
19:51:21 best_vector: [0, 1, 0.24837596344267499, 0.6249859731891114, 0.1007987101758134, 1, 0.5115619045069015, 0.09011083300166528, 0, 2, 1, 0, 0.8265067643129084, 0.8631439803437272, 0.3318784116564286, 0.9043590942510017], 2.0269731939301984e-32, 0.4933464354607723, -1.4650199104658948e-06
19:51:21 done sampling a new configuration.
19:51:21 HBMASTER: schedule new run for iteration 4
19:51:21 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
19:51:21 HBMASTER: submitting job (4, 0, 10) to dispatcher
19:51:21 DISPATCHER: trying to submit job (4, 0, 10)
19:51:21 DISPATCHER: trying to notify the job_runner thread.
19:51:21 HBMASTER: job (4, 0, 10) submitted to dispatcher
19:51:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:51:21 DISPATCHER: Trying to submit another job.
19:51:21 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:51:21 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:51:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:51:21 WORKER: start processing job (4, 0, 10)
19:51:21 WORKER: args: ()
19:51:21 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.003138715317859794, 'num_filters_1': 58, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.013098962434721452}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:52:14 DISPATCHER: Starting worker discovery
19:52:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:52:14 DISPATCHER: Finished worker discovery
19:52:19 WORKER: done with job (4, 0, 10), trying to register it.
19:52:19 WORKER: registered result for job (4, 0, 10) with dispatcher
19:52:19 DISPATCHER: job (4, 0, 10) finished
19:52:19 DISPATCHER: register_result: lock acquired
19:52:19 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
19:52:19 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.003138715317859794, 'num_filters_1': 58, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.013098962434721452}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6065104294472954, 'info': {'data05': 0.6065104294472954, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.003138715317859794, 'num_filters_1': 58, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.013098962434721452}"}}
exception: None

19:52:19 job_callback for (4, 0, 10) started
19:52:19 DISPATCHER: Trying to submit another job.
19:52:19 job_callback for (4, 0, 10) got condition
19:52:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:52:19 done building a new model for budget 44.444444 based on 17/32 split
Best loss for this budget:-0.794045





19:52:19 HBMASTER: Trying to run another job!
19:52:19 job_callback for (4, 0, 10) finished
19:52:19 start sampling a new configuration.
19:52:19 done sampling a new configuration.
19:52:19 HBMASTER: schedule new run for iteration 4
19:52:19 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
19:52:19 HBMASTER: submitting job (4, 0, 11) to dispatcher
19:52:19 DISPATCHER: trying to submit job (4, 0, 11)
19:52:19 DISPATCHER: trying to notify the job_runner thread.
19:52:19 HBMASTER: job (4, 0, 11) submitted to dispatcher
19:52:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:52:19 DISPATCHER: Trying to submit another job.
19:52:19 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:52:19 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:52:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:52:19 WORKER: start processing job (4, 0, 11)
19:52:19 WORKER: args: ()
19:52:19 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.027297613069792562, 'num_filters_1': 76, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.06223306913390591, 'kernel_size_2': 7, 'num_filters_2': 37}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:53:14 DISPATCHER: Starting worker discovery
19:53:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:53:14 DISPATCHER: Finished worker discovery
19:53:18 WORKER: done with job (4, 0, 11), trying to register it.
19:53:18 WORKER: registered result for job (4, 0, 11) with dispatcher
19:53:18 DISPATCHER: job (4, 0, 11) finished
19:53:18 DISPATCHER: register_result: lock acquired
19:53:18 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
19:53:18 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.027297613069792562, 'num_filters_1': 76, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.06223306913390591, 'kernel_size_2': 7, 'num_filters_2': 37}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -3.2866083039281404e-05, 'info': {'data05': 3.2866083039281404e-05, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.027297613069792562, 'num_filters_1': 76, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.06223306913390591, 'kernel_size_2': 7, 'num_filters_2': 37}"}}
exception: None

19:53:18 job_callback for (4, 0, 11) started
19:53:18 DISPATCHER: Trying to submit another job.
19:53:18 job_callback for (4, 0, 11) got condition
19:53:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:53:18 done building a new model for budget 44.444444 based on 17/33 split
Best loss for this budget:-0.794045





19:53:18 HBMASTER: Trying to run another job!
19:53:18 job_callback for (4, 0, 11) finished
19:53:18 start sampling a new configuration.
19:53:18 best_vector: [0, 1, 0.1662231862054407, 0.5860966403106742, 0.33370374168071737, 1, 0.25064974830855496, 0.23758234344959941, 2, 0, 2, 0, 0.9953778095650742, 0.10752125632880669, 0.20296814167614247, 0.9038361892248006], 5.072735952873482e-32, 0.1971322791665401, -1.10746402166173e-07
19:53:18 done sampling a new configuration.
19:53:18 HBMASTER: schedule new run for iteration 4
19:53:18 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
19:53:18 HBMASTER: submitting job (4, 0, 12) to dispatcher
19:53:18 DISPATCHER: trying to submit job (4, 0, 12)
19:53:18 DISPATCHER: trying to notify the job_runner thread.
19:53:18 HBMASTER: job (4, 0, 12) submitted to dispatcher
19:53:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:53:18 DISPATCHER: Trying to submit another job.
19:53:18 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:53:18 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:53:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:53:18 WORKER: start processing job (4, 0, 12)
19:53:18 WORKER: args: ()
19:53:18 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0021500391716232302, 'num_filters_1': 54, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.0203751941291504, 'kernel_size_2': 7, 'num_filters_2': 127}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:54:14 DISPATCHER: Starting worker discovery
19:54:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:54:14 DISPATCHER: Finished worker discovery
19:54:16 WORKER: done with job (4, 0, 12), trying to register it.
19:54:16 WORKER: registered result for job (4, 0, 12) with dispatcher
19:54:16 DISPATCHER: job (4, 0, 12) finished
19:54:16 DISPATCHER: register_result: lock acquired
19:54:16 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
19:54:16 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0021500391716232302, 'num_filters_1': 54, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.0203751941291504, 'kernel_size_2': 7, 'num_filters_2': 127}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6847150005792929, 'info': {'data05': 0.6847150005792929, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0021500391716232302, 'num_filters_1': 54, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.0203751941291504, 'kernel_size_2': 7, 'num_filters_2': 127}"}}
exception: None

19:54:16 job_callback for (4, 0, 12) started
19:54:16 DISPATCHER: Trying to submit another job.
19:54:16 job_callback for (4, 0, 12) got condition
19:54:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:54:16 done building a new model for budget 44.444444 based on 17/34 split
Best loss for this budget:-0.794045





19:54:16 HBMASTER: Trying to run another job!
19:54:16 job_callback for (4, 0, 12) finished
19:54:16 start sampling a new configuration.
19:54:17 best_vector: [2, 0, 0.03536446412033474, 0.9386432692311213, 0.2624008662959404, 0, 0.6959137453274324, 0.1488725008374096, 0, 0, 0, 0, 0.8177767060149015, 0.7965714151526391, 0.7601828333342372, 0.9027317204485702], 3.1216108531505216e-32, 0.32034742542964273, -1.2186091402240321e-05
19:54:17 done sampling a new configuration.
19:54:17 HBMASTER: schedule new run for iteration 4
19:54:17 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
19:54:17 HBMASTER: submitting job (4, 0, 13) to dispatcher
19:54:17 DISPATCHER: trying to submit job (4, 0, 13)
19:54:17 DISPATCHER: trying to notify the job_runner thread.
19:54:17 HBMASTER: job (4, 0, 13) submitted to dispatcher
19:54:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:54:17 DISPATCHER: Trying to submit another job.
19:54:17 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:54:17 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:54:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:54:17 WORKER: start processing job (4, 0, 13)
19:54:17 WORKER: args: ()
19:54:17 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0011768711814953642, 'num_filters_1': 113, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.015620235926040333, 'kernel_size_2': 3, 'num_filters_2': 87}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:55:13 WORKER: done with job (4, 0, 13), trying to register it.
19:55:13 WORKER: registered result for job (4, 0, 13) with dispatcher
19:55:13 DISPATCHER: job (4, 0, 13) finished
19:55:13 DISPATCHER: register_result: lock acquired
19:55:13 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
19:55:13 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0011768711814953642, 'num_filters_1': 113, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.015620235926040333, 'kernel_size_2': 3, 'num_filters_2': 87}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.13922686851411178, 'info': {'data05': 0.13922686851411178, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0011768711814953642, 'num_filters_1': 113, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.015620235926040333, 'kernel_size_2': 3, 'num_filters_2': 87}"}}
exception: None

19:55:13 job_callback for (4, 0, 13) started
19:55:13 DISPATCHER: Trying to submit another job.
19:55:13 job_callback for (4, 0, 13) got condition
19:55:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:55:13 done building a new model for budget 44.444444 based on 17/34 split
Best loss for this budget:-0.794045





19:55:13 HBMASTER: Trying to run another job!
19:55:13 job_callback for (4, 0, 13) finished
19:55:13 start sampling a new configuration.
19:55:13 done sampling a new configuration.
19:55:13 HBMASTER: schedule new run for iteration 4
19:55:13 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
19:55:13 HBMASTER: submitting job (4, 0, 14) to dispatcher
19:55:13 DISPATCHER: trying to submit job (4, 0, 14)
19:55:13 DISPATCHER: trying to notify the job_runner thread.
19:55:13 HBMASTER: job (4, 0, 14) submitted to dispatcher
19:55:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:55:13 DISPATCHER: Trying to submit another job.
19:55:13 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:55:13 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:55:13 WORKER: start processing job (4, 0, 14)
19:55:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:55:13 WORKER: args: ()
19:55:13 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0064122275919679846, 'num_filters_1': 68, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.013919153100552115, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 120, 'num_filters_3': 41}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:55:14 DISPATCHER: Starting worker discovery
19:55:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:55:14 DISPATCHER: Finished worker discovery
19:56:10 WORKER: done with job (4, 0, 14), trying to register it.
19:56:10 WORKER: registered result for job (4, 0, 14) with dispatcher
19:56:10 DISPATCHER: job (4, 0, 14) finished
19:56:10 DISPATCHER: register_result: lock acquired
19:56:10 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
19:56:10 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0064122275919679846, 'num_filters_1': 68, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.013919153100552115, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 120, 'num_filters_3': 41}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.001426259640669214, 'info': {'data05': 0.001426259640669214, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0064122275919679846, 'num_filters_1': 68, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.013919153100552115, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 120, 'num_filters_3': 41}"}}
exception: None

19:56:10 job_callback for (4, 0, 14) started
19:56:10 DISPATCHER: Trying to submit another job.
19:56:10 job_callback for (4, 0, 14) got condition
19:56:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:56:10 done building a new model for budget 44.444444 based on 17/35 split
Best loss for this budget:-0.794045





19:56:10 HBMASTER: Trying to run another job!
19:56:10 job_callback for (4, 0, 14) finished
19:56:10 start sampling a new configuration.
19:56:10 best_vector: [3, 0, 0.4865564721085061, 0.15965381340769513, 0.9736418048597624, 0, 0.6274433091343966, 0.41365136505777533, 2, 2, 2, 0, 0.5017513382786247, 0.26037813072715965, 0.7077189782522416, 0.9038681621839936], 3.4560825209626355e-31, 0.028934494299096374, -2.5297955535226317e-05
19:56:10 done sampling a new configuration.
19:56:10 HBMASTER: schedule new run for iteration 4
19:56:10 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
19:56:10 HBMASTER: submitting job (4, 0, 15) to dispatcher
19:56:10 DISPATCHER: trying to submit job (4, 0, 15)
19:56:10 DISPATCHER: trying to notify the job_runner thread.
19:56:10 HBMASTER: job (4, 0, 15) submitted to dispatcher
19:56:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:56:10 DISPATCHER: Trying to submit another job.
19:56:10 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:56:10 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:56:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:56:10 WORKER: start processing job (4, 0, 15)
19:56:10 WORKER: args: ()
19:56:10 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.009399677302389355, 'num_filters_1': 22, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.03452811215477627, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 45, 'num_filters_3': 27, 'num_filters_4': 69, 'num_filters_5': 105}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:56:14 DISPATCHER: Starting worker discovery
19:56:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:56:14 DISPATCHER: Finished worker discovery
19:57:06 WORKER: done with job (4, 0, 15), trying to register it.
19:57:06 WORKER: registered result for job (4, 0, 15) with dispatcher
19:57:06 DISPATCHER: job (4, 0, 15) finished
19:57:06 DISPATCHER: register_result: lock acquired
19:57:06 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
19:57:06 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.009399677302389355, 'num_filters_1': 22, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.03452811215477627, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 45, 'num_filters_3': 27, 'num_filters_4': 69, 'num_filters_5': 105}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.009399677302389355, 'num_filters_1': 22, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.03452811215477627, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 45, 'num_filters_3': 27, 'num_filters_4': 69, 'num_filters_5': 105}"}}
exception: None

19:57:06 job_callback for (4, 0, 15) started
19:57:06 job_callback for (4, 0, 15) got condition
19:57:06 DISPATCHER: Trying to submit another job.
19:57:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:57:06 done building a new model for budget 44.444444 based on 17/36 split
Best loss for this budget:-0.794045





19:57:06 HBMASTER: Trying to run another job!
19:57:06 job_callback for (4, 0, 15) finished
19:57:06 start sampling a new configuration.
19:57:06 done sampling a new configuration.
19:57:06 HBMASTER: schedule new run for iteration 4
19:57:06 HBMASTER: trying submitting job (4, 0, 16) to dispatcher
19:57:06 HBMASTER: submitting job (4, 0, 16) to dispatcher
19:57:06 DISPATCHER: trying to submit job (4, 0, 16)
19:57:06 DISPATCHER: trying to notify the job_runner thread.
19:57:06 HBMASTER: job (4, 0, 16) submitted to dispatcher
19:57:06 DISPATCHER: Trying to submit another job.
19:57:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:57:06 DISPATCHER: starting job (4, 0, 16) on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:57:06 DISPATCHER: job (4, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:57:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:57:06 WORKER: start processing job (4, 0, 16)
19:57:06 WORKER: args: ()
19:57:06 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.001115689868324481, 'num_filters_1': 17, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.19682159408843694}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:57:14 DISPATCHER: Starting worker discovery
19:57:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:57:14 DISPATCHER: Finished worker discovery
19:58:02 WORKER: done with job (4, 0, 16), trying to register it.
19:58:02 WORKER: registered result for job (4, 0, 16) with dispatcher
19:58:02 DISPATCHER: job (4, 0, 16) finished
19:58:02 DISPATCHER: register_result: lock acquired
19:58:02 DISPATCHER: job (4, 0, 16) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
19:58:02 job_id: (4, 0, 16)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.001115689868324481, 'num_filters_1': 17, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.19682159408843694}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.24482437355298314, 'info': {'data05': 0.24482437355298314, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.001115689868324481, 'num_filters_1': 17, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.19682159408843694}"}}
exception: None

19:58:02 job_callback for (4, 0, 16) started
19:58:02 job_callback for (4, 0, 16) got condition
19:58:02 DISPATCHER: Trying to submit another job.
19:58:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:58:02 done building a new model for budget 44.444444 based on 17/37 split
Best loss for this budget:-0.794045





19:58:02 HBMASTER: Trying to run another job!
19:58:02 job_callback for (4, 0, 16) finished
19:58:02 start sampling a new configuration.
19:58:02 done sampling a new configuration.
19:58:02 HBMASTER: schedule new run for iteration 4
19:58:02 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
19:58:02 HBMASTER: submitting job (4, 0, 17) to dispatcher
19:58:02 DISPATCHER: trying to submit job (4, 0, 17)
19:58:02 DISPATCHER: trying to notify the job_runner thread.
19:58:02 HBMASTER: job (4, 0, 17) submitted to dispatcher
19:58:02 DISPATCHER: Trying to submit another job.
19:58:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:58:02 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:58:02 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:58:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:58:02 WORKER: start processing job (4, 0, 17)
19:58:02 WORKER: args: ()
19:58:02 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.09364189152821269, 'num_filters_1': 60, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.16921531923326388}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:58:14 DISPATCHER: Starting worker discovery
19:58:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:58:14 DISPATCHER: Finished worker discovery
19:59:00 WORKER: done with job (4, 0, 17), trying to register it.
19:59:00 WORKER: registered result for job (4, 0, 17) with dispatcher
19:59:00 DISPATCHER: job (4, 0, 17) finished
19:59:00 DISPATCHER: register_result: lock acquired
19:59:00 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
19:59:00 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.09364189152821269, 'num_filters_1': 60, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.16921531923326388}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.05179151299970259, 'info': {'data05': 0.05179151299970259, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.09364189152821269, 'num_filters_1': 60, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.16921531923326388}"}}
exception: None

19:59:00 job_callback for (4, 0, 17) started
19:59:00 job_callback for (4, 0, 17) got condition
19:59:00 DISPATCHER: Trying to submit another job.
19:59:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:59:00 done building a new model for budget 44.444444 based on 17/38 split
Best loss for this budget:-0.794045





19:59:00 HBMASTER: Trying to run another job!
19:59:00 job_callback for (4, 0, 17) finished
19:59:00 start sampling a new configuration.
19:59:00 best_vector: [2, 1, 0.7242869746095462, 0.6186687011601876, 0.8494079337311821, 1, 0.45618028417270573, 0.21908144105351546, 0, 2, 1, 0, 0.5157586888509438, 0.39875367954817154, 0.08799019793088647, 0.9071410552500263], 9.794673389869329e-31, 0.010209630890135695, -5.089756639836428e-07
19:59:00 done sampling a new configuration.
19:59:00 HBMASTER: schedule new run for iteration 4
19:59:00 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
19:59:00 HBMASTER: submitting job (4, 0, 18) to dispatcher
19:59:00 DISPATCHER: trying to submit job (4, 0, 18)
19:59:00 DISPATCHER: trying to notify the job_runner thread.
19:59:00 HBMASTER: job (4, 0, 18) submitted to dispatcher
19:59:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:59:00 DISPATCHER: Trying to submit another job.
19:59:00 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:59:00 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:59:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:59:00 WORKER: start processing job (4, 0, 18)
19:59:00 WORKER: args: ()
19:59:00 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.028091436572120966, 'num_filters_1': 57, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.019276648411532444, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 46, 'num_filters_3': 36, 'num_filters_4': 19, 'num_filters_5': 106}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-685:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 4607182418800017408 is out of bounds for axis 0 with size 10

19:59:14 DISPATCHER: Starting worker discovery
19:59:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:59:14 DISPATCHER: Finished worker discovery
19:59:55 WORKER: done with job (4, 0, 18), trying to register it.
19:59:55 WORKER: registered result for job (4, 0, 18) with dispatcher
19:59:55 DISPATCHER: job (4, 0, 18) finished
19:59:55 DISPATCHER: register_result: lock acquired
19:59:55 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
19:59:55 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.028091436572120966, 'num_filters_1': 57, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.019276648411532444, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 46, 'num_filters_3': 36, 'num_filters_4': 19, 'num_filters_5': 106}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7678116192160497, 'info': {'data05': 0.7678116192160497, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.028091436572120966, 'num_filters_1': 57, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.019276648411532444, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 46, 'num_filters_3': 36, 'num_filters_4': 19, 'num_filters_5': 106}"}}
exception: None

19:59:55 job_callback for (4, 0, 18) started
19:59:55 job_callback for (4, 0, 18) got condition
19:59:55 DISPATCHER: Trying to submit another job.
19:59:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:59:55 done building a new model for budget 44.444444 based on 17/39 split
Best loss for this budget:-0.794045





19:59:55 HBMASTER: Trying to run another job!
19:59:55 job_callback for (4, 0, 18) finished
19:59:55 start sampling a new configuration.
19:59:55 done sampling a new configuration.
19:59:55 HBMASTER: schedule new run for iteration 4
19:59:55 HBMASTER: trying submitting job (4, 0, 19) to dispatcher
19:59:55 HBMASTER: submitting job (4, 0, 19) to dispatcher
19:59:55 DISPATCHER: trying to submit job (4, 0, 19)
19:59:55 DISPATCHER: trying to notify the job_runner thread.
19:59:55 HBMASTER: job (4, 0, 19) submitted to dispatcher
19:59:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:59:55 DISPATCHER: Trying to submit another job.
19:59:55 DISPATCHER: starting job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:59:55 DISPATCHER: job (4, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
19:59:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:59:55 WORKER: start processing job (4, 0, 19)
19:59:55 WORKER: args: ()
19:59:55 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.003210796193916864, 'num_filters_1': 35, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.16169868827397, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 40, 'num_filters_3': 110, 'num_filters_4': 20}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:00:14 DISPATCHER: Starting worker discovery
20:00:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:00:14 DISPATCHER: Finished worker discovery
20:00:54 WORKER: done with job (4, 0, 19), trying to register it.
20:00:54 WORKER: registered result for job (4, 0, 19) with dispatcher
20:00:54 DISPATCHER: job (4, 0, 19) finished
20:00:54 DISPATCHER: register_result: lock acquired
20:00:54 DISPATCHER: job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
20:00:54 job_id: (4, 0, 19)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.003210796193916864, 'num_filters_1': 35, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.16169868827397, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 40, 'num_filters_3': 110, 'num_filters_4': 20}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -1.4289651268004175e-05, 'info': {'data05': 1.4289651268004175e-05, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.003210796193916864, 'num_filters_1': 35, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.16169868827397, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 40, 'num_filters_3': 110, 'num_filters_4': 20}"}}
exception: None

20:00:54 job_callback for (4, 0, 19) started
20:00:54 DISPATCHER: Trying to submit another job.
20:00:54 job_callback for (4, 0, 19) got condition
20:00:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:00:54 done building a new model for budget 44.444444 based on 17/39 split
Best loss for this budget:-0.794045





20:00:54 HBMASTER: Trying to run another job!
20:00:54 job_callback for (4, 0, 19) finished
20:00:54 start sampling a new configuration.
20:00:54 best_vector: [0, 2, 0.41766652786060426, 0.9432733364824928, 0.5237681542879757, 1, 0.7527237524539525, 0.23066054229268862, 2, 0, 1, 0, 0.3053176276693471, 0.40963075924521, 0.6848698489309355, 0.9095401366778041], 1.710116772320778e-32, 0.5847553899158082, -2.0186090077953065e-05
20:00:54 done sampling a new configuration.
20:00:54 HBMASTER: schedule new run for iteration 4
20:00:54 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
20:00:54 HBMASTER: submitting job (4, 0, 20) to dispatcher
20:00:54 DISPATCHER: trying to submit job (4, 0, 20)
20:00:54 DISPATCHER: trying to notify the job_runner thread.
20:00:54 HBMASTER: job (4, 0, 20) submitted to dispatcher
20:00:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:00:54 DISPATCHER: Trying to submit another job.
20:00:54 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:00:54 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:00:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:00:54 WORKER: start processing job (4, 0, 20)
20:00:54 WORKER: args: ()
20:00:54 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.006844363328577427, 'num_filters_1': 114, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.01995704719416724, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 30, 'num_filters_3': 37}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:01:14 DISPATCHER: Starting worker discovery
20:01:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:01:14 DISPATCHER: Finished worker discovery
20:01:51 WORKER: done with job (4, 0, 20), trying to register it.
20:01:51 WORKER: registered result for job (4, 0, 20) with dispatcher
20:01:51 DISPATCHER: job (4, 0, 20) finished
20:01:51 DISPATCHER: register_result: lock acquired
20:01:51 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
20:01:51 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.006844363328577427, 'num_filters_1': 114, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.01995704719416724, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 30, 'num_filters_3': 37}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6770419651355424, 'info': {'data05': 0.6770419651355424, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.006844363328577427, 'num_filters_1': 114, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.01995704719416724, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 30, 'num_filters_3': 37}"}}
exception: None

20:01:51 job_callback for (4, 0, 20) started
20:01:51 DISPATCHER: Trying to submit another job.
20:01:51 job_callback for (4, 0, 20) got condition
20:01:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:01:51 done building a new model for budget 44.444444 based on 17/40 split
Best loss for this budget:-0.794045





20:01:51 HBMASTER: Trying to run another job!
20:01:51 job_callback for (4, 0, 20) finished
20:01:51 start sampling a new configuration.
20:01:51 done sampling a new configuration.
20:01:51 HBMASTER: schedule new run for iteration 4
20:01:51 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
20:01:51 HBMASTER: submitting job (4, 0, 21) to dispatcher
20:01:51 DISPATCHER: trying to submit job (4, 0, 21)
20:01:51 DISPATCHER: trying to notify the job_runner thread.
20:01:51 HBMASTER: job (4, 0, 21) submitted to dispatcher
20:01:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:01:51 DISPATCHER: Trying to submit another job.
20:01:51 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:01:51 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:01:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:01:51 WORKER: start processing job (4, 0, 21)
20:01:51 WORKER: args: ()
20:01:51 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.05218044509105421, 'num_filters_1': 36, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.03879833552144305, 'kernel_size_2': 5, 'num_filters_2': 39}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:02:14 DISPATCHER: Starting worker discovery
20:02:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:02:14 DISPATCHER: Finished worker discovery
20:02:48 WORKER: done with job (4, 0, 21), trying to register it.
20:02:48 WORKER: registered result for job (4, 0, 21) with dispatcher
20:02:48 DISPATCHER: job (4, 0, 21) finished
20:02:48 DISPATCHER: register_result: lock acquired
20:02:48 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
20:02:48 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.05218044509105421, 'num_filters_1': 36, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.03879833552144305, 'kernel_size_2': 5, 'num_filters_2': 39}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.10376515670224692, 'info': {'data05': 0.10376515670224692, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.05218044509105421, 'num_filters_1': 36, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.03879833552144305, 'kernel_size_2': 5, 'num_filters_2': 39}"}}
exception: None

20:02:48 job_callback for (4, 0, 21) started
20:02:48 DISPATCHER: Trying to submit another job.
20:02:48 job_callback for (4, 0, 21) got condition
20:02:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:02:48 done building a new model for budget 44.444444 based on 17/41 split
Best loss for this budget:-0.794045





20:02:48 HBMASTER: Trying to run another job!
20:02:48 job_callback for (4, 0, 21) finished
20:02:48 start sampling a new configuration.
20:02:48 done sampling a new configuration.
20:02:48 HBMASTER: schedule new run for iteration 4
20:02:48 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
20:02:48 HBMASTER: submitting job (4, 0, 22) to dispatcher
20:02:48 DISPATCHER: trying to submit job (4, 0, 22)
20:02:48 DISPATCHER: trying to notify the job_runner thread.
20:02:48 HBMASTER: job (4, 0, 22) submitted to dispatcher
20:02:48 DISPATCHER: Trying to submit another job.
20:02:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:02:48 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:02:48 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:02:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:02:48 WORKER: start processing job (4, 0, 22)
20:02:48 WORKER: args: ()
20:02:48 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.039823617224001434, 'num_filters_1': 16, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.019792116016733266}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:03:14 DISPATCHER: Starting worker discovery
20:03:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:03:14 DISPATCHER: Finished worker discovery
20:03:45 WORKER: done with job (4, 0, 22), trying to register it.
20:03:45 WORKER: registered result for job (4, 0, 22) with dispatcher
20:03:45 DISPATCHER: job (4, 0, 22) finished
20:03:45 DISPATCHER: register_result: lock acquired
20:03:45 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
20:03:45 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.039823617224001434, 'num_filters_1': 16, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.019792116016733266}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.021759835986242038, 'info': {'data05': 0.021759835986242038, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.039823617224001434, 'num_filters_1': 16, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.019792116016733266}"}}
exception: None

20:03:45 job_callback for (4, 0, 22) started
20:03:45 DISPATCHER: Trying to submit another job.
20:03:45 job_callback for (4, 0, 22) got condition
20:03:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:03:45 done building a new model for budget 44.444444 based on 17/42 split
Best loss for this budget:-0.794045





20:03:45 HBMASTER: Trying to run another job!
20:03:45 job_callback for (4, 0, 22) finished
20:03:45 start sampling a new configuration.
20:03:45 best_vector: [0, 1, 0.1715088360823145, 0.24338160715647528, 0.8101158141996158, 1, 0.33354277487884326, 0.16989608151305782, 0, 0, 1, 2, 0.4206092847900383, 0.5641837002264972, 0.7005417079847753, 0.9096680480662206], 0.0, inf, 0.00047786121970219215
20:03:45 done sampling a new configuration.
20:03:45 HBMASTER: schedule new run for iteration 4
20:03:45 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
20:03:45 HBMASTER: submitting job (4, 0, 23) to dispatcher
20:03:45 DISPATCHER: trying to submit job (4, 0, 23)
20:03:45 DISPATCHER: trying to notify the job_runner thread.
20:03:45 HBMASTER: job (4, 0, 23) submitted to dispatcher
20:03:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:03:45 DISPATCHER: Trying to submit another job.
20:03:45 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:03:45 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:03:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:03:45 WORKER: start processing job (4, 0, 23)
20:03:45 WORKER: args: ()
20:03:45 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0022030161056181825, 'num_filters_1': 26, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.016635654734256357, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 38, 'num_filters_3': 51, 'num_filters_4': 68, 'num_filters_5': 106}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:04:14 DISPATCHER: Starting worker discovery
20:04:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:04:14 DISPATCHER: Finished worker discovery
20:04:43 WORKER: done with job (4, 0, 23), trying to register it.
20:04:43 WORKER: registered result for job (4, 0, 23) with dispatcher
20:04:43 DISPATCHER: job (4, 0, 23) finished
20:04:43 DISPATCHER: register_result: lock acquired
20:04:43 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
20:04:43 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0022030161056181825, 'num_filters_1': 26, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.016635654734256357, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 38, 'num_filters_3': 51, 'num_filters_4': 68, 'num_filters_5': 106}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5833002534015054, 'info': {'data05': 0.5833002534015054, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0022030161056181825, 'num_filters_1': 26, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.016635654734256357, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 38, 'num_filters_3': 51, 'num_filters_4': 68, 'num_filters_5': 106}"}}
exception: None

20:04:43 job_callback for (4, 0, 23) started
20:04:43 DISPATCHER: Trying to submit another job.
20:04:43 job_callback for (4, 0, 23) got condition
20:04:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:04:43 done building a new model for budget 44.444444 based on 17/43 split
Best loss for this budget:-0.794045





20:04:43 HBMASTER: Trying to run another job!
20:04:43 job_callback for (4, 0, 23) finished
20:04:43 start sampling a new configuration.
20:04:43 best_vector: [3, 1, 0.23472032961906608, 0.5271325581122568, 0.9213325255811547, 1, 0.3495396247463205, 0.8846546042008867, 0, 0, 1, 0, 0.9696034939165794, 0.6392716987585858, 0.6496317755898342, 0.9079176074018236], 8.457433166120786e-29, 0.00011823918443788012, -1.5568467787926165e-06
20:04:43 done sampling a new configuration.
20:04:43 HBMASTER: schedule new run for iteration 4
20:04:43 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
20:04:43 HBMASTER: submitting job (4, 0, 24) to dispatcher
20:04:43 DISPATCHER: trying to submit job (4, 0, 24)
20:04:43 DISPATCHER: trying to notify the job_runner thread.
20:04:43 HBMASTER: job (4, 0, 24) submitted to dispatcher
20:04:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:04:43 DISPATCHER: Trying to submit another job.
20:04:43 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:04:43 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:04:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:04:43 WORKER: start processing job (4, 0, 24)
20:04:43 WORKER: args: ()
20:04:43 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002947410723279648, 'num_filters_1': 47, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.1415670479197554, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 120, 'num_filters_3': 60, 'num_filters_4': 61, 'num_filters_5': 106}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:05:14 DISPATCHER: Starting worker discovery
20:05:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:05:14 DISPATCHER: Finished worker discovery
20:05:39 WORKER: done with job (4, 0, 24), trying to register it.
20:05:39 WORKER: registered result for job (4, 0, 24) with dispatcher
20:05:39 DISPATCHER: job (4, 0, 24) finished
20:05:39 DISPATCHER: register_result: lock acquired
20:05:39 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
20:05:39 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002947410723279648, 'num_filters_1': 47, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.1415670479197554, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 120, 'num_filters_3': 60, 'num_filters_4': 61, 'num_filters_5': 106}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4402687727728317, 'info': {'data05': 0.4402687727728317, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002947410723279648, 'num_filters_1': 47, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.1415670479197554, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 120, 'num_filters_3': 60, 'num_filters_4': 61, 'num_filters_5': 106}"}}
exception: None

20:05:39 job_callback for (4, 0, 24) started
20:05:39 DISPATCHER: Trying to submit another job.
20:05:39 job_callback for (4, 0, 24) got condition
20:05:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:05:39 done building a new model for budget 44.444444 based on 17/44 split
Best loss for this budget:-0.794045





20:05:39 HBMASTER: Trying to run another job!
20:05:39 job_callback for (4, 0, 24) finished
20:05:39 start sampling a new configuration.
20:05:39 best_vector: [2, 2, 0.05270967275792389, 0.672542843734842, 0.32270914377260695, 1, 0.13095426709337732, 0.2461472457162205, 0, 2, 1, 0, 0.9139719822725894, 0.376573581938769, 0.24157510527368464, 0.9054011270733564], 6.434543027571657e-29, 0.00015541119170624178, -4.489534313939108e-06
20:05:39 done sampling a new configuration.
20:05:39 HBMASTER: schedule new run for iteration 4
20:05:39 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
20:05:39 HBMASTER: submitting job (4, 0, 25) to dispatcher
20:05:39 DISPATCHER: trying to submit job (4, 0, 25)
20:05:39 DISPATCHER: trying to notify the job_runner thread.
20:05:39 HBMASTER: job (4, 0, 25) submitted to dispatcher
20:05:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:05:39 DISPATCHER: Trying to submit another job.
20:05:39 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:05:39 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:05:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:05:39 WORKER: start processing job (4, 0, 25)
20:05:39 WORKER: args: ()
20:05:39 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0012747333423703865, 'num_filters_1': 64, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.02090474864447434, 'kernel_size_2': 3, 'num_filters_2': 107}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:06:14 DISPATCHER: Starting worker discovery
20:06:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:06:14 DISPATCHER: Finished worker discovery
20:06:38 WORKER: done with job (4, 0, 25), trying to register it.
20:06:38 WORKER: registered result for job (4, 0, 25) with dispatcher
20:06:38 DISPATCHER: job (4, 0, 25) finished
20:06:38 DISPATCHER: register_result: lock acquired
20:06:38 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
20:06:38 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0012747333423703865, 'num_filters_1': 64, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.02090474864447434, 'kernel_size_2': 3, 'num_filters_2': 107}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6438737850765675, 'info': {'data05': 0.6438737850765675, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0012747333423703865, 'num_filters_1': 64, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.02090474864447434, 'kernel_size_2': 3, 'num_filters_2': 107}"}}
exception: None

20:06:38 job_callback for (4, 0, 25) started
20:06:38 DISPATCHER: Trying to submit another job.
20:06:38 job_callback for (4, 0, 25) got condition
20:06:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:06:38 done building a new model for budget 44.444444 based on 17/45 split
Best loss for this budget:-0.794045





20:06:38 HBMASTER: Trying to run another job!
20:06:38 job_callback for (4, 0, 25) finished
20:06:38 start sampling a new configuration.
20:06:38 best_vector: [1, 0, 0.7957159731379446, 0.6626552079122352, 0.09107042220789162, 1, 0.6320656342557227, 0.38877173893066275, 2, 1, 2, 2, 0.5918448432412832, 0.7904822462148001, 0.8198276078707633, 0.9082585333525217], 6.925357062670285e-05, 1.553569284397437, 0.00010759022016049412
20:06:38 done sampling a new configuration.
20:06:38 HBMASTER: schedule new run for iteration 4
20:06:38 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
20:06:38 HBMASTER: submitting job (4, 0, 26) to dispatcher
20:06:38 DISPATCHER: trying to submit job (4, 0, 26)
20:06:38 DISPATCHER: trying to notify the job_runner thread.
20:06:38 HBMASTER: job (4, 0, 26) submitted to dispatcher
20:06:38 DISPATCHER: Trying to submit another job.
20:06:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:06:38 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:06:38 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:06:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:06:38 WORKER: start processing job (4, 0, 26)
20:06:38 WORKER: args: ()
20:06:38 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.039033001320092776, 'num_filters_1': 63, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.03204820380768878}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:07:14 DISPATCHER: Starting worker discovery
20:07:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:07:14 DISPATCHER: Finished worker discovery
20:07:35 WORKER: done with job (4, 0, 26), trying to register it.
20:07:35 WORKER: registered result for job (4, 0, 26) with dispatcher
20:07:35 DISPATCHER: job (4, 0, 26) finished
20:07:35 DISPATCHER: register_result: lock acquired
20:07:35 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
20:07:35 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.039033001320092776, 'num_filters_1': 63, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.03204820380768878}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3230916126651554, 'info': {'data05': 0.3230916126651554, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.039033001320092776, 'num_filters_1': 63, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.03204820380768878}"}}
exception: None

20:07:35 job_callback for (4, 0, 26) started
20:07:35 job_callback for (4, 0, 26) got condition
20:07:35 DISPATCHER: Trying to submit another job.
20:07:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:07:35 done building a new model for budget 44.444444 based on 17/45 split
Best loss for this budget:-0.794045





20:07:35 HBMASTER: Trying to run another job!
20:07:35 job_callback for (4, 0, 26) finished
20:07:35 ITERATION: Advancing config (4, 0, 1) to next budget 133.333333
20:07:35 ITERATION: Advancing config (4, 0, 4) to next budget 133.333333
20:07:35 ITERATION: Advancing config (4, 0, 6) to next budget 133.333333
20:07:35 ITERATION: Advancing config (4, 0, 10) to next budget 133.333333
20:07:35 ITERATION: Advancing config (4, 0, 12) to next budget 133.333333
20:07:35 ITERATION: Advancing config (4, 0, 18) to next budget 133.333333
20:07:35 ITERATION: Advancing config (4, 0, 20) to next budget 133.333333
20:07:35 ITERATION: Advancing config (4, 0, 23) to next budget 133.333333
20:07:35 ITERATION: Advancing config (4, 0, 25) to next budget 133.333333
20:07:35 HBMASTER: schedule new run for iteration 4
20:07:35 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
20:07:35 HBMASTER: submitting job (4, 0, 1) to dispatcher
20:07:35 DISPATCHER: trying to submit job (4, 0, 1)
20:07:35 DISPATCHER: trying to notify the job_runner thread.
20:07:35 HBMASTER: job (4, 0, 1) submitted to dispatcher
20:07:35 DISPATCHER: Trying to submit another job.
20:07:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:07:35 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:07:35 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:07:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:07:35 WORKER: start processing job (4, 0, 1)
20:07:35 WORKER: args: ()
20:07:35 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0071985418116446275, 'num_filters_1': 88, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.015446579014935883}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:08:14 DISPATCHER: Starting worker discovery
20:08:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:08:14 DISPATCHER: Finished worker discovery
20:09:14 DISPATCHER: Starting worker discovery
20:09:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:09:14 DISPATCHER: Finished worker discovery
20:10:06 WORKER: done with job (4, 0, 1), trying to register it.
20:10:06 WORKER: registered result for job (4, 0, 1) with dispatcher
20:10:06 DISPATCHER: job (4, 0, 1) finished
20:10:06 DISPATCHER: register_result: lock acquired
20:10:06 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
20:10:06 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0071985418116446275, 'num_filters_1': 88, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.015446579014935883}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.44919296438013107, 'info': {'data05': 0.44919296438013107, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0071985418116446275, 'num_filters_1': 88, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.015446579014935883}"}}
exception: None

20:10:06 job_callback for (4, 0, 1) started
20:10:06 DISPATCHER: Trying to submit another job.
20:10:06 job_callback for (4, 0, 1) got condition
20:10:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:10:06 HBMASTER: Trying to run another job!
20:10:06 job_callback for (4, 0, 1) finished
20:10:06 HBMASTER: schedule new run for iteration 4
20:10:06 HBMASTER: trying submitting job (4, 0, 4) to dispatcher
20:10:06 HBMASTER: submitting job (4, 0, 4) to dispatcher
20:10:06 DISPATCHER: trying to submit job (4, 0, 4)
20:10:06 DISPATCHER: trying to notify the job_runner thread.
20:10:06 HBMASTER: job (4, 0, 4) submitted to dispatcher
20:10:06 DISPATCHER: Trying to submit another job.
20:10:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:10:06 DISPATCHER: starting job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:10:06 DISPATCHER: job (4, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:10:06 WORKER: start processing job (4, 0, 4)
20:10:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:10:06 WORKER: args: ()
20:10:06 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0016785950516619418, 'num_filters_1': 78, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.011881675433017037}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:10:14 DISPATCHER: Starting worker discovery
20:10:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:10:14 DISPATCHER: Finished worker discovery
20:11:14 DISPATCHER: Starting worker discovery
20:11:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:11:14 DISPATCHER: Finished worker discovery
20:12:14 DISPATCHER: Starting worker discovery
20:12:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:12:14 DISPATCHER: Finished worker discovery
20:12:33 WORKER: done with job (4, 0, 4), trying to register it.
20:12:33 WORKER: registered result for job (4, 0, 4) with dispatcher
20:12:33 DISPATCHER: job (4, 0, 4) finished
20:12:33 DISPATCHER: register_result: lock acquired
20:12:33 DISPATCHER: job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
20:12:33 job_id: (4, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0016785950516619418, 'num_filters_1': 78, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.011881675433017037}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.31416701953052323, 'info': {'data05': 0.31416701953052323, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0016785950516619418, 'num_filters_1': 78, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.011881675433017037}"}}
exception: None

20:12:33 job_callback for (4, 0, 4) started
20:12:33 DISPATCHER: Trying to submit another job.
20:12:33 job_callback for (4, 0, 4) got condition
20:12:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:12:33 HBMASTER: Trying to run another job!
20:12:33 job_callback for (4, 0, 4) finished
20:12:33 HBMASTER: schedule new run for iteration 4
20:12:33 HBMASTER: trying submitting job (4, 0, 6) to dispatcher
20:12:33 HBMASTER: submitting job (4, 0, 6) to dispatcher
20:12:33 DISPATCHER: trying to submit job (4, 0, 6)
20:12:33 DISPATCHER: trying to notify the job_runner thread.
20:12:33 HBMASTER: job (4, 0, 6) submitted to dispatcher
20:12:33 DISPATCHER: Trying to submit another job.
20:12:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:12:33 DISPATCHER: starting job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:12:33 DISPATCHER: job (4, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:12:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:12:33 WORKER: start processing job (4, 0, 6)
20:12:33 WORKER: args: ()
20:12:33 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.05298222747912706, 'num_filters_1': 98, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.029814592133456063, 'kernel_size_2': 3, 'num_filters_2': 86}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:13:14 DISPATCHER: Starting worker discovery
20:13:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:13:14 DISPATCHER: Finished worker discovery
20:14:14 DISPATCHER: Starting worker discovery
20:14:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:14:14 DISPATCHER: Finished worker discovery
20:15:02 WORKER: done with job (4, 0, 6), trying to register it.
20:15:02 WORKER: registered result for job (4, 0, 6) with dispatcher
20:15:02 DISPATCHER: job (4, 0, 6) finished
20:15:02 DISPATCHER: register_result: lock acquired
20:15:02 DISPATCHER: job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
20:15:02 job_id: (4, 0, 6)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.05298222747912706, 'num_filters_1': 98, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.029814592133456063, 'kernel_size_2': 3, 'num_filters_2': 86}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.014917080510369263, 'info': {'data05': 0.014917080510369263, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.05298222747912706, 'num_filters_1': 98, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.029814592133456063, 'kernel_size_2': 3, 'num_filters_2': 86}"}}
exception: None

20:15:02 job_callback for (4, 0, 6) started
20:15:02 DISPATCHER: Trying to submit another job.
20:15:02 job_callback for (4, 0, 6) got condition
20:15:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:15:02 HBMASTER: Trying to run another job!
20:15:02 job_callback for (4, 0, 6) finished
20:15:02 HBMASTER: schedule new run for iteration 4
20:15:02 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
20:15:02 HBMASTER: submitting job (4, 0, 10) to dispatcher
20:15:02 DISPATCHER: trying to submit job (4, 0, 10)
20:15:02 DISPATCHER: trying to notify the job_runner thread.
20:15:02 HBMASTER: job (4, 0, 10) submitted to dispatcher
20:15:02 DISPATCHER: Trying to submit another job.
20:15:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:15:02 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:15:02 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:15:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:15:02 WORKER: start processing job (4, 0, 10)
20:15:02 WORKER: args: ()
20:15:02 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.003138715317859794, 'num_filters_1': 58, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.013098962434721452}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:15:14 DISPATCHER: Starting worker discovery
20:15:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:15:14 DISPATCHER: Finished worker discovery
20:16:14 DISPATCHER: Starting worker discovery
20:16:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:16:14 DISPATCHER: Finished worker discovery
20:17:14 DISPATCHER: Starting worker discovery
20:17:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:17:14 DISPATCHER: Finished worker discovery
20:17:34 WORKER: done with job (4, 0, 10), trying to register it.
20:17:34 WORKER: registered result for job (4, 0, 10) with dispatcher
20:17:34 DISPATCHER: job (4, 0, 10) finished
20:17:34 DISPATCHER: register_result: lock acquired
20:17:34 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
20:17:34 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.003138715317859794, 'num_filters_1': 58, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.013098962434721452}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.500873213212144, 'info': {'data05': 0.500873213212144, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.003138715317859794, 'num_filters_1': 58, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.013098962434721452}"}}
exception: None

20:17:34 job_callback for (4, 0, 10) started
20:17:34 DISPATCHER: Trying to submit another job.
20:17:34 job_callback for (4, 0, 10) got condition
20:17:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:17:34 HBMASTER: Trying to run another job!
20:17:34 job_callback for (4, 0, 10) finished
20:17:34 HBMASTER: schedule new run for iteration 4
20:17:34 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
20:17:34 HBMASTER: submitting job (4, 0, 12) to dispatcher
20:17:34 DISPATCHER: trying to submit job (4, 0, 12)
20:17:34 DISPATCHER: trying to notify the job_runner thread.
20:17:34 HBMASTER: job (4, 0, 12) submitted to dispatcher
20:17:34 DISPATCHER: Trying to submit another job.
20:17:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:17:34 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:17:34 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:17:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:17:34 WORKER: start processing job (4, 0, 12)
20:17:34 WORKER: args: ()
20:17:34 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0021500391716232302, 'num_filters_1': 54, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.0203751941291504, 'kernel_size_2': 7, 'num_filters_2': 127}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:18:14 DISPATCHER: Starting worker discovery
20:18:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:18:14 DISPATCHER: Finished worker discovery
20:19:14 DISPATCHER: Starting worker discovery
20:19:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:19:14 DISPATCHER: Finished worker discovery
20:20:08 WORKER: done with job (4, 0, 12), trying to register it.
20:20:08 WORKER: registered result for job (4, 0, 12) with dispatcher
20:20:08 DISPATCHER: job (4, 0, 12) finished
20:20:08 DISPATCHER: register_result: lock acquired
20:20:08 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
20:20:08 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0021500391716232302, 'num_filters_1': 54, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.0203751941291504, 'kernel_size_2': 7, 'num_filters_2': 127}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5667347329293582, 'info': {'data05': 0.5667347329293582, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0021500391716232302, 'num_filters_1': 54, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.0203751941291504, 'kernel_size_2': 7, 'num_filters_2': 127}"}}
exception: None

20:20:08 job_callback for (4, 0, 12) started
20:20:08 DISPATCHER: Trying to submit another job.
20:20:08 job_callback for (4, 0, 12) got condition
20:20:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:20:09 HBMASTER: Trying to run another job!
20:20:09 job_callback for (4, 0, 12) finished
20:20:09 HBMASTER: schedule new run for iteration 4
20:20:09 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
20:20:09 HBMASTER: submitting job (4, 0, 18) to dispatcher
20:20:09 DISPATCHER: trying to submit job (4, 0, 18)
20:20:09 DISPATCHER: trying to notify the job_runner thread.
20:20:09 HBMASTER: job (4, 0, 18) submitted to dispatcher
20:20:09 DISPATCHER: Trying to submit another job.
20:20:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:20:09 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:20:09 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:20:09 WORKER: start processing job (4, 0, 18)
20:20:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:20:09 WORKER: args: ()
20:20:09 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.028091436572120966, 'num_filters_1': 57, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.019276648411532444, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 46, 'num_filters_3': 36, 'num_filters_4': 19, 'num_filters_5': 106}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:20:14 DISPATCHER: Starting worker discovery
20:20:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:20:14 DISPATCHER: Finished worker discovery
20:21:14 DISPATCHER: Starting worker discovery
20:21:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:21:14 DISPATCHER: Finished worker discovery
20:22:14 DISPATCHER: Starting worker discovery
20:22:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:22:14 DISPATCHER: Finished worker discovery
20:22:36 WORKER: done with job (4, 0, 18), trying to register it.
20:22:36 WORKER: registered result for job (4, 0, 18) with dispatcher
20:22:36 DISPATCHER: job (4, 0, 18) finished
20:22:36 DISPATCHER: register_result: lock acquired
20:22:36 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
20:22:36 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.028091436572120966, 'num_filters_1': 57, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.019276648411532444, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 46, 'num_filters_3': 36, 'num_filters_4': 19, 'num_filters_5': 106}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.015461370486063736, 'info': {'data05': 0.015461370486063736, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.028091436572120966, 'num_filters_1': 57, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.019276648411532444, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 46, 'num_filters_3': 36, 'num_filters_4': 19, 'num_filters_5': 106}"}}
exception: None

20:22:36 job_callback for (4, 0, 18) started
20:22:36 DISPATCHER: Trying to submit another job.
20:22:36 job_callback for (4, 0, 18) got condition
20:22:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:22:36 HBMASTER: Trying to run another job!
20:22:36 job_callback for (4, 0, 18) finished
20:22:36 HBMASTER: schedule new run for iteration 4
20:22:36 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
20:22:36 HBMASTER: submitting job (4, 0, 20) to dispatcher
20:22:36 DISPATCHER: trying to submit job (4, 0, 20)
20:22:36 DISPATCHER: trying to notify the job_runner thread.
20:22:36 HBMASTER: job (4, 0, 20) submitted to dispatcher
20:22:36 DISPATCHER: Trying to submit another job.
20:22:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:22:36 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:22:36 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:22:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:22:36 WORKER: start processing job (4, 0, 20)
20:22:36 WORKER: args: ()
20:22:36 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.006844363328577427, 'num_filters_1': 114, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.01995704719416724, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 30, 'num_filters_3': 37}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:23:14 DISPATCHER: Starting worker discovery
20:23:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:23:14 DISPATCHER: Finished worker discovery
20:24:14 DISPATCHER: Starting worker discovery
20:24:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:24:14 DISPATCHER: Finished worker discovery
20:25:05 WORKER: done with job (4, 0, 20), trying to register it.
20:25:05 WORKER: registered result for job (4, 0, 20) with dispatcher
20:25:05 DISPATCHER: job (4, 0, 20) finished
20:25:05 DISPATCHER: register_result: lock acquired
20:25:05 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
20:25:05 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.006844363328577427, 'num_filters_1': 114, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.01995704719416724, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 30, 'num_filters_3': 37}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3154600487409668, 'info': {'data05': 0.3154600487409668, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.006844363328577427, 'num_filters_1': 114, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.01995704719416724, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 30, 'num_filters_3': 37}"}}
exception: None

20:25:05 job_callback for (4, 0, 20) started
20:25:05 job_callback for (4, 0, 20) got condition
20:25:05 DISPATCHER: Trying to submit another job.
20:25:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:25:05 HBMASTER: Trying to run another job!
20:25:05 job_callback for (4, 0, 20) finished
20:25:05 HBMASTER: schedule new run for iteration 4
20:25:05 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
20:25:05 HBMASTER: submitting job (4, 0, 23) to dispatcher
20:25:05 DISPATCHER: trying to submit job (4, 0, 23)
20:25:05 DISPATCHER: trying to notify the job_runner thread.
20:25:05 HBMASTER: job (4, 0, 23) submitted to dispatcher
20:25:05 DISPATCHER: Trying to submit another job.
20:25:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:25:05 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:25:05 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:25:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:25:05 WORKER: start processing job (4, 0, 23)
20:25:05 WORKER: args: ()
20:25:05 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0022030161056181825, 'num_filters_1': 26, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.016635654734256357, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 38, 'num_filters_3': 51, 'num_filters_4': 68, 'num_filters_5': 106}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:25:14 DISPATCHER: Starting worker discovery
20:25:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:25:14 DISPATCHER: Finished worker discovery
20:26:14 DISPATCHER: Starting worker discovery
20:26:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:26:15 DISPATCHER: Finished worker discovery
20:27:15 DISPATCHER: Starting worker discovery
20:27:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:27:15 DISPATCHER: Finished worker discovery
20:27:36 WORKER: done with job (4, 0, 23), trying to register it.
20:27:36 WORKER: registered result for job (4, 0, 23) with dispatcher
20:27:36 DISPATCHER: job (4, 0, 23) finished
20:27:36 DISPATCHER: register_result: lock acquired
20:27:36 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
20:27:36 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0022030161056181825, 'num_filters_1': 26, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.016635654734256357, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 38, 'num_filters_3': 51, 'num_filters_4': 68, 'num_filters_5': 106}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4537054662624011, 'info': {'data05': 0.4537054662624011, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0022030161056181825, 'num_filters_1': 26, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.016635654734256357, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 38, 'num_filters_3': 51, 'num_filters_4': 68, 'num_filters_5': 106}"}}
exception: None

20:27:36 job_callback for (4, 0, 23) started
20:27:36 DISPATCHER: Trying to submit another job.
20:27:36 job_callback for (4, 0, 23) got condition
20:27:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:27:36 HBMASTER: Trying to run another job!
20:27:36 job_callback for (4, 0, 23) finished
20:27:36 HBMASTER: schedule new run for iteration 4
20:27:36 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
20:27:36 HBMASTER: submitting job (4, 0, 25) to dispatcher
20:27:36 DISPATCHER: trying to submit job (4, 0, 25)
20:27:36 DISPATCHER: trying to notify the job_runner thread.
20:27:36 HBMASTER: job (4, 0, 25) submitted to dispatcher
20:27:36 DISPATCHER: Trying to submit another job.
20:27:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:27:36 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:27:36 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:27:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:27:36 WORKER: start processing job (4, 0, 25)
20:27:36 WORKER: args: ()
20:27:36 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0012747333423703865, 'num_filters_1': 64, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.02090474864447434, 'kernel_size_2': 3, 'num_filters_2': 107}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:28:15 DISPATCHER: Starting worker discovery
20:28:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:28:15 DISPATCHER: Finished worker discovery
20:29:15 DISPATCHER: Starting worker discovery
20:29:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:29:15 DISPATCHER: Finished worker discovery
20:30:09 WORKER: done with job (4, 0, 25), trying to register it.
20:30:09 WORKER: registered result for job (4, 0, 25) with dispatcher
20:30:09 DISPATCHER: job (4, 0, 25) finished
20:30:09 DISPATCHER: register_result: lock acquired
20:30:09 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
20:30:09 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0012747333423703865, 'num_filters_1': 64, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.02090474864447434, 'kernel_size_2': 3, 'num_filters_2': 107}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5638041087480261, 'info': {'data05': 0.5638041087480261, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0012747333423703865, 'num_filters_1': 64, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.02090474864447434, 'kernel_size_2': 3, 'num_filters_2': 107}"}}
exception: None

20:30:09 job_callback for (4, 0, 25) started
20:30:09 DISPATCHER: Trying to submit another job.
20:30:09 job_callback for (4, 0, 25) got condition
20:30:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:30:09 HBMASTER: Trying to run another job!
20:30:09 job_callback for (4, 0, 25) finished
20:30:09 ITERATION: Advancing config (4, 0, 10) to next budget 400.000000
20:30:09 ITERATION: Advancing config (4, 0, 12) to next budget 400.000000
20:30:09 ITERATION: Advancing config (4, 0, 25) to next budget 400.000000
20:30:09 HBMASTER: schedule new run for iteration 4
20:30:09 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
20:30:09 HBMASTER: submitting job (4, 0, 10) to dispatcher
20:30:09 DISPATCHER: trying to submit job (4, 0, 10)
20:30:09 DISPATCHER: trying to notify the job_runner thread.
20:30:09 HBMASTER: job (4, 0, 10) submitted to dispatcher
20:30:09 DISPATCHER: Trying to submit another job.
20:30:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:30:09 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:30:09 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:30:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:30:09 WORKER: start processing job (4, 0, 10)
20:30:09 WORKER: args: ()
20:30:09 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.003138715317859794, 'num_filters_1': 58, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.013098962434721452}, 'budget': 400.0, 'working_directory': '.'}
20:30:15 DISPATCHER: Starting worker discovery
20:30:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:30:15 DISPATCHER: Finished worker discovery
20:31:15 DISPATCHER: Starting worker discovery
20:31:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:31:15 DISPATCHER: Finished worker discovery
20:32:15 DISPATCHER: Starting worker discovery
20:32:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:32:15 DISPATCHER: Finished worker discovery
20:33:15 DISPATCHER: Starting worker discovery
20:33:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:33:15 DISPATCHER: Finished worker discovery
20:34:15 DISPATCHER: Starting worker discovery
20:34:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:34:15 DISPATCHER: Finished worker discovery
20:35:15 DISPATCHER: Starting worker discovery
20:35:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:35:15 DISPATCHER: Finished worker discovery
20:36:15 DISPATCHER: Starting worker discovery
20:36:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:36:15 DISPATCHER: Finished worker discovery
20:37:15 DISPATCHER: Starting worker discovery
20:37:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:37:15 DISPATCHER: Finished worker discovery
20:37:23 WORKER: done with job (4, 0, 10), trying to register it.
20:37:23 WORKER: registered result for job (4, 0, 10) with dispatcher
20:37:23 DISPATCHER: job (4, 0, 10) finished
20:37:23 DISPATCHER: register_result: lock acquired
20:37:23 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
20:37:23 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.003138715317859794, 'num_filters_1': 58, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.013098962434721452}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.4165612093537072, 'info': {'data05': 0.4165612093537072, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.003138715317859794, 'num_filters_1': 58, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.013098962434721452}"}}
exception: None

20:37:23 job_callback for (4, 0, 10) started
20:37:23 job_callback for (4, 0, 10) got condition
20:37:23 DISPATCHER: Trying to submit another job.
20:37:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:37:23 Only 13 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
20:37:23 HBMASTER: Trying to run another job!
20:37:23 job_callback for (4, 0, 10) finished
20:37:23 HBMASTER: schedule new run for iteration 4
20:37:23 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
20:37:23 HBMASTER: submitting job (4, 0, 12) to dispatcher
20:37:23 DISPATCHER: trying to submit job (4, 0, 12)
20:37:23 DISPATCHER: trying to notify the job_runner thread.
20:37:23 HBMASTER: job (4, 0, 12) submitted to dispatcher
20:37:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:37:23 DISPATCHER: Trying to submit another job.
20:37:23 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:37:23 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:37:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:37:23 WORKER: start processing job (4, 0, 12)
20:37:23 WORKER: args: ()
20:37:23 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0021500391716232302, 'num_filters_1': 54, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.0203751941291504, 'kernel_size_2': 7, 'num_filters_2': 127}, 'budget': 400.0, 'working_directory': '.'}
20:38:15 DISPATCHER: Starting worker discovery
20:38:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:38:15 DISPATCHER: Finished worker discovery
20:39:15 DISPATCHER: Starting worker discovery
20:39:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:39:15 DISPATCHER: Finished worker discovery
20:40:15 DISPATCHER: Starting worker discovery
20:40:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:40:15 DISPATCHER: Finished worker discovery
20:41:15 DISPATCHER: Starting worker discovery
20:41:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:41:15 DISPATCHER: Finished worker discovery
20:42:15 DISPATCHER: Starting worker discovery
20:42:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:42:15 DISPATCHER: Finished worker discovery
20:43:15 DISPATCHER: Starting worker discovery
20:43:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:43:15 DISPATCHER: Finished worker discovery
20:44:15 DISPATCHER: Starting worker discovery
20:44:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:44:15 DISPATCHER: Finished worker discovery
20:44:46 WORKER: done with job (4, 0, 12), trying to register it.
20:44:46 WORKER: registered result for job (4, 0, 12) with dispatcher
20:44:46 DISPATCHER: job (4, 0, 12) finished
20:44:46 DISPATCHER: register_result: lock acquired
20:44:46 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
20:44:46 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0021500391716232302, 'num_filters_1': 54, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.0203751941291504, 'kernel_size_2': 7, 'num_filters_2': 127}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.37177066523639757, 'info': {'data05': 0.37177066523639757, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0021500391716232302, 'num_filters_1': 54, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.0203751941291504, 'kernel_size_2': 7, 'num_filters_2': 127}"}}
exception: None

20:44:46 job_callback for (4, 0, 12) started
20:44:46 DISPATCHER: Trying to submit another job.
20:44:46 job_callback for (4, 0, 12) got condition
20:44:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:44:46 Only 14 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
20:44:46 HBMASTER: Trying to run another job!
20:44:46 job_callback for (4, 0, 12) finished
20:44:46 HBMASTER: schedule new run for iteration 4
20:44:46 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
20:44:46 HBMASTER: submitting job (4, 0, 25) to dispatcher
20:44:46 DISPATCHER: trying to submit job (4, 0, 25)
20:44:46 DISPATCHER: trying to notify the job_runner thread.
20:44:46 HBMASTER: job (4, 0, 25) submitted to dispatcher
20:44:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:44:46 DISPATCHER: Trying to submit another job.
20:44:46 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:44:46 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:44:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:44:46 WORKER: start processing job (4, 0, 25)
20:44:46 WORKER: args: ()
20:44:46 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0012747333423703865, 'num_filters_1': 64, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.02090474864447434, 'kernel_size_2': 3, 'num_filters_2': 107}, 'budget': 400.0, 'working_directory': '.'}
20:45:15 DISPATCHER: Starting worker discovery
20:45:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:45:15 DISPATCHER: Finished worker discovery
20:46:15 DISPATCHER: Starting worker discovery
20:46:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:46:15 DISPATCHER: Finished worker discovery
20:47:15 DISPATCHER: Starting worker discovery
20:47:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:47:15 DISPATCHER: Finished worker discovery
20:48:15 DISPATCHER: Starting worker discovery
20:48:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:48:15 DISPATCHER: Finished worker discovery
20:49:15 DISPATCHER: Starting worker discovery
20:49:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:49:15 DISPATCHER: Finished worker discovery
20:50:15 DISPATCHER: Starting worker discovery
20:50:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:50:15 DISPATCHER: Finished worker discovery
20:51:15 DISPATCHER: Starting worker discovery
20:51:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:51:15 DISPATCHER: Finished worker discovery
20:52:03 WORKER: done with job (4, 0, 25), trying to register it.
20:52:03 WORKER: registered result for job (4, 0, 25) with dispatcher
20:52:03 DISPATCHER: job (4, 0, 25) finished
20:52:03 DISPATCHER: register_result: lock acquired
20:52:03 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
20:52:03 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0012747333423703865, 'num_filters_1': 64, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.02090474864447434, 'kernel_size_2': 3, 'num_filters_2': 107}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.48219086171113945, 'info': {'data05': 0.48219086171113945, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0012747333423703865, 'num_filters_1': 64, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.02090474864447434, 'kernel_size_2': 3, 'num_filters_2': 107}"}}
exception: None

20:52:03 job_callback for (4, 0, 25) started
20:52:03 DISPATCHER: Trying to submit another job.
20:52:03 job_callback for (4, 0, 25) got condition
20:52:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:52:03 Only 15 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
20:52:03 HBMASTER: Trying to run another job!
20:52:03 job_callback for (4, 0, 25) finished
20:52:03 ITERATION: Advancing config (4, 0, 25) to next budget 1200.000000
20:52:03 HBMASTER: schedule new run for iteration 4
20:52:03 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
20:52:03 HBMASTER: submitting job (4, 0, 25) to dispatcher
20:52:03 DISPATCHER: trying to submit job (4, 0, 25)
20:52:03 DISPATCHER: trying to notify the job_runner thread.
20:52:03 HBMASTER: job (4, 0, 25) submitted to dispatcher
20:52:03 DISPATCHER: Trying to submit another job.
20:52:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:52:03 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:52:03 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
20:52:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:52:03 WORKER: start processing job (4, 0, 25)
20:52:03 WORKER: args: ()
20:52:03 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0012747333423703865, 'num_filters_1': 64, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.02090474864447434, 'kernel_size_2': 3, 'num_filters_2': 107}, 'budget': 1200.0, 'working_directory': '.'}
20:52:15 DISPATCHER: Starting worker discovery
20:52:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:52:15 DISPATCHER: Finished worker discovery
20:53:15 DISPATCHER: Starting worker discovery
20:53:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:53:15 DISPATCHER: Finished worker discovery
20:54:15 DISPATCHER: Starting worker discovery
20:54:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:54:15 DISPATCHER: Finished worker discovery
20:55:15 DISPATCHER: Starting worker discovery
20:55:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:55:15 DISPATCHER: Finished worker discovery
20:56:15 DISPATCHER: Starting worker discovery
20:56:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:56:15 DISPATCHER: Finished worker discovery
20:57:15 DISPATCHER: Starting worker discovery
20:57:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:57:15 DISPATCHER: Finished worker discovery
20:58:15 DISPATCHER: Starting worker discovery
20:58:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:58:15 DISPATCHER: Finished worker discovery
20:59:15 DISPATCHER: Starting worker discovery
20:59:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:59:15 DISPATCHER: Finished worker discovery
21:00:15 DISPATCHER: Starting worker discovery
21:00:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:00:15 DISPATCHER: Finished worker discovery
21:01:15 DISPATCHER: Starting worker discovery
21:01:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:01:15 DISPATCHER: Finished worker discovery
21:02:15 DISPATCHER: Starting worker discovery
21:02:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:02:15 DISPATCHER: Finished worker discovery
21:03:15 DISPATCHER: Starting worker discovery
21:03:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:03:15 DISPATCHER: Finished worker discovery
21:04:15 DISPATCHER: Starting worker discovery
21:04:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:04:15 DISPATCHER: Finished worker discovery
21:05:15 DISPATCHER: Starting worker discovery
21:05:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:05:15 DISPATCHER: Finished worker discovery
21:06:15 DISPATCHER: Starting worker discovery
21:06:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:06:15 DISPATCHER: Finished worker discovery
21:07:15 DISPATCHER: Starting worker discovery
21:07:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:07:15 DISPATCHER: Finished worker discovery
21:08:15 DISPATCHER: Starting worker discovery
21:08:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:08:15 DISPATCHER: Finished worker discovery
21:09:15 DISPATCHER: Starting worker discovery
21:09:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:09:15 DISPATCHER: Finished worker discovery
21:10:15 DISPATCHER: Starting worker discovery
21:10:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:10:15 DISPATCHER: Finished worker discovery
21:11:15 DISPATCHER: Starting worker discovery
21:11:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:11:15 DISPATCHER: Finished worker discovery
21:12:15 DISPATCHER: Starting worker discovery
21:12:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:12:15 DISPATCHER: Finished worker discovery
21:13:15 DISPATCHER: Starting worker discovery
21:13:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:13:15 DISPATCHER: Finished worker discovery
21:13:28 WORKER: done with job (4, 0, 25), trying to register it.
21:13:28 WORKER: registered result for job (4, 0, 25) with dispatcher
21:13:28 DISPATCHER: job (4, 0, 25) finished
21:13:28 DISPATCHER: register_result: lock acquired
21:13:28 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
21:13:28 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0012747333423703865, 'num_filters_1': 64, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.02090474864447434, 'kernel_size_2': 3, 'num_filters_2': 107}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.4637111082918055, 'info': {'data05': 0.4637111082918055, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0012747333423703865, 'num_filters_1': 64, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.02090474864447434, 'kernel_size_2': 3, 'num_filters_2': 107}"}}
exception: None

21:13:28 job_callback for (4, 0, 25) started
21:13:28 job_callback for (4, 0, 25) got condition
21:13:28 DISPATCHER: Trying to submit another job.
21:13:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:13:28 Only 9 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
21:13:28 HBMASTER: Trying to run another job!
21:13:28 job_callback for (4, 0, 25) finished
21:13:28 start sampling a new configuration.
21:13:28 done sampling a new configuration.
21:13:28 HBMASTER: schedule new run for iteration 5
21:13:28 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
21:13:28 HBMASTER: submitting job (5, 0, 0) to dispatcher
21:13:28 DISPATCHER: trying to submit job (5, 0, 0)
21:13:28 DISPATCHER: trying to notify the job_runner thread.
21:13:28 HBMASTER: job (5, 0, 0) submitted to dispatcher
21:13:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:13:28 DISPATCHER: Trying to submit another job.
21:13:28 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
21:13:28 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
21:13:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:13:28 WORKER: start processing job (5, 0, 0)
21:13:28 WORKER: args: ()
21:13:28 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.04093099614342373, 'num_filters_1': 127, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.13829587610216748, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 50, 'num_filters_3': 46, 'num_filters_4': 70, 'num_filters_5': 41}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:14:15 DISPATCHER: Starting worker discovery
21:14:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:14:15 DISPATCHER: Finished worker discovery
21:15:15 DISPATCHER: Starting worker discovery
21:15:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:15:15 DISPATCHER: Finished worker discovery
21:15:56 WORKER: done with job (5, 0, 0), trying to register it.
21:15:56 WORKER: registered result for job (5, 0, 0) with dispatcher
21:15:56 DISPATCHER: job (5, 0, 0) finished
21:15:56 DISPATCHER: register_result: lock acquired
21:15:56 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
21:15:56 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.04093099614342373, 'num_filters_1': 127, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.13829587610216748, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 50, 'num_filters_3': 46, 'num_filters_4': 70, 'num_filters_5': 41}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.04093099614342373, 'num_filters_1': 127, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.13829587610216748, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 50, 'num_filters_3': 46, 'num_filters_4': 70, 'num_filters_5': 41}"}}
exception: None

21:15:56 job_callback for (5, 0, 0) started
21:15:56 job_callback for (5, 0, 0) got condition
21:15:56 DISPATCHER: Trying to submit another job.
21:15:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:15:56 HBMASTER: Trying to run another job!
21:15:56 job_callback for (5, 0, 0) finished
21:15:56 start sampling a new configuration.
21:15:56 best_vector: [3, 2, 0.24998424752809156, 0.866749681102265, 0.17445551621943434, 1, 0.2108498899750893, 0.2456635208510063, 2, 0, 0, 1, 0.8378094522966971, 0.8708630158542878, 0.8726426972826614, 0.907264010647495], 4.8164783533617906e-05, 0.8358151908517366, 4.025685774148343e-05
21:15:56 done sampling a new configuration.
21:15:56 HBMASTER: schedule new run for iteration 5
21:15:56 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
21:15:56 HBMASTER: submitting job (5, 0, 1) to dispatcher
21:15:56 DISPATCHER: trying to submit job (5, 0, 1)
21:15:56 DISPATCHER: trying to notify the job_runner thread.
21:15:56 HBMASTER: job (5, 0, 1) submitted to dispatcher
21:15:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:15:56 DISPATCHER: Trying to submit another job.
21:15:56 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
21:15:56 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
21:15:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:15:56 WORKER: start processing job (5, 0, 1)
21:15:56 WORKER: args: ()
21:15:56 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.003162048267968778, 'num_filters_1': 97, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.020874477298744237}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:16:15 DISPATCHER: Starting worker discovery
21:16:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:16:15 DISPATCHER: Finished worker discovery
21:17:15 DISPATCHER: Starting worker discovery
21:17:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:17:15 DISPATCHER: Finished worker discovery
21:18:15 DISPATCHER: Starting worker discovery
21:18:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:18:15 DISPATCHER: Finished worker discovery
21:18:28 WORKER: done with job (5, 0, 1), trying to register it.
21:18:28 WORKER: registered result for job (5, 0, 1) with dispatcher
21:18:28 DISPATCHER: job (5, 0, 1) finished
21:18:28 DISPATCHER: register_result: lock acquired
21:18:28 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
21:18:28 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.003162048267968778, 'num_filters_1': 97, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.020874477298744237}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6076869030805185, 'info': {'data05': 0.6076869030805185, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.003162048267968778, 'num_filters_1': 97, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.020874477298744237}"}}
exception: None

21:18:28 job_callback for (5, 0, 1) started
21:18:28 DISPATCHER: Trying to submit another job.
21:18:28 job_callback for (5, 0, 1) got condition
21:18:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:18:28 HBMASTER: Trying to run another job!
21:18:28 job_callback for (5, 0, 1) finished
21:18:28 start sampling a new configuration.
21:18:29 best_vector: [0, 0, 0.7670464045514203, 0.4968479175200006, 0.5124665075843932, 1, 0.7069775674531188, 0.15692395003807702, 1, 1, 2, 1, 0.14915312335206138, 0.8880652103817255, 0.12824788421678013, 0.9115720088216896], 4.2487580530405567e-29, 0.00023536289605485204, -2.4538250432251426e-06
21:18:29 done sampling a new configuration.
21:18:29 HBMASTER: schedule new run for iteration 5
21:18:29 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
21:18:29 HBMASTER: submitting job (5, 0, 2) to dispatcher
21:18:29 DISPATCHER: trying to submit job (5, 0, 2)
21:18:29 DISPATCHER: trying to notify the job_runner thread.
21:18:29 HBMASTER: job (5, 0, 2) submitted to dispatcher
21:18:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:18:29 DISPATCHER: Trying to submit another job.
21:18:29 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
21:18:29 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
21:18:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:18:29 WORKER: start processing job (5, 0, 2)
21:18:29 WORKER: args: ()
21:18:29 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.03420525316228707, 'num_filters_1': 44, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.01600157627567056, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 21, 'num_filters_3': 101}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:19:15 DISPATCHER: Starting worker discovery
21:19:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:19:15 DISPATCHER: Finished worker discovery
21:20:15 DISPATCHER: Starting worker discovery
21:20:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:20:15 DISPATCHER: Finished worker discovery
21:20:56 WORKER: done with job (5, 0, 2), trying to register it.
21:20:56 WORKER: registered result for job (5, 0, 2) with dispatcher
21:20:56 DISPATCHER: job (5, 0, 2) finished
21:20:56 DISPATCHER: register_result: lock acquired
21:20:56 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
21:20:56 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.03420525316228707, 'num_filters_1': 44, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.01600157627567056, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 21, 'num_filters_3': 101}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.015338846842958468, 'info': {'data05': 0.015338846842958468, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.03420525316228707, 'num_filters_1': 44, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.01600157627567056, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 21, 'num_filters_3': 101}"}}
exception: None

21:20:56 job_callback for (5, 0, 2) started
21:20:56 DISPATCHER: Trying to submit another job.
21:20:56 job_callback for (5, 0, 2) got condition
21:20:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:20:56 HBMASTER: Trying to run another job!
21:20:56 job_callback for (5, 0, 2) finished
21:20:56 start sampling a new configuration.
21:20:56 done sampling a new configuration.
21:20:56 HBMASTER: schedule new run for iteration 5
21:20:56 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
21:20:56 HBMASTER: submitting job (5, 0, 3) to dispatcher
21:20:56 DISPATCHER: trying to submit job (5, 0, 3)
21:20:56 DISPATCHER: trying to notify the job_runner thread.
21:20:56 HBMASTER: job (5, 0, 3) submitted to dispatcher
21:20:56 DISPATCHER: Trying to submit another job.
21:20:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:20:56 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
21:20:56 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
21:20:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:20:56 WORKER: start processing job (5, 0, 3)
21:20:56 WORKER: args: ()
21:20:56 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.012245798608724625, 'num_filters_1': 35, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 10, 'weight_decay': 0.049765296832362915, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 65, 'num_filters_3': 57, 'num_filters_4': 39}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:21:15 DISPATCHER: Starting worker discovery
21:21:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:21:15 DISPATCHER: Finished worker discovery
21:22:15 DISPATCHER: Starting worker discovery
21:22:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:22:15 DISPATCHER: Finished worker discovery
21:23:15 DISPATCHER: Starting worker discovery
21:23:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:23:15 DISPATCHER: Finished worker discovery
21:23:31 WORKER: done with job (5, 0, 3), trying to register it.
21:23:31 WORKER: registered result for job (5, 0, 3) with dispatcher
21:23:31 DISPATCHER: job (5, 0, 3) finished
21:23:31 DISPATCHER: register_result: lock acquired
21:23:31 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
21:23:31 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.012245798608724625, 'num_filters_1': 35, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 10, 'weight_decay': 0.049765296832362915, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 65, 'num_filters_3': 57, 'num_filters_4': 39}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -7.971854708187848e-06, 'info': {'data05': 7.971854708187848e-06, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.012245798608724625, 'num_filters_1': 35, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 10, 'weight_decay': 0.049765296832362915, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 65, 'num_filters_3': 57, 'num_filters_4': 39}"}}
exception: None

21:23:31 job_callback for (5, 0, 3) started
21:23:31 DISPATCHER: Trying to submit another job.
21:23:31 job_callback for (5, 0, 3) got condition
21:23:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:23:31 HBMASTER: Trying to run another job!
21:23:31 job_callback for (5, 0, 3) finished
21:23:31 start sampling a new configuration.
21:23:31 best_vector: [2, 2, 0.5765553102714077, 0.6522017239939226, 0.6397291849619668, 1, 0.46219861129614126, 0.9408035153739632, 1, 0, 1, 0, 0.907705445962477, 0.13906803344530655, 0.15754378785682277, 0.90574692420328], 3.1472443560481575e-27, 3.1773827732132362e-06, -2.9539751782325097e-07
21:23:31 done sampling a new configuration.
21:23:31 HBMASTER: schedule new run for iteration 5
21:23:31 HBMASTER: trying submitting job (5, 0, 4) to dispatcher
21:23:31 HBMASTER: submitting job (5, 0, 4) to dispatcher
21:23:31 DISPATCHER: trying to submit job (5, 0, 4)
21:23:31 DISPATCHER: trying to notify the job_runner thread.
21:23:31 HBMASTER: job (5, 0, 4) submitted to dispatcher
21:23:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:23:31 DISPATCHER: Trying to submit another job.
21:23:31 DISPATCHER: starting job (5, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464
21:23:31 DISPATCHER: job (5, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
21:23:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:23:31 WORKER: start processing job (5, 0, 4)
21:23:31 WORKER: args: ()
21:23:31 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.014226911192013657, 'num_filters_1': 62, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.16749953029845743, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 106, 'num_filters_3': 21, 'num_filters_4': 22}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:24:15 DISPATCHER: Starting worker discovery
21:24:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:24:15 DISPATCHER: Finished worker discovery
21:25:15 DISPATCHER: Starting worker discovery
21:25:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:25:15 DISPATCHER: Finished worker discovery
21:25:57 WORKER: done with job (5, 0, 4), trying to register it.
21:25:57 WORKER: registered result for job (5, 0, 4) with dispatcher
21:25:57 DISPATCHER: job (5, 0, 4) finished
21:25:57 DISPATCHER: register_result: lock acquired
21:25:57 DISPATCHER: job (5, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
21:25:57 job_id: (5, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.014226911192013657, 'num_filters_1': 62, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.16749953029845743, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 106, 'num_filters_3': 21, 'num_filters_4': 22}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.07911968320146869, 'info': {'data05': 0.07911968320146869, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.014226911192013657, 'num_filters_1': 62, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.16749953029845743, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 106, 'num_filters_3': 21, 'num_filters_4': 22}"}}
exception: None

21:25:57 job_callback for (5, 0, 4) started
21:25:57 job_callback for (5, 0, 4) got condition
21:25:57 DISPATCHER: Trying to submit another job.
21:25:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:25:57 HBMASTER: Trying to run another job!
21:25:57 job_callback for (5, 0, 4) finished
21:25:57 start sampling a new configuration.
21:25:57 done sampling a new configuration.
21:25:57 HBMASTER: schedule new run for iteration 5
21:25:57 HBMASTER: trying submitting job (5, 0, 5) to dispatcher
21:25:57 HBMASTER: submitting job (5, 0, 5) to dispatcher
21:25:57 DISPATCHER: trying to submit job (5, 0, 5)
21:25:57 DISPATCHER: trying to notify the job_runner thread.
21:25:57 HBMASTER: job (5, 0, 5) submitted to dispatcher
21:25:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:25:57 DISPATCHER: Trying to submit another job.
21:25:57 DISPATCHER: starting job (5, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
21:25:57 DISPATCHER: job (5, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
21:25:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:25:57 WORKER: start processing job (5, 0, 5)
21:25:57 WORKER: args: ()
21:25:57 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.02024410668296505, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.017637114575356178, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 94, 'num_filters_3': 40, 'num_filters_4': 35}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:26:15 DISPATCHER: Starting worker discovery
21:26:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:26:15 DISPATCHER: Finished worker discovery
21:27:15 DISPATCHER: Starting worker discovery
21:27:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:27:16 DISPATCHER: Finished worker discovery
21:28:16 DISPATCHER: Starting worker discovery
21:28:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:28:16 DISPATCHER: Finished worker discovery
21:28:33 WORKER: done with job (5, 0, 5), trying to register it.
21:28:33 WORKER: registered result for job (5, 0, 5) with dispatcher
21:28:33 DISPATCHER: job (5, 0, 5) finished
21:28:33 DISPATCHER: register_result: lock acquired
21:28:33 DISPATCHER: job (5, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
21:28:33 job_id: (5, 0, 5)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.02024410668296505, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.017637114575356178, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 94, 'num_filters_3': 40, 'num_filters_4': 35}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.23399219982149858, 'info': {'data05': 0.23399219982149858, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.02024410668296505, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.017637114575356178, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 94, 'num_filters_3': 40, 'num_filters_4': 35}"}}
exception: None

21:28:33 job_callback for (5, 0, 5) started
21:28:33 DISPATCHER: Trying to submit another job.
21:28:33 job_callback for (5, 0, 5) got condition
21:28:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:28:33 HBMASTER: Trying to run another job!
21:28:33 job_callback for (5, 0, 5) finished
21:28:33 start sampling a new configuration.
21:28:33 best_vector: [3, 2, 0.7150760446022872, 0.3786959817186277, 0.9042796130183823, 1, 0.22039280026443298, 0.4677565800503729, 2, 1, 1, 0, 0.02893749590195044, 0.5761389065615268, 0.35413694468082874, 0.9104777607767489], 9.690416510741525e-31, 0.010319473872888035, -4.8292823370421715e-06
21:28:33 done sampling a new configuration.
21:28:33 HBMASTER: schedule new run for iteration 5
21:28:33 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
21:28:33 HBMASTER: submitting job (5, 0, 6) to dispatcher
21:28:33 DISPATCHER: trying to submit job (5, 0, 6)
21:28:33 DISPATCHER: trying to notify the job_runner thread.
21:28:33 HBMASTER: job (5, 0, 6) submitted to dispatcher
21:28:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:28:33 DISPATCHER: Trying to submit another job.
21:28:33 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464
21:28:33 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
21:28:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:28:33 WORKER: start processing job (5, 0, 6)
21:28:33 WORKER: args: ()
21:28:33 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.026924775399972088, 'num_filters_1': 35, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.04060367484836805, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 16, 'num_filters_3': 52, 'num_filters_4': 33, 'num_filters_5': 106}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:29:16 DISPATCHER: Starting worker discovery
21:29:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:29:16 DISPATCHER: Finished worker discovery
21:30:16 DISPATCHER: Starting worker discovery
21:30:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:30:16 DISPATCHER: Finished worker discovery
21:31:00 WORKER: done with job (5, 0, 6), trying to register it.
21:31:00 WORKER: registered result for job (5, 0, 6) with dispatcher
21:31:00 DISPATCHER: job (5, 0, 6) finished
21:31:00 DISPATCHER: register_result: lock acquired
21:31:00 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
21:31:00 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.026924775399972088, 'num_filters_1': 35, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.04060367484836805, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 16, 'num_filters_3': 52, 'num_filters_4': 33, 'num_filters_5': 106}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.009256479515849634, 'info': {'data05': 0.009256479515849634, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.026924775399972088, 'num_filters_1': 35, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.04060367484836805, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 16, 'num_filters_3': 52, 'num_filters_4': 33, 'num_filters_5': 106}"}}
exception: None

21:31:00 job_callback for (5, 0, 6) started
21:31:00 DISPATCHER: Trying to submit another job.
21:31:00 job_callback for (5, 0, 6) got condition
21:31:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:31:00 done building a new model for budget 133.333333 based on 17/28 split
Best loss for this budget:-0.607687





21:31:00 HBMASTER: Trying to run another job!
21:31:00 job_callback for (5, 0, 6) finished
21:31:00 start sampling a new configuration.
21:31:00 best_vector: [2, 2, 0.28989799326556576, 0.4626580938595353, 0.6559380031822778, 0, 0.8107190335634497, 0.03615330325754685, 1, 1, 1, 2, 0.5472373855412948, 0.04126697030140501, 0.421020222401042, 0.9068368907666131], 2.3250360692416463e-30, 0.004301008544466016, -5.962330311966474e-07
21:31:00 done sampling a new configuration.
21:31:00 HBMASTER: schedule new run for iteration 5
21:31:00 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
21:31:00 HBMASTER: submitting job (5, 0, 7) to dispatcher
21:31:00 DISPATCHER: trying to submit job (5, 0, 7)
21:31:00 DISPATCHER: trying to notify the job_runner thread.
21:31:00 HBMASTER: job (5, 0, 7) submitted to dispatcher
21:31:00 DISPATCHER: Trying to submit another job.
21:31:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:31:00 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464
21:31:00 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
21:31:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:31:00 WORKER: start processing job (5, 0, 7)
21:31:00 WORKER: args: ()
21:31:00 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0038001084111080907, 'num_filters_1': 41, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.011143882697544556, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 49, 'num_filters_3': 17, 'num_filters_4': 38}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:31:16 DISPATCHER: Starting worker discovery
21:31:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:31:16 DISPATCHER: Finished worker discovery
21:32:16 DISPATCHER: Starting worker discovery
21:32:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:32:16 DISPATCHER: Finished worker discovery
21:33:16 DISPATCHER: Starting worker discovery
21:33:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:33:16 DISPATCHER: Finished worker discovery
21:33:26 WORKER: done with job (5, 0, 7), trying to register it.
21:33:26 WORKER: registered result for job (5, 0, 7) with dispatcher
21:33:26 DISPATCHER: job (5, 0, 7) finished
21:33:26 DISPATCHER: register_result: lock acquired
21:33:26 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
21:33:26 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0038001084111080907, 'num_filters_1': 41, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.011143882697544556, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 49, 'num_filters_3': 17, 'num_filters_4': 38}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0035881152708419324, 'info': {'data05': 0.0035881152708419324, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0038001084111080907, 'num_filters_1': 41, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.011143882697544556, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 49, 'num_filters_3': 17, 'num_filters_4': 38}"}}
exception: None

21:33:26 job_callback for (5, 0, 7) started
21:33:26 job_callback for (5, 0, 7) got condition
21:33:26 DISPATCHER: Trying to submit another job.
21:33:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:33:26 done building a new model for budget 133.333333 based on 17/29 split
Best loss for this budget:-0.607687





21:33:26 HBMASTER: Trying to run another job!
21:33:26 job_callback for (5, 0, 7) finished
21:33:26 start sampling a new configuration.
21:33:26 best_vector: [2, 1, 0.08642555300035568, 0.37831796051426325, 0.0027973335777558977, 1, 0.731395703860425, 0.08622991154269244, 1, 2, 0, 2, 0.9454536462141843, 0.06530758264176129, 0.34537658095201457, 0.90867076232095], 5.209154196318085e-32, 0.19196974447537302, -1.4646591026449035e-07
21:33:26 done sampling a new configuration.
21:33:26 HBMASTER: schedule new run for iteration 5
21:33:26 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
21:33:26 HBMASTER: submitting job (5, 0, 8) to dispatcher
21:33:26 DISPATCHER: trying to submit job (5, 0, 8)
21:33:26 DISPATCHER: trying to notify the job_runner thread.
21:33:26 HBMASTER: job (5, 0, 8) submitted to dispatcher
21:33:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:33:26 DISPATCHER: Trying to submit another job.
21:33:26 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464
21:33:26 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
21:33:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:33:26 WORKER: start processing job (5, 0, 8)
21:33:26 WORKER: args: ()
21:33:26 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001488850551035738, 'num_filters_1': 35, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.012947553118940495}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:34:16 DISPATCHER: Starting worker discovery
21:34:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:34:16 DISPATCHER: Finished worker discovery
21:35:16 DISPATCHER: Starting worker discovery
21:35:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:35:16 DISPATCHER: Finished worker discovery
21:35:54 WORKER: done with job (5, 0, 8), trying to register it.
21:35:54 WORKER: registered result for job (5, 0, 8) with dispatcher
21:35:54 DISPATCHER: job (5, 0, 8) finished
21:35:54 DISPATCHER: register_result: lock acquired
21:35:54 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
21:35:54 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001488850551035738, 'num_filters_1': 35, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.012947553118940495}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5010255501446038, 'info': {'data05': 0.5010255501446038, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001488850551035738, 'num_filters_1': 35, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.012947553118940495}"}}
exception: None

21:35:54 job_callback for (5, 0, 8) started
21:35:54 DISPATCHER: Trying to submit another job.
21:35:54 job_callback for (5, 0, 8) got condition
21:35:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:35:54 done building a new model for budget 133.333333 based on 17/30 split
Best loss for this budget:-0.607687





21:35:54 HBMASTER: Trying to run another job!
21:35:54 job_callback for (5, 0, 8) finished
21:35:54 ITERATION: Advancing config (5, 0, 1) to next budget 400.000000
21:35:54 ITERATION: Advancing config (5, 0, 5) to next budget 400.000000
21:35:54 ITERATION: Advancing config (5, 0, 8) to next budget 400.000000
21:35:54 HBMASTER: schedule new run for iteration 5
21:35:54 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
21:35:54 HBMASTER: submitting job (5, 0, 1) to dispatcher
21:35:54 DISPATCHER: trying to submit job (5, 0, 1)
21:35:54 DISPATCHER: trying to notify the job_runner thread.
21:35:54 HBMASTER: job (5, 0, 1) submitted to dispatcher
21:35:54 DISPATCHER: Trying to submit another job.
21:35:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:35:54 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
21:35:54 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
21:35:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:35:54 WORKER: start processing job (5, 0, 1)
21:35:54 WORKER: args: ()
21:35:54 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.003162048267968778, 'num_filters_1': 97, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.020874477298744237}, 'budget': 400.0, 'working_directory': '.'}
21:36:16 DISPATCHER: Starting worker discovery
21:36:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:36:16 DISPATCHER: Finished worker discovery
21:37:16 DISPATCHER: Starting worker discovery
21:37:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:37:16 DISPATCHER: Finished worker discovery
21:38:16 DISPATCHER: Starting worker discovery
21:38:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:38:16 DISPATCHER: Finished worker discovery
21:39:16 DISPATCHER: Starting worker discovery
21:39:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:39:16 DISPATCHER: Finished worker discovery
21:40:16 DISPATCHER: Starting worker discovery
21:40:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:40:16 DISPATCHER: Finished worker discovery
21:41:16 DISPATCHER: Starting worker discovery
21:41:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:41:16 DISPATCHER: Finished worker discovery
21:42:16 DISPATCHER: Starting worker discovery
21:42:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:42:16 DISPATCHER: Finished worker discovery
21:43:06 WORKER: done with job (5, 0, 1), trying to register it.
21:43:06 WORKER: registered result for job (5, 0, 1) with dispatcher
21:43:06 DISPATCHER: job (5, 0, 1) finished
21:43:06 DISPATCHER: register_result: lock acquired
21:43:06 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
21:43:06 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.003162048267968778, 'num_filters_1': 97, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.020874477298744237}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5077795377161847, 'info': {'data05': 0.5077795377161847, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.003162048267968778, 'num_filters_1': 97, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.020874477298744237}"}}
exception: None

21:43:06 job_callback for (5, 0, 1) started
21:43:06 job_callback for (5, 0, 1) got condition
21:43:06 DISPATCHER: Trying to submit another job.
21:43:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:43:06 Only 16 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
21:43:06 HBMASTER: Trying to run another job!
21:43:06 job_callback for (5, 0, 1) finished
21:43:06 HBMASTER: schedule new run for iteration 5
21:43:06 HBMASTER: trying submitting job (5, 0, 5) to dispatcher
21:43:06 HBMASTER: submitting job (5, 0, 5) to dispatcher
21:43:06 DISPATCHER: trying to submit job (5, 0, 5)
21:43:06 DISPATCHER: trying to notify the job_runner thread.
21:43:06 HBMASTER: job (5, 0, 5) submitted to dispatcher
21:43:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:43:06 DISPATCHER: Trying to submit another job.
21:43:06 DISPATCHER: starting job (5, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
21:43:06 DISPATCHER: job (5, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
21:43:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:43:06 WORKER: start processing job (5, 0, 5)
21:43:06 WORKER: args: ()
21:43:06 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.02024410668296505, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.017637114575356178, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 94, 'num_filters_3': 40, 'num_filters_4': 35}, 'budget': 400.0, 'working_directory': '.'}
21:43:16 DISPATCHER: Starting worker discovery
21:43:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:43:16 DISPATCHER: Finished worker discovery
21:44:16 DISPATCHER: Starting worker discovery
21:44:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:44:16 DISPATCHER: Finished worker discovery
21:45:16 DISPATCHER: Starting worker discovery
21:45:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:45:16 DISPATCHER: Finished worker discovery
21:46:16 DISPATCHER: Starting worker discovery
21:46:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:46:16 DISPATCHER: Finished worker discovery
21:47:16 DISPATCHER: Starting worker discovery
21:47:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:47:16 DISPATCHER: Finished worker discovery
21:48:16 DISPATCHER: Starting worker discovery
21:48:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:48:16 DISPATCHER: Finished worker discovery
21:49:16 DISPATCHER: Starting worker discovery
21:49:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:49:16 DISPATCHER: Finished worker discovery
21:50:16 DISPATCHER: Starting worker discovery
21:50:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:50:16 DISPATCHER: Finished worker discovery
21:50:26 WORKER: done with job (5, 0, 5), trying to register it.
21:50:26 WORKER: registered result for job (5, 0, 5) with dispatcher
21:50:26 DISPATCHER: job (5, 0, 5) finished
21:50:26 DISPATCHER: register_result: lock acquired
21:50:26 DISPATCHER: job (5, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
21:50:26 job_id: (5, 0, 5)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.02024410668296505, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.017637114575356178, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 94, 'num_filters_3': 40, 'num_filters_4': 35}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.08606565258744667, 'info': {'data05': 0.08606565258744667, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.02024410668296505, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.017637114575356178, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 94, 'num_filters_3': 40, 'num_filters_4': 35}"}}
exception: None

21:50:26 job_callback for (5, 0, 5) started
21:50:26 DISPATCHER: Trying to submit another job.
21:50:26 job_callback for (5, 0, 5) got condition
21:50:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:50:26 HBMASTER: Trying to run another job!
21:50:26 job_callback for (5, 0, 5) finished
21:50:26 HBMASTER: schedule new run for iteration 5
21:50:26 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
21:50:26 HBMASTER: submitting job (5, 0, 8) to dispatcher
21:50:26 DISPATCHER: trying to submit job (5, 0, 8)
21:50:26 DISPATCHER: trying to notify the job_runner thread.
21:50:26 HBMASTER: job (5, 0, 8) submitted to dispatcher
21:50:26 DISPATCHER: Trying to submit another job.
21:50:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:50:26 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464
21:50:26 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
21:50:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:50:26 WORKER: start processing job (5, 0, 8)
21:50:26 WORKER: args: ()
21:50:26 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001488850551035738, 'num_filters_1': 35, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.012947553118940495}, 'budget': 400.0, 'working_directory': '.'}
21:51:16 DISPATCHER: Starting worker discovery
21:51:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:51:16 DISPATCHER: Finished worker discovery
21:52:16 DISPATCHER: Starting worker discovery
21:52:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:52:16 DISPATCHER: Finished worker discovery
21:53:16 DISPATCHER: Starting worker discovery
21:53:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:53:16 DISPATCHER: Finished worker discovery
21:54:16 DISPATCHER: Starting worker discovery
21:54:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:54:16 DISPATCHER: Finished worker discovery
21:55:16 DISPATCHER: Starting worker discovery
21:55:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:55:16 DISPATCHER: Finished worker discovery
21:56:16 DISPATCHER: Starting worker discovery
21:56:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:56:16 DISPATCHER: Finished worker discovery
21:57:16 DISPATCHER: Starting worker discovery
21:57:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:57:16 DISPATCHER: Finished worker discovery
21:57:26 WORKER: done with job (5, 0, 8), trying to register it.
21:57:26 WORKER: registered result for job (5, 0, 8) with dispatcher
21:57:26 DISPATCHER: job (5, 0, 8) finished
21:57:26 DISPATCHER: register_result: lock acquired
21:57:26 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
21:57:26 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001488850551035738, 'num_filters_1': 35, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.012947553118940495}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.48332696283808746, 'info': {'data05': 0.48332696283808746, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001488850551035738, 'num_filters_1': 35, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.012947553118940495}"}}
exception: None

21:57:26 job_callback for (5, 0, 8) started
21:57:26 DISPATCHER: Trying to submit another job.
21:57:26 job_callback for (5, 0, 8) got condition
21:57:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:57:26 HBMASTER: Trying to run another job!
21:57:26 job_callback for (5, 0, 8) finished
21:57:26 ITERATION: Advancing config (5, 0, 1) to next budget 1200.000000
21:57:26 HBMASTER: schedule new run for iteration 5
21:57:26 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
21:57:26 HBMASTER: submitting job (5, 0, 1) to dispatcher
21:57:26 DISPATCHER: trying to submit job (5, 0, 1)
21:57:26 DISPATCHER: trying to notify the job_runner thread.
21:57:26 HBMASTER: job (5, 0, 1) submitted to dispatcher
21:57:26 DISPATCHER: Trying to submit another job.
21:57:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:57:26 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
21:57:26 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
21:57:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:57:26 WORKER: start processing job (5, 0, 1)
21:57:26 WORKER: args: ()
21:57:26 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.003162048267968778, 'num_filters_1': 97, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.020874477298744237}, 'budget': 1200.0, 'working_directory': '.'}
21:58:16 DISPATCHER: Starting worker discovery
21:58:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:58:16 DISPATCHER: Finished worker discovery
21:59:16 DISPATCHER: Starting worker discovery
21:59:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:59:16 DISPATCHER: Finished worker discovery
22:00:16 DISPATCHER: Starting worker discovery
22:00:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:00:16 DISPATCHER: Finished worker discovery
22:01:16 DISPATCHER: Starting worker discovery
22:01:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:01:16 DISPATCHER: Finished worker discovery
22:02:16 DISPATCHER: Starting worker discovery
22:02:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:02:16 DISPATCHER: Finished worker discovery
22:03:16 DISPATCHER: Starting worker discovery
22:03:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:03:16 DISPATCHER: Finished worker discovery
22:04:16 DISPATCHER: Starting worker discovery
22:04:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:04:16 DISPATCHER: Finished worker discovery
22:05:16 DISPATCHER: Starting worker discovery
22:05:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:05:16 DISPATCHER: Finished worker discovery
22:06:16 DISPATCHER: Starting worker discovery
22:06:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:06:16 DISPATCHER: Finished worker discovery
22:07:16 DISPATCHER: Starting worker discovery
22:07:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:07:16 DISPATCHER: Finished worker discovery
22:08:16 DISPATCHER: Starting worker discovery
22:08:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:08:16 DISPATCHER: Finished worker discovery
22:09:16 DISPATCHER: Starting worker discovery
22:09:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:09:16 DISPATCHER: Finished worker discovery
22:10:16 DISPATCHER: Starting worker discovery
22:10:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:10:16 DISPATCHER: Finished worker discovery
22:11:16 DISPATCHER: Starting worker discovery
22:11:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:11:16 DISPATCHER: Finished worker discovery
22:12:16 DISPATCHER: Starting worker discovery
22:12:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:12:16 DISPATCHER: Finished worker discovery
22:13:16 DISPATCHER: Starting worker discovery
22:13:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:13:16 DISPATCHER: Finished worker discovery
22:14:16 DISPATCHER: Starting worker discovery
22:14:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:14:16 DISPATCHER: Finished worker discovery
22:15:16 DISPATCHER: Starting worker discovery
22:15:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:15:16 DISPATCHER: Finished worker discovery
22:16:16 DISPATCHER: Starting worker discovery
22:16:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:16:16 DISPATCHER: Finished worker discovery
22:17:16 DISPATCHER: Starting worker discovery
22:17:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:17:16 DISPATCHER: Finished worker discovery
22:18:16 DISPATCHER: Starting worker discovery
22:18:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:18:16 DISPATCHER: Finished worker discovery
22:18:34 WORKER: done with job (5, 0, 1), trying to register it.
22:18:34 WORKER: registered result for job (5, 0, 1) with dispatcher
22:18:34 DISPATCHER: job (5, 0, 1) finished
22:18:34 DISPATCHER: register_result: lock acquired
22:18:34 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
22:18:34 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.003162048267968778, 'num_filters_1': 97, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.020874477298744237}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.42479265939082467, 'info': {'data05': 0.42479265939082467, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.003162048267968778, 'num_filters_1': 97, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.020874477298744237}"}}
exception: None

22:18:34 job_callback for (5, 0, 1) started
22:18:34 DISPATCHER: Trying to submit another job.
22:18:34 job_callback for (5, 0, 1) got condition
22:18:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:18:34 Only 10 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
22:18:34 HBMASTER: Trying to run another job!
22:18:34 job_callback for (5, 0, 1) finished
22:18:34 start sampling a new configuration.
22:18:34 best_vector: [0, 1, 0.40973348661655673, 0.9461451686022923, 0.6819262392126252, 1, 0.4064674764419879, 0.2308235073796858, 1, 1, 2, 2, 0.18756155258619356, 0.03418732978432293, 0.7830095936801094, 0.9117708904050452], 2.8497600457057154e-31, 0.0350906737395976, -7.864334676339416e-05
22:18:34 done sampling a new configuration.
22:18:34 HBMASTER: schedule new run for iteration 6
22:18:34 HBMASTER: trying submitting job (6, 0, 0) to dispatcher
22:18:34 HBMASTER: submitting job (6, 0, 0) to dispatcher
22:18:34 DISPATCHER: trying to submit job (6, 0, 0)
22:18:34 DISPATCHER: trying to notify the job_runner thread.
22:18:34 HBMASTER: job (6, 0, 0) submitted to dispatcher
22:18:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:18:34 DISPATCHER: Trying to submit another job.
22:18:34 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:18:34 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:18:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:18:34 WORKER: start processing job (6, 0, 0)
22:18:34 WORKER: args: ()
22:18:34 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.006598830502679606, 'num_filters_1': 115, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.01996679259868746, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 23, 'num_filters_3': 17, 'num_filters_4': 81}, 'budget': 400.0, 'working_directory': '.'}
22:19:16 DISPATCHER: Starting worker discovery
22:19:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:19:16 DISPATCHER: Finished worker discovery
22:20:16 DISPATCHER: Starting worker discovery
22:20:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:20:16 DISPATCHER: Finished worker discovery
22:21:16 DISPATCHER: Starting worker discovery
22:21:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:21:16 DISPATCHER: Finished worker discovery
22:22:16 DISPATCHER: Starting worker discovery
22:22:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:22:16 DISPATCHER: Finished worker discovery
22:23:16 DISPATCHER: Starting worker discovery
22:23:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:23:16 DISPATCHER: Finished worker discovery
22:24:16 DISPATCHER: Starting worker discovery
22:24:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:24:16 DISPATCHER: Finished worker discovery
22:25:16 DISPATCHER: Starting worker discovery
22:25:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:25:16 DISPATCHER: Finished worker discovery
22:25:41 WORKER: done with job (6, 0, 0), trying to register it.
22:25:41 WORKER: registered result for job (6, 0, 0) with dispatcher
22:25:41 DISPATCHER: job (6, 0, 0) finished
22:25:41 DISPATCHER: register_result: lock acquired
22:25:41 DISPATCHER: job (6, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
22:25:41 job_id: (6, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.006598830502679606, 'num_filters_1': 115, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.01996679259868746, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 23, 'num_filters_3': 17, 'num_filters_4': 81}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.2662825080567615, 'info': {'data05': 0.2662825080567615, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.006598830502679606, 'num_filters_1': 115, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.01996679259868746, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 23, 'num_filters_3': 17, 'num_filters_4': 81}"}}
exception: None

22:25:41 job_callback for (6, 0, 0) started
22:25:41 DISPATCHER: Trying to submit another job.
22:25:41 job_callback for (6, 0, 0) got condition
22:25:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:25:41 HBMASTER: Trying to run another job!
22:25:41 job_callback for (6, 0, 0) finished
22:25:41 start sampling a new configuration.
22:25:41 best_vector: [0, 0, 0.5787996377576501, 0.6520292419576292, 0.7073286798223821, 0, 0.5559805174779379, 0.2563692431961589, 2, 1, 1, 2, 0.039598463643643306, 0.14085817788831334, 0.9079167426770525, 0.9102347536773211], 3.0286351940063896e-32, 0.33018172739291307, -6.250179045345196e-05
22:25:41 done sampling a new configuration.
22:25:41 HBMASTER: schedule new run for iteration 6
22:25:41 HBMASTER: trying submitting job (6, 0, 1) to dispatcher
22:25:41 HBMASTER: submitting job (6, 0, 1) to dispatcher
22:25:41 DISPATCHER: trying to submit job (6, 0, 1)
22:25:41 DISPATCHER: trying to notify the job_runner thread.
22:25:41 HBMASTER: job (6, 0, 1) submitted to dispatcher
22:25:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:25:41 DISPATCHER: Trying to submit another job.
22:25:41 DISPATCHER: starting job (6, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:25:41 DISPATCHER: job (6, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:25:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:25:41 WORKER: start processing job (6, 0, 1)
22:25:41 WORKER: args: ()
22:25:41 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.014374716078999487, 'num_filters_1': 62, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.02155480386298681, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 17, 'num_filters_3': 21, 'num_filters_4': 106}, 'budget': 400.0, 'working_directory': '.'}
22:26:16 DISPATCHER: Starting worker discovery
22:26:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:26:17 DISPATCHER: Finished worker discovery
22:27:17 DISPATCHER: Starting worker discovery
22:27:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:27:17 DISPATCHER: Finished worker discovery
22:28:17 DISPATCHER: Starting worker discovery
22:28:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:28:17 DISPATCHER: Finished worker discovery
22:29:17 DISPATCHER: Starting worker discovery
22:29:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:29:17 DISPATCHER: Finished worker discovery
22:30:17 DISPATCHER: Starting worker discovery
22:30:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:30:17 DISPATCHER: Finished worker discovery
22:31:17 DISPATCHER: Starting worker discovery
22:31:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:31:17 DISPATCHER: Finished worker discovery
22:32:17 DISPATCHER: Starting worker discovery
22:32:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:32:17 DISPATCHER: Finished worker discovery
22:32:41 WORKER: done with job (6, 0, 1), trying to register it.
22:32:41 WORKER: registered result for job (6, 0, 1) with dispatcher
22:32:41 DISPATCHER: job (6, 0, 1) finished
22:32:41 DISPATCHER: register_result: lock acquired
22:32:41 DISPATCHER: job (6, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
22:32:41 job_id: (6, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.014374716078999487, 'num_filters_1': 62, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.02155480386298681, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 17, 'num_filters_3': 21, 'num_filters_4': 106}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.014374716078999487, 'num_filters_1': 62, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.02155480386298681, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 17, 'num_filters_3': 21, 'num_filters_4': 106}"}}
exception: None

22:32:41 job_callback for (6, 0, 1) started
22:32:41 job_callback for (6, 0, 1) got condition
22:32:41 DISPATCHER: Trying to submit another job.
22:32:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:32:41 HBMASTER: Trying to run another job!
22:32:41 job_callback for (6, 0, 1) finished
22:32:41 start sampling a new configuration.
22:32:41 best_vector: [2, 0, 0.06504091287497438, 0.967940652380515, 0.7724223870834209, 1, 0.8261426576242312, 0.06886142732630933, 2, 0, 0, 2, 0.7273570186756801, 0.23640036429670266, 0.258073037630991, 0.9115941905901457], 6.748948297163019e-30, 0.0014817123438630566, -4.090502479320535e-06
22:32:41 done sampling a new configuration.
22:32:41 HBMASTER: schedule new run for iteration 6
22:32:41 HBMASTER: trying submitting job (6, 0, 2) to dispatcher
22:32:41 HBMASTER: submitting job (6, 0, 2) to dispatcher
22:32:41 DISPATCHER: trying to submit job (6, 0, 2)
22:32:41 DISPATCHER: trying to notify the job_runner thread.
22:32:41 HBMASTER: job (6, 0, 2) submitted to dispatcher
22:32:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:32:41 DISPATCHER: Trying to submit another job.
22:32:41 DISPATCHER: starting job (6, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:32:41 DISPATCHER: job (6, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:32:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:32:41 WORKER: start processing job (6, 0, 2)
22:32:41 WORKER: args: ()
22:32:41 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0013492170656475154, 'num_filters_1': 120, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.012291100860428901, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 72, 'num_filters_3': 26, 'num_filters_4': 27}, 'budget': 400.0, 'working_directory': '.'}
22:33:17 DISPATCHER: Starting worker discovery
22:33:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:33:17 DISPATCHER: Finished worker discovery
22:34:17 DISPATCHER: Starting worker discovery
22:34:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:34:17 DISPATCHER: Finished worker discovery
22:35:17 DISPATCHER: Starting worker discovery
22:35:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:35:17 DISPATCHER: Finished worker discovery
22:36:17 DISPATCHER: Starting worker discovery
22:36:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:36:17 DISPATCHER: Finished worker discovery
22:37:17 DISPATCHER: Starting worker discovery
22:37:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:37:17 DISPATCHER: Finished worker discovery
22:38:17 DISPATCHER: Starting worker discovery
22:38:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:38:17 DISPATCHER: Finished worker discovery
22:39:17 DISPATCHER: Starting worker discovery
22:39:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:39:17 DISPATCHER: Finished worker discovery
22:39:38 WORKER: done with job (6, 0, 2), trying to register it.
22:39:38 WORKER: registered result for job (6, 0, 2) with dispatcher
22:39:38 DISPATCHER: job (6, 0, 2) finished
22:39:38 DISPATCHER: register_result: lock acquired
22:39:38 DISPATCHER: job (6, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
22:39:38 job_id: (6, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0013492170656475154, 'num_filters_1': 120, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.012291100860428901, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 72, 'num_filters_3': 26, 'num_filters_4': 27}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7129216166423596, 'info': {'data05': 0.7129216166423596, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0013492170656475154, 'num_filters_1': 120, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.012291100860428901, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 72, 'num_filters_3': 26, 'num_filters_4': 27}"}}
exception: None

22:39:38 job_callback for (6, 0, 2) started
22:39:38 DISPATCHER: Trying to submit another job.
22:39:38 job_callback for (6, 0, 2) got condition
22:39:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:39:38 HBMASTER: Trying to run another job!
22:39:38 job_callback for (6, 0, 2) finished
22:39:38 start sampling a new configuration.
22:39:38 done sampling a new configuration.
22:39:38 HBMASTER: schedule new run for iteration 6
22:39:38 HBMASTER: trying submitting job (6, 0, 3) to dispatcher
22:39:38 HBMASTER: submitting job (6, 0, 3) to dispatcher
22:39:38 DISPATCHER: trying to submit job (6, 0, 3)
22:39:38 DISPATCHER: trying to notify the job_runner thread.
22:39:38 HBMASTER: job (6, 0, 3) submitted to dispatcher
22:39:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:39:38 DISPATCHER: Trying to submit another job.
22:39:38 DISPATCHER: starting job (6, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:39:38 DISPATCHER: job (6, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:39:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:39:38 WORKER: start processing job (6, 0, 3)
22:39:38 WORKER: args: ()
22:39:38 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004415966952736683, 'num_filters_1': 114, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.051174595932154225, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 24, 'num_filters_3': 69, 'num_filters_4': 16}, 'budget': 400.0, 'working_directory': '.'}
22:40:17 DISPATCHER: Starting worker discovery
22:40:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:40:17 DISPATCHER: Finished worker discovery
22:41:17 DISPATCHER: Starting worker discovery
22:41:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:41:17 DISPATCHER: Finished worker discovery
22:42:17 DISPATCHER: Starting worker discovery
22:42:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:42:17 DISPATCHER: Finished worker discovery
22:43:17 DISPATCHER: Starting worker discovery
22:43:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:43:17 DISPATCHER: Finished worker discovery
22:44:17 DISPATCHER: Starting worker discovery
22:44:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:44:17 DISPATCHER: Finished worker discovery
22:45:17 DISPATCHER: Starting worker discovery
22:45:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:45:17 DISPATCHER: Finished worker discovery
22:46:17 DISPATCHER: Starting worker discovery
22:46:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:46:17 DISPATCHER: Finished worker discovery
22:46:50 WORKER: done with job (6, 0, 3), trying to register it.
22:46:50 WORKER: registered result for job (6, 0, 3) with dispatcher
22:46:50 DISPATCHER: job (6, 0, 3) finished
22:46:50 DISPATCHER: register_result: lock acquired
22:46:50 DISPATCHER: job (6, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
22:46:50 job_id: (6, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004415966952736683, 'num_filters_1': 114, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.051174595932154225, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 24, 'num_filters_3': 69, 'num_filters_4': 16}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.26121761966434565, 'info': {'data05': 0.26121761966434565, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004415966952736683, 'num_filters_1': 114, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.051174595932154225, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 24, 'num_filters_3': 69, 'num_filters_4': 16}"}}
exception: None

22:46:50 job_callback for (6, 0, 3) started
22:46:50 DISPATCHER: Trying to submit another job.
22:46:50 job_callback for (6, 0, 3) got condition
22:46:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:46:50 HBMASTER: Trying to run another job!
22:46:50 job_callback for (6, 0, 3) finished
22:46:50 start sampling a new configuration.
22:46:50 done sampling a new configuration.
22:46:50 HBMASTER: schedule new run for iteration 6
22:46:50 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
22:46:50 HBMASTER: submitting job (6, 0, 4) to dispatcher
22:46:50 DISPATCHER: trying to submit job (6, 0, 4)
22:46:50 DISPATCHER: trying to notify the job_runner thread.
22:46:50 HBMASTER: job (6, 0, 4) submitted to dispatcher
22:46:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:46:50 DISPATCHER: Trying to submit another job.
22:46:50 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:46:50 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:46:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:46:50 WORKER: start processing job (6, 0, 4)
22:46:50 WORKER: args: ()
22:46:50 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.022126536838571395, 'num_filters_1': 80, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.022562282930828834, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 114, 'num_filters_3': 86, 'num_filters_4': 21}, 'budget': 400.0, 'working_directory': '.'}
22:47:17 DISPATCHER: Starting worker discovery
22:47:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:47:17 DISPATCHER: Finished worker discovery
22:48:17 DISPATCHER: Starting worker discovery
22:48:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:48:17 DISPATCHER: Finished worker discovery
22:49:17 DISPATCHER: Starting worker discovery
22:49:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:49:17 DISPATCHER: Finished worker discovery
22:50:17 DISPATCHER: Starting worker discovery
22:50:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:50:17 DISPATCHER: Finished worker discovery
22:51:17 DISPATCHER: Starting worker discovery
22:51:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:51:17 DISPATCHER: Finished worker discovery
22:52:17 DISPATCHER: Starting worker discovery
22:52:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:52:17 DISPATCHER: Finished worker discovery
22:53:17 DISPATCHER: Starting worker discovery
22:53:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:53:17 DISPATCHER: Finished worker discovery
22:53:56 WORKER: done with job (6, 0, 4), trying to register it.
22:53:56 WORKER: registered result for job (6, 0, 4) with dispatcher
22:53:56 DISPATCHER: job (6, 0, 4) finished
22:53:56 DISPATCHER: register_result: lock acquired
22:53:56 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
22:53:56 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.022126536838571395, 'num_filters_1': 80, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.022562282930828834, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 114, 'num_filters_3': 86, 'num_filters_4': 21}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.08144320903861536, 'info': {'data05': 0.08144320903861536, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.022126536838571395, 'num_filters_1': 80, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.022562282930828834, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 114, 'num_filters_3': 86, 'num_filters_4': 21}"}}
exception: None

22:53:56 job_callback for (6, 0, 4) started
22:53:56 DISPATCHER: Trying to submit another job.
22:53:56 job_callback for (6, 0, 4) got condition
22:53:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:53:56 HBMASTER: Trying to run another job!
22:53:56 job_callback for (6, 0, 4) finished
22:53:56 start sampling a new configuration.
22:53:56 best_vector: [2, 1, 0.36499183238103783, 0.5031341620081333, 0.016177412575944308, 1, 0.7450591480727337, 0.0008903280974603967, 2, 2, 1, 2, 0.6422873883027591, 0.8387898677669503, 0.5697073035900484, 0.9078284963928651], 0.0002516447416354569, 0.3104950484341608, 7.813444624230307e-05
22:53:56 done sampling a new configuration.
22:53:56 HBMASTER: schedule new run for iteration 6
22:53:56 HBMASTER: trying submitting job (6, 0, 5) to dispatcher
22:53:56 HBMASTER: submitting job (6, 0, 5) to dispatcher
22:53:56 DISPATCHER: trying to submit job (6, 0, 5)
22:53:56 DISPATCHER: trying to notify the job_runner thread.
22:53:56 HBMASTER: job (6, 0, 5) submitted to dispatcher
22:53:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:53:56 DISPATCHER: Trying to submit another job.
22:53:56 DISPATCHER: starting job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:53:56 DISPATCHER: job (6, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
22:53:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:53:56 WORKER: start processing job (6, 0, 5)
22:53:56 WORKER: args: ()
22:53:56 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.005370115972253127, 'num_filters_1': 45, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.01002670744716947}, 'budget': 400.0, 'working_directory': '.'}
22:54:17 DISPATCHER: Starting worker discovery
22:54:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:54:17 DISPATCHER: Finished worker discovery
22:55:17 DISPATCHER: Starting worker discovery
22:55:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:55:17 DISPATCHER: Finished worker discovery
22:56:17 DISPATCHER: Starting worker discovery
22:56:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:56:17 DISPATCHER: Finished worker discovery
22:57:17 DISPATCHER: Starting worker discovery
22:57:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:57:17 DISPATCHER: Finished worker discovery
22:58:17 DISPATCHER: Starting worker discovery
22:58:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:58:17 DISPATCHER: Finished worker discovery
22:59:17 DISPATCHER: Starting worker discovery
22:59:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:59:17 DISPATCHER: Finished worker discovery
23:00:17 DISPATCHER: Starting worker discovery
23:00:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:00:17 DISPATCHER: Finished worker discovery
23:00:57 WORKER: done with job (6, 0, 5), trying to register it.
23:00:57 WORKER: registered result for job (6, 0, 5) with dispatcher
23:00:57 DISPATCHER: job (6, 0, 5) finished
23:00:57 DISPATCHER: register_result: lock acquired
23:00:57 DISPATCHER: job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:00:57 job_id: (6, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.005370115972253127, 'num_filters_1': 45, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.01002670744716947}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.45329794494615994, 'info': {'data05': 0.45329794494615994, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.005370115972253127, 'num_filters_1': 45, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.01002670744716947}"}}
exception: None

23:00:57 job_callback for (6, 0, 5) started
23:00:57 job_callback for (6, 0, 5) got condition
23:00:57 DISPATCHER: Trying to submit another job.
23:00:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:00:57 HBMASTER: Trying to run another job!
23:00:57 job_callback for (6, 0, 5) finished
23:00:57 ITERATION: Advancing config (6, 0, 2) to next budget 1200.000000
23:00:57 ITERATION: Advancing config (6, 0, 5) to next budget 1200.000000
23:00:57 HBMASTER: schedule new run for iteration 6
23:00:57 HBMASTER: trying submitting job (6, 0, 2) to dispatcher
23:00:57 HBMASTER: submitting job (6, 0, 2) to dispatcher
23:00:57 DISPATCHER: trying to submit job (6, 0, 2)
23:00:57 DISPATCHER: trying to notify the job_runner thread.
23:00:57 HBMASTER: job (6, 0, 2) submitted to dispatcher
23:00:57 DISPATCHER: Trying to submit another job.
23:00:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:00:57 DISPATCHER: starting job (6, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:00:57 DISPATCHER: job (6, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:00:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:00:57 WORKER: start processing job (6, 0, 2)
23:00:57 WORKER: args: ()
23:00:57 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0013492170656475154, 'num_filters_1': 120, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.012291100860428901, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 72, 'num_filters_3': 26, 'num_filters_4': 27}, 'budget': 1200.0, 'working_directory': '.'}
23:01:17 DISPATCHER: Starting worker discovery
23:01:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:01:17 DISPATCHER: Finished worker discovery
23:02:17 DISPATCHER: Starting worker discovery
23:02:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:02:17 DISPATCHER: Finished worker discovery
23:03:17 DISPATCHER: Starting worker discovery
23:03:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:03:17 DISPATCHER: Finished worker discovery
23:04:17 DISPATCHER: Starting worker discovery
23:04:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:04:17 DISPATCHER: Finished worker discovery
23:05:17 DISPATCHER: Starting worker discovery
23:05:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:05:17 DISPATCHER: Finished worker discovery
23:06:17 DISPATCHER: Starting worker discovery
23:06:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:06:17 DISPATCHER: Finished worker discovery
23:07:17 DISPATCHER: Starting worker discovery
23:07:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:07:17 DISPATCHER: Finished worker discovery
23:08:17 DISPATCHER: Starting worker discovery
23:08:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:08:17 DISPATCHER: Finished worker discovery
23:09:17 DISPATCHER: Starting worker discovery
23:09:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:09:17 DISPATCHER: Finished worker discovery
23:10:17 DISPATCHER: Starting worker discovery
23:10:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:10:17 DISPATCHER: Finished worker discovery
23:11:17 DISPATCHER: Starting worker discovery
23:11:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:11:17 DISPATCHER: Finished worker discovery
23:12:17 DISPATCHER: Starting worker discovery
23:12:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:12:17 DISPATCHER: Finished worker discovery
23:13:17 DISPATCHER: Starting worker discovery
23:13:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:13:17 DISPATCHER: Finished worker discovery
23:14:17 DISPATCHER: Starting worker discovery
23:14:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:14:17 DISPATCHER: Finished worker discovery
23:15:17 DISPATCHER: Starting worker discovery
23:15:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:15:17 DISPATCHER: Finished worker discovery
23:16:17 DISPATCHER: Starting worker discovery
23:16:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:16:17 DISPATCHER: Finished worker discovery
23:17:17 DISPATCHER: Starting worker discovery
23:17:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:17:17 DISPATCHER: Finished worker discovery
23:18:17 DISPATCHER: Starting worker discovery
23:18:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:18:17 DISPATCHER: Finished worker discovery
23:19:17 DISPATCHER: Starting worker discovery
23:19:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:19:17 DISPATCHER: Finished worker discovery
23:20:17 DISPATCHER: Starting worker discovery
23:20:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:20:17 DISPATCHER: Finished worker discovery
23:21:17 DISPATCHER: Starting worker discovery
23:21:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:21:17 DISPATCHER: Finished worker discovery
23:21:27 WORKER: done with job (6, 0, 2), trying to register it.
23:21:27 WORKER: registered result for job (6, 0, 2) with dispatcher
23:21:27 DISPATCHER: job (6, 0, 2) finished
23:21:27 DISPATCHER: register_result: lock acquired
23:21:27 DISPATCHER: job (6, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:21:27 job_id: (6, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0013492170656475154, 'num_filters_1': 120, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.012291100860428901, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 72, 'num_filters_3': 26, 'num_filters_4': 27}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5126356128436873, 'info': {'data05': 0.5126356128436873, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0013492170656475154, 'num_filters_1': 120, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.012291100860428901, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 72, 'num_filters_3': 26, 'num_filters_4': 27}"}}
exception: None

23:21:27 job_callback for (6, 0, 2) started
23:21:27 job_callback for (6, 0, 2) got condition
23:21:27 DISPATCHER: Trying to submit another job.
23:21:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:21:27 Only 11 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
23:21:27 HBMASTER: Trying to run another job!
23:21:27 job_callback for (6, 0, 2) finished
23:21:27 HBMASTER: schedule new run for iteration 6
23:21:27 HBMASTER: trying submitting job (6, 0, 5) to dispatcher
23:21:27 HBMASTER: submitting job (6, 0, 5) to dispatcher
23:21:27 DISPATCHER: trying to submit job (6, 0, 5)
23:21:27 DISPATCHER: trying to notify the job_runner thread.
23:21:27 HBMASTER: job (6, 0, 5) submitted to dispatcher
23:21:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:21:27 DISPATCHER: Trying to submit another job.
23:21:27 DISPATCHER: starting job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:21:27 DISPATCHER: job (6, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:21:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:21:27 WORKER: start processing job (6, 0, 5)
23:21:27 WORKER: args: ()
23:21:27 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.005370115972253127, 'num_filters_1': 45, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.01002670744716947}, 'budget': 1200.0, 'working_directory': '.'}
23:22:17 DISPATCHER: Starting worker discovery
23:22:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:22:17 DISPATCHER: Finished worker discovery
23:23:17 DISPATCHER: Starting worker discovery
23:23:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:23:17 DISPATCHER: Finished worker discovery
23:24:17 DISPATCHER: Starting worker discovery
23:24:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:24:17 DISPATCHER: Finished worker discovery
23:25:17 DISPATCHER: Starting worker discovery
23:25:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:25:17 DISPATCHER: Finished worker discovery
23:26:17 DISPATCHER: Starting worker discovery
23:26:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:26:17 DISPATCHER: Finished worker discovery
23:27:17 DISPATCHER: Starting worker discovery
23:27:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:27:17 DISPATCHER: Finished worker discovery
23:28:17 DISPATCHER: Starting worker discovery
23:28:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:28:17 DISPATCHER: Finished worker discovery
23:29:17 DISPATCHER: Starting worker discovery
23:29:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:29:17 DISPATCHER: Finished worker discovery
23:30:17 DISPATCHER: Starting worker discovery
23:30:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:30:17 DISPATCHER: Finished worker discovery
23:31:17 DISPATCHER: Starting worker discovery
23:31:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:31:17 DISPATCHER: Finished worker discovery
23:32:17 DISPATCHER: Starting worker discovery
23:32:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:32:17 DISPATCHER: Finished worker discovery
23:33:17 DISPATCHER: Starting worker discovery
23:33:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:33:17 DISPATCHER: Finished worker discovery
23:34:17 DISPATCHER: Starting worker discovery
23:34:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:34:17 DISPATCHER: Finished worker discovery
23:35:17 DISPATCHER: Starting worker discovery
23:35:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:35:17 DISPATCHER: Finished worker discovery
23:36:17 DISPATCHER: Starting worker discovery
23:36:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:36:17 DISPATCHER: Finished worker discovery
23:37:17 DISPATCHER: Starting worker discovery
23:37:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:37:17 DISPATCHER: Finished worker discovery
23:38:17 DISPATCHER: Starting worker discovery
23:38:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:38:17 DISPATCHER: Finished worker discovery
23:39:17 DISPATCHER: Starting worker discovery
23:39:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:39:17 DISPATCHER: Finished worker discovery
23:40:17 DISPATCHER: Starting worker discovery
23:40:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:40:17 DISPATCHER: Finished worker discovery
23:41:17 DISPATCHER: Starting worker discovery
23:41:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:41:17 DISPATCHER: Finished worker discovery
23:42:07 WORKER: done with job (6, 0, 5), trying to register it.
23:42:07 WORKER: registered result for job (6, 0, 5) with dispatcher
23:42:07 DISPATCHER: job (6, 0, 5) finished
23:42:07 DISPATCHER: register_result: lock acquired
23:42:07 DISPATCHER: job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
23:42:07 job_id: (6, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.005370115972253127, 'num_filters_1': 45, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.01002670744716947}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.3826725034832277, 'info': {'data05': 0.3826725034832277, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.005370115972253127, 'num_filters_1': 45, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.01002670744716947}"}}
exception: None

23:42:07 job_callback for (6, 0, 5) started
23:42:07 job_callback for (6, 0, 5) got condition
23:42:07 DISPATCHER: Trying to submit another job.
23:42:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:42:07 Only 12 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
23:42:07 HBMASTER: Trying to run another job!
23:42:07 job_callback for (6, 0, 5) finished
23:42:07 start sampling a new configuration.
23:42:07 best_vector: [1, 1, 0.06649922198234705, 0.18837559736888906, 0.784666546312099, 1, 0.5940655323768782, 0.25455853129925077, 0, 2, 1, 2, 0.2955599874037046, 0.7536705125412086, 0.8514240971046187, 0.9098399956815324], 7.260221764290227e-06, 2.2756007167256795, 1.6521365850406217e-05
23:42:07 done sampling a new configuration.
23:42:07 HBMASTER: schedule new run for iteration 7
23:42:07 HBMASTER: trying submitting job (7, 0, 0) to dispatcher
23:42:07 HBMASTER: submitting job (7, 0, 0) to dispatcher
23:42:07 DISPATCHER: trying to submit job (7, 0, 0)
23:42:07 DISPATCHER: trying to notify the job_runner thread.
23:42:07 HBMASTER: job (7, 0, 0) submitted to dispatcher
23:42:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:42:07 DISPATCHER: Trying to submit another job.
23:42:07 DISPATCHER: starting job (7, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:42:07 DISPATCHER: job (7, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
23:42:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:42:07 WORKER: start processing job (7, 0, 0)
23:42:07 WORKER: args: ()
23:42:07 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0013583085798896007, 'num_filters_1': 23, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.021438198354863294, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 29, 'num_filters_3': 76, 'num_filters_4': 94}, 'budget': 1200.0, 'working_directory': '.'}
23:42:17 DISPATCHER: Starting worker discovery
23:42:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:42:17 DISPATCHER: Finished worker discovery
23:43:17 DISPATCHER: Starting worker discovery
23:43:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:43:18 DISPATCHER: Finished worker discovery
23:44:18 DISPATCHER: Starting worker discovery
23:44:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:44:18 DISPATCHER: Finished worker discovery
23:45:18 DISPATCHER: Starting worker discovery
23:45:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:45:18 DISPATCHER: Finished worker discovery
23:46:18 DISPATCHER: Starting worker discovery
23:46:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:46:18 DISPATCHER: Finished worker discovery
23:47:18 DISPATCHER: Starting worker discovery
23:47:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:47:18 DISPATCHER: Finished worker discovery
23:48:18 DISPATCHER: Starting worker discovery
23:48:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:48:18 DISPATCHER: Finished worker discovery
23:49:18 DISPATCHER: Starting worker discovery
23:49:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:49:18 DISPATCHER: Finished worker discovery
23:50:18 DISPATCHER: Starting worker discovery
23:50:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:50:18 DISPATCHER: Finished worker discovery
23:51:18 DISPATCHER: Starting worker discovery
23:51:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:51:18 DISPATCHER: Finished worker discovery
23:52:18 DISPATCHER: Starting worker discovery
23:52:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:52:18 DISPATCHER: Finished worker discovery
23:53:18 DISPATCHER: Starting worker discovery
23:53:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:53:18 DISPATCHER: Finished worker discovery
23:54:18 DISPATCHER: Starting worker discovery
23:54:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:54:18 DISPATCHER: Finished worker discovery
23:55:18 DISPATCHER: Starting worker discovery
23:55:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:55:18 DISPATCHER: Finished worker discovery
23:56:18 DISPATCHER: Starting worker discovery
23:56:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:56:18 DISPATCHER: Finished worker discovery
23:57:18 DISPATCHER: Starting worker discovery
23:57:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:57:18 DISPATCHER: Finished worker discovery
23:58:18 DISPATCHER: Starting worker discovery
23:58:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:58:18 DISPATCHER: Finished worker discovery
23:59:18 DISPATCHER: Starting worker discovery
23:59:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:59:18 DISPATCHER: Finished worker discovery
00:00:18 DISPATCHER: Starting worker discovery
00:00:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:00:18 DISPATCHER: Finished worker discovery
00:01:18 DISPATCHER: Starting worker discovery
00:01:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:01:18 DISPATCHER: Finished worker discovery
00:02:18 DISPATCHER: Starting worker discovery
00:02:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:02:18 DISPATCHER: Finished worker discovery
00:02:50 WORKER: done with job (7, 0, 0), trying to register it.
00:02:50 WORKER: registered result for job (7, 0, 0) with dispatcher
00:02:50 DISPATCHER: job (7, 0, 0) finished
00:02:50 DISPATCHER: register_result: lock acquired
00:02:50 DISPATCHER: job (7, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
00:02:50 job_id: (7, 0, 0)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0013583085798896007, 'num_filters_1': 23, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.021438198354863294, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 29, 'num_filters_3': 76, 'num_filters_4': 94}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.3612029028555219, 'info': {'data05': 0.3612029028555219, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0013583085798896007, 'num_filters_1': 23, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.021438198354863294, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 29, 'num_filters_3': 76, 'num_filters_4': 94}"}}
exception: None

00:02:50 job_callback for (7, 0, 0) started
00:02:50 DISPATCHER: Trying to submit another job.
00:02:50 job_callback for (7, 0, 0) got condition
00:02:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:02:50 Only 13 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
00:02:50 HBMASTER: Trying to run another job!
00:02:50 job_callback for (7, 0, 0) finished
00:02:50 start sampling a new configuration.
00:02:50 done sampling a new configuration.
00:02:50 HBMASTER: schedule new run for iteration 7
00:02:50 HBMASTER: trying submitting job (7, 0, 1) to dispatcher
00:02:50 HBMASTER: submitting job (7, 0, 1) to dispatcher
00:02:50 DISPATCHER: trying to submit job (7, 0, 1)
00:02:50 DISPATCHER: trying to notify the job_runner thread.
00:02:50 HBMASTER: job (7, 0, 1) submitted to dispatcher
00:02:50 DISPATCHER: Trying to submit another job.
00:02:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:02:50 DISPATCHER: starting job (7, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:02:50 DISPATCHER: job (7, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:02:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:02:50 WORKER: start processing job (7, 0, 1)
00:02:50 WORKER: args: ()
00:02:50 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.09969328008963321, 'num_filters_1': 34, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.0460568410234462}, 'budget': 1200.0, 'working_directory': '.'}
00:03:18 DISPATCHER: Starting worker discovery
00:03:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:03:18 DISPATCHER: Finished worker discovery
00:04:18 DISPATCHER: Starting worker discovery
00:04:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:04:18 DISPATCHER: Finished worker discovery
00:05:18 DISPATCHER: Starting worker discovery
00:05:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:05:18 DISPATCHER: Finished worker discovery
00:06:18 DISPATCHER: Starting worker discovery
00:06:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:06:18 DISPATCHER: Finished worker discovery
00:07:18 DISPATCHER: Starting worker discovery
00:07:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:07:18 DISPATCHER: Finished worker discovery
00:08:18 DISPATCHER: Starting worker discovery
00:08:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:08:18 DISPATCHER: Finished worker discovery
00:09:18 DISPATCHER: Starting worker discovery
00:09:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:09:18 DISPATCHER: Finished worker discovery
00:10:18 DISPATCHER: Starting worker discovery
00:10:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:10:18 DISPATCHER: Finished worker discovery
00:11:18 DISPATCHER: Starting worker discovery
00:11:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:11:18 DISPATCHER: Finished worker discovery
00:12:18 DISPATCHER: Starting worker discovery
00:12:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:12:18 DISPATCHER: Finished worker discovery
00:13:18 DISPATCHER: Starting worker discovery
00:13:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:13:18 DISPATCHER: Finished worker discovery
00:14:18 DISPATCHER: Starting worker discovery
00:14:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:14:18 DISPATCHER: Finished worker discovery
00:15:18 DISPATCHER: Starting worker discovery
00:15:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:15:18 DISPATCHER: Finished worker discovery
00:16:18 DISPATCHER: Starting worker discovery
00:16:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:16:18 DISPATCHER: Finished worker discovery
00:17:18 DISPATCHER: Starting worker discovery
00:17:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:17:18 DISPATCHER: Finished worker discovery
00:18:18 DISPATCHER: Starting worker discovery
00:18:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:18:18 DISPATCHER: Finished worker discovery
00:19:18 DISPATCHER: Starting worker discovery
00:19:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:19:18 DISPATCHER: Finished worker discovery
00:20:18 DISPATCHER: Starting worker discovery
00:20:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:20:18 DISPATCHER: Finished worker discovery
00:21:18 DISPATCHER: Starting worker discovery
00:21:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:21:18 DISPATCHER: Finished worker discovery
00:22:18 DISPATCHER: Starting worker discovery
00:22:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:22:18 DISPATCHER: Finished worker discovery
00:23:18 DISPATCHER: Starting worker discovery
00:23:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:23:18 DISPATCHER: Finished worker discovery
00:24:18 DISPATCHER: Starting worker discovery
00:24:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:24:18 DISPATCHER: Finished worker discovery
00:25:18 DISPATCHER: Starting worker discovery
00:25:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:25:18 DISPATCHER: Finished worker discovery
00:25:32 WORKER: done with job (7, 0, 1), trying to register it.
00:25:32 WORKER: registered result for job (7, 0, 1) with dispatcher
00:25:32 DISPATCHER: job (7, 0, 1) finished
00:25:32 DISPATCHER: register_result: lock acquired
00:25:32 DISPATCHER: job (7, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
00:25:32 job_id: (7, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.09969328008963321, 'num_filters_1': 34, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.0460568410234462}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.01675984354310898, 'info': {'data05': 0.01675984354310898, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.09969328008963321, 'num_filters_1': 34, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.0460568410234462}"}}
exception: None

00:25:32 job_callback for (7, 0, 1) started
00:25:32 job_callback for (7, 0, 1) got condition
00:25:32 DISPATCHER: Trying to submit another job.
00:25:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:25:32 Only 14 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
00:25:32 HBMASTER: Trying to run another job!
00:25:32 job_callback for (7, 0, 1) finished
00:25:32 start sampling a new configuration.
00:25:32 best_vector: [0, 2, 0.37144572809134757, 0.6025860533429638, 0.7321765275454657, 1, 0.36982873384704296, 0.7190724023398701, 2, 1, 0, 2, 0.6508080788615888, 0.12668300887526002, 0.9977329772313724, 0.9090699631123037], 1.4343761214825292e-31, 0.06971672109031132, -5.217405138765882e-06
00:25:32 done sampling a new configuration.
00:25:32 HBMASTER: schedule new run for iteration 7
00:25:32 HBMASTER: trying submitting job (7, 0, 2) to dispatcher
00:25:32 HBMASTER: submitting job (7, 0, 2) to dispatcher
00:25:32 DISPATCHER: trying to submit job (7, 0, 2)
00:25:32 DISPATCHER: trying to notify the job_runner thread.
00:25:32 HBMASTER: job (7, 0, 2) submitted to dispatcher
00:25:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:25:32 DISPATCHER: Trying to submit another job.
00:25:32 DISPATCHER: starting job (7, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:25:32 DISPATCHER: job (7, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:25:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:25:32 WORKER: start processing job (7, 0, 2)
00:25:32 WORKER: args: ()
00:25:32 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.005532118269429767, 'num_filters_1': 55, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.0862054581874977, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 61, 'num_filters_3': 20, 'num_filters_4': 128}, 'budget': 1200.0, 'working_directory': '.'}
00:26:18 DISPATCHER: Starting worker discovery
00:26:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:26:18 DISPATCHER: Finished worker discovery
00:27:18 DISPATCHER: Starting worker discovery
00:27:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:27:18 DISPATCHER: Finished worker discovery
00:28:18 DISPATCHER: Starting worker discovery
00:28:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:28:18 DISPATCHER: Finished worker discovery
00:29:18 DISPATCHER: Starting worker discovery
00:29:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:29:18 DISPATCHER: Finished worker discovery
00:30:18 DISPATCHER: Starting worker discovery
00:30:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:30:18 DISPATCHER: Finished worker discovery
00:31:18 DISPATCHER: Starting worker discovery
00:31:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:31:18 DISPATCHER: Finished worker discovery
00:32:18 DISPATCHER: Starting worker discovery
00:32:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:32:18 DISPATCHER: Finished worker discovery
00:33:18 DISPATCHER: Starting worker discovery
00:33:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:33:18 DISPATCHER: Finished worker discovery
00:34:18 DISPATCHER: Starting worker discovery
00:34:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:34:18 DISPATCHER: Finished worker discovery
00:35:18 DISPATCHER: Starting worker discovery
00:35:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:35:18 DISPATCHER: Finished worker discovery
00:36:18 DISPATCHER: Starting worker discovery
00:36:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:36:18 DISPATCHER: Finished worker discovery
00:37:18 DISPATCHER: Starting worker discovery
00:37:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:37:18 DISPATCHER: Finished worker discovery
00:38:18 DISPATCHER: Starting worker discovery
00:38:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:38:18 DISPATCHER: Finished worker discovery
00:39:18 DISPATCHER: Starting worker discovery
00:39:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:39:18 DISPATCHER: Finished worker discovery
00:40:18 DISPATCHER: Starting worker discovery
00:40:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:40:18 DISPATCHER: Finished worker discovery
00:41:18 DISPATCHER: Starting worker discovery
00:41:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:41:18 DISPATCHER: Finished worker discovery
00:42:18 DISPATCHER: Starting worker discovery
00:42:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:42:18 DISPATCHER: Finished worker discovery
00:43:18 DISPATCHER: Starting worker discovery
00:43:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:43:18 DISPATCHER: Finished worker discovery
00:44:18 DISPATCHER: Starting worker discovery
00:44:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:44:18 DISPATCHER: Finished worker discovery
00:45:18 DISPATCHER: Starting worker discovery
00:45:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:45:18 DISPATCHER: Finished worker discovery
00:46:18 DISPATCHER: Starting worker discovery
00:46:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:46:18 DISPATCHER: Finished worker discovery
00:46:42 WORKER: done with job (7, 0, 2), trying to register it.
00:46:42 WORKER: registered result for job (7, 0, 2) with dispatcher
00:46:42 DISPATCHER: job (7, 0, 2) finished
00:46:42 DISPATCHER: register_result: lock acquired
00:46:42 DISPATCHER: job (7, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
00:46:42 job_id: (7, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.005532118269429767, 'num_filters_1': 55, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.0862054581874977, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 61, 'num_filters_3': 20, 'num_filters_4': 128}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.18499861458199643, 'info': {'data05': 0.18499861458199643, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.005532118269429767, 'num_filters_1': 55, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.0862054581874977, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 61, 'num_filters_3': 20, 'num_filters_4': 128}"}}
exception: None

00:46:42 job_callback for (7, 0, 2) started
00:46:42 DISPATCHER: Trying to submit another job.
00:46:42 job_callback for (7, 0, 2) got condition
00:46:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:46:42 Only 15 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
00:46:42 HBMASTER: Trying to run another job!
00:46:42 job_callback for (7, 0, 2) finished
00:46:42 start sampling a new configuration.
00:46:42 best_vector: [2, 1, 0.700124075104374, 0.13119032116587437, 0.5454478506327655, 1, 0.8243751367935509, 0.044144214585681574, 2, 2, 1, 2, 0.7676111753394919, 0.20158147303242718, 0.26804061893377407, 0.9113007777663945], 4.816224187024682e-31, 0.020763153066962397, -2.3875894153328095e-06
00:46:42 done sampling a new configuration.
00:46:42 HBMASTER: schedule new run for iteration 7
00:46:42 HBMASTER: trying submitting job (7, 0, 3) to dispatcher
00:46:42 HBMASTER: submitting job (7, 0, 3) to dispatcher
00:46:42 DISPATCHER: trying to submit job (7, 0, 3)
00:46:42 DISPATCHER: trying to notify the job_runner thread.
00:46:42 HBMASTER: job (7, 0, 3) submitted to dispatcher
00:46:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:46:42 DISPATCHER: Trying to submit another job.
00:46:42 DISPATCHER: starting job (7, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:46:42 DISPATCHER: job (7, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
00:46:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:46:42 WORKER: start processing job (7, 0, 3)
00:46:42 WORKER: args: ()
00:46:42 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.02513322100812708, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.011413870671033425, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 79, 'num_filters_3': 24}, 'budget': 1200.0, 'working_directory': '.'}
00:47:18 DISPATCHER: Starting worker discovery
00:47:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:47:18 DISPATCHER: Finished worker discovery
00:48:18 DISPATCHER: Starting worker discovery
00:48:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:48:19 DISPATCHER: Finished worker discovery
00:49:19 DISPATCHER: Starting worker discovery
00:49:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:49:19 DISPATCHER: Finished worker discovery
00:50:19 DISPATCHER: Starting worker discovery
00:50:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:50:19 DISPATCHER: Finished worker discovery
00:51:19 DISPATCHER: Starting worker discovery
00:51:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:51:19 DISPATCHER: Finished worker discovery
00:52:19 DISPATCHER: Starting worker discovery
00:52:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:52:19 DISPATCHER: Finished worker discovery
00:53:19 DISPATCHER: Starting worker discovery
00:53:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:53:19 DISPATCHER: Finished worker discovery
00:54:19 DISPATCHER: Starting worker discovery
00:54:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:54:19 DISPATCHER: Finished worker discovery
00:55:19 DISPATCHER: Starting worker discovery
00:55:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:55:19 DISPATCHER: Finished worker discovery
00:56:19 DISPATCHER: Starting worker discovery
00:56:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:56:19 DISPATCHER: Finished worker discovery
00:57:19 DISPATCHER: Starting worker discovery
00:57:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:57:19 DISPATCHER: Finished worker discovery
00:58:19 DISPATCHER: Starting worker discovery
00:58:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:58:19 DISPATCHER: Finished worker discovery
00:59:19 DISPATCHER: Starting worker discovery
00:59:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:59:19 DISPATCHER: Finished worker discovery
01:00:19 DISPATCHER: Starting worker discovery
01:00:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:00:19 DISPATCHER: Finished worker discovery
01:01:19 DISPATCHER: Starting worker discovery
01:01:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:01:19 DISPATCHER: Finished worker discovery
01:02:19 DISPATCHER: Starting worker discovery
01:02:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:02:19 DISPATCHER: Finished worker discovery
01:03:19 DISPATCHER: Starting worker discovery
01:03:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:03:19 DISPATCHER: Finished worker discovery
01:04:19 DISPATCHER: Starting worker discovery
01:04:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:04:19 DISPATCHER: Finished worker discovery
01:05:19 DISPATCHER: Starting worker discovery
01:05:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:05:19 DISPATCHER: Finished worker discovery
01:06:19 DISPATCHER: Starting worker discovery
01:06:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:06:19 DISPATCHER: Finished worker discovery
01:07:12 WORKER: done with job (7, 0, 3), trying to register it.
01:07:12 WORKER: registered result for job (7, 0, 3) with dispatcher
01:07:12 DISPATCHER: job (7, 0, 3) finished
01:07:12 DISPATCHER: register_result: lock acquired
01:07:12 DISPATCHER: job (7, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:07:12 job_id: (7, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.02513322100812708, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.011413870671033425, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 79, 'num_filters_3': 24}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.03867677560592952, 'info': {'data05': 0.03867677560592952, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.02513322100812708, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.011413870671033425, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 79, 'num_filters_3': 24}"}}
exception: None

01:07:12 job_callback for (7, 0, 3) started
01:07:12 job_callback for (7, 0, 3) got condition
01:07:12 DISPATCHER: Trying to submit another job.
01:07:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:07:12 Only 16 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
01:07:12 HBMASTER: Trying to run another job!
01:07:12 job_callback for (7, 0, 3) finished
01:07:12 start sampling a new configuration.
01:07:12 best_vector: [0, 1, 0.009217369460225694, 0.6109110548190375, 0.4576688217929469, 1, 0.7644264909340764, 0.5844872171292483, 2, 1, 2, 2, 0.040273080268590555, 0.1773375372039897, 0.7973470243554341, 0.9038754204053955], 7.013243110778151e-27, 1.4258738563663532e-06, -5.721720270764487e-07
01:07:12 done sampling a new configuration.
01:07:12 HBMASTER: schedule new run for iteration 8
01:07:12 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
01:07:12 HBMASTER: submitting job (8, 0, 0) to dispatcher
01:07:12 DISPATCHER: trying to submit job (8, 0, 0)
01:07:12 DISPATCHER: trying to notify the job_runner thread.
01:07:12 HBMASTER: job (8, 0, 0) submitted to dispatcher
01:07:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:07:12 DISPATCHER: Trying to submit another job.
01:07:12 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:07:12 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:07:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:07:12 WORKER: start processing job (8, 0, 0)
01:07:12 WORKER: args: ()
01:07:12 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0010433613358863567, 'num_filters_1': 56, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.05760171334474211, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 17, 'num_filters_3': 23}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:07:19 DISPATCHER: Starting worker discovery
01:07:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:07:19 DISPATCHER: Finished worker discovery
01:08:09 WORKER: done with job (8, 0, 0), trying to register it.
01:08:09 WORKER: registered result for job (8, 0, 0) with dispatcher
01:08:09 DISPATCHER: job (8, 0, 0) finished
01:08:09 DISPATCHER: register_result: lock acquired
01:08:09 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:08:09 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0010433613358863567, 'num_filters_1': 56, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.05760171334474211, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 17, 'num_filters_3': 23}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4233896592413902, 'info': {'data05': 0.4233896592413902, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0010433613358863567, 'num_filters_1': 56, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.05760171334474211, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 17, 'num_filters_3': 23}"}}
exception: None

01:08:09 job_callback for (8, 0, 0) started
01:08:09 DISPATCHER: Trying to submit another job.
01:08:09 job_callback for (8, 0, 0) got condition
01:08:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:08:09 HBMASTER: Trying to run another job!
01:08:09 job_callback for (8, 0, 0) finished
01:08:09 start sampling a new configuration.
01:08:09 best_vector: [0, 1, 0.17341160008844883, 0.5637493953449229, 0.07589741419512022, 0, 0.5815842207747333, 0.7173070737631508, 1, 2, 0, 2, 0.5498183164106889, 0.7830664393905382, 0.00830595198746198, 0.9082836421562362], 1.7270455813022563e-30, 0.005790235132334857, -1.2205169775022188e-06
01:08:09 done sampling a new configuration.
01:08:09 HBMASTER: schedule new run for iteration 8
01:08:09 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
01:08:09 HBMASTER: submitting job (8, 0, 1) to dispatcher
01:08:09 DISPATCHER: trying to submit job (8, 0, 1)
01:08:09 DISPATCHER: trying to notify the job_runner thread.
01:08:09 HBMASTER: job (8, 0, 1) submitted to dispatcher
01:08:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:08:09 DISPATCHER: Trying to submit another job.
01:08:09 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:08:09 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:08:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:08:09 WORKER: start processing job (8, 0, 1)
01:08:09 WORKER: args: ()
01:08:09 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0022224049728786347, 'num_filters_1': 51, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.08575076814069352}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:08:19 DISPATCHER: Starting worker discovery
01:08:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:08:19 DISPATCHER: Finished worker discovery
01:09:06 WORKER: done with job (8, 0, 1), trying to register it.
01:09:06 WORKER: registered result for job (8, 0, 1) with dispatcher
01:09:06 DISPATCHER: job (8, 0, 1) finished
01:09:06 DISPATCHER: register_result: lock acquired
01:09:06 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:09:06 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0022224049728786347, 'num_filters_1': 51, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.08575076814069352}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2592391474069068, 'info': {'data05': 0.2592391474069068, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0022224049728786347, 'num_filters_1': 51, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.08575076814069352}"}}
exception: None

01:09:06 job_callback for (8, 0, 1) started
01:09:06 job_callback for (8, 0, 1) got condition
01:09:06 DISPATCHER: Trying to submit another job.
01:09:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:09:06 HBMASTER: Trying to run another job!
01:09:06 job_callback for (8, 0, 1) finished
01:09:06 start sampling a new configuration.
01:09:06 best_vector: [2, 0, 0.44966951204218863, 0.5409619692228109, 0.8597134678315664, 1, 0.7703189782012663, 0.1933627161559855, 1, 1, 0, 2, 0.7739256988820296, 0.6168967101437917, 0.11450229203303763, 0.9044646195086311], 2.800733176580297e-28, 3.570493642029131e-05, -6.8831678375307455e-06
01:09:06 done sampling a new configuration.
01:09:06 HBMASTER: schedule new run for iteration 8
01:09:06 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
01:09:06 HBMASTER: submitting job (8, 0, 2) to dispatcher
01:09:06 DISPATCHER: trying to submit job (8, 0, 2)
01:09:06 DISPATCHER: trying to notify the job_runner thread.
01:09:06 HBMASTER: job (8, 0, 2) submitted to dispatcher
01:09:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:09:06 DISPATCHER: Trying to submit another job.
01:09:06 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:09:06 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:09:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:09:06 WORKER: start processing job (8, 0, 2)
01:09:06 WORKER: args: ()
01:09:06 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.007931202237553068, 'num_filters_1': 49, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.017847224791710675, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 80, 'num_filters_3': 57, 'num_filters_4': 20, 'num_filters_5': 105}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:09:19 DISPATCHER: Starting worker discovery
01:09:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:09:19 DISPATCHER: Finished worker discovery
01:10:03 WORKER: done with job (8, 0, 2), trying to register it.
01:10:03 WORKER: registered result for job (8, 0, 2) with dispatcher
01:10:03 DISPATCHER: job (8, 0, 2) finished
01:10:03 DISPATCHER: register_result: lock acquired
01:10:03 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:10:03 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.007931202237553068, 'num_filters_1': 49, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.017847224791710675, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 80, 'num_filters_3': 57, 'num_filters_4': 20, 'num_filters_5': 105}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5833197808083862, 'info': {'data05': 0.5833197808083862, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.007931202237553068, 'num_filters_1': 49, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.017847224791710675, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 80, 'num_filters_3': 57, 'num_filters_4': 20, 'num_filters_5': 105}"}}
exception: None

01:10:03 job_callback for (8, 0, 2) started
01:10:03 DISPATCHER: Trying to submit another job.
01:10:03 job_callback for (8, 0, 2) got condition
01:10:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:10:03 HBMASTER: Trying to run another job!
01:10:03 job_callback for (8, 0, 2) finished
01:10:03 start sampling a new configuration.
01:10:03 done sampling a new configuration.
01:10:03 HBMASTER: schedule new run for iteration 8
01:10:03 HBMASTER: trying submitting job (8, 0, 3) to dispatcher
01:10:03 HBMASTER: submitting job (8, 0, 3) to dispatcher
01:10:03 DISPATCHER: trying to submit job (8, 0, 3)
01:10:03 DISPATCHER: trying to notify the job_runner thread.
01:10:03 HBMASTER: job (8, 0, 3) submitted to dispatcher
01:10:03 DISPATCHER: Trying to submit another job.
01:10:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:10:03 DISPATCHER: starting job (8, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:10:03 DISPATCHER: job (8, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:10:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:10:03 WORKER: start processing job (8, 0, 3)
01:10:03 WORKER: args: ()
01:10:03 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.058092393568444305, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.023011106420168438}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-735:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    preds = np.concatenate(preds)
IndexError: index 4607182418800017408 is out of bounds for axis 0 with size 10

01:10:19 DISPATCHER: Starting worker discovery
01:10:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:10:19 DISPATCHER: Finished worker discovery
01:10:58 WORKER: done with job (8, 0, 3), trying to register it.
01:10:58 WORKER: registered result for job (8, 0, 3) with dispatcher
01:10:58 DISPATCHER: job (8, 0, 3) finished
01:10:58 DISPATCHER: register_result: lock acquired
01:10:58 DISPATCHER: job (8, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:10:58 job_id: (8, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.058092393568444305, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.023011106420168438}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6685084435341294, 'info': {'data05': 0.6685084435341294, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.058092393568444305, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.023011106420168438}"}}
exception: None

01:10:58 job_callback for (8, 0, 3) started
01:10:58 job_callback for (8, 0, 3) got condition
01:10:58 DISPATCHER: Trying to submit another job.
01:10:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:10:58 HBMASTER: Trying to run another job!
01:10:58 job_callback for (8, 0, 3) finished
01:10:58 start sampling a new configuration.
01:10:58 done sampling a new configuration.
01:10:58 HBMASTER: schedule new run for iteration 8
01:10:58 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
01:10:58 HBMASTER: submitting job (8, 0, 4) to dispatcher
01:10:58 DISPATCHER: trying to submit job (8, 0, 4)
01:10:58 DISPATCHER: trying to notify the job_runner thread.
01:10:58 HBMASTER: job (8, 0, 4) submitted to dispatcher
01:10:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:10:58 DISPATCHER: Trying to submit another job.
01:10:58 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:10:58 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:10:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:10:58 WORKER: start processing job (8, 0, 4)
01:10:58 WORKER: args: ()
01:10:58 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.004928794460666617, 'num_filters_1': 21, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.126533547204922, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 24, 'num_filters_3': 78}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:11:19 DISPATCHER: Starting worker discovery
01:11:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:11:19 DISPATCHER: Finished worker discovery
01:11:56 WORKER: done with job (8, 0, 4), trying to register it.
01:11:56 WORKER: registered result for job (8, 0, 4) with dispatcher
01:11:56 DISPATCHER: job (8, 0, 4) finished
01:11:56 DISPATCHER: register_result: lock acquired
01:11:56 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:11:56 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.004928794460666617, 'num_filters_1': 21, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.126533547204922, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 24, 'num_filters_3': 78}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.014668958767909208, 'info': {'data05': 0.014668958767909208, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.004928794460666617, 'num_filters_1': 21, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.126533547204922, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 24, 'num_filters_3': 78}"}}
exception: None

01:11:56 job_callback for (8, 0, 4) started
01:11:56 job_callback for (8, 0, 4) got condition
01:11:56 DISPATCHER: Trying to submit another job.
01:11:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:11:56 HBMASTER: Trying to run another job!
01:11:56 job_callback for (8, 0, 4) finished
01:11:56 start sampling a new configuration.
01:11:56 best_vector: [2, 0, 0.08678525975506399, 0.5621897783896994, 0.37157837802468274, 1, 0.8957357746648518, 0.1121402911263461, 1, 2, 1, 2, 0.02039117207538499, 0.3482955614410458, 0.15907143004169133, 0.9058679164927816], 8.073063044502292e-29, 0.00012386872175871265, -1.9980276071443095e-07
01:11:56 done sampling a new configuration.
01:11:56 HBMASTER: schedule new run for iteration 8
01:11:56 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
01:11:56 HBMASTER: submitting job (8, 0, 5) to dispatcher
01:11:56 DISPATCHER: trying to submit job (8, 0, 5)
01:11:56 DISPATCHER: trying to notify the job_runner thread.
01:11:56 HBMASTER: job (8, 0, 5) submitted to dispatcher
01:11:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:11:56 DISPATCHER: Trying to submit another job.
01:11:56 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:11:56 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:11:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:11:56 WORKER: start processing job (8, 0, 5)
01:11:56 WORKER: args: ()
01:11:56 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.001491318891938862, 'num_filters_1': 51, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.013992582702966088, 'kernel_size_2': 5, 'num_filters_2': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:12:19 DISPATCHER: Starting worker discovery
01:12:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:12:19 DISPATCHER: Finished worker discovery
01:12:52 WORKER: done with job (8, 0, 5), trying to register it.
01:12:52 WORKER: registered result for job (8, 0, 5) with dispatcher
01:12:52 DISPATCHER: job (8, 0, 5) finished
01:12:52 DISPATCHER: register_result: lock acquired
01:12:52 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:12:52 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.001491318891938862, 'num_filters_1': 51, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.013992582702966088, 'kernel_size_2': 5, 'num_filters_2': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5182282296844583, 'info': {'data05': 0.5182282296844583, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.001491318891938862, 'num_filters_1': 51, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.013992582702966088, 'kernel_size_2': 5, 'num_filters_2': 16}"}}
exception: None

01:12:52 job_callback for (8, 0, 5) started
01:12:52 DISPATCHER: Trying to submit another job.
01:12:52 job_callback for (8, 0, 5) got condition
01:12:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:12:52 HBMASTER: Trying to run another job!
01:12:52 job_callback for (8, 0, 5) finished
01:12:52 start sampling a new configuration.
01:12:52 best_vector: [2, 2, 0.2589154506760387, 0.570807845979927, 0.08607084079179061, 1, 0.8942798880710947, 0.05901463049963509, 1, 0, 2, 2, 0.5974536912782235, 0.09849889400741618, 0.47571692087987016, 0.9117485706106147], 4.764822313480217e-30, 0.002098714147578783, -5.135101395737796e-07
01:12:52 done sampling a new configuration.
01:12:52 HBMASTER: schedule new run for iteration 8
01:12:52 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
01:12:52 HBMASTER: submitting job (8, 0, 6) to dispatcher
01:12:52 DISPATCHER: trying to submit job (8, 0, 6)
01:12:52 DISPATCHER: trying to notify the job_runner thread.
01:12:52 HBMASTER: job (8, 0, 6) submitted to dispatcher
01:12:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:12:52 DISPATCHER: Trying to submit another job.
01:12:52 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:12:52 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:12:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:12:52 WORKER: start processing job (8, 0, 6)
01:12:52 WORKER: args: ()
01:12:52 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003294813989948213, 'num_filters_1': 52, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.01193382883298465}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:13:19 DISPATCHER: Starting worker discovery
01:13:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:13:19 DISPATCHER: Finished worker discovery
01:13:48 WORKER: done with job (8, 0, 6), trying to register it.
01:13:48 WORKER: registered result for job (8, 0, 6) with dispatcher
01:13:48 DISPATCHER: job (8, 0, 6) finished
01:13:48 DISPATCHER: register_result: lock acquired
01:13:48 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:13:48 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003294813989948213, 'num_filters_1': 52, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.01193382883298465}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5696089732255365, 'info': {'data05': 0.5696089732255365, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003294813989948213, 'num_filters_1': 52, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.01193382883298465}"}}
exception: None

01:13:48 job_callback for (8, 0, 6) started
01:13:48 job_callback for (8, 0, 6) got condition
01:13:48 DISPATCHER: Trying to submit another job.
01:13:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:13:48 HBMASTER: Trying to run another job!
01:13:48 job_callback for (8, 0, 6) finished
01:13:48 start sampling a new configuration.
01:13:49 best_vector: [2, 1, 0.4806298616284246, 0.6786143012914156, 0.7318314058249945, 1, 0.7555329424304283, 0.19325145385868042, 0, 2, 0, 2, 0.7890418117452154, 0.8003857511049487, 0.20192871645143953, 0.9086694817884189], 1.0162977210953242e-05, 3.819708398791378, 3.881960940940347e-05
01:13:49 done sampling a new configuration.
01:13:49 HBMASTER: schedule new run for iteration 8
01:13:49 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
01:13:49 HBMASTER: submitting job (8, 0, 7) to dispatcher
01:13:49 DISPATCHER: trying to submit job (8, 0, 7)
01:13:49 DISPATCHER: trying to notify the job_runner thread.
01:13:49 HBMASTER: job (8, 0, 7) submitted to dispatcher
01:13:49 DISPATCHER: Trying to submit another job.
01:13:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:13:49 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:13:49 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:13:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:13:49 WORKER: start processing job (8, 0, 7)
01:13:49 WORKER: args: ()
01:13:49 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.009146600765877125, 'num_filters_1': 65, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.017841277087817447, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 82, 'num_filters_3': 84, 'num_filters_4': 24}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:14:19 DISPATCHER: Starting worker discovery
01:14:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:14:19 DISPATCHER: Finished worker discovery
01:14:45 WORKER: done with job (8, 0, 7), trying to register it.
01:14:45 WORKER: registered result for job (8, 0, 7) with dispatcher
01:14:45 DISPATCHER: job (8, 0, 7) finished
01:14:45 DISPATCHER: register_result: lock acquired
01:14:45 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:14:45 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.009146600765877125, 'num_filters_1': 65, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.017841277087817447, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 82, 'num_filters_3': 84, 'num_filters_4': 24}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.43645589664553935, 'info': {'data05': 0.43645589664553935, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.009146600765877125, 'num_filters_1': 65, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.017841277087817447, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 82, 'num_filters_3': 84, 'num_filters_4': 24}"}}
exception: None

01:14:45 job_callback for (8, 0, 7) started
01:14:45 DISPATCHER: Trying to submit another job.
01:14:45 job_callback for (8, 0, 7) got condition
01:14:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:14:45 HBMASTER: Trying to run another job!
01:14:45 job_callback for (8, 0, 7) finished
01:14:45 start sampling a new configuration.
01:14:45 best_vector: [2, 2, 0.009574696133771168, 0.7546255861050977, 0.6043365507878848, 1, 0.6032900706573318, 0.23628814906685242, 1, 1, 1, 2, 0.725680757416599, 0.6712255111912948, 0.4621339694069524, 0.9081800369930074], 4.06884340525902e-05, 0.651596557063567, 2.651244354097577e-05
01:14:45 done sampling a new configuration.
01:14:45 HBMASTER: schedule new run for iteration 8
01:14:45 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
01:14:45 HBMASTER: submitting job (8, 0, 8) to dispatcher
01:14:45 DISPATCHER: trying to submit job (8, 0, 8)
01:14:45 DISPATCHER: trying to notify the job_runner thread.
01:14:45 HBMASTER: job (8, 0, 8) submitted to dispatcher
01:14:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:14:45 DISPATCHER: Trying to submit another job.
01:14:45 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:14:45 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:14:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:14:45 WORKER: start processing job (8, 0, 8)
01:14:45 WORKER: args: ()
01:14:45 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001045079652683006, 'num_filters_1': 76, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.020296351219533926, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 72, 'num_filters_3': 64, 'num_filters_4': 41}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:15:19 DISPATCHER: Starting worker discovery
01:15:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:15:19 DISPATCHER: Finished worker discovery
01:15:41 WORKER: done with job (8, 0, 8), trying to register it.
01:15:41 WORKER: registered result for job (8, 0, 8) with dispatcher
01:15:41 DISPATCHER: job (8, 0, 8) finished
01:15:41 DISPATCHER: register_result: lock acquired
01:15:41 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:15:41 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001045079652683006, 'num_filters_1': 76, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.020296351219533926, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 72, 'num_filters_3': 64, 'num_filters_4': 41}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.644488087575624, 'info': {'data05': 0.644488087575624, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001045079652683006, 'num_filters_1': 76, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.020296351219533926, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 72, 'num_filters_3': 64, 'num_filters_4': 41}"}}
exception: None

01:15:41 job_callback for (8, 0, 8) started
01:15:41 DISPATCHER: Trying to submit another job.
01:15:41 job_callback for (8, 0, 8) got condition
01:15:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:15:41 HBMASTER: Trying to run another job!
01:15:41 job_callback for (8, 0, 8) finished
01:15:41 start sampling a new configuration.
01:15:41 sampled vector: [2, 1, 0.2699058063780078, 0.24218024059175847, 0.9693520378850062, 0, 0.18612289930567533, 0.6364799588588632, 2, 0, 0, 0, 0.683048820352671, 0.1544247604007003, 0.5849615383482824, 0.9075573079345529] has EI value nan
01:15:41 data in the KDEs:
[[3.         2.         0.24998425 0.86704202 0.0999984  1.
  0.21428565 0.24566352 0.         0.         1.         2.
  0.22601193 0.56308999 0.69910421 0.9089921 ]
 [3.         1.         0.06803028 0.73264973 0.0999984  1.
  0.56593408 0.2693847  0.         2.         0.         2.
  0.22601193 0.88144294 0.38509383 0.9089921 ]
 [0.         1.         0.16622319 0.59011412 0.2999992  1.
  0.24725269 0.23758234 2.         0.         0.         2.
  0.99444858 0.44822661 0.38509383 0.9089921 ]
 [2.         2.         0.05270967 0.67044128 0.2999992  1.
  0.12637354 0.24614725 0.         0.         0.         2.
  0.91343151 0.44822661 0.38509383 0.9089921 ]
 [2.         1.         0.08642555 0.38509383 0.0999984  1.
  0.73076928 0.08622991 0.         2.         1.         2.
  0.22601193 0.1205111  0.85218865 0.9089921 ]
 [0.         1.         0.24837596 0.62389945 0.0999984  1.
  0.51098901 0.09011083 0.         2.         1.         2.
  0.91343151 0.88144294 0.85218865 0.9089921 ]
 [0.         1.         0.17150884 0.24455523 0.9000016  1.
  0.3351648  0.16989608 0.         0.         1.         2.
  0.42397547 0.56308999 0.69910421 0.9089921 ]
 [0.         1.         0.42862227 0.82100415 0.0999984  1.
  0.43406592 0.14514063 1.         2.         1.         2.
  0.38509383 0.1205111  0.85218865 0.9089921 ]
 [0.         0.         0.23301232 0.99444858 0.5        1.
  0.29120875 0.37128064 0.         2.         1.         2.
  0.56308999 0.88144294 0.69910421 0.9089921 ]
 [1.         2.         0.04505993 0.7390824  0.2999992  1.
  0.57692309 0.72993966 0.         0.         1.         2.
  0.22601193 0.56308999 0.69910421 0.9089921 ]
 [1.         1.         0.16526793 0.31221238 0.0999984  1.
  0.28021973 0.39197879 0.         0.         0.         2.
  0.91343151 0.44822661 0.38509383 0.9089921 ]
 [1.         1.         0.43383167 0.92218719 0.7000008  1.
  0.68681323 0.40450175 1.         2.         1.         2.
  0.38509383 0.1205111  0.85218865 0.9089921 ]
 [0.         1.         0.14832595 0.54417572 0.0999984  0.
  0.55494507 0.34857774 2.         2.         1.         2.
  0.99444858 0.88144294 0.85218865 0.9089921 ]
 [0.         2.         0.41766653 0.94339225 0.5        1.
  0.75274731 0.23066054 2.         0.         1.         2.
  0.31221238 0.41136689 0.85218865 0.9089921 ]
 [3.         0.         0.11247297 0.76397201 0.0999984  0.
  0.78571435 0.05755262 1.         0.         0.         2.
  0.85218865 0.44822661 0.38509383 0.9089921 ]
 [0.         0.         0.65314931 0.1205111  0.7000008  1.
  0.19230762 0.18940957 1.         0.         0.         2.
  0.85218865 0.44822661 0.38509383 0.9089921 ]
 [0.         2.         0.51932819 0.56308999 0.7000008  1.
  0.69780224 0.09992786 1.         1.         2.         2.
  0.82100415 0.52447314 0.31221238 0.9089921 ]]
[[1.         0.         0.27244207 0.07069733 0.2999992  1.
  0.95054955 0.55661347 2.         2.         1.         1.
  0.48241935 0.96368694 0.6554307  0.91343151]
 [0.         0.         0.16675883 0.54417572 0.2999992  1.
  0.37912085 0.88116443 1.         2.         0.         0.
  0.63198159 0.53442706 0.20671155 0.62389945]
 [1.         1.         0.24467215 0.279593   0.0999984  1.
  0.06043946 0.79721064 1.         1.         1.         1.
  0.54417572 0.0436732  0.42397547 0.91343151]
 [0.         2.         0.41213634 0.6554307  0.7000008  1.
  0.34615381 0.34698137 0.         0.         0.         0.
  0.22601193 0.16557314 0.83162917 0.9089921 ]
 [2.         2.         0.57655531 0.6554307  0.7000008  1.
  0.46703296 0.94080352 1.         0.         1.         0.
  0.9089921  0.14357878 0.16557314 0.9089921 ]
 [1.         1.         0.74144104 0.88614739 0.0999984  0.
  0.24725269 0.38645499 0.         1.         1.         0.
  0.55372743 0.6554307  0.6554307  0.9089921 ]
 [2.         1.         0.86702441 0.89080549 0.2999992  1.
  0.84065942 0.05647939 1.         2.         0.         0.
  0.83685346 0.53442706 0.20671155 0.62389945]
 [2.         1.         0.72428697 0.61567675 0.9000016  1.
  0.45604395 0.21908144 0.         2.         1.         0.
  0.51430515 0.39841284 0.09625996 0.9089921 ]
 [0.         0.         0.7670464  0.49328864 0.5        1.
  0.70879125 0.15692395 1.         1.         0.         0.
  0.14357878 0.88614739 0.20671155 0.62389945]
 [0.         0.         0.86206511 0.87189123 0.2999992  1.
  0.73076928 0.36465637 0.         1.         2.         1.
  0.81013485 0.53442706 0.63198159 0.91343151]
 [0.         1.         0.81884281 0.34272578 0.7000008  1.
  0.32417579 0.58491771 0.         1.         1.         0.
  0.55372743 0.6554307  0.6554307  0.9089921 ]
 [3.         2.         0.71507604 0.38509383 0.9000016  1.
  0.22527466 0.46775658 2.         1.         1.         0.
  0.01501027 0.57227073 0.35727442 0.9089921 ]
 [2.         2.         0.28989799 0.45990111 0.7000008  0.
  0.80769238 0.0361533  1.         1.         1.         0.
  0.54417572 0.0436732  0.42397547 0.9089921 ]
 [0.         1.         0.55486179 0.76397201 0.2999992  0.
  0.18131861 0.50094924 1.         1.         2.         1.
  0.90451061 0.53442706 0.63198159 0.91343151]
 [3.         0.         0.54399356 0.38509383 0.7000008  0.
  0.0054944  0.53567297 2.         0.         1.         0.
  0.67777156 0.61567675 0.43625651 0.9089921 ]
 [0.         2.         0.64891428 0.16557314 0.5        0.
  0.12637354 0.6680423  0.         2.         0.         1.
  0.35727442 0.96368694 0.83162917 0.91343151]
 [2.         2.         0.80602616 0.99444858 0.9000016  0.
  0.34615381 0.87685083 2.         0.         0.         1.
  0.55372743 0.51430515 0.71280933 0.45990111]
 [3.         1.         0.98663789 0.54417572 0.9000016  0.
  0.79670336 0.17568671 0.         2.         0.         0.
  0.09625996 0.53442706 0.20671155 0.62389945]
 [1.         2.         0.87862407 0.73264973 0.9000016  0.
  0.93956054 0.87407967 1.         1.         2.         1.
  0.26239861 0.53442706 0.63198159 0.91343151]]
01:15:41 bandwidth of the KDEs:
[1.06872705e+00 6.21758117e-01 1.60813017e-01 2.26752192e-01
 2.46337830e-01 2.96411552e-01 1.96266879e-01 1.46744638e-01
 7.01437756e-01 8.85935072e-01 5.24684730e-01 1.00000000e-03
 2.77696501e-01 2.27991670e-01 1.96344012e-01 1.00000000e-03]
[1.01004546 0.72067357 0.21841365 0.22906288 0.25223676 0.45170606
 0.27281018 0.25867149 0.68097251 0.65670611 0.63516888 0.44132063
 0.23737847 0.24053759 0.21301701 0.13247419]
01:15:41 l(x) = nan
01:15:41 g(x) = 0.0003016659570034265
01:15:41 best_vector: [1, 2, 0.225477486465682, 0.14496944333014045, 0.03994429537998077, 0, 0.9944034328774858, 0.2956773668746416, 2, 0, 2, 2, 0.6970885882792006, 0.7092233818947389, 0.38196235799152617, 0.9075067361768225], 2.383774162091713e-30, 0.0041950282703061125, -1.065476969710247e-05
01:15:41 done sampling a new configuration.
01:15:41 HBMASTER: schedule new run for iteration 8
01:15:41 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
01:15:41 HBMASTER: submitting job (8, 0, 9) to dispatcher
01:15:41 DISPATCHER: trying to submit job (8, 0, 9)
01:15:41 DISPATCHER: trying to notify the job_runner thread.
01:15:41 HBMASTER: job (8, 0, 9) submitted to dispatcher
01:15:41 DISPATCHER: Trying to submit another job.
01:15:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:15:41 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:15:41 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:15:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:15:41 WORKER: start processing job (8, 0, 9)
01:15:41 WORKER: args: ()
01:15:41 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0028245871103358246, 'num_filters_1': 21, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.024248513668874212}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:16:19 DISPATCHER: Starting worker discovery
01:16:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:16:19 DISPATCHER: Finished worker discovery
01:16:37 WORKER: done with job (8, 0, 9), trying to register it.
01:16:37 WORKER: registered result for job (8, 0, 9) with dispatcher
01:16:37 DISPATCHER: job (8, 0, 9) finished
01:16:37 DISPATCHER: register_result: lock acquired
01:16:37 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:16:37 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0028245871103358246, 'num_filters_1': 21, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.024248513668874212}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2688467060030323, 'info': {'data05': 0.2688467060030323, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0028245871103358246, 'num_filters_1': 21, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.024248513668874212}"}}
exception: None

01:16:37 job_callback for (8, 0, 9) started
01:16:37 DISPATCHER: Trying to submit another job.
01:16:37 job_callback for (8, 0, 9) got condition
01:16:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:16:37 HBMASTER: Trying to run another job!
01:16:37 job_callback for (8, 0, 9) finished
01:16:37 start sampling a new configuration.
01:16:37 done sampling a new configuration.
01:16:37 HBMASTER: schedule new run for iteration 8
01:16:37 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
01:16:37 HBMASTER: submitting job (8, 0, 10) to dispatcher
01:16:37 DISPATCHER: trying to submit job (8, 0, 10)
01:16:37 DISPATCHER: trying to notify the job_runner thread.
01:16:37 HBMASTER: job (8, 0, 10) submitted to dispatcher
01:16:37 DISPATCHER: Trying to submit another job.
01:16:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:16:37 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:16:37 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:16:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:16:37 WORKER: start processing job (8, 0, 10)
01:16:37 WORKER: args: ()
01:16:37 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.07001521015502539, 'num_filters_1': 37, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.024743981828979723, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 39, 'num_filters_3': 18, 'num_filters_4': 43}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:17:19 DISPATCHER: Starting worker discovery
01:17:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:17:19 DISPATCHER: Finished worker discovery
01:17:34 WORKER: done with job (8, 0, 10), trying to register it.
01:17:34 WORKER: registered result for job (8, 0, 10) with dispatcher
01:17:34 DISPATCHER: job (8, 0, 10) finished
01:17:34 DISPATCHER: register_result: lock acquired
01:17:34 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:17:34 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.07001521015502539, 'num_filters_1': 37, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.024743981828979723, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 39, 'num_filters_3': 18, 'num_filters_4': 43}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.07001521015502539, 'num_filters_1': 37, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.024743981828979723, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 39, 'num_filters_3': 18, 'num_filters_4': 43}"}}
exception: None

01:17:34 job_callback for (8, 0, 10) started
01:17:34 job_callback for (8, 0, 10) got condition
01:17:34 DISPATCHER: Trying to submit another job.
01:17:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:17:34 HBMASTER: Trying to run another job!
01:17:34 job_callback for (8, 0, 10) finished
01:17:34 start sampling a new configuration.
01:17:35 best_vector: [0, 1, 0.6043494099966173, 0.9438243892972809, 0.3695679134967172, 1, 0.9686918353239553, 0.33395924529877935, 2, 0, 1, 2, 0.4093703837479927, 0.17735616566856657, 0.9254421052668391, 0.9086275063967567], 3.307767177897513e-06, 1.904169399368195, 6.2985490403869364e-06
01:17:35 done sampling a new configuration.
01:17:35 HBMASTER: schedule new run for iteration 8
01:17:35 HBMASTER: trying submitting job (8, 0, 11) to dispatcher
01:17:35 HBMASTER: submitting job (8, 0, 11) to dispatcher
01:17:35 DISPATCHER: trying to submit job (8, 0, 11)
01:17:35 DISPATCHER: trying to notify the job_runner thread.
01:17:35 HBMASTER: job (8, 0, 11) submitted to dispatcher
01:17:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:17:35 DISPATCHER: Trying to submit another job.
01:17:35 DISPATCHER: starting job (8, 0, 11) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:17:35 DISPATCHER: job (8, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:17:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:17:35 WORKER: start processing job (8, 0, 11)
01:17:35 WORKER: args: ()
01:17:35 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.016169583001239343, 'num_filters_1': 114, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.027195120999320144, 'kernel_size_2': 7, 'num_filters_2': 37}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:18:19 DISPATCHER: Starting worker discovery
01:18:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:18:19 DISPATCHER: Finished worker discovery
01:18:31 WORKER: done with job (8, 0, 11), trying to register it.
01:18:31 WORKER: registered result for job (8, 0, 11) with dispatcher
01:18:31 DISPATCHER: job (8, 0, 11) finished
01:18:31 DISPATCHER: register_result: lock acquired
01:18:31 DISPATCHER: job (8, 0, 11) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:18:31 job_id: (8, 0, 11)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.016169583001239343, 'num_filters_1': 114, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.027195120999320144, 'kernel_size_2': 7, 'num_filters_2': 37}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.48926035244529004, 'info': {'data05': 0.48926035244529004, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.016169583001239343, 'num_filters_1': 114, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.027195120999320144, 'kernel_size_2': 7, 'num_filters_2': 37}"}}
exception: None

01:18:31 job_callback for (8, 0, 11) started
01:18:31 job_callback for (8, 0, 11) got condition
01:18:31 DISPATCHER: Trying to submit another job.
01:18:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:18:31 HBMASTER: Trying to run another job!
01:18:31 job_callback for (8, 0, 11) finished
01:18:31 start sampling a new configuration.
01:18:31 done sampling a new configuration.
01:18:31 HBMASTER: schedule new run for iteration 8
01:18:31 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
01:18:31 HBMASTER: submitting job (8, 0, 12) to dispatcher
01:18:31 DISPATCHER: trying to submit job (8, 0, 12)
01:18:31 DISPATCHER: trying to notify the job_runner thread.
01:18:31 HBMASTER: job (8, 0, 12) submitted to dispatcher
01:18:31 DISPATCHER: Trying to submit another job.
01:18:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:18:31 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:18:31 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:18:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:18:31 WORKER: start processing job (8, 0, 12)
01:18:31 WORKER: args: ()
01:18:31 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.005979717048507537, 'num_filters_1': 21, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.0656144052160733}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:19:19 DISPATCHER: Starting worker discovery
01:19:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:19:19 DISPATCHER: Finished worker discovery
01:19:27 WORKER: done with job (8, 0, 12), trying to register it.
01:19:27 WORKER: registered result for job (8, 0, 12) with dispatcher
01:19:27 DISPATCHER: job (8, 0, 12) finished
01:19:27 DISPATCHER: register_result: lock acquired
01:19:27 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:19:27 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.005979717048507537, 'num_filters_1': 21, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.0656144052160733}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.11359876539434986, 'info': {'data05': 0.11359876539434986, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.005979717048507537, 'num_filters_1': 21, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.0656144052160733}"}}
exception: None

01:19:27 job_callback for (8, 0, 12) started
01:19:27 DISPATCHER: Trying to submit another job.
01:19:27 job_callback for (8, 0, 12) got condition
01:19:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:19:27 HBMASTER: Trying to run another job!
01:19:27 job_callback for (8, 0, 12) finished
01:19:27 start sampling a new configuration.
01:19:27 done sampling a new configuration.
01:19:27 HBMASTER: schedule new run for iteration 8
01:19:27 HBMASTER: trying submitting job (8, 0, 13) to dispatcher
01:19:27 HBMASTER: submitting job (8, 0, 13) to dispatcher
01:19:27 DISPATCHER: trying to submit job (8, 0, 13)
01:19:27 DISPATCHER: trying to notify the job_runner thread.
01:19:27 HBMASTER: job (8, 0, 13) submitted to dispatcher
01:19:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:19:27 DISPATCHER: Trying to submit another job.
01:19:27 DISPATCHER: starting job (8, 0, 13) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:19:27 DISPATCHER: job (8, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:19:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:19:27 WORKER: start processing job (8, 0, 13)
01:19:27 WORKER: args: ()
01:19:27 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0013813540326752377, 'num_filters_1': 31, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.0411768726364338, 'kernel_size_2': 3, 'num_filters_2': 62}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:20:19 DISPATCHER: Starting worker discovery
01:20:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:20:19 DISPATCHER: Finished worker discovery
01:20:24 WORKER: done with job (8, 0, 13), trying to register it.
01:20:24 WORKER: registered result for job (8, 0, 13) with dispatcher
01:20:24 DISPATCHER: job (8, 0, 13) finished
01:20:24 DISPATCHER: register_result: lock acquired
01:20:24 DISPATCHER: job (8, 0, 13) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:20:24 job_id: (8, 0, 13)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0013813540326752377, 'num_filters_1': 31, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.0411768726364338, 'kernel_size_2': 3, 'num_filters_2': 62}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.20674060831301047, 'info': {'data05': 0.20674060831301047, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0013813540326752377, 'num_filters_1': 31, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.0411768726364338, 'kernel_size_2': 3, 'num_filters_2': 62}"}}
exception: None

01:20:24 job_callback for (8, 0, 13) started
01:20:24 DISPATCHER: Trying to submit another job.
01:20:24 job_callback for (8, 0, 13) got condition
01:20:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:20:24 HBMASTER: Trying to run another job!
01:20:24 job_callback for (8, 0, 13) finished
01:20:24 start sampling a new configuration.
01:20:25 best_vector: [1, 2, 0.11377111700531085, 0.6979839343657929, 0.317998283156038, 1, 0.7954905068577226, 0.3187419027889163, 0, 0, 2, 2, 0.8064027918971981, 0.839244406123874, 0.6895166176103336, 0.9080646229976607], 4.0522187477661456e-05, 0.9487258500746317, 3.8444446761627964e-05
01:20:25 done sampling a new configuration.
01:20:25 HBMASTER: schedule new run for iteration 8
01:20:25 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
01:20:25 HBMASTER: submitting job (8, 0, 14) to dispatcher
01:20:25 DISPATCHER: trying to submit job (8, 0, 14)
01:20:25 DISPATCHER: trying to notify the job_runner thread.
01:20:25 HBMASTER: job (8, 0, 14) submitted to dispatcher
01:20:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:20:25 DISPATCHER: Trying to submit another job.
01:20:25 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:20:25 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:20:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:20:25 WORKER: start processing job (8, 0, 14)
01:20:25 WORKER: args: ()
01:20:25 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0016886600693088885, 'num_filters_1': 68, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.02598320838698465, 'kernel_size_2': 3, 'num_filters_2': 85}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:21:19 DISPATCHER: Starting worker discovery
01:21:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:21:19 DISPATCHER: Finished worker discovery
01:21:22 WORKER: done with job (8, 0, 14), trying to register it.
01:21:22 WORKER: registered result for job (8, 0, 14) with dispatcher
01:21:22 DISPATCHER: job (8, 0, 14) finished
01:21:22 DISPATCHER: register_result: lock acquired
01:21:22 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:21:22 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0016886600693088885, 'num_filters_1': 68, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.02598320838698465, 'kernel_size_2': 3, 'num_filters_2': 85}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5994542958621434, 'info': {'data05': 0.5994542958621434, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0016886600693088885, 'num_filters_1': 68, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.02598320838698465, 'kernel_size_2': 3, 'num_filters_2': 85}"}}
exception: None

01:21:22 job_callback for (8, 0, 14) started
01:21:22 DISPATCHER: Trying to submit another job.
01:21:22 job_callback for (8, 0, 14) got condition
01:21:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:21:22 HBMASTER: Trying to run another job!
01:21:22 job_callback for (8, 0, 14) finished
01:21:22 start sampling a new configuration.
01:21:22 done sampling a new configuration.
01:21:22 HBMASTER: schedule new run for iteration 8
01:21:22 HBMASTER: trying submitting job (8, 0, 15) to dispatcher
01:21:22 HBMASTER: submitting job (8, 0, 15) to dispatcher
01:21:22 DISPATCHER: trying to submit job (8, 0, 15)
01:21:22 DISPATCHER: trying to notify the job_runner thread.
01:21:22 HBMASTER: job (8, 0, 15) submitted to dispatcher
01:21:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:21:22 DISPATCHER: Trying to submit another job.
01:21:22 DISPATCHER: starting job (8, 0, 15) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:21:22 DISPATCHER: job (8, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:21:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:21:22 WORKER: start processing job (8, 0, 15)
01:21:22 WORKER: args: ()
01:21:22 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.06155780959453104, 'num_filters_1': 22, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.019731941988074146, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 32, 'num_filters_3': 51, 'num_filters_4': 28, 'num_filters_5': 50}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:22:19 DISPATCHER: Starting worker discovery
01:22:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:22:19 DISPATCHER: Finished worker discovery
01:22:19 WORKER: done with job (8, 0, 15), trying to register it.
01:22:19 WORKER: registered result for job (8, 0, 15) with dispatcher
01:22:19 DISPATCHER: job (8, 0, 15) finished
01:22:19 DISPATCHER: register_result: lock acquired
01:22:19 DISPATCHER: job (8, 0, 15) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:22:19 job_id: (8, 0, 15)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.06155780959453104, 'num_filters_1': 22, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.019731941988074146, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 32, 'num_filters_3': 51, 'num_filters_4': 28, 'num_filters_5': 50}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.06155780959453104, 'num_filters_1': 22, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.019731941988074146, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 32, 'num_filters_3': 51, 'num_filters_4': 28, 'num_filters_5': 50}"}}
exception: None

01:22:19 job_callback for (8, 0, 15) started
01:22:19 DISPATCHER: Trying to submit another job.
01:22:19 job_callback for (8, 0, 15) got condition
01:22:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:22:19 HBMASTER: Trying to run another job!
01:22:19 job_callback for (8, 0, 15) finished
01:22:19 start sampling a new configuration.
01:22:19 sampled vector: [1, 0, 0.8552639287707684, 0.7564589989630527, 0.17688363112339966, 0, 0.5005389873160471, 0.3079401000132624, 1, 2, 0, 1, 0.432284728943671, 0.9280502134262856, 0.4506236716296316, 0.9105397318270498] has EI value nan
01:22:19 data in the KDEs:
[[3.         2.         0.24998425 0.86704202 0.0999984  1.
  0.21428565 0.24566352 0.         0.         1.         2.
  0.22601193 0.56308999 0.69910421 0.9089921 ]
 [3.         1.         0.06803028 0.73264973 0.0999984  1.
  0.56593408 0.2693847  0.         2.         0.         2.
  0.22601193 0.88144294 0.38509383 0.9089921 ]
 [0.         1.         0.16622319 0.59011412 0.2999992  1.
  0.24725269 0.23758234 2.         0.         0.         2.
  0.99444858 0.44822661 0.38509383 0.9089921 ]
 [2.         2.         0.05270967 0.67044128 0.2999992  1.
  0.12637354 0.24614725 0.         0.         0.         2.
  0.91343151 0.44822661 0.38509383 0.9089921 ]
 [2.         1.         0.08642555 0.38509383 0.0999984  1.
  0.73076928 0.08622991 0.         2.         1.         2.
  0.22601193 0.1205111  0.85218865 0.9089921 ]
 [0.         1.         0.24837596 0.62389945 0.0999984  1.
  0.51098901 0.09011083 0.         2.         1.         2.
  0.91343151 0.88144294 0.85218865 0.9089921 ]
 [0.         1.         0.17150884 0.24455523 0.9000016  1.
  0.3351648  0.16989608 0.         0.         1.         2.
  0.42397547 0.56308999 0.69910421 0.9089921 ]
 [0.         1.         0.42862227 0.82100415 0.0999984  1.
  0.43406592 0.14514063 1.         2.         1.         2.
  0.38509383 0.1205111  0.85218865 0.9089921 ]
 [0.         0.         0.23301232 0.99444858 0.5        1.
  0.29120875 0.37128064 0.         2.         1.         2.
  0.56308999 0.88144294 0.69910421 0.9089921 ]
 [1.         2.         0.04505993 0.7390824  0.2999992  1.
  0.57692309 0.72993966 0.         0.         1.         2.
  0.22601193 0.56308999 0.69910421 0.9089921 ]
 [1.         1.         0.16526793 0.31221238 0.0999984  1.
  0.28021973 0.39197879 0.         0.         0.         2.
  0.91343151 0.44822661 0.38509383 0.9089921 ]
 [1.         1.         0.43383167 0.92218719 0.7000008  1.
  0.68681323 0.40450175 1.         2.         1.         2.
  0.38509383 0.1205111  0.85218865 0.9089921 ]
 [0.         1.         0.14832595 0.54417572 0.0999984  0.
  0.55494507 0.34857774 2.         2.         1.         2.
  0.99444858 0.88144294 0.85218865 0.9089921 ]
 [0.         2.         0.41766653 0.94339225 0.5        1.
  0.75274731 0.23066054 2.         0.         1.         2.
  0.31221238 0.41136689 0.85218865 0.9089921 ]
 [3.         0.         0.11247297 0.76397201 0.0999984  0.
  0.78571435 0.05755262 1.         0.         0.         2.
  0.85218865 0.44822661 0.38509383 0.9089921 ]
 [0.         0.         0.65314931 0.1205111  0.7000008  1.
  0.19230762 0.18940957 1.         0.         0.         2.
  0.85218865 0.44822661 0.38509383 0.9089921 ]
 [0.         2.         0.51932819 0.56308999 0.7000008  1.
  0.69780224 0.09992786 1.         1.         2.         2.
  0.82100415 0.52447314 0.31221238 0.9089921 ]]
[[1.         0.         0.27244207 0.07069733 0.2999992  1.
  0.95054955 0.55661347 2.         2.         1.         1.
  0.48241935 0.96368694 0.6554307  0.91343151]
 [0.         0.         0.16675883 0.54417572 0.2999992  1.
  0.37912085 0.88116443 1.         2.         0.         0.
  0.63198159 0.53442706 0.20671155 0.62389945]
 [1.         1.         0.24467215 0.279593   0.0999984  1.
  0.06043946 0.79721064 1.         1.         1.         1.
  0.54417572 0.0436732  0.42397547 0.91343151]
 [0.         2.         0.41213634 0.6554307  0.7000008  1.
  0.34615381 0.34698137 0.         0.         0.         0.
  0.22601193 0.16557314 0.83162917 0.9089921 ]
 [2.         2.         0.57655531 0.6554307  0.7000008  1.
  0.46703296 0.94080352 1.         0.         1.         0.
  0.9089921  0.14357878 0.16557314 0.9089921 ]
 [1.         1.         0.74144104 0.88614739 0.0999984  0.
  0.24725269 0.38645499 0.         1.         1.         0.
  0.55372743 0.6554307  0.6554307  0.9089921 ]
 [2.         1.         0.86702441 0.89080549 0.2999992  1.
  0.84065942 0.05647939 1.         2.         0.         0.
  0.83685346 0.53442706 0.20671155 0.62389945]
 [2.         1.         0.72428697 0.61567675 0.9000016  1.
  0.45604395 0.21908144 0.         2.         1.         0.
  0.51430515 0.39841284 0.09625996 0.9089921 ]
 [0.         0.         0.7670464  0.49328864 0.5        1.
  0.70879125 0.15692395 1.         1.         0.         0.
  0.14357878 0.88614739 0.20671155 0.62389945]
 [0.         0.         0.86206511 0.87189123 0.2999992  1.
  0.73076928 0.36465637 0.         1.         2.         1.
  0.81013485 0.53442706 0.63198159 0.91343151]
 [0.         1.         0.81884281 0.34272578 0.7000008  1.
  0.32417579 0.58491771 0.         1.         1.         0.
  0.55372743 0.6554307  0.6554307  0.9089921 ]
 [3.         2.         0.71507604 0.38509383 0.9000016  1.
  0.22527466 0.46775658 2.         1.         1.         0.
  0.01501027 0.57227073 0.35727442 0.9089921 ]
 [2.         2.         0.28989799 0.45990111 0.7000008  0.
  0.80769238 0.0361533  1.         1.         1.         0.
  0.54417572 0.0436732  0.42397547 0.9089921 ]
 [0.         1.         0.55486179 0.76397201 0.2999992  0.
  0.18131861 0.50094924 1.         1.         2.         1.
  0.90451061 0.53442706 0.63198159 0.91343151]
 [3.         0.         0.54399356 0.38509383 0.7000008  0.
  0.0054944  0.53567297 2.         0.         1.         0.
  0.67777156 0.61567675 0.43625651 0.9089921 ]
 [0.         2.         0.64891428 0.16557314 0.5        0.
  0.12637354 0.6680423  0.         2.         0.         1.
  0.35727442 0.96368694 0.83162917 0.91343151]
 [2.         2.         0.80602616 0.99444858 0.9000016  0.
  0.34615381 0.87685083 2.         0.         0.         1.
  0.55372743 0.51430515 0.71280933 0.45990111]
 [3.         1.         0.98663789 0.54417572 0.9000016  0.
  0.79670336 0.17568671 0.         2.         0.         0.
  0.09625996 0.53442706 0.20671155 0.62389945]
 [1.         2.         0.87862407 0.73264973 0.9000016  0.
  0.93956054 0.87407967 1.         1.         2.         1.
  0.26239861 0.53442706 0.63198159 0.91343151]]
01:22:19 bandwidth of the KDEs:
[1.06872705e+00 6.21758117e-01 1.60813017e-01 2.26752192e-01
 2.46337830e-01 2.96411552e-01 1.96266879e-01 1.46744638e-01
 7.01437756e-01 8.85935072e-01 5.24684730e-01 1.00000000e-03
 2.77696501e-01 2.27991670e-01 1.96344012e-01 1.00000000e-03]
[1.01004546 0.72067357 0.21841365 0.22906288 0.25223676 0.45170606
 0.27281018 0.25867149 0.68097251 0.65670611 0.63516888 0.44132063
 0.23737847 0.24053759 0.21301701 0.13247419]
01:22:19 l(x) = nan
01:22:19 g(x) = 0.00027943666654865637
01:22:19 best_vector: [2, 1, 0.0012477939616624203, 0.5762824658363644, 0.20057321974895814, 1, 0.9655943981355507, 0.14432125875956459, 1, 2, 1, 2, 0.48343771185036744, 0.0034832753062686295, 0.0017499774367930043, 0.9076242157678684], 1.8245322133533763e-30, 0.005480856915987591, -1.2941484540406527e-06
01:22:19 done sampling a new configuration.
01:22:19 HBMASTER: schedule new run for iteration 8
01:22:19 HBMASTER: trying submitting job (8, 0, 16) to dispatcher
01:22:19 HBMASTER: submitting job (8, 0, 16) to dispatcher
01:22:19 DISPATCHER: trying to submit job (8, 0, 16)
01:22:19 DISPATCHER: trying to notify the job_runner thread.
01:22:19 HBMASTER: job (8, 0, 16) submitted to dispatcher
01:22:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:22:19 DISPATCHER: Trying to submit another job.
01:22:19 DISPATCHER: starting job (8, 0, 16) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:22:19 DISPATCHER: job (8, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:22:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:22:19 WORKER: start processing job (8, 0, 16)
01:22:19 WORKER: args: ()
01:22:19 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0010057628452220622, 'num_filters_1': 52, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.015408710179779992, 'kernel_size_2': 5, 'num_filters_2': 43}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:23:16 WORKER: done with job (8, 0, 16), trying to register it.
01:23:16 WORKER: registered result for job (8, 0, 16) with dispatcher
01:23:16 DISPATCHER: job (8, 0, 16) finished
01:23:16 DISPATCHER: register_result: lock acquired
01:23:16 DISPATCHER: job (8, 0, 16) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:23:16 job_id: (8, 0, 16)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0010057628452220622, 'num_filters_1': 52, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.015408710179779992, 'kernel_size_2': 5, 'num_filters_2': 43}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6036878309127413, 'info': {'data05': 0.6036878309127413, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0010057628452220622, 'num_filters_1': 52, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.015408710179779992, 'kernel_size_2': 5, 'num_filters_2': 43}"}}
exception: None

01:23:16 job_callback for (8, 0, 16) started
01:23:16 DISPATCHER: Trying to submit another job.
01:23:16 job_callback for (8, 0, 16) got condition
01:23:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:23:16 HBMASTER: Trying to run another job!
01:23:16 job_callback for (8, 0, 16) finished
01:23:16 start sampling a new configuration.
01:23:16 best_vector: [2, 1, 0.25811951188671295, 0.5975359069465791, 0.7522835845940022, 1, 0.8923316775184305, 0.5138285185309247, 1, 2, 0, 2, 0.7584361061692672, 0.013746583718644012, 0.3545787267324379, 0.9122378341533024], 2.0714383537488404e-28, 4.8275634087310566e-05, -1.552644801602306e-05
01:23:16 done sampling a new configuration.
01:23:16 HBMASTER: schedule new run for iteration 8
01:23:16 HBMASTER: trying submitting job (8, 0, 17) to dispatcher
01:23:16 HBMASTER: submitting job (8, 0, 17) to dispatcher
01:23:16 DISPATCHER: trying to submit job (8, 0, 17)
01:23:16 DISPATCHER: trying to notify the job_runner thread.
01:23:16 HBMASTER: job (8, 0, 17) submitted to dispatcher
01:23:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:23:16 DISPATCHER: Trying to submit another job.
01:23:16 DISPATCHER: starting job (8, 0, 17) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:23:16 DISPATCHER: job (8, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:23:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:23:16 WORKER: start processing job (8, 0, 17)
01:23:16 WORKER: args: ()
01:23:16 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.003282759174660615, 'num_filters_1': 55, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.04661292061093964, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 77, 'num_filters_3': 16, 'num_filters_4': 33}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:23:19 DISPATCHER: Starting worker discovery
01:23:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:23:19 DISPATCHER: Finished worker discovery
01:24:13 WORKER: done with job (8, 0, 17), trying to register it.
01:24:13 WORKER: registered result for job (8, 0, 17) with dispatcher
01:24:13 DISPATCHER: job (8, 0, 17) finished
01:24:13 DISPATCHER: register_result: lock acquired
01:24:13 DISPATCHER: job (8, 0, 17) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:24:13 job_id: (8, 0, 17)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.003282759174660615, 'num_filters_1': 55, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.04661292061093964, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 77, 'num_filters_3': 16, 'num_filters_4': 33}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5541701303006434, 'info': {'data05': 0.5541701303006434, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.003282759174660615, 'num_filters_1': 55, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.04661292061093964, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 77, 'num_filters_3': 16, 'num_filters_4': 33}"}}
exception: None

01:24:13 job_callback for (8, 0, 17) started
01:24:13 DISPATCHER: Trying to submit another job.
01:24:13 job_callback for (8, 0, 17) got condition
01:24:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:24:13 HBMASTER: Trying to run another job!
01:24:13 job_callback for (8, 0, 17) finished
01:24:13 start sampling a new configuration.
01:24:13 best_vector: [0, 1, 0.023553147991743087, 0.9881733569896496, 0.32117792252388644, 1, 0.3632790834835154, 0.29339433887232863, 2, 1, 1, 2, 0.47446620335699946, 0.733083938827336, 0.46873318717198337, 0.9102518468871528], 9.99108445852955e-06, 1.1717692455624742, 1.1707245498322133e-05
01:24:13 done sampling a new configuration.
01:24:13 HBMASTER: schedule new run for iteration 8
01:24:13 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
01:24:13 HBMASTER: submitting job (8, 0, 18) to dispatcher
01:24:13 DISPATCHER: trying to submit job (8, 0, 18)
01:24:13 DISPATCHER: trying to notify the job_runner thread.
01:24:13 HBMASTER: job (8, 0, 18) submitted to dispatcher
01:24:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:24:13 DISPATCHER: Trying to submit another job.
01:24:13 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:24:13 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:24:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:24:13 WORKER: start processing job (8, 0, 18)
01:24:13 WORKER: args: ()
01:24:13 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001114567296738626, 'num_filters_1': 125, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.024083235663753318, 'kernel_size_2': 7, 'num_filters_2': 42}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:24:19 DISPATCHER: Starting worker discovery
01:24:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:24:19 DISPATCHER: Finished worker discovery
01:25:12 WORKER: done with job (8, 0, 18), trying to register it.
01:25:12 WORKER: registered result for job (8, 0, 18) with dispatcher
01:25:12 DISPATCHER: job (8, 0, 18) finished
01:25:12 DISPATCHER: register_result: lock acquired
01:25:12 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:25:12 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001114567296738626, 'num_filters_1': 125, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.024083235663753318, 'kernel_size_2': 7, 'num_filters_2': 42}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.619456250948212, 'info': {'data05': 0.619456250948212, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001114567296738626, 'num_filters_1': 125, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.024083235663753318, 'kernel_size_2': 7, 'num_filters_2': 42}"}}
exception: None

01:25:12 job_callback for (8, 0, 18) started
01:25:12 DISPATCHER: Trying to submit another job.
01:25:12 job_callback for (8, 0, 18) got condition
01:25:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:25:12 HBMASTER: Trying to run another job!
01:25:12 job_callback for (8, 0, 18) finished
01:25:12 start sampling a new configuration.
01:25:12 best_vector: [0, 1, 0.14787674001497153, 0.3161976659495758, 0.29114036461452986, 1, 0.5111993125039582, 0.19176195959528228, 2, 0, 2, 2, 0.06354474020259904, 0.45999523160307004, 0.4373662673626821, 0.908873551112907], 7.652951290371295e-05, 0.426275139426224, 3.262262878325125e-05
01:25:12 done sampling a new configuration.
01:25:12 HBMASTER: schedule new run for iteration 8
01:25:12 HBMASTER: trying submitting job (8, 0, 19) to dispatcher
01:25:12 HBMASTER: submitting job (8, 0, 19) to dispatcher
01:25:12 DISPATCHER: trying to submit job (8, 0, 19)
01:25:12 DISPATCHER: trying to notify the job_runner thread.
01:25:12 HBMASTER: job (8, 0, 19) submitted to dispatcher
01:25:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:25:12 DISPATCHER: Trying to submit another job.
01:25:12 DISPATCHER: starting job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:25:12 DISPATCHER: job (8, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:25:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:25:12 WORKER: start processing job (8, 0, 19)
01:25:12 WORKER: args: ()
01:25:12 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0019758477649295014, 'num_filters_1': 30, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.01776184441190741, 'kernel_size_2': 7, 'num_filters_2': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:25:19 DISPATCHER: Starting worker discovery
01:25:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:25:19 DISPATCHER: Finished worker discovery
01:26:11 WORKER: done with job (8, 0, 19), trying to register it.
01:26:11 WORKER: registered result for job (8, 0, 19) with dispatcher
01:26:11 DISPATCHER: job (8, 0, 19) finished
01:26:11 DISPATCHER: register_result: lock acquired
01:26:11 DISPATCHER: job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:26:11 job_id: (8, 0, 19)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0019758477649295014, 'num_filters_1': 30, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.01776184441190741, 'kernel_size_2': 7, 'num_filters_2': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4725267008896965, 'info': {'data05': 0.4725267008896965, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0019758477649295014, 'num_filters_1': 30, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.01776184441190741, 'kernel_size_2': 7, 'num_filters_2': 18}"}}
exception: None

01:26:11 job_callback for (8, 0, 19) started
01:26:11 job_callback for (8, 0, 19) got condition
01:26:11 DISPATCHER: Trying to submit another job.
01:26:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:26:11 HBMASTER: Trying to run another job!
01:26:11 job_callback for (8, 0, 19) finished
01:26:11 start sampling a new configuration.
01:26:11 best_vector: [0, 2, 0.08586048180959399, 0.8804137610287498, 0.5448306556005549, 1, 0.044285088808548645, 0.6173210362618677, 2, 2, 1, 2, 0.030458378070679137, 0.48712600892847385, 0.7470289899039645, 0.9121680237453693], 5.395180433317364e-30, 0.0018535061289602218, -1.1837731746870548e-06
01:26:11 done sampling a new configuration.
01:26:11 HBMASTER: schedule new run for iteration 8
01:26:11 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
01:26:11 HBMASTER: submitting job (8, 0, 20) to dispatcher
01:26:11 DISPATCHER: trying to submit job (8, 0, 20)
01:26:11 DISPATCHER: trying to notify the job_runner thread.
01:26:11 HBMASTER: job (8, 0, 20) submitted to dispatcher
01:26:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:26:11 DISPATCHER: Trying to submit another job.
01:26:11 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:26:11 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:26:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:26:11 WORKER: start processing job (8, 0, 20)
01:26:11 WORKER: args: ()
01:26:11 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0014849812278318888, 'num_filters_1': 100, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.0635555066447402, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 17, 'num_filters_3': 43}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:26:19 DISPATCHER: Starting worker discovery
01:26:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:26:19 DISPATCHER: Finished worker discovery
01:27:13 WORKER: done with job (8, 0, 20), trying to register it.
01:27:13 WORKER: registered result for job (8, 0, 20) with dispatcher
01:27:13 DISPATCHER: job (8, 0, 20) finished
01:27:13 DISPATCHER: register_result: lock acquired
01:27:13 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:27:13 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0014849812278318888, 'num_filters_1': 100, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.0635555066447402, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 17, 'num_filters_3': 43}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.38119706029492756, 'info': {'data05': 0.38119706029492756, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0014849812278318888, 'num_filters_1': 100, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.0635555066447402, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 17, 'num_filters_3': 43}"}}
exception: None

01:27:13 job_callback for (8, 0, 20) started
01:27:13 DISPATCHER: Trying to submit another job.
01:27:13 job_callback for (8, 0, 20) got condition
01:27:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:27:13 HBMASTER: Trying to run another job!
01:27:13 job_callback for (8, 0, 20) finished
01:27:13 start sampling a new configuration.
01:27:13 done sampling a new configuration.
01:27:13 HBMASTER: schedule new run for iteration 8
01:27:13 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
01:27:13 HBMASTER: submitting job (8, 0, 21) to dispatcher
01:27:13 DISPATCHER: trying to submit job (8, 0, 21)
01:27:13 DISPATCHER: trying to notify the job_runner thread.
01:27:13 HBMASTER: job (8, 0, 21) submitted to dispatcher
01:27:13 DISPATCHER: Trying to submit another job.
01:27:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:27:13 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:27:13 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:27:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:27:13 WORKER: start processing job (8, 0, 21)
01:27:13 WORKER: args: ()
01:27:13 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.009927868327220203, 'num_filters_1': 38, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.03572250305478965, 'kernel_size_2': 3, 'num_filters_2': 45}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:27:19 DISPATCHER: Starting worker discovery
01:27:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:27:19 DISPATCHER: Finished worker discovery
01:28:11 WORKER: done with job (8, 0, 21), trying to register it.
01:28:11 WORKER: registered result for job (8, 0, 21) with dispatcher
01:28:11 DISPATCHER: job (8, 0, 21) finished
01:28:11 DISPATCHER: register_result: lock acquired
01:28:11 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:28:11 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.009927868327220203, 'num_filters_1': 38, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.03572250305478965, 'kernel_size_2': 3, 'num_filters_2': 45}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.03185656693596489, 'info': {'data05': 0.03185656693596489, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.009927868327220203, 'num_filters_1': 38, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.03572250305478965, 'kernel_size_2': 3, 'num_filters_2': 45}"}}
exception: None

01:28:11 job_callback for (8, 0, 21) started
01:28:11 job_callback for (8, 0, 21) got condition
01:28:11 DISPATCHER: Trying to submit another job.
01:28:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:28:11 HBMASTER: Trying to run another job!
01:28:11 job_callback for (8, 0, 21) finished
01:28:11 start sampling a new configuration.
01:28:11 done sampling a new configuration.
01:28:11 HBMASTER: schedule new run for iteration 8
01:28:11 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
01:28:11 HBMASTER: submitting job (8, 0, 22) to dispatcher
01:28:11 DISPATCHER: trying to submit job (8, 0, 22)
01:28:11 DISPATCHER: trying to notify the job_runner thread.
01:28:11 HBMASTER: job (8, 0, 22) submitted to dispatcher
01:28:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:28:11 DISPATCHER: Trying to submit another job.
01:28:11 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:28:11 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:28:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:28:11 WORKER: start processing job (8, 0, 22)
01:28:11 WORKER: args: ()
01:28:11 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.02672238420446953, 'num_filters_1': 91, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.05162229947053483}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:28:19 DISPATCHER: Starting worker discovery
01:28:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:28:19 DISPATCHER: Finished worker discovery
01:29:09 WORKER: done with job (8, 0, 22), trying to register it.
01:29:09 WORKER: registered result for job (8, 0, 22) with dispatcher
01:29:09 DISPATCHER: job (8, 0, 22) finished
01:29:09 DISPATCHER: register_result: lock acquired
01:29:09 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:29:09 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.02672238420446953, 'num_filters_1': 91, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.05162229947053483}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0025493481071444017, 'info': {'data05': 0.0025493481071444017, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.02672238420446953, 'num_filters_1': 91, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.05162229947053483}"}}
exception: None

01:29:09 job_callback for (8, 0, 22) started
01:29:09 job_callback for (8, 0, 22) got condition
01:29:09 DISPATCHER: Trying to submit another job.
01:29:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:29:09 HBMASTER: Trying to run another job!
01:29:09 job_callback for (8, 0, 22) finished
01:29:09 start sampling a new configuration.
01:29:10 best_vector: [0, 1, 0.1518438864395984, 0.9188709495181485, 0.7002786750938619, 1, 0.6088152917977259, 0.4228089896538674, 1, 2, 0, 2, 0.13311236659937356, 0.6708363051724986, 0.43921911117573353, 0.9103364364311793], 0.00012543704488873815, 0.0734196060392169, 9.209538418454721e-06
01:29:10 done sampling a new configuration.
01:29:10 HBMASTER: schedule new run for iteration 8
01:29:10 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
01:29:10 HBMASTER: submitting job (8, 0, 23) to dispatcher
01:29:10 DISPATCHER: trying to submit job (8, 0, 23)
01:29:10 DISPATCHER: trying to notify the job_runner thread.
01:29:10 HBMASTER: job (8, 0, 23) submitted to dispatcher
01:29:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:29:10 DISPATCHER: Trying to submit another job.
01:29:10 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:29:10 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:29:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:29:10 WORKER: start processing job (8, 0, 23)
01:29:10 WORKER: args: ()
01:29:10 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002012277044347837, 'num_filters_1': 108, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.03548846197446794, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 21, 'num_filters_3': 64, 'num_filters_4': 39}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:29:19 DISPATCHER: Starting worker discovery
01:29:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:29:19 DISPATCHER: Finished worker discovery
01:30:07 WORKER: done with job (8, 0, 23), trying to register it.
01:30:07 WORKER: registered result for job (8, 0, 23) with dispatcher
01:30:07 DISPATCHER: job (8, 0, 23) finished
01:30:07 DISPATCHER: register_result: lock acquired
01:30:07 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:30:07 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002012277044347837, 'num_filters_1': 108, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.03548846197446794, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 21, 'num_filters_3': 64, 'num_filters_4': 39}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6185792473683915, 'info': {'data05': 0.6185792473683915, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002012277044347837, 'num_filters_1': 108, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.03548846197446794, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 21, 'num_filters_3': 64, 'num_filters_4': 39}"}}
exception: None

01:30:07 job_callback for (8, 0, 23) started
01:30:07 DISPATCHER: Trying to submit another job.
01:30:07 job_callback for (8, 0, 23) got condition
01:30:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:30:07 HBMASTER: Trying to run another job!
01:30:07 job_callback for (8, 0, 23) finished
01:30:07 start sampling a new configuration.
01:30:07 best_vector: [2, 2, 0.20689971834103665, 0.010442686995884465, 0.11409850213213565, 1, 0.3913650966119198, 0.08530015762584409, 2, 1, 0, 2, 0.5642689041287986, 0.2867605009129716, 0.16116576326408188, 0.9080817147047333], 0.00010743103163345631, 0.15042521033685904, 1.6160335530168422e-05
01:30:07 done sampling a new configuration.
01:30:07 HBMASTER: schedule new run for iteration 8
01:30:07 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
01:30:07 HBMASTER: submitting job (8, 0, 24) to dispatcher
01:30:07 DISPATCHER: trying to submit job (8, 0, 24)
01:30:07 DISPATCHER: trying to notify the job_runner thread.
01:30:07 HBMASTER: job (8, 0, 24) submitted to dispatcher
01:30:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:30:07 DISPATCHER: Trying to submit another job.
01:30:07 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:30:07 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:30:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:30:07 WORKER: start processing job (8, 0, 24)
01:30:07 WORKER: args: ()
01:30:07 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0025929816100864187, 'num_filters_1': 16, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.012911540555383749}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:30:19 DISPATCHER: Starting worker discovery
01:30:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:30:19 DISPATCHER: Finished worker discovery
01:31:04 WORKER: done with job (8, 0, 24), trying to register it.
01:31:04 WORKER: registered result for job (8, 0, 24) with dispatcher
01:31:04 DISPATCHER: job (8, 0, 24) finished
01:31:04 DISPATCHER: register_result: lock acquired
01:31:04 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:31:04 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0025929816100864187, 'num_filters_1': 16, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.012911540555383749}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.46200122062018834, 'info': {'data05': 0.46200122062018834, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0025929816100864187, 'num_filters_1': 16, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.012911540555383749}"}}
exception: None

01:31:04 job_callback for (8, 0, 24) started
01:31:04 job_callback for (8, 0, 24) got condition
01:31:04 DISPATCHER: Trying to submit another job.
01:31:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:31:04 HBMASTER: Trying to run another job!
01:31:04 job_callback for (8, 0, 24) finished
01:31:04 start sampling a new configuration.
01:31:04 best_vector: [1, 0, 0.2633730257599339, 0.24594255075170623, 0.11718190427254542, 1, 0.6666940456585801, 0.08464307214051842, 0, 1, 1, 2, 0.22828081879476234, 0.2378310317553739, 0.4821369794335244, 0.9085625908205365], 8.243176271174994e-05, 1.3871864156626958, 0.00011434822145287027
01:31:04 done sampling a new configuration.
01:31:04 HBMASTER: schedule new run for iteration 8
01:31:04 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
01:31:04 HBMASTER: submitting job (8, 0, 25) to dispatcher
01:31:04 DISPATCHER: trying to submit job (8, 0, 25)
01:31:04 DISPATCHER: trying to notify the job_runner thread.
01:31:04 HBMASTER: job (8, 0, 25) submitted to dispatcher
01:31:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:31:04 DISPATCHER: Trying to submit another job.
01:31:04 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:31:04 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:31:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:31:04 WORKER: start processing job (8, 0, 25)
01:31:04 WORKER: args: ()
01:31:04 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.003363148557971279, 'num_filters_1': 26, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.012886149803477638}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:31:19 DISPATCHER: Starting worker discovery
01:31:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:31:19 DISPATCHER: Finished worker discovery
01:32:02 WORKER: done with job (8, 0, 25), trying to register it.
01:32:02 WORKER: registered result for job (8, 0, 25) with dispatcher
01:32:02 DISPATCHER: job (8, 0, 25) finished
01:32:02 DISPATCHER: register_result: lock acquired
01:32:02 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:32:02 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.003363148557971279, 'num_filters_1': 26, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.012886149803477638}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5351890057671198, 'info': {'data05': 0.5351890057671198, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.003363148557971279, 'num_filters_1': 26, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.012886149803477638}"}}
exception: None

01:32:02 job_callback for (8, 0, 25) started
01:32:02 DISPATCHER: Trying to submit another job.
01:32:02 job_callback for (8, 0, 25) got condition
01:32:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:32:02 HBMASTER: Trying to run another job!
01:32:02 job_callback for (8, 0, 25) finished
01:32:02 start sampling a new configuration.
01:32:02 best_vector: [2, 1, 0.5619049679350636, 0.4597594883126283, 0.24097097322208902, 1, 0.6936515836988613, 0.008468227947976109, 1, 0, 1, 2, 0.3929022217979858, 0.12055788423001004, 0.21490204552189762, 0.9109886274910178], 7.564290559848018e-31, 0.013220010417210786, -2.981703826911509e-06
01:32:02 done sampling a new configuration.
01:32:02 HBMASTER: schedule new run for iteration 8
01:32:02 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
01:32:02 HBMASTER: submitting job (8, 0, 26) to dispatcher
01:32:02 DISPATCHER: trying to submit job (8, 0, 26)
01:32:02 DISPATCHER: trying to notify the job_runner thread.
01:32:02 HBMASTER: job (8, 0, 26) submitted to dispatcher
01:32:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:32:02 DISPATCHER: Trying to submit another job.
01:32:02 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:32:02 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:32:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:32:02 WORKER: start processing job (8, 0, 26)
01:32:02 WORKER: args: ()
01:32:02 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.01329872286851253, 'num_filters_1': 41, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.010256930636578013, 'kernel_size_2': 5, 'num_filters_2': 36}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:32:19 DISPATCHER: Starting worker discovery
01:32:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:32:19 DISPATCHER: Finished worker discovery
01:32:59 WORKER: done with job (8, 0, 26), trying to register it.
01:32:59 WORKER: registered result for job (8, 0, 26) with dispatcher
01:32:59 DISPATCHER: job (8, 0, 26) finished
01:32:59 DISPATCHER: register_result: lock acquired
01:32:59 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:32:59 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.01329872286851253, 'num_filters_1': 41, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.010256930636578013, 'kernel_size_2': 5, 'num_filters_2': 36}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5743942438995586, 'info': {'data05': 0.5743942438995586, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.01329872286851253, 'num_filters_1': 41, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.010256930636578013, 'kernel_size_2': 5, 'num_filters_2': 36}"}}
exception: None

01:32:59 job_callback for (8, 0, 26) started
01:32:59 DISPATCHER: Trying to submit another job.
01:32:59 job_callback for (8, 0, 26) got condition
01:32:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:32:59 HBMASTER: Trying to run another job!
01:32:59 job_callback for (8, 0, 26) finished
01:32:59 ITERATION: Advancing config (8, 0, 2) to next budget 133.333333
01:32:59 ITERATION: Advancing config (8, 0, 3) to next budget 133.333333
01:32:59 ITERATION: Advancing config (8, 0, 6) to next budget 133.333333
01:32:59 ITERATION: Advancing config (8, 0, 8) to next budget 133.333333
01:32:59 ITERATION: Advancing config (8, 0, 14) to next budget 133.333333
01:32:59 ITERATION: Advancing config (8, 0, 16) to next budget 133.333333
01:32:59 ITERATION: Advancing config (8, 0, 18) to next budget 133.333333
01:32:59 ITERATION: Advancing config (8, 0, 23) to next budget 133.333333
01:32:59 ITERATION: Advancing config (8, 0, 26) to next budget 133.333333
01:32:59 HBMASTER: schedule new run for iteration 8
01:32:59 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
01:32:59 HBMASTER: submitting job (8, 0, 2) to dispatcher
01:32:59 DISPATCHER: trying to submit job (8, 0, 2)
01:32:59 DISPATCHER: trying to notify the job_runner thread.
01:32:59 HBMASTER: job (8, 0, 2) submitted to dispatcher
01:32:59 DISPATCHER: Trying to submit another job.
01:32:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:32:59 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:32:59 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:32:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:32:59 WORKER: start processing job (8, 0, 2)
01:32:59 WORKER: args: ()
01:32:59 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.007931202237553068, 'num_filters_1': 49, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.017847224791710675, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 80, 'num_filters_3': 57, 'num_filters_4': 20, 'num_filters_5': 105}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:33:19 DISPATCHER: Starting worker discovery
01:33:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:33:19 DISPATCHER: Finished worker discovery
01:34:19 DISPATCHER: Starting worker discovery
01:34:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:34:19 DISPATCHER: Finished worker discovery
01:35:19 DISPATCHER: Starting worker discovery
01:35:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:35:19 DISPATCHER: Finished worker discovery
01:35:26 WORKER: done with job (8, 0, 2), trying to register it.
01:35:26 WORKER: registered result for job (8, 0, 2) with dispatcher
01:35:26 DISPATCHER: job (8, 0, 2) finished
01:35:26 DISPATCHER: register_result: lock acquired
01:35:26 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:35:26 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.007931202237553068, 'num_filters_1': 49, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.017847224791710675, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 80, 'num_filters_3': 57, 'num_filters_4': 20, 'num_filters_5': 105}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6046163200310862, 'info': {'data05': 0.6046163200310862, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.007931202237553068, 'num_filters_1': 49, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.017847224791710675, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 80, 'num_filters_3': 57, 'num_filters_4': 20, 'num_filters_5': 105}"}}
exception: None

01:35:26 job_callback for (8, 0, 2) started
01:35:26 DISPATCHER: Trying to submit another job.
01:35:26 job_callback for (8, 0, 2) got condition
01:35:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:35:26 done building a new model for budget 133.333333 based on 17/31 split
Best loss for this budget:-0.607687





01:35:26 HBMASTER: Trying to run another job!
01:35:26 job_callback for (8, 0, 2) finished
01:35:26 HBMASTER: schedule new run for iteration 8
01:35:26 HBMASTER: trying submitting job (8, 0, 3) to dispatcher
01:35:26 HBMASTER: submitting job (8, 0, 3) to dispatcher
01:35:26 DISPATCHER: trying to submit job (8, 0, 3)
01:35:26 DISPATCHER: trying to notify the job_runner thread.
01:35:26 HBMASTER: job (8, 0, 3) submitted to dispatcher
01:35:26 DISPATCHER: Trying to submit another job.
01:35:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:35:26 DISPATCHER: starting job (8, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:35:26 DISPATCHER: job (8, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:35:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:35:26 WORKER: start processing job (8, 0, 3)
01:35:26 WORKER: args: ()
01:35:26 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.058092393568444305, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.023011106420168438}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:36:19 DISPATCHER: Starting worker discovery
01:36:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:36:19 DISPATCHER: Finished worker discovery
01:37:19 DISPATCHER: Starting worker discovery
01:37:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:37:19 DISPATCHER: Finished worker discovery
01:37:52 WORKER: done with job (8, 0, 3), trying to register it.
01:37:52 WORKER: registered result for job (8, 0, 3) with dispatcher
01:37:52 DISPATCHER: job (8, 0, 3) finished
01:37:52 DISPATCHER: register_result: lock acquired
01:37:52 DISPATCHER: job (8, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:37:52 job_id: (8, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.058092393568444305, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.023011106420168438}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.05228984300424735, 'info': {'data05': 0.05228984300424735, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.058092393568444305, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.023011106420168438}"}}
exception: None

01:37:52 job_callback for (8, 0, 3) started
01:37:52 DISPATCHER: Trying to submit another job.
01:37:52 job_callback for (8, 0, 3) got condition
01:37:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:37:52 done building a new model for budget 133.333333 based on 17/32 split
Best loss for this budget:-0.607687





01:37:52 HBMASTER: Trying to run another job!
01:37:52 job_callback for (8, 0, 3) finished
01:37:52 HBMASTER: schedule new run for iteration 8
01:37:52 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
01:37:52 HBMASTER: submitting job (8, 0, 6) to dispatcher
01:37:52 DISPATCHER: trying to submit job (8, 0, 6)
01:37:52 DISPATCHER: trying to notify the job_runner thread.
01:37:52 HBMASTER: job (8, 0, 6) submitted to dispatcher
01:37:52 DISPATCHER: Trying to submit another job.
01:37:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:37:52 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:37:52 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:37:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:37:52 WORKER: start processing job (8, 0, 6)
01:37:52 WORKER: args: ()
01:37:52 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003294813989948213, 'num_filters_1': 52, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.01193382883298465}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:38:19 DISPATCHER: Starting worker discovery
01:38:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:38:19 DISPATCHER: Finished worker discovery
01:39:19 DISPATCHER: Starting worker discovery
01:39:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:39:19 DISPATCHER: Finished worker discovery
01:40:19 WORKER: done with job (8, 0, 6), trying to register it.
01:40:19 WORKER: registered result for job (8, 0, 6) with dispatcher
01:40:19 DISPATCHER: job (8, 0, 6) finished
01:40:19 DISPATCHER: register_result: lock acquired
01:40:19 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:40:19 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003294813989948213, 'num_filters_1': 52, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.01193382883298465}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5660527251387817, 'info': {'data05': 0.5660527251387817, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003294813989948213, 'num_filters_1': 52, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.01193382883298465}"}}
exception: None

01:40:19 job_callback for (8, 0, 6) started
01:40:19 job_callback for (8, 0, 6) got condition
01:40:19 DISPATCHER: Trying to submit another job.
01:40:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:40:19 done building a new model for budget 133.333333 based on 17/33 split
Best loss for this budget:-0.607687





01:40:19 HBMASTER: Trying to run another job!
01:40:19 job_callback for (8, 0, 6) finished
01:40:19 HBMASTER: schedule new run for iteration 8
01:40:19 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
01:40:19 HBMASTER: submitting job (8, 0, 8) to dispatcher
01:40:19 DISPATCHER: trying to submit job (8, 0, 8)
01:40:19 DISPATCHER: trying to notify the job_runner thread.
01:40:19 HBMASTER: job (8, 0, 8) submitted to dispatcher
01:40:19 DISPATCHER: Trying to submit another job.
01:40:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:40:19 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:40:19 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:40:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:40:19 WORKER: start processing job (8, 0, 8)
01:40:19 WORKER: args: ()
01:40:19 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001045079652683006, 'num_filters_1': 76, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.020296351219533926, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 72, 'num_filters_3': 64, 'num_filters_4': 41}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:40:19 DISPATCHER: Starting worker discovery
01:40:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:40:19 DISPATCHER: Finished worker discovery
01:41:19 DISPATCHER: Starting worker discovery
01:41:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:41:19 DISPATCHER: Finished worker discovery
01:42:19 DISPATCHER: Starting worker discovery
01:42:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:42:19 DISPATCHER: Finished worker discovery
01:42:45 WORKER: done with job (8, 0, 8), trying to register it.
01:42:45 WORKER: registered result for job (8, 0, 8) with dispatcher
01:42:45 DISPATCHER: job (8, 0, 8) finished
01:42:45 DISPATCHER: register_result: lock acquired
01:42:45 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:42:45 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001045079652683006, 'num_filters_1': 76, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.020296351219533926, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 72, 'num_filters_3': 64, 'num_filters_4': 41}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6702131914523325, 'info': {'data05': 0.6702131914523325, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001045079652683006, 'num_filters_1': 76, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.020296351219533926, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 72, 'num_filters_3': 64, 'num_filters_4': 41}"}}
exception: None

01:42:45 job_callback for (8, 0, 8) started
01:42:45 DISPATCHER: Trying to submit another job.
01:42:45 job_callback for (8, 0, 8) got condition
01:42:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:42:45 done building a new model for budget 133.333333 based on 17/34 split
Best loss for this budget:-0.670213





01:42:45 HBMASTER: Trying to run another job!
01:42:45 job_callback for (8, 0, 8) finished
01:42:45 HBMASTER: schedule new run for iteration 8
01:42:45 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
01:42:45 HBMASTER: submitting job (8, 0, 14) to dispatcher
01:42:45 DISPATCHER: trying to submit job (8, 0, 14)
01:42:45 DISPATCHER: trying to notify the job_runner thread.
01:42:45 HBMASTER: job (8, 0, 14) submitted to dispatcher
01:42:45 DISPATCHER: Trying to submit another job.
01:42:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:42:45 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:42:45 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:42:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:42:45 WORKER: start processing job (8, 0, 14)
01:42:45 WORKER: args: ()
01:42:45 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0016886600693088885, 'num_filters_1': 68, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.02598320838698465, 'kernel_size_2': 3, 'num_filters_2': 85}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:43:19 DISPATCHER: Starting worker discovery
01:43:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:43:19 DISPATCHER: Finished worker discovery
01:44:19 DISPATCHER: Starting worker discovery
01:44:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:44:19 DISPATCHER: Finished worker discovery
01:45:13 WORKER: done with job (8, 0, 14), trying to register it.
01:45:13 WORKER: registered result for job (8, 0, 14) with dispatcher
01:45:13 DISPATCHER: job (8, 0, 14) finished
01:45:13 DISPATCHER: register_result: lock acquired
01:45:13 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:45:13 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0016886600693088885, 'num_filters_1': 68, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.02598320838698465, 'kernel_size_2': 3, 'num_filters_2': 85}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5811050357660932, 'info': {'data05': 0.5811050357660932, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0016886600693088885, 'num_filters_1': 68, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.02598320838698465, 'kernel_size_2': 3, 'num_filters_2': 85}"}}
exception: None

01:45:13 job_callback for (8, 0, 14) started
01:45:13 job_callback for (8, 0, 14) got condition
01:45:13 DISPATCHER: Trying to submit another job.
01:45:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:45:13 done building a new model for budget 133.333333 based on 17/34 split
Best loss for this budget:-0.670213





01:45:13 HBMASTER: Trying to run another job!
01:45:13 job_callback for (8, 0, 14) finished
01:45:13 HBMASTER: schedule new run for iteration 8
01:45:13 HBMASTER: trying submitting job (8, 0, 16) to dispatcher
01:45:13 HBMASTER: submitting job (8, 0, 16) to dispatcher
01:45:13 DISPATCHER: trying to submit job (8, 0, 16)
01:45:13 DISPATCHER: trying to notify the job_runner thread.
01:45:13 HBMASTER: job (8, 0, 16) submitted to dispatcher
01:45:13 DISPATCHER: Trying to submit another job.
01:45:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:45:13 DISPATCHER: starting job (8, 0, 16) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:45:13 DISPATCHER: job (8, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:45:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:45:13 WORKER: start processing job (8, 0, 16)
01:45:13 WORKER: args: ()
01:45:13 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0010057628452220622, 'num_filters_1': 52, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.015408710179779992, 'kernel_size_2': 5, 'num_filters_2': 43}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:45:19 DISPATCHER: Starting worker discovery
01:45:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:45:19 DISPATCHER: Finished worker discovery
01:46:19 DISPATCHER: Starting worker discovery
01:46:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:46:19 DISPATCHER: Finished worker discovery
01:47:19 DISPATCHER: Starting worker discovery
01:47:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:47:19 DISPATCHER: Finished worker discovery
01:47:40 WORKER: done with job (8, 0, 16), trying to register it.
01:47:40 WORKER: registered result for job (8, 0, 16) with dispatcher
01:47:40 DISPATCHER: job (8, 0, 16) finished
01:47:40 DISPATCHER: register_result: lock acquired
01:47:40 DISPATCHER: job (8, 0, 16) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:47:40 job_id: (8, 0, 16)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0010057628452220622, 'num_filters_1': 52, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.015408710179779992, 'kernel_size_2': 5, 'num_filters_2': 43}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4918118801428841, 'info': {'data05': 0.4918118801428841, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0010057628452220622, 'num_filters_1': 52, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.015408710179779992, 'kernel_size_2': 5, 'num_filters_2': 43}"}}
exception: None

01:47:40 job_callback for (8, 0, 16) started
01:47:40 DISPATCHER: Trying to submit another job.
01:47:40 job_callback for (8, 0, 16) got condition
01:47:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:47:40 done building a new model for budget 133.333333 based on 17/35 split
Best loss for this budget:-0.670213





01:47:40 HBMASTER: Trying to run another job!
01:47:40 job_callback for (8, 0, 16) finished
01:47:40 HBMASTER: schedule new run for iteration 8
01:47:40 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
01:47:40 HBMASTER: submitting job (8, 0, 18) to dispatcher
01:47:40 DISPATCHER: trying to submit job (8, 0, 18)
01:47:40 DISPATCHER: trying to notify the job_runner thread.
01:47:40 HBMASTER: job (8, 0, 18) submitted to dispatcher
01:47:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:47:40 DISPATCHER: Trying to submit another job.
01:47:40 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:47:40 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:47:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:47:40 WORKER: start processing job (8, 0, 18)
01:47:40 WORKER: args: ()
01:47:40 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001114567296738626, 'num_filters_1': 125, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.024083235663753318, 'kernel_size_2': 7, 'num_filters_2': 42}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:48:19 DISPATCHER: Starting worker discovery
01:48:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:48:19 DISPATCHER: Finished worker discovery
01:49:19 DISPATCHER: Starting worker discovery
01:49:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:49:19 DISPATCHER: Finished worker discovery
01:50:12 WORKER: done with job (8, 0, 18), trying to register it.
01:50:12 WORKER: registered result for job (8, 0, 18) with dispatcher
01:50:12 DISPATCHER: job (8, 0, 18) finished
01:50:12 DISPATCHER: register_result: lock acquired
01:50:12 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:50:12 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001114567296738626, 'num_filters_1': 125, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.024083235663753318, 'kernel_size_2': 7, 'num_filters_2': 42}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6124105757990174, 'info': {'data05': 0.6124105757990174, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001114567296738626, 'num_filters_1': 125, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.024083235663753318, 'kernel_size_2': 7, 'num_filters_2': 42}"}}
exception: None

01:50:12 job_callback for (8, 0, 18) started
01:50:12 DISPATCHER: Trying to submit another job.
01:50:12 job_callback for (8, 0, 18) got condition
01:50:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:50:12 done building a new model for budget 133.333333 based on 17/36 split
Best loss for this budget:-0.670213





01:50:12 HBMASTER: Trying to run another job!
01:50:12 job_callback for (8, 0, 18) finished
01:50:12 HBMASTER: schedule new run for iteration 8
01:50:12 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
01:50:12 HBMASTER: submitting job (8, 0, 23) to dispatcher
01:50:12 DISPATCHER: trying to submit job (8, 0, 23)
01:50:12 DISPATCHER: trying to notify the job_runner thread.
01:50:12 HBMASTER: job (8, 0, 23) submitted to dispatcher
01:50:12 DISPATCHER: Trying to submit another job.
01:50:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:50:12 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:50:12 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:50:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:50:12 WORKER: start processing job (8, 0, 23)
01:50:12 WORKER: args: ()
01:50:12 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002012277044347837, 'num_filters_1': 108, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.03548846197446794, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 21, 'num_filters_3': 64, 'num_filters_4': 39}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:50:19 DISPATCHER: Starting worker discovery
01:50:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:50:19 DISPATCHER: Finished worker discovery
01:51:19 DISPATCHER: Starting worker discovery
01:51:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:51:19 DISPATCHER: Finished worker discovery
01:52:19 DISPATCHER: Starting worker discovery
01:52:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:52:19 DISPATCHER: Finished worker discovery
01:52:41 WORKER: done with job (8, 0, 23), trying to register it.
01:52:41 WORKER: registered result for job (8, 0, 23) with dispatcher
01:52:41 DISPATCHER: job (8, 0, 23) finished
01:52:41 DISPATCHER: register_result: lock acquired
01:52:41 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:52:41 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002012277044347837, 'num_filters_1': 108, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.03548846197446794, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 21, 'num_filters_3': 64, 'num_filters_4': 39}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5065021883985791, 'info': {'data05': 0.5065021883985791, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002012277044347837, 'num_filters_1': 108, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.03548846197446794, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 21, 'num_filters_3': 64, 'num_filters_4': 39}"}}
exception: None

01:52:41 job_callback for (8, 0, 23) started
01:52:41 DISPATCHER: Trying to submit another job.
01:52:41 job_callback for (8, 0, 23) got condition
01:52:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:52:41 done building a new model for budget 133.333333 based on 17/37 split
Best loss for this budget:-0.670213





01:52:41 HBMASTER: Trying to run another job!
01:52:41 job_callback for (8, 0, 23) finished
01:52:41 HBMASTER: schedule new run for iteration 8
01:52:41 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
01:52:41 HBMASTER: submitting job (8, 0, 26) to dispatcher
01:52:41 DISPATCHER: trying to submit job (8, 0, 26)
01:52:41 DISPATCHER: trying to notify the job_runner thread.
01:52:41 HBMASTER: job (8, 0, 26) submitted to dispatcher
01:52:41 DISPATCHER: Trying to submit another job.
01:52:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:52:41 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:52:41 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:52:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:52:41 WORKER: start processing job (8, 0, 26)
01:52:41 WORKER: args: ()
01:52:41 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.01329872286851253, 'num_filters_1': 41, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.010256930636578013, 'kernel_size_2': 5, 'num_filters_2': 36}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:53:19 DISPATCHER: Starting worker discovery
01:53:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:53:19 DISPATCHER: Finished worker discovery
01:54:19 DISPATCHER: Starting worker discovery
01:54:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:54:19 DISPATCHER: Finished worker discovery
01:55:08 WORKER: done with job (8, 0, 26), trying to register it.
01:55:08 WORKER: registered result for job (8, 0, 26) with dispatcher
01:55:08 DISPATCHER: job (8, 0, 26) finished
01:55:08 DISPATCHER: register_result: lock acquired
01:55:08 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
01:55:08 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.01329872286851253, 'num_filters_1': 41, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.010256930636578013, 'kernel_size_2': 5, 'num_filters_2': 36}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.44165648703606, 'info': {'data05': 0.44165648703606, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.01329872286851253, 'num_filters_1': 41, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.010256930636578013, 'kernel_size_2': 5, 'num_filters_2': 36}"}}
exception: None

01:55:08 job_callback for (8, 0, 26) started
01:55:08 DISPATCHER: Trying to submit another job.
01:55:08 job_callback for (8, 0, 26) got condition
01:55:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:55:08 done building a new model for budget 133.333333 based on 17/38 split
Best loss for this budget:-0.670213





01:55:08 HBMASTER: Trying to run another job!
01:55:08 job_callback for (8, 0, 26) finished
01:55:08 ITERATION: Advancing config (8, 0, 2) to next budget 400.000000
01:55:08 ITERATION: Advancing config (8, 0, 8) to next budget 400.000000
01:55:08 ITERATION: Advancing config (8, 0, 18) to next budget 400.000000
01:55:08 HBMASTER: schedule new run for iteration 8
01:55:08 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
01:55:08 HBMASTER: submitting job (8, 0, 2) to dispatcher
01:55:08 DISPATCHER: trying to submit job (8, 0, 2)
01:55:08 DISPATCHER: trying to notify the job_runner thread.
01:55:08 HBMASTER: job (8, 0, 2) submitted to dispatcher
01:55:08 DISPATCHER: Trying to submit another job.
01:55:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:55:08 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:55:08 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
01:55:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:55:08 WORKER: start processing job (8, 0, 2)
01:55:08 WORKER: args: ()
01:55:08 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.007931202237553068, 'num_filters_1': 49, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.017847224791710675, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 80, 'num_filters_3': 57, 'num_filters_4': 20, 'num_filters_5': 105}, 'budget': 400.0, 'working_directory': '.'}
01:55:19 DISPATCHER: Starting worker discovery
01:55:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:55:19 DISPATCHER: Finished worker discovery
01:56:19 DISPATCHER: Starting worker discovery
01:56:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:56:19 DISPATCHER: Finished worker discovery
01:57:19 DISPATCHER: Starting worker discovery
01:57:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:57:19 DISPATCHER: Finished worker discovery
01:58:19 DISPATCHER: Starting worker discovery
01:58:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:58:19 DISPATCHER: Finished worker discovery
01:59:19 DISPATCHER: Starting worker discovery
01:59:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:59:19 DISPATCHER: Finished worker discovery
02:00:19 DISPATCHER: Starting worker discovery
02:00:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:00:19 DISPATCHER: Finished worker discovery
02:01:19 DISPATCHER: Starting worker discovery
02:01:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:01:19 DISPATCHER: Finished worker discovery
02:02:05 WORKER: done with job (8, 0, 2), trying to register it.
02:02:05 WORKER: registered result for job (8, 0, 2) with dispatcher
02:02:05 DISPATCHER: job (8, 0, 2) finished
02:02:05 DISPATCHER: register_result: lock acquired
02:02:05 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
02:02:05 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.007931202237553068, 'num_filters_1': 49, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.017847224791710675, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 80, 'num_filters_3': 57, 'num_filters_4': 20, 'num_filters_5': 105}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.12202543018234768, 'info': {'data05': 0.12202543018234768, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.007931202237553068, 'num_filters_1': 49, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.017847224791710675, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 80, 'num_filters_3': 57, 'num_filters_4': 20, 'num_filters_5': 105}"}}
exception: None

02:02:05 job_callback for (8, 0, 2) started
02:02:05 job_callback for (8, 0, 2) got condition
02:02:05 DISPATCHER: Trying to submit another job.
02:02:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:02:05 HBMASTER: Trying to run another job!
02:02:05 job_callback for (8, 0, 2) finished
02:02:05 HBMASTER: schedule new run for iteration 8
02:02:05 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
02:02:05 HBMASTER: submitting job (8, 0, 8) to dispatcher
02:02:05 DISPATCHER: trying to submit job (8, 0, 8)
02:02:05 DISPATCHER: trying to notify the job_runner thread.
02:02:05 HBMASTER: job (8, 0, 8) submitted to dispatcher
02:02:05 DISPATCHER: Trying to submit another job.
02:02:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:02:05 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:02:05 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:02:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:02:05 WORKER: start processing job (8, 0, 8)
02:02:05 WORKER: args: ()
02:02:05 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001045079652683006, 'num_filters_1': 76, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.020296351219533926, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 72, 'num_filters_3': 64, 'num_filters_4': 41}, 'budget': 400.0, 'working_directory': '.'}
02:02:19 DISPATCHER: Starting worker discovery
02:02:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:02:19 DISPATCHER: Finished worker discovery
02:03:19 DISPATCHER: Starting worker discovery
02:03:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:03:19 DISPATCHER: Finished worker discovery
02:04:19 DISPATCHER: Starting worker discovery
02:04:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:04:19 DISPATCHER: Finished worker discovery
02:05:19 DISPATCHER: Starting worker discovery
02:05:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:05:20 DISPATCHER: Finished worker discovery
02:06:20 DISPATCHER: Starting worker discovery
02:06:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:06:20 DISPATCHER: Finished worker discovery
02:07:20 DISPATCHER: Starting worker discovery
02:07:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:07:20 DISPATCHER: Finished worker discovery
02:08:20 DISPATCHER: Starting worker discovery
02:08:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:08:20 DISPATCHER: Finished worker discovery
02:09:05 WORKER: done with job (8, 0, 8), trying to register it.
02:09:05 WORKER: registered result for job (8, 0, 8) with dispatcher
02:09:05 DISPATCHER: job (8, 0, 8) finished
02:09:05 DISPATCHER: register_result: lock acquired
02:09:05 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
02:09:05 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001045079652683006, 'num_filters_1': 76, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.020296351219533926, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 72, 'num_filters_3': 64, 'num_filters_4': 41}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5865847771206876, 'info': {'data05': 0.5865847771206876, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001045079652683006, 'num_filters_1': 76, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.020296351219533926, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 72, 'num_filters_3': 64, 'num_filters_4': 41}"}}
exception: None

02:09:05 job_callback for (8, 0, 8) started
02:09:05 job_callback for (8, 0, 8) got condition
02:09:05 DISPATCHER: Trying to submit another job.
02:09:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:09:05 HBMASTER: Trying to run another job!
02:09:05 job_callback for (8, 0, 8) finished
02:09:05 HBMASTER: schedule new run for iteration 8
02:09:05 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
02:09:05 HBMASTER: submitting job (8, 0, 18) to dispatcher
02:09:05 DISPATCHER: trying to submit job (8, 0, 18)
02:09:05 DISPATCHER: trying to notify the job_runner thread.
02:09:05 HBMASTER: job (8, 0, 18) submitted to dispatcher
02:09:05 DISPATCHER: Trying to submit another job.
02:09:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:09:05 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:09:05 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:09:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:09:05 WORKER: start processing job (8, 0, 18)
02:09:05 WORKER: args: ()
02:09:05 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001114567296738626, 'num_filters_1': 125, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.024083235663753318, 'kernel_size_2': 7, 'num_filters_2': 42}, 'budget': 400.0, 'working_directory': '.'}
02:09:20 DISPATCHER: Starting worker discovery
02:09:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:09:20 DISPATCHER: Finished worker discovery
02:10:20 DISPATCHER: Starting worker discovery
02:10:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:10:20 DISPATCHER: Finished worker discovery
02:11:20 DISPATCHER: Starting worker discovery
02:11:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:11:20 DISPATCHER: Finished worker discovery
02:12:20 DISPATCHER: Starting worker discovery
02:12:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:12:20 DISPATCHER: Finished worker discovery
02:13:20 DISPATCHER: Starting worker discovery
02:13:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:13:20 DISPATCHER: Finished worker discovery
02:14:20 DISPATCHER: Starting worker discovery
02:14:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:14:20 DISPATCHER: Finished worker discovery
02:15:20 DISPATCHER: Starting worker discovery
02:15:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:15:20 DISPATCHER: Finished worker discovery
02:16:19 WORKER: done with job (8, 0, 18), trying to register it.
02:16:19 WORKER: registered result for job (8, 0, 18) with dispatcher
02:16:19 DISPATCHER: job (8, 0, 18) finished
02:16:19 DISPATCHER: register_result: lock acquired
02:16:19 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
02:16:19 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001114567296738626, 'num_filters_1': 125, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.024083235663753318, 'kernel_size_2': 7, 'num_filters_2': 42}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5096718876333425, 'info': {'data05': 0.5096718876333425, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001114567296738626, 'num_filters_1': 125, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.024083235663753318, 'kernel_size_2': 7, 'num_filters_2': 42}"}}
exception: None

02:16:19 job_callback for (8, 0, 18) started
02:16:19 DISPATCHER: Trying to submit another job.
02:16:19 job_callback for (8, 0, 18) got condition
02:16:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:16:19 HBMASTER: Trying to run another job!
02:16:19 job_callback for (8, 0, 18) finished
02:16:19 ITERATION: Advancing config (8, 0, 8) to next budget 1200.000000
02:16:19 HBMASTER: schedule new run for iteration 8
02:16:19 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
02:16:19 HBMASTER: submitting job (8, 0, 8) to dispatcher
02:16:19 DISPATCHER: trying to submit job (8, 0, 8)
02:16:19 DISPATCHER: trying to notify the job_runner thread.
02:16:19 HBMASTER: job (8, 0, 8) submitted to dispatcher
02:16:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:16:19 DISPATCHER: Trying to submit another job.
02:16:19 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:16:19 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:16:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:16:19 WORKER: start processing job (8, 0, 8)
02:16:19 WORKER: args: ()
02:16:19 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001045079652683006, 'num_filters_1': 76, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.020296351219533926, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 72, 'num_filters_3': 64, 'num_filters_4': 41}, 'budget': 1200.0, 'working_directory': '.'}
02:16:20 DISPATCHER: Starting worker discovery
02:16:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:16:20 DISPATCHER: Finished worker discovery
02:17:20 DISPATCHER: Starting worker discovery
02:17:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:17:20 DISPATCHER: Finished worker discovery
02:18:20 DISPATCHER: Starting worker discovery
02:18:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:18:20 DISPATCHER: Finished worker discovery
02:19:20 DISPATCHER: Starting worker discovery
02:19:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:19:20 DISPATCHER: Finished worker discovery
02:20:20 DISPATCHER: Starting worker discovery
02:20:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:20:20 DISPATCHER: Finished worker discovery
02:21:20 DISPATCHER: Starting worker discovery
02:21:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:21:20 DISPATCHER: Finished worker discovery
02:22:20 DISPATCHER: Starting worker discovery
02:22:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:22:20 DISPATCHER: Finished worker discovery
02:23:20 DISPATCHER: Starting worker discovery
02:23:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:23:20 DISPATCHER: Finished worker discovery
02:24:20 DISPATCHER: Starting worker discovery
02:24:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:24:20 DISPATCHER: Finished worker discovery
02:25:20 DISPATCHER: Starting worker discovery
02:25:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:25:20 DISPATCHER: Finished worker discovery
02:26:20 DISPATCHER: Starting worker discovery
02:26:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:26:20 DISPATCHER: Finished worker discovery
02:27:20 DISPATCHER: Starting worker discovery
02:27:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:27:20 DISPATCHER: Finished worker discovery
02:28:20 DISPATCHER: Starting worker discovery
02:28:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:28:20 DISPATCHER: Finished worker discovery
02:29:20 DISPATCHER: Starting worker discovery
02:29:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:29:20 DISPATCHER: Finished worker discovery
02:30:20 DISPATCHER: Starting worker discovery
02:30:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:30:20 DISPATCHER: Finished worker discovery
02:31:20 DISPATCHER: Starting worker discovery
02:31:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:31:20 DISPATCHER: Finished worker discovery
02:32:20 DISPATCHER: Starting worker discovery
02:32:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:32:20 DISPATCHER: Finished worker discovery
02:33:20 DISPATCHER: Starting worker discovery
02:33:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:33:20 DISPATCHER: Finished worker discovery
02:34:20 DISPATCHER: Starting worker discovery
02:34:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:34:20 DISPATCHER: Finished worker discovery
02:35:20 DISPATCHER: Starting worker discovery
02:35:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:35:20 DISPATCHER: Finished worker discovery
02:36:20 DISPATCHER: Starting worker discovery
02:36:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:36:20 DISPATCHER: Finished worker discovery
02:36:51 WORKER: done with job (8, 0, 8), trying to register it.
02:36:51 WORKER: registered result for job (8, 0, 8) with dispatcher
02:36:51 DISPATCHER: job (8, 0, 8) finished
02:36:51 DISPATCHER: register_result: lock acquired
02:36:51 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
02:36:51 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001045079652683006, 'num_filters_1': 76, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.020296351219533926, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 72, 'num_filters_3': 64, 'num_filters_4': 41}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.4214700397103456, 'info': {'data05': 0.4214700397103456, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001045079652683006, 'num_filters_1': 76, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.020296351219533926, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 72, 'num_filters_3': 64, 'num_filters_4': 41}"}}
exception: None

02:36:51 job_callback for (8, 0, 8) started
02:36:51 DISPATCHER: Trying to submit another job.
02:36:51 job_callback for (8, 0, 8) got condition
02:36:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:36:51 HBMASTER: Trying to run another job!
02:36:51 job_callback for (8, 0, 8) finished
02:36:51 start sampling a new configuration.
02:36:51 best_vector: [0, 0, 0.009066474772473548, 0.7732618638933803, 0.9393072207432155, 1, 0.7364019416268608, 0.13594365861119886, 0, 1, 0, 2, 0.8266376587133791, 0.6562541868312309, 0.4340032129012558, 0.9076141808152917], 1.857991569405142e-06, 6.704011259630942, 1.2455996401591437e-05
02:36:51 done sampling a new configuration.
02:36:51 HBMASTER: schedule new run for iteration 9
02:36:51 HBMASTER: trying submitting job (9, 0, 0) to dispatcher
02:36:51 HBMASTER: submitting job (9, 0, 0) to dispatcher
02:36:51 DISPATCHER: trying to submit job (9, 0, 0)
02:36:51 DISPATCHER: trying to notify the job_runner thread.
02:36:51 HBMASTER: job (9, 0, 0) submitted to dispatcher
02:36:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:36:51 DISPATCHER: Trying to submit another job.
02:36:51 DISPATCHER: starting job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:36:51 DISPATCHER: job (9, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:36:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:36:51 WORKER: start processing job (9, 0, 0)
02:36:51 WORKER: args: ()
02:36:51 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001042636560413345, 'num_filters_1': 80, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.015026809390281174, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 89, 'num_filters_3': 62, 'num_filters_4': 39, 'num_filters_5': 106}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:37:20 DISPATCHER: Starting worker discovery
02:37:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:37:20 DISPATCHER: Finished worker discovery
02:38:20 DISPATCHER: Starting worker discovery
02:38:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:38:20 DISPATCHER: Finished worker discovery
02:39:19 WORKER: done with job (9, 0, 0), trying to register it.
02:39:19 WORKER: registered result for job (9, 0, 0) with dispatcher
02:39:19 DISPATCHER: job (9, 0, 0) finished
02:39:19 DISPATCHER: register_result: lock acquired
02:39:19 DISPATCHER: job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
02:39:19 job_id: (9, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001042636560413345, 'num_filters_1': 80, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.015026809390281174, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 89, 'num_filters_3': 62, 'num_filters_4': 39, 'num_filters_5': 106}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6565267949560698, 'info': {'data05': 0.6565267949560698, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001042636560413345, 'num_filters_1': 80, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.015026809390281174, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 89, 'num_filters_3': 62, 'num_filters_4': 39, 'num_filters_5': 106}"}}
exception: None

02:39:19 job_callback for (9, 0, 0) started
02:39:19 DISPATCHER: Trying to submit another job.
02:39:19 job_callback for (9, 0, 0) got condition
02:39:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:39:19 done building a new model for budget 133.333333 based on 17/39 split
Best loss for this budget:-0.670213





02:39:19 HBMASTER: Trying to run another job!
02:39:19 job_callback for (9, 0, 0) finished
02:39:19 start sampling a new configuration.
02:39:19 done sampling a new configuration.
02:39:19 HBMASTER: schedule new run for iteration 9
02:39:19 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
02:39:19 HBMASTER: submitting job (9, 0, 1) to dispatcher
02:39:19 DISPATCHER: trying to submit job (9, 0, 1)
02:39:19 DISPATCHER: trying to notify the job_runner thread.
02:39:19 HBMASTER: job (9, 0, 1) submitted to dispatcher
02:39:19 DISPATCHER: Trying to submit another job.
02:39:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:39:19 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:39:19 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:39:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:39:19 WORKER: start processing job (9, 0, 1)
02:39:19 WORKER: args: ()
02:39:19 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0024064645671595586, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.08369524065157535, 'kernel_size_2': 3, 'num_filters_2': 18}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:39:20 DISPATCHER: Starting worker discovery
02:39:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:39:20 DISPATCHER: Finished worker discovery
02:40:20 DISPATCHER: Starting worker discovery
02:40:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:40:20 DISPATCHER: Finished worker discovery
02:41:20 DISPATCHER: Starting worker discovery
02:41:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:41:20 DISPATCHER: Finished worker discovery
02:41:47 WORKER: done with job (9, 0, 1), trying to register it.
02:41:47 WORKER: registered result for job (9, 0, 1) with dispatcher
02:41:47 DISPATCHER: job (9, 0, 1) finished
02:41:47 DISPATCHER: register_result: lock acquired
02:41:47 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
02:41:47 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0024064645671595586, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.08369524065157535, 'kernel_size_2': 3, 'num_filters_2': 18}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.26911462611567993, 'info': {'data05': 0.26911462611567993, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0024064645671595586, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.08369524065157535, 'kernel_size_2': 3, 'num_filters_2': 18}"}}
exception: None

02:41:47 job_callback for (9, 0, 1) started
02:41:47 DISPATCHER: Trying to submit another job.
02:41:47 job_callback for (9, 0, 1) got condition
02:41:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:41:47 done building a new model for budget 133.333333 based on 17/39 split
Best loss for this budget:-0.670213





02:41:47 HBMASTER: Trying to run another job!
02:41:47 job_callback for (9, 0, 1) finished
02:41:47 start sampling a new configuration.
02:41:47 best_vector: [1, 1, 0.6235899057894341, 0.5128712964160246, 0.4775124705829431, 1, 0.8096787149408018, 0.145310529433454, 1, 1, 1, 2, 0.16676822310580924, 0.6462439189596596, 0.47816117038945605, 0.9053170241432916], 3.0302964833113285e-05, 6.213209180218222, 0.0001882786592889294
02:41:47 done sampling a new configuration.
02:41:47 HBMASTER: schedule new run for iteration 9
02:41:47 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
02:41:47 HBMASTER: submitting job (9, 0, 2) to dispatcher
02:41:47 DISPATCHER: trying to submit job (9, 0, 2)
02:41:47 DISPATCHER: trying to notify the job_runner thread.
02:41:47 HBMASTER: job (9, 0, 2) submitted to dispatcher
02:41:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:41:47 DISPATCHER: Trying to submit another job.
02:41:47 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:41:47 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:41:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:41:47 WORKER: start processing job (9, 0, 2)
02:41:47 WORKER: args: ()
02:41:47 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.01766769167295138, 'num_filters_1': 46, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.015454443013706689, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 22, 'num_filters_3': 61}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:42:20 DISPATCHER: Starting worker discovery
02:42:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:42:20 DISPATCHER: Finished worker discovery
02:43:20 DISPATCHER: Starting worker discovery
02:43:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:43:20 DISPATCHER: Finished worker discovery
02:44:15 WORKER: done with job (9, 0, 2), trying to register it.
02:44:15 WORKER: registered result for job (9, 0, 2) with dispatcher
02:44:15 DISPATCHER: job (9, 0, 2) finished
02:44:15 DISPATCHER: register_result: lock acquired
02:44:15 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
02:44:15 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.01766769167295138, 'num_filters_1': 46, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.015454443013706689, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 22, 'num_filters_3': 61}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.08263515439811359, 'info': {'data05': 0.08263515439811359, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.01766769167295138, 'num_filters_1': 46, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.015454443013706689, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 22, 'num_filters_3': 61}"}}
exception: None

02:44:15 job_callback for (9, 0, 2) started
02:44:15 job_callback for (9, 0, 2) got condition
02:44:15 DISPATCHER: Trying to submit another job.
02:44:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:44:15 done building a new model for budget 133.333333 based on 17/40 split
Best loss for this budget:-0.670213





02:44:15 HBMASTER: Trying to run another job!
02:44:15 job_callback for (9, 0, 2) finished
02:44:15 start sampling a new configuration.
02:44:15 best_vector: [2, 1, 0.006192593010375965, 0.9157418809569581, 0.29162485245850805, 1, 0.6602197336590264, 0.16127637880040263, 1, 1, 0, 2, 0.8856485951452042, 0.7039048831487427, 0.24221289093336973, 0.9086777864529181], 2.435642435059933e-05, 11.997940026837062, 0.00029222691862668457
02:44:15 done sampling a new configuration.
02:44:15 HBMASTER: schedule new run for iteration 9
02:44:15 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
02:44:15 HBMASTER: submitting job (9, 0, 3) to dispatcher
02:44:15 DISPATCHER: trying to submit job (9, 0, 3)
02:44:15 DISPATCHER: trying to notify the job_runner thread.
02:44:15 HBMASTER: job (9, 0, 3) submitted to dispatcher
02:44:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:44:15 DISPATCHER: Trying to submit another job.
02:44:15 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:44:15 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:44:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:44:15 WORKER: start processing job (9, 0, 3)
02:44:15 WORKER: args: ()
02:44:15 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0010289284744871533, 'num_filters_1': 108, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.016211582338254798, 'kernel_size_2': 5, 'num_filters_2': 101}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:44:20 DISPATCHER: Starting worker discovery
02:44:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:44:20 DISPATCHER: Finished worker discovery
02:45:20 DISPATCHER: Starting worker discovery
02:45:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:45:20 DISPATCHER: Finished worker discovery
02:46:20 DISPATCHER: Starting worker discovery
02:46:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:46:20 DISPATCHER: Finished worker discovery
02:46:43 WORKER: done with job (9, 0, 3), trying to register it.
02:46:43 WORKER: registered result for job (9, 0, 3) with dispatcher
02:46:43 DISPATCHER: job (9, 0, 3) finished
02:46:43 DISPATCHER: register_result: lock acquired
02:46:43 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
02:46:43 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0010289284744871533, 'num_filters_1': 108, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.016211582338254798, 'kernel_size_2': 5, 'num_filters_2': 101}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6448847892143974, 'info': {'data05': 0.6448847892143974, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0010289284744871533, 'num_filters_1': 108, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.016211582338254798, 'kernel_size_2': 5, 'num_filters_2': 101}"}}
exception: None

02:46:43 job_callback for (9, 0, 3) started
02:46:43 DISPATCHER: Trying to submit another job.
02:46:43 job_callback for (9, 0, 3) got condition
02:46:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:46:43 done building a new model for budget 133.333333 based on 17/41 split
Best loss for this budget:-0.670213





02:46:43 HBMASTER: Trying to run another job!
02:46:43 job_callback for (9, 0, 3) finished
02:46:43 start sampling a new configuration.
02:46:43 done sampling a new configuration.
02:46:43 HBMASTER: schedule new run for iteration 9
02:46:43 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
02:46:43 HBMASTER: submitting job (9, 0, 4) to dispatcher
02:46:43 DISPATCHER: trying to submit job (9, 0, 4)
02:46:43 DISPATCHER: trying to notify the job_runner thread.
02:46:43 HBMASTER: job (9, 0, 4) submitted to dispatcher
02:46:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:46:43 DISPATCHER: Trying to submit another job.
02:46:43 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:46:43 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:46:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:46:43 WORKER: start processing job (9, 0, 4)
02:46:43 WORKER: args: ()
02:46:43 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.05497066668734546, 'num_filters_1': 57, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.025505065768275877}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:47:20 DISPATCHER: Starting worker discovery
02:47:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:47:20 DISPATCHER: Finished worker discovery
02:48:20 DISPATCHER: Starting worker discovery
02:48:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:48:20 DISPATCHER: Finished worker discovery
02:49:11 WORKER: done with job (9, 0, 4), trying to register it.
02:49:11 WORKER: registered result for job (9, 0, 4) with dispatcher
02:49:11 DISPATCHER: job (9, 0, 4) finished
02:49:11 DISPATCHER: register_result: lock acquired
02:49:11 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
02:49:11 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.05497066668734546, 'num_filters_1': 57, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.025505065768275877}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.02626628037028518, 'info': {'data05': 0.02626628037028518, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.05497066668734546, 'num_filters_1': 57, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.025505065768275877}"}}
exception: None

02:49:11 job_callback for (9, 0, 4) started
02:49:11 job_callback for (9, 0, 4) got condition
02:49:11 DISPATCHER: Trying to submit another job.
02:49:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:49:11 done building a new model for budget 133.333333 based on 17/42 split
Best loss for this budget:-0.670213





02:49:11 HBMASTER: Trying to run another job!
02:49:11 job_callback for (9, 0, 4) finished
02:49:11 start sampling a new configuration.
02:49:11 done sampling a new configuration.
02:49:11 HBMASTER: schedule new run for iteration 9
02:49:11 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
02:49:11 HBMASTER: submitting job (9, 0, 5) to dispatcher
02:49:11 DISPATCHER: trying to submit job (9, 0, 5)
02:49:11 DISPATCHER: trying to notify the job_runner thread.
02:49:11 HBMASTER: job (9, 0, 5) submitted to dispatcher
02:49:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:49:11 DISPATCHER: Trying to submit another job.
02:49:11 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:49:11 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:49:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:49:11 WORKER: start processing job (9, 0, 5)
02:49:11 WORKER: args: ()
02:49:11 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.006406802130321269, 'num_filters_1': 100, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.12381448490423379, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 44, 'num_filters_3': 51, 'num_filters_4': 36, 'num_filters_5': 53}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:49:20 DISPATCHER: Starting worker discovery
02:49:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:49:20 DISPATCHER: Finished worker discovery
02:50:20 DISPATCHER: Starting worker discovery
02:50:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:50:20 DISPATCHER: Finished worker discovery
02:51:20 DISPATCHER: Starting worker discovery
02:51:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:51:20 DISPATCHER: Finished worker discovery
02:51:39 WORKER: done with job (9, 0, 5), trying to register it.
02:51:39 WORKER: registered result for job (9, 0, 5) with dispatcher
02:51:39 DISPATCHER: job (9, 0, 5) finished
02:51:39 DISPATCHER: register_result: lock acquired
02:51:39 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
02:51:39 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.006406802130321269, 'num_filters_1': 100, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.12381448490423379, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 44, 'num_filters_3': 51, 'num_filters_4': 36, 'num_filters_5': 53}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data05': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.006406802130321269, 'num_filters_1': 100, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.12381448490423379, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 44, 'num_filters_3': 51, 'num_filters_4': 36, 'num_filters_5': 53}"}}
exception: None

02:51:39 job_callback for (9, 0, 5) started
02:51:39 DISPATCHER: Trying to submit another job.
02:51:39 job_callback for (9, 0, 5) got condition
02:51:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:51:39 done building a new model for budget 133.333333 based on 17/43 split
Best loss for this budget:-0.670213





02:51:39 HBMASTER: Trying to run another job!
02:51:39 job_callback for (9, 0, 5) finished
02:51:39 start sampling a new configuration.
02:51:39 best_vector: [0, 0, 0.08775077678763851, 0.4353649835290135, 0.1460204620309068, 1, 0.7793729615446836, 0.3254284955233857, 0, 1, 0, 2, 0.7320916872774889, 0.6615032559498457, 0.5688956020544171, 0.9102966169429227], 2.6114087502223786e-06, 33.18468595772847, 8.665877928339382e-05
02:51:39 done sampling a new configuration.
02:51:39 HBMASTER: schedule new run for iteration 9
02:51:39 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
02:51:39 HBMASTER: submitting job (9, 0, 6) to dispatcher
02:51:39 DISPATCHER: trying to submit job (9, 0, 6)
02:51:39 DISPATCHER: trying to notify the job_runner thread.
02:51:39 HBMASTER: job (9, 0, 6) submitted to dispatcher
02:51:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:51:39 DISPATCHER: Trying to submit another job.
02:51:39 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:51:39 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:51:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:51:39 WORKER: start processing job (9, 0, 6)
02:51:39 WORKER: args: ()
02:51:39 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001497964611613133, 'num_filters_1': 39, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.02650893218456683}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:52:20 DISPATCHER: Starting worker discovery
02:52:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:52:20 DISPATCHER: Finished worker discovery
02:53:20 DISPATCHER: Starting worker discovery
02:53:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:53:20 DISPATCHER: Finished worker discovery
02:54:08 WORKER: done with job (9, 0, 6), trying to register it.
02:54:08 WORKER: registered result for job (9, 0, 6) with dispatcher
02:54:08 DISPATCHER: job (9, 0, 6) finished
02:54:08 DISPATCHER: register_result: lock acquired
02:54:08 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
02:54:08 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001497964611613133, 'num_filters_1': 39, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.02650893218456683}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.521483874998564, 'info': {'data05': 0.521483874998564, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001497964611613133, 'num_filters_1': 39, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.02650893218456683}"}}
exception: None

02:54:08 job_callback for (9, 0, 6) started
02:54:08 job_callback for (9, 0, 6) got condition
02:54:08 DISPATCHER: Trying to submit another job.
02:54:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:54:08 done building a new model for budget 133.333333 based on 17/44 split
Best loss for this budget:-0.670213





02:54:08 HBMASTER: Trying to run another job!
02:54:08 job_callback for (9, 0, 6) finished
02:54:08 start sampling a new configuration.
02:54:08 best_vector: [1, 1, 0.050506605723646444, 0.7423256242503191, 0.535156976901855, 1, 0.8362934993067713, 0.09232903717251517, 1, 2, 0, 2, 0.801653405006723, 0.664905372945723, 0.46391336077652057, 0.9095053710438942], 6.848422460743209e-07, 164.03431498822826, 0.00011233762870980089
02:54:08 done sampling a new configuration.
02:54:08 HBMASTER: schedule new run for iteration 9
02:54:08 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
02:54:08 HBMASTER: submitting job (9, 0, 7) to dispatcher
02:54:08 DISPATCHER: trying to submit job (9, 0, 7)
02:54:08 DISPATCHER: trying to notify the job_runner thread.
02:54:08 HBMASTER: job (9, 0, 7) submitted to dispatcher
02:54:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:54:08 DISPATCHER: Trying to submit another job.
02:54:08 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:54:08 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:54:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:54:08 WORKER: start processing job (9, 0, 7)
02:54:08 WORKER: args: ()
02:54:08 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0012618659205758187, 'num_filters_1': 75, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.01318629680367574, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 84, 'num_filters_3': 63}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:54:20 DISPATCHER: Starting worker discovery
02:54:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:54:20 DISPATCHER: Finished worker discovery
02:55:20 DISPATCHER: Starting worker discovery
02:55:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:55:20 DISPATCHER: Finished worker discovery
02:56:20 DISPATCHER: Starting worker discovery
02:56:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:56:20 DISPATCHER: Finished worker discovery
02:56:35 WORKER: done with job (9, 0, 7), trying to register it.
02:56:35 WORKER: registered result for job (9, 0, 7) with dispatcher
02:56:35 DISPATCHER: job (9, 0, 7) finished
02:56:35 DISPATCHER: register_result: lock acquired
02:56:35 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
02:56:35 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0012618659205758187, 'num_filters_1': 75, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.01318629680367574, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 84, 'num_filters_3': 63}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.627690141972128, 'info': {'data05': 0.627690141972128, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0012618659205758187, 'num_filters_1': 75, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.01318629680367574, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 84, 'num_filters_3': 63}"}}
exception: None

02:56:35 job_callback for (9, 0, 7) started
02:56:35 job_callback for (9, 0, 7) got condition
02:56:35 DISPATCHER: Trying to submit another job.
02:56:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:56:35 done building a new model for budget 133.333333 based on 17/45 split
Best loss for this budget:-0.670213





02:56:35 HBMASTER: Trying to run another job!
02:56:35 job_callback for (9, 0, 7) finished
02:56:35 start sampling a new configuration.
02:56:35 best_vector: [0, 1, 0.024224350928530418, 0.6667533283629309, 0.505574396725488, 1, 0.5397203165573791, 0.29959194076953305, 1, 2, 0, 2, 0.6916438904687254, 0.6432127456511605, 0.3406929906242582, 0.91067050114525], 4.1853717672512724e-07, 176.33151135593226, 7.38012929305866e-05
02:56:35 done sampling a new configuration.
02:56:35 HBMASTER: schedule new run for iteration 9
02:56:35 HBMASTER: trying submitting job (9, 0, 8) to dispatcher
02:56:35 HBMASTER: submitting job (9, 0, 8) to dispatcher
02:56:35 DISPATCHER: trying to submit job (9, 0, 8)
02:56:35 DISPATCHER: trying to notify the job_runner thread.
02:56:35 HBMASTER: job (9, 0, 8) submitted to dispatcher
02:56:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:56:35 DISPATCHER: Trying to submit another job.
02:56:35 DISPATCHER: starting job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:56:35 DISPATCHER: job (9, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:56:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:56:35 WORKER: start processing job (9, 0, 8)
02:56:35 WORKER: args: ()
02:56:35 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0011180177583838026, 'num_filters_1': 64, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.02453455026069551, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 67, 'num_filters_3': 60}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:57:20 DISPATCHER: Starting worker discovery
02:57:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:57:20 DISPATCHER: Finished worker discovery
02:58:20 DISPATCHER: Starting worker discovery
02:58:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:58:20 DISPATCHER: Finished worker discovery
02:59:04 WORKER: done with job (9, 0, 8), trying to register it.
02:59:04 WORKER: registered result for job (9, 0, 8) with dispatcher
02:59:04 DISPATCHER: job (9, 0, 8) finished
02:59:04 DISPATCHER: register_result: lock acquired
02:59:04 DISPATCHER: job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
02:59:04 job_id: (9, 0, 8)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0011180177583838026, 'num_filters_1': 64, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.02453455026069551, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 67, 'num_filters_3': 60}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5595729808249013, 'info': {'data05': 0.5595729808249013, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0011180177583838026, 'num_filters_1': 64, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.02453455026069551, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 67, 'num_filters_3': 60}"}}
exception: None

02:59:04 job_callback for (9, 0, 8) started
02:59:04 job_callback for (9, 0, 8) got condition
02:59:04 DISPATCHER: Trying to submit another job.
02:59:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:59:04 done building a new model for budget 133.333333 based on 17/45 split
Best loss for this budget:-0.670213





02:59:04 HBMASTER: Trying to run another job!
02:59:04 job_callback for (9, 0, 8) finished
02:59:04 ITERATION: Advancing config (9, 0, 0) to next budget 400.000000
02:59:04 ITERATION: Advancing config (9, 0, 3) to next budget 400.000000
02:59:04 ITERATION: Advancing config (9, 0, 7) to next budget 400.000000
02:59:04 HBMASTER: schedule new run for iteration 9
02:59:04 HBMASTER: trying submitting job (9, 0, 0) to dispatcher
02:59:04 HBMASTER: submitting job (9, 0, 0) to dispatcher
02:59:04 DISPATCHER: trying to submit job (9, 0, 0)
02:59:04 DISPATCHER: trying to notify the job_runner thread.
02:59:04 HBMASTER: job (9, 0, 0) submitted to dispatcher
02:59:04 DISPATCHER: Trying to submit another job.
02:59:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:59:04 DISPATCHER: starting job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:59:05 DISPATCHER: job (9, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
02:59:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:59:05 WORKER: start processing job (9, 0, 0)
02:59:05 WORKER: args: ()
02:59:05 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001042636560413345, 'num_filters_1': 80, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.015026809390281174, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 89, 'num_filters_3': 62, 'num_filters_4': 39, 'num_filters_5': 106}, 'budget': 400.0, 'working_directory': '.'}
02:59:20 DISPATCHER: Starting worker discovery
02:59:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:59:20 DISPATCHER: Finished worker discovery
03:00:20 DISPATCHER: Starting worker discovery
03:00:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:00:20 DISPATCHER: Finished worker discovery
03:01:20 DISPATCHER: Starting worker discovery
03:01:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:01:20 DISPATCHER: Finished worker discovery
03:02:20 DISPATCHER: Starting worker discovery
03:02:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:02:20 DISPATCHER: Finished worker discovery
03:03:20 DISPATCHER: Starting worker discovery
03:03:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:03:20 DISPATCHER: Finished worker discovery
03:04:20 DISPATCHER: Starting worker discovery
03:04:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:04:20 DISPATCHER: Finished worker discovery
03:05:20 DISPATCHER: Starting worker discovery
03:05:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:05:20 DISPATCHER: Finished worker discovery
03:06:06 WORKER: done with job (9, 0, 0), trying to register it.
03:06:06 WORKER: registered result for job (9, 0, 0) with dispatcher
03:06:06 DISPATCHER: job (9, 0, 0) finished
03:06:06 DISPATCHER: register_result: lock acquired
03:06:06 DISPATCHER: job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
03:06:06 job_id: (9, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001042636560413345, 'num_filters_1': 80, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.015026809390281174, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 89, 'num_filters_3': 62, 'num_filters_4': 39, 'num_filters_5': 106}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5487696225964074, 'info': {'data05': 0.5487696225964074, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001042636560413345, 'num_filters_1': 80, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.015026809390281174, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 89, 'num_filters_3': 62, 'num_filters_4': 39, 'num_filters_5': 106}"}}
exception: None

03:06:06 job_callback for (9, 0, 0) started
03:06:06 job_callback for (9, 0, 0) got condition
03:06:06 DISPATCHER: Trying to submit another job.
03:06:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:06:06 HBMASTER: Trying to run another job!
03:06:06 job_callback for (9, 0, 0) finished
03:06:06 HBMASTER: schedule new run for iteration 9
03:06:06 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
03:06:06 HBMASTER: submitting job (9, 0, 3) to dispatcher
03:06:06 DISPATCHER: trying to submit job (9, 0, 3)
03:06:06 DISPATCHER: trying to notify the job_runner thread.
03:06:06 HBMASTER: job (9, 0, 3) submitted to dispatcher
03:06:06 DISPATCHER: Trying to submit another job.
03:06:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:06:06 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
03:06:06 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
03:06:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:06:06 WORKER: start processing job (9, 0, 3)
03:06:06 WORKER: args: ()
03:06:06 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0010289284744871533, 'num_filters_1': 108, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.016211582338254798, 'kernel_size_2': 5, 'num_filters_2': 101}, 'budget': 400.0, 'working_directory': '.'}
03:06:20 DISPATCHER: Starting worker discovery
03:06:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:06:20 DISPATCHER: Finished worker discovery
03:07:20 DISPATCHER: Starting worker discovery
03:07:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:07:20 DISPATCHER: Finished worker discovery
03:08:20 DISPATCHER: Starting worker discovery
03:08:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:08:20 DISPATCHER: Finished worker discovery
03:09:20 DISPATCHER: Starting worker discovery
03:09:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:09:20 DISPATCHER: Finished worker discovery
03:10:20 DISPATCHER: Starting worker discovery
03:10:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:10:20 DISPATCHER: Finished worker discovery
03:11:20 DISPATCHER: Starting worker discovery
03:11:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:11:20 DISPATCHER: Finished worker discovery
03:12:20 DISPATCHER: Starting worker discovery
03:12:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:12:20 DISPATCHER: Finished worker discovery
03:13:04 WORKER: done with job (9, 0, 3), trying to register it.
03:13:04 WORKER: registered result for job (9, 0, 3) with dispatcher
03:13:04 DISPATCHER: job (9, 0, 3) finished
03:13:04 DISPATCHER: register_result: lock acquired
03:13:04 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
03:13:04 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0010289284744871533, 'num_filters_1': 108, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.016211582338254798, 'kernel_size_2': 5, 'num_filters_2': 101}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6183053680323368, 'info': {'data05': 0.6183053680323368, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0010289284744871533, 'num_filters_1': 108, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.016211582338254798, 'kernel_size_2': 5, 'num_filters_2': 101}"}}
exception: None

03:13:04 job_callback for (9, 0, 3) started
03:13:04 job_callback for (9, 0, 3) got condition
03:13:04 DISPATCHER: Trying to submit another job.
03:13:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:13:04 HBMASTER: Trying to run another job!
03:13:04 job_callback for (9, 0, 3) finished
03:13:04 HBMASTER: schedule new run for iteration 9
03:13:04 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
03:13:04 HBMASTER: submitting job (9, 0, 7) to dispatcher
03:13:04 DISPATCHER: trying to submit job (9, 0, 7)
03:13:04 DISPATCHER: trying to notify the job_runner thread.
03:13:04 HBMASTER: job (9, 0, 7) submitted to dispatcher
03:13:04 DISPATCHER: Trying to submit another job.
03:13:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:13:04 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464
03:13:04 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
03:13:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:13:04 WORKER: start processing job (9, 0, 7)
03:13:04 WORKER: args: ()
03:13:04 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0012618659205758187, 'num_filters_1': 75, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.01318629680367574, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 84, 'num_filters_3': 63}, 'budget': 400.0, 'working_directory': '.'}
03:13:20 DISPATCHER: Starting worker discovery
03:13:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:13:20 DISPATCHER: Finished worker discovery
03:14:20 DISPATCHER: Starting worker discovery
03:14:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:14:20 DISPATCHER: Finished worker discovery
03:15:20 DISPATCHER: Starting worker discovery
03:15:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:15:20 DISPATCHER: Finished worker discovery
03:16:20 DISPATCHER: Starting worker discovery
03:16:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:16:20 DISPATCHER: Finished worker discovery
03:17:20 DISPATCHER: Starting worker discovery
03:17:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:17:20 DISPATCHER: Finished worker discovery
03:18:20 DISPATCHER: Starting worker discovery
03:18:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:18:20 DISPATCHER: Finished worker discovery
03:19:20 DISPATCHER: Starting worker discovery
03:19:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:19:20 DISPATCHER: Finished worker discovery
03:20:03 WORKER: done with job (9, 0, 7), trying to register it.
03:20:03 WORKER: registered result for job (9, 0, 7) with dispatcher
03:20:03 DISPATCHER: job (9, 0, 7) finished
03:20:03 DISPATCHER: register_result: lock acquired
03:20:03 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
03:20:03 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0012618659205758187, 'num_filters_1': 75, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.01318629680367574, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 84, 'num_filters_3': 63}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5546560523964916, 'info': {'data05': 0.5546560523964916, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0012618659205758187, 'num_filters_1': 75, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.01318629680367574, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 84, 'num_filters_3': 63}"}}
exception: None

03:20:03 job_callback for (9, 0, 7) started
03:20:03 job_callback for (9, 0, 7) got condition
03:20:03 DISPATCHER: Trying to submit another job.
03:20:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:20:03 HBMASTER: Trying to run another job!
03:20:03 job_callback for (9, 0, 7) finished
03:20:03 ITERATION: Advancing config (9, 0, 3) to next budget 1200.000000
03:20:03 HBMASTER: schedule new run for iteration 9
03:20:03 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
03:20:03 HBMASTER: submitting job (9, 0, 3) to dispatcher
03:20:03 DISPATCHER: trying to submit job (9, 0, 3)
03:20:03 DISPATCHER: trying to notify the job_runner thread.
03:20:03 HBMASTER: job (9, 0, 3) submitted to dispatcher
03:20:03 DISPATCHER: Trying to submit another job.
03:20:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:20:03 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464
03:20:03 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13101140314513094464
03:20:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:20:03 WORKER: start processing job (9, 0, 3)
03:20:03 WORKER: args: ()
03:20:03 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0010289284744871533, 'num_filters_1': 108, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.016211582338254798, 'kernel_size_2': 5, 'num_filters_2': 101}, 'budget': 1200.0, 'working_directory': '.'}
03:20:20 DISPATCHER: Starting worker discovery
03:20:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:20:20 DISPATCHER: Finished worker discovery
03:21:20 DISPATCHER: Starting worker discovery
03:21:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:21:20 DISPATCHER: Finished worker discovery
03:22:20 DISPATCHER: Starting worker discovery
03:22:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:22:20 DISPATCHER: Finished worker discovery
03:23:20 DISPATCHER: Starting worker discovery
03:23:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:23:21 DISPATCHER: Finished worker discovery
03:24:21 DISPATCHER: Starting worker discovery
03:24:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:24:21 DISPATCHER: Finished worker discovery
03:25:21 DISPATCHER: Starting worker discovery
03:25:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:25:21 DISPATCHER: Finished worker discovery
03:26:21 DISPATCHER: Starting worker discovery
03:26:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:26:21 DISPATCHER: Finished worker discovery
03:27:21 DISPATCHER: Starting worker discovery
03:27:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:27:21 DISPATCHER: Finished worker discovery
03:28:21 DISPATCHER: Starting worker discovery
03:28:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:28:21 DISPATCHER: Finished worker discovery
03:29:21 DISPATCHER: Starting worker discovery
03:29:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:29:21 DISPATCHER: Finished worker discovery
03:30:21 DISPATCHER: Starting worker discovery
03:30:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:30:21 DISPATCHER: Finished worker discovery
03:31:21 DISPATCHER: Starting worker discovery
03:31:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:31:21 DISPATCHER: Finished worker discovery
03:32:21 DISPATCHER: Starting worker discovery
03:32:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:32:21 DISPATCHER: Finished worker discovery
03:33:21 DISPATCHER: Starting worker discovery
03:33:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:33:21 DISPATCHER: Finished worker discovery
03:34:21 DISPATCHER: Starting worker discovery
03:34:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:34:21 DISPATCHER: Finished worker discovery
03:35:21 DISPATCHER: Starting worker discovery
03:35:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:35:21 DISPATCHER: Finished worker discovery
03:36:21 DISPATCHER: Starting worker discovery
03:36:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:36:21 DISPATCHER: Finished worker discovery
03:37:21 DISPATCHER: Starting worker discovery
03:37:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:37:21 DISPATCHER: Finished worker discovery
03:38:21 DISPATCHER: Starting worker discovery
03:38:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:38:21 DISPATCHER: Finished worker discovery
03:39:21 DISPATCHER: Starting worker discovery
03:39:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:39:21 DISPATCHER: Finished worker discovery
03:40:21 DISPATCHER: Starting worker discovery
03:40:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:40:21 DISPATCHER: Finished worker discovery
03:40:37 WORKER: done with job (9, 0, 3), trying to register it.
03:40:37 WORKER: registered result for job (9, 0, 3) with dispatcher
03:40:37 DISPATCHER: job (9, 0, 3) finished
03:40:37 DISPATCHER: register_result: lock acquired
03:40:37 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.13101140314513094464 finished
03:40:37 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0010289284744871533, 'num_filters_1': 108, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.016211582338254798, 'kernel_size_2': 5, 'num_filters_2': 101}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5736538162110512, 'info': {'data05': 0.5736538162110512, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0010289284744871533, 'num_filters_1': 108, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.016211582338254798, 'kernel_size_2': 5, 'num_filters_2': 101}"}}
exception: None

03:40:37 job_callback for (9, 0, 3) started
03:40:37 DISPATCHER: Trying to submit another job.
03:40:37 job_callback for (9, 0, 3) got condition
03:40:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:40:37 HBMASTER: Trying to run another job!
03:40:37 job_callback for (9, 0, 3) finished
03:40:37 HBMASTER: shutdown initiated, shutdown_workers = True
03:40:37 WORKER: shutting down now!
03:40:37 DISPATCHER: Dispatcher shutting down
03:40:37 DISPATCHER: Trying to submit another job.
03:40:37 DISPATCHER: job_runner shutting down
03:40:37 DISPATCHER: discover_workers shutting down
03:40:37 DISPATCHER: 'discover_worker' thread exited
03:40:37 DISPATCHER: 'job_runner' thread exited
03:40:37 DISPATCHER: shut down complete
